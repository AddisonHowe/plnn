Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r5', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1704158314

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.216843787943116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.216843787943116 | validation: 12.374100139809888]
	TIME [epoch: 89.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.307354448332658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.307354448332658 | validation: 11.56938215269759]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.01295303637789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.01295303637789 | validation: 10.811385034207749]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.531595246845777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.531595246845777 | validation: 10.38288897242031]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.16348394084825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.16348394084825 | validation: 10.295847560771218]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.036566763393532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.036566763393532 | validation: 9.52275534574624]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.927514543419298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.927514543419298 | validation: 11.364720506681182]
	TIME [epoch: 12.9 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.801031774534968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.801031774534968 | validation: 8.91167846247785]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.135644647842176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.135644647842176 | validation: 5.874033699881227]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.330070345116108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.330070345116108 | validation: 7.063774925214054]
	TIME [epoch: 12.9 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.784030743446408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.784030743446408 | validation: 4.641271146897394]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.723396526332431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.723396526332431 | validation: 4.467550258616758]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.341718249793187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.341718249793187 | validation: 4.6292193622791675]
	TIME [epoch: 12.9 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.334690073532507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.334690073532507 | validation: 4.232491342020439]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3688953292311075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3688953292311075 | validation: 4.777134431374784]
	TIME [epoch: 12.9 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3975835873813605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3975835873813605 | validation: 4.178417437933108]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.383284911014221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.383284911014221 | validation: 4.578847154326192]
	TIME [epoch: 12.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.352000601318268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.352000601318268 | validation: 4.105552870369319]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.877833368622438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.877833368622438 | validation: 4.064342512759431]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.011463124811597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.011463124811597 | validation: 4.51447360700164]
	TIME [epoch: 12.9 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.254887003864944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.254887003864944 | validation: 4.376247240996793]
	TIME [epoch: 12.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.194465885594419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.194465885594419 | validation: 4.022533772897407]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.107517251318619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.107517251318619 | validation: 4.7451868386019544]
	TIME [epoch: 12.9 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.142182675876471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.142182675876471 | validation: 3.8591552918470255]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.867812181154356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.867812181154356 | validation: 3.986375254466103]
	TIME [epoch: 12.9 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6993666102831306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6993666102831306 | validation: 3.767340984206935]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.442953610409666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.442953610409666 | validation: 3.8161613397865195]
	TIME [epoch: 12.9 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.743869822114907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.743869822114907 | validation: 3.1876082336362517]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2453810301901234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2453810301901234 | validation: 3.9505087196449766]
	TIME [epoch: 12.9 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216988775173096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.216988775173096 | validation: 3.1368630205030184]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4827080160387074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4827080160387074 | validation: 2.7047743547054006]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4680607665758734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4680607665758734 | validation: 2.6571079152231847]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.543597720565104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.543597720565104 | validation: 2.6252086720682395]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6388142398795886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6388142398795886 | validation: 2.5219456943595766]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.46314082671398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.46314082671398 | validation: 2.4529009048512727]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315416447051957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.315416447051957 | validation: 5.010859374344643]
	TIME [epoch: 12.9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5163730483460363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5163730483460363 | validation: 2.7423306411921624]
	TIME [epoch: 12.9 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.424364954022085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.424364954022085 | validation: 3.9032909081678384]
	TIME [epoch: 12.9 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.657483813280058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.657483813280058 | validation: 2.892532905473946]
	TIME [epoch: 12.9 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2696686416102216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2696686416102216 | validation: 2.749748247972309]
	TIME [epoch: 12.9 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0799009128212016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0799009128212016 | validation: 1.9737512582583434]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.165388191622102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.165388191622102 | validation: 1.620221653107017]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0042199323055434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0042199323055434 | validation: 1.9273969070558956]
	TIME [epoch: 12.9 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8491076556260126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8491076556260126 | validation: 1.9284593216723789]
	TIME [epoch: 12.9 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0560640853208656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0560640853208656 | validation: 1.7773349024644283]
	TIME [epoch: 12.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8979477867517982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8979477867517982 | validation: 1.957564403278297]
	TIME [epoch: 12.9 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.968636825827449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.968636825827449 | validation: 1.7592379319532387]
	TIME [epoch: 12.9 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302009980981769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.302009980981769 | validation: 3.206127160875198]
	TIME [epoch: 12.9 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.227859760427543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.227859760427543 | validation: 2.019178954842227]
	TIME [epoch: 12.9 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7300784962756333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7300784962756333 | validation: 1.741566126115094]
	TIME [epoch: 12.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6936328151949027		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.6936328151949027 | validation: 1.7010725439440537]
	TIME [epoch: 12.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6549513548112573		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.6549513548112573 | validation: 1.389231914534733]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2958607908724944		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.2958607908724944 | validation: 1.5955296568655117]
	TIME [epoch: 12.9 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3897512899613806		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.3897512899613806 | validation: 1.693539186668009]
	TIME [epoch: 12.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9529167616702416		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.9529167616702416 | validation: 1.3213834009309045]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2734485347388644		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.2734485347388644 | validation: 1.86883488992988]
	TIME [epoch: 12.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5933393566459169		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.5933393566459169 | validation: 1.1564010347689524]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.386128447886468		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.386128447886468 | validation: 1.5071871956474285]
	TIME [epoch: 12.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3644325541524145		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.3644325541524145 | validation: 1.4600305781534304]
	TIME [epoch: 12.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7168529875460972		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.7168529875460972 | validation: 1.1894571444525235]
	TIME [epoch: 12.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3540594946681352		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.3540594946681352 | validation: 1.4776160193274261]
	TIME [epoch: 12.9 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.612611284787305		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.612611284787305 | validation: 1.4916922992676755]
	TIME [epoch: 12.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2648665948032822		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.2648665948032822 | validation: 1.6325991704804284]
	TIME [epoch: 12.9 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.57376082112032		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.57376082112032 | validation: 1.3176319440115876]
	TIME [epoch: 12.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6790758300856632		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.6790758300856632 | validation: 1.4612858528000794]
	TIME [epoch: 12.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.330617378230679		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.330617378230679 | validation: 1.417347611481657]
	TIME [epoch: 12.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.282863928993319		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.282863928993319 | validation: 1.392365832759033]
	TIME [epoch: 12.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5081372406252127		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.5081372406252127 | validation: 1.4321573419054319]
	TIME [epoch: 12.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3431965691495473		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.3431965691495473 | validation: 1.2874045976669926]
	TIME [epoch: 12.9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.383394652202573		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.383394652202573 | validation: 1.2443378341246896]
	TIME [epoch: 12.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4741875117306138		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.4741875117306138 | validation: 1.1930174350476332]
	TIME [epoch: 12.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.253183727393098		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.253183727393098 | validation: 1.1139540782446309]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3619114178523772		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.3619114178523772 | validation: 1.515466571370739]
	TIME [epoch: 13 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.814147647356489		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.814147647356489 | validation: 1.0943324671302344]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4511749808653875		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.4511749808653875 | validation: 1.0593243853337249]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.20998011799892		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.20998011799892 | validation: 1.1369522572027604]
	TIME [epoch: 12.9 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0839012802352515		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.0839012802352515 | validation: 1.3334834562938318]
	TIME [epoch: 12.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3341564145700573		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.3341564145700573 | validation: 1.1647309366948717]
	TIME [epoch: 12.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4051244080038847		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.4051244080038847 | validation: 0.9964594706679307]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.404743358479264		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.404743358479264 | validation: 0.8631054360862851]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1031714195186648		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.1031714195186648 | validation: 1.4008119657618507]
	TIME [epoch: 12.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.29358440966663		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.29358440966663 | validation: 1.4449640522371123]
	TIME [epoch: 12.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4056539380335638		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.4056539380335638 | validation: 0.9347376434785055]
	TIME [epoch: 12.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0280013947524989		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.0280013947524989 | validation: 1.8756984700191175]
	TIME [epoch: 12.9 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4900639971823255		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.4900639971823255 | validation: 1.3751170346467292]
	TIME [epoch: 12.9 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2454160055160768		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.2454160055160768 | validation: 1.0339150532768582]
	TIME [epoch: 12.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.037802550712415		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.037802550712415 | validation: 1.4015404521216517]
	TIME [epoch: 12.9 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.068392555279695		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.068392555279695 | validation: 1.5024913062630705]
	TIME [epoch: 12.9 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.29884927846735		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.29884927846735 | validation: 1.1499268485678327]
	TIME [epoch: 12.9 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3373177555695084		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.3373177555695084 | validation: 1.1528489472885692]
	TIME [epoch: 12.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.165059705837419		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.165059705837419 | validation: 0.912011702318515]
	TIME [epoch: 12.9 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.446248041067159		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.446248041067159 | validation: 1.1694708440748958]
	TIME [epoch: 12.9 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0974971668598585		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.0974971668598585 | validation: 0.8777929621671676]
	TIME [epoch: 12.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3246948843805324		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.3246948843805324 | validation: 1.0861962501308629]
	TIME [epoch: 12.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.105350023970927		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.105350023970927 | validation: 1.0085853456913016]
	TIME [epoch: 12.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.280478876998918		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.280478876998918 | validation: 1.3635514874575099]
	TIME [epoch: 12.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2934204077598206		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.2934204077598206 | validation: 0.9362489112207727]
	TIME [epoch: 12.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8968576479164796		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.8968576479164796 | validation: 1.17908360533913]
	TIME [epoch: 12.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2958767599601784		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.2958767599601784 | validation: 0.8575975681617394]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.209925196309484		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.209925196309484 | validation: 1.524039166610581]
	TIME [epoch: 12.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1194295242449368		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.1194295242449368 | validation: 0.7459216407549577]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0694207684547146		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.0694207684547146 | validation: 0.8067306337787872]
	TIME [epoch: 12.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.975305731674085		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.975305731674085 | validation: 1.9408504194807261]
	TIME [epoch: 12.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2606102819274714		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.2606102819274714 | validation: 0.8803555047638462]
	TIME [epoch: 12.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0038717600561324		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.0038717600561324 | validation: 0.9125466707851664]
	TIME [epoch: 12.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2994647924596114		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.2994647924596114 | validation: 1.8795951230436772]
	TIME [epoch: 12.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.292814028199928		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.292814028199928 | validation: 0.7553278637224492]
	TIME [epoch: 12.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1129234886773278		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.1129234886773278 | validation: 1.0612304012894773]
	TIME [epoch: 12.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0544126563770204		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.0544126563770204 | validation: 1.314449035392517]
	TIME [epoch: 12.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1601896183523717		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.1601896183523717 | validation: 0.7980346089293489]
	TIME [epoch: 12.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9539160333333818		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.9539160333333818 | validation: 1.9394506100651108]
	TIME [epoch: 12.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4002720687467194		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.4002720687467194 | validation: 1.262348711010595]
	TIME [epoch: 12.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1494090958642955		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.1494090958642955 | validation: 1.3256745382751232]
	TIME [epoch: 12.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0115120197787286		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.0115120197787286 | validation: 0.8734932214525907]
	TIME [epoch: 12.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.998650901390977		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.998650901390977 | validation: 0.8453402597539548]
	TIME [epoch: 12.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9695325820435003		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.9695325820435003 | validation: 0.8882321729061639]
	TIME [epoch: 12.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0687612740927042		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.0687612740927042 | validation: 0.8515733360854674]
	TIME [epoch: 12.9 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9690525853827197		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.9690525853827197 | validation: 0.7711203450126267]
	TIME [epoch: 12.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9900188362082383		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.9900188362082383 | validation: 0.7110660305238105]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9847476289745908		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.9847476289745908 | validation: 1.1790806317768583]
	TIME [epoch: 12.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.073364503570375		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.073364503570375 | validation: 0.8644533158786314]
	TIME [epoch: 12.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0537837457671366		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.0537837457671366 | validation: 0.8176129908346123]
	TIME [epoch: 12.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9203939703865156		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.9203939703865156 | validation: 0.626137618587136]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8674384793956098		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.8674384793956098 | validation: 1.0268642867190627]
	TIME [epoch: 12.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.943484620711839		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.943484620711839 | validation: 0.8486480985918787]
	TIME [epoch: 12.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9267890257912934		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.9267890257912934 | validation: 0.8172357415179059]
	TIME [epoch: 12.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0643075092972034		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.0643075092972034 | validation: 0.7086153041964439]
	TIME [epoch: 13 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0881814245813222		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.0881814245813222 | validation: 0.7831365833125693]
	TIME [epoch: 12.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2085826678382896		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.2085826678382896 | validation: 0.8238910419162936]
	TIME [epoch: 12.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8449456071153175		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.8449456071153175 | validation: 0.9847073718326587]
	TIME [epoch: 12.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1357864137900242		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.1357864137900242 | validation: 0.6766851462455996]
	TIME [epoch: 12.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9248972282908468		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.9248972282908468 | validation: 0.9152126630129126]
	TIME [epoch: 12.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.123239069798796		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.123239069798796 | validation: 1.2294986183189704]
	TIME [epoch: 12.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.092178329496103		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.092178329496103 | validation: 1.7839098143754075]
	TIME [epoch: 12.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0618208342961142		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.0618208342961142 | validation: 0.6879698335821319]
	TIME [epoch: 12.9 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9364677870195653		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.9364677870195653 | validation: 0.9057881492968707]
	TIME [epoch: 12.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285682893569652		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.2285682893569652 | validation: 2.504329591980742]
	TIME [epoch: 12.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.428546052244546		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.428546052244546 | validation: 1.2496885139944567]
	TIME [epoch: 12.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0876562193089008		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.0876562193089008 | validation: 0.642135749642142]
	TIME [epoch: 12.9 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0026143899366025		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.0026143899366025 | validation: 0.9438821470054702]
	TIME [epoch: 12.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.886007725171724		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.886007725171724 | validation: 1.1180842576820298]
	TIME [epoch: 12.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0781024038437945		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.0781024038437945 | validation: 0.8884299654712294]
	TIME [epoch: 12.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0142583426864185		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.0142583426864185 | validation: 1.0463643359616064]
	TIME [epoch: 12.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9589572079356767		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.9589572079356767 | validation: 0.9977196108451931]
	TIME [epoch: 12.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0420143765255838		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.0420143765255838 | validation: 0.8161027329033683]
	TIME [epoch: 12.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8808420786238964		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.8808420786238964 | validation: 0.7117072502243448]
	TIME [epoch: 12.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0788351818373227		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.0788351818373227 | validation: 0.6157308332220947]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0123728343983058		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.0123728343983058 | validation: 1.3329203804307803]
	TIME [epoch: 12.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9747822326173271		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.9747822326173271 | validation: 0.9424241086104153]
	TIME [epoch: 12.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9057241720170852		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.9057241720170852 | validation: 0.8383197010900307]
	TIME [epoch: 12.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8897021991065943		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.8897021991065943 | validation: 0.7686759931069507]
	TIME [epoch: 12.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9223619496375952		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.9223619496375952 | validation: 0.6513812126486846]
	TIME [epoch: 12.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.87524703543978		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.87524703543978 | validation: 1.4005005000817272]
	TIME [epoch: 12.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9858809921192494		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.9858809921192494 | validation: 0.7271638199527795]
	TIME [epoch: 12.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.985956280293351		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.985956280293351 | validation: 0.6566206247487171]
	TIME [epoch: 12.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.840757925276596		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.840757925276596 | validation: 1.121759833233976]
	TIME [epoch: 12.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.920339485253699		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.920339485253699 | validation: 2.514856102806773]
	TIME [epoch: 12.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.421782594335916		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.421782594335916 | validation: 0.8167244020289463]
	TIME [epoch: 12.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.982464363552835		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.982464363552835 | validation: 0.8620343756556119]
	TIME [epoch: 12.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8845226448314685		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.8845226448314685 | validation: 0.6443543227106722]
	TIME [epoch: 12.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7871141226706315		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.7871141226706315 | validation: 0.9190168177069875]
	TIME [epoch: 12.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.873336737014659		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.873336737014659 | validation: 0.7659705476043479]
	TIME [epoch: 12.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8936092476057556		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.8936092476057556 | validation: 0.6050113888724853]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7336090539378478		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.7336090539378478 | validation: 1.011630045432119]
	TIME [epoch: 12.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0590633864029824		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.0590633864029824 | validation: 0.5618113830377536]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8748946326707597		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.8748946326707597 | validation: 0.6221449822909181]
	TIME [epoch: 12.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7311663974302298		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.7311663974302298 | validation: 0.6905047006864734]
	TIME [epoch: 12.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6898538145779427		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.6898538145779427 | validation: 1.1478670344077297]
	TIME [epoch: 12.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9071343050107941		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.9071343050107941 | validation: 0.7803609325966104]
	TIME [epoch: 12.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8642458089245018		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.8642458089245018 | validation: 0.7217403618787234]
	TIME [epoch: 12.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7233066070170192		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.7233066070170192 | validation: 0.8123589995941772]
	TIME [epoch: 12.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9996869978503093		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.9996869978503093 | validation: 0.758346238745855]
	TIME [epoch: 12.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7510280273548113		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.7510280273548113 | validation: 0.5904903652906808]
	TIME [epoch: 12.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.874476516704022		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.874476516704022 | validation: 1.2438987001504638]
	TIME [epoch: 12.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9209216290229189		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.9209216290229189 | validation: 0.9987009228239323]
	TIME [epoch: 12.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7871963474481652		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.7871963474481652 | validation: 1.3371893191136377]
	TIME [epoch: 12.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.00041758345873		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.00041758345873 | validation: 0.7921165136570669]
	TIME [epoch: 12.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.809831711358448		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.809831711358448 | validation: 0.7749050118255736]
	TIME [epoch: 12.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9396479771761539		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.9396479771761539 | validation: 0.5788466499546105]
	TIME [epoch: 12.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8346265791074704		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.8346265791074704 | validation: 0.6001706042149776]
	TIME [epoch: 12.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8092590410094049		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.8092590410094049 | validation: 0.5814486199212864]
	TIME [epoch: 12.9 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7186588230734828		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.7186588230734828 | validation: 0.616423920478031]
	TIME [epoch: 12.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3915563687061017		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.3915563687061017 | validation: 0.9080762546873479]
	TIME [epoch: 12.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9785419796139843		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9785419796139843 | validation: 0.5836595980038134]
	TIME [epoch: 12.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7521652235811064		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.7521652235811064 | validation: 0.544743643665276]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6997536427408907		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.6997536427408907 | validation: 0.8332622389386387]
	TIME [epoch: 12.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9039913805799732		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.9039913805799732 | validation: 1.0561208371542978]
	TIME [epoch: 12.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8803714622069075		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.8803714622069075 | validation: 0.8003568149069287]
	TIME [epoch: 12.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.777168457052621		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.777168457052621 | validation: 0.7952273598049002]
	TIME [epoch: 12.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8102579512171713		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.8102579512171713 | validation: 1.877211104125744]
	TIME [epoch: 12.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1897903305103263		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.1897903305103263 | validation: 0.6123731811720473]
	TIME [epoch: 12.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7632108995263466		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.7632108995263466 | validation: 0.7440510167622583]
	TIME [epoch: 12.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6991688128335469		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.6991688128335469 | validation: 0.8410682825200173]
	TIME [epoch: 12.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8736952897750586		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.8736952897750586 | validation: 0.553820761470301]
	TIME [epoch: 12.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7386690831792317		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.7386690831792317 | validation: 0.799044361888835]
	TIME [epoch: 12.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8140001112351114		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.8140001112351114 | validation: 0.6204147873020474]
	TIME [epoch: 12.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8401536682174732		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.8401536682174732 | validation: 0.8764006560235217]
	TIME [epoch: 12.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.769851707575016		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.769851707575016 | validation: 0.8263278992734627]
	TIME [epoch: 12.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8896752957771203		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.8896752957771203 | validation: 0.9054254709322007]
	TIME [epoch: 12.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8047032665985965		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.8047032665985965 | validation: 0.6301302728846768]
	TIME [epoch: 12.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7800364562253228		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.7800364562253228 | validation: 0.5455449351452772]
	TIME [epoch: 12.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0014491146453128		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.0014491146453128 | validation: 0.5975212982804888]
	TIME [epoch: 12.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9217576821422819		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.9217576821422819 | validation: 0.709195812219099]
	TIME [epoch: 12.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7911113148558853		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.7911113148558853 | validation: 0.5980791283741775]
	TIME [epoch: 12.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070310860342374		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.7070310860342374 | validation: 0.7870933619960578]
	TIME [epoch: 12.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6915559689351434		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.6915559689351434 | validation: 0.8218815115923083]
	TIME [epoch: 12.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.164532998115813		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.164532998115813 | validation: 0.7158606424128788]
	TIME [epoch: 12.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8419575587740467		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.8419575587740467 | validation: 0.7428056006542377]
	TIME [epoch: 12.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8029561714609427		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.8029561714609427 | validation: 0.5777407176180062]
	TIME [epoch: 12.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6708898992078411		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.6708898992078411 | validation: 0.5202953978063898]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7648387666881192		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.7648387666881192 | validation: 0.7121556962583708]
	TIME [epoch: 12.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841121529445466		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.6841121529445466 | validation: 0.58750127537623]
	TIME [epoch: 12.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235446798304136		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.6235446798304136 | validation: 1.1330529526687831]
	TIME [epoch: 12.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.814407073435055		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.814407073435055 | validation: 0.5979263614788934]
	TIME [epoch: 12.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7031302083735262		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.7031302083735262 | validation: 0.6795360623562118]
	TIME [epoch: 12.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6203236697162167		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.6203236697162167 | validation: 0.7390862752749027]
	TIME [epoch: 12.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8501654553381637		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.8501654553381637 | validation: 0.530115447886054]
	TIME [epoch: 12.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993240519646305		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.6993240519646305 | validation: 0.9026439777043246]
	TIME [epoch: 12.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7923944094741633		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.7923944094741633 | validation: 0.5695774625541354]
	TIME [epoch: 12.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6085496188650512		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.6085496188650512 | validation: 0.7080764486760819]
	TIME [epoch: 12.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245538419619475		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.7245538419619475 | validation: 0.5219023097833746]
	TIME [epoch: 12.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8639429194881865		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.8639429194881865 | validation: 0.5950861679588126]
	TIME [epoch: 12.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.648320256682225		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.648320256682225 | validation: 0.6873373731916818]
	TIME [epoch: 12.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6157855417471978		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.6157855417471978 | validation: 0.6996055672715914]
	TIME [epoch: 12.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7590744572334441		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.7590744572334441 | validation: 0.49302003518158344]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886794328292811		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.6886794328292811 | validation: 0.5890216856247202]
	TIME [epoch: 12.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657194085417371		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.6657194085417371 | validation: 0.6226716354675191]
	TIME [epoch: 12.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.610481316663664		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.610481316663664 | validation: 0.4900706954174261]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6485086051128119		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.6485086051128119 | validation: 0.5445718962218528]
	TIME [epoch: 12.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6419336251460526		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.6419336251460526 | validation: 0.48036639957099475]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.763511873694111		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.763511873694111 | validation: 0.4897929438843335]
	TIME [epoch: 12.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6773697887824843		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.6773697887824843 | validation: 0.48162934698833826]
	TIME [epoch: 12.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.663219715512082		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.663219715512082 | validation: 0.8732978100984553]
	TIME [epoch: 12.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6471961878708831		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.6471961878708831 | validation: 0.6073723662441851]
	TIME [epoch: 12.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.656180144982494		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.656180144982494 | validation: 0.833745763703395]
	TIME [epoch: 12.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820181135778591		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.6820181135778591 | validation: 0.7477949032818063]
	TIME [epoch: 12.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6757571055827696		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.6757571055827696 | validation: 1.2087160379750004]
	TIME [epoch: 12.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7352606066403607		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.7352606066403607 | validation: 0.41677225812434676]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.56509459657954		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.56509459657954 | validation: 1.1640617023140925]
	TIME [epoch: 12.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6891680468089911		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.6891680468089911 | validation: 0.6550992436497722]
	TIME [epoch: 12.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5618983267852339		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.5618983267852339 | validation: 0.6977015901918361]
	TIME [epoch: 12.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6264609703940259		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.6264609703940259 | validation: 0.497417296444887]
	TIME [epoch: 12.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6293336489418586		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.6293336489418586 | validation: 0.565009910763565]
	TIME [epoch: 12.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5598669033086711		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.5598669033086711 | validation: 0.5769488655834377]
	TIME [epoch: 12.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6930690469228734		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.6930690469228734 | validation: 0.7709914402479783]
	TIME [epoch: 12.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042355092815453		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.7042355092815453 | validation: 0.5924713309573152]
	TIME [epoch: 12.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6731318762173671		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.6731318762173671 | validation: 0.6084266646696762]
	TIME [epoch: 12.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5984799809887567		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.5984799809887567 | validation: 0.8321770382805244]
	TIME [epoch: 12.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6153584400655451		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.6153584400655451 | validation: 0.71425268370828]
	TIME [epoch: 12.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.663973453110153		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.663973453110153 | validation: 0.9172212369430327]
	TIME [epoch: 12.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834926580589262		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.6834926580589262 | validation: 0.450634986656286]
	TIME [epoch: 12.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6050992601030284		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.6050992601030284 | validation: 0.38922709860485166]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5932106720390644		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.5932106720390644 | validation: 0.708950276957539]
	TIME [epoch: 12.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5824850980338963		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.5824850980338963 | validation: 0.7561981057618082]
	TIME [epoch: 12.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8467747444309672		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.8467747444309672 | validation: 0.7479355798411857]
	TIME [epoch: 12.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6519181601174392		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.6519181601174392 | validation: 0.3916026010052255]
	TIME [epoch: 12.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5761475878281132		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.5761475878281132 | validation: 0.6815049356692134]
	TIME [epoch: 12.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5854521621819555		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.5854521621819555 | validation: 0.4593585665759801]
	TIME [epoch: 12.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5285986522749246		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.5285986522749246 | validation: 0.8812620146625075]
	TIME [epoch: 13 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.706802039435011		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.706802039435011 | validation: 0.993246049033786]
	TIME [epoch: 12.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881114423622621		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.6881114423622621 | validation: 0.5406901051367842]
	TIME [epoch: 12.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888991209179932		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.6888991209179932 | validation: 0.4779516345026225]
	TIME [epoch: 12.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5886107206327988		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.5886107206327988 | validation: 0.6127636828761213]
	TIME [epoch: 12.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6440851408351974		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.6440851408351974 | validation: 0.4436318929418442]
	TIME [epoch: 12.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5253496303268971		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.5253496303268971 | validation: 0.42621319004846187]
	TIME [epoch: 13 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5951586894870768		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.5951586894870768 | validation: 0.45102711671429574]
	TIME [epoch: 13 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6348125705923502		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.6348125705923502 | validation: 0.5631410444369148]
	TIME [epoch: 13 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5797212556453196		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.5797212556453196 | validation: 0.7114543127578208]
	TIME [epoch: 12.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170794170853065		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.7170794170853065 | validation: 0.3474718886962346]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6616122045428285		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.6616122045428285 | validation: 0.45350766946213583]
	TIME [epoch: 13 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5851157448673148		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.5851157448673148 | validation: 0.7894117693013896]
	TIME [epoch: 12.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7896894047170848		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.7896894047170848 | validation: 0.7076773222015799]
	TIME [epoch: 12.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849055814555544		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6849055814555544 | validation: 0.5762539394674652]
	TIME [epoch: 12.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6052220703587634		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.6052220703587634 | validation: 0.5153100928985481]
	TIME [epoch: 12.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5378137179113673		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.5378137179113673 | validation: 0.5228530853409862]
	TIME [epoch: 12.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5589896021984305		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.5589896021984305 | validation: 0.5769231789087084]
	TIME [epoch: 12.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5469919957100144		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.5469919957100144 | validation: 0.414570302269793]
	TIME [epoch: 12.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.53133431878157		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.53133431878157 | validation: 0.7547473114756649]
	TIME [epoch: 12.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6520116143225223		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6520116143225223 | validation: 0.41429721097280037]
	TIME [epoch: 12.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5774580005715958		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.5774580005715958 | validation: 0.8156807069008204]
	TIME [epoch: 12.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6588141662970072		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.6588141662970072 | validation: 0.800580290385798]
	TIME [epoch: 12.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6756738357387998		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.6756738357387998 | validation: 0.712031674011152]
	TIME [epoch: 12.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6728631571294029		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.6728631571294029 | validation: 0.9537234672363932]
	TIME [epoch: 12.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.740121744737614		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.740121744737614 | validation: 0.48547477381263265]
	TIME [epoch: 12.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5786267063457075		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.5786267063457075 | validation: 0.40774081434326603]
	TIME [epoch: 12.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.514551576690942		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.514551576690942 | validation: 0.4953856213539211]
	TIME [epoch: 12.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6484389209983801		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6484389209983801 | validation: 0.3605101379320587]
	TIME [epoch: 12.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45404497561308116		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.45404497561308116 | validation: 0.3533178536473098]
	TIME [epoch: 13 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47714044973895553		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.47714044973895553 | validation: 0.45583339010748203]
	TIME [epoch: 12.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5737110347534238		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.5737110347534238 | validation: 0.7285347193964141]
	TIME [epoch: 12.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283656091263413		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.6283656091263413 | validation: 0.5247807919203777]
	TIME [epoch: 12.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6204346974649395		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.6204346974649395 | validation: 0.5526287338622583]
	TIME [epoch: 12.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9258236839650109		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.9258236839650109 | validation: 0.5407428717686239]
	TIME [epoch: 12.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4635996152727344		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.4635996152727344 | validation: 0.46099706348114744]
	TIME [epoch: 12.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.531566230654759		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.531566230654759 | validation: 0.44345020365234694]
	TIME [epoch: 13 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5865630413235154		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.5865630413235154 | validation: 0.37418291071240795]
	TIME [epoch: 12.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5720469905630008		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.5720469905630008 | validation: 0.45793393333985094]
	TIME [epoch: 12.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5041711116331092		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.5041711116331092 | validation: 0.612086575330904]
	TIME [epoch: 13 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540229830251167		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.5540229830251167 | validation: 0.41164426935114073]
	TIME [epoch: 13 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6072304827767387		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.6072304827767387 | validation: 0.5120792365697006]
	TIME [epoch: 12.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.624971149168718		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.624971149168718 | validation: 0.5758561098775468]
	TIME [epoch: 12.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5688590320515933		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.5688590320515933 | validation: 0.5646278545759416]
	TIME [epoch: 13 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5966361526166406		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.5966361526166406 | validation: 0.38981089057020213]
	TIME [epoch: 13 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49420974018984215		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.49420974018984215 | validation: 0.3981502902480095]
	TIME [epoch: 12.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5349714317111707		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.5349714317111707 | validation: 0.4119988058533353]
	TIME [epoch: 12.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540493795112913		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.5540493795112913 | validation: 0.40767724544108885]
	TIME [epoch: 12.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6175106924851836		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.6175106924851836 | validation: 0.5048655264105362]
	TIME [epoch: 12.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5225460825779505		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.5225460825779505 | validation: 0.5143521518921608]
	TIME [epoch: 12.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4935164429309355		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.4935164429309355 | validation: 0.3287175451610309]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_309.pth
	Model improved!!!
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49297341582811727		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.49297341582811727 | validation: 0.3669626948989354]
	TIME [epoch: 12.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44374621556948235		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.44374621556948235 | validation: 0.8865552268387153]
	TIME [epoch: 12.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5102951640107856		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5102951640107856 | validation: 0.36637454203055625]
	TIME [epoch: 12.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112915256262296		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.5112915256262296 | validation: 0.35466247300463966]
	TIME [epoch: 13 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44868613647885036		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.44868613647885036 | validation: 0.4996665563059102]
	TIME [epoch: 12.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47978916794707493		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.47978916794707493 | validation: 0.6042401993582919]
	TIME [epoch: 12.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5164463547316096		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.5164463547316096 | validation: 0.39474390903567363]
	TIME [epoch: 13 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4713962591363597		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.4713962591363597 | validation: 0.5874029199365879]
	TIME [epoch: 12.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5711883030666137		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5711883030666137 | validation: 1.8288776441527503]
	TIME [epoch: 12.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9527480081319274		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.9527480081319274 | validation: 0.3629458537515437]
	TIME [epoch: 12.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5466834567635535		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.5466834567635535 | validation: 0.4624044712562063]
	TIME [epoch: 13 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4390427935144077		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.4390427935144077 | validation: 0.28216777068973]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47660826077238755		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.47660826077238755 | validation: 0.42481878477624807]
	TIME [epoch: 12.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446412281175252		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.5446412281175252 | validation: 0.36990497143866935]
	TIME [epoch: 12.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42210923242132103		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.42210923242132103 | validation: 0.3710970304082704]
	TIME [epoch: 13 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45151440767751577		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.45151440767751577 | validation: 0.42843163219878366]
	TIME [epoch: 12.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4401762811667683		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.4401762811667683 | validation: 0.6028070817156302]
	TIME [epoch: 13 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47361308380362604		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.47361308380362604 | validation: 0.36600364701779775]
	TIME [epoch: 13 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4201688053106083		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.4201688053106083 | validation: 0.4686741983684627]
	TIME [epoch: 13 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46082359990518584		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.46082359990518584 | validation: 0.3089197298344221]
	TIME [epoch: 12.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42213611831351927		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.42213611831351927 | validation: 0.6042563163895892]
	TIME [epoch: 13 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5615736672893243		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5615736672893243 | validation: 0.577796067602925]
	TIME [epoch: 13 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5182468074249053		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.5182468074249053 | validation: 0.7383157113909238]
	TIME [epoch: 12.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49956585617122506		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.49956585617122506 | validation: 0.6113466351985585]
	TIME [epoch: 13 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4906379345092319		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.4906379345092319 | validation: 0.34508266223780243]
	TIME [epoch: 13 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49427458686036313		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.49427458686036313 | validation: 0.39026024423491495]
	TIME [epoch: 12.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4412925153769104		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.4412925153769104 | validation: 0.4237961756473025]
	TIME [epoch: 13 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5003037423014747		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.5003037423014747 | validation: 0.34871529388624994]
	TIME [epoch: 12.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40167879765677783		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.40167879765677783 | validation: 0.4420592390407421]
	TIME [epoch: 13 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38845469659273496		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.38845469659273496 | validation: 0.4105808851672849]
	TIME [epoch: 12.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44249934785254147		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.44249934785254147 | validation: 0.45419914798297084]
	TIME [epoch: 12.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5302953264944212		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.5302953264944212 | validation: 0.36495861078094416]
	TIME [epoch: 13 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43375721184161653		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.43375721184161653 | validation: 0.2890154316368799]
	TIME [epoch: 12.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5829940532918191		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.5829940532918191 | validation: 0.44750385921723834]
	TIME [epoch: 12.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5111290292068784		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5111290292068784 | validation: 0.4551063915310638]
	TIME [epoch: 12.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4033631668070532		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.4033631668070532 | validation: 0.3906328503609028]
	TIME [epoch: 13 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5174951463709314		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.5174951463709314 | validation: 0.4655485776906509]
	TIME [epoch: 12.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46533162695065544		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.46533162695065544 | validation: 0.3544703356619017]
	TIME [epoch: 12.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46989718449154577		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.46989718449154577 | validation: 0.3244103902271779]
	TIME [epoch: 12.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4747418943672462		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.4747418943672462 | validation: 0.49942015952702945]
	TIME [epoch: 12.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5417437073261491		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5417437073261491 | validation: 0.5275832802752345]
	TIME [epoch: 12.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5291287860231608		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.5291287860231608 | validation: 1.1874487895575991]
	TIME [epoch: 12.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.65353511905164		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.65353511905164 | validation: 0.2833510950102781]
	TIME [epoch: 12.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3378374733654869		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.3378374733654869 | validation: 0.7437418241210351]
	TIME [epoch: 12.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4928134653554009		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.4928134653554009 | validation: 0.6042920370743907]
	TIME [epoch: 12.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5047039472517085		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5047039472517085 | validation: 0.3046592492338756]
	TIME [epoch: 12.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.426265954178921		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.426265954178921 | validation: 0.3082787593990555]
	TIME [epoch: 13 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990854697034709		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.3990854697034709 | validation: 0.23629863211015825]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.426789743435243		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.426789743435243 | validation: 0.40877127959864207]
	TIME [epoch: 12.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42412751049207964		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.42412751049207964 | validation: 0.32608892300565695]
	TIME [epoch: 13 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37365504426377105		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.37365504426377105 | validation: 0.5123859776629134]
	TIME [epoch: 12.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4024638835120848		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.4024638835120848 | validation: 0.31703410812715876]
	TIME [epoch: 12.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4108706080886974		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.4108706080886974 | validation: 0.4241844770613234]
	TIME [epoch: 12.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243600815084855		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.7243600815084855 | validation: 0.6323853290123801]
	TIME [epoch: 13 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4764750614523333		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.4764750614523333 | validation: 0.2775102582233363]
	TIME [epoch: 12.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35491781900423236		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.35491781900423236 | validation: 0.4097623307113944]
	TIME [epoch: 12.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4215374122488841		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.4215374122488841 | validation: 0.5052892289553905]
	TIME [epoch: 13 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49143017619554374		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.49143017619554374 | validation: 0.9106206242517477]
	TIME [epoch: 12.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5395373474890035		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5395373474890035 | validation: 0.31835057077814616]
	TIME [epoch: 12.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45539158568736227		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.45539158568736227 | validation: 0.26198314804771583]
	TIME [epoch: 12.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48552671957441557		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.48552671957441557 | validation: 0.39019362045626327]
	TIME [epoch: 13 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3806213451882344		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.3806213451882344 | validation: 0.26183389788445]
	TIME [epoch: 12.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42162856731223103		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.42162856731223103 | validation: 0.24987536970894533]
	TIME [epoch: 12.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4719168658500915		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.4719168658500915 | validation: 0.30430448680957783]
	TIME [epoch: 12.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46518197139118755		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.46518197139118755 | validation: 0.4342655253779634]
	TIME [epoch: 12.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40818953645277956		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.40818953645277956 | validation: 0.3305136818988496]
	TIME [epoch: 12.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41243130775593306		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.41243130775593306 | validation: 0.27146451441965846]
	TIME [epoch: 12.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4372293828014268		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.4372293828014268 | validation: 0.4134356724067142]
	TIME [epoch: 13 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3807100001487499		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.3807100001487499 | validation: 0.30338552748243236]
	TIME [epoch: 12.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4284050415234346		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.4284050415234346 | validation: 0.24603561502111426]
	TIME [epoch: 12.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3681979287739938		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.3681979287739938 | validation: 0.3952430459233574]
	TIME [epoch: 12.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5773053287547597		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5773053287547597 | validation: 0.38622914836305816]
	TIME [epoch: 12.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45019450066179856		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.45019450066179856 | validation: 0.3125376208556123]
	TIME [epoch: 12.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4082283509481755		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.4082283509481755 | validation: 0.32636563381123895]
	TIME [epoch: 12.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4430577265427747		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.4430577265427747 | validation: 0.4926181787857923]
	TIME [epoch: 13 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42964887667287155		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.42964887667287155 | validation: 0.5441300776043412]
	TIME [epoch: 12.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41866198118711995		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.41866198118711995 | validation: 0.45444552094758905]
	TIME [epoch: 12.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5808407979575536		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.5808407979575536 | validation: 0.31060833453330605]
	TIME [epoch: 12.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3452216243361682		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.3452216243361682 | validation: 0.41320974857975834]
	TIME [epoch: 12.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41315829602644816		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.41315829602644816 | validation: 0.6347456716883769]
	TIME [epoch: 12.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7119635552464507		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.7119635552464507 | validation: 0.49660568298680247]
	TIME [epoch: 12.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4488247339812683		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.4488247339812683 | validation: 0.2573629518230087]
	TIME [epoch: 12.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389776645142655		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.389776645142655 | validation: 0.45144523134819314]
	TIME [epoch: 12.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4702427078176266		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.4702427078176266 | validation: 0.34852994377677915]
	TIME [epoch: 12.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42356859978833483		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.42356859978833483 | validation: 0.34856158137129684]
	TIME [epoch: 12.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38780892136635337		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.38780892136635337 | validation: 0.32783329852304904]
	TIME [epoch: 12.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38834381362798115		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.38834381362798115 | validation: 0.27031548171574094]
	TIME [epoch: 12.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38575575196306544		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.38575575196306544 | validation: 0.42873503458841966]
	TIME [epoch: 12.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4532999554549455		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.4532999554549455 | validation: 0.3478307129846813]
	TIME [epoch: 12.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38860440052358874		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.38860440052358874 | validation: 0.32516636875913235]
	TIME [epoch: 13 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42314432028536764		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.42314432028536764 | validation: 0.533118159644075]
	TIME [epoch: 12.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4096139732870326		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.4096139732870326 | validation: 0.789076098265861]
	TIME [epoch: 12.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5956049927613375		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.5956049927613375 | validation: 0.3417761281586]
	TIME [epoch: 12.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35150434547505155		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.35150434547505155 | validation: 0.48408590436261056]
	TIME [epoch: 12.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4052378482792849		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.4052378482792849 | validation: 0.2768045207252568]
	TIME [epoch: 12.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33972089142389705		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.33972089142389705 | validation: 0.5617788089380218]
	TIME [epoch: 12.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500624781228464		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.4500624781228464 | validation: 0.4329929936481557]
	TIME [epoch: 13 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42473966287170056		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.42473966287170056 | validation: 0.31098445222369037]
	TIME [epoch: 12.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36183932363415006		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.36183932363415006 | validation: 0.49164084916770007]
	TIME [epoch: 12.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36271977949454487		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.36271977949454487 | validation: 0.4060764128667052]
	TIME [epoch: 13 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3801112036180467		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.3801112036180467 | validation: 0.7081230823088279]
	TIME [epoch: 12.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5592549828085592		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5592549828085592 | validation: 0.4916207206741149]
	TIME [epoch: 12.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42864253096567817		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.42864253096567817 | validation: 0.7427959770394966]
	TIME [epoch: 12.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4776717422625378		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.4776717422625378 | validation: 0.29858818990884867]
	TIME [epoch: 12.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4510102597537643		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.4510102597537643 | validation: 0.31014198621242234]
	TIME [epoch: 12.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.430068108932663		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.430068108932663 | validation: 0.3034776215176558]
	TIME [epoch: 12.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3669557574759781		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.3669557574759781 | validation: 0.41903624096274383]
	TIME [epoch: 13 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40162157748782745		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.40162157748782745 | validation: 0.2825655385467482]
	TIME [epoch: 12.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3698623349494197		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.3698623349494197 | validation: 0.3462329388183815]
	TIME [epoch: 12.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40995766003803946		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.40995766003803946 | validation: 0.38944303424978033]
	TIME [epoch: 12.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4463366417268467		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.4463366417268467 | validation: 0.5803209098342026]
	TIME [epoch: 13 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43481791756719795		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.43481791756719795 | validation: 0.2646916528375081]
	TIME [epoch: 12.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3917818358882346		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.3917818358882346 | validation: 0.29021892907507585]
	TIME [epoch: 12.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3238764703252029		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.3238764703252029 | validation: 0.3885700046964013]
	TIME [epoch: 12.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5577711109976736		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.5577711109976736 | validation: 0.3815400337791631]
	TIME [epoch: 12.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34968030428532787		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.34968030428532787 | validation: 0.4874430021830047]
	TIME [epoch: 12.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3851609170528067		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.3851609170528067 | validation: 0.2499519318902678]
	TIME [epoch: 12.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4307633350354041		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.4307633350354041 | validation: 0.2993681939407233]
	TIME [epoch: 13 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34715198051665924		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.34715198051665924 | validation: 0.792937024011294]
	TIME [epoch: 12.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47712671555308095		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.47712671555308095 | validation: 0.38609262633328667]
	TIME [epoch: 12.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3314338376968459		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.3314338376968459 | validation: 0.36225179446074035]
	TIME [epoch: 13 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47623022954139727		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.47623022954139727 | validation: 0.3749517825401525]
	TIME [epoch: 13 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393291505754617		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.393291505754617 | validation: 0.21877206115771158]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003251911675673		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.3003251911675673 | validation: 0.27028073100714745]
	TIME [epoch: 12.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3168641062546081		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.3168641062546081 | validation: 0.42430521676728816]
	TIME [epoch: 13 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4180559390708968		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.4180559390708968 | validation: 0.5555812253693317]
	TIME [epoch: 12.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4362024590914463		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.4362024590914463 | validation: 0.21058565404657947]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33631540785172076		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.33631540785172076 | validation: 0.22120905831814852]
	TIME [epoch: 12.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3210999578782661		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.3210999578782661 | validation: 0.481613123429984]
	TIME [epoch: 13 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39594324865428326		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.39594324865428326 | validation: 0.25874151188640965]
	TIME [epoch: 12.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4922196761504679		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.4922196761504679 | validation: 0.4289159071273544]
	TIME [epoch: 12.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36933711150483506		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.36933711150483506 | validation: 0.34381337186249455]
	TIME [epoch: 13 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3167428581136886		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.3167428581136886 | validation: 0.26778306556892095]
	TIME [epoch: 12.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447866891551196		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.3447866891551196 | validation: 0.26706970916072065]
	TIME [epoch: 12.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44304916781316284		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.44304916781316284 | validation: 0.28165352127718557]
	TIME [epoch: 12.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36790370446822906		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.36790370446822906 | validation: 0.26463749714660517]
	TIME [epoch: 13 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3261430386965126		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.3261430386965126 | validation: 0.23964495091777238]
	TIME [epoch: 12.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42308310865992815		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.42308310865992815 | validation: 0.39685279300535314]
	TIME [epoch: 12.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4888141447030743		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.4888141447030743 | validation: 0.8048441502273486]
	TIME [epoch: 12.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5555437333405171		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.5555437333405171 | validation: 0.4715320860074744]
	TIME [epoch: 12.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37431735690086354		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.37431735690086354 | validation: 0.31881050404986583]
	TIME [epoch: 12.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333173971446112		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.333173971446112 | validation: 0.3414544521159576]
	TIME [epoch: 12.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33146344621161766		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.33146344621161766 | validation: 0.3285044025881421]
	TIME [epoch: 13 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4210888394565593		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.4210888394565593 | validation: 0.5104185897351419]
	TIME [epoch: 12.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4800682540784883		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.4800682540784883 | validation: 0.3214455940016644]
	TIME [epoch: 12.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805994965948094		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.3805994965948094 | validation: 0.25927997008019177]
	TIME [epoch: 12.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41096644984594927		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.41096644984594927 | validation: 0.21322821830296754]
	TIME [epoch: 12.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3380328802500133		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.3380328802500133 | validation: 0.21945005744082316]
	TIME [epoch: 12.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32075925397472527		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.32075925397472527 | validation: 0.27803337293305236]
	TIME [epoch: 12.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35162541121279295		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.35162541121279295 | validation: 0.30667527695113833]
	TIME [epoch: 13 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2968808524761001		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.2968808524761001 | validation: 0.4647336098238216]
	TIME [epoch: 12.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36656381915072456		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.36656381915072456 | validation: 0.2503666799214778]
	TIME [epoch: 12.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31806947913437633		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.31806947913437633 | validation: 0.36691600018949855]
	TIME [epoch: 12.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33990998899667957		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.33990998899667957 | validation: 0.2820000305829402]
	TIME [epoch: 13 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34099480098435586		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.34099480098435586 | validation: 0.18737394840242025]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_464.pth
	Model improved!!!
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3135092922671312		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.3135092922671312 | validation: 0.22291656015625919]
	TIME [epoch: 12.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29901812697224595		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.29901812697224595 | validation: 0.39722666026830833]
	TIME [epoch: 13 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39520586900568927		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.39520586900568927 | validation: 0.20735962269009975]
	TIME [epoch: 12.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3355963616107408		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.3355963616107408 | validation: 0.46464311392295055]
	TIME [epoch: 12.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3961416618399176		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.3961416618399176 | validation: 0.31526096054705965]
	TIME [epoch: 12.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3098531160074198		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.3098531160074198 | validation: 0.28408387782116534]
	TIME [epoch: 13 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3824889601658194		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.3824889601658194 | validation: 0.24999078196864502]
	TIME [epoch: 12.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3571656634158317		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.3571656634158317 | validation: 0.26061803480510426]
	TIME [epoch: 12.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28696608192074036		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.28696608192074036 | validation: 0.33698143290983595]
	TIME [epoch: 13 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28891243093228625		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.28891243093228625 | validation: 0.2655121291106687]
	TIME [epoch: 13 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32095381015647684		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.32095381015647684 | validation: 0.27047063996886506]
	TIME [epoch: 12.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47096122389692013		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.47096122389692013 | validation: 0.2998572665590591]
	TIME [epoch: 12.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352433965184743		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.3352433965184743 | validation: 0.25958203135044755]
	TIME [epoch: 13 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33200319034952214		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.33200319034952214 | validation: 0.43453348898859345]
	TIME [epoch: 12.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3627534552220063		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.3627534552220063 | validation: 0.2880458141787577]
	TIME [epoch: 12.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3184442711582408		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.3184442711582408 | validation: 0.25142823366026135]
	TIME [epoch: 12.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34700968376960584		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.34700968376960584 | validation: 0.19924362639049173]
	TIME [epoch: 13 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3200633571864514		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.3200633571864514 | validation: 0.5096926418849999]
	TIME [epoch: 12.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4081139425744006		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.4081139425744006 | validation: 0.4059204143884881]
	TIME [epoch: 12.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35208456568154584		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.35208456568154584 | validation: 0.28208665087114004]
	TIME [epoch: 13 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3379618262000069		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.3379618262000069 | validation: 0.402164460852882]
	TIME [epoch: 12.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3656118449151726		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.3656118449151726 | validation: 0.2215529935043993]
	TIME [epoch: 12.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33683547548365883		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.33683547548365883 | validation: 0.35046566955861663]
	TIME [epoch: 12.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32221768283749674		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.32221768283749674 | validation: 0.20119809967705485]
	TIME [epoch: 13 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.354207026283902		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.354207026283902 | validation: 0.23016885568184386]
	TIME [epoch: 12.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3276330695004851		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.3276330695004851 | validation: 0.2319041833797989]
	TIME [epoch: 12.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.317240499721333		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.317240499721333 | validation: 0.3677318082124907]
	TIME [epoch: 13 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3580167327342452		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.3580167327342452 | validation: 0.32800133235244616]
	TIME [epoch: 12.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40934269008101565		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.40934269008101565 | validation: 0.37130178230197436]
	TIME [epoch: 12.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3256442306450023		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.3256442306450023 | validation: 0.4795752026163361]
	TIME [epoch: 12.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3647007316860811		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.3647007316860811 | validation: 0.24601825341268413]
	TIME [epoch: 13 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552686204172453		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.3552686204172453 | validation: 0.21322174195265348]
	TIME [epoch: 12.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3328490345459217		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.3328490345459217 | validation: 0.1967972921565224]
	TIME [epoch: 12.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28786838687495087		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.28786838687495087 | validation: 0.38842649508272403]
	TIME [epoch: 13 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3539190119216481		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.3539190119216481 | validation: 0.23816943856349823]
	TIME [epoch: 13 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3130158485773118		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.3130158485773118 | validation: 0.24944462988972657]
	TIME [epoch: 12.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33371020935424495		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.33371020935424495 | validation: 0.29609120199915073]
	TIME [epoch: 12.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29754876753881615		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.29754876753881615 | validation: 0.5799638851696863]
	TIME [epoch: 13 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35373297316353897		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.35373297316353897 | validation: 0.3695253821006305]
	TIME [epoch: 12.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32221228246364564		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.32221228246364564 | validation: 0.5417079514243061]
	TIME [epoch: 12.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41305321839784565		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.41305321839784565 | validation: 0.2201983102963102]
	TIME [epoch: 12.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609540087127741		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.3609540087127741 | validation: 0.2954662376813157]
	TIME [epoch: 13 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38344611018535835		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.38344611018535835 | validation: 0.25536863358097334]
	TIME [epoch: 12.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29199897327870217		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.29199897327870217 | validation: 0.20892839170171557]
	TIME [epoch: 12.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30761291416994885		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.30761291416994885 | validation: 0.24585132192595174]
	TIME [epoch: 13 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3183756746831962		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.3183756746831962 | validation: 0.3101756380944497]
	TIME [epoch: 12.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810714508977295		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.3810714508977295 | validation: 0.3772531563040014]
	TIME [epoch: 12.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34911410859564035		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.34911410859564035 | validation: 0.2971678761892357]
	TIME [epoch: 13 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3124422035778378		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.3124422035778378 | validation: 0.27247847940364833]
	TIME [epoch: 13 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38718926935620146		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.38718926935620146 | validation: 0.24272000826501547]
	TIME [epoch: 12.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2889482705156455		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.2889482705156455 | validation: 0.3873313947682225]
	TIME [epoch: 12.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442942764944209		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.3442942764944209 | validation: 0.4235947318331955]
	TIME [epoch: 13 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601093222344757		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.3601093222344757 | validation: 0.2071531773129398]
	TIME [epoch: 12.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.344509933334316		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.344509933334316 | validation: 0.32692295388211845]
	TIME [epoch: 12.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2987549851267048		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.2987549851267048 | validation: 0.31345776199213204]
	TIME [epoch: 12.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.425832301093733		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.425832301093733 | validation: 0.19805138459417168]
	TIME [epoch: 13 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30948753724077505		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.30948753724077505 | validation: 0.271094474894131]
	TIME [epoch: 12.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898095300620381		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.2898095300620381 | validation: 0.26285023725311873]
	TIME [epoch: 12.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29517942961300786		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.29517942961300786 | validation: 0.38132214118075825]
	TIME [epoch: 13 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38588612598444283		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.38588612598444283 | validation: 0.3213086324363437]
	TIME [epoch: 12.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321978477168321		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.3321978477168321 | validation: 0.2245328473128836]
	TIME [epoch: 12.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26977953708441726		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.26977953708441726 | validation: 0.19381004151547082]
	TIME [epoch: 13 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25424639367115165		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.25424639367115165 | validation: 0.28116587453170394]
	TIME [epoch: 13 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.292283562022067		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.292283562022067 | validation: 0.20434040387368932]
	TIME [epoch: 12.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3148609120468312		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.3148609120468312 | validation: 0.24284683327572196]
	TIME [epoch: 12.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34696286089762696		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.34696286089762696 | validation: 0.21065049441173997]
	TIME [epoch: 12.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2799107800176141		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.2799107800176141 | validation: 0.276627100765448]
	TIME [epoch: 13 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34515915578070716		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.34515915578070716 | validation: 0.28901293626055896]
	TIME [epoch: 12.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3198562785983545		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.3198562785983545 | validation: 0.23058926009417546]
	TIME [epoch: 13 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27972623933346674		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.27972623933346674 | validation: 0.19614986181445443]
	TIME [epoch: 13 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32426872045678923		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.32426872045678923 | validation: 0.22264210351993147]
	TIME [epoch: 12.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846844012243419		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.2846844012243419 | validation: 0.3071344190725456]
	TIME [epoch: 12.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3195508470829563		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.3195508470829563 | validation: 0.23796810985995995]
	TIME [epoch: 12.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.296859130879113		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.296859130879113 | validation: 0.27333281718792934]
	TIME [epoch: 13 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31759949979971913		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.31759949979971913 | validation: 0.24153365098184443]
	TIME [epoch: 12.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28420580351215263		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.28420580351215263 | validation: 0.3683597013750206]
	TIME [epoch: 12.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31898026421652353		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.31898026421652353 | validation: 0.39911376130364223]
	TIME [epoch: 13 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3275550555613592		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.3275550555613592 | validation: 0.25479736028367955]
	TIME [epoch: 13 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3111986476720048		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.3111986476720048 | validation: 0.175024700453959]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_543.pth
	Model improved!!!
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26925438502535287		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.26925438502535287 | validation: 0.2148138975358579]
	TIME [epoch: 13 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25019968123319897		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.25019968123319897 | validation: 0.17546165846350845]
	TIME [epoch: 13 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3146144623341496		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.3146144623341496 | validation: 0.2368342564734307]
	TIME [epoch: 12.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2832671761233855		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.2832671761233855 | validation: 0.19268353246443526]
	TIME [epoch: 12.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2377851999367347		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.2377851999367347 | validation: 0.2283028557761613]
	TIME [epoch: 13 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27019497388733543		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.27019497388733543 | validation: 0.24065216672131376]
	TIME [epoch: 13 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093646867347436		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.3093646867347436 | validation: 0.1953983711824924]
	TIME [epoch: 13 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27372541824613134		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.27372541824613134 | validation: 0.19436096412665904]
	TIME [epoch: 12.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27510963843145175		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.27510963843145175 | validation: 0.5421367048538548]
	TIME [epoch: 13 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44490777051059394		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.44490777051059394 | validation: 0.20961093331163105]
	TIME [epoch: 12.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3243359236673836		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.3243359236673836 | validation: 0.23146675080757173]
	TIME [epoch: 12.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33822430411315935		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.33822430411315935 | validation: 0.24406432900789285]
	TIME [epoch: 12.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3001922652943106		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.3001922652943106 | validation: 0.24568902948029628]
	TIME [epoch: 13 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2661119120563457		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.2661119120563457 | validation: 0.650066176336904]
	TIME [epoch: 12.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4805663102595227		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.4805663102595227 | validation: 0.3898273700335415]
	TIME [epoch: 12.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32290172409167966		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.32290172409167966 | validation: 0.3159310547441117]
	TIME [epoch: 13 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3364548702330229		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.3364548702330229 | validation: 0.16620437031786373]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2638491142403352		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.2638491142403352 | validation: 0.1916393949398301]
	TIME [epoch: 12.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703985023366395		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.2703985023366395 | validation: 0.29620312435637186]
	TIME [epoch: 12.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29000377282777035		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.29000377282777035 | validation: 0.2089087175905551]
	TIME [epoch: 13 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2676689750969711		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.2676689750969711 | validation: 0.2353283419667357]
	TIME [epoch: 12.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2803986662174663		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.2803986662174663 | validation: 0.16358087039905553]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745800860807634		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.2745800860807634 | validation: 0.2083987654367844]
	TIME [epoch: 13 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27332261231901644		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.27332261231901644 | validation: 0.46842325299873694]
	TIME [epoch: 13 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3714125616524058		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.3714125616524058 | validation: 0.1794420101746114]
	TIME [epoch: 13 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586652635177519		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.2586652635177519 | validation: 0.20741244984417598]
	TIME [epoch: 12.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24067177039976695		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.24067177039976695 | validation: 0.2141360051680887]
	TIME [epoch: 13 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24832461791113683		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.24832461791113683 | validation: 0.22986505149232145]
	TIME [epoch: 13 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34246136163787066		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.34246136163787066 | validation: 0.21181746114533048]
	TIME [epoch: 13 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3330592552578856		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.3330592552578856 | validation: 0.4461167988768081]
	TIME [epoch: 13 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36695324855551364		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.36695324855551364 | validation: 0.17906454977937947]
	TIME [epoch: 13 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24405193970546013		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.24405193970546013 | validation: 0.15452815010918505]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_575.pth
	Model improved!!!
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24906192657783974		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.24906192657783974 | validation: 0.2913757707830396]
	TIME [epoch: 12.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3317022816158567		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.3317022816158567 | validation: 0.20810002478073186]
	TIME [epoch: 13 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3137833790268481		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.3137833790268481 | validation: 0.2478223021866711]
	TIME [epoch: 12.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2691080081487385		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.2691080081487385 | validation: 0.20431996693476442]
	TIME [epoch: 12.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27316155635050854		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.27316155635050854 | validation: 0.21427348296048052]
	TIME [epoch: 13 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626527668916229		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.2626527668916229 | validation: 0.2383167001597963]
	TIME [epoch: 12.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2614452407943972		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.2614452407943972 | validation: 0.31434216937904247]
	TIME [epoch: 12.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29180289229201983		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.29180289229201983 | validation: 0.26225941758331817]
	TIME [epoch: 12.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3192263270298264		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.3192263270298264 | validation: 0.35873872562668185]
	TIME [epoch: 13 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573646810796972		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.3573646810796972 | validation: 0.19703599478367045]
	TIME [epoch: 13 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23098533315412328		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.23098533315412328 | validation: 0.17900257470929098]
	TIME [epoch: 12.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.225278875325121		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.225278875325121 | validation: 0.30540711594495096]
	TIME [epoch: 12.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38596744895998847		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.38596744895998847 | validation: 0.24786872460877946]
	TIME [epoch: 13 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30974949642663563		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.30974949642663563 | validation: 0.2782495082733275]
	TIME [epoch: 12.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30041679946700073		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.30041679946700073 | validation: 0.26966917726232903]
	TIME [epoch: 12.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2908129461146904		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.2908129461146904 | validation: 0.2740454207597495]
	TIME [epoch: 13 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2875094536586847		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.2875094536586847 | validation: 0.17896343051580096]
	TIME [epoch: 13 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27252642347740313		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.27252642347740313 | validation: 0.2612974678188575]
	TIME [epoch: 13 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897012074640073		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.2897012074640073 | validation: 0.1663639513859693]
	TIME [epoch: 12.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26264173099138766		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.26264173099138766 | validation: 0.18818267743511358]
	TIME [epoch: 13 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789239427839846		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.2789239427839846 | validation: 0.16601613009716662]
	TIME [epoch: 13 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30093507585809814		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.30093507585809814 | validation: 0.2003883093187497]
	TIME [epoch: 13 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2931739611354564		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.2931739611354564 | validation: 0.17134854675549158]
	TIME [epoch: 13 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24734747680677593		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.24734747680677593 | validation: 0.1782733037205545]
	TIME [epoch: 13 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22952651937577828		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.22952651937577828 | validation: 0.2865299825027901]
	TIME [epoch: 13 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2779442074806304		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.2779442074806304 | validation: 0.20022531020315293]
	TIME [epoch: 13 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25634444396319395		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.25634444396319395 | validation: 0.27978801943244636]
	TIME [epoch: 13 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4403945800024981		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.4403945800024981 | validation: 0.41584583991938295]
	TIME [epoch: 12.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2871189353552719		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.2871189353552719 | validation: 0.1926819412401231]
	TIME [epoch: 13 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30116639443269777		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.30116639443269777 | validation: 0.19833057687820174]
	TIME [epoch: 13 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25568429494828626		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.25568429494828626 | validation: 0.191166596164963]
	TIME [epoch: 13 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3010134207903534		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.3010134207903534 | validation: 0.33825028919129224]
	TIME [epoch: 13 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27606557170827173		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.27606557170827173 | validation: 0.1601878102901389]
	TIME [epoch: 13 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29710652670151527		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.29710652670151527 | validation: 0.3129952307546663]
	TIME [epoch: 13 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3026142092009945		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.3026142092009945 | validation: 0.30024563759183176]
	TIME [epoch: 13 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3131246019478686		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.3131246019478686 | validation: 0.2059502846579474]
	TIME [epoch: 13 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2567032722833259		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.2567032722833259 | validation: 0.2560743219456487]
	TIME [epoch: 13 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2887846911857699		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.2887846911857699 | validation: 0.17185774084437888]
	TIME [epoch: 13 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22724243139129982		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.22724243139129982 | validation: 0.1654618449872266]
	TIME [epoch: 13 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23022698236852762		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.23022698236852762 | validation: 0.29203887381497645]
	TIME [epoch: 13 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613108857283665		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.2613108857283665 | validation: 0.3255727974778898]
	TIME [epoch: 13 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2922061292468874		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.2922061292468874 | validation: 0.20075679481598865]
	TIME [epoch: 13 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24435889083998258		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.24435889083998258 | validation: 0.22710161550212]
	TIME [epoch: 13 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2975624404665972		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.2975624404665972 | validation: 0.16741112259721355]
	TIME [epoch: 13 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28118654040219704		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.28118654040219704 | validation: 0.18047723303005953]
	TIME [epoch: 13 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2798847289477311		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.2798847289477311 | validation: 0.19519327405757075]
	TIME [epoch: 13 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24164424130610523		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.24164424130610523 | validation: 0.14459034629833464]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_622.pth
	Model improved!!!
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22723292132105055		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.22723292132105055 | validation: 0.20958725371257422]
	TIME [epoch: 13 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23292036777086453		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.23292036777086453 | validation: 0.2825188640723185]
	TIME [epoch: 13 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26657039631968427		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.26657039631968427 | validation: 0.249762524824427]
	TIME [epoch: 13 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23370480089229984		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.23370480089229984 | validation: 0.2888772319443121]
	TIME [epoch: 12.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2798630366053799		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.2798630366053799 | validation: 0.1662712562680353]
	TIME [epoch: 13 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26485122949521156		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.26485122949521156 | validation: 0.21738278358353988]
	TIME [epoch: 12.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23463700867353415		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.23463700867353415 | validation: 0.23723177758851716]
	TIME [epoch: 13 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2424315629229577		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.2424315629229577 | validation: 0.2595185511568951]
	TIME [epoch: 13 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26315067257293895		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.26315067257293895 | validation: 0.4167300768171315]
	TIME [epoch: 13 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29821134528924537		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.29821134528924537 | validation: 0.22616997233711694]
	TIME [epoch: 13 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2887308226019776		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.2887308226019776 | validation: 0.3604436858571618]
	TIME [epoch: 12.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4141565978813722		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.4141565978813722 | validation: 0.2602995236067313]
	TIME [epoch: 13 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2615603466608489		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.2615603466608489 | validation: 0.2868559485316011]
	TIME [epoch: 13 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3550690393121261		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.3550690393121261 | validation: 0.25870300464318197]
	TIME [epoch: 12.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22551310624375845		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.22551310624375845 | validation: 0.15434986824196406]
	TIME [epoch: 13 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20448113757268707		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.20448113757268707 | validation: 0.19089278008090518]
	TIME [epoch: 13 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22053165631633953		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.22053165631633953 | validation: 0.3290461725812399]
	TIME [epoch: 12.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2796704338386809		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.2796704338386809 | validation: 0.17984611164811373]
	TIME [epoch: 13 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26713361011531245		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.26713361011531245 | validation: 0.15309183161378806]
	TIME [epoch: 13 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22821199286330632		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.22821199286330632 | validation: 0.24303747442165155]
	TIME [epoch: 13 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24592154532041238		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.24592154532041238 | validation: 0.2571960869120013]
	TIME [epoch: 13 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33391084275749694		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.33391084275749694 | validation: 0.2930328215887695]
	TIME [epoch: 12.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24158092162283615		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.24158092162283615 | validation: 0.14773932779395244]
	TIME [epoch: 13 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25323625874403766		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.25323625874403766 | validation: 0.1802355501882404]
	TIME [epoch: 13 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22895387367632225		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.22895387367632225 | validation: 0.21390224596943785]
	TIME [epoch: 12.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2849893694881573		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.2849893694881573 | validation: 0.2267967025092812]
	TIME [epoch: 13 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2926881405814119		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.2926881405814119 | validation: 0.20190860239662647]
	TIME [epoch: 12.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24338185580682012		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.24338185580682012 | validation: 0.1480460535568732]
	TIME [epoch: 13 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20387905064572576		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.20387905064572576 | validation: 0.19450410972249896]
	TIME [epoch: 12.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22818029111019983		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.22818029111019983 | validation: 0.21647212961340195]
	TIME [epoch: 13 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31859731837203786		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.31859731837203786 | validation: 0.19095300666152537]
	TIME [epoch: 13 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21298429332608632		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.21298429332608632 | validation: 0.14117621389574234]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_654.pth
	Model improved!!!
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23279163528122904		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.23279163528122904 | validation: 0.32537936353785013]
	TIME [epoch: 13 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2926455050180781		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.2926455050180781 | validation: 0.21185611331875792]
	TIME [epoch: 12.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26582768973298776		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.26582768973298776 | validation: 0.18664425794513087]
	TIME [epoch: 12.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2240337497913618		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.2240337497913618 | validation: 0.18722920049970526]
	TIME [epoch: 12.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25043400331508175		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.25043400331508175 | validation: 0.265143070383732]
	TIME [epoch: 13 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25940662989759555		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.25940662989759555 | validation: 0.155616050992894]
	TIME [epoch: 12.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2052936760750049		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.2052936760750049 | validation: 0.214802161240694]
	TIME [epoch: 12.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2594046969010235		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.2594046969010235 | validation: 0.17285613733979496]
	TIME [epoch: 13 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23334108041018314		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.23334108041018314 | validation: 0.15215499707823985]
	TIME [epoch: 12.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2312051745360491		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.2312051745360491 | validation: 0.21017846007772195]
	TIME [epoch: 12.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2175497013896097		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.2175497013896097 | validation: 0.17982913311649948]
	TIME [epoch: 12.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2455840844445505		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.2455840844445505 | validation: 0.15841290476469008]
	TIME [epoch: 13 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24217270129679397		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.24217270129679397 | validation: 0.18240234198411004]
	TIME [epoch: 12.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2373378108432316		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.2373378108432316 | validation: 0.22784026223119405]
	TIME [epoch: 13 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22549876531103963		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.22549876531103963 | validation: 0.2352337501011007]
	TIME [epoch: 13 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23638894597069032		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.23638894597069032 | validation: 0.15720280826627964]
	TIME [epoch: 13 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2320618922386979		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.2320618922386979 | validation: 0.19920128403170484]
	TIME [epoch: 12.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25457167114684265		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.25457167114684265 | validation: 0.1701737876656165]
	TIME [epoch: 13 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29230785978381923		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.29230785978381923 | validation: 0.15340770017553693]
	TIME [epoch: 13 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2208248376196255		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.2208248376196255 | validation: 0.3234870381459544]
	TIME [epoch: 13 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26307994053604006		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.26307994053604006 | validation: 0.16022706606275086]
	TIME [epoch: 12.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25299605036532546		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.25299605036532546 | validation: 0.2366533263564695]
	TIME [epoch: 13 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25543821966317526		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.25543821966317526 | validation: 0.16659554189440684]
	TIME [epoch: 13 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519030781911284		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.2519030781911284 | validation: 0.258842922293139]
	TIME [epoch: 13 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25312121871612353		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.25312121871612353 | validation: 0.18747728527310842]
	TIME [epoch: 12.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22010848409735348		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.22010848409735348 | validation: 0.19488022246079667]
	TIME [epoch: 13 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21684940890654875		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.21684940890654875 | validation: 0.16925491426293732]
	TIME [epoch: 13 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510943873954319		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.2510943873954319 | validation: 0.20181894591310395]
	TIME [epoch: 13 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23539179922244302		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.23539179922244302 | validation: 0.28945330118858215]
	TIME [epoch: 12.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22882048983517417		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.22882048983517417 | validation: 0.18528561205866179]
	TIME [epoch: 13 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22310676050586134		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.22310676050586134 | validation: 0.21246015474436697]
	TIME [epoch: 12.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.243859561242255		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.243859561242255 | validation: 0.1480718304529007]
	TIME [epoch: 12.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21768024024228314		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.21768024024228314 | validation: 0.1757541433033629]
	TIME [epoch: 13 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251185954880344		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.251185954880344 | validation: 0.17423038268193355]
	TIME [epoch: 12.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23522641619748255		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.23522641619748255 | validation: 0.24098317067771027]
	TIME [epoch: 12.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.295767086662298		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.295767086662298 | validation: 0.15913542189164373]
	TIME [epoch: 12.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21941964185893417		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.21941964185893417 | validation: 0.21179455297111371]
	TIME [epoch: 12.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2743383245529219		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.2743383245529219 | validation: 0.23014533995970532]
	TIME [epoch: 12.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2883036153538239		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.2883036153538239 | validation: 0.2102713107970817]
	TIME [epoch: 12.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23961051775624398		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.23961051775624398 | validation: 0.16922653635755963]
	TIME [epoch: 12.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22140987210289081		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.22140987210289081 | validation: 0.15588047767744345]
	TIME [epoch: 12.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20277990834019843		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.20277990834019843 | validation: 0.19612912669277044]
	TIME [epoch: 12.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22640299004103367		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.22640299004103367 | validation: 0.23008356526830512]
	TIME [epoch: 12.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2877496316280433		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.2877496316280433 | validation: 0.21659604231262283]
	TIME [epoch: 12.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519865658706907		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.2519865658706907 | validation: 0.2565486345623021]
	TIME [epoch: 12.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24652173974900227		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.24652173974900227 | validation: 0.46026424848567077]
	TIME [epoch: 13 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3604807862476445		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.3604807862476445 | validation: 0.16237203852723753]
	TIME [epoch: 12.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.191470414608457		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.191470414608457 | validation: 0.19932942533177028]
	TIME [epoch: 13 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22048572853897289		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.22048572853897289 | validation: 0.14316182766045235]
	TIME [epoch: 13 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2017935342162336		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.2017935342162336 | validation: 0.15213995654260085]
	TIME [epoch: 12.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25898743635126575		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.25898743635126575 | validation: 0.1467759747815747]
	TIME [epoch: 13 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22113641485396074		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.22113641485396074 | validation: 0.14411084770383756]
	TIME [epoch: 12.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20199353577680548		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.20199353577680548 | validation: 0.2226815292802499]
	TIME [epoch: 12.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21978463247481886		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.21978463247481886 | validation: 0.1977440620181657]
	TIME [epoch: 13 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21510706780130995		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.21510706780130995 | validation: 0.32077356256147793]
	TIME [epoch: 13 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2550650379655652		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.2550650379655652 | validation: 0.18670947045184727]
	TIME [epoch: 12.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2210542380595757		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.2210542380595757 | validation: 0.1901339244243934]
	TIME [epoch: 12.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2567482694294595		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.2567482694294595 | validation: 0.19461912591940947]
	TIME [epoch: 13 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2332308484945973		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.2332308484945973 | validation: 0.1588172349006477]
	TIME [epoch: 13 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.215803966299038		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.215803966299038 | validation: 0.19635290206620234]
	TIME [epoch: 12.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23337485237225658		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.23337485237225658 | validation: 0.21868245442396606]
	TIME [epoch: 12.9 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23099366441992283		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.23099366441992283 | validation: 0.1516802993808154]
	TIME [epoch: 13 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21206335609380156		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.21206335609380156 | validation: 0.1984800649100427]
	TIME [epoch: 13 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23149428138496841		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.23149428138496841 | validation: 0.19745740177989868]
	TIME [epoch: 13 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23073548601628774		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.23073548601628774 | validation: 0.31065543593707]
	TIME [epoch: 12.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2623268969749052		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.2623268969749052 | validation: 0.14410332530485045]
	TIME [epoch: 13 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20638718461016572		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.20638718461016572 | validation: 0.16497586170106462]
	TIME [epoch: 12.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23425577865845915		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.23425577865845915 | validation: 0.16993557122317313]
	TIME [epoch: 12.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19914767337055855		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.19914767337055855 | validation: 0.29142689100306723]
	TIME [epoch: 13 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2569845088087691		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.2569845088087691 | validation: 0.29787969782064666]
	TIME [epoch: 12.9 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592289767576359		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.2592289767576359 | validation: 0.15830001684406036]
	TIME [epoch: 13 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20660703762695093		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.20660703762695093 | validation: 0.16313410998698852]
	TIME [epoch: 12.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19620931829046095		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.19620931829046095 | validation: 0.14311653756337567]
	TIME [epoch: 13 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2168086179234327		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.2168086179234327 | validation: 0.15902248157231116]
	TIME [epoch: 12.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23807246588152653		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.23807246588152653 | validation: 0.18259289141681037]
	TIME [epoch: 13 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23019401101975623		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.23019401101975623 | validation: 0.13908146832083854]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_730.pth
	Model improved!!!
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19892091077754578		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.19892091077754578 | validation: 0.15132479461284207]
	TIME [epoch: 12.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2054570537682033		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.2054570537682033 | validation: 0.17496885995296343]
	TIME [epoch: 13 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27295569986875057		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.27295569986875057 | validation: 0.14172136598795246]
	TIME [epoch: 13 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24087754934652492		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.24087754934652492 | validation: 0.14520228248514536]
	TIME [epoch: 13 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22910327213482112		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.22910327213482112 | validation: 0.29305354342083817]
	TIME [epoch: 13 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22591678731782994		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.22591678731782994 | validation: 0.15903389411260818]
	TIME [epoch: 13 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24519895981235515		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.24519895981235515 | validation: 0.1575724362412855]
	TIME [epoch: 13 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2548920070973252		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.2548920070973252 | validation: 0.1622393271781372]
	TIME [epoch: 13 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20833251087604304		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.20833251087604304 | validation: 0.1912928464359284]
	TIME [epoch: 13 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20382402071925312		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.20382402071925312 | validation: 0.16263682221061668]
	TIME [epoch: 13 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19819099734024015		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.19819099734024015 | validation: 0.2847078165632795]
	TIME [epoch: 13 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5341640172608144		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.5341640172608144 | validation: 0.2470869766295151]
	TIME [epoch: 12.9 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21518497083324617		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.21518497083324617 | validation: 0.26089963642074954]
	TIME [epoch: 13 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2225258735104675		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.2225258735104675 | validation: 0.13716279610177887]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_744.pth
	Model improved!!!
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21275535202421875		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.21275535202421875 | validation: 0.2000412633348163]
	TIME [epoch: 13 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2623327324049586		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.2623327324049586 | validation: 0.19938519804266264]
	TIME [epoch: 13 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.247246618789855		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.247246618789855 | validation: 0.14898103760228976]
	TIME [epoch: 13 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19365398879154164		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.19365398879154164 | validation: 0.29963583437357844]
	TIME [epoch: 13 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505807035034907		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.2505807035034907 | validation: 0.1701185271290153]
	TIME [epoch: 13 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21631117480095163		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.21631117480095163 | validation: 0.19826318229008377]
	TIME [epoch: 13 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2926242146094731		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.2926242146094731 | validation: 0.24730111758041604]
	TIME [epoch: 13 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2137372901270361		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.2137372901270361 | validation: 0.16661628618391258]
	TIME [epoch: 13 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20432956222075255		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.20432956222075255 | validation: 0.1976708271292072]
	TIME [epoch: 13 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22162474803149096		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.22162474803149096 | validation: 0.22265934412996957]
	TIME [epoch: 13 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21291233100088497		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.21291233100088497 | validation: 0.12964630400330057]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_755.pth
	Model improved!!!
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1859044379230878		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.1859044379230878 | validation: 0.20930049277160948]
	TIME [epoch: 13 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25565328467678045		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.25565328467678045 | validation: 0.2021892344033752]
	TIME [epoch: 13 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1880760717573845		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.1880760717573845 | validation: 0.2172737460515423]
	TIME [epoch: 13 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26291188644469166		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.26291188644469166 | validation: 0.1714032293178138]
	TIME [epoch: 13 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21867628315672735		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.21867628315672735 | validation: 0.13990124416924496]
	TIME [epoch: 13 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23232144518547265		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.23232144518547265 | validation: 0.15236022834984805]
	TIME [epoch: 13 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2048291790307699		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.2048291790307699 | validation: 0.13694196992131394]
	TIME [epoch: 13 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20821599614796055		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.20821599614796055 | validation: 0.1596540683453496]
	TIME [epoch: 13 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19888797057850263		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.19888797057850263 | validation: 0.16480482866845422]
	TIME [epoch: 13 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20524803890254445		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.20524803890254445 | validation: 0.19108128620487388]
	TIME [epoch: 13 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2149812687523884		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.2149812687523884 | validation: 0.18375981355007084]
	TIME [epoch: 13 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2199066525683876		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.2199066525683876 | validation: 0.13631564345287922]
	TIME [epoch: 13 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2517154632201008		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.2517154632201008 | validation: 0.21294626397164088]
	TIME [epoch: 12.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25694617618003907		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.25694617618003907 | validation: 0.1576942372903782]
	TIME [epoch: 13 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20836874725777008		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.20836874725777008 | validation: 0.13549640424887086]
	TIME [epoch: 13 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1846380674299157		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.1846380674299157 | validation: 0.12206382190908442]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_771.pth
	Model improved!!!
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.182920537692252		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.182920537692252 | validation: 0.13672443001223702]
	TIME [epoch: 13 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21988864325266005		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.21988864325266005 | validation: 0.2435273499328219]
	TIME [epoch: 13 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2084843373147886		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.2084843373147886 | validation: 0.13707332410396098]
	TIME [epoch: 13 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1865744715728449		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1865744715728449 | validation: 0.18627179065690339]
	TIME [epoch: 13 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19455170185048395		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.19455170185048395 | validation: 0.17199510578032334]
	TIME [epoch: 13 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22072337345393078		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.22072337345393078 | validation: 0.3632518244301551]
	TIME [epoch: 13 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25534121935000526		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.25534121935000526 | validation: 0.17466925110066356]
	TIME [epoch: 13 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1983606107967058		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.1983606107967058 | validation: 0.14297241847683345]
	TIME [epoch: 13 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21542658677557175		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.21542658677557175 | validation: 0.17749625882465503]
	TIME [epoch: 13 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23661518969267098		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.23661518969267098 | validation: 0.18278462535489837]
	TIME [epoch: 13 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20596829937891722		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.20596829937891722 | validation: 0.16533123619179793]
	TIME [epoch: 13 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20663141205450608		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.20663141205450608 | validation: 0.15211821332417627]
	TIME [epoch: 13 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18766679965681704		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.18766679965681704 | validation: 0.13067301578721024]
	TIME [epoch: 13 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21138379690338258		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.21138379690338258 | validation: 0.1857069900065435]
	TIME [epoch: 13 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22297176734458815		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.22297176734458815 | validation: 0.18170151377321583]
	TIME [epoch: 13 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21387248789023125		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.21387248789023125 | validation: 0.15239497951510406]
	TIME [epoch: 13 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20643625565849286		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.20643625565849286 | validation: 0.12121121137387682]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_788.pth
	Model improved!!!
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2259407087910401		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.2259407087910401 | validation: 0.15544540708095825]
	TIME [epoch: 13 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22418258345413372		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.22418258345413372 | validation: 0.16319198624815975]
	TIME [epoch: 13 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19955434781311499		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.19955434781311499 | validation: 0.15949161667300357]
	TIME [epoch: 13 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2330781781630069		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.2330781781630069 | validation: 0.16918453484776472]
	TIME [epoch: 13 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21785595348513567		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.21785595348513567 | validation: 0.15212653737332554]
	TIME [epoch: 13 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1826966040270801		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.1826966040270801 | validation: 0.17500330550207896]
	TIME [epoch: 13 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1962396537740163		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.1962396537740163 | validation: 0.22719748919093805]
	TIME [epoch: 13 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22074905273429818		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.22074905273429818 | validation: 0.16841732520339606]
	TIME [epoch: 13 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21183806323690463		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.21183806323690463 | validation: 0.20722443451645275]
	TIME [epoch: 13 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2391286367803584		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.2391286367803584 | validation: 0.19008139275439903]
	TIME [epoch: 13 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18714176058096904		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.18714176058096904 | validation: 0.24685729631012046]
	TIME [epoch: 13 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22909738757562284		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.22909738757562284 | validation: 0.16510893801211338]
	TIME [epoch: 13 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20716525395549165		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.20716525395549165 | validation: 0.410425859534943]
	TIME [epoch: 13 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28784538248186053		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.28784538248186053 | validation: 0.12864512699008407]
	TIME [epoch: 13 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2188143952305085		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.2188143952305085 | validation: 0.1557529230465096]
	TIME [epoch: 13 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19844732194865058		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.19844732194865058 | validation: 0.2562453446936827]
	TIME [epoch: 13 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23559139107736404		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.23559139107736404 | validation: 0.1591510335955502]
	TIME [epoch: 13 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21443445356665616		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.21443445356665616 | validation: 0.1882901586092243]
	TIME [epoch: 13 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22252985851729132		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.22252985851729132 | validation: 0.18071078501237214]
	TIME [epoch: 13 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1964715943095437		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.1964715943095437 | validation: 0.11548927518562724]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_808.pth
	Model improved!!!
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.166394360608359		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.166394360608359 | validation: 0.2180797769690307]
	TIME [epoch: 13 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19340019015808851		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.19340019015808851 | validation: 0.14762136352706015]
	TIME [epoch: 13 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26564142943301755		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.26564142943301755 | validation: 0.1577530248489224]
	TIME [epoch: 13 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21298980705201484		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.21298980705201484 | validation: 0.14962515257445233]
	TIME [epoch: 13 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20276143303128744		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.20276143303128744 | validation: 0.20370389650018836]
	TIME [epoch: 13 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20733955436381518		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.20733955436381518 | validation: 0.13291544603716335]
	TIME [epoch: 13 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18232835999307664		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.18232835999307664 | validation: 0.14670594495585346]
	TIME [epoch: 13 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22447292193091065		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.22447292193091065 | validation: 0.13177868214721186]
	TIME [epoch: 13 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18225857988223923		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.18225857988223923 | validation: 0.14073318807937457]
	TIME [epoch: 13 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18552227356854636		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.18552227356854636 | validation: 0.16865725905624956]
	TIME [epoch: 13 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1878306913719574		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.1878306913719574 | validation: 0.13770838705067207]
	TIME [epoch: 13 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17487700011129687		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.17487700011129687 | validation: 0.11423753206326286]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_820.pth
	Model improved!!!
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18191365209837662		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.18191365209837662 | validation: 0.16414618856659527]
	TIME [epoch: 13 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17883711571534588		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.17883711571534588 | validation: 0.19836370629403127]
	TIME [epoch: 13 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22173340201043518		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.22173340201043518 | validation: 0.13453997824654346]
	TIME [epoch: 13 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2072688805475613		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.2072688805475613 | validation: 0.1446552544295544]
	TIME [epoch: 13 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21249257048971706		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.21249257048971706 | validation: 0.267746080197003]
	TIME [epoch: 13 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2263328925950602		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.2263328925950602 | validation: 0.1649816611001838]
	TIME [epoch: 13 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2349878744299973		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.2349878744299973 | validation: 0.13657264427825136]
	TIME [epoch: 13 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18050597308493585		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.18050597308493585 | validation: 0.1513592580200689]
	TIME [epoch: 13 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18831753997686482		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.18831753997686482 | validation: 0.12843301008966246]
	TIME [epoch: 13 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18746206133465868		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.18746206133465868 | validation: 0.14141016971904286]
	TIME [epoch: 13 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19330538553001197		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.19330538553001197 | validation: 0.18651774189856268]
	TIME [epoch: 13 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18851320033089092		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.18851320033089092 | validation: 0.1488366309227301]
	TIME [epoch: 13 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1828954902643445		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.1828954902643445 | validation: 0.15140383293076773]
	TIME [epoch: 13 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19523643098058313		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.19523643098058313 | validation: 0.12755168444886408]
	TIME [epoch: 13 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1717156315824559		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.1717156315824559 | validation: 0.16812442666102914]
	TIME [epoch: 13 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1894900921009508		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.1894900921009508 | validation: 0.15861336179104832]
	TIME [epoch: 13 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1912246007138842		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.1912246007138842 | validation: 0.3270213866579197]
	TIME [epoch: 13 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25350196175843215		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.25350196175843215 | validation: 0.16725913420795308]
	TIME [epoch: 13 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18056674434251002		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.18056674434251002 | validation: 0.13504838177135503]
	TIME [epoch: 13 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1725270655654709		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.1725270655654709 | validation: 0.1537575717456705]
	TIME [epoch: 13 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19327237977626055		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.19327237977626055 | validation: 0.1720322651003454]
	TIME [epoch: 13 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18511438915251355		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.18511438915251355 | validation: 0.12567384059293973]
	TIME [epoch: 12.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17376977817473416		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.17376977817473416 | validation: 0.17977608940156473]
	TIME [epoch: 12.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17898034679589048		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.17898034679589048 | validation: 0.16144004232549314]
	TIME [epoch: 13 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20567850449726577		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.20567850449726577 | validation: 0.22841790698303677]
	TIME [epoch: 12.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19612258732408394		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.19612258732408394 | validation: 0.15146313697779337]
	TIME [epoch: 12.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2175152109827025		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.2175152109827025 | validation: 0.14131439905209364]
	TIME [epoch: 13 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17491725935958208		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.17491725935958208 | validation: 0.11671218554455962]
	TIME [epoch: 13 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16833232009054203		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.16833232009054203 | validation: 0.19577083801644468]
	TIME [epoch: 13 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1980957438000066		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.1980957438000066 | validation: 0.12734147967122142]
	TIME [epoch: 13 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17352080287743973		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.17352080287743973 | validation: 0.18841365186086606]
	TIME [epoch: 13 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21041582351926252		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.21041582351926252 | validation: 0.24379388213845055]
	TIME [epoch: 13 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20498135487138924		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.20498135487138924 | validation: 0.18937542220003267]
	TIME [epoch: 13 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22566724737214808		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.22566724737214808 | validation: 0.12161250426783791]
	TIME [epoch: 13 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18776740690449825		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.18776740690449825 | validation: 0.16147176965257395]
	TIME [epoch: 13 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896821893133858		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.1896821893133858 | validation: 0.19454557468814188]
	TIME [epoch: 13 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19564548507942212		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.19564548507942212 | validation: 0.1289820444420764]
	TIME [epoch: 13 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18630962963199976		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.18630962963199976 | validation: 0.11893847943188161]
	TIME [epoch: 13 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18328158668900274		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.18328158668900274 | validation: 0.15489636272156293]
	TIME [epoch: 12.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.174004275108544		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.174004275108544 | validation: 0.1261532735419458]
	TIME [epoch: 12.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18080475346319658		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.18080475346319658 | validation: 0.21272999990777344]
	TIME [epoch: 12.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23413251389899065		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.23413251389899065 | validation: 0.11572014399475798]
	TIME [epoch: 13 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17647832218377282		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.17647832218377282 | validation: 0.123320802601963]
	TIME [epoch: 12.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17455867955421658		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.17455867955421658 | validation: 0.15509333362153224]
	TIME [epoch: 12.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17434763977437942		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.17434763977437942 | validation: 0.14656233409441172]
	TIME [epoch: 13 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16893019975640117		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.16893019975640117 | validation: 0.1233531088243325]
	TIME [epoch: 13 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22347347563290207		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.22347347563290207 | validation: 0.13364713018962657]
	TIME [epoch: 13 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1717535391042065		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.1717535391042065 | validation: 0.15189997477789516]
	TIME [epoch: 13 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23764831826581168		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.23764831826581168 | validation: 0.12377704388499418]
	TIME [epoch: 13 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17192104006347242		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.17192104006347242 | validation: 0.13565696298573213]
	TIME [epoch: 13 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20405822216279978		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.20405822216279978 | validation: 0.12822948241639176]
	TIME [epoch: 13 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18518780847328892		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.18518780847328892 | validation: 0.13948646965370312]
	TIME [epoch: 13 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16814180490370445		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.16814180490370445 | validation: 0.1335260859033658]
	TIME [epoch: 13 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18504236434739135		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.18504236434739135 | validation: 0.42281459575232094]
	TIME [epoch: 13 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3289348570292338		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.3289348570292338 | validation: 0.17297378847549297]
	TIME [epoch: 13 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21548945648560638		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.21548945648560638 | validation: 0.15263551174855863]
	TIME [epoch: 13 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17471435476082847		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.17471435476082847 | validation: 0.11480464473638065]
	TIME [epoch: 13 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18219614260608108		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.18219614260608108 | validation: 0.11464087229523577]
	TIME [epoch: 13 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17652490499816081		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.17652490499816081 | validation: 0.137297010230307]
	TIME [epoch: 13 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2749623545370782		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.2749623545370782 | validation: 0.18250952415771518]
	TIME [epoch: 13 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1849838841782523		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.1849838841782523 | validation: 0.16209468126530638]
	TIME [epoch: 13 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1853533525870941		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.1853533525870941 | validation: 0.22802351382643352]
	TIME [epoch: 13 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19551591656738518		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.19551591656738518 | validation: 0.11835568581933524]
	TIME [epoch: 13 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1935761446979942		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.1935761446979942 | validation: 0.14309447152151258]
	TIME [epoch: 12.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18620771301205524		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.18620771301205524 | validation: 0.12808565979880934]
	TIME [epoch: 12.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1865064924368168		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.1865064924368168 | validation: 0.12681699657728795]
	TIME [epoch: 12.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1845069771656302		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.1845069771656302 | validation: 0.137208441091844]
	TIME [epoch: 13 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17934550648892636		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.17934550648892636 | validation: 0.12290675314996279]
	TIME [epoch: 12.9 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17654078075182567		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.17654078075182567 | validation: 0.13868476601516525]
	TIME [epoch: 12.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17393441218979513		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.17393441218979513 | validation: 0.1581382210787201]
	TIME [epoch: 13 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18635941725077132		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.18635941725077132 | validation: 0.13160081277016]
	TIME [epoch: 12.9 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21301548279470195		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.21301548279470195 | validation: 0.14473185912737513]
	TIME [epoch: 12.9 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20113791877615672		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.20113791877615672 | validation: 0.16252488321412195]
	TIME [epoch: 12.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17587282807615567		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.17587282807615567 | validation: 0.1326435903305716]
	TIME [epoch: 13 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17885997235614415		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.17885997235614415 | validation: 0.1309247829675097]
	TIME [epoch: 12.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18932206736450335		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.18932206736450335 | validation: 0.13009361411813763]
	TIME [epoch: 12.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17906911223978364		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.17906911223978364 | validation: 0.17643467989685754]
	TIME [epoch: 13 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19077839581311923		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.19077839581311923 | validation: 0.12575633479909148]
	TIME [epoch: 12.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2271568075669893		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.2271568075669893 | validation: 0.17892322974450195]
	TIME [epoch: 12.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18091736064628106		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.18091736064628106 | validation: 0.11843206535055725]
	TIME [epoch: 12.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16698673599652628		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.16698673599652628 | validation: 0.11818373046517523]
	TIME [epoch: 13 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17954428116188337		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.17954428116188337 | validation: 0.1258797535056669]
	TIME [epoch: 13 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21509327943744758		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.21509327943744758 | validation: 0.19020496859993657]
	TIME [epoch: 13 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19854616530466285		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.19854616530466285 | validation: 0.1392718590592237]
	TIME [epoch: 13 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.194084065221227		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.194084065221227 | validation: 0.1495426265891275]
	TIME [epoch: 13 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19403566626629154		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.19403566626629154 | validation: 0.11423023687708604]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_906.pth
	Model improved!!!
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17127732344606683		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.17127732344606683 | validation: 0.13892701205343083]
	TIME [epoch: 13 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17703204080859405		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.17703204080859405 | validation: 0.1486330024943143]
	TIME [epoch: 13 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2177242926118249		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.2177242926118249 | validation: 0.1604615331367278]
	TIME [epoch: 13 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708783618119505		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.1708783618119505 | validation: 0.16803931150186777]
	TIME [epoch: 12.9 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17643801105035295		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.17643801105035295 | validation: 0.13829097559120956]
	TIME [epoch: 13 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17450091495378958		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.17450091495378958 | validation: 0.11922217037587754]
	TIME [epoch: 12.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1664570709816084		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.1664570709816084 | validation: 0.13895901765458715]
	TIME [epoch: 13 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18206013715000108		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.18206013715000108 | validation: 0.16641560253075646]
	TIME [epoch: 12.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18406548306297765		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.18406548306297765 | validation: 0.13245077937030003]
	TIME [epoch: 13 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18072864841198083		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.18072864841198083 | validation: 0.22962049100520637]
	TIME [epoch: 12.9 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19244897686223722		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.19244897686223722 | validation: 0.18313511888276662]
	TIME [epoch: 12.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23341746500820607		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.23341746500820607 | validation: 0.16624469652637458]
	TIME [epoch: 12.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2094631238792924		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.2094631238792924 | validation: 0.15740959203258945]
	TIME [epoch: 13 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18998900643025735		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.18998900643025735 | validation: 0.11885855047275797]
	TIME [epoch: 12.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590406637528538		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.1590406637528538 | validation: 0.11707540232333308]
	TIME [epoch: 13 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1735382593269078		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.1735382593269078 | validation: 0.1301580676511294]
	TIME [epoch: 13 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1613888845656198		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.1613888845656198 | validation: 0.12063457506431674]
	TIME [epoch: 13 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17202050665846735		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.17202050665846735 | validation: 0.14582655223575347]
	TIME [epoch: 12.9 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1678944026833966		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.1678944026833966 | validation: 0.12919321878588755]
	TIME [epoch: 13 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15999872591962988		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.15999872591962988 | validation: 0.12527958246887105]
	TIME [epoch: 13 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16396696821251233		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.16396696821251233 | validation: 0.1263425996811174]
	TIME [epoch: 13 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16602277422209072		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.16602277422209072 | validation: 0.1559903196272312]
	TIME [epoch: 12.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1926152648148292		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.1926152648148292 | validation: 0.13819440068366384]
	TIME [epoch: 13 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17536096286998487		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.17536096286998487 | validation: 0.11634919118206373]
	TIME [epoch: 13 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18096974584785372		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.18096974584785372 | validation: 0.13216206064144692]
	TIME [epoch: 13 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17343494266330572		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.17343494266330572 | validation: 0.18855428294404575]
	TIME [epoch: 12.9 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19485316876732012		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.19485316876732012 | validation: 0.1597239246786718]
	TIME [epoch: 13 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17187464236209823		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.17187464236209823 | validation: 0.13133387134020372]
	TIME [epoch: 12.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16596964517321766		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.16596964517321766 | validation: 0.14696197539642758]
	TIME [epoch: 13 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16964688539529954		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.16964688539529954 | validation: 0.14243015521842375]
	TIME [epoch: 13 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18878989708989108		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.18878989708989108 | validation: 0.15106113438107163]
	TIME [epoch: 13 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18740650381630516		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.18740650381630516 | validation: 0.13439197406785502]
	TIME [epoch: 12.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17907891449719288		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.17907891449719288 | validation: 0.134070503958338]
	TIME [epoch: 13 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1847586234001433		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.1847586234001433 | validation: 0.1546919050778526]
	TIME [epoch: 13 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16366801699870304		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.16366801699870304 | validation: 0.1256906913931289]
	TIME [epoch: 12.9 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18345339550242884		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.18345339550242884 | validation: 0.14094757820889517]
	TIME [epoch: 13 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21443061580123732		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.21443061580123732 | validation: 0.11996229346142942]
	TIME [epoch: 13 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16630936625707135		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.16630936625707135 | validation: 0.13785980802028483]
	TIME [epoch: 13 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16823135004706755		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.16823135004706755 | validation: 0.11929604919190633]
	TIME [epoch: 13 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15231586993238214		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.15231586993238214 | validation: 0.13481404593066665]
	TIME [epoch: 13 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1858335390854972		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.1858335390854972 | validation: 0.14477388847897904]
	TIME [epoch: 13 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16993216770538017		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.16993216770538017 | validation: 0.1373987359419874]
	TIME [epoch: 12.9 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1798464740115332		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.1798464740115332 | validation: 0.11621991476633384]
	TIME [epoch: 13 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16903241918651513		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.16903241918651513 | validation: 0.1159304986204848]
	TIME [epoch: 13 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16465553609168804		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.16465553609168804 | validation: 0.11931892553157056]
	TIME [epoch: 13 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521003855513614		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.1521003855513614 | validation: 0.10643460517034484]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_952.pth
	Model improved!!!
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1583036116212065		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.1583036116212065 | validation: 0.18166411361474075]
	TIME [epoch: 13 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2146858735285205		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.2146858735285205 | validation: 0.1785281647606899]
	TIME [epoch: 13 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17081303983912177		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.17081303983912177 | validation: 0.1243658638750556]
	TIME [epoch: 12.9 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16480872461137125		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.16480872461137125 | validation: 0.12929310945990058]
	TIME [epoch: 13 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16924771459705412		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.16924771459705412 | validation: 0.13037652085000714]
	TIME [epoch: 12.9 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17679555563745283		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.17679555563745283 | validation: 0.13806505300630378]
	TIME [epoch: 13 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15686104341062282		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.15686104341062282 | validation: 0.12217779466261806]
	TIME [epoch: 12.9 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17528017904925242		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.17528017904925242 | validation: 0.19342990370942498]
	TIME [epoch: 12.9 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838772670672293		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.1838772670672293 | validation: 0.12248965364699028]
	TIME [epoch: 13 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16364756508841222		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.16364756508841222 | validation: 0.15779958871935748]
	TIME [epoch: 13 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16573726505566044		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.16573726505566044 | validation: 0.13511868631285892]
	TIME [epoch: 12.9 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1593577928490252		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.1593577928490252 | validation: 0.11354446241862856]
	TIME [epoch: 13 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15577309685324425		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.15577309685324425 | validation: 0.13604861044159042]
	TIME [epoch: 13 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17287100908161798		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.17287100908161798 | validation: 0.11299585082582389]
	TIME [epoch: 13 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168740158921717		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.168740158921717 | validation: 0.15315110306235988]
	TIME [epoch: 13 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17875952979093027		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.17875952979093027 | validation: 0.1479334472805814]
	TIME [epoch: 13 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16743638480833736		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.16743638480833736 | validation: 0.16483449091000107]
	TIME [epoch: 13 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17024454277013734		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.17024454277013734 | validation: 0.13597500008154567]
	TIME [epoch: 12.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16605967910290217		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.16605967910290217 | validation: 0.1355827454220073]
	TIME [epoch: 13 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17570106053697013		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.17570106053697013 | validation: 0.1819101100103415]
	TIME [epoch: 13 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1969104567743759		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.1969104567743759 | validation: 0.16317985549208608]
	TIME [epoch: 13 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16279265343024865		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.16279265343024865 | validation: 0.11669161338140552]
	TIME [epoch: 13 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635178356469854		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.1635178356469854 | validation: 0.13292305998359805]
	TIME [epoch: 13 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16885790646033552		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.16885790646033552 | validation: 0.12559990369981333]
	TIME [epoch: 13 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660647234929341		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.1660647234929341 | validation: 0.1267296438728998]
	TIME [epoch: 12.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1561965834478387		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.1561965834478387 | validation: 0.12373397548513453]
	TIME [epoch: 12.9 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16433984643207072		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.16433984643207072 | validation: 0.12387805526347727]
	TIME [epoch: 12.9 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1735101254971676		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.1735101254971676 | validation: 0.11801065815044073]
	TIME [epoch: 12.9 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15302258338310704		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.15302258338310704 | validation: 0.12867585910322904]
	TIME [epoch: 12.9 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18105688086356447		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.18105688086356447 | validation: 0.12881071242567188]
	TIME [epoch: 12.9 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17795336026380912		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.17795336026380912 | validation: 0.11817879680261265]
	TIME [epoch: 12.9 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16390898607868695		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.16390898607868695 | validation: 0.1464329052297056]
	TIME [epoch: 12.9 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1741529860453274		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.1741529860453274 | validation: 0.11323996443123652]
	TIME [epoch: 12.9 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15450086686321673		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.15450086686321673 | validation: 0.13088900523000926]
	TIME [epoch: 13 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16339150199870192		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.16339150199870192 | validation: 0.1529202231643037]
	TIME [epoch: 13 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1650074199769995		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.1650074199769995 | validation: 0.1287552678631628]
	TIME [epoch: 13 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16188290704226962		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.16188290704226962 | validation: 0.09585590338036165]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_989.pth
	Model improved!!!
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15086245324530317		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.15086245324530317 | validation: 0.14631138090042659]
	TIME [epoch: 13 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.172940849856755		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.172940849856755 | validation: 0.17242506505568947]
	TIME [epoch: 13 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20066106707074288		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.20066106707074288 | validation: 0.12759913821799596]
	TIME [epoch: 13 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17480945972692297		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.17480945972692297 | validation: 0.11260617549602434]
	TIME [epoch: 13 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15709319384475007		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.15709319384475007 | validation: 0.11888063643853665]
	TIME [epoch: 13 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16023732371571486		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.16023732371571486 | validation: 0.10869563158466922]
	TIME [epoch: 13 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16351926687371907		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.16351926687371907 | validation: 0.17464827335664573]
	TIME [epoch: 13 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18169426476538195		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.18169426476538195 | validation: 0.1306957335743185]
	TIME [epoch: 13 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16167144339572742		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.16167144339572742 | validation: 0.15476742384723902]
	TIME [epoch: 13 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19061680517649376		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.19061680517649376 | validation: 0.18279905921722914]
	TIME [epoch: 13 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18683257029584732		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.18683257029584732 | validation: 0.15922551764825219]
	TIME [epoch: 13 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17267081056915412		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.17267081056915412 | validation: 0.14558663825708698]
	TIME [epoch: 13 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1629875052890083		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.1629875052890083 | validation: 0.11142309520918459]
	TIME [epoch: 13 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16248316017211134		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.16248316017211134 | validation: 0.11214639240138487]
	TIME [epoch: 13 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14989570159137203		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.14989570159137203 | validation: 0.1134715956453126]
	TIME [epoch: 13 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1693385806683954		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.1693385806683954 | validation: 0.228533581948577]
	TIME [epoch: 12.9 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17933234880591675		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.17933234880591675 | validation: 0.11548139054267974]
	TIME [epoch: 12.9 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15134041718264263		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.15134041718264263 | validation: 0.16701828154580356]
	TIME [epoch: 12.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747585433409579		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.1747585433409579 | validation: 0.11846062007902082]
	TIME [epoch: 13 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17583192617468468		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.17583192617468468 | validation: 0.130952132694181]
	TIME [epoch: 12.9 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15673265112590684		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.15673265112590684 | validation: 0.12452361214260274]
	TIME [epoch: 12.9 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452795678054257		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.1452795678054257 | validation: 0.12603423933811395]
	TIME [epoch: 13 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15368327306792184		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.15368327306792184 | validation: 0.13173141184526846]
	TIME [epoch: 12.9 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17182245710308608		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.17182245710308608 | validation: 0.12144011980128529]
	TIME [epoch: 12.9 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16017855248288063		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.16017855248288063 | validation: 0.11646270344942737]
	TIME [epoch: 12.9 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487680309403955		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.1487680309403955 | validation: 0.13726050045700658]
	TIME [epoch: 13 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17570151634578562		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.17570151634578562 | validation: 0.09796337124685302]
	TIME [epoch: 13 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14663204303867353		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.14663204303867353 | validation: 0.10105884434142556]
	TIME [epoch: 13 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15540564024325393		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.15540564024325393 | validation: 0.14260216111043342]
	TIME [epoch: 13 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16952196533655525		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.16952196533655525 | validation: 0.1216278076716731]
	TIME [epoch: 13 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16029839278338062		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.16029839278338062 | validation: 0.16305642308369858]
	TIME [epoch: 13 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21389303705851023		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.21389303705851023 | validation: 0.12395690161592071]
	TIME [epoch: 13 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17862582714447722		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.17862582714447722 | validation: 0.12065442287053213]
	TIME [epoch: 13 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555307830103088		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.1555307830103088 | validation: 0.11201390889656836]
	TIME [epoch: 13 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15531280757125282		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.15531280757125282 | validation: 0.12427114775148106]
	TIME [epoch: 13 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16706601688108447		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.16706601688108447 | validation: 0.1515863701665836]
	TIME [epoch: 13 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17179192285681347		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.17179192285681347 | validation: 0.14156396448288874]
	TIME [epoch: 13 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18492116478552145		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.18492116478552145 | validation: 0.19342501273833412]
	TIME [epoch: 13 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22344925313605032		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.22344925313605032 | validation: 0.1179450108692879]
	TIME [epoch: 13 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15749984443234535		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.15749984443234535 | validation: 0.189222147766386]
	TIME [epoch: 13 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17646479690267508		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.17646479690267508 | validation: 0.12432611347367639]
	TIME [epoch: 13 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16669337662568542		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.16669337662568542 | validation: 0.13687148350866996]
	TIME [epoch: 13 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17127093306886737		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.17127093306886737 | validation: 0.1275546937256605]
	TIME [epoch: 13 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20484533533423122		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.20484533533423122 | validation: 0.16395519118890178]
	TIME [epoch: 13 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17022162666433113		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.17022162666433113 | validation: 0.14016464463620973]
	TIME [epoch: 12.9 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15328658198243783		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.15328658198243783 | validation: 0.123353832478833]
	TIME [epoch: 12.9 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15307230933380991		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.15307230933380991 | validation: 0.11110064595090549]
	TIME [epoch: 13 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15143824966880087		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.15143824966880087 | validation: 0.12110825871379774]
	TIME [epoch: 12.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15073590785137278		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.15073590785137278 | validation: 0.10929179758367635]
	TIME [epoch: 12.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16333677569421584		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.16333677569421584 | validation: 0.1485495859273036]
	TIME [epoch: 12.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19270624156886007		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.19270624156886007 | validation: 0.11335983380589588]
	TIME [epoch: 12.9 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15529050394170382		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.15529050394170382 | validation: 0.10831663447048596]
	TIME [epoch: 12.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15485598378757776		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.15485598378757776 | validation: 0.11963471717340696]
	TIME [epoch: 12.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14764597551564132		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.14764597551564132 | validation: 0.14954778875581265]
	TIME [epoch: 13 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16213023779891658		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.16213023779891658 | validation: 0.11170945493177889]
	TIME [epoch: 12.9 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15007880222837		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.15007880222837 | validation: 0.14391650200987832]
	TIME [epoch: 12.9 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16413716451716395		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.16413716451716395 | validation: 0.1433103143054088]
	TIME [epoch: 13 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2224370364434063		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.2224370364434063 | validation: 0.18767495329744613]
	TIME [epoch: 13 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17840158682591642		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.17840158682591642 | validation: 0.13272153431346198]
	TIME [epoch: 12.9 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16188695834954248		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.16188695834954248 | validation: 0.11013995369660007]
	TIME [epoch: 13 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14595217256982476		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.14595217256982476 | validation: 0.10896027267130702]
	TIME [epoch: 13 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15103947518576422		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.15103947518576422 | validation: 0.10256104428875844]
	TIME [epoch: 13 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.154559523323494		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.154559523323494 | validation: 0.14615426930715902]
	TIME [epoch: 12.9 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16091367903231915		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.16091367903231915 | validation: 0.10309850435001117]
	TIME [epoch: 13 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17046545342755062		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.17046545342755062 | validation: 0.16676230222245828]
	TIME [epoch: 13 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572832629418494		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.1572832629418494 | validation: 0.1479870476948783]
	TIME [epoch: 13 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1711778995939447		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.1711778995939447 | validation: 0.14555741940922487]
	TIME [epoch: 13 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18335475747985852		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.18335475747985852 | validation: 0.15561915081039104]
	TIME [epoch: 13 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1634303842799299		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.1634303842799299 | validation: 0.11580366386211285]
	TIME [epoch: 13.3 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485433054946783		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.1485433054946783 | validation: 0.11962775327872914]
	TIME [epoch: 13 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1556170470328878		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.1556170470328878 | validation: 0.1293236518177455]
	TIME [epoch: 13 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16590331619071552		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.16590331619071552 | validation: 0.14746706297401319]
	TIME [epoch: 13 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16574274634493674		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.16574274634493674 | validation: 0.14410210115080233]
	TIME [epoch: 13 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15434879057113682		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.15434879057113682 | validation: 0.12440767656614306]
	TIME [epoch: 13 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16168259514574346		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.16168259514574346 | validation: 0.1364244362254771]
	TIME [epoch: 13 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15455161089421654		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.15455161089421654 | validation: 0.10533859430486456]
	TIME [epoch: 13 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14572018871582273		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.14572018871582273 | validation: 0.10716346336364754]
	TIME [epoch: 13 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14577738773789664		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.14577738773789664 | validation: 0.10673600411873807]
	TIME [epoch: 13 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16617518177575782		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.16617518177575782 | validation: 0.13388238727495866]
	TIME [epoch: 13 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15625599301330312		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.15625599301330312 | validation: 0.12016956379078682]
	TIME [epoch: 13 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544869951082753		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.1544869951082753 | validation: 0.110524865154389]
	TIME [epoch: 13 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15320252406474627		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.15320252406474627 | validation: 0.11450817011088345]
	TIME [epoch: 13 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16868633035157615		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.16868633035157615 | validation: 0.11641851929123542]
	TIME [epoch: 13 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16786552696375232		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.16786552696375232 | validation: 0.11476960858574707]
	TIME [epoch: 13 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16577568844747917		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.16577568844747917 | validation: 0.11741838738706588]
	TIME [epoch: 13 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16562279041641062		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.16562279041641062 | validation: 0.1278665149834157]
	TIME [epoch: 13 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15293265889075353		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.15293265889075353 | validation: 0.10803170824296593]
	TIME [epoch: 13 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15423505763222986		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.15423505763222986 | validation: 0.11057738242339941]
	TIME [epoch: 13 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14493856622193452		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.14493856622193452 | validation: 0.12814976137006545]
	TIME [epoch: 13 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1463325575150284		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.1463325575150284 | validation: 0.11104935368163531]
	TIME [epoch: 13 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15785782865551526		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.15785782865551526 | validation: 0.11659130768166963]
	TIME [epoch: 13 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15820677998866822		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.15820677998866822 | validation: 0.12994341958891592]
	TIME [epoch: 13 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15404928336022222		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.15404928336022222 | validation: 0.10404368177094937]
	TIME [epoch: 13 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15559168705487322		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.15559168705487322 | validation: 0.1564027033778644]
	TIME [epoch: 13 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16001351811034759		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.16001351811034759 | validation: 0.1183641538947759]
	TIME [epoch: 13 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14867369992591706		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.14867369992591706 | validation: 0.1052091811813238]
	TIME [epoch: 13 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464729753955453		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.1464729753955453 | validation: 0.10230522533906511]
	TIME [epoch: 13 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1639570397987864		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.1639570397987864 | validation: 0.1249574322377211]
	TIME [epoch: 13 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626372090130449		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.1626372090130449 | validation: 0.11226686406831574]
	TIME [epoch: 13 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14938394402474545		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.14938394402474545 | validation: 0.10980958170862205]
	TIME [epoch: 13 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14821836362294233		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.14821836362294233 | validation: 0.1145404551569035]
	TIME [epoch: 13 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15395941108287564		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.15395941108287564 | validation: 0.13310372606079343]
	TIME [epoch: 13 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16002946027709192		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.16002946027709192 | validation: 0.10292920438514731]
	TIME [epoch: 13 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522672092645852		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.1522672092645852 | validation: 0.11279771980382616]
	TIME [epoch: 13 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19942487379110155		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.19942487379110155 | validation: 0.2746297645729653]
	TIME [epoch: 13 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21345476756084852		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.21345476756084852 | validation: 0.11561966205166627]
	TIME [epoch: 13 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660982099200506		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.1660982099200506 | validation: 0.14065713328059012]
	TIME [epoch: 13 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1589241911069497		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.1589241911069497 | validation: 0.11870846313927767]
	TIME [epoch: 13 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14508023783625137		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.14508023783625137 | validation: 0.1096370285605984]
	TIME [epoch: 13 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14631273547337592		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.14631273547337592 | validation: 0.1003716389347127]
	TIME [epoch: 13 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15013720964011373		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.15013720964011373 | validation: 0.10874910158145987]
	TIME [epoch: 13 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429099176681748		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.1429099176681748 | validation: 0.1112458395932252]
	TIME [epoch: 13 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14951118981560083		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.14951118981560083 | validation: 0.10683027162355208]
	TIME [epoch: 13 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13968623151094256		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.13968623151094256 | validation: 0.11527590880868856]
	TIME [epoch: 13 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142204579925175		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.142204579925175 | validation: 0.11408069369583354]
	TIME [epoch: 13 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15528131321974703		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.15528131321974703 | validation: 0.13344507899057684]
	TIME [epoch: 13 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14876747103367047		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.14876747103367047 | validation: 0.11562045053585586]
	TIME [epoch: 13 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14355757583173945		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.14355757583173945 | validation: 0.1392124324459058]
	TIME [epoch: 13 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15420434734514854		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.15420434734514854 | validation: 0.13215013427546826]
	TIME [epoch: 13 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15842809153364318		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.15842809153364318 | validation: 0.183158006051318]
	TIME [epoch: 13 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1653376098346564		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.1653376098346564 | validation: 0.11768126529932939]
	TIME [epoch: 13 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18052633681694158		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.18052633681694158 | validation: 0.15078971901663277]
	TIME [epoch: 13 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16327338870305505		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.16327338870305505 | validation: 0.10251742782749043]
	TIME [epoch: 13 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13818772008084193		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.13818772008084193 | validation: 0.12083830697372323]
	TIME [epoch: 13 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15216568701718608		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.15216568701718608 | validation: 0.11872745517411737]
	TIME [epoch: 13 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14281109192172026		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.14281109192172026 | validation: 0.1252578056060289]
	TIME [epoch: 13 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.148736306328736		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.148736306328736 | validation: 0.12757345031510586]
	TIME [epoch: 13 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15541138081450645		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.15541138081450645 | validation: 0.12672803024679236]
	TIME [epoch: 13 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14504869192838937		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.14504869192838937 | validation: 0.13845053688008854]
	TIME [epoch: 13 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15210645447376991		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.15210645447376991 | validation: 0.11783049097669579]
	TIME [epoch: 13 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15315000964163492		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.15315000964163492 | validation: 0.11550646871775776]
	TIME [epoch: 13 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15492236858573816		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.15492236858573816 | validation: 0.1460101321696687]
	TIME [epoch: 13 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16744809654870374		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.16744809654870374 | validation: 0.12749861360747225]
	TIME [epoch: 13 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14250108225770994		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.14250108225770994 | validation: 0.11745286618991319]
	TIME [epoch: 13 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15881423910895914		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.15881423910895914 | validation: 0.1014753062342766]
	TIME [epoch: 13 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14657652099161467		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.14657652099161467 | validation: 0.10624036708711192]
	TIME [epoch: 13 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14271568202150342		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.14271568202150342 | validation: 0.10705391415534536]
	TIME [epoch: 13 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13879043057865173		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.13879043057865173 | validation: 0.10127846695261183]
	TIME [epoch: 13 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14613584725419557		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.14613584725419557 | validation: 0.10726385415966867]
	TIME [epoch: 13 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14400127613406732		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.14400127613406732 | validation: 0.10372820950569464]
	TIME [epoch: 13 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13593499092319067		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.13593499092319067 | validation: 0.11819507214399952]
	TIME [epoch: 13 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14576862530276224		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.14576862530276224 | validation: 0.1089121179711801]
	TIME [epoch: 13 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15381460343362668		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.15381460343362668 | validation: 0.10908270142133145]
	TIME [epoch: 13 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14394496735185233		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.14394496735185233 | validation: 0.11654011385107371]
	TIME [epoch: 13 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13932908896714097		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.13932908896714097 | validation: 0.10914733740137025]
	TIME [epoch: 13 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1467795969592032		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.1467795969592032 | validation: 0.1835874496164057]
	TIME [epoch: 13 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18109418040004208		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.18109418040004208 | validation: 0.11577254764409105]
	TIME [epoch: 13 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14996156467871063		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.14996156467871063 | validation: 0.12773768554653528]
	TIME [epoch: 13 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508272144212167		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.1508272144212167 | validation: 0.1292092971754881]
	TIME [epoch: 13 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15163794974969014		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.15163794974969014 | validation: 0.10555971297267998]
	TIME [epoch: 13 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14045971196306306		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.14045971196306306 | validation: 0.10018204793127637]
	TIME [epoch: 13 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1534713376162943		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.1534713376162943 | validation: 0.19953958806535702]
	TIME [epoch: 13 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21834627680874572		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.21834627680874572 | validation: 0.1416814500353828]
	TIME [epoch: 13 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15200283512570079		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.15200283512570079 | validation: 0.11618983394444415]
	TIME [epoch: 13 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14600270626960807		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.14600270626960807 | validation: 0.10596036984849473]
	TIME [epoch: 13 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14754574573876142		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.14754574573876142 | validation: 0.1069218996408973]
	TIME [epoch: 13 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1915944243206048		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.1915944243206048 | validation: 0.15616596349348902]
	TIME [epoch: 13 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18921209526588587		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.18921209526588587 | validation: 0.11043024639068776]
	TIME [epoch: 13 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13783281939578268		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.13783281939578268 | validation: 0.10217071754128224]
	TIME [epoch: 13 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13712147065268154		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.13712147065268154 | validation: 0.09333961039709804]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_1149.pth
	Model improved!!!
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14438642558967546		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.14438642558967546 | validation: 0.15137551247639397]
	TIME [epoch: 13 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505966504590915		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.1505966504590915 | validation: 0.10870087036739627]
	TIME [epoch: 13 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15310590678315814		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.15310590678315814 | validation: 0.11823983676370463]
	TIME [epoch: 13 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14847008694790817		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.14847008694790817 | validation: 0.10004152679266472]
	TIME [epoch: 13 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15689101993701354		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.15689101993701354 | validation: 0.10567253022453589]
	TIME [epoch: 13 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.149244889711006		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.149244889711006 | validation: 0.12447605929390115]
	TIME [epoch: 13 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15369604617567045		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.15369604617567045 | validation: 0.12062750315920606]
	TIME [epoch: 13 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14925054723949188		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.14925054723949188 | validation: 0.10771779525018595]
	TIME [epoch: 13 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14820973504914248		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.14820973504914248 | validation: 0.10788187206233034]
	TIME [epoch: 13 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1494253995961532		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.1494253995961532 | validation: 0.1308909636158302]
	TIME [epoch: 13 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14393259889151921		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.14393259889151921 | validation: 0.10877831471601195]
	TIME [epoch: 13 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13890149760124249		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.13890149760124249 | validation: 0.1181307743420027]
	TIME [epoch: 13 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1494598255015382		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.1494598255015382 | validation: 0.11860977586962099]
	TIME [epoch: 13 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659611898943058		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.1659611898943058 | validation: 0.10966296984386865]
	TIME [epoch: 13 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14152058298890505		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.14152058298890505 | validation: 0.10022259148947602]
	TIME [epoch: 13 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13536967442069595		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.13536967442069595 | validation: 0.10910603947963747]
	TIME [epoch: 13 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422435730059355		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.1422435730059355 | validation: 0.12032156247427406]
	TIME [epoch: 13 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14110896430620007		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.14110896430620007 | validation: 0.11428939913907585]
	TIME [epoch: 13 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429974873993104		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.1429974873993104 | validation: 0.13422474180681118]
	TIME [epoch: 13 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14976054458804874		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.14976054458804874 | validation: 0.11505757170594144]
	TIME [epoch: 13 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14282600763399678		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.14282600763399678 | validation: 0.10791364503333978]
	TIME [epoch: 13 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14862589928264125		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.14862589928264125 | validation: 0.12040750806847349]
	TIME [epoch: 13 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17012778520680094		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.17012778520680094 | validation: 0.13959919779697158]
	TIME [epoch: 13 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659564063465655		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.1659564063465655 | validation: 0.12828366699738541]
	TIME [epoch: 13 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14948727971575754		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.14948727971575754 | validation: 0.10012454896024822]
	TIME [epoch: 13 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14121460851628465		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.14121460851628465 | validation: 0.14356718502334415]
	TIME [epoch: 13 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.177315064523591		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.177315064523591 | validation: 0.1060452969956246]
	TIME [epoch: 13 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446213714068729		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.1446213714068729 | validation: 0.11042292966854088]
	TIME [epoch: 13 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15177467359883565		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.15177467359883565 | validation: 0.1278465671137925]
	TIME [epoch: 13 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162286595598275		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.162286595598275 | validation: 0.12751112311465299]
	TIME [epoch: 13 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1490618778650994		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.1490618778650994 | validation: 0.11641012716929826]
	TIME [epoch: 13 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14228637707538744		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.14228637707538744 | validation: 0.13288127448456125]
	TIME [epoch: 13 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522723726991228		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.1522723726991228 | validation: 0.11308615931489953]
	TIME [epoch: 13 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515622935853167		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.1515622935853167 | validation: 0.12137835995111637]
	TIME [epoch: 13 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15032975917084593		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.15032975917084593 | validation: 0.1263301202926853]
	TIME [epoch: 13 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14622412725937442		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.14622412725937442 | validation: 0.13905977818545978]
	TIME [epoch: 13 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1584851271760742		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.1584851271760742 | validation: 0.10400136574748647]
	TIME [epoch: 13 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14339190394000179		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.14339190394000179 | validation: 0.13738112737421254]
	TIME [epoch: 13 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14656762862512107		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.14656762862512107 | validation: 0.11426669749822022]
	TIME [epoch: 13 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350366587210185		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.1350366587210185 | validation: 0.10775555316822026]
	TIME [epoch: 13 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14338598002587244		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.14338598002587244 | validation: 0.11275094221312942]
	TIME [epoch: 13 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374988413217649		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.1374988413217649 | validation: 0.113373876348089]
	TIME [epoch: 13 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13905054254632604		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.13905054254632604 | validation: 0.10480867074726576]
	TIME [epoch: 13 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13552353680068047		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.13552353680068047 | validation: 0.1251886194569653]
	TIME [epoch: 13 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16219777141559158		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.16219777141559158 | validation: 0.114011997558059]
	TIME [epoch: 13 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489766367329488		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.1489766367329488 | validation: 0.10249538696860942]
	TIME [epoch: 13 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427779890938906		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.1427779890938906 | validation: 0.10118627019130144]
	TIME [epoch: 13 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403467623707112		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.1403467623707112 | validation: 0.10351358009733092]
	TIME [epoch: 13 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14847185805275778		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.14847185805275778 | validation: 0.11211137669426222]
	TIME [epoch: 13 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14294884091010734		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.14294884091010734 | validation: 0.1266635354599384]
	TIME [epoch: 13 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1495533125002069		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.1495533125002069 | validation: 0.11386098661838132]
	TIME [epoch: 13 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14670834453189327		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.14670834453189327 | validation: 0.10564908500611911]
	TIME [epoch: 13 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14317498623122152		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.14317498623122152 | validation: 0.14463442433449658]
	TIME [epoch: 12.9 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13989154919501845		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.13989154919501845 | validation: 0.13932625914358335]
	TIME [epoch: 13 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15856000911173213		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.15856000911173213 | validation: 0.13356608412566157]
	TIME [epoch: 12.9 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14278770155224035		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.14278770155224035 | validation: 0.11344162806027981]
	TIME [epoch: 13 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16645763080654036		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.16645763080654036 | validation: 0.10701125341310144]
	TIME [epoch: 13 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14172145446680937		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.14172145446680937 | validation: 0.11347460924654806]
	TIME [epoch: 13 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1414763227396445		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.1414763227396445 | validation: 0.10960350024702727]
	TIME [epoch: 12.9 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14545771955014597		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.14545771955014597 | validation: 0.110570064727552]
	TIME [epoch: 12.9 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13802186077867487		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.13802186077867487 | validation: 0.10359283537797709]
	TIME [epoch: 13 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346477135246072		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.1346477135246072 | validation: 0.09407866329413457]
	TIME [epoch: 13 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621198828503444		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.1621198828503444 | validation: 0.12311768897107779]
	TIME [epoch: 13 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654701425374634		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.1654701425374634 | validation: 0.11537111063937384]
	TIME [epoch: 13 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13923476811516888		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.13923476811516888 | validation: 0.10134534766479497]
	TIME [epoch: 13 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140219267590543		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.140219267590543 | validation: 0.14941167825244125]
	TIME [epoch: 13 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15539385674163217		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.15539385674163217 | validation: 0.11401764477764244]
	TIME [epoch: 13 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14580740524081726		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.14580740524081726 | validation: 0.10432229635765924]
	TIME [epoch: 13 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14090926133646522		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.14090926133646522 | validation: 0.12292071305763867]
	TIME [epoch: 13 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14679228484712942		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.14679228484712942 | validation: 0.11240541289112832]
	TIME [epoch: 13 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339105328991234		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.1339105328991234 | validation: 0.107328773056858]
	TIME [epoch: 13 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14474894894589346		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.14474894894589346 | validation: 0.11498521033456129]
	TIME [epoch: 13 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14245882328059176		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.14245882328059176 | validation: 0.11473924232832251]
	TIME [epoch: 13 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14664078073279718		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.14664078073279718 | validation: 0.1341280202437827]
	TIME [epoch: 13 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14247993796291664		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.14247993796291664 | validation: 0.12089960369115488]
	TIME [epoch: 13 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14422853127895574		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.14422853127895574 | validation: 0.13530204847329777]
	TIME [epoch: 13 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442069495174953		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.1442069495174953 | validation: 0.10786072032198649]
	TIME [epoch: 13 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1392648486658154		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.1392648486658154 | validation: 0.11090894843870754]
	TIME [epoch: 13 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14014682096680187		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.14014682096680187 | validation: 0.11138691416801642]
	TIME [epoch: 13 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14868247247350297		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.14868247247350297 | validation: 0.11257277369139473]
	TIME [epoch: 13 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1504348744214743		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.1504348744214743 | validation: 0.10647007090299358]
	TIME [epoch: 13 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348076282677288		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.1348076282677288 | validation: 0.1040138013593501]
	TIME [epoch: 13 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422803383752002		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.1422803383752002 | validation: 0.10574366361260426]
	TIME [epoch: 13 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14170163702126717		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.14170163702126717 | validation: 0.15119597397816675]
	TIME [epoch: 13 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19088125644113946		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.19088125644113946 | validation: 0.16660021625237498]
	TIME [epoch: 13 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16537550329221162		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.16537550329221162 | validation: 0.10602723774327558]
	TIME [epoch: 13 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14791172808189854		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.14791172808189854 | validation: 0.12285422498383756]
	TIME [epoch: 13 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632704920712731		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.1632704920712731 | validation: 0.11141129841369128]
	TIME [epoch: 13 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14628363111802767		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.14628363111802767 | validation: 0.11308737182452241]
	TIME [epoch: 13 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14971901542423982		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.14971901542423982 | validation: 0.10644363540590938]
	TIME [epoch: 13 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14427222956122837		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.14427222956122837 | validation: 0.1111368888308631]
	TIME [epoch: 13 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14597652813409773		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.14597652813409773 | validation: 0.1201107399286039]
	TIME [epoch: 13 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1451996138826863		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.1451996138826863 | validation: 0.1282136767902973]
	TIME [epoch: 13 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1656755565957712		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.1656755565957712 | validation: 0.16118789771974804]
	TIME [epoch: 13 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15735479096165142		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.15735479096165142 | validation: 0.10893346181506157]
	TIME [epoch: 13 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15150557243591956		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.15150557243591956 | validation: 0.14218191850248244]
	TIME [epoch: 13 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16695843302846783		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.16695843302846783 | validation: 0.10795068435105]
	TIME [epoch: 13 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141993606700285		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.141993606700285 | validation: 0.10385627866810772]
	TIME [epoch: 12.9 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449727947502289		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.1449727947502289 | validation: 0.12867709430602692]
	TIME [epoch: 12.9 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14726478843264376		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.14726478843264376 | validation: 0.10195906071377785]
	TIME [epoch: 12.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13902435358767104		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.13902435358767104 | validation: 0.11027257075411949]
	TIME [epoch: 13 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14268642446747706		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.14268642446747706 | validation: 0.13164309728752455]
	TIME [epoch: 13 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14997310510345704		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.14997310510345704 | validation: 0.1167188343815607]
	TIME [epoch: 13 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15314388004308893		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.15314388004308893 | validation: 0.1370455792348492]
	TIME [epoch: 13 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1454204626068199		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.1454204626068199 | validation: 0.1032109228420005]
	TIME [epoch: 13 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346520221326224		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.1346520221326224 | validation: 0.09494764589606985]
	TIME [epoch: 13 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14778251053761862		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.14778251053761862 | validation: 0.11549703939778869]
	TIME [epoch: 13 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14368191891329607		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.14368191891329607 | validation: 0.11438147668572579]
	TIME [epoch: 13 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14269976705706913		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.14269976705706913 | validation: 0.11161541562544228]
	TIME [epoch: 13 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13746866482027387		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.13746866482027387 | validation: 0.100578870668495]
	TIME [epoch: 13 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13446518987656617		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.13446518987656617 | validation: 0.11006906801326119]
	TIME [epoch: 13 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13527522620584104		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.13527522620584104 | validation: 0.10737258635964984]
	TIME [epoch: 13 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13307581543027827		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.13307581543027827 | validation: 0.09947874883563645]
	TIME [epoch: 12.9 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13516402471274203		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.13516402471274203 | validation: 0.12626722847178512]
	TIME [epoch: 13 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13433618859565413		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.13433618859565413 | validation: 0.10003804302818821]
	TIME [epoch: 13 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13329019101302592		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.13329019101302592 | validation: 0.11160726773434256]
	TIME [epoch: 13 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14013798436675354		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.14013798436675354 | validation: 0.11259549685467772]
	TIME [epoch: 13 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516670976206152		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.1516670976206152 | validation: 0.14799858919967931]
	TIME [epoch: 13 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14832261911330422		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.14832261911330422 | validation: 0.10692534140742348]
	TIME [epoch: 13 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13404013878119234		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.13404013878119234 | validation: 0.11084204614657789]
	TIME [epoch: 13 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1382246433905317		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.1382246433905317 | validation: 0.12111130721904957]
	TIME [epoch: 13 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13653321889530878		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.13653321889530878 | validation: 0.12067347588215492]
	TIME [epoch: 13 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15586315671810896		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.15586315671810896 | validation: 0.10973885651511468]
	TIME [epoch: 13 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13987079162641408		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.13987079162641408 | validation: 0.09885543484061543]
	TIME [epoch: 13 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13475642450188993		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.13475642450188993 | validation: 0.1091704528365861]
	TIME [epoch: 13 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13359649638611748		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.13359649638611748 | validation: 0.09618607130019642]
	TIME [epoch: 13 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13890466668545848		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.13890466668545848 | validation: 0.10699282301829005]
	TIME [epoch: 13 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1352302070763305		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.1352302070763305 | validation: 0.09950853133666915]
	TIME [epoch: 13 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1412576447596988		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.1412576447596988 | validation: 0.10332575457824071]
	TIME [epoch: 13 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400873263161743		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.1400873263161743 | validation: 0.11867756580385647]
	TIME [epoch: 13 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14080808042146697		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.14080808042146697 | validation: 0.10951278723351443]
	TIME [epoch: 13 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411351059443992		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.1411351059443992 | validation: 0.11240689004471838]
	TIME [epoch: 13 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141584339048573		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.141584339048573 | validation: 0.10765458431018238]
	TIME [epoch: 13 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13738367942257304		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.13738367942257304 | validation: 0.09773319274458071]
	TIME [epoch: 13 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13648079443919967		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.13648079443919967 | validation: 0.11547631189408623]
	TIME [epoch: 13 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1512838186655439		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.1512838186655439 | validation: 0.11284114435395261]
	TIME [epoch: 13 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13719434754164186		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.13719434754164186 | validation: 0.09943357863010924]
	TIME [epoch: 13 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14226296216063924		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.14226296216063924 | validation: 0.12257357276804606]
	TIME [epoch: 12.9 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16108992846176026		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.16108992846176026 | validation: 0.15046684351886241]
	TIME [epoch: 13 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15159402920904566		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.15159402920904566 | validation: 0.11552506852214915]
	TIME [epoch: 13 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14114131045320724		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.14114131045320724 | validation: 0.10251702591195484]
	TIME [epoch: 13 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14169647633293123		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.14169647633293123 | validation: 0.10404107195199255]
	TIME [epoch: 13 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13987436226575567		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.13987436226575567 | validation: 0.10687351698714168]
	TIME [epoch: 13 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13590232023952176		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.13590232023952176 | validation: 0.09870738215183388]
	TIME [epoch: 13 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13021671470206414		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.13021671470206414 | validation: 0.10393995866202964]
	TIME [epoch: 13 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13848772360995867		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.13848772360995867 | validation: 0.12289396160614022]
	TIME [epoch: 13 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1573842346288125		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.1573842346288125 | validation: 0.12636261606323354]
	TIME [epoch: 13 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15219426678270018		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.15219426678270018 | validation: 0.11566302556957694]
	TIME [epoch: 13 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13928924308264437		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.13928924308264437 | validation: 0.12957449188467596]
	TIME [epoch: 13 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14126926216348046		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.14126926216348046 | validation: 0.10170154279096266]
	TIME [epoch: 13 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406637366928127		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.1406637366928127 | validation: 0.12336610154090714]
	TIME [epoch: 13 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1443110636281876		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.1443110636281876 | validation: 0.11812560832460761]
	TIME [epoch: 13 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365107089753884		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.1365107089753884 | validation: 0.11375533535379155]
	TIME [epoch: 13 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14827559508005117		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.14827559508005117 | validation: 0.1372549088976302]
	TIME [epoch: 13 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14776548839453887		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.14776548839453887 | validation: 0.11828547813580174]
	TIME [epoch: 13 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13810249013791734		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.13810249013791734 | validation: 0.1146837272254103]
	TIME [epoch: 13 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14428662702230324		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.14428662702230324 | validation: 0.1121359028138613]
	TIME [epoch: 13 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13873618207584335		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.13873618207584335 | validation: 0.11233085178048807]
	TIME [epoch: 13 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14441408273614356		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.14441408273614356 | validation: 0.15700655932477653]
	TIME [epoch: 13 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16319644625629104		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.16319644625629104 | validation: 0.14807308648783804]
	TIME [epoch: 13 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1444892130214433		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.1444892130214433 | validation: 0.100518789817509]
	TIME [epoch: 13 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13353721263971924		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.13353721263971924 | validation: 0.10634913107971622]
	TIME [epoch: 13 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13669945386232896		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.13669945386232896 | validation: 0.10727388653095239]
	TIME [epoch: 13 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13569207825245114		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.13569207825245114 | validation: 0.10141262940355429]
	TIME [epoch: 13 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13855352860606818		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.13855352860606818 | validation: 0.10997421939708472]
	TIME [epoch: 13 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13867822115525705		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.13867822115525705 | validation: 0.10373044810947747]
	TIME [epoch: 13 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13266090609688985		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.13266090609688985 | validation: 0.1087378625032229]
	TIME [epoch: 13 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361736826437266		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.1361736826437266 | validation: 0.10969633877611842]
	TIME [epoch: 13 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13906174278651143		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.13906174278651143 | validation: 0.10725205036911749]
	TIME [epoch: 13 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13889645708125015		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.13889645708125015 | validation: 0.12417878930422685]
	TIME [epoch: 13 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384868902172654		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.1384868902172654 | validation: 0.12035762472151197]
	TIME [epoch: 13 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438742408367591		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.1438742408367591 | validation: 0.10502308837695147]
	TIME [epoch: 13 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13959145453298527		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.13959145453298527 | validation: 0.11147330903364637]
	TIME [epoch: 13 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13886976486655955		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.13886976486655955 | validation: 0.10965318226576383]
	TIME [epoch: 13 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13141749135224623		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.13141749135224623 | validation: 0.11413023430717555]
	TIME [epoch: 13 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15320265731679		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.15320265731679 | validation: 0.10505927189742556]
	TIME [epoch: 13 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13730003276500963		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.13730003276500963 | validation: 0.11037787392770457]
	TIME [epoch: 13 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369949011233015		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.1369949011233015 | validation: 0.10457514480803806]
	TIME [epoch: 13 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14464955540134317		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.14464955540134317 | validation: 0.10303094582061441]
	TIME [epoch: 13 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379501964194847		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.1379501964194847 | validation: 0.09802932619923833]
	TIME [epoch: 13 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13405068906217027		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.13405068906217027 | validation: 0.10378250558277]
	TIME [epoch: 13 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13312840267767984		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.13312840267767984 | validation: 0.10392654483355344]
	TIME [epoch: 13 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136813917937044		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.136813917937044 | validation: 0.10907352825340694]
	TIME [epoch: 13 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1444961418883906		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.1444961418883906 | validation: 0.1030171137966794]
	TIME [epoch: 13 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323159540106976		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.1323159540106976 | validation: 0.09080577487374317]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_1334.pth
	Model improved!!!
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391443452461172		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.1391443452461172 | validation: 0.09570084505070522]
	TIME [epoch: 13 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14415065136973607		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.14415065136973607 | validation: 0.0969126755215699]
	TIME [epoch: 13 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13338617680940393		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.13338617680940393 | validation: 0.1281797619006867]
	TIME [epoch: 13 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14785396138977774		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.14785396138977774 | validation: 0.12866204154868585]
	TIME [epoch: 13 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13973162792992538		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.13973162792992538 | validation: 0.10761209650188072]
	TIME [epoch: 13 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13494913350417043		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.13494913350417043 | validation: 0.10281422586059437]
	TIME [epoch: 13 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12995533387145142		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.12995533387145142 | validation: 0.10326008967770431]
	TIME [epoch: 13 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400147948565673		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.1400147948565673 | validation: 0.10292543079193532]
	TIME [epoch: 13 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14138962302847563		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.14138962302847563 | validation: 0.11977467855647436]
	TIME [epoch: 13 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13866542082034575		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.13866542082034575 | validation: 0.10527401863459664]
	TIME [epoch: 13 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369722797193505		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.1369722797193505 | validation: 0.10499721934117436]
	TIME [epoch: 13 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15319940323448716		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.15319940323448716 | validation: 0.11147496070282407]
	TIME [epoch: 13 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14500433891757583		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.14500433891757583 | validation: 0.10661504620603783]
	TIME [epoch: 13 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13425805050428763		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.13425805050428763 | validation: 0.10509970252705919]
	TIME [epoch: 13 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13144138607893074		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.13144138607893074 | validation: 0.11121039449196302]
	TIME [epoch: 13 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14752645330640102		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.14752645330640102 | validation: 0.12509339303474082]
	TIME [epoch: 13 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15881893404352157		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.15881893404352157 | validation: 0.10548900391291106]
	TIME [epoch: 13 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13249119469414308		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.13249119469414308 | validation: 0.10273989004446618]
	TIME [epoch: 12.9 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13745416058349486		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.13745416058349486 | validation: 0.12175773446159882]
	TIME [epoch: 13 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13829075745724007		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.13829075745724007 | validation: 0.11295899317786028]
	TIME [epoch: 13 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14041509964241966		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.14041509964241966 | validation: 0.10781478800741635]
	TIME [epoch: 13 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13470080350695218		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.13470080350695218 | validation: 0.11067368486979844]
	TIME [epoch: 13 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13433897769672262		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.13433897769672262 | validation: 0.12271612027680387]
	TIME [epoch: 13 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14732368332672616		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.14732368332672616 | validation: 0.117647919509132]
	TIME [epoch: 13 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1366663042559636		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.1366663042559636 | validation: 0.10888953923663923]
	TIME [epoch: 13 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13598151704124914		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.13598151704124914 | validation: 0.12335443462751385]
	TIME [epoch: 13 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13868024420159603		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.13868024420159603 | validation: 0.10346956731958845]
	TIME [epoch: 13 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13719540188330853		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.13719540188330853 | validation: 0.10688555392013743]
	TIME [epoch: 13 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14578227649567035		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.14578227649567035 | validation: 0.10978225115629271]
	TIME [epoch: 13 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369172141851917		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.1369172141851917 | validation: 0.10988381569067182]
	TIME [epoch: 13 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13913695495489464		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.13913695495489464 | validation: 0.10565881050033779]
	TIME [epoch: 13 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1358443855492321		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.1358443855492321 | validation: 0.11986832815831314]
	TIME [epoch: 13 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14081469854340214		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.14081469854340214 | validation: 0.1184676095885657]
	TIME [epoch: 13 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1368229047465341		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.1368229047465341 | validation: 0.10334419373762103]
	TIME [epoch: 13 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13003421745477806		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.13003421745477806 | validation: 0.10243419981639529]
	TIME [epoch: 13 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13646360363474833		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.13646360363474833 | validation: 0.09214152217030057]
	TIME [epoch: 13 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13045349838335774		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.13045349838335774 | validation: 0.10214380687127138]
	TIME [epoch: 13 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13332674984792822		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.13332674984792822 | validation: 0.11202120722465037]
	TIME [epoch: 13 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13966583565429372		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.13966583565429372 | validation: 0.11170786082079168]
	TIME [epoch: 12.9 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13597561718846646		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.13597561718846646 | validation: 0.10538040412828284]
	TIME [epoch: 13 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391666936924026		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.1391666936924026 | validation: 0.10428840311632341]
	TIME [epoch: 12.9 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13899855637750802		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.13899855637750802 | validation: 0.11268636261182877]
	TIME [epoch: 13 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13860313059496787		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.13860313059496787 | validation: 0.12695395524296363]
	TIME [epoch: 13 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15856897230552788		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.15856897230552788 | validation: 0.14270594773716952]
	TIME [epoch: 13 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15000319746863167		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.15000319746863167 | validation: 0.10340558897209738]
	TIME [epoch: 13 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13374763094017247		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.13374763094017247 | validation: 0.10278129846467068]
	TIME [epoch: 13 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13872730186269538		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.13872730186269538 | validation: 0.09909164803555646]
	TIME [epoch: 13 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13789193340143915		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.13789193340143915 | validation: 0.0942526792896994]
	TIME [epoch: 13 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14111524586635843		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.14111524586635843 | validation: 0.09532323342348903]
	TIME [epoch: 13 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12814569141863952		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.12814569141863952 | validation: 0.09311792315455789]
	TIME [epoch: 13 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12846209501521832		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.12846209501521832 | validation: 0.10304893770399769]
	TIME [epoch: 13 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13323120812333664		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.13323120812333664 | validation: 0.11070342485422824]
	TIME [epoch: 13 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1463799587776033		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.1463799587776033 | validation: 0.09979352143952853]
	TIME [epoch: 13 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13583719609618594		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.13583719609618594 | validation: 0.10369480545239793]
	TIME [epoch: 13 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13639577186654062		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.13639577186654062 | validation: 0.10502736908057843]
	TIME [epoch: 13 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1413374734375366		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.1413374734375366 | validation: 0.12868100779757286]
	TIME [epoch: 13 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14275919482679428		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.14275919482679428 | validation: 0.10029581673451776]
	TIME [epoch: 13 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353834185389923		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.1353834185389923 | validation: 0.10384501333032803]
	TIME [epoch: 13 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13458437865454742		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.13458437865454742 | validation: 0.09276620001555347]
	TIME [epoch: 13 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319372259032004		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.1319372259032004 | validation: 0.09804168352867175]
	TIME [epoch: 13 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13091347707357887		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.13091347707357887 | validation: 0.10196952971682524]
	TIME [epoch: 13 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403922323505727		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.1403922323505727 | validation: 0.10897492978047219]
	TIME [epoch: 13 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14354230760497766		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.14354230760497766 | validation: 0.0997233134663582]
	TIME [epoch: 13 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139105893646303		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.139105893646303 | validation: 0.09909621252936367]
	TIME [epoch: 13 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12923581572781406		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.12923581572781406 | validation: 0.10250577978129599]
	TIME [epoch: 13 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315132979379858		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.1315132979379858 | validation: 0.09802768179772883]
	TIME [epoch: 13 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13360857820514446		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.13360857820514446 | validation: 0.10247307263414206]
	TIME [epoch: 13 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298136667042142		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.1298136667042142 | validation: 0.09699045240551314]
	TIME [epoch: 13 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12705004407951834		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.12705004407951834 | validation: 0.10618460611415692]
	TIME [epoch: 13 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14084488279359197		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.14084488279359197 | validation: 0.10923447353992347]
	TIME [epoch: 13 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1407365772271229		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.1407365772271229 | validation: 0.09450358238003609]
	TIME [epoch: 13 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291063214333338		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.1291063214333338 | validation: 0.09609180458027926]
	TIME [epoch: 13 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13472386707345688		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.13472386707345688 | validation: 0.10565831620424543]
	TIME [epoch: 13 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13383142037925358		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.13383142037925358 | validation: 0.11681319847661654]
	TIME [epoch: 13 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13998218018377234		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.13998218018377234 | validation: 0.10991699557692464]
	TIME [epoch: 13 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13506103559878413		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.13506103559878413 | validation: 0.10802204849767659]
	TIME [epoch: 13 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433281806602846		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.1433281806602846 | validation: 0.10689960142940667]
	TIME [epoch: 13 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13564845766705297		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.13564845766705297 | validation: 0.1033382357431751]
	TIME [epoch: 13 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13203798949166667		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.13203798949166667 | validation: 0.11218020378176138]
	TIME [epoch: 13 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13464409418134085		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.13464409418134085 | validation: 0.09991317226242996]
	TIME [epoch: 13 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13945094972446576		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.13945094972446576 | validation: 0.09661073825125907]
	TIME [epoch: 13 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14210860258076413		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.14210860258076413 | validation: 0.10450552965790962]
	TIME [epoch: 13 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12920842382012915		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.12920842382012915 | validation: 0.10927191940784572]
	TIME [epoch: 13 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13193384130256575		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.13193384130256575 | validation: 0.10395715004090006]
	TIME [epoch: 12.9 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13695126279282155		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.13695126279282155 | validation: 0.10027858569695396]
	TIME [epoch: 13 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323594081164729		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.1323594081164729 | validation: 0.09675136311949814]
	TIME [epoch: 13 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13010202083757677		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.13010202083757677 | validation: 0.10747747856218293]
	TIME [epoch: 13 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371637926176722		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.1371637926176722 | validation: 0.11502280986686846]
	TIME [epoch: 12.9 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13656103724685592		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.13656103724685592 | validation: 0.10185110062200899]
	TIME [epoch: 13 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343210234067611		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.1343210234067611 | validation: 0.1070642495097639]
	TIME [epoch: 13 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12895312859320418		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.12895312859320418 | validation: 0.09396157912143079]
	TIME [epoch: 13 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12740467076417394		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.12740467076417394 | validation: 0.09617467877945825]
	TIME [epoch: 13 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13148217035724563		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.13148217035724563 | validation: 0.1132941516644691]
	TIME [epoch: 13 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13726924132909707		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.13726924132909707 | validation: 0.11162375287094743]
	TIME [epoch: 13 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13673857337111123		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.13673857337111123 | validation: 0.10187649095673951]
	TIME [epoch: 13 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13525190614124516		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.13525190614124516 | validation: 0.09751416035564528]
	TIME [epoch: 13 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314917328123543		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.1314917328123543 | validation: 0.10416909250823952]
	TIME [epoch: 13 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13665601268149602		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.13665601268149602 | validation: 0.09565720580176121]
	TIME [epoch: 13 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13406807528623726		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.13406807528623726 | validation: 0.10257320954981611]
	TIME [epoch: 13 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753955286968772		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.13753955286968772 | validation: 0.10100944403401997]
	TIME [epoch: 13 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13271089691514357		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.13271089691514357 | validation: 0.09131346183485864]
	TIME [epoch: 13 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300935903115373		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.1300935903115373 | validation: 0.09577007515420613]
	TIME [epoch: 13 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13301864175524997		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.13301864175524997 | validation: 0.0996835728446968]
	TIME [epoch: 13 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13451614373826937		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.13451614373826937 | validation: 0.09396617151386931]
	TIME [epoch: 13 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13696163796333566		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.13696163796333566 | validation: 0.09861814737976511]
	TIME [epoch: 13 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13462795367225355		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.13462795367225355 | validation: 0.10311213364600612]
	TIME [epoch: 13 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307057948832937		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.1307057948832937 | validation: 0.09859197543271309]
	TIME [epoch: 13 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13380233240235007		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.13380233240235007 | validation: 0.10073005787201073]
	TIME [epoch: 13 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354629414265865		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.1354629414265865 | validation: 0.10204919753730249]
	TIME [epoch: 13 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12561560057341736		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.12561560057341736 | validation: 0.10505033987527451]
	TIME [epoch: 13 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13386630741683897		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.13386630741683897 | validation: 0.1097329507289195]
	TIME [epoch: 13 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13725387470795444		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.13725387470795444 | validation: 0.10886218449103906]
	TIME [epoch: 13 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12981041624587675		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.12981041624587675 | validation: 0.107437946589108]
	TIME [epoch: 13 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13433005951794896		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.13433005951794896 | validation: 0.1086759023446292]
	TIME [epoch: 13 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13234251433832422		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.13234251433832422 | validation: 0.09297866532508241]
	TIME [epoch: 13 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13362415617116438		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.13362415617116438 | validation: 0.09454209802891794]
	TIME [epoch: 13 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13259010665050402		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.13259010665050402 | validation: 0.09720047447384665]
	TIME [epoch: 13 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13126717932168563		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.13126717932168563 | validation: 0.10829250396004207]
	TIME [epoch: 13 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13466803632481278		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.13466803632481278 | validation: 0.1005294951505714]
	TIME [epoch: 13 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13428012144512072		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.13428012144512072 | validation: 0.10032782921849226]
	TIME [epoch: 13 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12869595149080146		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.12869595149080146 | validation: 0.10317577312518707]
	TIME [epoch: 13 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13053977870052103		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.13053977870052103 | validation: 0.10678264300394659]
	TIME [epoch: 13 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13401273325825097		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.13401273325825097 | validation: 0.10250591836606748]
	TIME [epoch: 13 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13282636688465518		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.13282636688465518 | validation: 0.09539624821213469]
	TIME [epoch: 13 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321758375508254		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.1321758375508254 | validation: 0.1070694887711813]
	TIME [epoch: 13 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13141025468197817		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.13141025468197817 | validation: 0.09895156739377743]
	TIME [epoch: 13 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308408746890506		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.1308408746890506 | validation: 0.10376650060324266]
	TIME [epoch: 13 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13199049244471409		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.13199049244471409 | validation: 0.1062398501186414]
	TIME [epoch: 13 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625236377383134		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.12625236377383134 | validation: 0.09659427909537342]
	TIME [epoch: 13 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300916059936653		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.1300916059936653 | validation: 0.10222183080529312]
	TIME [epoch: 13 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12769390134684835		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.12769390134684835 | validation: 0.09092897814553055]
	TIME [epoch: 13 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12860380075947098		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.12860380075947098 | validation: 0.10087053652642478]
	TIME [epoch: 13 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13179419292936276		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.13179419292936276 | validation: 0.1046023544079391]
	TIME [epoch: 13 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13645321416211403		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.13645321416211403 | validation: 0.10099872552188068]
	TIME [epoch: 13 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383850146296572		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.1383850146296572 | validation: 0.09767333567915638]
	TIME [epoch: 13 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13827919698481103		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.13827919698481103 | validation: 0.12055116815564855]
	TIME [epoch: 13 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339397659371723		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.1339397659371723 | validation: 0.11557005608707996]
	TIME [epoch: 13 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13987248041758776		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.13987248041758776 | validation: 0.11221830019152225]
	TIME [epoch: 13 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350187430471144		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.1350187430471144 | validation: 0.1003416552218323]
	TIME [epoch: 13 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12891962285214603		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.12891962285214603 | validation: 0.10037132848912876]
	TIME [epoch: 13 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13780559442354473		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.13780559442354473 | validation: 0.10726726458723423]
	TIME [epoch: 13 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.134219391321532		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.134219391321532 | validation: 0.1090852752775579]
	TIME [epoch: 13 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13249603871860127		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.13249603871860127 | validation: 0.09325147640404169]
	TIME [epoch: 13 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286751968515707		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.1286751968515707 | validation: 0.10384987806083902]
	TIME [epoch: 13 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127677568557193		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.127677568557193 | validation: 0.10434371004509432]
	TIME [epoch: 13 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12876203966695748		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.12876203966695748 | validation: 0.09863111122049331]
	TIME [epoch: 13 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335721798306807		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.1335721798306807 | validation: 0.10798615510491624]
	TIME [epoch: 13 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319218739040429		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.1319218739040429 | validation: 0.09685763679326455]
	TIME [epoch: 13 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13628561017062468		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.13628561017062468 | validation: 0.11193370170262729]
	TIME [epoch: 13 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13641428205443842		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.13641428205443842 | validation: 0.09857940507414778]
	TIME [epoch: 13 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13067552032785174		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.13067552032785174 | validation: 0.10277549333693321]
	TIME [epoch: 13 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13563076958971726		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.13563076958971726 | validation: 0.11974061455811409]
	TIME [epoch: 13 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13442870320899522		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.13442870320899522 | validation: 0.1049693973255861]
	TIME [epoch: 13 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132169304030761		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.132169304030761 | validation: 0.09659054756038074]
	TIME [epoch: 13 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13424577285007067		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.13424577285007067 | validation: 0.09147496434068834]
	TIME [epoch: 13 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12908002994787143		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.12908002994787143 | validation: 0.1019674606505275]
	TIME [epoch: 13 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13594082184234418		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.13594082184234418 | validation: 0.10099421225453245]
	TIME [epoch: 13 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13114311341661286		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.13114311341661286 | validation: 0.10228539176661049]
	TIME [epoch: 13 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329173282836683		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.1329173282836683 | validation: 0.1016585544337964]
	TIME [epoch: 13 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13231088969539156		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.13231088969539156 | validation: 0.09684116718980733]
	TIME [epoch: 13 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13547416451875904		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.13547416451875904 | validation: 0.0938184377344519]
	TIME [epoch: 13 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12820700693099601		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.12820700693099601 | validation: 0.10416764179743482]
	TIME [epoch: 13 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13564332073933183		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.13564332073933183 | validation: 0.099250911679081]
	TIME [epoch: 13 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13157026524533078		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.13157026524533078 | validation: 0.10349314207124868]
	TIME [epoch: 13 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13338295933875932		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.13338295933875932 | validation: 0.10064066248979653]
	TIME [epoch: 13 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13353062504202645		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.13353062504202645 | validation: 0.09957953225197845]
	TIME [epoch: 13 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380997788776576		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.1380997788776576 | validation: 0.10124749118929127]
	TIME [epoch: 13 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13378062524333134		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.13378062524333134 | validation: 0.0997298830116705]
	TIME [epoch: 13 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13545128318249886		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.13545128318249886 | validation: 0.10475122945886264]
	TIME [epoch: 13 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13907274047855367		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.13907274047855367 | validation: 0.10017063252009419]
	TIME [epoch: 13 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14002247676772867		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.14002247676772867 | validation: 0.09812915953152691]
	TIME [epoch: 13 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13567941718700233		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.13567941718700233 | validation: 0.10043265121623712]
	TIME [epoch: 13 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312827964061233		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.1312827964061233 | validation: 0.09848026942169419]
	TIME [epoch: 13 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322123957674024		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.1322123957674024 | validation: 0.10621682386571867]
	TIME [epoch: 13 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133324270781742		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.133324270781742 | validation: 0.101066163045549]
	TIME [epoch: 13 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13083134433651722		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.13083134433651722 | validation: 0.09409701963367827]
	TIME [epoch: 13 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13516990096190643		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.13516990096190643 | validation: 0.10147658932706602]
	TIME [epoch: 13 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13278583173528347		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.13278583173528347 | validation: 0.09840534985189794]
	TIME [epoch: 13 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13290783258509245		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.13290783258509245 | validation: 0.10365168552221654]
	TIME [epoch: 13 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13456066972594183		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.13456066972594183 | validation: 0.10282312394024697]
	TIME [epoch: 13 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308234407091625		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.1308234407091625 | validation: 0.09802606018085104]
	TIME [epoch: 13 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310952182928275		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.1310952182928275 | validation: 0.09306703171931602]
	TIME [epoch: 13 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12998123126393787		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.12998123126393787 | validation: 0.10320935946715717]
	TIME [epoch: 13 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327087275572294		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.1327087275572294 | validation: 0.0994865533776429]
	TIME [epoch: 13 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13669574422658082		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.13669574422658082 | validation: 0.11277768993331375]
	TIME [epoch: 13 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13756809088826		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.13756809088826 | validation: 0.10434441753116364]
	TIME [epoch: 13 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13254301771141083		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.13254301771141083 | validation: 0.09940509794092169]
	TIME [epoch: 13 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13474067838108533		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.13474067838108533 | validation: 0.09881517717237287]
	TIME [epoch: 13 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12892849865919914		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.12892849865919914 | validation: 0.09982874878456378]
	TIME [epoch: 13 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13092730576114528		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.13092730576114528 | validation: 0.11131597951435905]
	TIME [epoch: 13 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13667641020734014		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.13667641020734014 | validation: 0.10416925805034379]
	TIME [epoch: 13 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298405924688053		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.1298405924688053 | validation: 0.10431647242916398]
	TIME [epoch: 13 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13250393467688065		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.13250393467688065 | validation: 0.0999306534136595]
	TIME [epoch: 13 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12926062877821426		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.12926062877821426 | validation: 0.0943300082190887]
	TIME [epoch: 13 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13146309028834963		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.13146309028834963 | validation: 0.09374535152659041]
	TIME [epoch: 13 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1305069404424849		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.1305069404424849 | validation: 0.10286543881847827]
	TIME [epoch: 12.9 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136958639089706		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.136958639089706 | validation: 0.09606553216080328]
	TIME [epoch: 13 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326092936064939		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.1326092936064939 | validation: 0.09947135520997932]
	TIME [epoch: 12.9 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12981377524552823		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.12981377524552823 | validation: 0.10084135986862641]
	TIME [epoch: 12.9 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13249310690466895		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.13249310690466895 | validation: 0.09664434760031149]
	TIME [epoch: 13 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12589251054720565		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.12589251054720565 | validation: 0.10469791506188933]
	TIME [epoch: 12.9 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13162468098192648		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.13162468098192648 | validation: 0.0992544304948138]
	TIME [epoch: 12.9 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13039561221880558		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.13039561221880558 | validation: 0.09555737134971862]
	TIME [epoch: 12.9 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312476894013157		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.1312476894013157 | validation: 0.0942184755668141]
	TIME [epoch: 12.9 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13473904579342258		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.13473904579342258 | validation: 0.09710126165994845]
	TIME [epoch: 12.9 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13483646534047022		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.13483646534047022 | validation: 0.10326446375453895]
	TIME [epoch: 13 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13388978125616846		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.13388978125616846 | validation: 0.09831924567566755]
	TIME [epoch: 13 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300084528802663		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.1300084528802663 | validation: 0.10281117542255369]
	TIME [epoch: 13 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13215268186405515		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.13215268186405515 | validation: 0.10361891375629284]
	TIME [epoch: 13 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13270182159682736		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.13270182159682736 | validation: 0.10126036650644615]
	TIME [epoch: 13 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287267337454467		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.1287267337454467 | validation: 0.09311856265026522]
	TIME [epoch: 13 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13178985092746243		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.13178985092746243 | validation: 0.09669718446589996]
	TIME [epoch: 13 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12930463516988644		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.12930463516988644 | validation: 0.10471285481255835]
	TIME [epoch: 13 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13037676749200303		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.13037676749200303 | validation: 0.1069997053677161]
	TIME [epoch: 13 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353456332370586		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.1353456332370586 | validation: 0.10767703723732214]
	TIME [epoch: 13 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12817662658746365		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.12817662658746365 | validation: 0.09783820997993967]
	TIME [epoch: 13 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308801318776424		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.1308801318776424 | validation: 0.10758855070319502]
	TIME [epoch: 12.9 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297024141465252		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.1297024141465252 | validation: 0.10108145592964406]
	TIME [epoch: 13 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13245218203859455		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.13245218203859455 | validation: 0.09840166294309405]
	TIME [epoch: 12.9 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13229051193019883		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.13229051193019883 | validation: 0.0964449927616115]
	TIME [epoch: 12.9 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289047661228998		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.1289047661228998 | validation: 0.10411363831105593]
	TIME [epoch: 13 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13199734595117876		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.13199734595117876 | validation: 0.10008695133798319]
	TIME [epoch: 13 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13510226516395732		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.13510226516395732 | validation: 0.10044345991510652]
	TIME [epoch: 13 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13191658511076246		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.13191658511076246 | validation: 0.10370364083382275]
	TIME [epoch: 13 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12940356867000566		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.12940356867000566 | validation: 0.10674217301536094]
	TIME [epoch: 13 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12858065130817037		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.12858065130817037 | validation: 0.0930995289776845]
	TIME [epoch: 13 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13486057459823222		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.13486057459823222 | validation: 0.10023993134291924]
	TIME [epoch: 13 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12899855799456605		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.12899855799456605 | validation: 0.10497949865200434]
	TIME [epoch: 13 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12961130658523		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.12961130658523 | validation: 0.10553905030377102]
	TIME [epoch: 13 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314042047712418		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.1314042047712418 | validation: 0.1024707421025623]
	TIME [epoch: 13 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13227605645010676		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.13227605645010676 | validation: 0.1042660785590434]
	TIME [epoch: 13 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13275188346131267		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.13275188346131267 | validation: 0.10508230659738477]
	TIME [epoch: 13 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13436142075159022		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.13436142075159022 | validation: 0.09829607992168583]
	TIME [epoch: 13 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13291578559144404		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.13291578559144404 | validation: 0.09790898308708465]
	TIME [epoch: 13 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296457900359416		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.1296457900359416 | validation: 0.10518056042530921]
	TIME [epoch: 12.9 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13183778225028187		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.13183778225028187 | validation: 0.10183267666549069]
	TIME [epoch: 13 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303905924633554		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.1303905924633554 | validation: 0.09280873315274787]
	TIME [epoch: 13 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129473783030304		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.129473783030304 | validation: 0.09531641632478677]
	TIME [epoch: 13 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13321662005440266		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.13321662005440266 | validation: 0.10500493962381711]
	TIME [epoch: 13 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13192462190117443		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.13192462190117443 | validation: 0.09702336183564186]
	TIME [epoch: 13 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13045057305178137		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.13045057305178137 | validation: 0.09271543277893639]
	TIME [epoch: 12.9 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132802867149193		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.132802867149193 | validation: 0.09321776436993999]
	TIME [epoch: 13 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327306074605436		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.1327306074605436 | validation: 0.09576976717022011]
	TIME [epoch: 13 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13239312146534613		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.13239312146534613 | validation: 0.09577618244263816]
	TIME [epoch: 12.9 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315333203715911		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.1315333203715911 | validation: 0.09999851798356706]
	TIME [epoch: 13 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625738756727584		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.12625738756727584 | validation: 0.09868727215992387]
	TIME [epoch: 13 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12883351086503164		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.12883351086503164 | validation: 0.09428433727728991]
	TIME [epoch: 13 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290748894816129		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.1290748894816129 | validation: 0.09426686105832445]
	TIME [epoch: 13 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13241310451804547		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.13241310451804547 | validation: 0.10524578077526815]
	TIME [epoch: 13 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12563181211291774		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.12563181211291774 | validation: 0.09692951636814431]
	TIME [epoch: 13 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13022907125555022		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.13022907125555022 | validation: 0.10155769248817582]
	TIME [epoch: 13 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13364109116425854		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.13364109116425854 | validation: 0.0991711323506354]
	TIME [epoch: 13 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13143828766562002		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.13143828766562002 | validation: 0.097026830472386]
	TIME [epoch: 13 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136990935586469		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.136990935586469 | validation: 0.09033522749541607]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_1588.pth
	Model improved!!!
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13096438178393682		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.13096438178393682 | validation: 0.09446438655767408]
	TIME [epoch: 13 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13442775371551946		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.13442775371551946 | validation: 0.0882048028770122]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_1590.pth
	Model improved!!!
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13488478124400446		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.13488478124400446 | validation: 0.09876176685253667]
	TIME [epoch: 13 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133534893490685		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.133534893490685 | validation: 0.0951385045707729]
	TIME [epoch: 13 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13553056818868037		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.13553056818868037 | validation: 0.10104222550972852]
	TIME [epoch: 13 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12981111866640155		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.12981111866640155 | validation: 0.09654714787796649]
	TIME [epoch: 13 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13471597374120237		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.13471597374120237 | validation: 0.10401099388428049]
	TIME [epoch: 13 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13463308372921762		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.13463308372921762 | validation: 0.09510489477509028]
	TIME [epoch: 13 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424072824240631		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.1424072824240631 | validation: 0.1036618888795844]
	TIME [epoch: 13 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351660306730327		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.1351660306730327 | validation: 0.09807553550362624]
	TIME [epoch: 13 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351965568632485		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.1351965568632485 | validation: 0.10500096923800797]
	TIME [epoch: 12.9 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333818206416052		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.1333818206416052 | validation: 0.10615653613646718]
	TIME [epoch: 12.9 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12954812177924535		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.12954812177924535 | validation: 0.09494841553516738]
	TIME [epoch: 12.9 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312103504075042		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.1312103504075042 | validation: 0.09777618565576482]
	TIME [epoch: 13 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13303077085057646		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.13303077085057646 | validation: 0.10447379952472641]
	TIME [epoch: 12.9 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13462746052223043		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.13462746052223043 | validation: 0.11303000341399085]
	TIME [epoch: 12.9 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341402691168403		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.1341402691168403 | validation: 0.10024817793431552]
	TIME [epoch: 13 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13067570547511087		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.13067570547511087 | validation: 0.10135578098605336]
	TIME [epoch: 12.9 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13401809845842017		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.13401809845842017 | validation: 0.10874366343690955]
	TIME [epoch: 13 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13293468269933603		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.13293468269933603 | validation: 0.1092302958921389]
	TIME [epoch: 13 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408262961361893		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.1408262961361893 | validation: 0.11104027602121129]
	TIME [epoch: 13 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13356802963799086		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.13356802963799086 | validation: 0.10152605378485983]
	TIME [epoch: 13 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297529627097307		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.1297529627097307 | validation: 0.09791631953695783]
	TIME [epoch: 13 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13364440748210826		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.13364440748210826 | validation: 0.09634089411282382]
	TIME [epoch: 13 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13167925833803995		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.13167925833803995 | validation: 0.09944541792252658]
	TIME [epoch: 13 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13138435457188335		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.13138435457188335 | validation: 0.10224184384339434]
	TIME [epoch: 13 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13454848281273965		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.13454848281273965 | validation: 0.10152624442461364]
	TIME [epoch: 13 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343491055118384		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.1343491055118384 | validation: 0.10117076694461523]
	TIME [epoch: 13 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361296063032918		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.1361296063032918 | validation: 0.09369337830182134]
	TIME [epoch: 13 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13286230855698422		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.13286230855698422 | validation: 0.09695966473236066]
	TIME [epoch: 13 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12925518214692344		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.12925518214692344 | validation: 0.09083305642632115]
	TIME [epoch: 13 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259159415351469		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.1259159415351469 | validation: 0.1014895282682216]
	TIME [epoch: 13 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127598445603291		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.127598445603291 | validation: 0.09427785547983002]
	TIME [epoch: 13 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12867888841825753		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.12867888841825753 | validation: 0.0998303672207883]
	TIME [epoch: 13 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13552610968518283		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.13552610968518283 | validation: 0.0995953527867004]
	TIME [epoch: 13 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13308350385249332		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.13308350385249332 | validation: 0.10151245037331172]
	TIME [epoch: 13 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12897216639340137		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.12897216639340137 | validation: 0.0993107507866541]
	TIME [epoch: 13 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12743587944193208		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.12743587944193208 | validation: 0.10242640663910049]
	TIME [epoch: 13 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12714617632900746		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.12714617632900746 | validation: 0.09606916878536403]
	TIME [epoch: 13 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292054696267255		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.1292054696267255 | validation: 0.09434381220774722]
	TIME [epoch: 13 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12835134761312683		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.12835134761312683 | validation: 0.10280139774970343]
	TIME [epoch: 13 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327773398376471		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.1327773398376471 | validation: 0.09773629684747133]
	TIME [epoch: 13 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12745342558948305		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.12745342558948305 | validation: 0.10060129668344941]
	TIME [epoch: 13 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314136206670748		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.1314136206670748 | validation: 0.09745734939279142]
	TIME [epoch: 13 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337861293822044		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.1337861293822044 | validation: 0.09977243418506046]
	TIME [epoch: 13 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13261871058788471		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.13261871058788471 | validation: 0.10444782561633201]
	TIME [epoch: 13 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12685196625171902		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.12685196625171902 | validation: 0.10767274725185173]
	TIME [epoch: 13 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290125442191359		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.1290125442191359 | validation: 0.09299048576891263]
	TIME [epoch: 13 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13388957360373926		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.13388957360373926 | validation: 0.10088656296819515]
	TIME [epoch: 13 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13339008897905563		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.13339008897905563 | validation: 0.10768207484392363]
	TIME [epoch: 12.9 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13465386714252917		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.13465386714252917 | validation: 0.09706391138852752]
	TIME [epoch: 12.9 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12966654095864116		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.12966654095864116 | validation: 0.10058452805715218]
	TIME [epoch: 12.9 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323489709969407		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.1323489709969407 | validation: 0.10884719998308696]
	TIME [epoch: 13 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389404294327663		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.1389404294327663 | validation: 0.11653124964847568]
	TIME [epoch: 12.9 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13931197530319286		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.13931197530319286 | validation: 0.11289556654541562]
	TIME [epoch: 12.9 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13956389843962325		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.13956389843962325 | validation: 0.12081449281246431]
	TIME [epoch: 13 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13451345839572748		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.13451345839572748 | validation: 0.10717964022329966]
	TIME [epoch: 12.9 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12958006828461666		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.12958006828461666 | validation: 0.10029217564467524]
	TIME [epoch: 12.9 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12985380673734626		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.12985380673734626 | validation: 0.100885087189744]
	TIME [epoch: 13 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338015679166659		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.1338015679166659 | validation: 0.09942829993582081]
	TIME [epoch: 13 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13218814072954618		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.13218814072954618 | validation: 0.10046372369404777]
	TIME [epoch: 13 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12996025884659235		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.12996025884659235 | validation: 0.10014100551523505]
	TIME [epoch: 13 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12932377166642736		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.12932377166642736 | validation: 0.09666887894892401]
	TIME [epoch: 13 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12931765740490314		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.12931765740490314 | validation: 0.09452943397240265]
	TIME [epoch: 13 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13036286509262046		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.13036286509262046 | validation: 0.09670312588019724]
	TIME [epoch: 13 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13087288431562813		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.13087288431562813 | validation: 0.09488101161280872]
	TIME [epoch: 13 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12726552281504053		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.12726552281504053 | validation: 0.09905991992851869]
	TIME [epoch: 13 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337364365987762		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.1337364365987762 | validation: 0.10607215016649843]
	TIME [epoch: 13 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1288734935739173		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.1288734935739173 | validation: 0.10079149247972025]
	TIME [epoch: 13 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273558664465722		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.1273558664465722 | validation: 0.09201432652858055]
	TIME [epoch: 13 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12484707314529153		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.12484707314529153 | validation: 0.09547975570909958]
	TIME [epoch: 13 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316279418407037		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.1316279418407037 | validation: 0.09630722642218892]
	TIME [epoch: 13 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13452886584260423		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.13452886584260423 | validation: 0.10713717112999248]
	TIME [epoch: 13 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14250508254327698		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.14250508254327698 | validation: 0.10440004422984563]
	TIME [epoch: 13 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13905770579301147		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.13905770579301147 | validation: 0.1045601794100762]
	TIME [epoch: 13 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13337161413440313		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.13337161413440313 | validation: 0.10131781539891727]
	TIME [epoch: 13 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13911481448986032		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.13911481448986032 | validation: 0.10246440529561249]
	TIME [epoch: 13 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13831647942292097		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.13831647942292097 | validation: 0.09296082508322673]
	TIME [epoch: 13 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13623247432354885		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.13623247432354885 | validation: 0.09425614196309955]
	TIME [epoch: 13 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13417049078691715		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.13417049078691715 | validation: 0.10236610885767401]
	TIME [epoch: 13 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13220679641966568		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.13220679641966568 | validation: 0.10015924227789888]
	TIME [epoch: 13 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12886374833516198		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.12886374833516198 | validation: 0.09820947063556801]
	TIME [epoch: 13 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13151060610415138		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.13151060610415138 | validation: 0.09253730996141524]
	TIME [epoch: 13 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12950539959655868		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.12950539959655868 | validation: 0.0989041634184081]
	TIME [epoch: 13 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13826117145873207		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.13826117145873207 | validation: 0.09256788934280433]
	TIME [epoch: 13 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13824781922560164		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.13824781922560164 | validation: 0.09030614964701833]
	TIME [epoch: 13 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13130103183028596		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.13130103183028596 | validation: 0.09845506719978016]
	TIME [epoch: 13 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13044016062969127		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.13044016062969127 | validation: 0.10375527524243305]
	TIME [epoch: 13 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13125561398133828		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.13125561398133828 | validation: 0.09628203994387934]
	TIME [epoch: 13 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297305469661359		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.1297305469661359 | validation: 0.10152456836390986]
	TIME [epoch: 13 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12985661435775592		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.12985661435775592 | validation: 0.10248671712550733]
	TIME [epoch: 13 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13022567216371736		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.13022567216371736 | validation: 0.10344271248041573]
	TIME [epoch: 13 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13297335509362945		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.13297335509362945 | validation: 0.10823701550897451]
	TIME [epoch: 13 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13067060626493945		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.13067060626493945 | validation: 0.10059075873518697]
	TIME [epoch: 13 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13021346477166715		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.13021346477166715 | validation: 0.09455922253092515]
	TIME [epoch: 13 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12839775103644097		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.12839775103644097 | validation: 0.09493746169984058]
	TIME [epoch: 13 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318367665593061		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.1318367665593061 | validation: 0.105982557552799]
	TIME [epoch: 13 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12515672768808062		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.12515672768808062 | validation: 0.09878742360900145]
	TIME [epoch: 13 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13090062615618248		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.13090062615618248 | validation: 0.09568889919135255]
	TIME [epoch: 13 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13089414524812046		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.13089414524812046 | validation: 0.09851667705343094]
	TIME [epoch: 13 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310398557437991		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.1310398557437991 | validation: 0.10646640789238287]
	TIME [epoch: 13 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12855009136763845		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.12855009136763845 | validation: 0.10094604927707351]
	TIME [epoch: 13 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12945036822095404		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.12945036822095404 | validation: 0.09606205751002424]
	TIME [epoch: 13 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295165931261301		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.1295165931261301 | validation: 0.10085049962109613]
	TIME [epoch: 13 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12813707590061169		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.12813707590061169 | validation: 0.10096409843771534]
	TIME [epoch: 13 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13176784404980493		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.13176784404980493 | validation: 0.10622249022047399]
	TIME [epoch: 13 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307824208175833		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.1307824208175833 | validation: 0.1016625620910937]
	TIME [epoch: 13 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13319558884323485		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.13319558884323485 | validation: 0.1091455664215237]
	TIME [epoch: 13 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13235598946180677		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.13235598946180677 | validation: 0.0983926750080276]
	TIME [epoch: 13 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13140400453855378		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.13140400453855378 | validation: 0.09832209228784747]
	TIME [epoch: 13 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12604217952750066		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.12604217952750066 | validation: 0.10430068269892204]
	TIME [epoch: 13 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13142391602397666		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.13142391602397666 | validation: 0.1090279257128261]
	TIME [epoch: 13 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13284127795341236		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.13284127795341236 | validation: 0.10725563871243025]
	TIME [epoch: 13 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1366864786828341		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.1366864786828341 | validation: 0.108589643331471]
	TIME [epoch: 13 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1330438422130858		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.1330438422130858 | validation: 0.10533829798995718]
	TIME [epoch: 13 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12757274440916438		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.12757274440916438 | validation: 0.0991526684183927]
	TIME [epoch: 13 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129725766506987		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.129725766506987 | validation: 0.0997779766710401]
	TIME [epoch: 13 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13597123262654737		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.13597123262654737 | validation: 0.09377429080645264]
	TIME [epoch: 13 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13097930275122086		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.13097930275122086 | validation: 0.09911616584465742]
	TIME [epoch: 13 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12872849273399642		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.12872849273399642 | validation: 0.10219374824965004]
	TIME [epoch: 13 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12674622691582366		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.12674622691582366 | validation: 0.0996714734502065]
	TIME [epoch: 13 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13207109301879325		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.13207109301879325 | validation: 0.09235240402838894]
	TIME [epoch: 13 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12988304975021234		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.12988304975021234 | validation: 0.09603118784324406]
	TIME [epoch: 13 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12902519069066462		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.12902519069066462 | validation: 0.1015392326602038]
	TIME [epoch: 13 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301171333969724		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.1301171333969724 | validation: 0.09856230325966138]
	TIME [epoch: 13 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13065276989134664		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.13065276989134664 | validation: 0.0939494071326903]
	TIME [epoch: 13 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12749408938687296		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.12749408938687296 | validation: 0.09920932385982821]
	TIME [epoch: 13 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13125476900459107		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.13125476900459107 | validation: 0.1040283114750389]
	TIME [epoch: 13 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308960282055807		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.1308960282055807 | validation: 0.10735453294864482]
	TIME [epoch: 13 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12870499114898354		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.12870499114898354 | validation: 0.09912848013164141]
	TIME [epoch: 13 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12785207796055195		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.12785207796055195 | validation: 0.10690746270291056]
	TIME [epoch: 13 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12440538353471825		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.12440538353471825 | validation: 0.10638513443104618]
	TIME [epoch: 13 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1324675706303794		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.1324675706303794 | validation: 0.10716449752431968]
	TIME [epoch: 13 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13007078210287906		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.13007078210287906 | validation: 0.10357161439183221]
	TIME [epoch: 13 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132846576232468		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.132846576232468 | validation: 0.09489702982970419]
	TIME [epoch: 13 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13090365466657466		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.13090365466657466 | validation: 0.10539040425077514]
	TIME [epoch: 13 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309596991634004		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.1309596991634004 | validation: 0.10720050956712973]
	TIME [epoch: 13 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336836769189869		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.1336836769189869 | validation: 0.10451873985103571]
	TIME [epoch: 13 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13263134604526386		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.13263134604526386 | validation: 0.09897128142315496]
	TIME [epoch: 12.9 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13005806632143213		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.13005806632143213 | validation: 0.10374121280387388]
	TIME [epoch: 12.9 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13560506239540154		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.13560506239540154 | validation: 0.10471372888939588]
	TIME [epoch: 12.9 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13129733055047543		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.13129733055047543 | validation: 0.11347680851925276]
	TIME [epoch: 13 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13193931187430405		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.13193931187430405 | validation: 0.09491514494314326]
	TIME [epoch: 12.9 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1284924670525324		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.1284924670525324 | validation: 0.10561233877320465]
	TIME [epoch: 12.9 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13379010378274472		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.13379010378274472 | validation: 0.09322534959620547]
	TIME [epoch: 13 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12737826785776507		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.12737826785776507 | validation: 0.10265156822378224]
	TIME [epoch: 13 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12745070562349767		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.12745070562349767 | validation: 0.10741100104555913]
	TIME [epoch: 13 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1285499591375307		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.1285499591375307 | validation: 0.10521490777804658]
	TIME [epoch: 13 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129345201598087		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.129345201598087 | validation: 0.10071871018342131]
	TIME [epoch: 13 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12817187575624103		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.12817187575624103 | validation: 0.09363966648833116]
	TIME [epoch: 13 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317611132106347		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.1317611132106347 | validation: 0.1029196015928961]
	TIME [epoch: 13 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290406646861172		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.1290406646861172 | validation: 0.10434322195537821]
	TIME [epoch: 13 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309362995797382		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.1309362995797382 | validation: 0.09785469903444324]
	TIME [epoch: 13 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12877175609722558		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.12877175609722558 | validation: 0.09834389742103375]
	TIME [epoch: 13 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12573871505760154		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.12573871505760154 | validation: 0.10386731847279243]
	TIME [epoch: 13 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12893795801719365		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.12893795801719365 | validation: 0.0924558996249879]
	TIME [epoch: 13 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279449085659013		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.1279449085659013 | validation: 0.09988774447093528]
	TIME [epoch: 13 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12712447803707513		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.12712447803707513 | validation: 0.10257410720525321]
	TIME [epoch: 13 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309002872514533		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.1309002872514533 | validation: 0.0920460288044681]
	TIME [epoch: 13 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269894811587016		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.1269894811587016 | validation: 0.09276901146067626]
	TIME [epoch: 13 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12706643883360086		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.12706643883360086 | validation: 0.09611392617778565]
	TIME [epoch: 12.9 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12546998854744681		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.12546998854744681 | validation: 0.09250664043339146]
	TIME [epoch: 12.9 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12768418507987425		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.12768418507987425 | validation: 0.09456929577475083]
	TIME [epoch: 13 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332727407540278		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.1332727407540278 | validation: 0.09766883710192506]
	TIME [epoch: 12.9 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12885240703281198		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.12885240703281198 | validation: 0.09919023042927175]
	TIME [epoch: 12.9 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12806569123427344		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.12806569123427344 | validation: 0.0906961312276138]
	TIME [epoch: 13 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12596673484469845		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.12596673484469845 | validation: 0.10210015258833899]
	TIME [epoch: 12.9 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12898274069928575		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.12898274069928575 | validation: 0.10011542385965416]
	TIME [epoch: 12.9 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12645367953748962		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.12645367953748962 | validation: 0.10504265784738477]
	TIME [epoch: 12.9 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12938946408202062		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.12938946408202062 | validation: 0.10202250395502546]
	TIME [epoch: 13 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12737977873155415		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.12737977873155415 | validation: 0.10426063833765824]
	TIME [epoch: 12.9 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13001322210472474		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.13001322210472474 | validation: 0.12136974250235065]
	TIME [epoch: 12.9 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13719155645732528		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.13719155645732528 | validation: 0.10986180047847423]
	TIME [epoch: 12.9 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13420347918242467		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.13420347918242467 | validation: 0.11836020031465969]
	TIME [epoch: 13 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291645996963591		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.1291645996963591 | validation: 0.1004500456959198]
	TIME [epoch: 12.9 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12723464828461373		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.12723464828461373 | validation: 0.09959810132301909]
	TIME [epoch: 13 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12921914182034383		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.12921914182034383 | validation: 0.0940259537363771]
	TIME [epoch: 13 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274310437898443		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.1274310437898443 | validation: 0.09785451283676816]
	TIME [epoch: 13 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12644839697588223		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.12644839697588223 | validation: 0.10156815610993875]
	TIME [epoch: 13 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12986667436511343		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.12986667436511343 | validation: 0.10094151189760087]
	TIME [epoch: 13 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12775791621407417		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.12775791621407417 | validation: 0.10130102059932719]
	TIME [epoch: 13 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12760608778958216		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.12760608778958216 | validation: 0.09606931450562561]
	TIME [epoch: 13 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12398660686558433		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.12398660686558433 | validation: 0.09938612089182307]
	TIME [epoch: 13 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12738648560172464		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.12738648560172464 | validation: 0.10812133365774017]
	TIME [epoch: 13 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13123158333215734		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.13123158333215734 | validation: 0.10663779753874161]
	TIME [epoch: 13 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335980649511906		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.1335980649511906 | validation: 0.10440090671419333]
	TIME [epoch: 13 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12930005075537357		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.12930005075537357 | validation: 0.10237220791662381]
	TIME [epoch: 13 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12924447069501843		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.12924447069501843 | validation: 0.10369258186630342]
	TIME [epoch: 13 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12910599060382244		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.12910599060382244 | validation: 0.10193330448899826]
	TIME [epoch: 13 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12922153963427074		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.12922153963427074 | validation: 0.09769653991982899]
	TIME [epoch: 13 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12704564819712358		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.12704564819712358 | validation: 0.090014859432586]
	TIME [epoch: 13 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266761773210454		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.1266761773210454 | validation: 0.09140468951362951]
	TIME [epoch: 13 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13003578338306176		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.13003578338306176 | validation: 0.09671314375306922]
	TIME [epoch: 13 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12631528967411154		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.12631528967411154 | validation: 0.09622756176650815]
	TIME [epoch: 13 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12713894967895728		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.12713894967895728 | validation: 0.09482407929130038]
	TIME [epoch: 13 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328440294976424		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.1328440294976424 | validation: 0.10186878953676427]
	TIME [epoch: 13 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12028911841379475		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.12028911841379475 | validation: 0.09987953743242994]
	TIME [epoch: 13 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261541474154259		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.1261541474154259 | validation: 0.10626267992514307]
	TIME [epoch: 13 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12747545777781166		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.12747545777781166 | validation: 0.09569441218970352]
	TIME [epoch: 13 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12652902770629268		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.12652902770629268 | validation: 0.09857945645400122]
	TIME [epoch: 13 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282881812252547		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.1282881812252547 | validation: 0.10389919693278657]
	TIME [epoch: 13 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13134292336541697		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.13134292336541697 | validation: 0.10455294119583589]
	TIME [epoch: 13 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12970633398493775		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.12970633398493775 | validation: 0.10097400265050581]
	TIME [epoch: 12.9 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274834133885208		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.1274834133885208 | validation: 0.10204495542021152]
	TIME [epoch: 12.9 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12829967499463824		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.12829967499463824 | validation: 0.09686706880474207]
	TIME [epoch: 12.9 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128332945588896		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.128332945588896 | validation: 0.10181279930099141]
	TIME [epoch: 13 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12961021207584375		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.12961021207584375 | validation: 0.10500194211564245]
	TIME [epoch: 12.9 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12344368833579522		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.12344368833579522 | validation: 0.09806658976126156]
	TIME [epoch: 12.9 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12986733034410833		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.12986733034410833 | validation: 0.08691203621239658]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_1797.pth
	Model improved!!!
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12944163168868172		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.12944163168868172 | validation: 0.10180070192897434]
	TIME [epoch: 13 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13052378956965147		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.13052378956965147 | validation: 0.0949240713484669]
	TIME [epoch: 13 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12807241236259814		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.12807241236259814 | validation: 0.10702242470894077]
	TIME [epoch: 13 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12900985451278685		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.12900985451278685 | validation: 0.09615432381982814]
	TIME [epoch: 13 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12656555381374965		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.12656555381374965 | validation: 0.10323433275317756]
	TIME [epoch: 13 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13143078879291514		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.13143078879291514 | validation: 0.09941707404816102]
	TIME [epoch: 13 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308738988177391		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.1308738988177391 | validation: 0.09174785507522179]
	TIME [epoch: 13 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286851891636265		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.1286851891636265 | validation: 0.08798464410151162]
	TIME [epoch: 13 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304381467963371		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.1304381467963371 | validation: 0.09673099346096851]
	TIME [epoch: 13 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12888513022309023		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.12888513022309023 | validation: 0.09825129328850878]
	TIME [epoch: 13 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13155373609791943		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.13155373609791943 | validation: 0.09053656867465781]
	TIME [epoch: 13 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12792441682526004		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.12792441682526004 | validation: 0.09602712487067869]
	TIME [epoch: 13 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13048326850915593		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.13048326850915593 | validation: 0.10005816080501745]
	TIME [epoch: 13 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13111148032384018		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.13111148032384018 | validation: 0.10020111085509195]
	TIME [epoch: 13 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283369197529687		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.1283369197529687 | validation: 0.09918302138842279]
	TIME [epoch: 13 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129352999343451		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.129352999343451 | validation: 0.10208729335357135]
	TIME [epoch: 13 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13089313227016175		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.13089313227016175 | validation: 0.09140727315769712]
	TIME [epoch: 13 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12799512974606636		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.12799512974606636 | validation: 0.10996779975905716]
	TIME [epoch: 13 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12666475633822902		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.12666475633822902 | validation: 0.09704142071981597]
	TIME [epoch: 13 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12666782225508344		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.12666782225508344 | validation: 0.10116206879042264]
	TIME [epoch: 13 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12932007240288917		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.12932007240288917 | validation: 0.09214770308761087]
	TIME [epoch: 13 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12710889959147229		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.12710889959147229 | validation: 0.09586382076288537]
	TIME [epoch: 13 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260483850539947		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.1260483850539947 | validation: 0.09974964529777516]
	TIME [epoch: 13 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1236322083176595		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.1236322083176595 | validation: 0.10437606463776312]
	TIME [epoch: 13 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12733363260731528		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.12733363260731528 | validation: 0.10146408480482068]
	TIME [epoch: 13 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12807758376400388		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.12807758376400388 | validation: 0.0909480604165021]
	TIME [epoch: 13 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12722825421736406		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.12722825421736406 | validation: 0.09905050662469084]
	TIME [epoch: 13 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12498942107762805		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.12498942107762805 | validation: 0.09413401985848507]
	TIME [epoch: 13 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12854507558266912		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.12854507558266912 | validation: 0.09250854621298768]
	TIME [epoch: 13 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625299539805807		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.12625299539805807 | validation: 0.10628727150310238]
	TIME [epoch: 13 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12548360022180896		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.12548360022180896 | validation: 0.10239970347790404]
	TIME [epoch: 13 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267436956949045		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.1267436956949045 | validation: 0.089916458565423]
	TIME [epoch: 13 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304322162963233		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.1304322162963233 | validation: 0.0956979093635969]
	TIME [epoch: 13 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12686702450526582		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.12686702450526582 | validation: 0.10125523693541418]
	TIME [epoch: 13 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12672420924891697		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.12672420924891697 | validation: 0.08773747802440622]
	TIME [epoch: 13 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12484312434829556		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.12484312434829556 | validation: 0.09312676361452685]
	TIME [epoch: 13 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276583062056513		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.1276583062056513 | validation: 0.0883154675004]
	TIME [epoch: 13 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12909091563923691		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.12909091563923691 | validation: 0.09709758159697476]
	TIME [epoch: 13 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129103139028068		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.129103139028068 | validation: 0.09535366726964924]
	TIME [epoch: 13 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12347203038146988		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.12347203038146988 | validation: 0.09589474901565227]
	TIME [epoch: 13 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259540497985892		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.1259540497985892 | validation: 0.09360364452704553]
	TIME [epoch: 13 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12815668857798174		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.12815668857798174 | validation: 0.10023372159454223]
	TIME [epoch: 13 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12572003697155001		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.12572003697155001 | validation: 0.0967130282086273]
	TIME [epoch: 13 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12865945060335626		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.12865945060335626 | validation: 0.1067948803358924]
	TIME [epoch: 13 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12573135365625593		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.12573135365625593 | validation: 0.0950067194152433]
	TIME [epoch: 13 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292496570230879		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.1292496570230879 | validation: 0.09155280404539565]
	TIME [epoch: 13 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129600383405664		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.129600383405664 | validation: 0.10615243559780904]
	TIME [epoch: 12.9 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12853928387592722		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.12853928387592722 | validation: 0.09292402828999367]
	TIME [epoch: 12.9 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12800850716739218		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.12800850716739218 | validation: 0.09475643614811212]
	TIME [epoch: 12.9 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12689857160436596		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.12689857160436596 | validation: 0.0986773263038922]
	TIME [epoch: 13 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289656800996977		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.1289656800996977 | validation: 0.09553446579853933]
	TIME [epoch: 12.9 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293226992962536		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.1293226992962536 | validation: 0.09688088853663228]
	TIME [epoch: 12.9 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13267225588154072		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.13267225588154072 | validation: 0.08913937665877597]
	TIME [epoch: 13 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12894622101975178		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.12894622101975178 | validation: 0.09924324957252026]
	TIME [epoch: 12.9 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12293588357911019		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.12293588357911019 | validation: 0.09148856714093155]
	TIME [epoch: 12.9 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12585733507097857		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.12585733507097857 | validation: 0.0997932525025489]
	TIME [epoch: 13 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270162231201856		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.1270162231201856 | validation: 0.10142397011884263]
	TIME [epoch: 13 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13169797698128693		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.13169797698128693 | validation: 0.09393391429444309]
	TIME [epoch: 13 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13041125162535616		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.13041125162535616 | validation: 0.097636284438859]
	TIME [epoch: 13 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126898365453494		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.126898365453494 | validation: 0.10291926914301676]
	TIME [epoch: 13 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277764898557164		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.1277764898557164 | validation: 0.1039651349312156]
	TIME [epoch: 13 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12530226600020442		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.12530226600020442 | validation: 0.09016834487805037]
	TIME [epoch: 13 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12910307419576164		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.12910307419576164 | validation: 0.09815223850649923]
	TIME [epoch: 13 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12490585809675728		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.12490585809675728 | validation: 0.09871436907162288]
	TIME [epoch: 13 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283576886821547		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.1283576886821547 | validation: 0.09885918916518581]
	TIME [epoch: 13 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12677902884092604		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.12677902884092604 | validation: 0.10324486658235334]
	TIME [epoch: 13 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13089234163272215		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.13089234163272215 | validation: 0.09756159929585329]
	TIME [epoch: 13 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297764398522942		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.1297764398522942 | validation: 0.10655883274818827]
	TIME [epoch: 13 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266903213061395		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.1266903213061395 | validation: 0.09015354727318242]
	TIME [epoch: 13 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13028440851564507		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.13028440851564507 | validation: 0.10339355433879195]
	TIME [epoch: 13 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12654221665565749		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.12654221665565749 | validation: 0.09222313135209521]
	TIME [epoch: 13 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12819494864962622		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.12819494864962622 | validation: 0.09733030122850668]
	TIME [epoch: 13 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128056078969881		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.128056078969881 | validation: 0.09885092504050906]
	TIME [epoch: 13 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12800715481332467		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.12800715481332467 | validation: 0.08911164332161298]
	TIME [epoch: 13 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13254005390093063		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.13254005390093063 | validation: 0.09322178695089274]
	TIME [epoch: 13 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12758974934189432		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.12758974934189432 | validation: 0.09727890783014682]
	TIME [epoch: 13 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12978132679251728		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.12978132679251728 | validation: 0.10397960395860899]
	TIME [epoch: 13 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13061373173135662		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.13061373173135662 | validation: 0.09417079711783592]
	TIME [epoch: 13 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12822249703098237		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.12822249703098237 | validation: 0.09377433849197753]
	TIME [epoch: 13 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13139923500200737		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.13139923500200737 | validation: 0.09317958247765736]
	TIME [epoch: 12.9 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13076285644989571		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.13076285644989571 | validation: 0.09320939612360533]
	TIME [epoch: 12.9 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12685712368442748		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.12685712368442748 | validation: 0.09301863456836428]
	TIME [epoch: 13 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12867298143940137		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.12867298143940137 | validation: 0.09834505505277397]
	TIME [epoch: 12.9 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12750331816381963		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.12750331816381963 | validation: 0.10382688479509518]
	TIME [epoch: 13 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13008030960284653		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.13008030960284653 | validation: 0.09707424773785739]
	TIME [epoch: 13 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12854432352360323		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.12854432352360323 | validation: 0.09907187319011733]
	TIME [epoch: 13 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13319504661799003		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.13319504661799003 | validation: 0.09394359321959758]
	TIME [epoch: 13 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13037414537943004		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.13037414537943004 | validation: 0.09686097263409113]
	TIME [epoch: 13 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282664168483226		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.1282664168483226 | validation: 0.10052194427992898]
	TIME [epoch: 13 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12416408774393513		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.12416408774393513 | validation: 0.09896181787283101]
	TIME [epoch: 13 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13203945656578878		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.13203945656578878 | validation: 0.09088021230919684]
	TIME [epoch: 13 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13257992247420958		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.13257992247420958 | validation: 0.10018582114600619]
	TIME [epoch: 13 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13019809561309864		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.13019809561309864 | validation: 0.09939854788852168]
	TIME [epoch: 13 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12478070735576877		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.12478070735576877 | validation: 0.10197216066242805]
	TIME [epoch: 13 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12941327156347682		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.12941327156347682 | validation: 0.09752661913992051]
	TIME [epoch: 13 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12897220983395263		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.12897220983395263 | validation: 0.09511096231526694]
	TIME [epoch: 13 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12832874164106411		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.12832874164106411 | validation: 0.09043328933577995]
	TIME [epoch: 12.9 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12369769701319401		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.12369769701319401 | validation: 0.08587262065726224]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_1895.pth
	Model improved!!!
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283182880979823		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.1283182880979823 | validation: 0.10641751053596657]
	TIME [epoch: 12.9 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12690004971617297		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.12690004971617297 | validation: 0.09690538736636306]
	TIME [epoch: 13 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12969747449191496		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.12969747449191496 | validation: 0.10283240982636394]
	TIME [epoch: 12.9 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129942801879155		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.129942801879155 | validation: 0.0962070328159531]
	TIME [epoch: 12.9 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12742900690042652		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.12742900690042652 | validation: 0.09407967652703413]
	TIME [epoch: 13 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12734385392842973		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.12734385392842973 | validation: 0.09640637448243851]
	TIME [epoch: 12.9 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12536582858162187		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.12536582858162187 | validation: 0.09727032058318912]
	TIME [epoch: 13 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13173801094184212		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.13173801094184212 | validation: 0.09580930502878143]
	TIME [epoch: 13 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12802848246185594		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.12802848246185594 | validation: 0.09791851415751637]
	TIME [epoch: 13 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291033365445079		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.1291033365445079 | validation: 0.09869019206030637]
	TIME [epoch: 13 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12359987551250046		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.12359987551250046 | validation: 0.09152852833935696]
	TIME [epoch: 13 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12211165594616358		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.12211165594616358 | validation: 0.10174687348811609]
	TIME [epoch: 13 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12708752893358016		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.12708752893358016 | validation: 0.0881397838164121]
	TIME [epoch: 13 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12514985436285317		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.12514985436285317 | validation: 0.11051289390554057]
	TIME [epoch: 13 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12192572678281893		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.12192572678281893 | validation: 0.09326205140917418]
	TIME [epoch: 13 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13043057292790136		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.13043057292790136 | validation: 0.1008576803797983]
	TIME [epoch: 13 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12996810785698032		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.12996810785698032 | validation: 0.10150101441491899]
	TIME [epoch: 13 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12799817404165084		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.12799817404165084 | validation: 0.09833163844928439]
	TIME [epoch: 13 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293148852511572		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.1293148852511572 | validation: 0.09195079974401446]
	TIME [epoch: 13 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295663069489169		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.1295663069489169 | validation: 0.09488811771829073]
	TIME [epoch: 13 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12561043873875652		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.12561043873875652 | validation: 0.10262193624732145]
	TIME [epoch: 13 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128535970671186		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.128535970671186 | validation: 0.09088221836364412]
	TIME [epoch: 13 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12740774130334925		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.12740774130334925 | validation: 0.09549906664308715]
	TIME [epoch: 13 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12795351524229753		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.12795351524229753 | validation: 0.09084769437389575]
	TIME [epoch: 13 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12883781895633478		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.12883781895633478 | validation: 0.09286439050042022]
	TIME [epoch: 13 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126744192264642		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.126744192264642 | validation: 0.09365270925728156]
	TIME [epoch: 13 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12912261236022102		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.12912261236022102 | validation: 0.09056731260982467]
	TIME [epoch: 13 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12736750653812004		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.12736750653812004 | validation: 0.10269322534176166]
	TIME [epoch: 13 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13000379440011864		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.13000379440011864 | validation: 0.09867861815990221]
	TIME [epoch: 13 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12509018658077256		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.12509018658077256 | validation: 0.08928464439834938]
	TIME [epoch: 13 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12385559570594956		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.12385559570594956 | validation: 0.09334808139868236]
	TIME [epoch: 13 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12929951777202892		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.12929951777202892 | validation: 0.09430040028780086]
	TIME [epoch: 13 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12706395714757796		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.12706395714757796 | validation: 0.0946866103170208]
	TIME [epoch: 13 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266436007799665		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.1266436007799665 | validation: 0.10139427352916613]
	TIME [epoch: 13 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262594069806669		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.1262594069806669 | validation: 0.10323849310476621]
	TIME [epoch: 13 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12891521868705108		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.12891521868705108 | validation: 0.08901521625525]
	TIME [epoch: 13 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13042300482626112		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.13042300482626112 | validation: 0.08806239948866022]
	TIME [epoch: 13 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12361863777637169		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.12361863777637169 | validation: 0.09987802983569614]
	TIME [epoch: 13 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279491917031589		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.1279491917031589 | validation: 0.09254446541266088]
	TIME [epoch: 13 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12633563566524766		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.12633563566524766 | validation: 0.09316117256406019]
	TIME [epoch: 13 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12923584070279048		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.12923584070279048 | validation: 0.09733899619030256]
	TIME [epoch: 13 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12493359947270445		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.12493359947270445 | validation: 0.09976559866732977]
	TIME [epoch: 13 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126279163075877		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.126279163075877 | validation: 0.09893703796814958]
	TIME [epoch: 13 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13207134677949617		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.13207134677949617 | validation: 0.09902798791002869]
	TIME [epoch: 13 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1231555541207722		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.1231555541207722 | validation: 0.09268530374935181]
	TIME [epoch: 13 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286644706601859		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.1286644706601859 | validation: 0.09103923721979988]
	TIME [epoch: 13 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12319959013894707		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.12319959013894707 | validation: 0.09850151699179044]
	TIME [epoch: 13 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12480895219308338		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.12480895219308338 | validation: 0.099966102599755]
	TIME [epoch: 13 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12780953654396504		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.12780953654396504 | validation: 0.09757310004850583]
	TIME [epoch: 13 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12740541934635594		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.12740541934635594 | validation: 0.10074682615389918]
	TIME [epoch: 13 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12467056570211096		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.12467056570211096 | validation: 0.09697813753083352]
	TIME [epoch: 13 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12766167817470417		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.12766167817470417 | validation: 0.10067004578401285]
	TIME [epoch: 13 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275414866742543		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.1275414866742543 | validation: 0.09910862911458289]
	TIME [epoch: 13 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12600563089962435		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.12600563089962435 | validation: 0.09442486185301324]
	TIME [epoch: 13 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264982004761238		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.1264982004761238 | validation: 0.09861105585192409]
	TIME [epoch: 13 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291812193076443		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.1291812193076443 | validation: 0.09405017728190357]
	TIME [epoch: 13 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12995825998706545		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.12995825998706545 | validation: 0.09807476750726057]
	TIME [epoch: 13 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255559930497135		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.1255559930497135 | validation: 0.09316147163579881]
	TIME [epoch: 13 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269806436501094		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.1269806436501094 | validation: 0.09582275295747643]
	TIME [epoch: 13 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12633698144155156		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.12633698144155156 | validation: 0.09720457877236222]
	TIME [epoch: 13 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12779084749702002		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.12779084749702002 | validation: 0.10080637703734717]
	TIME [epoch: 13 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12944702294286675		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.12944702294286675 | validation: 0.1027682168360829]
	TIME [epoch: 13 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270779982887451		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.1270779982887451 | validation: 0.1088521317480322]
	TIME [epoch: 13 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12901827420519896		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.12901827420519896 | validation: 0.09608300616793855]
	TIME [epoch: 13 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13078833494388403		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.13078833494388403 | validation: 0.10190728177072181]
	TIME [epoch: 13 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12634100675284043		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.12634100675284043 | validation: 0.09161711788038102]
	TIME [epoch: 13 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287759003600077		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.1287759003600077 | validation: 0.10602702347278137]
	TIME [epoch: 13 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12692282243182682		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.12692282243182682 | validation: 0.09951389521540599]
	TIME [epoch: 13 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12714404914051397		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.12714404914051397 | validation: 0.0973916388271858]
	TIME [epoch: 13 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12731825416750153		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.12731825416750153 | validation: 0.10304080738746395]
	TIME [epoch: 13 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254633388784458		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.1254633388784458 | validation: 0.09998055265474819]
	TIME [epoch: 13 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12819716531990727		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.12819716531990727 | validation: 0.09921330818125242]
	TIME [epoch: 13 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11926853852541627		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.11926853852541627 | validation: 0.10550050064973548]
	TIME [epoch: 13 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304363706846909		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.1304363706846909 | validation: 0.09787294783888831]
	TIME [epoch: 13 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272263680140305		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.1272263680140305 | validation: 0.09602907608485696]
	TIME [epoch: 13 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12751025982533684		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.12751025982533684 | validation: 0.09975821118707433]
	TIME [epoch: 13 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12850961809876604		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.12850961809876604 | validation: 0.10029426327116386]
	TIME [epoch: 13 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12785135456250787		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.12785135456250787 | validation: 0.09525029366628672]
	TIME [epoch: 13 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12512156231689917		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.12512156231689917 | validation: 0.09620145688100007]
	TIME [epoch: 13 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12810055114769583		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.12810055114769583 | validation: 0.09763379148176425]
	TIME [epoch: 13 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12689690500665923		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.12689690500665923 | validation: 0.10070454539164743]
	TIME [epoch: 13 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12848310809312022		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.12848310809312022 | validation: 0.09402088225189655]
	TIME [epoch: 13 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12608193827253888		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.12608193827253888 | validation: 0.09437471905494008]
	TIME [epoch: 13 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12485472036144865		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.12485472036144865 | validation: 0.09333181554947599]
	TIME [epoch: 13 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12695216610929028		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.12695216610929028 | validation: 0.09970307892828872]
	TIME [epoch: 13 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266392360695571		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.1266392360695571 | validation: 0.09965862982310786]
	TIME [epoch: 13 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264993610310819		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.1264993610310819 | validation: 0.10099291502078703]
	TIME [epoch: 13 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267378850350973		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.1267378850350973 | validation: 0.09270104852973368]
	TIME [epoch: 13 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12594894487184824		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.12594894487184824 | validation: 0.08487570999729217]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240310_051403/states/model_tr_study204_1984.pth
	Model improved!!!
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12402525976787382		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.12402525976787382 | validation: 0.09911780288516255]
	TIME [epoch: 13 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12789513772543193		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.12789513772543193 | validation: 0.09849366437688983]
	TIME [epoch: 13 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12855755180212217		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.12855755180212217 | validation: 0.09797364566928274]
	TIME [epoch: 13 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128813226272407		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.128813226272407 | validation: 0.09943963930232258]
	TIME [epoch: 13 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254621486160219		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.1254621486160219 | validation: 0.10134866122379721]
	TIME [epoch: 13 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271072122432821		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.1271072122432821 | validation: 0.0954927521637648]
	TIME [epoch: 13 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269789523032515		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.1269789523032515 | validation: 0.09524389270878078]
	TIME [epoch: 13 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12573392742235281		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.12573392742235281 | validation: 0.09763120715734981]
	TIME [epoch: 13 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12641542201031838		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.12641542201031838 | validation: 0.10013342916690529]
	TIME [epoch: 13 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1245931275688287		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.1245931275688287 | validation: 0.0971550058346562]
	TIME [epoch: 13 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13005109115039754		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.13005109115039754 | validation: 0.09260817829538992]
	TIME [epoch: 13 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12943108019137453		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.12943108019137453 | validation: 0.10481826245674601]
	TIME [epoch: 13 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12660872331610523		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.12660872331610523 | validation: 0.10360330739943435]
	TIME [epoch: 13 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12566082475516382		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.12566082475516382 | validation: 0.0938007200911964]
	TIME [epoch: 13 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268637765977401		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.1268637765977401 | validation: 0.10139328087062754]
	TIME [epoch: 13 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12727743213082438		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.12727743213082438 | validation: 0.10118491516293825]
	TIME [epoch: 13 sec]
Finished training in 26346.271 seconds.
