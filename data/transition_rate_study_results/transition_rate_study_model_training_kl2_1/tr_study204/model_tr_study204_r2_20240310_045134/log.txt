Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r2', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1742024176

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.492836056553232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.492836056553232 | validation: 11.326508937783633]
	TIME [epoch: 98.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.584598353344813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.584598353344813 | validation: 9.5110471560741]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.49983322117113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.49983322117113 | validation: 8.82389354385731]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.634320923674794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.634320923674794 | validation: 10.036981928635383]
	TIME [epoch: 11.6 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.294764697166796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.294764697166796 | validation: 7.6069271185631155]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.5943220500130355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.5943220500130355 | validation: 6.617016153434885]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2310408715955905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2310408715955905 | validation: 5.690388637940189]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.035118720495695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.035118720495695 | validation: 4.391985307999322]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1957157811766255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1957157811766255 | validation: 3.864462418617344]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.513239315914879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.513239315914879 | validation: 4.093742275962816]
	TIME [epoch: 11.5 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8111690582223074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8111690582223074 | validation: 3.9672646953037005]
	TIME [epoch: 11.6 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.412591997453788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.412591997453788 | validation: 4.081154500205328]
	TIME [epoch: 11.5 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489923786586144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.489923786586144 | validation: 3.4877592952039174]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.670887845023387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.670887845023387 | validation: 3.9784467128067083]
	TIME [epoch: 11.6 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468226003987602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.468226003987602 | validation: 3.92510981454803]
	TIME [epoch: 11.6 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2541587544147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2541587544147 | validation: 3.5349772744967023]
	TIME [epoch: 11.6 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485406443572467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.485406443572467 | validation: 3.338745935085059]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.147861675722364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.147861675722364 | validation: 3.7819455211299497]
	TIME [epoch: 11.6 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.047877285029362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.047877285029362 | validation: 3.8571239683719614]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.945958770664265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.945958770664265 | validation: 3.4967377344771977]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6414057281553527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6414057281553527 | validation: 3.145844819182503]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.888963735637359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.888963735637359 | validation: 3.3574241746021514]
	TIME [epoch: 11.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.436298750807416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.436298750807416 | validation: 4.493328150310327]
	TIME [epoch: 11.5 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.748319433848321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.748319433848321 | validation: 3.173534285470672]
	TIME [epoch: 11.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.654598259984457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.654598259984457 | validation: 2.2886486684341856]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1054156624552753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1054156624552753 | validation: 2.37903066915957]
	TIME [epoch: 11.5 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.251218652415435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.251218652415435 | validation: 1.9073067274368714]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3588954203900774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3588954203900774 | validation: 2.178049804926334]
	TIME [epoch: 11.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9594405732836337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9594405732836337 | validation: 2.8135473131858966]
	TIME [epoch: 11.5 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.412963746263564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.412963746263564 | validation: 1.828003794363414]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1449669112826255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1449669112826255 | validation: 1.983846785903669]
	TIME [epoch: 11.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8838386124823776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8838386124823776 | validation: 2.616075935816475]
	TIME [epoch: 11.5 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1195957715773366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1195957715773366 | validation: 1.9813432426031676]
	TIME [epoch: 11.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7519801776736843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7519801776736843 | validation: 2.396839400047658]
	TIME [epoch: 11.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0949977332840395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0949977332840395 | validation: 2.1120128564021106]
	TIME [epoch: 11.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.848442530301826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.848442530301826 | validation: 2.110490122721702]
	TIME [epoch: 11.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2694310611283233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2694310611283233 | validation: 1.5698472406960409]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.897681136306456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.897681136306456 | validation: 1.7898499841849382]
	TIME [epoch: 11.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0056975261848233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0056975261848233 | validation: 2.0377051087235794]
	TIME [epoch: 11.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8887426200291983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8887426200291983 | validation: 1.7471265103772908]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8285176836179193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8285176836179193 | validation: 1.584654852111909]
	TIME [epoch: 11.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7807475607977055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7807475607977055 | validation: 1.7792100397964594]
	TIME [epoch: 11.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.552663483001244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.552663483001244 | validation: 2.9185404840964053]
	TIME [epoch: 11.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.735311840207939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.735311840207939 | validation: 3.2090776748914056]
	TIME [epoch: 11.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4216321292536787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4216321292536787 | validation: 1.997441274890877]
	TIME [epoch: 11.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7523277916741384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7523277916741384 | validation: 2.064517330576171]
	TIME [epoch: 11.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6094115916430733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6094115916430733 | validation: 1.552454056440268]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.918926405296631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.918926405296631 | validation: 2.094315132389272]
	TIME [epoch: 11.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8357297265885797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8357297265885797 | validation: 1.4860746751058447]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.356036972894164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.356036972894164 | validation: 1.8030784931001649]
	TIME [epoch: 11.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.814727695112915		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.814727695112915 | validation: 2.0605644677880917]
	TIME [epoch: 11.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7013943838198213		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.7013943838198213 | validation: 2.044962872257283]
	TIME [epoch: 11.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.675182771486458		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.675182771486458 | validation: 1.6858610188454373]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5136531944885476		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.5136531944885476 | validation: 1.8012839241911203]
	TIME [epoch: 11.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.646169189591458		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.646169189591458 | validation: 2.4614496892919577]
	TIME [epoch: 11.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.872676090284317		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.872676090284317 | validation: 1.4414094203008028]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.917237691752315		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.917237691752315 | validation: 1.8396623469057602]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7952869013693196		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.7952869013693196 | validation: 1.6926453446816436]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6767399016392193		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.6767399016392193 | validation: 1.562934171664923]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5297777114385736		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.5297777114385736 | validation: 1.85514574488198]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5417556953075735		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.5417556953075735 | validation: 2.6206817115875833]
	TIME [epoch: 11.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7012175573065864		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.7012175573065864 | validation: 1.9898628587528264]
	TIME [epoch: 11.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.492885265451452		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.492885265451452 | validation: 1.5692568909036104]
	TIME [epoch: 11.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.841172071918648		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.841172071918648 | validation: 1.6913760568198655]
	TIME [epoch: 11.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5685013009715667		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.5685013009715667 | validation: 1.4557406093841365]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6382405607896295		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.6382405607896295 | validation: 1.598604820246466]
	TIME [epoch: 11.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3564295591725424		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.3564295591725424 | validation: 1.7593678655358904]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.502099700353538		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.502099700353538 | validation: 2.459497760446176]
	TIME [epoch: 11.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5737809192219663		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.5737809192219663 | validation: 2.25557438040892]
	TIME [epoch: 11.5 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4563579747152584		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.4563579747152584 | validation: 2.523189965943188]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.623513877060245		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.623513877060245 | validation: 1.576095153494431]
	TIME [epoch: 11.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.476824770007594		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.476824770007594 | validation: 1.3969471206782482]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.566919559577652		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.566919559577652 | validation: 1.4809664564670235]
	TIME [epoch: 11.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.461055430841607		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.461055430841607 | validation: 1.5717528315584646]
	TIME [epoch: 11.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.48890263467628		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.48890263467628 | validation: 1.6619656337618234]
	TIME [epoch: 11.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.478979490040271		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.478979490040271 | validation: 1.6995626990324981]
	TIME [epoch: 11.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.402371162482435		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.402371162482435 | validation: 1.948979466701042]
	TIME [epoch: 11.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5296300556222633		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.5296300556222633 | validation: 1.5029925142694465]
	TIME [epoch: 11.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4574974589154395		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.4574974589154395 | validation: 1.4589689905612904]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.379666011616654		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.379666011616654 | validation: 1.3444565705633602]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5165410296945625		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.5165410296945625 | validation: 1.3057393494005856]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.165159028639377		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.165159028639377 | validation: 2.0447023311541064]
	TIME [epoch: 11.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4780135890910824		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.4780135890910824 | validation: 1.6040185514967074]
	TIME [epoch: 11.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3976738718406247		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.3976738718406247 | validation: 1.3974427547670925]
	TIME [epoch: 11.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.420828291054253		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.420828291054253 | validation: 1.395510198519197]
	TIME [epoch: 11.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268601865132095		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.268601865132095 | validation: 1.943842978547106]
	TIME [epoch: 11.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6200440140203334		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.6200440140203334 | validation: 1.819643465226954]
	TIME [epoch: 11.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4585900191538532		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.4585900191538532 | validation: 1.7098895294035805]
	TIME [epoch: 11.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4405468714147647		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.4405468714147647 | validation: 1.3462214843403149]
	TIME [epoch: 11.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4426874179126354		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.4426874179126354 | validation: 1.9444154899375372]
	TIME [epoch: 11.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.429338978849196		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.429338978849196 | validation: 1.3585923371169182]
	TIME [epoch: 11.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3932914992782526		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.3932914992782526 | validation: 1.3764342332225905]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275084415853241		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.275084415853241 | validation: 3.0658713124707866]
	TIME [epoch: 11.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8100661168253307		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.8100661168253307 | validation: 2.465174602625043]
	TIME [epoch: 11.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6096994016202544		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.6096994016202544 | validation: 1.5564197633903336]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3212940598029626		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.3212940598029626 | validation: 1.3569291643068966]
	TIME [epoch: 11.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.456844578787962		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.456844578787962 | validation: 1.5500745067218844]
	TIME [epoch: 11.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.364242580951009		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.364242580951009 | validation: 1.5799286980486562]
	TIME [epoch: 11.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4294989613417264		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.4294989613417264 | validation: 1.2923096922265291]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.360834636320284		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.360834636320284 | validation: 1.435153934550522]
	TIME [epoch: 11.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.368226839136326		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.368226839136326 | validation: 1.3081745465984849]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2202226805757523		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.2202226805757523 | validation: 1.463867498408952]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.350244601712687		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.350244601712687 | validation: 1.7183849101999165]
	TIME [epoch: 11.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3154473619416134		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.3154473619416134 | validation: 1.495601373354886]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.421386715257131		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.421386715257131 | validation: 1.41163253796595]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.428144452083783		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.428144452083783 | validation: 1.6181422412941815]
	TIME [epoch: 11.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2457713528863166		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.2457713528863166 | validation: 1.6538716860755949]
	TIME [epoch: 11.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3861017964101845		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.3861017964101845 | validation: 1.6227381825225258]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3761227986455165		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.3761227986455165 | validation: 1.2969956921049954]
	TIME [epoch: 11.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277571764035235		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.277571764035235 | validation: 1.3347313449217473]
	TIME [epoch: 11.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3233887049777047		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.3233887049777047 | validation: 1.3673875724671904]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.173402248846371		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.173402248846371 | validation: 1.825975642515805]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5196807866548436		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.5196807866548436 | validation: 1.3565674721064165]
	TIME [epoch: 11.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2644181506458714		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.2644181506458714 | validation: 1.4301765143279075]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.241235525567917		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.241235525567917 | validation: 1.6267780753864234]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4232121130372435		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.4232121130372435 | validation: 1.6422046373657007]
	TIME [epoch: 11.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2753835223547623		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.2753835223547623 | validation: 1.468017114683717]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2888326933632457		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.2888326933632457 | validation: 1.6762828609321891]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.47500651389072		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.47500651389072 | validation: 1.3954298757361954]
	TIME [epoch: 11.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2845315356584703		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.2845315356584703 | validation: 1.1999610508527587]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.406616333844348		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.406616333844348 | validation: 1.5130223804722835]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3363500458173005		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.3363500458173005 | validation: 1.2689215823568167]
	TIME [epoch: 11.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2967181410802784		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.2967181410802784 | validation: 1.6889828157877458]
	TIME [epoch: 11.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305880405103749		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.305880405103749 | validation: 1.341095163557563]
	TIME [epoch: 11.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.365814783256953		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.365814783256953 | validation: 1.9136428775347025]
	TIME [epoch: 11.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2902873083645674		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.2902873083645674 | validation: 1.3878291718543907]
	TIME [epoch: 11.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3346442984447613		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.3346442984447613 | validation: 1.240875689872119]
	TIME [epoch: 11.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2595815174212057		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.2595815174212057 | validation: 1.2058536828529323]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.366664800997796		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.366664800997796 | validation: 1.3037911390354675]
	TIME [epoch: 11.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305050971514513		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.305050971514513 | validation: 1.3874629782470354]
	TIME [epoch: 11.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3507103520339716		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.3507103520339716 | validation: 1.374082434171004]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3612754990844977		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.3612754990844977 | validation: 1.703927793388474]
	TIME [epoch: 11.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2519246238141752		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.2519246238141752 | validation: 1.2586293752734041]
	TIME [epoch: 11.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2125582018412997		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.2125582018412997 | validation: 2.163916205560517]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318081138058867		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.318081138058867 | validation: 1.6585313538199244]
	TIME [epoch: 11.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2630355163881735		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.2630355163881735 | validation: 1.265600813200504]
	TIME [epoch: 11.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.343333961176333		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.343333961176333 | validation: 1.2396547388506538]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.222571426144872		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.222571426144872 | validation: 1.3541637037462368]
	TIME [epoch: 11.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5194665020095766		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.5194665020095766 | validation: 1.317930351932756]
	TIME [epoch: 11.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3062848247548797		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.3062848247548797 | validation: 1.2212465875105518]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.238057575990513		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.238057575990513 | validation: 1.3488684655158192]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3380515388552348		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.3380515388552348 | validation: 1.4140774995808483]
	TIME [epoch: 11.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3049481181380043		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.3049481181380043 | validation: 1.3726951427126586]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3189333458940684		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.3189333458940684 | validation: 1.2164613941351166]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1565274510266788		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.1565274510266788 | validation: 1.1894476680929762]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2242604964071724		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.2242604964071724 | validation: 1.3084938002385789]
	TIME [epoch: 11.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2410317466230865		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.2410317466230865 | validation: 1.1919489866099915]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2351939804185696		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 2.2351939804185696 | validation: 1.1944101745377667]
	TIME [epoch: 11.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.162351669428427		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.162351669428427 | validation: 1.1661528244988386]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2072241000127653		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.2072241000127653 | validation: 1.287616327318193]
	TIME [epoch: 11.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258872157387712		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.258872157387712 | validation: 1.3308565685067522]
	TIME [epoch: 11.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.204079763805522		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.204079763805522 | validation: 1.1910966851258484]
	TIME [epoch: 11.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2287207211753515		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.2287207211753515 | validation: 1.225801187042304]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1856511101379104		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.1856511101379104 | validation: 1.2924391856558015]
	TIME [epoch: 11.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.17991021959798		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.17991021959798 | validation: 1.1896713914184565]
	TIME [epoch: 11.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2939631200056843		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.2939631200056843 | validation: 1.418053427302591]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.16154271537447		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.16154271537447 | validation: 1.4157546908311316]
	TIME [epoch: 11.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.256834575711675		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.256834575711675 | validation: 1.3571889202325087]
	TIME [epoch: 11.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.190265714731861		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.190265714731861 | validation: 1.1604887799681851]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.200624830571439		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.200624830571439 | validation: 1.180367785592141]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1127468815536012		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.1127468815536012 | validation: 1.3689635201029462]
	TIME [epoch: 11.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2796011778202523		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.2796011778202523 | validation: 1.1765636694720316]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2208459832039074		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.2208459832039074 | validation: 1.350060253865135]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1513748874674103		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.1513748874674103 | validation: 1.5200498459384943]
	TIME [epoch: 11.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315842359952976		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.315842359952976 | validation: 1.2377297280149695]
	TIME [epoch: 11.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1139186483609342		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.1139186483609342 | validation: 1.2504113439272213]
	TIME [epoch: 11.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25838666403882		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.25838666403882 | validation: 1.7514461528324745]
	TIME [epoch: 11.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.255483558154946		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.255483558154946 | validation: 1.1589471471563804]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.122073772175545		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.122073772175545 | validation: 1.2703938425767962]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2002443000074567		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.2002443000074567 | validation: 1.915380177207762]
	TIME [epoch: 11.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.915429351827882		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.915429351827882 | validation: 1.3832664595446142]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.199384634308007		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.199384634308007 | validation: 1.3264663797302847]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.153206966176019		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.153206966176019 | validation: 1.1985450337614796]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.190943713250649		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.190943713250649 | validation: 1.3587651697815557]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.108680087656773		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.108680087656773 | validation: 1.5386257586529086]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2105116967517286		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.2105116967517286 | validation: 1.2986020268585827]
	TIME [epoch: 11.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.457529971573092		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.457529971573092 | validation: 1.2988842661745952]
	TIME [epoch: 11.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1752692035072174		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.1752692035072174 | validation: 1.2374178026768412]
	TIME [epoch: 11.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1441286075567403		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.1441286075567403 | validation: 1.215199609782327]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.173945260445539		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.173945260445539 | validation: 1.303036822403983]
	TIME [epoch: 11.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.126291438159463		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.126291438159463 | validation: 1.1860355302331187]
	TIME [epoch: 11.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2734044817527677		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.2734044817527677 | validation: 2.7360233067824162]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.496753065096763		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.496753065096763 | validation: 1.1672008521542254]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.158691599008873		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.158691599008873 | validation: 1.2611076918423403]
	TIME [epoch: 11.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.147829050359998		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.147829050359998 | validation: 1.2721338273263165]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0803976986516233		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.0803976986516233 | validation: 2.755091248619743]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.584281939602236		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.584281939602236 | validation: 1.20572913382316]
	TIME [epoch: 11.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1063740821355204		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.1063740821355204 | validation: 1.2503777007389079]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0644998751621197		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.0644998751621197 | validation: 1.2826358920993586]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.156672846871283		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 2.156672846871283 | validation: 1.1987702297900513]
	TIME [epoch: 11.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1396092054056255		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.1396092054056255 | validation: 1.3618945883262235]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2137026670444073		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.2137026670444073 | validation: 1.283400641536466]
	TIME [epoch: 11.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0822468238118765		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.0822468238118765 | validation: 1.1967731412529239]
	TIME [epoch: 11.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.233477222339725		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.233477222339725 | validation: 1.4556589745843627]
	TIME [epoch: 11.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.126593883542768		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.126593883542768 | validation: 1.2023153994577522]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1887971994168027		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.1887971994168027 | validation: 1.3756330325747803]
	TIME [epoch: 11.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1350798261676056		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.1350798261676056 | validation: 1.2894081765433043]
	TIME [epoch: 11.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1348834874728775		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.1348834874728775 | validation: 1.2934888290464057]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0843828744392385		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.0843828744392385 | validation: 1.6534000942739204]
	TIME [epoch: 11.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.205171854091878		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.205171854091878 | validation: 1.2575015853934568]
	TIME [epoch: 11.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1382988821580686		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.1382988821580686 | validation: 1.276261895881182]
	TIME [epoch: 11.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1371508935453343		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.1371508935453343 | validation: 1.2565256502310487]
	TIME [epoch: 11.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.104536029884418		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.104536029884418 | validation: 1.4834215889000018]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1944769639248323		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.1944769639248323 | validation: 1.214126220759571]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4509405040803594		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.4509405040803594 | validation: 1.1345471555022417]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0249083043712024		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.0249083043712024 | validation: 1.8011721896606319]
	TIME [epoch: 11.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1819882225734015		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.1819882225734015 | validation: 1.0917341992059642]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.199483457780257		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.199483457780257 | validation: 1.2048677601613833]
	TIME [epoch: 11.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.090896750427601		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.090896750427601 | validation: 1.2315784525661118]
	TIME [epoch: 11.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0267768190552147		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.0267768190552147 | validation: 1.2143614189548877]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.120940433598891		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.120940433598891 | validation: 1.1635168144234902]
	TIME [epoch: 11.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1064986261116485		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.1064986261116485 | validation: 1.0667548968285434]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.072912802664335		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.072912802664335 | validation: 1.0678906167826374]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0550277943517363		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.0550277943517363 | validation: 1.312574456768437]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0941441308400384		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.0941441308400384 | validation: 1.6951562706637067]
	TIME [epoch: 11.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.231201223689625		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.231201223689625 | validation: 1.124458931593507]
	TIME [epoch: 11.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1843219063276553		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.1843219063276553 | validation: 1.1342854402308051]
	TIME [epoch: 11.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0346301584993873		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 2.0346301584993873 | validation: 1.224759029542957]
	TIME [epoch: 11.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.997323848090658		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.997323848090658 | validation: 1.7232322547308707]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1960778643507		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.1960778643507 | validation: 1.1257940103788562]
	TIME [epoch: 11.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.11740948640435		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.11740948640435 | validation: 1.0841199783662345]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8071198257996763		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.8071198257996763 | validation: 1.5382139784662894]
	TIME [epoch: 11.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.206311700879469		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.206311700879469 | validation: 1.597166886416071]
	TIME [epoch: 11.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2483874860609623		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.2483874860609623 | validation: 1.3330937115173145]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.116294853790336		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.116294853790336 | validation: 1.1812346191339937]
	TIME [epoch: 11.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060249531063673		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 2.060249531063673 | validation: 1.1034778262375302]
	TIME [epoch: 11.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.105861461922859		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.105861461922859 | validation: 1.127929160731012]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2103096847442987		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.2103096847442987 | validation: 1.1471466755845787]
	TIME [epoch: 11.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0749650909624084		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.0749650909624084 | validation: 1.2521037786894895]
	TIME [epoch: 11.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.136117114609034		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.136117114609034 | validation: 1.061938851457661]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1134197312493495		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.1134197312493495 | validation: 1.1000213229601017]
	TIME [epoch: 11.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0510805881274354		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.0510805881274354 | validation: 1.3448620504425737]
	TIME [epoch: 11.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.166161098710284		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.166161098710284 | validation: 1.0495718801801992]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1395724536011467		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 2.1395724536011467 | validation: 1.1147344433369069]
	TIME [epoch: 11.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069371419089538		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.069371419089538 | validation: 1.1489950845430166]
	TIME [epoch: 11.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2438936203823516		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 2.2438936203823516 | validation: 1.1028384945835734]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.239954700199602		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.239954700199602 | validation: 1.124371409461766]
	TIME [epoch: 11.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0292599853869007		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 2.0292599853869007 | validation: 1.056166924869684]
	TIME [epoch: 11.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0072590753842325		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.0072590753842325 | validation: 1.2585165160307037]
	TIME [epoch: 11.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086223386992934		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.086223386992934 | validation: 1.1517293464333376]
	TIME [epoch: 11.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8441627261631943		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.8441627261631943 | validation: 4.2887584625538935]
	TIME [epoch: 11.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.013350598173808		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 3.013350598173808 | validation: 1.1744869552852282]
	TIME [epoch: 11.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0191833327281694		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 2.0191833327281694 | validation: 1.5368214407924128]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2373724919956444		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.2373724919956444 | validation: 1.3219176695964858]
	TIME [epoch: 11.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0864212770795447		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.0864212770795447 | validation: 1.0877640970840727]
	TIME [epoch: 11.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0027987475857127		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.0027987475857127 | validation: 1.2788148582134402]
	TIME [epoch: 11.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.076861901960404		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 2.076861901960404 | validation: 1.442288710258768]
	TIME [epoch: 11.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1271512355550737		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.1271512355550737 | validation: 1.1101781103250716]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.973212040768816		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.973212040768816 | validation: 1.1141421126718931]
	TIME [epoch: 11.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.029456119930424		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.029456119930424 | validation: 1.088753716258773]
	TIME [epoch: 11.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0546174427888686		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 2.0546174427888686 | validation: 1.5949436715782144]
	TIME [epoch: 11.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.188500493218341		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 2.188500493218341 | validation: 1.1437412383176193]
	TIME [epoch: 11.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9979801038226845		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.9979801038226845 | validation: 1.094319706748814]
	TIME [epoch: 11.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0715373311488805		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.0715373311488805 | validation: 1.2426169062764842]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0916634810805492		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.0916634810805492 | validation: 1.0634387967392163]
	TIME [epoch: 11.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0851288841693685		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.0851288841693685 | validation: 1.126781483661917]
	TIME [epoch: 11.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0106569518678143		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 2.0106569518678143 | validation: 1.0661996852028224]
	TIME [epoch: 11.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.219089188352398		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.219089188352398 | validation: 1.130504389129159]
	TIME [epoch: 11.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.13786487261301		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.13786487261301 | validation: 1.218899336000836]
	TIME [epoch: 11.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.093766142399177		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.093766142399177 | validation: 1.9770795952382703]
	TIME [epoch: 11.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2793196469138834		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.2793196469138834 | validation: 1.1122054515780995]
	TIME [epoch: 11.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1384041913252716		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 2.1384041913252716 | validation: 1.1686134633144112]
	TIME [epoch: 11.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.048399459648325		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.048399459648325 | validation: 1.2157303303402125]
	TIME [epoch: 11.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0263542671839305		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 2.0263542671839305 | validation: 1.148965095323425]
	TIME [epoch: 11.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0819257420936523		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.0819257420936523 | validation: 1.1807496757896687]
	TIME [epoch: 11.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0050889239592156		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 2.0050889239592156 | validation: 1.0919048740402688]
	TIME [epoch: 11.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9955097767902714		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.9955097767902714 | validation: 1.1024166111775313]
	TIME [epoch: 11.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9650513841535167		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.9650513841535167 | validation: 1.0512566659709845]
	TIME [epoch: 11.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074078969270237		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 2.074078969270237 | validation: 1.4850207845243597]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2564341150176044		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 2.2564341150176044 | validation: 1.3220987239680613]
	TIME [epoch: 11.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.164622648980483		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 2.164622648980483 | validation: 1.097087573527291]
	TIME [epoch: 11.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.239018738276769		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.239018738276769 | validation: 1.1832480663189804]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1100971147554732		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 2.1100971147554732 | validation: 1.0928815178558517]
	TIME [epoch: 11.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069400816886217		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.069400816886217 | validation: 1.1943316455230895]
	TIME [epoch: 11.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.99550254618215		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.99550254618215 | validation: 1.051950855176012]
	TIME [epoch: 11.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.025445529166054		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 2.025445529166054 | validation: 1.2601936492025265]
	TIME [epoch: 11.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0213905548353277		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.0213905548353277 | validation: 1.08354247758428]
	TIME [epoch: 11.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9807986391612489		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.9807986391612489 | validation: 1.122532148022398]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0093428415912724		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 2.0093428415912724 | validation: 1.08413879210288]
	TIME [epoch: 11.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9719415099481017		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.9719415099481017 | validation: 1.153321172586078]
	TIME [epoch: 11.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9982641384887199		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.9982641384887199 | validation: 1.2266704750947883]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0019824655427603		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 2.0019824655427603 | validation: 1.203750691646993]
	TIME [epoch: 11.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9920658414423231		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.9920658414423231 | validation: 1.1073021965882728]
	TIME [epoch: 11.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.01492382370662		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.01492382370662 | validation: 1.2176378433432669]
	TIME [epoch: 11.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0262478432215603		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.0262478432215603 | validation: 1.15470819551812]
	TIME [epoch: 11.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285210768915313		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.285210768915313 | validation: 1.2167463534555238]
	TIME [epoch: 11.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0648317309486086		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.0648317309486086 | validation: 1.1268287915642135]
	TIME [epoch: 11.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0596479327358734		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.0596479327358734 | validation: 1.0500979449133534]
	TIME [epoch: 11.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.035283024222588		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.035283024222588 | validation: 1.2207270615179109]
	TIME [epoch: 11.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0170671325638674		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.0170671325638674 | validation: 1.332977741262344]
	TIME [epoch: 11.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.113405302693706		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 2.113405302693706 | validation: 1.2356456393324668]
	TIME [epoch: 11.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0110443766413604		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.0110443766413604 | validation: 1.2017778509610286]
	TIME [epoch: 11.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0170812056771963		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.0170812056771963 | validation: 1.073257940053456]
	TIME [epoch: 11.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0244737969180147		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.0244737969180147 | validation: 1.0300477418540563]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.01972848311729		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.01972848311729 | validation: 1.3772366454637046]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0895233357857466		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.0895233357857466 | validation: 1.1230534125393785]
	TIME [epoch: 11.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9924201995538855		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.9924201995538855 | validation: 1.3501497454742646]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.045212126222148		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 2.045212126222148 | validation: 1.1227018480068895]
	TIME [epoch: 11.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.001478513925686		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 2.001478513925686 | validation: 1.142577176403657]
	TIME [epoch: 11.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.974340467547		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.974340467547 | validation: 1.1952278759025854]
	TIME [epoch: 11.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9954433746041083		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.9954433746041083 | validation: 1.0565238414930491]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0463510424995985		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.0463510424995985 | validation: 1.058338743813082]
	TIME [epoch: 11.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9841038723596605		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.9841038723596605 | validation: 1.0550175175379057]
	TIME [epoch: 11.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9545322575437953		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.9545322575437953 | validation: 1.0629667589744778]
	TIME [epoch: 11.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0202226019532996		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 2.0202226019532996 | validation: 1.2967035167550487]
	TIME [epoch: 11.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0114771069549353		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 2.0114771069549353 | validation: 1.0318532467299157]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0350202979141176		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 2.0350202979141176 | validation: 1.2956442399516022]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9856799397171372		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.9856799397171372 | validation: 1.7773746473423877]
	TIME [epoch: 11.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1714218648062116		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.1714218648062116 | validation: 1.1175921977905636]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9586683994544076		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.9586683994544076 | validation: 1.0865749193865717]
	TIME [epoch: 11.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0175514268141126		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 2.0175514268141126 | validation: 1.1072861824422624]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.15673339880009		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 2.15673339880009 | validation: 1.114494973520548]
	TIME [epoch: 11.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.920961749151968		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.920961749151968 | validation: 1.0885803353557477]
	TIME [epoch: 11.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0122341790541096		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 2.0122341790541096 | validation: 1.2979495161564456]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0153250202865065		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 2.0153250202865065 | validation: 1.2549396522917062]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0329713334529784		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.0329713334529784 | validation: 1.1370617237410192]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0591531126889535		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 2.0591531126889535 | validation: 1.1247760291150157]
	TIME [epoch: 11.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.011297639746149		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 2.011297639746149 | validation: 1.2149847899257855]
	TIME [epoch: 11.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9983494716001196		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.9983494716001196 | validation: 1.075967028194909]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059586693478485		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 2.059586693478485 | validation: 1.1132265012219535]
	TIME [epoch: 11.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9802085537661749		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.9802085537661749 | validation: 1.1035327056428923]
	TIME [epoch: 11.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.005022394189555		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.005022394189555 | validation: 1.1597261092219815]
	TIME [epoch: 11.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9986154281137325		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.9986154281137325 | validation: 1.0931585562455697]
	TIME [epoch: 11.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9887246505841594		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.9887246505841594 | validation: 1.0878604074925509]
	TIME [epoch: 11.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9431176308463713		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.9431176308463713 | validation: 1.0211737493457345]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9892108000653363		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.9892108000653363 | validation: 1.3116959680590423]
	TIME [epoch: 11.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.023823653213824		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 2.023823653213824 | validation: 1.3095602699659452]
	TIME [epoch: 11.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.042938539799527		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 2.042938539799527 | validation: 1.12179647785776]
	TIME [epoch: 11.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0583174218681988		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.0583174218681988 | validation: 1.0399379513434546]
	TIME [epoch: 11.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9515954401461144		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.9515954401461144 | validation: 1.0675445176296912]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9996381441443911		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.9996381441443911 | validation: 1.0399630278763659]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.965071674758118		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.965071674758118 | validation: 1.0705084868096344]
	TIME [epoch: 11.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9605385358158236		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.9605385358158236 | validation: 1.4111753469776187]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1378338413464526		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 2.1378338413464526 | validation: 1.0197260080441977]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_334.pth
	Model improved!!!
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9443703373675698		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.9443703373675698 | validation: 1.1239047117937677]
	TIME [epoch: 11.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.939246627131665		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.939246627131665 | validation: 1.143278166307683]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9425718231507876		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.9425718231507876 | validation: 1.0525301487689838]
	TIME [epoch: 11.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0296817932474265		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 2.0296817932474265 | validation: 1.1826245319277846]
	TIME [epoch: 11.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.003171156193205		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 2.003171156193205 | validation: 1.234440492961117]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9895053999084318		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.9895053999084318 | validation: 1.0653003778048293]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.984124848040343		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.984124848040343 | validation: 1.0146875036913268]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9649224719674017		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.9649224719674017 | validation: 1.0399331119143225]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.970373183347789		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.970373183347789 | validation: 1.1333593266679742]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9622205533897747		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.9622205533897747 | validation: 1.1803300360238003]
	TIME [epoch: 11.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074044188755362		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 2.074044188755362 | validation: 1.0599802217503302]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9571844062808519		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.9571844062808519 | validation: 1.044984427493829]
	TIME [epoch: 11.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9497587955357263		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.9497587955357263 | validation: 1.1321402595130938]
	TIME [epoch: 11.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9943575966801639		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.9943575966801639 | validation: 1.0768414497082905]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9295621442104105		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.9295621442104105 | validation: 1.121236380106875]
	TIME [epoch: 11.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9742584543987098		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.9742584543987098 | validation: 1.776397962688507]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1953808212333383		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 2.1953808212333383 | validation: 1.0790824185572272]
	TIME [epoch: 11.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0318844746265436		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 2.0318844746265436 | validation: 1.0247112578831192]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9974889718716038		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.9974889718716038 | validation: 1.1756882524789685]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.09497560638044		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 2.09497560638044 | validation: 1.1791880425817873]
	TIME [epoch: 11.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9677669109186868		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.9677669109186868 | validation: 1.0119603064731106]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_355.pth
	Model improved!!!
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.960183395663427		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.960183395663427 | validation: 0.9926779344570961]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_356.pth
	Model improved!!!
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9833396096647928		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.9833396096647928 | validation: 1.1320504860940654]
	TIME [epoch: 11.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.947776007099026		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.947776007099026 | validation: 1.1180619133648784]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9169284278993934		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.9169284278993934 | validation: 1.4335202017560296]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.072055542324682		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 2.072055542324682 | validation: 1.0502417549307486]
	TIME [epoch: 11.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9162034064522975		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.9162034064522975 | validation: 1.041361668784592]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9500211793637512		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.9500211793637512 | validation: 1.2689379317251193]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9991416057027087		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.9991416057027087 | validation: 1.0962166964969122]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9587467239107317		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.9587467239107317 | validation: 1.4664448735861428]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0218103131397958		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 2.0218103131397958 | validation: 1.0056867257946673]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.926652954258644		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.926652954258644 | validation: 1.0538611457714853]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9390243580293396		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.9390243580293396 | validation: 1.0308084794266534]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9143702338451838		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.9143702338451838 | validation: 1.0570889339764715]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9488917393937106		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.9488917393937106 | validation: 1.0744503146136457]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.964105316537573		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.964105316537573 | validation: 1.102390139774809]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.957222186044826		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.957222186044826 | validation: 1.0140538939432568]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9693393252982045		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.9693393252982045 | validation: 0.9694497934651617]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_372.pth
	Model improved!!!
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.017971080919883		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 2.017971080919883 | validation: 1.0960429258469926]
	TIME [epoch: 11.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9719783739454995		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.9719783739454995 | validation: 1.0349237981907689]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.002386364043938		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 2.002386364043938 | validation: 1.067969367453153]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9353306247429096		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.9353306247429096 | validation: 0.9819831498276965]
	TIME [epoch: 11.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9125660334741035		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.9125660334741035 | validation: 1.2941388030388306]
	TIME [epoch: 11.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9564106031566542		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.9564106031566542 | validation: 0.9698615736908447]
	TIME [epoch: 11.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.893078620152763		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.893078620152763 | validation: 0.952195291859116]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.887115496224029		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.887115496224029 | validation: 1.045677945997945]
	TIME [epoch: 11.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9228550322666487		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.9228550322666487 | validation: 0.9886677605951296]
	TIME [epoch: 11.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8895307460998216		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.8895307460998216 | validation: 1.1063415725407322]
	TIME [epoch: 11.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0846536257985084		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 2.0846536257985084 | validation: 1.2961196354716669]
	TIME [epoch: 11.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.032652667063832		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 2.032652667063832 | validation: 1.0799420745453414]
	TIME [epoch: 11.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9299749213511244		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.9299749213511244 | validation: 0.951727244943422]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_385.pth
	Model improved!!!
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9088929263718637		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.9088929263718637 | validation: 0.9777532420729463]
	TIME [epoch: 11.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9314962075101771		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.9314962075101771 | validation: 0.9966763763204725]
	TIME [epoch: 11.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0983056866832004		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 2.0983056866832004 | validation: 1.051214468909246]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8931019366134585		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.8931019366134585 | validation: 1.0565302158163603]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9075070675641561		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.9075070675641561 | validation: 1.0521224077450528]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9216355626228425		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.9216355626228425 | validation: 1.1872242770041417]
	TIME [epoch: 11.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9694126834453143		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.9694126834453143 | validation: 0.9537403797973459]
	TIME [epoch: 11.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9077639854855415		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.9077639854855415 | validation: 1.0225642076780697]
	TIME [epoch: 11.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086758740707958		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 2.086758740707958 | validation: 1.0099244808180212]
	TIME [epoch: 11.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.92181209209613		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.92181209209613 | validation: 1.002261853329879]
	TIME [epoch: 11.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.908905771315393		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.908905771315393 | validation: 1.027756576946614]
	TIME [epoch: 11.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.896840173606233		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.896840173606233 | validation: 1.118566491644073]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9513626997060676		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.9513626997060676 | validation: 1.119538827855162]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9875567042912516		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.9875567042912516 | validation: 0.9705943942379315]
	TIME [epoch: 11.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8833192250051152		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.8833192250051152 | validation: 0.9479861016127704]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9219942942914798		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.9219942942914798 | validation: 1.0691280822757128]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9120199052144398		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.9120199052144398 | validation: 1.0483694377540729]
	TIME [epoch: 11.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.957168404749278		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.957168404749278 | validation: 1.0868822489313419]
	TIME [epoch: 11.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8974560866016137		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.8974560866016137 | validation: 0.9776907240817206]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.902281347452777		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.902281347452777 | validation: 1.2467591193034242]
	TIME [epoch: 11.6 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9718611310767682		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.9718611310767682 | validation: 1.1460745306194102]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9340907889224481		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.9340907889224481 | validation: 1.0786141818670278]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9192054671924168		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.9192054671924168 | validation: 0.9819438155798992]
	TIME [epoch: 11.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8625401828233785		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.8625401828233785 | validation: 0.9893274392250813]
	TIME [epoch: 11.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8676738805550166		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.8676738805550166 | validation: 1.229669557421178]
	TIME [epoch: 11.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9593965133077982		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.9593965133077982 | validation: 0.9915425334712835]
	TIME [epoch: 11.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9295214244840475		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.9295214244840475 | validation: 1.2299965708866585]
	TIME [epoch: 11.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9547212439034094		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.9547212439034094 | validation: 1.098931575016018]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.931599488024403		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.931599488024403 | validation: 1.0062279959515938]
	TIME [epoch: 11.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8579534918755942		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.8579534918755942 | validation: 1.024113796107068]
	TIME [epoch: 11.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8836520423735879		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.8836520423735879 | validation: 0.9525846990814679]
	TIME [epoch: 11.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.031004736620141		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 2.031004736620141 | validation: 1.0217592074955197]
	TIME [epoch: 11.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0785603261948027		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 2.0785603261948027 | validation: 1.192558314829805]
	TIME [epoch: 11.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9376189283298613		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.9376189283298613 | validation: 1.0415885613091798]
	TIME [epoch: 11.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8848654743755828		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.8848654743755828 | validation: 0.9866343879697982]
	TIME [epoch: 11.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9374511848701386		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.9374511848701386 | validation: 0.9606092984985094]
	TIME [epoch: 11.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.19627301095024		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 2.19627301095024 | validation: 1.0064514002604545]
	TIME [epoch: 11.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0223668973465747		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 2.0223668973465747 | validation: 1.0425757798598931]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9989279253597392		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.9989279253597392 | validation: 1.1139956724973996]
	TIME [epoch: 11.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.955752418354036		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.955752418354036 | validation: 1.0108670827149198]
	TIME [epoch: 11.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8817082972788133		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.8817082972788133 | validation: 1.1654510603514592]
	TIME [epoch: 11.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0121547352800615		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 2.0121547352800615 | validation: 1.4925531782263277]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9958431663050897		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.9958431663050897 | validation: 1.0383872630244073]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.876669218534745		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.876669218534745 | validation: 1.0105609258043189]
	TIME [epoch: 11.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8797230594403032		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.8797230594403032 | validation: 0.964307297006751]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.912022905445006		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.912022905445006 | validation: 1.051803043796673]
	TIME [epoch: 11.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9155251479697402		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.9155251479697402 | validation: 0.9714810108965768]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8990889953995533		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.8990889953995533 | validation: 0.9708602540787995]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8949551029071778		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.8949551029071778 | validation: 0.9473048103681159]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8996575130796873		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.8996575130796873 | validation: 0.9884210376825016]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9216065689564936		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.9216065689564936 | validation: 1.0214353207085678]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9414949436644262		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.9414949436644262 | validation: 0.9611716234085185]
	TIME [epoch: 11.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.92952128138173		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.92952128138173 | validation: 1.0051641837407086]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.900955452709145		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.900955452709145 | validation: 0.9770739220912356]
	TIME [epoch: 11.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8516222393634387		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.8516222393634387 | validation: 1.2064354890965765]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9586240646572302		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.9586240646572302 | validation: 1.017006284336621]
	TIME [epoch: 11.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9187048342972397		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.9187048342972397 | validation: 1.0865894803891574]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8969792423645824		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.8969792423645824 | validation: 1.1451054152158024]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.930556207389598		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.930556207389598 | validation: 1.010101749033832]
	TIME [epoch: 11.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8543794009412093		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.8543794009412093 | validation: 1.0824254256077763]
	TIME [epoch: 11.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8903032727423779		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.8903032727423779 | validation: 0.9863059417864107]
	TIME [epoch: 11.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8848990789337172		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.8848990789337172 | validation: 1.0444600629361553]
	TIME [epoch: 11.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8947189295585154		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.8947189295585154 | validation: 1.0592852440105294]
	TIME [epoch: 11.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8934964065524764		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.8934964065524764 | validation: 0.9598184634690273]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.886206121402927		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.886206121402927 | validation: 0.9468617687498204]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.887859928226966		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.887859928226966 | validation: 0.9780222742445085]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.852206328496349		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.852206328496349 | validation: 1.0033306138839413]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8746560188676182		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.8746560188676182 | validation: 1.1971399165148513]
	TIME [epoch: 11.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.911730826108078		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.911730826108078 | validation: 1.0499160263842033]
	TIME [epoch: 11.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9170465477273448		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.9170465477273448 | validation: 0.9527019431611001]
	TIME [epoch: 11.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.895288341898154		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.895288341898154 | validation: 1.034579027629439]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9260211018536477		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.9260211018536477 | validation: 1.0997045743837095]
	TIME [epoch: 11.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.924303765324013		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.924303765324013 | validation: 1.0372087675546413]
	TIME [epoch: 11.6 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8833103487563303		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.8833103487563303 | validation: 1.0482443298792194]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8774992161824229		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.8774992161824229 | validation: 1.0467500062169743]
	TIME [epoch: 11.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.885323608866878		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.885323608866878 | validation: 1.019618291575079]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9007929907978056		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.9007929907978056 | validation: 0.9983098100456372]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8898833755804636		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.8898833755804636 | validation: 0.9519099833633456]
	TIME [epoch: 11.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8620822990675288		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.8620822990675288 | validation: 0.9920478267203967]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8938870643364676		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.8938870643364676 | validation: 1.0041230735410522]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9106085244780153		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.9106085244780153 | validation: 1.0086734656159224]
	TIME [epoch: 11.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8801952738340721		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.8801952738340721 | validation: 1.12120602751508]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9095068839153049		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.9095068839153049 | validation: 0.954972488706379]
	TIME [epoch: 11.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8432797369699165		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.8432797369699165 | validation: 0.9370408118545516]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_469.pth
	Model improved!!!
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8783208606830448		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.8783208606830448 | validation: 1.0682914341509553]
	TIME [epoch: 11.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.886825495177361		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.886825495177361 | validation: 1.013497571057516]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.868745781846219		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.868745781846219 | validation: 0.9069316146900996]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8174704221698883		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.8174704221698883 | validation: 0.9567419894375097]
	TIME [epoch: 11.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8584254288167146		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.8584254288167146 | validation: 1.0408928440878518]
	TIME [epoch: 11.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9116423371810365		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.9116423371810365 | validation: 0.9468347430310615]
	TIME [epoch: 11.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.866919406600902		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.866919406600902 | validation: 0.9690382958749848]
	TIME [epoch: 11.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8923870892248877		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.8923870892248877 | validation: 0.9259150211011599]
	TIME [epoch: 11.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8980428277623331		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.8980428277623331 | validation: 1.1436825531858719]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9250016301818014		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.9250016301818014 | validation: 1.1527616227717423]
	TIME [epoch: 11.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.893561815001184		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.893561815001184 | validation: 0.9887632705153024]
	TIME [epoch: 11.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8622211667399542		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 1.8622211667399542 | validation: 0.9533731247477991]
	TIME [epoch: 11.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8529075338935765		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 1.8529075338935765 | validation: 0.9441254025310224]
	TIME [epoch: 11.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8312813482908847		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.8312813482908847 | validation: 1.0933619018979368]
	TIME [epoch: 11.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.975697953707799		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.975697953707799 | validation: 1.006832988004078]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8740364620225416		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.8740364620225416 | validation: 0.9702135721031201]
	TIME [epoch: 11.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8301221641870404		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.8301221641870404 | validation: 0.9472518368650051]
	TIME [epoch: 11.6 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.880497463032528		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.880497463032528 | validation: 1.0023798921287042]
	TIME [epoch: 11.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9117994607713171		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.9117994607713171 | validation: 0.9691176082034494]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.951793018721308		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.951793018721308 | validation: 0.9398001799537998]
	TIME [epoch: 11.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8282907970210416		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.8282907970210416 | validation: 0.9366081000352431]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8828648102505796		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.8828648102505796 | validation: 1.0115671571951057]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8643228942265162		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.8643228942265162 | validation: 1.1370970127765252]
	TIME [epoch: 11.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9211014960895134		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.9211014960895134 | validation: 0.9761190869885824]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8518092469352705		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.8518092469352705 | validation: 0.9925835946031049]
	TIME [epoch: 11.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8841571281202423		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.8841571281202423 | validation: 1.0195512919032825]
	TIME [epoch: 11.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9310746357909945		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 1.9310746357909945 | validation: 0.9563352401645028]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.89171790007422		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.89171790007422 | validation: 0.9946081212962979]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.88651490270298		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.88651490270298 | validation: 1.0279071541137546]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8652796329641983		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.8652796329641983 | validation: 1.0658249202484666]
	TIME [epoch: 11.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.909384574265355		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.909384574265355 | validation: 1.0943870169118273]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.914278500490353		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.914278500490353 | validation: 0.9595117899908711]
	TIME [epoch: 11.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8750766755581		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.8750766755581 | validation: 1.0880613777758763]
	TIME [epoch: 11.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.910704615277073		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.910704615277073 | validation: 1.0813368210175895]
	TIME [epoch: 11.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9168625630713274		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 1.9168625630713274 | validation: 1.0581752497543262]
	TIME [epoch: 11.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9032178239498099		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.9032178239498099 | validation: 0.9745026097429715]
	TIME [epoch: 11.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8851643062682482		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.8851643062682482 | validation: 0.9380694431683121]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8505037089535528		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.8505037089535528 | validation: 1.0303556392954858]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.878667999638495		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.878667999638495 | validation: 1.0041112752461387]
	TIME [epoch: 11.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8386691746745962		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.8386691746745962 | validation: 1.0523633040426819]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8814825791745864		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.8814825791745864 | validation: 1.1270484618220655]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9539314356129436		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.9539314356129436 | validation: 1.0243513089423903]
	TIME [epoch: 11.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.905758625579877		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.905758625579877 | validation: 0.9328855025417822]
	TIME [epoch: 11.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8569602024327783		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.8569602024327783 | validation: 0.9672503281931918]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8444722911853142		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.8444722911853142 | validation: 1.0455349793423774]
	TIME [epoch: 11.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8472727993702243		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.8472727993702243 | validation: 0.9243348249531123]
	TIME [epoch: 11.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9008916144685915		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 1.9008916144685915 | validation: 0.9867434058849105]
	TIME [epoch: 11.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8451613842463852		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.8451613842463852 | validation: 0.9634900389996912]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8452838552901643		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.8452838552901643 | validation: 1.2131318387422045]
	TIME [epoch: 11.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9293479151735111		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.9293479151735111 | validation: 0.9371435906145925]
	TIME [epoch: 11.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.814825355166214		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.814825355166214 | validation: 1.0133754126179715]
	TIME [epoch: 11.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.850524659649102		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 1.850524659649102 | validation: 0.9897627967398281]
	TIME [epoch: 11.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8310400909024023		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.8310400909024023 | validation: 0.9277466554228999]
	TIME [epoch: 11.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.885048971002572		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.885048971002572 | validation: 0.9461352766232072]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.832635213386299		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.832635213386299 | validation: 0.9786821622627295]
	TIME [epoch: 11.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8402987508618813		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 1.8402987508618813 | validation: 1.0658090556640512]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8642766961045143		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.8642766961045143 | validation: 1.0036502713626352]
	TIME [epoch: 11.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8369396257655768		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.8369396257655768 | validation: 1.0115133134669716]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8336757701858308		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.8336757701858308 | validation: 0.9665925625427447]
	TIME [epoch: 11.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8265387878554389		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.8265387878554389 | validation: 0.9334777546567665]
	TIME [epoch: 11.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8532325644445617		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 1.8532325644445617 | validation: 1.0834757657022558]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9431251190158145		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.9431251190158145 | validation: 1.0020886374799953]
	TIME [epoch: 11.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8673140694399726		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.8673140694399726 | validation: 0.9450225747687524]
	TIME [epoch: 11.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.863453930086385		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.863453930086385 | validation: 0.9204261029787987]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.862595056782636		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.862595056782636 | validation: 1.0149058371490565]
	TIME [epoch: 11.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8501319824404476		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 1.8501319824404476 | validation: 0.9996933068994125]
	TIME [epoch: 11.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8754180669532008		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 1.8754180669532008 | validation: 1.0275057763430906]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8588805688464793		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 1.8588805688464793 | validation: 0.922906087360627]
	TIME [epoch: 11.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8507311101911896		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 1.8507311101911896 | validation: 1.0089736371190388]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8913059884672019		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 1.8913059884672019 | validation: 0.92872242438506]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8461687871623687		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.8461687871623687 | validation: 0.9574355436161262]
	TIME [epoch: 11.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8691810774368771		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.8691810774368771 | validation: 0.9089842218170068]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8492295854041196		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 1.8492295854041196 | validation: 1.00088383440385]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.86249370213361		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 1.86249370213361 | validation: 0.9284744831067399]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8312352326431944		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 1.8312352326431944 | validation: 1.1203573815389094]
	TIME [epoch: 11.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8642049529295275		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 1.8642049529295275 | validation: 0.9910313721905541]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8395716680578964		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 1.8395716680578964 | validation: 1.0272198866361029]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8585036061038895		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 1.8585036061038895 | validation: 0.9810542194160232]
	TIME [epoch: 11.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8279065510730939		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 1.8279065510730939 | validation: 0.9093909049430516]
	TIME [epoch: 11.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8795805740322142		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 1.8795805740322142 | validation: 1.0199215020700365]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8404837503311096		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 1.8404837503311096 | validation: 0.9892821369986973]
	TIME [epoch: 11.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8449367064629891		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 1.8449367064629891 | validation: 0.9113785727844922]
	TIME [epoch: 11.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8531452257903087		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 1.8531452257903087 | validation: 1.0202656496217548]
	TIME [epoch: 11.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8644611689513044		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 1.8644611689513044 | validation: 1.010323793118003]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8577254489628623		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 1.8577254489628623 | validation: 1.0022087802599555]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8508671366755443		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 1.8508671366755443 | validation: 0.9317044755120251]
	TIME [epoch: 11.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8492451971628132		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 1.8492451971628132 | validation: 0.9550889159471894]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8764865468678449		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 1.8764865468678449 | validation: 1.3032697332427983]
	TIME [epoch: 11.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051996094953861		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 2.051996094953861 | validation: 0.9206041240551042]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8406590505983143		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.8406590505983143 | validation: 0.9929064264035256]
	TIME [epoch: 11.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8145989705689207		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 1.8145989705689207 | validation: 0.9063460582763591]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8254448833091304		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 1.8254448833091304 | validation: 0.9413744532872975]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.831769724216012		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 1.831769724216012 | validation: 0.9252408595723364]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8230918170916794		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 1.8230918170916794 | validation: 1.0464217511353986]
	TIME [epoch: 11.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8695787749375197		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 1.8695787749375197 | validation: 1.0111036479394935]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8488042385417591		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 1.8488042385417591 | validation: 1.0854597765275875]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8597744415512427		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 1.8597744415512427 | validation: 0.9673709213656116]
	TIME [epoch: 11.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8445646885649714		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.8445646885649714 | validation: 0.9502009524767222]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.837200680814615		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 1.837200680814615 | validation: 0.9565210784356073]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8343039353288877		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 1.8343039353288877 | validation: 1.0649670962739288]
	TIME [epoch: 11.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.865630381808697		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.865630381808697 | validation: 1.0336168828117733]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8284875116284534		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 1.8284875116284534 | validation: 0.9024106574831334]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_571.pth
	Model improved!!!
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8041708881702694		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 1.8041708881702694 | validation: 1.0249182178675402]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8789902505213718		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 1.8789902505213718 | validation: 0.9452953289589686]
	TIME [epoch: 11.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8506819357859317		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 1.8506819357859317 | validation: 0.918563573524576]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.825136330622192		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 1.825136330622192 | validation: 1.0685913430164329]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8727454136833965		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 1.8727454136833965 | validation: 1.0358612623712666]
	TIME [epoch: 11.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8557572754163143		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 1.8557572754163143 | validation: 0.9449359532224557]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8173629325551173		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 1.8173629325551173 | validation: 1.0133910033997946]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9460281267642752		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 1.9460281267642752 | validation: 0.9401256028547053]
	TIME [epoch: 11.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8239042683731428		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 1.8239042683731428 | validation: 0.9134619240518668]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8476991007109345		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 1.8476991007109345 | validation: 0.9286465744420476]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8298526312312244		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 1.8298526312312244 | validation: 0.9476250325662425]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8513906838407461		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 1.8513906838407461 | validation: 0.9542581524109767]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8216646197790012		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 1.8216646197790012 | validation: 0.9252184321080412]
	TIME [epoch: 11.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8219902892538835		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 1.8219902892538835 | validation: 1.0153551281905908]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9429882623739902		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 1.9429882623739902 | validation: 0.9315813867153073]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8342817923968173		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 1.8342817923968173 | validation: 0.9452357276787564]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8128939625693927		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 1.8128939625693927 | validation: 0.9713745780857184]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8517025403752214		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 1.8517025403752214 | validation: 0.9643150941514301]
	TIME [epoch: 11.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.829247653532504		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 1.829247653532504 | validation: 0.9074781127278737]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.919118249886851		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.919118249886851 | validation: 0.9949582145769911]
	TIME [epoch: 11.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8779391231888234		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 1.8779391231888234 | validation: 1.0128887641923074]
	TIME [epoch: 11.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8958815377949534		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 1.8958815377949534 | validation: 0.900130234651661]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_593.pth
	Model improved!!!
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8140535189094529		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 1.8140535189094529 | validation: 0.9258999128788505]
	TIME [epoch: 11.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.828695613250133		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 1.828695613250133 | validation: 0.961490436531024]
	TIME [epoch: 11.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8682923674165612		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 1.8682923674165612 | validation: 0.9401509355226791]
	TIME [epoch: 11.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8215962831958459		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 1.8215962831958459 | validation: 0.936759328003744]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8822652484171911		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 1.8822652484171911 | validation: 0.980121200572901]
	TIME [epoch: 11.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8375924032868856		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 1.8375924032868856 | validation: 0.9111625546107489]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7937709853198442		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 1.7937709853198442 | validation: 0.9392581861950144]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8278829173538358		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 1.8278829173538358 | validation: 1.5268637685770798]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.985727617155544		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 1.985727617155544 | validation: 0.9872665470290923]
	TIME [epoch: 11.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8181298112800315		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 1.8181298112800315 | validation: 0.9531423645189034]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8110339152468986		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 1.8110339152468986 | validation: 0.8988833021302497]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_604.pth
	Model improved!!!
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7898017372536763		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 1.7898017372536763 | validation: 0.9054020959783304]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8014888719715134		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.8014888719715134 | validation: 0.912969562624157]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8051107772314865		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 1.8051107772314865 | validation: 0.9337032259054838]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7966424610562908		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 1.7966424610562908 | validation: 0.9105206438476876]
	TIME [epoch: 11.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8205575715627815		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 1.8205575715627815 | validation: 0.9156333097432505]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8358236547218283		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 1.8358236547218283 | validation: 1.2657175901697586]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9160272219099173		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 1.9160272219099173 | validation: 0.935503365868141]
	TIME [epoch: 11.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8124140216871032		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 1.8124140216871032 | validation: 0.9019449312410279]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.790528346756687		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 1.790528346756687 | validation: 0.9912410118085521]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9165311935787643		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 1.9165311935787643 | validation: 0.9405310805376458]
	TIME [epoch: 11.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.79897530890263		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 1.79897530890263 | validation: 0.9351939225795556]
	TIME [epoch: 11.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8429352868920672		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 1.8429352868920672 | validation: 0.9346969603356823]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.80796023247611		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 1.80796023247611 | validation: 0.9610984091284466]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8298201986527507		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 1.8298201986527507 | validation: 0.9990346856363246]
	TIME [epoch: 11.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.832312862321776		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 1.832312862321776 | validation: 1.0200923055057203]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8333816707726958		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 1.8333816707726958 | validation: 0.9202104336031742]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8108263307069845		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 1.8108263307069845 | validation: 0.9844615739517607]
	TIME [epoch: 11.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8637273103457062		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 1.8637273103457062 | validation: 0.9497187613581016]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8213954308044167		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 1.8213954308044167 | validation: 0.9799129360365362]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8475303869986932		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 1.8475303869986932 | validation: 0.9237544452702221]
	TIME [epoch: 11.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8065444092033696		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 1.8065444092033696 | validation: 0.9397131730409186]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8408919183261454		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 1.8408919183261454 | validation: 1.044146761330126]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8260177250408627		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 1.8260177250408627 | validation: 0.9579239377122346]
	TIME [epoch: 11.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8007316733797403		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 1.8007316733797403 | validation: 0.9099356036381346]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7870254734272777		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 1.7870254734272777 | validation: 1.1680526391469028]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8899105129498017		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 1.8899105129498017 | validation: 0.9186498386298589]
	TIME [epoch: 11.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8184482087626677		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 1.8184482087626677 | validation: 0.9125299309326564]
	TIME [epoch: 11.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7962104487783455		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 1.7962104487783455 | validation: 0.9876428569221689]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8526824455995374		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 1.8526824455995374 | validation: 0.9830996028306426]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8258234023595343		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 1.8258234023595343 | validation: 0.9546074873147075]
	TIME [epoch: 11.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8219073179617906		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 1.8219073179617906 | validation: 0.946560137032569]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8225765233815283		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 1.8225765233815283 | validation: 0.9024870824643341]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8122868179593838		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 1.8122868179593838 | validation: 1.084121224261262]
	TIME [epoch: 11.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8662389301703517		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 1.8662389301703517 | validation: 0.9340866229805851]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8460887128774035		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 1.8460887128774035 | validation: 0.996324273857866]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8400473234025299		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 1.8400473234025299 | validation: 0.9206732287497621]
	TIME [epoch: 11.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8279725094180632		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 1.8279725094180632 | validation: 0.9746204428067148]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.818212589975691		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 1.818212589975691 | validation: 0.8912698836539573]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_642.pth
	Model improved!!!
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8412225909758129		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 1.8412225909758129 | validation: 0.9258537346036039]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8244452414579206		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 1.8244452414579206 | validation: 1.0624044819414207]
	TIME [epoch: 11.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8620013990966842		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.8620013990966842 | validation: 1.103829512244713]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8667498141377188		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 1.8667498141377188 | validation: 0.9053406041477291]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8007976261256387		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 1.8007976261256387 | validation: 0.9380289841905096]
	TIME [epoch: 11.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8343477533544212		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 1.8343477533544212 | validation: 0.9480861523827956]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8278209873883717		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 1.8278209873883717 | validation: 0.9190706807550163]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.811261264603062		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 1.811261264603062 | validation: 0.9163203686450777]
	TIME [epoch: 11.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.839871334300938		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 1.839871334300938 | validation: 0.9242849144504507]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9445749497165954		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 1.9445749497165954 | validation: 1.0820225069819438]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8584552039143414		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 1.8584552039143414 | validation: 0.9280850360656893]
	TIME [epoch: 11.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8105241312994247		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 1.8105241312994247 | validation: 0.8983416230079203]
	TIME [epoch: 11.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7963770975203122		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 1.7963770975203122 | validation: 0.9065235486378819]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7909692670475263		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 1.7909692670475263 | validation: 0.9016539877640114]
	TIME [epoch: 11.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.821620116593518		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 1.821620116593518 | validation: 0.9054958505156054]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8114192583789421		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 1.8114192583789421 | validation: 0.9015428706996644]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8083529624766164		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 1.8083529624766164 | validation: 0.909282317026343]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8127739860829821		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 1.8127739860829821 | validation: 0.9230419520100677]
	TIME [epoch: 11.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8009864807025038		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 1.8009864807025038 | validation: 0.9995701969894134]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8274390084347267		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 1.8274390084347267 | validation: 0.9480614328500759]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7921726329046417		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 1.7921726329046417 | validation: 0.9104828973008902]
	TIME [epoch: 11.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.883443389822163		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 1.883443389822163 | validation: 1.0012697969586495]
	TIME [epoch: 11.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.807658794476993		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 1.807658794476993 | validation: 0.9074295391205817]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.80752907624655		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 1.80752907624655 | validation: 1.0407652392789688]
	TIME [epoch: 11.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.834979236074262		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 1.834979236074262 | validation: 0.981603665426087]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8066522654385344		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 1.8066522654385344 | validation: 1.0154622917200786]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8106981467975525		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 1.8106981467975525 | validation: 0.8974037718079889]
	TIME [epoch: 11.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8092240790127812		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 1.8092240790127812 | validation: 1.0012819992704]
	TIME [epoch: 11.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8071573082973198		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 1.8071573082973198 | validation: 0.9032996536713236]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8223270067043549		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 1.8223270067043549 | validation: 0.8928699957174324]
	TIME [epoch: 11.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8513580329378454		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 1.8513580329378454 | validation: 1.0671301403475502]
	TIME [epoch: 11.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9060982781060387		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 1.9060982781060387 | validation: 1.0508782564475718]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8671514625223316		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 1.8671514625223316 | validation: 0.8906395498789601]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8740472011383842		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 1.8740472011383842 | validation: 0.8947288445788083]
	TIME [epoch: 11.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8448184911232959		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 1.8448184911232959 | validation: 0.9441800773312556]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7920545306663105		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 1.7920545306663105 | validation: 1.0712030770833678]
	TIME [epoch: 11.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.935887373085983		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 1.935887373085983 | validation: 0.9403181616796349]
	TIME [epoch: 11.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.850185626043475		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 1.850185626043475 | validation: 0.8848076726010907]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.777654496243775		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 1.777654496243775 | validation: 0.9246797234648783]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8140329934422161		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 1.8140329934422161 | validation: 0.9048769175159964]
	TIME [epoch: 11.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7881313363400186		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 1.7881313363400186 | validation: 0.8951604753681501]
	TIME [epoch: 11.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.791001090304691		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 1.791001090304691 | validation: 0.9090702204467053]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8162497274499996		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 1.8162497274499996 | validation: 0.9455187810728489]
	TIME [epoch: 11.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7958264952098388		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 1.7958264952098388 | validation: 0.9104898680750009]
	TIME [epoch: 11.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7859328280865667		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 1.7859328280865667 | validation: 0.929607740968493]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8251447788991728		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 1.8251447788991728 | validation: 0.9695706106075612]
	TIME [epoch: 11.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.810513601004697		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 1.810513601004697 | validation: 0.9195793193841777]
	TIME [epoch: 11.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7882617721107747		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 1.7882617721107747 | validation: 0.9133700311081162]
	TIME [epoch: 11.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7974500920576433		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 1.7974500920576433 | validation: 0.9080914724409829]
	TIME [epoch: 11.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8396515324923235		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 1.8396515324923235 | validation: 0.892295636060366]
	TIME [epoch: 11.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7827337268038486		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 1.7827337268038486 | validation: 0.9705795229596994]
	TIME [epoch: 11.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8209819818025959		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 1.8209819818025959 | validation: 0.9215355879026987]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7746385205214832		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 1.7746385205214832 | validation: 0.8934238869428407]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7994111691116084		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 1.7994111691116084 | validation: 0.9152039805166655]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8201989301541834		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 1.8201989301541834 | validation: 0.9203202291587855]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8130133212992332		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 1.8130133212992332 | validation: 1.0407541760999344]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8336184815201988		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 1.8336184815201988 | validation: 0.8953702040053828]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8082274524341206		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 1.8082274524341206 | validation: 0.9627658315773456]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8067303796237242		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 1.8067303796237242 | validation: 0.9632423049498462]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8023036199520925		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 1.8023036199520925 | validation: 0.9194701349649818]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.798958264207222		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 1.798958264207222 | validation: 0.9671950421474756]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8391260707440067		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 1.8391260707440067 | validation: 0.8997819781608554]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7856735430073587		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 1.7856735430073587 | validation: 0.8879454463041847]
	TIME [epoch: 11.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.794765990098017		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 1.794765990098017 | validation: 0.8989120519455861]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7847123584270719		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 1.7847123584270719 | validation: 0.8774666667795233]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_707.pth
	Model improved!!!
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.795139779786524		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 1.795139779786524 | validation: 0.905760872543702]
	TIME [epoch: 11.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8225194935309528		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 1.8225194935309528 | validation: 0.9041400959284579]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7958311759029317		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 1.7958311759029317 | validation: 0.886771846406273]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7780878107545128		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 1.7780878107545128 | validation: 0.9207969554434036]
	TIME [epoch: 11.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8104050164920462		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 1.8104050164920462 | validation: 0.9082183221727561]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.794436374867278		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 1.794436374867278 | validation: 0.8975621428328711]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7828869547948316		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 1.7828869547948316 | validation: 0.9098606161457076]
	TIME [epoch: 11.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8143327304216958		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 1.8143327304216958 | validation: 0.9066822789860497]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8162322164317202		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 1.8162322164317202 | validation: 1.078277758046293]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8281242874977568		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 1.8281242874977568 | validation: 0.9176892531631458]
	TIME [epoch: 11.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.787275136713078		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 1.787275136713078 | validation: 0.9274894497934892]
	TIME [epoch: 11.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7904887800881424		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 1.7904887800881424 | validation: 0.96519391064371]
	TIME [epoch: 11.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7935840520732649		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 1.7935840520732649 | validation: 0.9820234629866872]
	TIME [epoch: 11.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8480998835841782		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 1.8480998835841782 | validation: 0.9366275640280819]
	TIME [epoch: 11.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8034571125913579		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 1.8034571125913579 | validation: 0.9029328007640173]
	TIME [epoch: 11.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.777947801462354		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 1.777947801462354 | validation: 0.8969475034831033]
	TIME [epoch: 11.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7809609915623748		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 1.7809609915623748 | validation: 0.8880629991852784]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7939992188633205		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 1.7939992188633205 | validation: 1.0749270787768388]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8585691726268294		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 1.8585691726268294 | validation: 0.9525974758188761]
	TIME [epoch: 11.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.796240818845678		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 1.796240818845678 | validation: 0.904211181954486]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7913425142515844		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 1.7913425142515844 | validation: 0.9163207721430129]
	TIME [epoch: 11.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.803232015121214		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 1.803232015121214 | validation: 0.9397103496542684]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8018709087874887		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 1.8018709087874887 | validation: 0.9455666661545399]
	TIME [epoch: 11.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7887461333670942		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 1.7887461333670942 | validation: 0.9117784072150255]
	TIME [epoch: 11.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7718684617814513		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 1.7718684617814513 | validation: 0.8967258602621162]
	TIME [epoch: 11.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.809976781376487		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 1.809976781376487 | validation: 0.9653301219662705]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8106049990015445		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 1.8106049990015445 | validation: 0.891443693056116]
	TIME [epoch: 11.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7787743418093176		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 1.7787743418093176 | validation: 0.910180618857972]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7927691872970966		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 1.7927691872970966 | validation: 0.8989429927515602]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7820098429014077		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 1.7820098429014077 | validation: 0.9238781501018707]
	TIME [epoch: 11.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.800248633092513		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 1.800248633092513 | validation: 1.012483767866552]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8430358168339658		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 1.8430358168339658 | validation: 0.9097727505034149]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7894499209197214		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 1.7894499209197214 | validation: 0.96022414869275]
	TIME [epoch: 11.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8104915801970574		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 1.8104915801970574 | validation: 0.9206027065542469]
	TIME [epoch: 11.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7851505634419889		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 1.7851505634419889 | validation: 0.8754728409090038]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_742.pth
	Model improved!!!
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7642188717333123		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 1.7642188717333123 | validation: 0.878206568012026]
	TIME [epoch: 11.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.79965603128057		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 1.79965603128057 | validation: 0.945699273604481]
	TIME [epoch: 11.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.779981084302979		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 1.779981084302979 | validation: 0.9047366037119509]
	TIME [epoch: 11.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8368410214225368		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 1.8368410214225368 | validation: 0.9800870770764906]
	TIME [epoch: 11.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7919270392100832		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 1.7919270392100832 | validation: 0.8905105730673836]
	TIME [epoch: 11.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7788775217370776		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 1.7788775217370776 | validation: 0.9113595892099557]
	TIME [epoch: 11.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.878341184690465		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 1.878341184690465 | validation: 0.927695134145913]
	TIME [epoch: 11.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.817398818939629		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 1.817398818939629 | validation: 0.9820961256729673]
	TIME [epoch: 11.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8099201019451616		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 1.8099201019451616 | validation: 0.9039854037224171]
	TIME [epoch: 11.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.782149309176063		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 1.782149309176063 | validation: 0.8889977356641774]
	TIME [epoch: 11.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7780842518328062		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 1.7780842518328062 | validation: 0.9217239785014298]
	TIME [epoch: 11.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7954804071834505		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 1.7954804071834505 | validation: 0.8797633435388695]
	TIME [epoch: 11.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7904471108124893		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 1.7904471108124893 | validation: 0.9229016868795133]
	TIME [epoch: 11.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7845027129800988		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 1.7845027129800988 | validation: 0.8792369125402519]
	TIME [epoch: 11.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.794088781631309		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 1.794088781631309 | validation: 0.9134647704257853]
	TIME [epoch: 11.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7861285966422449		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 1.7861285966422449 | validation: 0.878005581897427]
	TIME [epoch: 11.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7780413109632187		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 1.7780413109632187 | validation: 0.9449959731311128]
	TIME [epoch: 11.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.79816629820338		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 1.79816629820338 | validation: 0.9156852786674539]
	TIME [epoch: 11.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7929106013641292		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 1.7929106013641292 | validation: 0.866029060389456]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_761.pth
	Model improved!!!
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8047965460711088		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 1.8047965460711088 | validation: 0.9012570697295147]
	TIME [epoch: 11.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.782825541439195		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 1.782825541439195 | validation: 0.8690500139252321]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8332667181863793		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 1.8332667181863793 | validation: 1.1462152885561012]
	TIME [epoch: 11.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8352534300824181		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 1.8352534300824181 | validation: 0.918231058334034]
	TIME [epoch: 11.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.798718239854662		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 1.798718239854662 | validation: 0.9541787946943945]
	TIME [epoch: 11.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8302543791178523		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 1.8302543791178523 | validation: 0.9132989129901372]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8591957870873808		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 1.8591957870873808 | validation: 0.9688376900073152]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7774824830712264		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 1.7774824830712264 | validation: 0.9154689323548892]
	TIME [epoch: 11.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.782093505418198		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 1.782093505418198 | validation: 0.912245419477566]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.805891205942048		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 1.805891205942048 | validation: 0.9116465194946138]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7997880673255315		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 1.7997880673255315 | validation: 0.9169785635703265]
	TIME [epoch: 11.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.804790290168268		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 1.804790290168268 | validation: 1.0125159437452647]
	TIME [epoch: 11.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.80389610983706		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 1.80389610983706 | validation: 0.8857795134417206]
	TIME [epoch: 11.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8082150897436033		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 1.8082150897436033 | validation: 0.9337397600325718]
	TIME [epoch: 11.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8014984958627183		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 1.8014984958627183 | validation: 0.8918304189695458]
	TIME [epoch: 11.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.77128893017312		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 1.77128893017312 | validation: 0.8986857514605384]
	TIME [epoch: 11.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.761860569540373		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 1.761860569540373 | validation: 0.9053284688468507]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7743585589457718		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 1.7743585589457718 | validation: 0.9636954768662573]
	TIME [epoch: 11.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7892517282131841		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 1.7892517282131841 | validation: 0.872126309442022]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7617351910286303		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 1.7617351910286303 | validation: 0.8901489759307017]
	TIME [epoch: 11.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.786089659338303		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 1.786089659338303 | validation: 0.9165858630788507]
	TIME [epoch: 11.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8026926660997378		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 1.8026926660997378 | validation: 0.9416756985207986]
	TIME [epoch: 11.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7920410341079576		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 1.7920410341079576 | validation: 0.9171231006375458]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.807072179533955		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 1.807072179533955 | validation: 0.8826872240647272]
	TIME [epoch: 11.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7976481419902846		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 1.7976481419902846 | validation: 1.0083950340252958]
	TIME [epoch: 11.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.800515058164786		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 1.800515058164786 | validation: 0.9026322828193071]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7624636026548535		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 1.7624636026548535 | validation: 0.8803913137557345]
	TIME [epoch: 11.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7747704996204354		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 1.7747704996204354 | validation: 0.9248109832007032]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8064022050761255		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 1.8064022050761255 | validation: 0.8726094276221216]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.764891190215066		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 1.764891190215066 | validation: 0.9246413616444862]
	TIME [epoch: 11.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7838194202110549		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 1.7838194202110549 | validation: 0.949404995511688]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.856578932593399		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 1.856578932593399 | validation: 0.875043630038573]
	TIME [epoch: 11.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8083650688294173		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 1.8083650688294173 | validation: 0.9674253548184354]
	TIME [epoch: 11.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8157034253622897		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 1.8157034253622897 | validation: 0.953612949386881]
	TIME [epoch: 11.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8213186238841312		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 1.8213186238841312 | validation: 0.9711191063610497]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7887676116838551		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 1.7887676116838551 | validation: 0.8824636163968318]
	TIME [epoch: 11.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.765003227827984		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 1.765003227827984 | validation: 0.8690060968952993]
	TIME [epoch: 11.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7530137594153987		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 1.7530137594153987 | validation: 0.8701810384249763]
	TIME [epoch: 11.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.779182978187233		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 1.779182978187233 | validation: 1.0847876629475754]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8249873982104448		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 1.8249873982104448 | validation: 0.8781888851650865]
	TIME [epoch: 11.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7681300165713576		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 1.7681300165713576 | validation: 0.8926904438674456]
	TIME [epoch: 11.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7655204269241815		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 1.7655204269241815 | validation: 0.9093823400497445]
	TIME [epoch: 11.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.798069494208543		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 1.798069494208543 | validation: 0.9198130493384581]
	TIME [epoch: 11.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8318431017388697		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 1.8318431017388697 | validation: 1.0237783592646377]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7962223531280732		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 1.7962223531280732 | validation: 0.9070687384303585]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7704921224550094		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 1.7704921224550094 | validation: 0.896259191294333]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7657618636365418		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 1.7657618636365418 | validation: 0.8866101833419094]
	TIME [epoch: 11.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7670162203220254		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 1.7670162203220254 | validation: 0.8717128819624601]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7542025716804908		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 1.7542025716804908 | validation: 0.8799262284098748]
	TIME [epoch: 11.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7669473589255613		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 1.7669473589255613 | validation: 0.9687724518823965]
	TIME [epoch: 11.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7873424406504639		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 1.7873424406504639 | validation: 0.9402844671150535]
	TIME [epoch: 11.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8158147430342875		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 1.8158147430342875 | validation: 0.9737655427232256]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7857504142044012		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 1.7857504142044012 | validation: 0.8989867039063978]
	TIME [epoch: 11.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7815477964437776		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 1.7815477964437776 | validation: 0.9082497384943529]
	TIME [epoch: 11.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7694926766898444		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 1.7694926766898444 | validation: 0.9770550557534319]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8050423076950777		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 1.8050423076950777 | validation: 0.8577521784737963]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_817.pth
	Model improved!!!
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7547710874687452		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 1.7547710874687452 | validation: 0.8878095557516553]
	TIME [epoch: 11.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7627140861143071		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 1.7627140861143071 | validation: 0.9870761833801388]
	TIME [epoch: 11.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.807850862907606		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 1.807850862907606 | validation: 0.8612976748232842]
	TIME [epoch: 11.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7678342075561098		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 1.7678342075561098 | validation: 0.8851451297949631]
	TIME [epoch: 11.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.757901775428818		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 1.757901775428818 | validation: 0.900910615042132]
	TIME [epoch: 11.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.767718728131492		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 1.767718728131492 | validation: 0.8753144202463259]
	TIME [epoch: 11.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.752649504529378		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 1.752649504529378 | validation: 0.9362324224206791]
	TIME [epoch: 11.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7889743340268476		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 1.7889743340268476 | validation: 0.8937684800642334]
	TIME [epoch: 11.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7615142912466337		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 1.7615142912466337 | validation: 0.9202965653328079]
	TIME [epoch: 11.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8193366498218841		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 1.8193366498218841 | validation: 0.8986363575548783]
	TIME [epoch: 11.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7770145484181818		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 1.7770145484181818 | validation: 0.9592480220361931]
	TIME [epoch: 11.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7794643519193567		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 1.7794643519193567 | validation: 0.9434355458500526]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8076941927174166		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 1.8076941927174166 | validation: 0.8768300199499044]
	TIME [epoch: 11.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.752868351034615		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 1.752868351034615 | validation: 0.917758270277454]
	TIME [epoch: 11.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7628094581248241		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 1.7628094581248241 | validation: 0.9238778676405062]
	TIME [epoch: 11.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.77449456732434		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 1.77449456732434 | validation: 0.8580560940080382]
	TIME [epoch: 11.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7544901416536973		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 1.7544901416536973 | validation: 0.8832089966342886]
	TIME [epoch: 11.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7543102389214345		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 1.7543102389214345 | validation: 0.8728213742968366]
	TIME [epoch: 11.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7658547963404199		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 1.7658547963404199 | validation: 0.8637607638640004]
	TIME [epoch: 11.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7826162113545063		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 1.7826162113545063 | validation: 0.8918426861853028]
	TIME [epoch: 11.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7956549897252856		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 1.7956549897252856 | validation: 0.8963638190313953]
	TIME [epoch: 11.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.769458859354803		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 1.769458859354803 | validation: 0.9803366275195065]
	TIME [epoch: 11.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7885333207794671		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 1.7885333207794671 | validation: 0.9465079538659897]
	TIME [epoch: 11.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7735617391336111		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 1.7735617391336111 | validation: 0.8703379688691493]
	TIME [epoch: 11.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7432566914970302		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 1.7432566914970302 | validation: 0.8716662013377935]
	TIME [epoch: 11.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.755504264633529		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 1.755504264633529 | validation: 0.8830696927347653]
	TIME [epoch: 11.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7609356125831768		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 1.7609356125831768 | validation: 0.8651414709243841]
	TIME [epoch: 11.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7505955657374699		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 1.7505955657374699 | validation: 0.8818233007003664]
	TIME [epoch: 11.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8326616687525044		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 1.8326616687525044 | validation: 0.8958235799774719]
	TIME [epoch: 11.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7656419951121487		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 1.7656419951121487 | validation: 0.9584241112365314]
	TIME [epoch: 11.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.811257589674396		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 1.811257589674396 | validation: 0.9553016502433542]
	TIME [epoch: 11.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7713705031272458		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 1.7713705031272458 | validation: 0.8825762534063007]
	TIME [epoch: 11.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7531663973546359		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 1.7531663973546359 | validation: 0.8703400877488988]
	TIME [epoch: 11.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.772350421710561		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 1.772350421710561 | validation: 0.8890377122945746]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7521317978222788		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 1.7521317978222788 | validation: 0.8591291602614968]
	TIME [epoch: 11.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7846136253907026		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 1.7846136253907026 | validation: 0.8941766163546717]
	TIME [epoch: 11.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.792830047880819		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 1.792830047880819 | validation: 0.8848985770535182]
	TIME [epoch: 11.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7495200707995313		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 1.7495200707995313 | validation: 0.8691197384337523]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.758861042361723		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 1.758861042361723 | validation: 0.9442272149111992]
	TIME [epoch: 11.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7848428184619012		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 1.7848428184619012 | validation: 0.8737211723841662]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.768132810566978		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 1.768132810566978 | validation: 0.9146941521778533]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8703564822165548		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 1.8703564822165548 | validation: 0.879608567105439]
	TIME [epoch: 11.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7661926015744824		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 1.7661926015744824 | validation: 0.8643095746230657]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7492408141446514		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 1.7492408141446514 | validation: 0.8664236367904826]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7554183645030623		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 1.7554183645030623 | validation: 0.8809352513890676]
	TIME [epoch: 11.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.754148327769431		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 1.754148327769431 | validation: 1.015289459270941]
	TIME [epoch: 11.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.812993760415089		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 1.812993760415089 | validation: 0.9145703024906728]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8382751577793675		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 1.8382751577793675 | validation: 1.0199529195217625]
	TIME [epoch: 11.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8125260362161917		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 1.8125260362161917 | validation: 0.9264238484308169]
	TIME [epoch: 11.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7911018208384641		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 1.7911018208384641 | validation: 0.9970910853051155]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8189958233381303		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 1.8189958233381303 | validation: 0.9199788779858655]
	TIME [epoch: 11.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.800664261444362		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 1.800664261444362 | validation: 0.9255290969312938]
	TIME [epoch: 11.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.783588322513904		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 1.783588322513904 | validation: 0.8990642554974997]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.787873472372876		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 1.787873472372876 | validation: 0.8765668442267929]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.819491556601978		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 1.819491556601978 | validation: 0.9691795629123021]
	TIME [epoch: 11.6 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7948206176644883		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 1.7948206176644883 | validation: 0.8751627680187534]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7571577664173588		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 1.7571577664173588 | validation: 0.920826967020588]
	TIME [epoch: 11.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8165089184580085		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 1.8165089184580085 | validation: 0.8585975074477934]
	TIME [epoch: 11.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8139563344768026		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 1.8139563344768026 | validation: 0.9458094742762638]
	TIME [epoch: 11.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.775702549360866		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 1.775702549360866 | validation: 0.8920711625094399]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7554755373638622		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 1.7554755373638622 | validation: 0.8756871179499878]
	TIME [epoch: 11.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7683577507113732		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 1.7683577507113732 | validation: 0.8912710903957934]
	TIME [epoch: 11.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.785629450805254		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 1.785629450805254 | validation: 0.8598940270542089]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7440565616511121		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 1.7440565616511121 | validation: 0.8784318715800705]
	TIME [epoch: 11.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.861822633295223		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 1.861822633295223 | validation: 0.9794088159501237]
	TIME [epoch: 11.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7922911539008577		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 1.7922911539008577 | validation: 0.9296825646965912]
	TIME [epoch: 11.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7835632268203523		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 1.7835632268203523 | validation: 0.8904784484310335]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.753029146372279		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 1.753029146372279 | validation: 0.9184614062311164]
	TIME [epoch: 11.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.759124447406119		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 1.759124447406119 | validation: 0.8663239442388351]
	TIME [epoch: 11.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7522699945597044		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 1.7522699945597044 | validation: 0.876484515253111]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7725342015367258		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 1.7725342015367258 | validation: 0.9179017466960414]
	TIME [epoch: 11.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7637713747603305		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 1.7637713747603305 | validation: 0.8786292851973991]
	TIME [epoch: 11.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7561380736298113		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 1.7561380736298113 | validation: 0.8715514837016174]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7503401249350938		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 1.7503401249350938 | validation: 0.8859662261476882]
	TIME [epoch: 11.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7571419932079433		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 1.7571419932079433 | validation: 0.8831631184692152]
	TIME [epoch: 11.6 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7578562403177225		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 1.7578562403177225 | validation: 0.8988412112368844]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7839666512898318		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 1.7839666512898318 | validation: 0.867263533046704]
	TIME [epoch: 11.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.782007629227604		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 1.782007629227604 | validation: 0.9333792712567177]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.805829183450199		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 1.805829183450199 | validation: 1.1000716387640594]
	TIME [epoch: 11.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.862007949399331		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 1.862007949399331 | validation: 1.0481701311737135]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8200819366700864		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 1.8200819366700864 | validation: 0.8748622316118955]
	TIME [epoch: 11.6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.756964112192187		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 1.756964112192187 | validation: 0.8731335684763386]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7783083675390001		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 1.7783083675390001 | validation: 0.9647334654476799]
	TIME [epoch: 11.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8336602766995767		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 1.8336602766995767 | validation: 1.1747892474521868]
	TIME [epoch: 11.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.972243235733615		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 1.972243235733615 | validation: 0.9551487641653087]
	TIME [epoch: 11.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7756469950285156		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 1.7756469950285156 | validation: 0.8961696287902523]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.775754096918131		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 1.775754096918131 | validation: 0.9226725535423314]
	TIME [epoch: 11.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7660176808198607		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 1.7660176808198607 | validation: 0.88543964703722]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7718061235199412		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 1.7718061235199412 | validation: 0.879415150598294]
	TIME [epoch: 11.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7665552316843218		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 1.7665552316843218 | validation: 0.921089288781085]
	TIME [epoch: 11.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.757326138638035		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 1.757326138638035 | validation: 0.879998818898153]
	TIME [epoch: 11.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.782899776438211		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 1.782899776438211 | validation: 0.9059730534982896]
	TIME [epoch: 11.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7810016420714232		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 1.7810016420714232 | validation: 0.8768245761654113]
	TIME [epoch: 11.6 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7581174721006325		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 1.7581174721006325 | validation: 0.8660430012545576]
	TIME [epoch: 11.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.750075305058797		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 1.750075305058797 | validation: 0.9648816178944489]
	TIME [epoch: 11.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.804696289793441		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 1.804696289793441 | validation: 0.8991332752715591]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7625383992710604		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 1.7625383992710604 | validation: 0.9232082547266879]
	TIME [epoch: 11.6 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.779859937699281		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 1.779859937699281 | validation: 1.1137807569928477]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8237869852447903		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 1.8237869852447903 | validation: 0.8725621580902129]
	TIME [epoch: 11.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7875352629216121		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 1.7875352629216121 | validation: 0.8856541931002799]
	TIME [epoch: 11.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.772632503189911		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 1.772632503189911 | validation: 0.9073549943106517]
	TIME [epoch: 11.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7557959245843835		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 1.7557959245843835 | validation: 0.8779298617611585]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.746240005002697		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 1.746240005002697 | validation: 0.8643253376823737]
	TIME [epoch: 11.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7686364357812743		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 1.7686364357812743 | validation: 0.8872416466893295]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7864419539264815		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 1.7864419539264815 | validation: 1.115413213437014]
	TIME [epoch: 11.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9617217121448762		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 1.9617217121448762 | validation: 0.9436808600892252]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7776884390887089		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 1.7776884390887089 | validation: 0.8771246763177071]
	TIME [epoch: 11.6 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7841732880418095		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 1.7841732880418095 | validation: 1.0598733052913838]
	TIME [epoch: 11.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8301961086936112		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 1.8301961086936112 | validation: 0.9113881231600306]
	TIME [epoch: 11.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7899130934680976		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 1.7899130934680976 | validation: 0.8709643971065907]
	TIME [epoch: 11.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7463478508577857		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 1.7463478508577857 | validation: 0.8920486125568441]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7615644729553512		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 1.7615644729553512 | validation: 0.8797831136608995]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7675702149290329		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 1.7675702149290329 | validation: 0.8709729226987921]
	TIME [epoch: 11.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.750420934611598		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 1.750420934611598 | validation: 0.8746284482425917]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7572420032592544		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 1.7572420032592544 | validation: 0.9220995701517685]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7829113448951657		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 1.7829113448951657 | validation: 0.9773860403721721]
	TIME [epoch: 11.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7691353824520752		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 1.7691353824520752 | validation: 0.8870826851201866]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7485730927038823		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 1.7485730927038823 | validation: 0.8693264283645394]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7793225119462681		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 1.7793225119462681 | validation: 0.9050343158520598]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7664197786002538		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 1.7664197786002538 | validation: 0.8616208042259997]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.751602701908629		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 1.751602701908629 | validation: 0.8742018000448988]
	TIME [epoch: 11.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.754771464140636		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 1.754771464140636 | validation: 0.8619931043294742]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7585121365545606		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 1.7585121365545606 | validation: 0.8678618500525744]
	TIME [epoch: 11.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.757284100061952		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 1.757284100061952 | validation: 0.9771623294662435]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8550519224793387		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 1.8550519224793387 | validation: 0.8838770727259595]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7500577652614264		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 1.7500577652614264 | validation: 0.868572118628825]
	TIME [epoch: 11.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.746454278434252		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 1.746454278434252 | validation: 0.8715491887157252]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7562762437848578		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 1.7562762437848578 | validation: 0.8841210990620596]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7701117000840678		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 1.7701117000840678 | validation: 0.8921350402427193]
	TIME [epoch: 11.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7641508814162807		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 1.7641508814162807 | validation: 0.8657986950284005]
	TIME [epoch: 11.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.758903179323605		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 1.758903179323605 | validation: 0.9399421742298004]
	TIME [epoch: 11.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.813852972754461		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 1.813852972754461 | validation: 0.920235427020348]
	TIME [epoch: 11.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7713651743377476		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 1.7713651743377476 | validation: 1.0118233371831606]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.846386133335761		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 1.846386133335761 | validation: 0.8948083331947903]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.75288519076613		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 1.75288519076613 | validation: 0.8641166406371048]
	TIME [epoch: 11.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7431974179597909		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 1.7431974179597909 | validation: 0.858793322603988]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7429809288129725		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 1.7429809288129725 | validation: 0.889630503278206]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7517444126544688		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 1.7517444126544688 | validation: 0.8870995369182518]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8621248065671543		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 1.8621248065671543 | validation: 1.214605421048819]
	TIME [epoch: 11.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.918252380753925		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 1.918252380753925 | validation: 0.9545838103782289]
	TIME [epoch: 11.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7593909759481512		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 1.7593909759481512 | validation: 0.8714870561822085]
	TIME [epoch: 11.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7545215096995572		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 1.7545215096995572 | validation: 0.9019739000324808]
	TIME [epoch: 11.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7696973925595976		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 1.7696973925595976 | validation: 0.8823688172725426]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7627125860289303		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 1.7627125860289303 | validation: 0.9147184317725181]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7735557371175106		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 1.7735557371175106 | validation: 0.957784969686964]
	TIME [epoch: 11.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.778249426911539		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 1.778249426911539 | validation: 0.8889696530527664]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7542000772281139		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 1.7542000772281139 | validation: 0.9556078482827826]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.806416549260728		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 1.806416549260728 | validation: 0.8689754475632977]
	TIME [epoch: 11.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7680588754743822		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 1.7680588754743822 | validation: 0.8703628932469636]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7419996234012962		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 1.7419996234012962 | validation: 0.8699568836223063]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7563916915844346		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 1.7563916915844346 | validation: 0.882228506977685]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.746933231153218		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 1.746933231153218 | validation: 0.8686014259963086]
	TIME [epoch: 11.6 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7619718743983483		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 1.7619718743983483 | validation: 0.9407088611707098]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8091680643522359		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 1.8091680643522359 | validation: 0.8975821662526633]
	TIME [epoch: 11.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7496883778353978		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 1.7496883778353978 | validation: 0.8632129567120091]
	TIME [epoch: 11.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7615205958109885		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 1.7615205958109885 | validation: 0.9337732996949055]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7732801535323568		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 1.7732801535323568 | validation: 0.8909700802250586]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7903743784586328		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 1.7903743784586328 | validation: 0.9119889108038254]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7955441385151585		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 1.7955441385151585 | validation: 0.8959731699941447]
	TIME [epoch: 11.6 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7541591619630958		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 1.7541591619630958 | validation: 0.89265580682604]
	TIME [epoch: 11.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7739354280392776		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 1.7739354280392776 | validation: 0.9182587619518582]
	TIME [epoch: 11.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7656024066278715		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 1.7656024066278715 | validation: 0.8580095093672029]
	TIME [epoch: 11.6 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7468493243156908		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 1.7468493243156908 | validation: 0.8573775978987308]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_980.pth
	Model improved!!!
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7543444554611907		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 1.7543444554611907 | validation: 0.8761350198755682]
	TIME [epoch: 11.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7552060468011286		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 1.7552060468011286 | validation: 0.8777846207824104]
	TIME [epoch: 11.6 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7493425751122733		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 1.7493425751122733 | validation: 0.8689211341527607]
	TIME [epoch: 11.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7561327667634905		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 1.7561327667634905 | validation: 0.8657971632894277]
	TIME [epoch: 11.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7503557450364913		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 1.7503557450364913 | validation: 0.8659398838150623]
	TIME [epoch: 11.6 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7472262575719077		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 1.7472262575719077 | validation: 0.8705361597457955]
	TIME [epoch: 11.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7970947588066084		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 1.7970947588066084 | validation: 0.8950856830682389]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7509159557852096		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 1.7509159557852096 | validation: 0.9060308464220813]
	TIME [epoch: 11.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8430140164661681		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 1.8430140164661681 | validation: 0.9702543396609338]
	TIME [epoch: 11.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7638085281251192		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 1.7638085281251192 | validation: 0.8834044954790364]
	TIME [epoch: 11.6 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8112601856066657		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 1.8112601856066657 | validation: 0.9256345025509813]
	TIME [epoch: 11.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8012011475005154		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 1.8012011475005154 | validation: 0.9691600488358246]
	TIME [epoch: 11.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.771611018537959		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 1.771611018537959 | validation: 0.916711172765773]
	TIME [epoch: 11.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7753722268722745		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 1.7753722268722745 | validation: 0.8704359310967719]
	TIME [epoch: 11.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7508995595091845		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 1.7508995595091845 | validation: 0.8617141778629183]
	TIME [epoch: 11.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7640262762712047		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 1.7640262762712047 | validation: 0.9077834282930788]
	TIME [epoch: 11.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.747307256490835		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 1.747307256490835 | validation: 0.8775076652284437]
	TIME [epoch: 11.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7502191928958515		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 1.7502191928958515 | validation: 0.8832025676531388]
	TIME [epoch: 11.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7586509112749795		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 1.7586509112749795 | validation: 0.9039955643093716]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7499334778006692		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 1.7499334778006692 | validation: 0.8916793406083716]
	TIME [epoch: 11.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7780192192730084		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 1.7780192192730084 | validation: 0.8960988997493097]
	TIME [epoch: 11.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.789692091303341		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 1.789692091303341 | validation: 0.9261227491010194]
	TIME [epoch: 11.6 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.767003354785304		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 1.767003354785304 | validation: 0.8935860981073319]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7732789316678998		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 1.7732789316678998 | validation: 0.8809883336757125]
	TIME [epoch: 11.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7525012881873798		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 1.7525012881873798 | validation: 0.9130494462610272]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9698269481102377		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 1.9698269481102377 | validation: 1.13826959062158]
	TIME [epoch: 11.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8294905355006332		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 1.8294905355006332 | validation: 0.8501065460301872]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_1007.pth
	Model improved!!!
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7541201873328678		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 1.7541201873328678 | validation: 0.9096747456566103]
	TIME [epoch: 11.6 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.761299611805704		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 1.761299611805704 | validation: 0.86800082335058]
	TIME [epoch: 11.6 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7961830531872447		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 1.7961830531872447 | validation: 0.9584182441048527]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7724451809100108		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 1.7724451809100108 | validation: 0.926561694081108]
	TIME [epoch: 11.6 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7650052336058637		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 1.7650052336058637 | validation: 0.8637913115544913]
	TIME [epoch: 11.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7443847156516696		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 1.7443847156516696 | validation: 0.8540370902405938]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7631060454491083		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 1.7631060454491083 | validation: 0.92668859240798]
	TIME [epoch: 11.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8389337237840735		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 1.8389337237840735 | validation: 1.0205229767008395]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.794674121207075		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 1.794674121207075 | validation: 0.9399571301858908]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7635055010385283		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 1.7635055010385283 | validation: 0.9077215096068245]
	TIME [epoch: 11.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7848669677269875		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 1.7848669677269875 | validation: 0.872170616295461]
	TIME [epoch: 11.6 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7603023177874566		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 1.7603023177874566 | validation: 0.887929686315655]
	TIME [epoch: 11.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7658829043475213		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 1.7658829043475213 | validation: 0.8675304022640647]
	TIME [epoch: 11.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7456540297976688		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 1.7456540297976688 | validation: 0.8668403631705939]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7441030994844042		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 1.7441030994844042 | validation: 0.8737050079781864]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7550279376128182		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 1.7550279376128182 | validation: 0.9084592184052582]
	TIME [epoch: 11.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7600978933518272		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 1.7600978933518272 | validation: 0.8856691861199663]
	TIME [epoch: 11.6 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7470123253448602		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 1.7470123253448602 | validation: 0.8548169484466649]
	TIME [epoch: 11.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7440777067491964		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 1.7440777067491964 | validation: 0.8595380452589169]
	TIME [epoch: 11.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7526974245620668		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 1.7526974245620668 | validation: 0.874288917968567]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7486023360683263		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 1.7486023360683263 | validation: 0.86694916557451]
	TIME [epoch: 11.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7396066356208086		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 1.7396066356208086 | validation: 0.8572939290860919]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7546934754740877		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 1.7546934754740877 | validation: 0.8935537276746964]
	TIME [epoch: 11.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7495598045928626		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 1.7495598045928626 | validation: 0.8640723723314406]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7380618437645097		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 1.7380618437645097 | validation: 0.8782287671028621]
	TIME [epoch: 11.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7466624734072624		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 1.7466624734072624 | validation: 0.8576004810363185]
	TIME [epoch: 11.6 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7423705321057774		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 1.7423705321057774 | validation: 0.8851052789854645]
	TIME [epoch: 11.6 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7598419310636628		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 1.7598419310636628 | validation: 0.8585487804492078]
	TIME [epoch: 11.6 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7489304744172274		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 1.7489304744172274 | validation: 0.8756756476712765]
	TIME [epoch: 11.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7556269296326192		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 1.7556269296326192 | validation: 0.8855898521021416]
	TIME [epoch: 11.6 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7869590728576574		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 1.7869590728576574 | validation: 0.9379608234953354]
	TIME [epoch: 11.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7704998768607727		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 1.7704998768607727 | validation: 0.8730454330309303]
	TIME [epoch: 11.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7490675539594331		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 1.7490675539594331 | validation: 0.8654277572684589]
	TIME [epoch: 11.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7439737223302294		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 1.7439737223302294 | validation: 0.8877844486997246]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7620046383177583		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 1.7620046383177583 | validation: 0.8551257721258756]
	TIME [epoch: 11.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7504566539603932		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 1.7504566539603932 | validation: 0.9245616466091687]
	TIME [epoch: 11.6 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7795024682239804		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 1.7795024682239804 | validation: 0.8823364096632083]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7420316664496052		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 1.7420316664496052 | validation: 0.8588287471452756]
	TIME [epoch: 11.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7681499255736626		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 1.7681499255736626 | validation: 0.9514660381500855]
	TIME [epoch: 11.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7794653654573005		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 1.7794653654573005 | validation: 0.854888383077509]
	TIME [epoch: 11.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7446569096320261		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 1.7446569096320261 | validation: 0.8984037943451074]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7647785036197903		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 1.7647785036197903 | validation: 0.9266141807375254]
	TIME [epoch: 11.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.878361621867573		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 1.878361621867573 | validation: 0.9875210927385348]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7968156337628067		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 1.7968156337628067 | validation: 0.8598352066942841]
	TIME [epoch: 11.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7463969036478197		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 1.7463969036478197 | validation: 0.8495118658189807]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_1052.pth
	Model improved!!!
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7708581680670306		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 1.7708581680670306 | validation: 0.9051219042530855]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.761667826818286		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 1.761667826818286 | validation: 0.8914676448282924]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.754897444188439		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 1.754897444188439 | validation: 0.8661559882763118]
	TIME [epoch: 11.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7468602429614222		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 1.7468602429614222 | validation: 0.8696900367471153]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7505789100318927		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 1.7505789100318927 | validation: 0.8776913834243317]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7464129262757673		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 1.7464129262757673 | validation: 0.8588891610294457]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7645890634424346		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 1.7645890634424346 | validation: 0.8544529904718331]
	TIME [epoch: 11.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7363259943498426		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 1.7363259943498426 | validation: 0.8467139249782099]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_1060.pth
	Model improved!!!
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7404389275269245		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 1.7404389275269245 | validation: 0.8596622656792218]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7449365223058397		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 1.7449365223058397 | validation: 0.8641446181118049]
	TIME [epoch: 11.6 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.744639524993135		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 1.744639524993135 | validation: 0.8542532456565186]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7344373907453943		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 1.7344373907453943 | validation: 0.8544071367571762]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7418690959456204		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 1.7418690959456204 | validation: 0.8714555407124399]
	TIME [epoch: 11.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7443245457938779		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 1.7443245457938779 | validation: 0.8774881996269484]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7384403546880276		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 1.7384403546880276 | validation: 0.861242486726556]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7435085389650378		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 1.7435085389650378 | validation: 0.8625586163152886]
	TIME [epoch: 11.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7539269676175824		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 1.7539269676175824 | validation: 0.8965526876884172]
	TIME [epoch: 11.6 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7652761923119589		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 1.7652761923119589 | validation: 0.9179340143864648]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7624406443561207		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 1.7624406443561207 | validation: 0.86409858963251]
	TIME [epoch: 11.6 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7438659056203805		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 1.7438659056203805 | validation: 0.8588446993471797]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.752736423497403		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 1.752736423497403 | validation: 0.8714819774287473]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.75023584274735		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 1.75023584274735 | validation: 0.8522145328366415]
	TIME [epoch: 11.6 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7485197102906653		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 1.7485197102906653 | validation: 0.8933468593864092]
	TIME [epoch: 11.6 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7532848574318092		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 1.7532848574318092 | validation: 0.8800501352330204]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.758668852921486		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 1.758668852921486 | validation: 0.9088202563186616]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7591526077215445		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 1.7591526077215445 | validation: 0.8757844863585809]
	TIME [epoch: 11.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.772370305481698		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 1.772370305481698 | validation: 0.9069724166293602]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.751681264930984		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 1.751681264930984 | validation: 0.8693059633545085]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7507888146552029		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 1.7507888146552029 | validation: 0.8703308101965075]
	TIME [epoch: 11.6 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7536751985888672		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 1.7536751985888672 | validation: 0.8646322376329332]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7398549461414514		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 1.7398549461414514 | validation: 0.8940522019974233]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7636156022058747		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 1.7636156022058747 | validation: 0.8716400394221583]
	TIME [epoch: 11.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7561620299768748		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 1.7561620299768748 | validation: 0.945389405181077]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8386459706417244		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 1.8386459706417244 | validation: 0.9918141220558875]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.814032138792662		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 1.814032138792662 | validation: 0.8645544943137264]
	TIME [epoch: 11.6 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7518970799052567		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 1.7518970799052567 | validation: 0.8652309700803719]
	TIME [epoch: 11.6 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.74624324024432		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 1.74624324024432 | validation: 0.861003602124429]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7406729702602883		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 1.7406729702602883 | validation: 0.8668190451404428]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7385049157974863		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 1.7385049157974863 | validation: 0.867101539142066]
	TIME [epoch: 11.6 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7393370666484766		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 1.7393370666484766 | validation: 0.855917854458115]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7434052219670952		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 1.7434052219670952 | validation: 0.8606122904986593]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7480163268166207		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 1.7480163268166207 | validation: 0.8890817926586485]
	TIME [epoch: 11.6 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7539642392445676		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 1.7539642392445676 | validation: 0.887640172132131]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7670873978183463		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 1.7670873978183463 | validation: 0.8771769331626706]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7450820289124487		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 1.7450820289124487 | validation: 0.8761234625524166]
	TIME [epoch: 11.6 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.76107336299634		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 1.76107336299634 | validation: 0.8707648645744402]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7441420854433392		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 1.7441420854433392 | validation: 0.8643739614076864]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7668970171745908		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 1.7668970171745908 | validation: 0.9090402949138777]
	TIME [epoch: 11.6 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7532465003958637		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 1.7532465003958637 | validation: 0.872682438256231]
	TIME [epoch: 11.6 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7479859206550423		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 1.7479859206550423 | validation: 0.8574833229441343]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.753645575132763		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 1.753645575132763 | validation: 0.8734952809903955]
	TIME [epoch: 11.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.767955188100117		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 1.767955188100117 | validation: 0.910263740227318]
	TIME [epoch: 11.6 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7652047675734568		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 1.7652047675734568 | validation: 0.8726696857441364]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7432132226429196		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 1.7432132226429196 | validation: 0.861429725741493]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7406833258702679		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 1.7406833258702679 | validation: 0.8704058176187494]
	TIME [epoch: 11.6 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7509184661741117		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 1.7509184661741117 | validation: 0.8979406128384928]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7666597504155752		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 1.7666597504155752 | validation: 0.9220967039492927]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7717394031189049		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 1.7717394031189049 | validation: 0.8639670334683075]
	TIME [epoch: 11.6 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7494342780984358		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 1.7494342780984358 | validation: 0.8666688186138235]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.746498278623262		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 1.746498278623262 | validation: 0.8839523816819201]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7646763189331125		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 1.7646763189331125 | validation: 0.8866195530130487]
	TIME [epoch: 11.6 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7671588827415263		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 1.7671588827415263 | validation: 0.8701859658564317]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7490709002446094		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 1.7490709002446094 | validation: 0.8694550837256361]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7608671560292481		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 1.7608671560292481 | validation: 0.8692025398094577]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7500059241413104		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 1.7500059241413104 | validation: 0.8728825932242871]
	TIME [epoch: 11.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7505593678626958		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 1.7505593678626958 | validation: 0.869809795144889]
	TIME [epoch: 11.6 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7408462653375776		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 1.7408462653375776 | validation: 0.8559256125107502]
	TIME [epoch: 11.6 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7398360488906075		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 1.7398360488906075 | validation: 0.8700199302716228]
	TIME [epoch: 11.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.760299077561951		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 1.760299077561951 | validation: 0.899115215089549]
	TIME [epoch: 11.6 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.768806806440771		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 1.768806806440771 | validation: 0.871156894844585]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.739789492511961		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 1.739789492511961 | validation: 0.8609287710291761]
	TIME [epoch: 11.6 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.746323560897552		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 1.746323560897552 | validation: 0.8682544282220863]
	TIME [epoch: 11.6 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7439665980235077		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 1.7439665980235077 | validation: 0.8628240228000854]
	TIME [epoch: 11.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7440905432245675		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 1.7440905432245675 | validation: 0.8613895648379821]
	TIME [epoch: 11.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7475486101989546		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 1.7475486101989546 | validation: 0.861119649492571]
	TIME [epoch: 11.6 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7505244965755804		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 1.7505244965755804 | validation: 0.8668913160036358]
	TIME [epoch: 11.6 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.744785985423564		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 1.744785985423564 | validation: 0.8695879935442793]
	TIME [epoch: 11.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7574520682680659		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 1.7574520682680659 | validation: 0.877445029818868]
	TIME [epoch: 11.6 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7468676873289979		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 1.7468676873289979 | validation: 0.8669603163902636]
	TIME [epoch: 11.6 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.74814723448432		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 1.74814723448432 | validation: 0.8686316059449979]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7565462844449737		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 1.7565462844449737 | validation: 0.8764278277162802]
	TIME [epoch: 11.6 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.751761548098259		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 1.751761548098259 | validation: 0.8595172730855163]
	TIME [epoch: 11.6 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7461912742236851		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 1.7461912742236851 | validation: 0.8690172063069195]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7611613955402423		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 1.7611613955402423 | validation: 0.8785097876793448]
	TIME [epoch: 11.6 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7488149340620565		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 1.7488149340620565 | validation: 0.8620354402341026]
	TIME [epoch: 11.6 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.737391449098744		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 1.737391449098744 | validation: 0.8766864484338501]
	TIME [epoch: 11.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7528254811225819		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 1.7528254811225819 | validation: 0.8523964426005912]
	TIME [epoch: 11.6 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7352992287011522		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 1.7352992287011522 | validation: 0.852587912738825]
	TIME [epoch: 11.6 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7340632188837188		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 1.7340632188837188 | validation: 0.865393874938869]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.740293412561523		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 1.740293412561523 | validation: 0.873214082488687]
	TIME [epoch: 11.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7399055535290027		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 1.7399055535290027 | validation: 0.8741407985040954]
	TIME [epoch: 11.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.751150523529938		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 1.751150523529938 | validation: 0.8608572578645197]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7385754206810775		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 1.7385754206810775 | validation: 0.8686091262679986]
	TIME [epoch: 11.6 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7348059068157686		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 1.7348059068157686 | validation: 0.8655683754790537]
	TIME [epoch: 11.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7365742475905237		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 1.7365742475905237 | validation: 0.8540047682449697]
	TIME [epoch: 11.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7336124472128236		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 1.7336124472128236 | validation: 0.8626226417167309]
	TIME [epoch: 11.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7559417325837468		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 1.7559417325837468 | validation: 0.875855506403745]
	TIME [epoch: 11.6 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.747749551985262		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 1.747749551985262 | validation: 0.8759118636285832]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7449792376549735		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 1.7449792376549735 | validation: 0.8799630020114677]
	TIME [epoch: 11.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.766873261978103		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 1.766873261978103 | validation: 0.8664267013511626]
	TIME [epoch: 11.6 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7377974376713072		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 1.7377974376713072 | validation: 0.8463935706656658]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_1153.pth
	Model improved!!!
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7352321527375627		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 1.7352321527375627 | validation: 0.8609696419080216]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7410769323333333		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 1.7410769323333333 | validation: 0.8553235447087565]
	TIME [epoch: 11.6 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7415138177843343		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 1.7415138177843343 | validation: 0.8674144424863927]
	TIME [epoch: 11.6 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7385866041266131		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 1.7385866041266131 | validation: 0.8590405108546699]
	TIME [epoch: 11.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7383782327530057		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 1.7383782327530057 | validation: 0.8532125293732358]
	TIME [epoch: 11.6 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7400849537190628		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 1.7400849537190628 | validation: 0.8830543393998325]
	TIME [epoch: 11.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7415510849892923		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 1.7415510849892923 | validation: 0.8567240828180751]
	TIME [epoch: 11.6 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7482410355085787		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 1.7482410355085787 | validation: 0.888714301457228]
	TIME [epoch: 11.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7779385461102324		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 1.7779385461102324 | validation: 0.8764187964657321]
	TIME [epoch: 11.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7450075275719548		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 1.7450075275719548 | validation: 0.8620324344673526]
	TIME [epoch: 11.6 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.733839260259301		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 1.733839260259301 | validation: 0.8568877779375255]
	TIME [epoch: 11.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7441844594151605		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 1.7441844594151605 | validation: 0.8571784482432468]
	TIME [epoch: 11.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7427432913740466		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 1.7427432913740466 | validation: 0.8612014130832598]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7386646365936818		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 1.7386646365936818 | validation: 0.8837764652084651]
	TIME [epoch: 11.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7489622530884172		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 1.7489622530884172 | validation: 0.8814608023146886]
	TIME [epoch: 11.6 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7484200566882857		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 1.7484200566882857 | validation: 0.8954188217734744]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.766375801469073		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 1.766375801469073 | validation: 0.8884419804314871]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7419380721923758		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 1.7419380721923758 | validation: 0.8642489884942153]
	TIME [epoch: 11.6 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.744611421075638		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 1.744611421075638 | validation: 0.8780590945806305]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7387708609076835		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 1.7387708609076835 | validation: 0.88178996026775]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7453494006958188		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 1.7453494006958188 | validation: 0.8660060892214004]
	TIME [epoch: 11.6 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7405001606107797		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 1.7405001606107797 | validation: 0.85331256491461]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7619849893666066		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 1.7619849893666066 | validation: 0.8995919303512282]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.748185906110291		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 1.748185906110291 | validation: 0.8725432171186593]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7588579154848252		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 1.7588579154848252 | validation: 0.8946356000060304]
	TIME [epoch: 11.6 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7547847620860237		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 1.7547847620860237 | validation: 0.8502556865093033]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7375092845382594		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 1.7375092845382594 | validation: 0.8531713626569272]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7414192587800805		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 1.7414192587800805 | validation: 0.8755290281675798]
	TIME [epoch: 11.6 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.737348025216738		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 1.737348025216738 | validation: 0.866207338713314]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.773048262304464		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 1.773048262304464 | validation: 0.9446234003213491]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7758666761485256		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 1.7758666761485256 | validation: 0.8927106473861006]
	TIME [epoch: 11.6 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.744209381739522		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 1.744209381739522 | validation: 0.8621296864871262]
	TIME [epoch: 11.6 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7387846711503943		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 1.7387846711503943 | validation: 0.8756497234505646]
	TIME [epoch: 11.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7526241083398317		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 1.7526241083398317 | validation: 0.9012925168509709]
	TIME [epoch: 11.6 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.750751760275747		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 1.750751760275747 | validation: 0.8534150982486413]
	TIME [epoch: 11.6 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7338000599291048		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 1.7338000599291048 | validation: 0.8492416779939137]
	TIME [epoch: 11.6 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7399337165092001		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 1.7399337165092001 | validation: 0.8639411460187946]
	TIME [epoch: 11.6 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.747806958754794		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 1.747806958754794 | validation: 0.8724713856660639]
	TIME [epoch: 11.6 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7660519530817749		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 1.7660519530817749 | validation: 0.8831876629816975]
	TIME [epoch: 11.6 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.755364183036254		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 1.755364183036254 | validation: 0.871768920423427]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7740037740144987		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 1.7740037740144987 | validation: 0.904547227246112]
	TIME [epoch: 11.6 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.778595807485446		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 1.778595807485446 | validation: 0.8726474572742515]
	TIME [epoch: 11.6 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.750478181058447		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 1.750478181058447 | validation: 0.8529104226459926]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7365019847053198		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 1.7365019847053198 | validation: 0.8560781709405333]
	TIME [epoch: 11.6 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7388487937241242		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 1.7388487937241242 | validation: 0.8557159574328886]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7346181799087212		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 1.7346181799087212 | validation: 0.8563773717156937]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7405259532832735		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 1.7405259532832735 | validation: 0.8709479952465177]
	TIME [epoch: 11.6 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.739561709924002		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 1.739561709924002 | validation: 0.8618869066411631]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7356737618790752		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 1.7356737618790752 | validation: 0.8530846994383942]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.734021111605531		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 1.734021111605531 | validation: 0.8459645722273595]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_1203.pth
	Model improved!!!
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7369013266947422		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 1.7369013266947422 | validation: 0.8534243546415808]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.736518460918491		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 1.736518460918491 | validation: 0.8494908018042739]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7394586967193653		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 1.7394586967193653 | validation: 0.8510049249985272]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7428089578413632		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 1.7428089578413632 | validation: 0.8788032354016773]
	TIME [epoch: 11.6 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7555742934892955		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 1.7555742934892955 | validation: 0.8681739971872687]
	TIME [epoch: 11.6 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7427616796124532		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 1.7427616796124532 | validation: 0.8551292081282403]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7433877169542173		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 1.7433877169542173 | validation: 0.8713507675377922]
	TIME [epoch: 11.6 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7501062974693649		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 1.7501062974693649 | validation: 0.8650782057052502]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7371295069667414		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 1.7371295069667414 | validation: 0.8633583319370769]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7432821232279108		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 1.7432821232279108 | validation: 0.8659547363884477]
	TIME [epoch: 11.6 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.735042280500262		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 1.735042280500262 | validation: 0.8591847377270321]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.745052505966036		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 1.745052505966036 | validation: 0.8761461011253442]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7487996012659786		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 1.7487996012659786 | validation: 0.8937043305500936]
	TIME [epoch: 11.6 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.770461287542692		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 1.770461287542692 | validation: 0.9070738466533612]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7665992357008249		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 1.7665992357008249 | validation: 0.9356526980400615]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.807225013531986		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 1.807225013531986 | validation: 0.9631801858876838]
	TIME [epoch: 11.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7903547169418954		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 1.7903547169418954 | validation: 0.9162708756458966]
	TIME [epoch: 11.6 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7585690083948295		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 1.7585690083948295 | validation: 0.8658918430945275]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.744671639678236		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 1.744671639678236 | validation: 0.8878075094759023]
	TIME [epoch: 11.6 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7510398270481375		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 1.7510398270481375 | validation: 0.8649843725169799]
	TIME [epoch: 11.6 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7405872966590927		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 1.7405872966590927 | validation: 0.8651829879262682]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7348844747855638		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 1.7348844747855638 | validation: 0.848702121727375]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7364557130252836		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 1.7364557130252836 | validation: 0.8472690039162979]
	TIME [epoch: 11.6 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7346017281150652		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 1.7346017281150652 | validation: 0.8633214345483787]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7423569294163608		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 1.7423569294163608 | validation: 0.8682709993078467]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7413490362488453		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 1.7413490362488453 | validation: 0.8540833566602182]
	TIME [epoch: 11.6 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7347116221002055		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 1.7347116221002055 | validation: 0.8560067005573595]
	TIME [epoch: 11.6 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7342015644044804		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 1.7342015644044804 | validation: 0.8630268766770084]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7354128603761825		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 1.7354128603761825 | validation: 0.8703694613813483]
	TIME [epoch: 11.6 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7477744681097005		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 1.7477744681097005 | validation: 0.8679046621573328]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7356738866116381		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 1.7356738866116381 | validation: 0.8495526656625565]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7354965737541796		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 1.7354965737541796 | validation: 0.8592271227127367]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.734755975009012		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 1.734755975009012 | validation: 0.8580534264189359]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731669401660582		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 1.731669401660582 | validation: 0.8493877886659056]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7619012990690819		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 1.7619012990690819 | validation: 0.9448780651032921]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8269586381364276		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 1.8269586381364276 | validation: 1.0661485604907663]
	TIME [epoch: 11.6 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9039507443531025		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 1.9039507443531025 | validation: 1.1309086370232893]
	TIME [epoch: 11.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8762392762371067		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 1.8762392762371067 | validation: 0.9683027924419227]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.794167318906215		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 1.794167318906215 | validation: 0.8948447411714558]
	TIME [epoch: 11.6 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7563217630350496		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 1.7563217630350496 | validation: 0.9037405220762404]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.75557623772512		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 1.75557623772512 | validation: 0.9105245326720803]
	TIME [epoch: 11.6 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8015502178500105		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 1.8015502178500105 | validation: 0.9953089244635964]
	TIME [epoch: 11.6 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7836911056336675		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 1.7836911056336675 | validation: 0.878710941334616]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7459147365357783		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 1.7459147365357783 | validation: 0.9147594455902004]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.778586529147141		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 1.778586529147141 | validation: 0.9576985337891277]
	TIME [epoch: 11.6 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7939884153393013		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 1.7939884153393013 | validation: 0.9463939022432117]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.792894136944252		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 1.792894136944252 | validation: 0.9338726786979357]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.784737581125533		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 1.784737581125533 | validation: 0.9326344079372899]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7944259553963242		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 1.7944259553963242 | validation: 0.9451901474531335]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7866976296329828		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 1.7866976296329828 | validation: 0.9180791125315397]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7697658835604477		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 1.7697658835604477 | validation: 0.9411536703031894]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7656444220187235		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 1.7656444220187235 | validation: 0.8765881825055846]
	TIME [epoch: 11.6 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7497667413633287		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 1.7497667413633287 | validation: 0.8925672713163837]
	TIME [epoch: 11.6 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.770204264775167		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 1.770204264775167 | validation: 0.8919819045278519]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7570348370055415		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 1.7570348370055415 | validation: 0.8757634558056947]
	TIME [epoch: 11.6 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.751497593932557		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 1.751497593932557 | validation: 0.8727223400583174]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7577080533528862		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 1.7577080533528862 | validation: 0.9192240543676067]
	TIME [epoch: 11.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7603993582498285		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 1.7603993582498285 | validation: 0.8732592732250687]
	TIME [epoch: 11.6 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7475546917291351		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 1.7475546917291351 | validation: 0.8729453274343681]
	TIME [epoch: 11.6 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.74967697079037		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 1.74967697079037 | validation: 0.8669150208694332]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7453194298840096		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 1.7453194298840096 | validation: 0.8739564822768854]
	TIME [epoch: 11.6 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7475292386726269		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 1.7475292386726269 | validation: 0.8811712818782189]
	TIME [epoch: 11.6 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7567125798381122		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 1.7567125798381122 | validation: 0.8745707583268958]
	TIME [epoch: 11.6 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.758667596430289		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 1.758667596430289 | validation: 0.8621897008716252]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7425367508274396		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 1.7425367508274396 | validation: 0.8607066269835872]
	TIME [epoch: 11.6 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7474313661408158		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 1.7474313661408158 | validation: 0.8658651039244368]
	TIME [epoch: 11.6 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7533727161522823		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 1.7533727161522823 | validation: 0.8728276565094097]
	TIME [epoch: 11.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.761849446842994		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 1.761849446842994 | validation: 0.884907827319108]
	TIME [epoch: 11.6 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7523393341569107		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 1.7523393341569107 | validation: 0.8728809802216974]
	TIME [epoch: 11.6 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7445301440364682		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 1.7445301440364682 | validation: 0.8576047675722572]
	TIME [epoch: 11.6 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7406979313105313		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 1.7406979313105313 | validation: 0.8558816210232831]
	TIME [epoch: 11.6 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.746632898393423		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 1.746632898393423 | validation: 0.8606993624896461]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7407584580736981		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 1.7407584580736981 | validation: 0.8526313434798906]
	TIME [epoch: 11.6 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7379617901272717		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 1.7379617901272717 | validation: 0.8562607894514738]
	TIME [epoch: 11.6 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7444641754072296		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 1.7444641754072296 | validation: 0.8711302147491418]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7473596709828396		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 1.7473596709828396 | validation: 0.8561422613294832]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.737868705310517		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 1.737868705310517 | validation: 0.8659907888419227]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7357544239725977		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 1.7357544239725977 | validation: 0.8505333134841625]
	TIME [epoch: 11.6 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.741789099023898		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 1.741789099023898 | validation: 0.8783984892747461]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7665341159313344		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 1.7665341159313344 | validation: 0.8826022966123768]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7501405155938732		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 1.7501405155938732 | validation: 0.8583947501081686]
	TIME [epoch: 11.6 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7375912699570084		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 1.7375912699570084 | validation: 0.860784699317529]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7374410333322543		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 1.7374410333322543 | validation: 0.8729501298505616]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7354978543078654		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 1.7354978543078654 | validation: 0.851796653381404]
	TIME [epoch: 11.6 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7347785250233074		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 1.7347785250233074 | validation: 0.8594924794029373]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7376587679954425		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 1.7376587679954425 | validation: 0.8569267580965498]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7374465841850786		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 1.7374465841850786 | validation: 0.8541477837372631]
	TIME [epoch: 11.6 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7363948698330405		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 1.7363948698330405 | validation: 0.8632835975898985]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7400775599847245		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 1.7400775599847245 | validation: 0.858587464266206]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732269035607506		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 1.732269035607506 | validation: 0.8700189695201068]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.764895049534013		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 1.764895049534013 | validation: 0.8812795563897458]
	TIME [epoch: 11.6 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7599553241573254		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 1.7599553241573254 | validation: 0.8568105662866954]
	TIME [epoch: 11.6 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7390577385208363		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 1.7390577385208363 | validation: 0.8573027298959863]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7359682604194115		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 1.7359682604194115 | validation: 0.8530447953566214]
	TIME [epoch: 11.6 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7377774278622131		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 1.7377774278622131 | validation: 0.8565356510280643]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7478748632627266		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 1.7478748632627266 | validation: 0.8627542564022658]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7609694746755933		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 1.7609694746755933 | validation: 0.8759991435388317]
	TIME [epoch: 11.6 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7557626581062418		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 1.7557626581062418 | validation: 0.8681197441109282]
	TIME [epoch: 11.6 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7410186592067893		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 1.7410186592067893 | validation: 0.868106852650618]
	TIME [epoch: 11.6 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7463168111000704		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 1.7463168111000704 | validation: 0.8658372126818202]
	TIME [epoch: 11.6 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7363482894897877		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 1.7363482894897877 | validation: 0.8506067062082445]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.736325204705828		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 1.736325204705828 | validation: 0.8646692517463744]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7351769130654475		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 1.7351769130654475 | validation: 0.8480911018199145]
	TIME [epoch: 11.6 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7376625464615063		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 1.7376625464615063 | validation: 0.8523781559684248]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7368406549183506		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 1.7368406549183506 | validation: 0.8515148328326985]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7363995589163044		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 1.7363995589163044 | validation: 0.8465445165588489]
	TIME [epoch: 11.6 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311491111420412		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 1.7311491111420412 | validation: 0.8596876775242441]
	TIME [epoch: 11.6 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7365110083340358		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 1.7365110083340358 | validation: 0.856901549639473]
	TIME [epoch: 11.6 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7347754214333062		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 1.7347754214333062 | validation: 0.8580010646770293]
	TIME [epoch: 11.6 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.739927605031341		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 1.739927605031341 | validation: 0.8543793945140263]
	TIME [epoch: 11.6 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.738378157868028		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 1.738378157868028 | validation: 0.8735776494032681]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7450998452092112		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 1.7450998452092112 | validation: 0.8639810903364981]
	TIME [epoch: 11.6 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732169491448312		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 1.732169491448312 | validation: 0.8512701499219287]
	TIME [epoch: 11.6 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311705271209727		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 1.7311705271209727 | validation: 0.8500937965717492]
	TIME [epoch: 11.6 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.734768921834807		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 1.734768921834807 | validation: 0.8534935963666794]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7344283394917708		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 1.7344283394917708 | validation: 0.8641521521954352]
	TIME [epoch: 11.6 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7406181915686452		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 1.7406181915686452 | validation: 0.8515544501052367]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.739466057376974		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 1.739466057376974 | validation: 0.8558500239483768]
	TIME [epoch: 11.6 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.736127883450441		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 1.736127883450441 | validation: 0.8494284536816555]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7307722945475228		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 1.7307722945475228 | validation: 0.852351196079679]
	TIME [epoch: 11.6 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7322352060769877		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 1.7322352060769877 | validation: 0.8546974429998047]
	TIME [epoch: 11.6 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7343294654729586		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 1.7343294654729586 | validation: 0.8423334292712386]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_1325.pth
	Model improved!!!
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309139249201513		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 1.7309139249201513 | validation: 0.8503431819054669]
	TIME [epoch: 11.6 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7352547920421777		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 1.7352547920421777 | validation: 0.8408212185112833]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_1327.pth
	Model improved!!!
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7339852019455178		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 1.7339852019455178 | validation: 0.8634510403730198]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7416641366815924		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 1.7416641366815924 | validation: 0.8710688457717534]
	TIME [epoch: 11.6 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.739262469929125		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 1.739262469929125 | validation: 0.8833163920814844]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7578163455272315		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 1.7578163455272315 | validation: 0.9042684578359738]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7580504146172022		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 1.7580504146172022 | validation: 0.8945400533112803]
	TIME [epoch: 11.6 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7575012009176119		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 1.7575012009176119 | validation: 0.8601940850360034]
	TIME [epoch: 11.6 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7360241990282725		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 1.7360241990282725 | validation: 0.8607234785092729]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7418635571624002		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 1.7418635571624002 | validation: 0.8555980571237105]
	TIME [epoch: 11.6 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7389776666610302		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 1.7389776666610302 | validation: 0.8543204006889406]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7332842643018695		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 1.7332842643018695 | validation: 0.8662230865203836]
	TIME [epoch: 11.6 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7398566466379737		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 1.7398566466379737 | validation: 0.8591210989202973]
	TIME [epoch: 11.6 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7350572802617115		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 1.7350572802617115 | validation: 0.8500552794112133]
	TIME [epoch: 11.6 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.733315778496971		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 1.733315778496971 | validation: 0.8599284481097381]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7336804586788597		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 1.7336804586788597 | validation: 0.8523830797824621]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7374773141646842		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 1.7374773141646842 | validation: 0.8461202687518735]
	TIME [epoch: 11.6 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.737316596908255		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 1.737316596908255 | validation: 0.8591873032484558]
	TIME [epoch: 11.6 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7413942191740144		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 1.7413942191740144 | validation: 0.8605144560291913]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7400588101232932		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 1.7400588101232932 | validation: 0.8443472893410241]
	TIME [epoch: 11.6 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7305295401393317		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 1.7305295401393317 | validation: 0.8569606902147495]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7339596741447438		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 1.7339596741447438 | validation: 0.8509869305459945]
	TIME [epoch: 11.6 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7316964002938988		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 1.7316964002938988 | validation: 0.857703295300328]
	TIME [epoch: 11.6 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7347794376568983		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 1.7347794376568983 | validation: 0.8674648068062726]
	TIME [epoch: 11.6 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7574383721217846		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 1.7574383721217846 | validation: 0.8915460071302604]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7493858186556317		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 1.7493858186556317 | validation: 0.8628500670908855]
	TIME [epoch: 11.6 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7434005559781434		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 1.7434005559781434 | validation: 0.8715364764218684]
	TIME [epoch: 11.6 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7396908440512016		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 1.7396908440512016 | validation: 0.8617061166883718]
	TIME [epoch: 11.6 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7346864644238236		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 1.7346864644238236 | validation: 0.8498464581236883]
	TIME [epoch: 11.6 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732848050355287		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 1.732848050355287 | validation: 0.8567134841934031]
	TIME [epoch: 11.6 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7312789486416806		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 1.7312789486416806 | validation: 0.8554954692835226]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7374308028892993		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 1.7374308028892993 | validation: 0.8616428254245162]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.740876251341239		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 1.740876251341239 | validation: 0.8627820453375188]
	TIME [epoch: 11.6 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.739138357135946		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 1.739138357135946 | validation: 0.8510471129777761]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.736499573740491		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 1.736499573740491 | validation: 0.8460685392632794]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7285364866660793		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 1.7285364866660793 | validation: 0.8562902940190642]
	TIME [epoch: 11.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7319473557904816		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 1.7319473557904816 | validation: 0.8581583565958749]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73571497598356		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 1.73571497598356 | validation: 0.8552057302093655]
	TIME [epoch: 11.6 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7335013891196		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 1.7335013891196 | validation: 0.8759397885685277]
	TIME [epoch: 11.6 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7437983191167807		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 1.7437983191167807 | validation: 0.8708175066565871]
	TIME [epoch: 11.6 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7425584425419016		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 1.7425584425419016 | validation: 0.880247611792374]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7520109775989845		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 1.7520109775989845 | validation: 0.8840634067815447]
	TIME [epoch: 11.6 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7570383670438356		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 1.7570383670438356 | validation: 0.8814312334619456]
	TIME [epoch: 11.6 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7471435477019082		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 1.7471435477019082 | validation: 0.8546483425997186]
	TIME [epoch: 11.6 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7372801195427023		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 1.7372801195427023 | validation: 0.8651028127240423]
	TIME [epoch: 11.6 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7404708421619879		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 1.7404708421619879 | validation: 0.8610134274592939]
	TIME [epoch: 11.6 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7391090073188251		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 1.7391090073188251 | validation: 0.8457168926914724]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301366123601536		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 1.7301366123601536 | validation: 0.8564872289362712]
	TIME [epoch: 11.6 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7344588210189784		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 1.7344588210189784 | validation: 0.8491652374616294]
	TIME [epoch: 11.6 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7363621873720456		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 1.7363621873720456 | validation: 0.8471807707092869]
	TIME [epoch: 11.6 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7378212919320573		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 1.7378212919320573 | validation: 0.8579734587111557]
	TIME [epoch: 11.6 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7415125124307966		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 1.7415125124307966 | validation: 0.8471103181230651]
	TIME [epoch: 11.6 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7379681871274326		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 1.7379681871274326 | validation: 0.861456594879221]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.743962192273492		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 1.743962192273492 | validation: 0.8556424603067353]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7389356677108136		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 1.7389356677108136 | validation: 0.8596242222412204]
	TIME [epoch: 11.6 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7348864672963011		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 1.7348864672963011 | validation: 0.8609674005161522]
	TIME [epoch: 11.6 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731460492340392		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 1.731460492340392 | validation: 0.8534733109930451]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7363584750596064		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 1.7363584750596064 | validation: 0.8585317710674056]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7372110380391927		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 1.7372110380391927 | validation: 0.8540553112258945]
	TIME [epoch: 11.6 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7312249262233421		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 1.7312249262233421 | validation: 0.8461083173215598]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7315122809078745		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 1.7315122809078745 | validation: 0.8502742612693583]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7352961998129628		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 1.7352961998129628 | validation: 0.8563845504610547]
	TIME [epoch: 11.6 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7319903875059783		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 1.7319903875059783 | validation: 0.8400405701835338]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_1388.pth
	Model improved!!!
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.734634837405563		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 1.734634837405563 | validation: 0.8643227527746641]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.734224655376328		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 1.734224655376328 | validation: 0.8573193376367452]
	TIME [epoch: 11.6 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7352410537062664		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 1.7352410537062664 | validation: 0.8533703132442275]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.735297003544541		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 1.735297003544541 | validation: 0.8597002356854978]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7347964856056075		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 1.7347964856056075 | validation: 0.8592355244767822]
	TIME [epoch: 11.6 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7390891160105106		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 1.7390891160105106 | validation: 0.8599934511621737]
	TIME [epoch: 11.6 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7310862712089083		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 1.7310862712089083 | validation: 0.8499085701694676]
	TIME [epoch: 11.6 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.734005800943431		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 1.734005800943431 | validation: 0.8702265330659023]
	TIME [epoch: 11.6 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7514700940788266		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 1.7514700940788266 | validation: 0.9035233072600315]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7883948339015276		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 1.7883948339015276 | validation: 0.9612022580386089]
	TIME [epoch: 11.6 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8012250952022744		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 1.8012250952022744 | validation: 0.9612947705183654]
	TIME [epoch: 11.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8034843369368592		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 1.8034843369368592 | validation: 0.9429582716285869]
	TIME [epoch: 11.6 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7858830777643782		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 1.7858830777643782 | validation: 0.9013236335850846]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.753085193938754		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 1.753085193938754 | validation: 0.8663739350294232]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.733685157051525		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 1.733685157051525 | validation: 0.859136787976043]
	TIME [epoch: 11.6 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7337473813787625		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 1.7337473813787625 | validation: 0.8580117537291873]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7318018441788885		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 1.7318018441788885 | validation: 0.8761329718032943]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7336973471376351		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 1.7336973471376351 | validation: 0.8534102294737237]
	TIME [epoch: 11.6 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7305285245262914		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 1.7305285245262914 | validation: 0.8485937374847967]
	TIME [epoch: 11.6 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7310591971552587		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 1.7310591971552587 | validation: 0.856468907245692]
	TIME [epoch: 11.6 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7341147319368355		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 1.7341147319368355 | validation: 0.8573380033154558]
	TIME [epoch: 11.6 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7353220993028968		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 1.7353220993028968 | validation: 0.860506236328696]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7344064663446859		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 1.7344064663446859 | validation: 0.8542950965844126]
	TIME [epoch: 11.6 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732739965208495		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 1.732739965208495 | validation: 0.8531053041249145]
	TIME [epoch: 11.6 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7264585931609153		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 1.7264585931609153 | validation: 0.8539092529212816]
	TIME [epoch: 11.6 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732270965983099		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 1.732270965983099 | validation: 0.8488904448324253]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.733921273892227		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 1.733921273892227 | validation: 0.8620993072450763]
	TIME [epoch: 11.6 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7385818760306644		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 1.7385818760306644 | validation: 0.8624291330411858]
	TIME [epoch: 11.6 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7384316522515912		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 1.7384316522515912 | validation: 0.8756006909682882]
	TIME [epoch: 11.6 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7567396773633965		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 1.7567396773633965 | validation: 0.8770173045851111]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7429323588310566		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 1.7429323588310566 | validation: 0.8639903778499728]
	TIME [epoch: 11.6 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7380386745521168		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 1.7380386745521168 | validation: 0.8690390381431865]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7316743653185753		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 1.7316743653185753 | validation: 0.8572304209175244]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7315674484521155		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 1.7315674484521155 | validation: 0.8471186718046549]
	TIME [epoch: 11.6 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.733051093219545		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 1.733051093219545 | validation: 0.8424050815461311]
	TIME [epoch: 11.6 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73169426987876		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 1.73169426987876 | validation: 0.8532999524739538]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7330294478828834		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 1.7330294478828834 | validation: 0.8647196707456962]
	TIME [epoch: 11.6 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7424554155615812		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 1.7424554155615812 | validation: 0.8677198946905287]
	TIME [epoch: 11.6 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7377705456050954		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 1.7377705456050954 | validation: 0.8604439517063801]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7319387757149558		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 1.7319387757149558 | validation: 0.845469164487204]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7297972860544644		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 1.7297972860544644 | validation: 0.8474371715827806]
	TIME [epoch: 11.6 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7315360699718476		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 1.7315360699718476 | validation: 0.8431376415949282]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73572066637206		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 1.73572066637206 | validation: 0.8427177014790133]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7392302105320778		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 1.7392302105320778 | validation: 0.8532742201064124]
	TIME [epoch: 11.6 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301019399080173		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 1.7301019399080173 | validation: 0.8573734521812933]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7335692633245496		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 1.7335692633245496 | validation: 0.8521451851582768]
	TIME [epoch: 11.6 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7322037558440238		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 1.7322037558440238 | validation: 0.8484499053988777]
	TIME [epoch: 11.6 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.733909571947759		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 1.733909571947759 | validation: 0.8534561125221651]
	TIME [epoch: 11.6 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7321792265035745		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 1.7321792265035745 | validation: 0.8521373560612462]
	TIME [epoch: 11.6 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732802882008334		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 1.732802882008334 | validation: 0.8630700300280819]
	TIME [epoch: 11.6 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.739289561634711		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 1.739289561634711 | validation: 0.8605796470958762]
	TIME [epoch: 11.6 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73302219783975		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 1.73302219783975 | validation: 0.8518646877150584]
	TIME [epoch: 11.6 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7345865609951652		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 1.7345865609951652 | validation: 0.8496639779917204]
	TIME [epoch: 11.6 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7318950952297851		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 1.7318950952297851 | validation: 0.8443140867794501]
	TIME [epoch: 11.6 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7293470632542394		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 1.7293470632542394 | validation: 0.8519043719770113]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7295474154970834		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 1.7295474154970834 | validation: 0.8451078978933899]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7287293827130967		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 1.7287293827130967 | validation: 0.8533262401649685]
	TIME [epoch: 11.6 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7317078315455636		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 1.7317078315455636 | validation: 0.8528697545165056]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7322343933799988		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 1.7322343933799988 | validation: 0.8452772218735254]
	TIME [epoch: 11.6 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7294133103428324		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 1.7294133103428324 | validation: 0.8546116440173444]
	TIME [epoch: 11.6 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7330662148012868		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 1.7330662148012868 | validation: 0.8533986097126394]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7361554960027612		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 1.7361554960027612 | validation: 0.8595714316914922]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7376272118793208		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 1.7376272118793208 | validation: 0.8602702997399645]
	TIME [epoch: 11.6 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7324288516200141		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 1.7324288516200141 | validation: 0.8544777181350176]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7317069581379183		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 1.7317069581379183 | validation: 0.8591917005358205]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7331926617618423		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 1.7331926617618423 | validation: 0.8582065622340969]
	TIME [epoch: 11.6 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301949096409568		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 1.7301949096409568 | validation: 0.8459300162175695]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7361841858131892		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 1.7361841858131892 | validation: 0.8607522062222352]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7374919976234193		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 1.7374919976234193 | validation: 0.853056571730572]
	TIME [epoch: 11.6 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730116668950518		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 1.730116668950518 | validation: 0.8475797533109531]
	TIME [epoch: 11.6 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7327172144366965		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 1.7327172144366965 | validation: 0.8492205384203425]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7319552376709044		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 1.7319552376709044 | validation: 0.8571168838012825]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.737146088096381		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 1.737146088096381 | validation: 0.8498621671938402]
	TIME [epoch: 11.6 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7305582197785596		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 1.7305582197785596 | validation: 0.8473905210158696]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7312086613035176		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 1.7312086613035176 | validation: 0.8469799278016783]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7305587586800804		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 1.7305587586800804 | validation: 0.8481672712681904]
	TIME [epoch: 11.6 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7303160894258465		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 1.7303160894258465 | validation: 0.8506656523173095]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7288269179984082		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 1.7288269179984082 | validation: 0.8523424385824829]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7360883380828764		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 1.7360883380828764 | validation: 0.8650936388497533]
	TIME [epoch: 11.6 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7376514430222032		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 1.7376514430222032 | validation: 0.8565634225437893]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7362985429539162		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 1.7362985429539162 | validation: 0.8525776400782354]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7369943408109016		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 1.7369943408109016 | validation: 0.8519436960033973]
	TIME [epoch: 11.6 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7343895042698059		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 1.7343895042698059 | validation: 0.8512613017856265]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7297616389547972		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 1.7297616389547972 | validation: 0.8467516039089578]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7318559454972422		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 1.7318559454972422 | validation: 0.8542591451095656]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7320418892089382		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 1.7320418892089382 | validation: 0.8358757742749997]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r2_20240310_045134/states/model_tr_study204_1474.pth
	Model improved!!!
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7319746150024895		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 1.7319746150024895 | validation: 0.8539157467205509]
	TIME [epoch: 11.6 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7334751721355506		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 1.7334751721355506 | validation: 0.8494903242715734]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7335035502368157		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 1.7335035502368157 | validation: 0.8547301862453216]
	TIME [epoch: 11.6 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7359132500379748		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 1.7359132500379748 | validation: 0.848339786414399]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7321382587168535		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 1.7321382587168535 | validation: 0.8507188647355983]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7369596036625978		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 1.7369596036625978 | validation: 0.8624814364326445]
	TIME [epoch: 11.6 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.740595740022351		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 1.740595740022351 | validation: 0.8681463603230075]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7409996240382877		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 1.7409996240382877 | validation: 0.8531474404637648]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7332168608663903		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 1.7332168608663903 | validation: 0.8578892759973894]
	TIME [epoch: 11.6 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7357674269251717		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 1.7357674269251717 | validation: 0.8478174470001995]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7353412302793876		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 1.7353412302793876 | validation: 0.8532583985624246]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.735879514843152		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 1.735879514843152 | validation: 0.8490664058317325]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7406749169604065		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 1.7406749169604065 | validation: 0.8606449339976573]
	TIME [epoch: 11.6 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7380002440560245		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 1.7380002440560245 | validation: 0.8520976445492822]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7389949035806573		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 1.7389949035806573 | validation: 0.8472154989840539]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7307745345724872		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 1.7307745345724872 | validation: 0.8488485181519968]
	TIME [epoch: 11.6 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.72650029515808		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 1.72650029515808 | validation: 0.855219310895834]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7310742534948327		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 1.7310742534948327 | validation: 0.8666596271996658]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7315944242041452		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 1.7315944242041452 | validation: 0.8494287679821265]
	TIME [epoch: 11.6 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728894018468639		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 1.728894018468639 | validation: 0.8475481279537621]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7332325411012028		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 1.7332325411012028 | validation: 0.8578700248003926]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7331610649107838		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 1.7331610649107838 | validation: 0.8558550324293203]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7289578037785913		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 1.7289578037785913 | validation: 0.8484066329259509]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728171888918483		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 1.728171888918483 | validation: 0.8395358627007338]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731234828289425		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 1.731234828289425 | validation: 0.8537726465314839]
	TIME [epoch: 11.6 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7336409437190992		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 1.7336409437190992 | validation: 0.8560909077132303]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7352163660327617		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 1.7352163660327617 | validation: 0.8714994771742585]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7389728317788042		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 1.7389728317788042 | validation: 0.8634842753703307]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7348970625878208		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 1.7348970625878208 | validation: 0.8621961900648074]
	TIME [epoch: 11.6 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7315443275958113		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 1.7315443275958113 | validation: 0.870712013016875]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7416815568838098		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 1.7416815568838098 | validation: 0.8703774167180631]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7368881361497852		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 1.7368881361497852 | validation: 0.85981219540025]
	TIME [epoch: 11.6 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7356745346302247		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 1.7356745346302247 | validation: 0.8635794215080165]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7358674733938653		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 1.7358674733938653 | validation: 0.8570576596449989]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729065445891568		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 1.729065445891568 | validation: 0.860612988647387]
	TIME [epoch: 11.6 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731715128820859		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 1.731715128820859 | validation: 0.8647720571127359]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7270895157822523		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 1.7270895157822523 | validation: 0.8432083742894532]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728945060481487		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 1.728945060481487 | validation: 0.849804631823724]
	TIME [epoch: 11.6 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730626429441419		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 1.730626429441419 | validation: 0.8603578212039449]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7336143563542938		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 1.7336143563542938 | validation: 0.8532074085674493]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309333627558414		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 1.7309333627558414 | validation: 0.8577437484806091]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7334957503284807		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 1.7334957503284807 | validation: 0.8555854316446201]
	TIME [epoch: 11.6 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7353368886404295		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 1.7353368886404295 | validation: 0.8644221447661345]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7394114530733535		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 1.7394114530733535 | validation: 0.8601722379671966]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7400848471387835		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 1.7400848471387835 | validation: 0.8575046856731635]
	TIME [epoch: 11.6 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7350667050213435		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 1.7350667050213435 | validation: 0.8528539202378344]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7355404637997989		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 1.7355404637997989 | validation: 0.8500960362823321]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.72872615605116		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 1.72872615605116 | validation: 0.8513324768739017]
	TIME [epoch: 11.6 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286465650018463		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 1.7286465650018463 | validation: 0.8583095744708242]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311660235098005		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 1.7311660235098005 | validation: 0.8641730372308425]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7381010883975434		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 1.7381010883975434 | validation: 0.8658410610018392]
	TIME [epoch: 11.6 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7324520709646531		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 1.7324520709646531 | validation: 0.8525082210080807]
	TIME [epoch: 11.6 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7338718213340627		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 1.7338718213340627 | validation: 0.8576389384685459]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7303326558525898		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 1.7303326558525898 | validation: 0.8584742898765442]
	TIME [epoch: 11.6 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7332177410896683		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 1.7332177410896683 | validation: 0.8599942949854843]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7354450046976173		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 1.7354450046976173 | validation: 0.8589107970372352]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7310755426960163		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 1.7310755426960163 | validation: 0.8490553814344992]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7296382235209817		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 1.7296382235209817 | validation: 0.8459762529748813]
	TIME [epoch: 11.6 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7313677022958232		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 1.7313677022958232 | validation: 0.8702969682902776]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7388238636199476		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 1.7388238636199476 | validation: 0.8712584693560419]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7413916035504866		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 1.7413916035504866 | validation: 0.8703077178617037]
	TIME [epoch: 11.6 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.738377999531096		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 1.738377999531096 | validation: 0.8738846691911161]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7399555927794055		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 1.7399555927794055 | validation: 0.8595159591720962]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7414042266847716		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 1.7414042266847716 | validation: 0.8569998452283162]
	TIME [epoch: 11.6 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7371240612854408		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 1.7371240612854408 | validation: 0.8642061896548151]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7422151022517691		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 1.7422151022517691 | validation: 0.8677885259858278]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.744723924601967		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 1.744723924601967 | validation: 0.8834995416596166]
	TIME [epoch: 11.6 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7451237133457411		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 1.7451237133457411 | validation: 0.8760771223947623]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7455704859501453		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 1.7455704859501453 | validation: 0.872851354750384]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7463958623246978		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 1.7463958623246978 | validation: 0.8630710137376763]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7349805234438738		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 1.7349805234438738 | validation: 0.8509757437629659]
	TIME [epoch: 11.6 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7290000334201951		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 1.7290000334201951 | validation: 0.8584154806884057]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7315273036583592		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 1.7315273036583592 | validation: 0.8409682473141022]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732936230115166		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 1.732936230115166 | validation: 0.8452418382388851]
	TIME [epoch: 11.6 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7342773499777757		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 1.7342773499777757 | validation: 0.8531129378466287]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7363606593906344		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 1.7363606593906344 | validation: 0.8415919600990506]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.735906989715071		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 1.735906989715071 | validation: 0.853533258461593]
	TIME [epoch: 11.6 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731183360647417		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 1.731183360647417 | validation: 0.8549277596144298]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7334126159181373		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 1.7334126159181373 | validation: 0.8512311235366337]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7315589609019928		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 1.7315589609019928 | validation: 0.8405522443648141]
	TIME [epoch: 11.6 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7317532617868001		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 1.7317532617868001 | validation: 0.8589082682967054]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311461410827258		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 1.7311461410827258 | validation: 0.8525043226520742]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7342263640235718		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 1.7342263640235718 | validation: 0.8573491572030435]
	TIME [epoch: 11.6 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7340783474462012		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 1.7340783474462012 | validation: 0.853761367092639]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7306793057841046		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 1.7306793057841046 | validation: 0.8551960923690581]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7340626376186818		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 1.7340626376186818 | validation: 0.8478269808022776]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7283924912840944		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 1.7283924912840944 | validation: 0.8478050149483288]
	TIME [epoch: 11.6 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7303021579211795		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 1.7303021579211795 | validation: 0.8473884090711858]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7288325501051132		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 1.7288325501051132 | validation: 0.8487322358137331]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731231801932325		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 1.731231801932325 | validation: 0.8470347391967405]
	TIME [epoch: 11.6 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7310377093907037		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 1.7310377093907037 | validation: 0.8505949182878988]
	TIME [epoch: 11.6 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7347020709002732		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 1.7347020709002732 | validation: 0.8488010117406194]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7300696346649032		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 1.7300696346649032 | validation: 0.8558210223119567]
	TIME [epoch: 11.6 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7280216183793546		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 1.7280216183793546 | validation: 0.8405476977128555]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7265133552573504		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 1.7265133552573504 | validation: 0.8582209260788539]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7324066573160892		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 1.7324066573160892 | validation: 0.8454008907842603]
	TIME [epoch: 11.6 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729492023403607		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 1.729492023403607 | validation: 0.8541290265391304]
	TIME [epoch: 11.6 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7355755243930595		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 1.7355755243930595 | validation: 0.852411351204115]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311868208998857		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 1.7311868208998857 | validation: 0.8591557953359872]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.735383642487604		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 1.735383642487604 | validation: 0.8632551367743919]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7338158855546317		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 1.7338158855546317 | validation: 0.8544496885516901]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.738377035770731		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 1.738377035770731 | validation: 0.8560295699500021]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73652561218689		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 1.73652561218689 | validation: 0.8472797720845071]
	TIME [epoch: 11.6 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7344544141568727		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 1.7344544141568727 | validation: 0.8541785912269009]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7331259994817858		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 1.7331259994817858 | validation: 0.8564889014622068]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7363997809544727		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 1.7363997809544727 | validation: 0.8508558216953952]
	TIME [epoch: 11.6 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7283083692039105		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 1.7283083692039105 | validation: 0.8501239510198195]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7345462977601314		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 1.7345462977601314 | validation: 0.847430590013255]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7315120960342538		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 1.7315120960342538 | validation: 0.8439446780041909]
	TIME [epoch: 11.6 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.726027120291059		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 1.726027120291059 | validation: 0.8496611206049653]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286051810056537		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 1.7286051810056537 | validation: 0.8498818086113378]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7289935369782623		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 1.7289935369782623 | validation: 0.8520857760920946]
	TIME [epoch: 11.6 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7329146105536852		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 1.7329146105536852 | validation: 0.8542382246941412]
	TIME [epoch: 11.6 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311700666687067		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 1.7311700666687067 | validation: 0.8464582355940334]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7278082116544344		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 1.7278082116544344 | validation: 0.8496987234283421]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730884406493813		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 1.730884406493813 | validation: 0.8486540241846424]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7319616499097719		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 1.7319616499097719 | validation: 0.8500605376291508]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7349290420054717		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 1.7349290420054717 | validation: 0.8511348300664417]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730566743965074		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 1.730566743965074 | validation: 0.8567116983319738]
	TIME [epoch: 11.6 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.733760862255692		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 1.733760862255692 | validation: 0.8445503167979871]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311015329758912		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 1.7311015329758912 | validation: 0.8470737149577656]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7321122692119841		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 1.7321122692119841 | validation: 0.8535871930335935]
	TIME [epoch: 11.6 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.734631991880432		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 1.734631991880432 | validation: 0.8508856671538659]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731732797751114		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 1.731732797751114 | validation: 0.8537892537056136]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7289434595461026		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 1.7289434595461026 | validation: 0.8533219587322739]
	TIME [epoch: 11.6 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7304228488381364		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 1.7304228488381364 | validation: 0.858087155268333]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309741781197499		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 1.7309741781197499 | validation: 0.8488780932260513]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7335706930020374		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 1.7335706930020374 | validation: 0.8616661041285987]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729492901892911		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 1.729492901892911 | validation: 0.859616395984994]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7292712157294334		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 1.7292712157294334 | validation: 0.8553966582191016]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728091469669809		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 1.728091469669809 | validation: 0.8552684755672469]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7356635640082678		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 1.7356635640082678 | validation: 0.8490367660787694]
	TIME [epoch: 11.6 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301322791351037		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 1.7301322791351037 | validation: 0.8514028957842145]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7290831153049626		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 1.7290831153049626 | validation: 0.8511879103280054]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7251051221381606		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 1.7251051221381606 | validation: 0.856956010317636]
	TIME [epoch: 11.6 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7280737394447643		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 1.7280737394447643 | validation: 0.8523941950425333]
	TIME [epoch: 11.6 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7307551406614188		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 1.7307551406614188 | validation: 0.8556710701798917]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309585489574308		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 1.7309585489574308 | validation: 0.8592562015981873]
	TIME [epoch: 11.6 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.726443539737562		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 1.726443539737562 | validation: 0.8480773432728173]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730423337463745		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 1.730423337463745 | validation: 0.8454287148343123]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7256468464519281		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 1.7256468464519281 | validation: 0.8532185097533844]
	TIME [epoch: 11.6 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7273691039634573		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 1.7273691039634573 | validation: 0.8466071355063466]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7284466876863371		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 1.7284466876863371 | validation: 0.853768882809689]
	TIME [epoch: 11.6 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7353128533513127		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 1.7353128533513127 | validation: 0.853688270833081]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73776279817052		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 1.73776279817052 | validation: 0.8582316822189152]
	TIME [epoch: 11.6 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7326375218397188		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 1.7326375218397188 | validation: 0.851021598001889]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7337451834869795		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 1.7337451834869795 | validation: 0.8516358501627338]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7310480556198227		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 1.7310480556198227 | validation: 0.8513434746770939]
	TIME [epoch: 11.6 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7331199734608551		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 1.7331199734608551 | validation: 0.8578867783224284]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7348687332315944		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 1.7348687332315944 | validation: 0.8603265466511933]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7354290904697314		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 1.7354290904697314 | validation: 0.8474368639197007]
	TIME [epoch: 11.6 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7346502639010968		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 1.7346502639010968 | validation: 0.8524488461826627]
	TIME [epoch: 11.6 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7382909781370741		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 1.7382909781370741 | validation: 0.8571193709025511]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.738731075111888		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 1.738731075111888 | validation: 0.8645424412568627]
	TIME [epoch: 11.6 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7371327984823512		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 1.7371327984823512 | validation: 0.8602564723882473]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7405750446889072		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 1.7405750446889072 | validation: 0.8614662493888656]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7415131289258583		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 1.7415131289258583 | validation: 0.858756128047386]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7393121196293073		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 1.7393121196293073 | validation: 0.8582686328955279]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7374457395359135		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 1.7374457395359135 | validation: 0.854649147887083]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.736593127217811		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 1.736593127217811 | validation: 0.8539427215041994]
	TIME [epoch: 11.6 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7375467904956663		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 1.7375467904956663 | validation: 0.850324106874924]
	TIME [epoch: 11.6 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309607604689812		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 1.7309607604689812 | validation: 0.8469289610640862]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7345253712678446		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 1.7345253712678446 | validation: 0.8461840408574096]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.734447770967224		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 1.734447770967224 | validation: 0.8440365987617693]
	TIME [epoch: 11.6 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.735131445197988		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 1.735131445197988 | validation: 0.8476582386081307]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7298637337090854		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 1.7298637337090854 | validation: 0.8525738929926305]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727230273368661		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 1.727230273368661 | validation: 0.8483320440422528]
	TIME [epoch: 11.6 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7287851308298328		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 1.7287851308298328 | validation: 0.8534501129284421]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728347209090291		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 1.728347209090291 | validation: 0.8571551949619496]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731011963492308		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 1.731011963492308 | validation: 0.8467733087687623]
	TIME [epoch: 11.6 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7296185369039747		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 1.7296185369039747 | validation: 0.8525365898016105]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7284035261958832		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 1.7284035261958832 | validation: 0.8382301122452178]
	TIME [epoch: 11.6 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7304104445302715		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 1.7304104445302715 | validation: 0.8474870715865725]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7305906451747832		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 1.7305906451747832 | validation: 0.8542310487891367]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7331865439914744		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 1.7331865439914744 | validation: 0.854349032385262]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.72783551153683		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 1.72783551153683 | validation: 0.853447033533431]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728222281016549		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 1.728222281016549 | validation: 0.8392009999795437]
	TIME [epoch: 11.6 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7289644887031796		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 1.7289644887031796 | validation: 0.8511564784251314]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727943207809594		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 1.727943207809594 | validation: 0.8516594056676732]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7334545682033338		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 1.7334545682033338 | validation: 0.8587632253666402]
	TIME [epoch: 11.6 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7308103369536287		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 1.7308103369536287 | validation: 0.8531436188101978]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7356379836908085		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 1.7356379836908085 | validation: 0.8511684554928632]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7312690730863165		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 1.7312690730863165 | validation: 0.8520998427047173]
	TIME [epoch: 11.6 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7308407389145244		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 1.7308407389145244 | validation: 0.8505659364325721]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7305500418896247		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 1.7305500418896247 | validation: 0.8513418756140285]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7323958119687464		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 1.7323958119687464 | validation: 0.8497172072843472]
	TIME [epoch: 11.6 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730484302212138		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 1.730484302212138 | validation: 0.8530712631316498]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7322625355265324		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 1.7322625355265324 | validation: 0.8530564811088857]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730575819122504		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 1.730575819122504 | validation: 0.8551979859764223]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7326392799911619		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 1.7326392799911619 | validation: 0.8474419475041526]
	TIME [epoch: 11.6 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7327827511149492		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 1.7327827511149492 | validation: 0.8501318267723786]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7325732186053262		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 1.7325732186053262 | validation: 0.8481388798727713]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7277465506850676		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 1.7277465506850676 | validation: 0.8519202688548996]
	TIME [epoch: 11.6 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7293381513706574		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 1.7293381513706574 | validation: 0.8461026166232918]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7287932857193131		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 1.7287932857193131 | validation: 0.8541413212443649]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7317092252928412		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 1.7317092252928412 | validation: 0.8505905006361133]
	TIME [epoch: 11.6 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311023168688138		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 1.7311023168688138 | validation: 0.8478497883207838]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732616009755619		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 1.732616009755619 | validation: 0.8580905144198369]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7291255447720053		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 1.7291255447720053 | validation: 0.8537391331468279]
	TIME [epoch: 11.6 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7339795820149388		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 1.7339795820149388 | validation: 0.8493487559103697]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7324332236952733		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 1.7324332236952733 | validation: 0.8537353479520171]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730638140268236		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 1.730638140268236 | validation: 0.8490277114734568]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7275756438957492		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 1.7275756438957492 | validation: 0.8468717397219419]
	TIME [epoch: 11.6 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286553415447214		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 1.7286553415447214 | validation: 0.8519293461002553]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7325047672587865		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 1.7325047672587865 | validation: 0.8502605090250182]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7324594173912788		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 1.7324594173912788 | validation: 0.8445929615063459]
	TIME [epoch: 11.6 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7330975427811492		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 1.7330975427811492 | validation: 0.8559987589145517]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7331284108894747		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 1.7331284108894747 | validation: 0.8516131582600365]
	TIME [epoch: 11.6 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7302963916953216		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 1.7302963916953216 | validation: 0.853823304668303]
	TIME [epoch: 11.6 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7329427139245572		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 1.7329427139245572 | validation: 0.8503681376111762]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7325772866251956		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 1.7325772866251956 | validation: 0.8587796852732653]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7293975020198706		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 1.7293975020198706 | validation: 0.8526080111209028]
	TIME [epoch: 11.6 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7339255401502456		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 1.7339255401502456 | validation: 0.8492246348829514]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7269411117360474		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 1.7269411117360474 | validation: 0.8504258157711297]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7316669115610002		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 1.7316669115610002 | validation: 0.8426532127872216]
	TIME [epoch: 11.6 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7270853663857584		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 1.7270853663857584 | validation: 0.8444615654678508]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7263378579990416		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 1.7263378579990416 | validation: 0.850876060945116]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7290482509369145		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 1.7290482509369145 | validation: 0.8439219720142598]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729132806794163		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 1.729132806794163 | validation: 0.8404476308748204]
	TIME [epoch: 11.6 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728918636655169		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 1.728918636655169 | validation: 0.8499437067628648]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7268806209321892		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 1.7268806209321892 | validation: 0.8463881725608025]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7282437190033422		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 1.7282437190033422 | validation: 0.8531368170488495]
	TIME [epoch: 11.6 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729863432498038		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 1.729863432498038 | validation: 0.8513220083873878]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7297784030771224		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 1.7297784030771224 | validation: 0.847758799097996]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729204270684729		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 1.729204270684729 | validation: 0.85368495053405]
	TIME [epoch: 11.6 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7299464078317248		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 1.7299464078317248 | validation: 0.8531556463273577]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7282758069293225		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 1.7282758069293225 | validation: 0.850226506309258]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727309032983691		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 1.727309032983691 | validation: 0.848091949694754]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7271313522247655		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 1.7271313522247655 | validation: 0.8410605132884038]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7329360403061669		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 1.7329360403061669 | validation: 0.8450510412684322]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7281003214900839		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 1.7281003214900839 | validation: 0.8396861792401547]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7306093012612462		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 1.7306093012612462 | validation: 0.8499002448871152]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7294189193332283		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 1.7294189193332283 | validation: 0.8471217742240115]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7329072159740664		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 1.7329072159740664 | validation: 0.851306711357284]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7319780924780666		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 1.7319780924780666 | validation: 0.8514957322270044]
	TIME [epoch: 11.6 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7282991864432597		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 1.7282991864432597 | validation: 0.8423322613030747]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7285187491198726		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 1.7285187491198726 | validation: 0.8517872536196628]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7305321146973927		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 1.7305321146973927 | validation: 0.854852850375518]
	TIME [epoch: 11.6 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286840210466612		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 1.7286840210466612 | validation: 0.856569454319608]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7313196749399666		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 1.7313196749399666 | validation: 0.860917706558268]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7333953722469673		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 1.7333953722469673 | validation: 0.8608581271390565]
	TIME [epoch: 11.6 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7316796980009646		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 1.7316796980009646 | validation: 0.8585236884920465]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7306867460562596		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 1.7306867460562596 | validation: 0.854448903708314]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7336269046843378		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 1.7336269046843378 | validation: 0.8502774109679354]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286003266361543		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 1.7286003266361543 | validation: 0.8498706695761351]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7318369657353712		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 1.7318369657353712 | validation: 0.8596170492996106]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73451830417868		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 1.73451830417868 | validation: 0.8525078888694446]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7294632943972652		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 1.7294632943972652 | validation: 0.8576047108117952]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73237617438848		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 1.73237617438848 | validation: 0.8598313344410616]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732703967465651		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 1.732703967465651 | validation: 0.8517422330256318]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7355502990319667		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 1.7355502990319667 | validation: 0.8616758048063636]
	TIME [epoch: 11.6 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732062960599664		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 1.732062960599664 | validation: 0.8516388295666926]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7292144419442441		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 1.7292144419442441 | validation: 0.8540594743062062]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309762604899475		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 1.7309762604899475 | validation: 0.8547639226821255]
	TIME [epoch: 11.6 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7307027816268241		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 1.7307027816268241 | validation: 0.8561583341677812]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7294767334369188		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 1.7294767334369188 | validation: 0.8549163187285886]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7313514396348313		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 1.7313514396348313 | validation: 0.8561091518481523]
	TIME [epoch: 11.6 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73403357360973		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 1.73403357360973 | validation: 0.863791713283068]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732893615050714		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 1.732893615050714 | validation: 0.8681621970153546]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7369734834325343		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 1.7369734834325343 | validation: 0.8645853423415801]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.740427975456802		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 1.740427975456802 | validation: 0.8586677859187546]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7358763117946334		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 1.7358763117946334 | validation: 0.8550087492921131]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7316481265467605		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 1.7316481265467605 | validation: 0.8476802562006287]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7314528862400118		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 1.7314528862400118 | validation: 0.8575321460596186]
	TIME [epoch: 11.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309939842412467		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 1.7309939842412467 | validation: 0.8524386025965552]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7294421864951508		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 1.7294421864951508 | validation: 0.8457847706115724]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7300626116690854		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 1.7300626116690854 | validation: 0.8485015076824723]
	TIME [epoch: 11.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7317822989477722		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 1.7317822989477722 | validation: 0.858728217599208]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7323010574907007		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 1.7323010574907007 | validation: 0.8478342727817634]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7276418965203357		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 1.7276418965203357 | validation: 0.848460344812383]
	TIME [epoch: 11.6 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7252902242686423		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 1.7252902242686423 | validation: 0.8537187884142131]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729182101973235		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 1.729182101973235 | validation: 0.842736449482679]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73144796553848		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 1.73144796553848 | validation: 0.8528963571944325]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301088500738007		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 1.7301088500738007 | validation: 0.8433593952858398]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7282631952704044		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 1.7282631952704044 | validation: 0.8475340730660773]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311693560595809		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 1.7311693560595809 | validation: 0.8445635668651263]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7294051891334923		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 1.7294051891334923 | validation: 0.8463848169216474]
	TIME [epoch: 11.6 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7317391172591867		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 1.7317391172591867 | validation: 0.8438779071841839]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286941203924355		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 1.7286941203924355 | validation: 0.8517758648105944]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7282237468569974		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 1.7282237468569974 | validation: 0.8510965962306163]
	TIME [epoch: 11.6 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729802643909253		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 1.729802643909253 | validation: 0.8531105437385129]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7290792437779685		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 1.7290792437779685 | validation: 0.8491188927717027]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301056159420316		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 1.7301056159420316 | validation: 0.8509979317395296]
	TIME [epoch: 11.6 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286760257250962		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 1.7286760257250962 | validation: 0.849570233647384]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7324964400859129		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 1.7324964400859129 | validation: 0.844296464500123]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7271208099659283		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 1.7271208099659283 | validation: 0.8508900685646268]
	TIME [epoch: 11.6 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731021158016193		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 1.731021158016193 | validation: 0.8529014770172763]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731649688582044		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 1.731649688582044 | validation: 0.8498401138217156]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311968040543535		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 1.7311968040543535 | validation: 0.8527233128556343]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729727441193149		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 1.729727441193149 | validation: 0.8477837543380475]
	TIME [epoch: 11.6 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7274339848091422		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 1.7274339848091422 | validation: 0.8513748010837486]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7270305954059746		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 1.7270305954059746 | validation: 0.8561938622329064]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7285335831565263		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 1.7285335831565263 | validation: 0.8567367784457975]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727036918552749		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 1.727036918552749 | validation: 0.8469978145459814]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7287216062170712		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 1.7287216062170712 | validation: 0.8478417825528263]
	TIME [epoch: 11.6 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7278181987856938		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 1.7278181987856938 | validation: 0.8534082952753059]
	TIME [epoch: 11.6 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7268779468957265		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 1.7268779468957265 | validation: 0.8552712449554862]
	TIME [epoch: 11.6 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728067809940808		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 1.728067809940808 | validation: 0.8496781650710793]
	TIME [epoch: 11.6 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730132442210931		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 1.730132442210931 | validation: 0.8541785169245958]
	TIME [epoch: 11.6 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731562115560955		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 1.731562115560955 | validation: 0.8451762809725963]
	TIME [epoch: 11.6 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730841785013029		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 1.730841785013029 | validation: 0.8497390017456372]
	TIME [epoch: 11.6 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7308342253583748		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 1.7308342253583748 | validation: 0.8490694753062924]
	TIME [epoch: 11.6 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7292240774958356		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 1.7292240774958356 | validation: 0.852347041432395]
	TIME [epoch: 11.6 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7308789113402179		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 1.7308789113402179 | validation: 0.8491068699955555]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728542573255877		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 1.728542573255877 | validation: 0.8496415804676142]
	TIME [epoch: 11.6 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7330220977514985		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 1.7330220977514985 | validation: 0.857049553836696]
	TIME [epoch: 11.6 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7310106142438109		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 1.7310106142438109 | validation: 0.8598319480404957]
	TIME [epoch: 11.6 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7303314520162063		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 1.7303314520162063 | validation: 0.8490658614028229]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7305512815222097		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 1.7305512815222097 | validation: 0.853929530620834]
	TIME [epoch: 11.6 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309472230341112		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 1.7309472230341112 | validation: 0.8555174475133409]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7336633450063517		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 1.7336633450063517 | validation: 0.8578033635620343]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286315811249768		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 1.7286315811249768 | validation: 0.852159539973663]
	TIME [epoch: 11.6 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729024722019393		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 1.729024722019393 | validation: 0.8569229918651757]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7310412787820255		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 1.7310412787820255 | validation: 0.8554375364971641]
	TIME [epoch: 11.6 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7359640927633142		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 1.7359640927633142 | validation: 0.8531014631175046]
	TIME [epoch: 11.6 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.733797475224447		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 1.733797475224447 | validation: 0.8557384790068383]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7360735869927715		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 1.7360735869927715 | validation: 0.8637069301194807]
	TIME [epoch: 11.6 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7357149375234497		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 1.7357149375234497 | validation: 0.8624696463606477]
	TIME [epoch: 11.6 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.735981266066122		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 1.735981266066122 | validation: 0.8631644058195101]
	TIME [epoch: 11.6 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7359471511901083		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 1.7359471511901083 | validation: 0.8593742337665673]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.733357459746266		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 1.733357459746266 | validation: 0.8576582696451487]
	TIME [epoch: 11.6 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7297883003002725		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 1.7297883003002725 | validation: 0.8511020478645329]
	TIME [epoch: 11.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7273436960216073		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 1.7273436960216073 | validation: 0.8521126154877685]
	TIME [epoch: 11.6 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7287068543727113		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 1.7287068543727113 | validation: 0.8489363101992055]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7242598120999961		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 1.7242598120999961 | validation: 0.8534589119355965]
	TIME [epoch: 11.6 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7268851188925112		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 1.7268851188925112 | validation: 0.8584817787713864]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7288044878939757		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 1.7288044878939757 | validation: 0.8518066182253561]
	TIME [epoch: 11.6 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7320197688950012		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 1.7320197688950012 | validation: 0.8408741912466609]
	TIME [epoch: 11.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7259462497460563		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 1.7259462497460563 | validation: 0.8503454780541256]
	TIME [epoch: 11.6 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7265868433161202		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 1.7265868433161202 | validation: 0.8508263479276214]
	TIME [epoch: 11.6 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728475407699813		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 1.728475407699813 | validation: 0.8434457458251277]
	TIME [epoch: 11.6 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.72530680809036		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 1.72530680809036 | validation: 0.8464320588263149]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7307380256526104		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 1.7307380256526104 | validation: 0.8562781631461915]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7291425785445056		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 1.7291425785445056 | validation: 0.8484311899635764]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7302652737663697		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 1.7302652737663697 | validation: 0.8608034891364694]
	TIME [epoch: 11.6 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.735429688066364		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 1.735429688066364 | validation: 0.8571315205169181]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7384847177997378		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 1.7384847177997378 | validation: 0.8630271179207506]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7359614087281439		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 1.7359614087281439 | validation: 0.8661694374068537]
	TIME [epoch: 11.6 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.734591248310171		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 1.734591248310171 | validation: 0.8572599693090172]
	TIME [epoch: 11.6 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7305089419450557		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 1.7305089419450557 | validation: 0.857207493514375]
	TIME [epoch: 11.6 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729617402557997		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 1.729617402557997 | validation: 0.844000808319978]
	TIME [epoch: 11.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7293700378988544		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 1.7293700378988544 | validation: 0.8517919615737941]
	TIME [epoch: 11.6 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728846681212862		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 1.728846681212862 | validation: 0.8498359915086752]
	TIME [epoch: 11.6 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7292291328021763		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 1.7292291328021763 | validation: 0.8480003232611218]
	TIME [epoch: 11.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7258227039450258		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 1.7258227039450258 | validation: 0.8484252404587972]
	TIME [epoch: 11.6 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7287910582467276		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 1.7287910582467276 | validation: 0.8474388078116546]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7279901439367853		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 1.7279901439367853 | validation: 0.8486137443815827]
	TIME [epoch: 11.6 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7280060595915674		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 1.7280060595915674 | validation: 0.8460104887551987]
	TIME [epoch: 11.6 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7276408681853703		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 1.7276408681853703 | validation: 0.8493810547667326]
	TIME [epoch: 11.6 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7304824750153334		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 1.7304824750153334 | validation: 0.8460199650589506]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727317507432851		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 1.727317507432851 | validation: 0.8478264493667483]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730287908035686		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 1.730287908035686 | validation: 0.8545093032402521]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7281404877815183		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 1.7281404877815183 | validation: 0.8496461507831566]
	TIME [epoch: 11.6 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309731378752646		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 1.7309731378752646 | validation: 0.8433149599177421]
	TIME [epoch: 11.6 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727413645235021		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 1.727413645235021 | validation: 0.8425332110587614]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.724809834394999		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 1.724809834394999 | validation: 0.8538346684305265]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7302505372534296		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 1.7302505372534296 | validation: 0.8586415433995367]
	TIME [epoch: 11.6 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729697227296118		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 1.729697227296118 | validation: 0.8507177383970264]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7304932317201516		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 1.7304932317201516 | validation: 0.8454051715001693]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7334640138438435		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 1.7334640138438435 | validation: 0.8406215590568828]
	TIME [epoch: 11.6 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7282195047850073		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 1.7282195047850073 | validation: 0.8399697735393123]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727072279228152		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 1.727072279228152 | validation: 0.8481879768171292]
	TIME [epoch: 11.6 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7273713834329036		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 1.7273713834329036 | validation: 0.842932295379197]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7279652504424927		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 1.7279652504424927 | validation: 0.856863600951605]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7280669191729194		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 1.7280669191729194 | validation: 0.8460104325858318]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7263479441267067		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 1.7263479441267067 | validation: 0.8482923430889683]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7296792029538945		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 1.7296792029538945 | validation: 0.854136392746261]
	TIME [epoch: 11.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301400042865904		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 1.7301400042865904 | validation: 0.8470122246822654]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7282179963202917		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 1.7282179963202917 | validation: 0.8446227614951839]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7300074522599556		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 1.7300074522599556 | validation: 0.8537251150645265]
	TIME [epoch: 11.6 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7285806780182176		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 1.7285806780182176 | validation: 0.8510857351623065]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7274795275813033		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 1.7274795275813033 | validation: 0.8503647649720998]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7284011350931117		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 1.7284011350931117 | validation: 0.8459998035068452]
	TIME [epoch: 11.6 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7331102634989635		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 1.7331102634989635 | validation: 0.8439636770716823]
	TIME [epoch: 11.6 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7279444947970644		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 1.7279444947970644 | validation: 0.8522550476963017]
	TIME [epoch: 11.6 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7290142629125334		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 1.7290142629125334 | validation: 0.8481811770146938]
	TIME [epoch: 11.6 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7321227285660128		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 1.7321227285660128 | validation: 0.8510812045334621]
	TIME [epoch: 11.6 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727584198788523		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 1.727584198788523 | validation: 0.8505291252869303]
	TIME [epoch: 11.6 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7294955637149216		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 1.7294955637149216 | validation: 0.8522420943715152]
	TIME [epoch: 11.6 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.724411168237956		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 1.724411168237956 | validation: 0.8521076820514876]
	TIME [epoch: 11.6 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7247071404146779		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 1.7247071404146779 | validation: 0.8444336116271934]
	TIME [epoch: 11.6 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7299075846713876		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 1.7299075846713876 | validation: 0.8539982891697077]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7304950311775729		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 1.7304950311775729 | validation: 0.8476685583890808]
	TIME [epoch: 11.6 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7299804102105885		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 1.7299804102105885 | validation: 0.8462043248609037]
	TIME [epoch: 11.6 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.726432372631291		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 1.726432372631291 | validation: 0.8453261971824136]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7245160241637496		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 1.7245160241637496 | validation: 0.8530517425069484]
	TIME [epoch: 11.6 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7294561166915652		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 1.7294561166915652 | validation: 0.8509592726742108]
	TIME [epoch: 11.6 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7313001835246702		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 1.7313001835246702 | validation: 0.8461758718931381]
	TIME [epoch: 11.6 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728354658646763		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 1.728354658646763 | validation: 0.8513032847209892]
	TIME [epoch: 11.6 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7241408319289895		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 1.7241408319289895 | validation: 0.8451420658754079]
	TIME [epoch: 11.6 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7291911062100427		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 1.7291911062100427 | validation: 0.8497722371589441]
	TIME [epoch: 11.6 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729369144732935		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 1.729369144732935 | validation: 0.8516979234995291]
	TIME [epoch: 11.6 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727855864575457		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 1.727855864575457 | validation: 0.8495006070392067]
	TIME [epoch: 11.6 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7275237884972128		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 1.7275237884972128 | validation: 0.849875070661059]
	TIME [epoch: 11.6 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7271082943545912		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 1.7271082943545912 | validation: 0.8514259822496255]
	TIME [epoch: 11.6 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7269862749475948		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 1.7269862749475948 | validation: 0.8489228382390143]
	TIME [epoch: 11.6 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7280861165346395		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 1.7280861165346395 | validation: 0.8455305055600144]
	TIME [epoch: 11.6 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7255576463299054		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 1.7255576463299054 | validation: 0.8638586788652518]
	TIME [epoch: 11.6 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7264067521410107		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 1.7264067521410107 | validation: 0.8486243855472622]
	TIME [epoch: 11.6 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309433673669585		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 1.7309433673669585 | validation: 0.8562129838360827]
	TIME [epoch: 11.6 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731523436456188		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 1.731523436456188 | validation: 0.8507503718719202]
	TIME [epoch: 11.6 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729750261278118		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 1.729750261278118 | validation: 0.8483275456442944]
	TIME [epoch: 11.6 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7289271359990919		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 1.7289271359990919 | validation: 0.852937454247499]
	TIME [epoch: 11.6 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7287773185186062		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 1.7287773185186062 | validation: 0.8540628293114386]
	TIME [epoch: 11.6 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7293521391551328		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 1.7293521391551328 | validation: 0.8554168027564493]
	TIME [epoch: 11.6 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7328629392469752		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 1.7328629392469752 | validation: 0.8535809918541698]
	TIME [epoch: 11.6 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311709972709797		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 1.7311709972709797 | validation: 0.8557252548519663]
	TIME [epoch: 11.6 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7300645294150598		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 1.7300645294150598 | validation: 0.8506668751073041]
	TIME [epoch: 11.6 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7317169368664782		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 1.7317169368664782 | validation: 0.8433042628248046]
	TIME [epoch: 11.6 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7314537720614713		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 1.7314537720614713 | validation: 0.8568233882476785]
	TIME [epoch: 11.6 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7293419140395625		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 1.7293419140395625 | validation: 0.8589012173038566]
	TIME [epoch: 11.6 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7280169624429114		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 1.7280169624429114 | validation: 0.8530233775223652]
	TIME [epoch: 11.6 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729842296850449		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 1.729842296850449 | validation: 0.8637989947546642]
	TIME [epoch: 11.6 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7300621239085123		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 1.7300621239085123 | validation: 0.8487059248213242]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7284357919099702		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 1.7284357919099702 | validation: 0.8495349814882758]
	TIME [epoch: 11.6 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7270310684538248		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 1.7270310684538248 | validation: 0.8478472095259707]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301184192054964		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 1.7301184192054964 | validation: 0.859237844996349]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7324930986013207		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 1.7324930986013207 | validation: 0.857505881210874]
	TIME [epoch: 11.6 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7264236023482742		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 1.7264236023482742 | validation: 0.8555280558770527]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7325082135635195		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 1.7325082135635195 | validation: 0.8554963548673908]
	TIME [epoch: 11.6 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301352472134162		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 1.7301352472134162 | validation: 0.8450999947708769]
	TIME [epoch: 11.6 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7312088123554679		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 1.7312088123554679 | validation: 0.8474914203713482]
	TIME [epoch: 11.6 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286185778761352		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 1.7286185778761352 | validation: 0.8574247686873531]
	TIME [epoch: 11.6 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301268885782182		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 1.7301268885782182 | validation: 0.8535117226573143]
	TIME [epoch: 11.6 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7276820925199403		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 1.7276820925199403 | validation: 0.8500077518305506]
	TIME [epoch: 11.6 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7299853134510093		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 1.7299853134510093 | validation: 0.8588245639526144]
	TIME [epoch: 11.6 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7282148007645741		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 1.7282148007645741 | validation: 0.8492659408348121]
	TIME [epoch: 11.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7262978723390827		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 1.7262978723390827 | validation: 0.8509037502070481]
	TIME [epoch: 11.6 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7285425909833403		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 1.7285425909833403 | validation: 0.8470768006884518]
	TIME [epoch: 11.6 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7290702586301616		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 1.7290702586301616 | validation: 0.8451597497552016]
	TIME [epoch: 11.6 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730078584372398		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 1.730078584372398 | validation: 0.8467703647468054]
	TIME [epoch: 11.6 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7297140896524723		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 1.7297140896524723 | validation: 0.8480243804961362]
	TIME [epoch: 11.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.72799172972605		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 1.72799172972605 | validation: 0.8473880163499005]
	TIME [epoch: 11.6 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7330576277130174		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 1.7330576277130174 | validation: 0.8513771402450246]
	TIME [epoch: 11.6 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7279464002284943		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 1.7279464002284943 | validation: 0.8527496290522855]
	TIME [epoch: 11.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727155355919806		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 1.727155355919806 | validation: 0.8599968900825639]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7284859418004568		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 1.7284859418004568 | validation: 0.8515319856520992]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7298084804804508		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 1.7298084804804508 | validation: 0.8450486651712499]
	TIME [epoch: 11.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7271197389188921		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 1.7271197389188921 | validation: 0.8547721799538716]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7324631927645098		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 1.7324631927645098 | validation: 0.8510619093271354]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7290465003660156		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 1.7290465003660156 | validation: 0.8529686788428634]
	TIME [epoch: 11.6 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7268121453569563		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 1.7268121453569563 | validation: 0.850760256841431]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729037858148466		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 1.729037858148466 | validation: 0.8444864451380408]
	TIME [epoch: 11.5 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7281690981849378		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 1.7281690981849378 | validation: 0.8465420787604702]
	TIME [epoch: 11.6 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727456104887642		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 1.727456104887642 | validation: 0.8552972265574462]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7280176062755264		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 1.7280176062755264 | validation: 0.8498390026964497]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7284222266773657		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 1.7284222266773657 | validation: 0.846462712789994]
	TIME [epoch: 11.6 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7290251578282494		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 1.7290251578282494 | validation: 0.8429090465737875]
	TIME [epoch: 11.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7281396754586678		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 1.7281396754586678 | validation: 0.8506719478648646]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7285742017199892		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 1.7285742017199892 | validation: 0.8490269145010956]
	TIME [epoch: 11.6 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7322177843314652		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 1.7322177843314652 | validation: 0.8498670101660062]
	TIME [epoch: 11.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286775024036105		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 1.7286775024036105 | validation: 0.8484025748174738]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7271788904258543		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 1.7271788904258543 | validation: 0.8472545197755801]
	TIME [epoch: 11.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7330844687799993		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 1.7330844687799993 | validation: 0.8440320052027377]
	TIME [epoch: 11.6 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.732322006938671		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 1.732322006938671 | validation: 0.8546778494315467]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7254932364031443		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 1.7254932364031443 | validation: 0.8474731119202451]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7332545830463253		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 1.7332545830463253 | validation: 0.8475154033841977]
	TIME [epoch: 11.6 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7331461009033358		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 1.7331461009033358 | validation: 0.8443476724319515]
	TIME [epoch: 11.6 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7304648719482751		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 1.7304648719482751 | validation: 0.8446531118007602]
	TIME [epoch: 11.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7300458488131196		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 1.7300458488131196 | validation: 0.8458986247573548]
	TIME [epoch: 11.6 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7269943021480838		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 1.7269943021480838 | validation: 0.8466818730475049]
	TIME [epoch: 11.6 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7262074946630597		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 1.7262074946630597 | validation: 0.8549775702292101]
	TIME [epoch: 11.6 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7289560455173878		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 1.7289560455173878 | validation: 0.8512898065829967]
	TIME [epoch: 11.6 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730220813721343		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 1.730220813721343 | validation: 0.8489333659450228]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7288368740259705		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 1.7288368740259705 | validation: 0.8446604172294495]
	TIME [epoch: 11.6 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7316685100299096		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 1.7316685100299096 | validation: 0.8548844593338183]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7312561164351916		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 1.7312561164351916 | validation: 0.8494000383521404]
	TIME [epoch: 11.6 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729760599837304		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 1.729760599837304 | validation: 0.84941144125716]
	TIME [epoch: 11.6 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7291290445066936		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 1.7291290445066936 | validation: 0.8509096507888418]
	TIME [epoch: 11.6 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7285531744003841		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 1.7285531744003841 | validation: 0.8436723899210494]
	TIME [epoch: 11.6 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7307443092913066		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 1.7307443092913066 | validation: 0.8440485095469227]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7287689989398503		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 1.7287689989398503 | validation: 0.8512666303503599]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7305738766569918		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 1.7305738766569918 | validation: 0.849851515803735]
	TIME [epoch: 11.6 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7303174535705674		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 1.7303174535705674 | validation: 0.8423922858320612]
	TIME [epoch: 11.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7282543299727837		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 1.7282543299727837 | validation: 0.8438794738820952]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7312838114407672		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 1.7312838114407672 | validation: 0.8479654467917423]
	TIME [epoch: 11.6 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7275844316327722		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 1.7275844316327722 | validation: 0.8437407829055624]
	TIME [epoch: 11.6 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7259503352192684		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 1.7259503352192684 | validation: 0.8479724691452549]
	TIME [epoch: 11.6 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7253287217605489		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 1.7253287217605489 | validation: 0.851299796836977]
	TIME [epoch: 11.6 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7292101127011992		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 1.7292101127011992 | validation: 0.8431187922298538]
	TIME [epoch: 11.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730430725984577		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 1.730430725984577 | validation: 0.8537507522874984]
	TIME [epoch: 11.6 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7265257692303397		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 1.7265257692303397 | validation: 0.8487277994272954]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7268646435565507		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 1.7268646435565507 | validation: 0.8411160698146358]
	TIME [epoch: 11.6 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.726959590897955		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 1.726959590897955 | validation: 0.8447667112738014]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7293819727148587		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 1.7293819727148587 | validation: 0.8466372442642491]
	TIME [epoch: 11.6 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7302304241574982		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 1.7302304241574982 | validation: 0.8492215898393016]
	TIME [epoch: 11.6 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7250675340142374		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 1.7250675340142374 | validation: 0.8464598932691425]
	TIME [epoch: 11.6 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.726596633807361		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 1.726596633807361 | validation: 0.8521706939495929]
	TIME [epoch: 11.6 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7308229361821756		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 1.7308229361821756 | validation: 0.8491151779026258]
	TIME [epoch: 11.6 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7303688394328454		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 1.7303688394328454 | validation: 0.8445930950795372]
	TIME [epoch: 11.6 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7288682580412271		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 1.7288682580412271 | validation: 0.8515556482253563]
	TIME [epoch: 11.6 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7276875110423997		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 1.7276875110423997 | validation: 0.8463272282567836]
	TIME [epoch: 11.6 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7253442854310532		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 1.7253442854310532 | validation: 0.8490739926252624]
	TIME [epoch: 11.6 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730690669972712		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 1.730690669972712 | validation: 0.8518262740658278]
	TIME [epoch: 11.6 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7293980205550357		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 1.7293980205550357 | validation: 0.8366105129455024]
	TIME [epoch: 11.6 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7268999516625314		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 1.7268999516625314 | validation: 0.8421304559430571]
	TIME [epoch: 11.6 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7267202378005235		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 1.7267202378005235 | validation: 0.8510776449029501]
	TIME [epoch: 11.6 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7299371027040449		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 1.7299371027040449 | validation: 0.8457631817443884]
	TIME [epoch: 11.6 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7266567901463916		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 1.7266567901463916 | validation: 0.8499746989036604]
	TIME [epoch: 11.6 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.729933834122515		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 1.729933834122515 | validation: 0.8399161276730456]
	TIME [epoch: 11.6 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7320230717177483		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 1.7320230717177483 | validation: 0.8400389505714644]
	TIME [epoch: 11.6 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286243610011416		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 1.7286243610011416 | validation: 0.8488406815768922]
	TIME [epoch: 11.6 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7255677917802017		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 1.7255677917802017 | validation: 0.8428968542399524]
	TIME [epoch: 11.6 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7280078001245418		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 1.7280078001245418 | validation: 0.8498702570550328]
	TIME [epoch: 11.6 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730184266622294		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 1.730184266622294 | validation: 0.8445905312883957]
	TIME [epoch: 11.6 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7294854990695456		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 1.7294854990695456 | validation: 0.8458035586789551]
	TIME [epoch: 11.6 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7273296056059781		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 1.7273296056059781 | validation: 0.843280071561027]
	TIME [epoch: 11.6 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7303604769803262		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 1.7303604769803262 | validation: 0.8504819078983148]
	TIME [epoch: 11.6 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7245076601984115		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 1.7245076601984115 | validation: 0.8508167096214657]
	TIME [epoch: 11.6 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7256914309771476		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 1.7256914309771476 | validation: 0.8494466957248834]
	TIME [epoch: 11.6 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.724574817167337		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 1.724574817167337 | validation: 0.8530253541637515]
	TIME [epoch: 11.6 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7247979450277082		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 1.7247979450277082 | validation: 0.8446371053840299]
	TIME [epoch: 11.6 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7324995550675686		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 1.7324995550675686 | validation: 0.841314447429991]
	TIME [epoch: 11.6 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7280677951740107		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 1.7280677951740107 | validation: 0.8392229308965068]
	TIME [epoch: 11.6 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7284156609499326		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 1.7284156609499326 | validation: 0.8430668289711152]
	TIME [epoch: 11.6 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7281611940486605		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 1.7281611940486605 | validation: 0.8450388903595368]
	TIME [epoch: 11.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73035634275622		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 1.73035634275622 | validation: 0.8411234266233462]
	TIME [epoch: 11.6 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7257196138147064		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 1.7257196138147064 | validation: 0.8398962608469472]
	TIME [epoch: 11.6 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730144266274294		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 1.730144266274294 | validation: 0.8468272803659482]
	TIME [epoch: 11.6 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7276270676010328		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 1.7276270676010328 | validation: 0.8469411534573494]
	TIME [epoch: 11.6 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301323978657777		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 1.7301323978657777 | validation: 0.8420278919866023]
	TIME [epoch: 11.6 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.726809216684913		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 1.726809216684913 | validation: 0.8557948947466284]
	TIME [epoch: 11.6 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7299935660696601		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 1.7299935660696601 | validation: 0.8490407845116803]
	TIME [epoch: 11.6 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7289056410731258		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 1.7289056410731258 | validation: 0.856335791557683]
	TIME [epoch: 11.6 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.726046094227468		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 1.726046094227468 | validation: 0.8475142573362778]
	TIME [epoch: 11.6 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728657003636196		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 1.728657003636196 | validation: 0.8468387619460689]
	TIME [epoch: 11.5 sec]
Finished training in 23315.422 seconds.
