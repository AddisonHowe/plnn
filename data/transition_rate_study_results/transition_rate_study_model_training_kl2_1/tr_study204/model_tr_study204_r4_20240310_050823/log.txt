Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r4', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4098408676

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.71141937598311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.71141937598311 | validation: 10.689117549820228]
	TIME [epoch: 98.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.556019624352956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.556019624352956 | validation: 11.339514121109405]
	TIME [epoch: 11.6 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.251880702679507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.251880702679507 | validation: 10.689051193115882]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.282080773028508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.282080773028508 | validation: 9.012205403595365]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.00413109692786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.00413109692786 | validation: 8.737424024936217]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.023871531391594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.023871531391594 | validation: 7.678817295314534]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.761097568369005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.761097568369005 | validation: 6.733727750844398]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.987056596082193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.987056596082193 | validation: 6.683067704520665]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.220218923392963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.220218923392963 | validation: 5.409860895068477]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0786586065736214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0786586065736214 | validation: 4.484466161290533]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.995029575016434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.995029575016434 | validation: 4.658291128129412]
	TIME [epoch: 11.6 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4766639191591855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4766639191591855 | validation: 4.431089422364785]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.29756023525476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.29756023525476 | validation: 4.862588427388263]
	TIME [epoch: 11.5 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464424785735096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.464424785735096 | validation: 3.6593741989804798]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.99803308215951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.99803308215951 | validation: 3.6753724130203533]
	TIME [epoch: 11.5 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.375628770587265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.375628770587265 | validation: 3.275266570040047]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7461551427785267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7461551427785267 | validation: 7.785194048705887]
	TIME [epoch: 11.5 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.699403543016062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.699403543016062 | validation: 4.448013271420775]
	TIME [epoch: 11.5 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8690060267205397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8690060267205397 | validation: 3.286464016457552]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.436758113907527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.436758113907527 | validation: 3.4275306785068027]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.580028354352964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.580028354352964 | validation: 3.831172113161616]
	TIME [epoch: 11.5 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7666151247591313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7666151247591313 | validation: 3.273971130063602]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.304011766417041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.304011766417041 | validation: 3.2673179010838176]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6611141293194547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6611141293194547 | validation: 2.9240610354739647]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0192118849264453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0192118849264453 | validation: 2.7248913838105375]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9003268396157793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9003268396157793 | validation: 3.4659446845761663]
	TIME [epoch: 11.5 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.652711875059691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.652711875059691 | validation: 2.786528741898658]
	TIME [epoch: 11.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.495228071792705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.495228071792705 | validation: 2.99345766163778]
	TIME [epoch: 11.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.200792471223573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.200792471223573 | validation: 3.2326873462267463]
	TIME [epoch: 11.5 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6864565109866834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6864565109866834 | validation: 3.926238932864081]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.511116731456774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.511116731456774 | validation: 2.6484294944301574]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.957414076818439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.957414076818439 | validation: 3.434003813836303]
	TIME [epoch: 11.5 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4547256348186544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4547256348186544 | validation: 2.741729429337669]
	TIME [epoch: 11.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.405105848914061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.405105848914061 | validation: 2.6357979112870398]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1902819321464126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1902819321464126 | validation: 3.9267485595181575]
	TIME [epoch: 11.5 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5016486882744062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5016486882744062 | validation: 2.6424569828427895]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0470294002255582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0470294002255582 | validation: 3.1240129327017074]
	TIME [epoch: 11.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.052276971358958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.052276971358958 | validation: 2.8816739077991578]
	TIME [epoch: 11.5 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.449992427510636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.449992427510636 | validation: 3.1732925262416236]
	TIME [epoch: 11.5 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2997603803544067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2997603803544067 | validation: 2.9197453758690446]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.19088529800573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.19088529800573 | validation: 2.581747882021929]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.29173514780652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.29173514780652 | validation: 2.70285752819399]
	TIME [epoch: 11.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1081410964182696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1081410964182696 | validation: 2.8152864343534247]
	TIME [epoch: 11.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.002233120246638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.002233120246638 | validation: 2.6068930425776755]
	TIME [epoch: 11.5 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1434435906327516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1434435906327516 | validation: 2.6889377839481643]
	TIME [epoch: 11.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8701652665973536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8701652665973536 | validation: 3.169810931173267]
	TIME [epoch: 11.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.058575166876587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.058575166876587 | validation: 3.082684938404613]
	TIME [epoch: 11.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.924086678200155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.924086678200155 | validation: 2.366405983523742]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2940152674677363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2940152674677363 | validation: 2.59762910699049]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1344785293163175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1344785293163175 | validation: 3.093058555687693]
	TIME [epoch: 11.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8947370658925093		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.8947370658925093 | validation: 2.7147052693706675]
	TIME [epoch: 11.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.138449932487347		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.138449932487347 | validation: 2.904248326818463]
	TIME [epoch: 11.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.845017252760833		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.845017252760833 | validation: 2.4848901045859]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9523906562361435		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.9523906562361435 | validation: 2.4312658562713967]
	TIME [epoch: 11.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.958628110611804		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.958628110611804 | validation: 2.379047128475774]
	TIME [epoch: 11.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.893665349012692		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.893665349012692 | validation: 2.878906953942973]
	TIME [epoch: 11.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.096895005514379		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.096895005514379 | validation: 2.415673268412651]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.026761081347769		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.026761081347769 | validation: 2.7201752295432358]
	TIME [epoch: 11.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.863970415430794		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.863970415430794 | validation: 2.7972051118116372]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.726332695204239		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.726332695204239 | validation: 2.602589738949054]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.827374833427206		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.827374833427206 | validation: 3.928097306765516]
	TIME [epoch: 11.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1667563854087346		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.1667563854087346 | validation: 2.3989658151040776]
	TIME [epoch: 11.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0693503998189824		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.0693503998189824 | validation: 2.6171804984518796]
	TIME [epoch: 11.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.923314255112832		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.923314255112832 | validation: 2.533820550942999]
	TIME [epoch: 11.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9053665023093824		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.9053665023093824 | validation: 2.4236012449592184]
	TIME [epoch: 11.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.85889784205216		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.85889784205216 | validation: 2.359781164337229]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8501185116968637		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.8501185116968637 | validation: 2.5076048947324705]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.858552564052407		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.858552564052407 | validation: 2.468581466207517]
	TIME [epoch: 11.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6955910944147186		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.6955910944147186 | validation: 2.632426205078392]
	TIME [epoch: 11.5 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.992937031925347		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.992937031925347 | validation: 2.4081186617364385]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.783403002839764		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.783403002839764 | validation: 2.429188162705366]
	TIME [epoch: 11.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8594153588066087		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.8594153588066087 | validation: 2.4769717497929116]
	TIME [epoch: 11.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8186517147156076		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.8186517147156076 | validation: 2.5045049885590114]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6946509831314653		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.6946509831314653 | validation: 2.3808298295365917]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5783216135444866		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.5783216135444866 | validation: 2.634377714814873]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.101871473087678		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.101871473087678 | validation: 2.796946228795635]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7274416594446724		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.7274416594446724 | validation: 2.3107751254541853]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8304244987233487		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.8304244987233487 | validation: 2.566882255163293]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.725060355542198		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.725060355542198 | validation: 3.1485281393344873]
	TIME [epoch: 11.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.774437816550163		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.774437816550163 | validation: 2.5040386689647107]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8522809751105704		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.8522809751105704 | validation: 2.354773462693294]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.530163180103771		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.530163180103771 | validation: 2.616808927794985]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.707485053067485		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.707485053067485 | validation: 2.5217574505468794]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.995828147562253		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.995828147562253 | validation: 2.3566350945966947]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8530508849022667		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.8530508849022667 | validation: 2.2425901735160894]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.757155237423489		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.757155237423489 | validation: 2.325437400124779]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5789634266571317		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.5789634266571317 | validation: 2.501414709951201]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.605838476648467		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.605838476648467 | validation: 2.4658257730016726]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7327060050318646		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.7327060050318646 | validation: 2.2239872247188686]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6005089053043764		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.6005089053043764 | validation: 3.6110996701316487]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.892542488988348		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.892542488988348 | validation: 2.2730291356999826]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.654677292040422		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.654677292040422 | validation: 2.7279052836669013]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7320308523919943		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.7320308523919943 | validation: 2.419851513803516]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.697127405703327		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.697127405703327 | validation: 2.173109671784364]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6486583045659957		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.6486583045659957 | validation: 2.3154890665296968]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7649488081610802		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.7649488081610802 | validation: 2.219035030627884]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.572393269698364		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.572393269698364 | validation: 2.302234831217794]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6991366878024117		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.6991366878024117 | validation: 2.4443645405895587]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5107537008230865		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.5107537008230865 | validation: 2.246832835144506]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.664336464292335		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.664336464292335 | validation: 2.2002814068198857]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.453532872289133		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.453532872289133 | validation: 2.212008163014705]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6857503220252146		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.6857503220252146 | validation: 2.077659287699251]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5778183818172145		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.5778183818172145 | validation: 2.1925042814564883]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5178255775004925		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.5178255775004925 | validation: 2.4403770777825247]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.41855499286462		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.41855499286462 | validation: 2.2483632344852853]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6238252499204537		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.6238252499204537 | validation: 2.40002889628279]
	TIME [epoch: 11.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5659153113090736		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.5659153113090736 | validation: 2.2296709653067364]
	TIME [epoch: 11.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.726859965795348		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.726859965795348 | validation: 2.1946027848038807]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.554399049977929		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.554399049977929 | validation: 2.3639986964289825]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4737385587074883		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.4737385587074883 | validation: 2.4689443826782926]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6020413858192497		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.6020413858192497 | validation: 2.392405809483995]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.500819812620106		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.500819812620106 | validation: 2.0132646003816235]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5971265539094457		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.5971265539094457 | validation: 2.1171187581093074]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.488272700693296		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.488272700693296 | validation: 2.121948877287942]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3880297098684045		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.3880297098684045 | validation: 2.3110083269983255]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4220815921099366		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.4220815921099366 | validation: 2.36160951386476]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.562887877649905		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.562887877649905 | validation: 1.9679290426654836]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3800685635696066		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.3800685635696066 | validation: 2.0306618075147287]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3704033709604158		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.3704033709604158 | validation: 2.0539886831482823]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.371204274390312		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.371204274390312 | validation: 2.2865581726292272]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.517787721313222		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.517787721313222 | validation: 2.412277936816918]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.345574195597521		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.345574195597521 | validation: 2.0976944410475524]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6407110864392678		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.6407110864392678 | validation: 1.873300849501972]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4348149736236806		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.4348149736236806 | validation: 2.0445788825546947]
	TIME [epoch: 11.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2359031186670033		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.2359031186670033 | validation: 2.3162005868941864]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.387033667389021		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.387033667389021 | validation: 2.0811036134083145]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2315497320285256		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.2315497320285256 | validation: 1.8141751546845764]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5147361198980214		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.5147361198980214 | validation: 1.8968452172611794]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4121324282938743		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.4121324282938743 | validation: 2.2241251917138674]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3376857818505066		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.3376857818505066 | validation: 1.7751316183289072]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2342204547822124		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.2342204547822124 | validation: 2.1403962095914966]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1618934896900277		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.1618934896900277 | validation: 1.7735918981785488]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.137877375128914		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.137877375128914 | validation: 1.8037196975299394]
	TIME [epoch: 11.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3280532946690897		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.3280532946690897 | validation: 1.830482732866122]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053314834227426		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.053314834227426 | validation: 1.7697704346372154]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25178024246666		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.25178024246666 | validation: 1.8877027507997242]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.903092500725183		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.903092500725183 | validation: 1.6733425289375163]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.713321943550146		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.713321943550146 | validation: 1.2918736599553802]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7970092241293727		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.7970092241293727 | validation: 1.3741960139922265]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3664092111270831		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.3664092111270831 | validation: 1.0884970645066505]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1392209129168098		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.1392209129168098 | validation: 1.146435962107965]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0685929742623888		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.0685929742623888 | validation: 0.9362838840115926]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239863267620335		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.0239863267620335 | validation: 1.1771872124310516]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0627574835026405		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.0627574835026405 | validation: 1.3901568870080008]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1374789400863872		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.1374789400863872 | validation: 2.0117162313126613]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7666569329172144		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.7666569329172144 | validation: 1.3060314154736932]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9149313718634768		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.9149313718634768 | validation: 0.893515303521435]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9178995424734854		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.9178995424734854 | validation: 0.8596310814077376]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7983412468595943		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.7983412468595943 | validation: 1.145350346912157]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.512507013411953		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.512507013411953 | validation: 1.2267578724823551]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9597517844806224		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.9597517844806224 | validation: 0.783547620076767]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8191656863003058		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.8191656863003058 | validation: 0.8774763502987627]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9413222213807504		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.9413222213807504 | validation: 0.7233456827060839]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8721882049470213		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.8721882049470213 | validation: 1.3633831459126358]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9434818825037985		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.9434818825037985 | validation: 0.844379044330309]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.913115481019773		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.913115481019773 | validation: 1.0615149066450023]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8938887624889214		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.8938887624889214 | validation: 1.1571058016989417]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0150739290680153		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.0150739290680153 | validation: 0.7458430291111985]
	TIME [epoch: 11.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7489847386036013		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.7489847386036013 | validation: 0.9027876277042658]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064010132042495		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.7064010132042495 | validation: 1.0297069292581196]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.85113476816301		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.85113476816301 | validation: 0.6685725062769333]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6682110944090734		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.6682110944090734 | validation: 0.7858894845317329]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0382339852212006		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.0382339852212006 | validation: 1.0240414681623524]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.823141232244912		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.823141232244912 | validation: 0.7128681308464467]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8322208183280113		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.8322208183280113 | validation: 0.9357269391792231]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8083148464790416		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.8083148464790416 | validation: 0.6751647464894986]
	TIME [epoch: 11.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8005121133365098		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.8005121133365098 | validation: 0.8468347253850556]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9507670412055504		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.9507670412055504 | validation: 0.6389816949179691]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7820762897012109		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.7820762897012109 | validation: 0.7995856845957314]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7115027576466156		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.7115027576466156 | validation: 0.7403011717934322]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6559393785479576		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.6559393785479576 | validation: 0.6961396196026132]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.742547957611571		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.742547957611571 | validation: 1.1750618528738404]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7806335502380581		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.7806335502380581 | validation: 1.2640486011814698]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0212504286955597		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.0212504286955597 | validation: 1.3750453601861548]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9327794292983311		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.9327794292983311 | validation: 0.7217544159124492]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6476731238791873		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.6476731238791873 | validation: 1.1131999030952344]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9702411285863252		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.9702411285863252 | validation: 0.689948488266092]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6580379772421162		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.6580379772421162 | validation: 0.7101829115159407]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6059205187116442		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.6059205187116442 | validation: 0.9378927944582551]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7704944564763827		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.7704944564763827 | validation: 0.9682079983022098]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7762901760211334		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.7762901760211334 | validation: 0.575570051277285]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6380942094142685		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.6380942094142685 | validation: 0.8641224662044843]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7531655879834793		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.7531655879834793 | validation: 0.698098494579311]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6524123094782877		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.6524123094782877 | validation: 1.5762356870152168]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8685969370929665		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.8685969370929665 | validation: 0.5879933800062921]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9153390563850543		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.9153390563850543 | validation: 0.7009033231892298]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6709130652789668		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.6709130652789668 | validation: 0.7359445294968439]
	TIME [epoch: 11.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6149679907404725		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.6149679907404725 | validation: 0.7024119570057128]
	TIME [epoch: 11.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7845814728379207		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.7845814728379207 | validation: 0.7304481467553811]
	TIME [epoch: 11.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6610135166836153		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.6610135166836153 | validation: 1.4804474344752891]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9553775208825154		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.9553775208825154 | validation: 0.6194567144002439]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6461982978999258		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.6461982978999258 | validation: 0.8560582710216386]
	TIME [epoch: 11.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850175764423717		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.6850175764423717 | validation: 1.212105038744405]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7162535465719688		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.7162535465719688 | validation: 0.8373241985800093]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6168393648300224		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.6168393648300224 | validation: 1.1615059447820142]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8346709120764995		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.8346709120764995 | validation: 0.8183204526108472]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6673078193012061		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.6673078193012061 | validation: 0.9243335347824063]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7425100245344969		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.7425100245344969 | validation: 1.2200719352445846]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7644084813879458		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.7644084813879458 | validation: 1.0142340258338642]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6806616412862755		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.6806616412862755 | validation: 0.6207675231130279]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6239273536378172		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.6239273536378172 | validation: 0.8841246833942955]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7895027064889665		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.7895027064889665 | validation: 0.7788324804906783]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7510918277953691		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.7510918277953691 | validation: 0.6241145871429975]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5704545184510414		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.5704545184510414 | validation: 0.6634165914329574]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5792582153107043		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.5792582153107043 | validation: 0.635061729974191]
	TIME [epoch: 11.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5738005551446674		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.5738005551446674 | validation: 1.094400392541671]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6538296037859832		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.6538296037859832 | validation: 0.6435740768676569]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5660950415493593		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.5660950415493593 | validation: 0.4908924789304962]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8152252323845982		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.8152252323845982 | validation: 0.5987940675039874]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6684903210396232		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.6684903210396232 | validation: 0.8359822698579071]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6891661103982053		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.6891661103982053 | validation: 0.7497995477172456]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8512335863591576		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8512335863591576 | validation: 0.8046335601759467]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5713682053889584		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.5713682053889584 | validation: 0.7900873150361832]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5952457691719888		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.5952457691719888 | validation: 0.49423726105409105]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6769839039291201		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.6769839039291201 | validation: 1.0590574727837534]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7830771875118911		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.7830771875118911 | validation: 0.5348742903439893]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5408689647279389		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.5408689647279389 | validation: 0.5853393106515771]
	TIME [epoch: 11.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5732951318840546		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.5732951318840546 | validation: 0.6458386228892589]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6110290845802091		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.6110290845802091 | validation: 0.46704394975249613]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5848368349896992		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.5848368349896992 | validation: 0.9637561817649952]
	TIME [epoch: 11.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6175584234363128		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.6175584234363128 | validation: 0.7499517515727387]
	TIME [epoch: 11.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6395063421303423		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.6395063421303423 | validation: 0.5424298272007648]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.561599013784654		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.561599013784654 | validation: 0.6243675313397137]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5730756067513468		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.5730756067513468 | validation: 0.6718788222013856]
	TIME [epoch: 11.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.639623089786318		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.639623089786318 | validation: 0.8970482881619282]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5803352391568111		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.5803352391568111 | validation: 0.6074930395773231]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6244865575523346		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.6244865575523346 | validation: 0.7530334719474615]
	TIME [epoch: 11.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.640268444641059		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.640268444641059 | validation: 0.6337915168641821]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5362287142838527		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.5362287142838527 | validation: 0.9187699294939462]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7594877356129799		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.7594877356129799 | validation: 0.4628539579886195]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.449752126340365		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.449752126340365 | validation: 0.5437702287540513]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5948768299445502		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.5948768299445502 | validation: 0.43866750921677783]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.600926387770291		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.600926387770291 | validation: 1.1264532306419117]
	TIME [epoch: 11.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.802747837590329		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.802747837590329 | validation: 0.6817595626400155]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6460031452546462		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.6460031452546462 | validation: 0.46839807328321187]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5944787659397788		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.5944787659397788 | validation: 0.5063354630626846]
	TIME [epoch: 11.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5041006894302589		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.5041006894302589 | validation: 0.7411398700548089]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.81015734605693		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.81015734605693 | validation: 0.5094643111190466]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6671733722889067		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.6671733722889067 | validation: 0.4857115052088763]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42377002405677333		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.42377002405677333 | validation: 0.4341704166474099]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5392594005691328		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.5392594005691328 | validation: 0.4529185508271105]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5070379488535814		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.5070379488535814 | validation: 0.4485787662442081]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5167938383967043		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.5167938383967043 | validation: 0.5899543329524886]
	TIME [epoch: 11.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5799950511598153		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.5799950511598153 | validation: 0.7503381263846944]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.461861007165482		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.461861007165482 | validation: 0.8577921838356057]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6163202461017268		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.6163202461017268 | validation: 0.6174191426679816]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5616108020166752		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.5616108020166752 | validation: 0.7354838147773303]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5848686202459993		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.5848686202459993 | validation: 0.47372196587547905]
	TIME [epoch: 11.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5604003169753654		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.5604003169753654 | validation: 0.8596026204551146]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5692916533096388		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.5692916533096388 | validation: 0.45233449818133437]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6245389926214263		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.6245389926214263 | validation: 0.5249648070462577]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5070820019302791		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.5070820019302791 | validation: 0.8033629022725651]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5525228587302843		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.5525228587302843 | validation: 0.7300520496316402]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6448740828820302		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.6448740828820302 | validation: 0.4926536855897669]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5433436311274316		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.5433436311274316 | validation: 0.4458682297315501]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45581793950195665		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.45581793950195665 | validation: 0.6072599164693001]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47787673193202707		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.47787673193202707 | validation: 0.6680824040754282]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5943707414834456		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.5943707414834456 | validation: 0.43192667996006806]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5535145092211502		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.5535145092211502 | validation: 0.49730325118442786]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4525243403722413		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.4525243403722413 | validation: 0.6808581344766981]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5460005521256973		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.5460005521256973 | validation: 0.43103871143893135]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4609068664954873		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.4609068664954873 | validation: 0.6208604290358583]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4962242427384136		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.4962242427384136 | validation: 0.6507776930779591]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4617703347821712		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.4617703347821712 | validation: 0.4679365732561709]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4555468458447482		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.4555468458447482 | validation: 0.4790197557165341]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4529905421290466		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.4529905421290466 | validation: 0.5868047534036605]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7634951741439138		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.7634951741439138 | validation: 0.9692630346269124]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6491306432449158		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.6491306432449158 | validation: 0.5250929483954755]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5378925664255056		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.5378925664255056 | validation: 0.5202093929289562]
	TIME [epoch: 11.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46261040399767167		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.46261040399767167 | validation: 0.49375735366586426]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4550981238612513		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.4550981238612513 | validation: 0.6698057719804444]
	TIME [epoch: 11.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5289716397694313		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.5289716397694313 | validation: 1.1459607743818712]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7432880717985786		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.7432880717985786 | validation: 0.6498826267766856]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593878802194607		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.5593878802194607 | validation: 0.41664029248368084]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4716425975183949		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.4716425975183949 | validation: 0.918580154046889]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5700528449701296		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.5700528449701296 | validation: 0.4423380541479604]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.518294717980248		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.518294717980248 | validation: 1.0278208322704363]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215474106746286		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.7215474106746286 | validation: 0.5517810744839844]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4826566672532685		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.4826566672532685 | validation: 0.6608871199433948]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5644518634379743		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.5644518634379743 | validation: 0.45619860479971125]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4264417677241592		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.4264417677241592 | validation: 0.48939298766879374]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199622727511845		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.5199622727511845 | validation: 0.5028974743272459]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40448189769650156		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.40448189769650156 | validation: 0.5889977109750839]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45362714804518933		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.45362714804518933 | validation: 0.4637750895314603]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4908444905909784		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.4908444905909784 | validation: 0.693976878138693]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5055426344690691		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.5055426344690691 | validation: 0.4565323242160767]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.466266995998583		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.466266995998583 | validation: 0.6787520288447799]
	TIME [epoch: 11.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4675023378037542		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.4675023378037542 | validation: 0.47049443313920586]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49730189693938603		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.49730189693938603 | validation: 0.6770355579343023]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5668970953171968		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.5668970953171968 | validation: 0.5002869403196074]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.426039229196803		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.426039229196803 | validation: 1.149718054172035]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7131053897689592		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.7131053897689592 | validation: 0.6260493104289355]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.440840772382157		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.440840772382157 | validation: 0.393870778428397]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563387076696825		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.6563387076696825 | validation: 0.4977163156207712]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5710425394478555		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.5710425394478555 | validation: 0.4065785624092716]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4115122749839337		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.4115122749839337 | validation: 0.6000788496373589]
	TIME [epoch: 11.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.506276670517114		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.506276670517114 | validation: 0.40878566754199996]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49449124075124223		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.49449124075124223 | validation: 0.37455748359973323]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_298.pth
	Model improved!!!
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38343228125834417		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.38343228125834417 | validation: 0.4823330931326213]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44719032590099644		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.44719032590099644 | validation: 0.5130834655119414]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3897184355339546		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.3897184355339546 | validation: 0.4445775788572797]
	TIME [epoch: 11.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40638545292862094		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.40638545292862094 | validation: 0.45112494725007596]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4722899762531757		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.4722899762531757 | validation: 0.7183988170352862]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6152150040680933		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.6152150040680933 | validation: 0.33364132227080234]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4218790535253594		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.4218790535253594 | validation: 0.45343730807945376]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48391424594017385		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.48391424594017385 | validation: 0.5375717395737357]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5624990128613712		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.5624990128613712 | validation: 0.5283647479678696]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43923241613510056		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.43923241613510056 | validation: 0.4437707517126376]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409867005423904		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.409867005423904 | validation: 0.4096902914599824]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141432227978867		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.5141432227978867 | validation: 0.5026959176832878]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39500343714193975		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.39500343714193975 | validation: 0.464443792595177]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4097399796118052		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.4097399796118052 | validation: 0.42918301183141483]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5904416085811655		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.5904416085811655 | validation: 0.39046251136862453]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3646654921384176		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.3646654921384176 | validation: 0.4034101414025298]
	TIME [epoch: 11.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3980461187897455		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.3980461187897455 | validation: 0.4687185921937197]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38371824520079006		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.38371824520079006 | validation: 0.41137760751278474]
	TIME [epoch: 11.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3279679343103359		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.3279679343103359 | validation: 0.341089103901554]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49506787548310616		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.49506787548310616 | validation: 0.32723033216177927]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442839080925588		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.3442839080925588 | validation: 0.45023215294471175]
	TIME [epoch: 11.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48565922813984636		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.48565922813984636 | validation: 0.4110689121068053]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6902880253553276		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6902880253553276 | validation: 0.7562876106316497]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48140464602278077		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.48140464602278077 | validation: 0.34661747350214206]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5285389938551016		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.5285389938551016 | validation: 0.6641669657533579]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4921130345115484		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.4921130345115484 | validation: 0.461856574746959]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38476105851301107		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.38476105851301107 | validation: 0.3824509796677258]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454086928220956		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.3454086928220956 | validation: 0.6830489120098717]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077795789327875		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.5077795789327875 | validation: 0.42074847509985963]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409495432105753		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.409495432105753 | validation: 0.614649649167469]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45037897812847993		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.45037897812847993 | validation: 0.320422354860784]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_329.pth
	Model improved!!!
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4314262840554787		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.4314262840554787 | validation: 0.4515573837021962]
	TIME [epoch: 11.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5390889009137733		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5390889009137733 | validation: 0.49180964246582115]
	TIME [epoch: 11.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4134232526641999		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.4134232526641999 | validation: 0.4525533392233896]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5046396522188854		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.5046396522188854 | validation: 0.5564792607444667]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44949109517108543		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.44949109517108543 | validation: 0.37037043588510005]
	TIME [epoch: 11.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36142175915204916		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.36142175915204916 | validation: 0.37415978130608224]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3996724208957677		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.3996724208957677 | validation: 0.37581170736364866]
	TIME [epoch: 11.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4291611914723573		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.4291611914723573 | validation: 0.3486174605712759]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4908790571773798		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.4908790571773798 | validation: 0.45079242847955003]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3562057428908763		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.3562057428908763 | validation: 0.4393798673399498]
	TIME [epoch: 11.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36115430980906266		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.36115430980906266 | validation: 0.40064980172100934]
	TIME [epoch: 11.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5854115626016192		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.5854115626016192 | validation: 0.3792933118950833]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3704820488784988		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.3704820488784988 | validation: 0.6971649181272962]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4095338547009153		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.4095338547009153 | validation: 0.436963592039337]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3756549439780989		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.3756549439780989 | validation: 0.6774844328353866]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42527504072549027		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.42527504072549027 | validation: 0.4129532306644475]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43197641546134774		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.43197641546134774 | validation: 1.3880064143640536]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8561863394324214		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.8561863394324214 | validation: 0.3610932300845509]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.420605720970244		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.420605720970244 | validation: 0.531198314670425]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3794065374255786		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.3794065374255786 | validation: 0.3555306760415593]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31326522968639847		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.31326522968639847 | validation: 0.31608213106163585]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5039309558424612		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.5039309558424612 | validation: 0.3799284553601769]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32024034085176106		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.32024034085176106 | validation: 0.34525582264720217]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4014126079135282		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.4014126079135282 | validation: 0.44813549131220554]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38142903923293703		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.38142903923293703 | validation: 0.41954754313128917]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093495062209466		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.3093495062209466 | validation: 0.6024241945414399]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39738182084823104		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.39738182084823104 | validation: 0.3771639228763954]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32871777972357274		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.32871777972357274 | validation: 0.7821009383889543]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4533458163432481		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.4533458163432481 | validation: 0.4160848264805461]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35069658393496517		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.35069658393496517 | validation: 0.32261045661162097]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35415133498592494		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.35415133498592494 | validation: 0.9802397736741747]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.566699136648371		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.566699136648371 | validation: 0.3873405716116929]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3465200104855809		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.3465200104855809 | validation: 0.5255871876278663]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3177308167997181		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.3177308167997181 | validation: 0.39730286371490076]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3650528664243228		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.3650528664243228 | validation: 0.3975714210111086]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860218859233497		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.3860218859233497 | validation: 0.3006172530633088]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_365.pth
	Model improved!!!
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3858861614105411		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.3858861614105411 | validation: 0.3206721312817457]
	TIME [epoch: 11.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3311293119688875		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.3311293119688875 | validation: 0.3536991264391912]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3282409326168441		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.3282409326168441 | validation: 0.4072986063241102]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7704359009698418		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.7704359009698418 | validation: 0.317768642536946]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3641002693694929		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.3641002693694929 | validation: 0.3169110698450933]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29776969879538395		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.29776969879538395 | validation: 0.3683769205518108]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37684054117822074		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.37684054117822074 | validation: 0.3551554826228789]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4395476300157245		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.4395476300157245 | validation: 0.34259957932153584]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3286139595096234		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.3286139595096234 | validation: 0.346139238197553]
	TIME [epoch: 11.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31528958632443943		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.31528958632443943 | validation: 0.3168995905832336]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521968958471417		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.3521968958471417 | validation: 0.34983416494531017]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385131539433114		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.3385131539433114 | validation: 0.3248539877186423]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35315500823993384		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.35315500823993384 | validation: 0.4456403819403741]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37469769301185263		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.37469769301185263 | validation: 0.39562477519318306]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41990966523397333		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.41990966523397333 | validation: 0.31312198299568805]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30901860419251437		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.30901860419251437 | validation: 0.44845280491284345]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34199657069698314		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.34199657069698314 | validation: 0.6133254568301084]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4362616753644071		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.4362616753644071 | validation: 0.40134498667822294]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3068912980929445		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.3068912980929445 | validation: 0.43549113927340743]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4089938202653643		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.4089938202653643 | validation: 0.35889051508986214]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3170093920212408		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.3170093920212408 | validation: 0.34852367953913926]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702653827334472		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.3702653827334472 | validation: 0.3841677965441299]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3159447341678029		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.3159447341678029 | validation: 0.41206994397088337]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36192982148709324		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.36192982148709324 | validation: 0.34367143599216154]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3315644765776655		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.3315644765776655 | validation: 0.44846238742137007]
	TIME [epoch: 11.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33013639777169684		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.33013639777169684 | validation: 0.3890904353097645]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32761886579299815		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.32761886579299815 | validation: 0.25850755518786295]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3397604434636662		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.3397604434636662 | validation: 0.3715060477036527]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.307210387281206		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.307210387281206 | validation: 0.3839188911220943]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33334305205085923		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.33334305205085923 | validation: 0.33209812000100397]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3212347312133913		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.3212347312133913 | validation: 0.33235363686213576]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2977309601508652		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.2977309601508652 | validation: 0.4219653162627697]
	TIME [epoch: 11.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.315534531591464		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.315534531591464 | validation: 0.2737903182398998]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453369169771981		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.3453369169771981 | validation: 0.3498126724632139]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27667755251562365		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.27667755251562365 | validation: 0.3901919337595983]
	TIME [epoch: 11.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295804322565519		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.3295804322565519 | validation: 0.2496112941707397]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25943800500754477		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.25943800500754477 | validation: 0.31601266050420057]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30184626186576846		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.30184626186576846 | validation: 0.45721167719584416]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552199035704283		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.3552199035704283 | validation: 0.3965592909481852]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34310600276979825		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.34310600276979825 | validation: 0.3634827921463563]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3271767333328348		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.3271767333328348 | validation: 0.3811403107159672]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39800136533471986		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.39800136533471986 | validation: 0.4583518412904293]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652313886468522		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.3652313886468522 | validation: 0.3738090225313526]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31438011924263826		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.31438011924263826 | validation: 0.48946935323754387]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38497520883936354		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.38497520883936354 | validation: 0.339532071660039]
	TIME [epoch: 11.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31525900555234815		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.31525900555234815 | validation: 0.5849020547940817]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359469141427593		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.359469141427593 | validation: 0.3619596873592873]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2824065886488897		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.2824065886488897 | validation: 0.5018716340963436]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46528661597687815		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.46528661597687815 | validation: 0.2774776307248186]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2884102386914415		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.2884102386914415 | validation: 0.35726900429537894]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491304201432402		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.3491304201432402 | validation: 0.29894673473024513]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943131392640096		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.2943131392640096 | validation: 0.32944388674890773]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.264058526163783		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.264058526163783 | validation: 0.5577392981634225]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3799610903318499		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.3799610903318499 | validation: 0.33607797115293964]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2775235657895957		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.2775235657895957 | validation: 0.315930640248233]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30018284471410506		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.30018284471410506 | validation: 0.25372581356899004]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28817864393041576		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.28817864393041576 | validation: 0.2934675859710578]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33331841325600925		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.33331841325600925 | validation: 0.36708923317274644]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36247661212849513		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.36247661212849513 | validation: 0.37932636003058967]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003251574640615		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.3003251574640615 | validation: 0.31505767688677894]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36975211784127154		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.36975211784127154 | validation: 0.2787637130913125]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28816079964821023		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.28816079964821023 | validation: 0.29479599878452234]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3170615746855468		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.3170615746855468 | validation: 0.32699333731746516]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25751910015453117		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.25751910015453117 | validation: 0.3070385618349607]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22397642680778834		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.22397642680778834 | validation: 0.2508076057633547]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2596734787389749		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.2596734787389749 | validation: 0.4757394871514988]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3525196883266978		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.3525196883266978 | validation: 0.25467238571692213]
	TIME [epoch: 11.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2631323140291377		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.2631323140291377 | validation: 0.3618913955464407]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3191293469810872		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.3191293469810872 | validation: 0.27409598929926693]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.318278253347974		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.318278253347974 | validation: 0.24300174360703117]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34427006263133475		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.34427006263133475 | validation: 0.25460105820967527]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3746582040746237		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.3746582040746237 | validation: 0.3077634590350906]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552519416124903		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.3552519416124903 | validation: 0.38398687785390595]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925780269090664		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.2925780269090664 | validation: 0.3034076865196549]
	TIME [epoch: 11.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2948020348616269		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.2948020348616269 | validation: 0.25603723139409446]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26122734391885316		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.26122734391885316 | validation: 0.5386285873154301]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365396131170983		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.365396131170983 | validation: 0.26056737259490587]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440667938939249		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.3440667938939249 | validation: 0.3030044345312847]
	TIME [epoch: 11.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2706040731624735		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.2706040731624735 | validation: 0.3521435299658686]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3221068531330256		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.3221068531330256 | validation: 0.44384286119009203]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3131575739927705		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.3131575739927705 | validation: 0.26193834156579193]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27457205336178064		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.27457205336178064 | validation: 0.26477887925846827]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2672716004199272		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.2672716004199272 | validation: 0.274044122763111]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27294322797538967		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.27294322797538967 | validation: 0.2981106931479216]
	TIME [epoch: 11.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26499662363522775		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.26499662363522775 | validation: 0.26360735577826966]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26410893916517736		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.26410893916517736 | validation: 0.4913052722486515]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29453627772450197		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.29453627772450197 | validation: 0.2567518478550362]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26485928889122945		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.26485928889122945 | validation: 0.31065679673258745]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2516667809682475		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.2516667809682475 | validation: 0.34605057595838845]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.291966825558337		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.291966825558337 | validation: 0.2460322032487793]
	TIME [epoch: 11.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26337759856553145		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.26337759856553145 | validation: 0.4817563988358602]
	TIME [epoch: 11.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2950416686156855		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.2950416686156855 | validation: 0.2878327662522179]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755893902602659		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.2755893902602659 | validation: 0.45470671363343357]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28469635748413713		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.28469635748413713 | validation: 0.6215950454519248]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3989978311630613		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.3989978311630613 | validation: 0.2815069673489514]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23194423542318893		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.23194423542318893 | validation: 0.27693270195825875]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29741980494268194		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.29741980494268194 | validation: 0.34217103091250456]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28863676334208305		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.28863676334208305 | validation: 0.2372992609688358]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_463.pth
	Model improved!!!
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2684678361040975		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.2684678361040975 | validation: 0.28173117203074716]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29910146716079755		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.29910146716079755 | validation: 0.2543315993544283]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2717632324163688		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.2717632324163688 | validation: 0.34704173225214624]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39184129876248275		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.39184129876248275 | validation: 0.6701595046035734]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3438408267036887		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.3438408267036887 | validation: 0.4157330454444534]
	TIME [epoch: 11.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28556782109059065		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.28556782109059065 | validation: 0.29737204089226327]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43255313976014736		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.43255313976014736 | validation: 0.4955765022186502]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35337539429978876		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.35337539429978876 | validation: 0.2709101528528231]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22780424818617268		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.22780424818617268 | validation: 0.304902964690227]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509030476576449		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.2509030476576449 | validation: 0.38087786290891545]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2991514297288385		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.2991514297288385 | validation: 0.29301078795055374]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25701377536736214		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.25701377536736214 | validation: 0.28563600472671785]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923237915907455		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2923237915907455 | validation: 0.2611245915049224]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29282519115551464		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.29282519115551464 | validation: 0.40679297827043054]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32029789591252744		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.32029789591252744 | validation: 0.2749221004522926]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25415503519367		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.25415503519367 | validation: 0.2813690011016807]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2820029811589172		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.2820029811589172 | validation: 0.29879708467618027]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3030478147946829		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.3030478147946829 | validation: 0.24348360554865728]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28570830401469116		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.28570830401469116 | validation: 0.25668735649272684]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2566309209911313		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.2566309209911313 | validation: 0.2373540903528056]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3504113080712643		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.3504113080712643 | validation: 0.2829438186900017]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26303042845285163		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.26303042845285163 | validation: 0.28777252133587883]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21766884518105756		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.21766884518105756 | validation: 0.32422329999937005]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2773286163028364		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.2773286163028364 | validation: 0.3354851082022563]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24688952958154597		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.24688952958154597 | validation: 0.23734332630303498]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2236268285698439		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.2236268285698439 | validation: 0.36383851992303284]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5429370540523769		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.5429370540523769 | validation: 0.34089717668814146]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24992538484823007		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.24992538484823007 | validation: 0.31788618471309954]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26884751050802846		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.26884751050802846 | validation: 0.22802694875529908]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_492.pth
	Model improved!!!
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624942544955127		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.2624942544955127 | validation: 0.28823186040543863]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30826784596782547		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.30826784596782547 | validation: 0.21373889944593089]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25690778697626315		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.25690778697626315 | validation: 0.2482686122074593]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3072136884124197		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.3072136884124197 | validation: 0.2700819419467036]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3658612016086879		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.3658612016086879 | validation: 0.2844909391094383]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27892719280417766		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.27892719280417766 | validation: 0.29840053816683154]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25372003235179597		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.25372003235179597 | validation: 0.23648680581916595]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2212764567249753		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.2212764567249753 | validation: 0.4082348087728096]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2975622672633013		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.2975622672633013 | validation: 0.3444217263051976]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2932855161144219		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.2932855161144219 | validation: 0.20673294891865646]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_502.pth
	Model improved!!!
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27860173431862406		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.27860173431862406 | validation: 0.4184557711385024]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3375486793991872		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.3375486793991872 | validation: 0.2602494222945239]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23998446045621344		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.23998446045621344 | validation: 0.260851078799487]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2390448791357549		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.2390448791357549 | validation: 0.2857863805230081]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28020894460335144		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.28020894460335144 | validation: 0.660689391409981]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36793767303357994		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.36793767303357994 | validation: 0.29029196236348015]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30323611241209386		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.30323611241209386 | validation: 0.3050144306694363]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.302435817781046		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.302435817781046 | validation: 0.22813747829059813]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26291350467634816		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.26291350467634816 | validation: 0.28358681686914755]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2779536121527789		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.2779536121527789 | validation: 0.3437796315490149]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32037480148189984		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.32037480148189984 | validation: 0.2781164622461712]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28682195592181287		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.28682195592181287 | validation: 0.3102171211340329]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23958944966552406		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.23958944966552406 | validation: 0.28321240509681417]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2419083034242436		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.2419083034242436 | validation: 0.24052851350945412]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25943790653946197		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.25943790653946197 | validation: 0.23843684357357528]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2875521166793723		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.2875521166793723 | validation: 0.24820305631000544]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2255329099042252		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.2255329099042252 | validation: 0.2840318525612471]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25916932764380374		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.25916932764380374 | validation: 0.26745554455557286]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2445863324208601		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.2445863324208601 | validation: 0.22137210099225854]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22134460551517549		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.22134460551517549 | validation: 0.26190133342754157]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933389145320223		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.2933389145320223 | validation: 0.24197482951570923]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27377592893875335		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.27377592893875335 | validation: 0.27147466938340753]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28121039855662405		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.28121039855662405 | validation: 0.34891519778637486]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2417336324137167		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.2417336324137167 | validation: 0.25396400665996394]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2341439454443307		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.2341439454443307 | validation: 0.33452220236319336]
	TIME [epoch: 11.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30819868271340267		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.30819868271340267 | validation: 0.6013463165987636]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3409661361479417		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.3409661361479417 | validation: 0.2564849755435192]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28332607865500437		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.28332607865500437 | validation: 0.20261412890379604]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_530.pth
	Model improved!!!
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24616072465504432		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.24616072465504432 | validation: 0.21272830253347386]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22025916047312344		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.22025916047312344 | validation: 0.2679697256367637]
	TIME [epoch: 11.4 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2243976911954428		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.2243976911954428 | validation: 0.2090526310413402]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22252334211556246		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.22252334211556246 | validation: 0.3252014887774689]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25724733057320615		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.25724733057320615 | validation: 0.23735873784104045]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2116378602148349		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.2116378602148349 | validation: 0.24723093045746708]
	TIME [epoch: 11.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524001124822145		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.2524001124822145 | validation: 0.2598720252087775]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26686860734849477		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.26686860734849477 | validation: 0.35135492536620405]
	TIME [epoch: 11.4 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24750989180879962		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.24750989180879962 | validation: 0.3017421298756555]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20195376375244786		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.20195376375244786 | validation: 0.2545804157848265]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21427322528255796		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.21427322528255796 | validation: 0.253990508478902]
	TIME [epoch: 11.4 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21605354062797588		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.21605354062797588 | validation: 0.4306650778850544]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612290096859293		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.3612290096859293 | validation: 0.22687174417083647]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2477739882348376		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.2477739882348376 | validation: 0.23308193505163943]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23224791030675168		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.23224791030675168 | validation: 0.24209165942601601]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22363666924846645		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.22363666924846645 | validation: 0.23302677923332268]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2011813754676494		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.2011813754676494 | validation: 0.24515510278496463]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24550302776845184		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.24550302776845184 | validation: 0.19450573809447821]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29665951407933555		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.29665951407933555 | validation: 0.2695446196923669]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24983248582171788		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.24983248582171788 | validation: 0.3465490591789714]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26279822472897574		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.26279822472897574 | validation: 0.27739846926948086]
	TIME [epoch: 11.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2226756414680072		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.2226756414680072 | validation: 0.24229729050855744]
	TIME [epoch: 11.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21306235303595866		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.21306235303595866 | validation: 0.2167588663637734]
	TIME [epoch: 11.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21121622155715308		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.21121622155715308 | validation: 0.2816648476843258]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23339100904714055		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.23339100904714055 | validation: 0.27925209841999804]
	TIME [epoch: 11.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21425809021990522		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.21425809021990522 | validation: 0.2380300567399933]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2013985427155502		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.2013985427155502 | validation: 0.21187637954410754]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21505392867897297		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.21505392867897297 | validation: 0.26194125961813225]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23090789040023182		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.23090789040023182 | validation: 0.2707481958331012]
	TIME [epoch: 11.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22635084682144593		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.22635084682144593 | validation: 0.3266753864891521]
	TIME [epoch: 11.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24322762422767957		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.24322762422767957 | validation: 0.24900605886532404]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19876897894153492		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.19876897894153492 | validation: 0.28751018438008813]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2104648767613006		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.2104648767613006 | validation: 0.24335143033511536]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24020408195136755		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.24020408195136755 | validation: 0.23833266628890318]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2579564934866272		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.2579564934866272 | validation: 0.22467815466585034]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24765599983162934		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.24765599983162934 | validation: 0.221225603808084]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1954098164792191		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.1954098164792191 | validation: 0.3612640925434549]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2468539215561465		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.2468539215561465 | validation: 0.2401416525504197]
	TIME [epoch: 11.4 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20542361899503628		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.20542361899503628 | validation: 0.2250662266741673]
	TIME [epoch: 11.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23463392145836734		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.23463392145836734 | validation: 0.19856598183847568]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17904376653550977		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.17904376653550977 | validation: 0.21885910910211684]
	TIME [epoch: 11.4 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2125399693066361		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.2125399693066361 | validation: 0.2733333558648795]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998187736072514		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.2998187736072514 | validation: 0.35986327259434786]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24794664225732677		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.24794664225732677 | validation: 0.2281333702526354]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20894106587192812		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.20894106587192812 | validation: 0.28788185851987214]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2441108231435382		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.2441108231435382 | validation: 0.3234257998530725]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26196228089325846		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.26196228089325846 | validation: 0.2588719509802353]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21191827569629054		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.21191827569629054 | validation: 0.20421108450866826]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17343928005853074		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.17343928005853074 | validation: 0.21943417960160638]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2049420343184047		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.2049420343184047 | validation: 0.3328197458085101]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3240695180001594		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.3240695180001594 | validation: 0.29446454393217486]
	TIME [epoch: 11.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106909416542639		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.2106909416542639 | validation: 0.4410949824739652]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3176036822900328		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.3176036822900328 | validation: 0.37930575333911576]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3977898318385294		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.3977898318385294 | validation: 0.3148475445879744]
	TIME [epoch: 11.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3246723990113924		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.3246723990113924 | validation: 0.32485255408481406]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24581827779767573		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.24581827779767573 | validation: 0.2336005898520032]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21757344496059397		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.21757344496059397 | validation: 0.3036700278715928]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2321589867122944		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.2321589867122944 | validation: 0.2168961558383]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18963311409619543		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.18963311409619543 | validation: 0.20445142232731614]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2075889982568863		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.2075889982568863 | validation: 0.22625156161342644]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18950223221520743		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.18950223221520743 | validation: 0.23211824044241433]
	TIME [epoch: 11.4 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21170745955121484		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.21170745955121484 | validation: 0.2236787328877602]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19771181374584923		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.19771181374584923 | validation: 0.18676785169799623]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_593.pth
	Model improved!!!
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19627187797454715		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.19627187797454715 | validation: 0.22744164855896748]
	TIME [epoch: 11.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21755854077857326		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.21755854077857326 | validation: 0.20176369527643162]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20973102990648035		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.20973102990648035 | validation: 0.814689312978758]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49064307818737407		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.49064307818737407 | validation: 0.2373710126684116]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20953461997397127		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.20953461997397127 | validation: 0.2368385778881012]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19329002909171067		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.19329002909171067 | validation: 0.2865669124554858]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19621251270659174		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.19621251270659174 | validation: 0.22325443714778467]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3129006888236291		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.3129006888236291 | validation: 0.2840128891670627]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2180097125377111		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2180097125377111 | validation: 0.27875522798340735]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21389812831904842		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.21389812831904842 | validation: 0.24820694755431366]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27887731894935974		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.27887731894935974 | validation: 0.30052953693344736]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21358330967943198		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.21358330967943198 | validation: 0.22220396287664243]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17490797769903446		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.17490797769903446 | validation: 0.24097587932360576]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24888355427209885		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.24888355427209885 | validation: 0.31267144906442884]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21968700376538702		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.21968700376538702 | validation: 0.2266563807243607]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19552950414485562		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.19552950414485562 | validation: 0.23571760588058838]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19687766105605556		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.19687766105605556 | validation: 0.20575917436350316]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21997019413816804		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.21997019413816804 | validation: 0.2613931555841764]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23369038656512953		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.23369038656512953 | validation: 0.20131460483451735]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19842498419985874		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.19842498419985874 | validation: 0.2653223926937402]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2104146845172074		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.2104146845172074 | validation: 0.2919838845972024]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24456347622235974		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.24456347622235974 | validation: 0.21364208636844406]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1959990736955371		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.1959990736955371 | validation: 0.1888093673631499]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23556484164156827		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.23556484164156827 | validation: 0.37109553758758873]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3004782332153626		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.3004782332153626 | validation: 0.36725333733283605]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31910121047347684		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.31910121047347684 | validation: 0.30985806636304436]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24001882606451314		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.24001882606451314 | validation: 0.2595799956368597]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19459873340902745		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.19459873340902745 | validation: 0.2911113561303376]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2707403114882426		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.2707403114882426 | validation: 0.2762128708679868]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21178036511765944		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.21178036511765944 | validation: 0.19573878926139002]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17540379979124188		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.17540379979124188 | validation: 0.21627404371578907]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1912697010775503		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.1912697010775503 | validation: 0.22704895446527826]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18846083171749084		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.18846083171749084 | validation: 0.19890953770803557]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18436490199038702		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.18436490199038702 | validation: 0.36312684381672056]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2450679153199366		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.2450679153199366 | validation: 0.21761263444240425]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.201466369280793		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.201466369280793 | validation: 0.26080068391294636]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2269414660512203		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.2269414660512203 | validation: 0.1992183452444707]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22137542335110452		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.22137542335110452 | validation: 0.24504676883308033]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24928162782623983		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.24928162782623983 | validation: 0.2546558424725659]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19739308082713802		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.19739308082713802 | validation: 0.2257620560515631]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19875970912960755		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.19875970912960755 | validation: 0.18885531258317342]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1704089594008077		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.1704089594008077 | validation: 0.2537016161815415]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.226007194667472		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.226007194667472 | validation: 0.2379260617045425]
	TIME [epoch: 11.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20915986638338657		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.20915986638338657 | validation: 0.20432976111511691]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2507777739247145		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.2507777739247145 | validation: 0.27151925058735943]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2139039431275997		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.2139039431275997 | validation: 0.20354844527114488]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1753160747247679		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.1753160747247679 | validation: 0.2085700265785344]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19408410345198052		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.19408410345198052 | validation: 0.21243125442422062]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17760545419852136		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.17760545419852136 | validation: 0.19031828977264245]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20761553357947962		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.20761553357947962 | validation: 0.3873035290472795]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25913585768538394		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.25913585768538394 | validation: 0.19829760521574827]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21091325158025695		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.21091325158025695 | validation: 0.2103058056928318]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22657995067941294		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.22657995067941294 | validation: 0.23008732689937145]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2069351005227517		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.2069351005227517 | validation: 0.2060477235660323]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2206602085268932		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.2206602085268932 | validation: 0.2386836757307839]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2198738487732231		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.2198738487732231 | validation: 0.22717394029157587]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2271117622993003		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.2271117622993003 | validation: 0.23581433812653857]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2094860817649299		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.2094860817649299 | validation: 0.25204905544312584]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18771256855745033		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.18771256855745033 | validation: 0.27808026701059196]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21018536310299007		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.21018536310299007 | validation: 0.27059114486815344]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2103056069142955		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.2103056069142955 | validation: 0.2016835736123881]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18434765128542657		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.18434765128542657 | validation: 0.25273078954740547]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2383843550978369		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.2383843550978369 | validation: 0.23097865149480548]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20614723843918092		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.20614723843918092 | validation: 0.1897222219213498]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19298055831376024		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.19298055831376024 | validation: 0.47426887544461194]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27169294334194505		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.27169294334194505 | validation: 0.21538251254719398]
	TIME [epoch: 11.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20042755220711145		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.20042755220711145 | validation: 0.2933633832858675]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23640979434825757		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.23640979434825757 | validation: 0.21544560910536434]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1792994640335761		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.1792994640335761 | validation: 0.21267096917401435]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17215358775279474		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.17215358775279474 | validation: 0.198433817743813]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18568594787970713		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.18568594787970713 | validation: 0.1976299014949264]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21267878195438294		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.21267878195438294 | validation: 0.21306012989671025]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1797681957173824		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.1797681957173824 | validation: 0.2785333333681227]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25220039957580004		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.25220039957580004 | validation: 0.2583382810870176]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19583579040890525		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.19583579040890525 | validation: 0.19560406331928018]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17020260020194564		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.17020260020194564 | validation: 0.2659271022268836]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22954120847549536		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.22954120847549536 | validation: 0.22391454404202282]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18494120099260453		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.18494120099260453 | validation: 0.23581527939670008]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28431770460253336		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.28431770460253336 | validation: 0.2394542358636479]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18416169177627073		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.18416169177627073 | validation: 0.1844581202628325]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_673.pth
	Model improved!!!
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20058841000882865		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.20058841000882865 | validation: 0.200107259234809]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19761105622972414		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.19761105622972414 | validation: 0.24492572862021342]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18849656868674425		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.18849656868674425 | validation: 0.1888339756458831]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17912113458201157		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.17912113458201157 | validation: 0.2252801951310934]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1757483072824123		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.1757483072824123 | validation: 0.1934737413430431]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659076746785627		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.1659076746785627 | validation: 0.19052625601623374]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18705932635576966		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.18705932635576966 | validation: 0.29856552488551386]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20268196272802813		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.20268196272802813 | validation: 0.2116294665125079]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740683617239933		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.1740683617239933 | validation: 0.23644408523080349]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18076524368468766		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.18076524368468766 | validation: 0.22307302991690775]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17970794132490533		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.17970794132490533 | validation: 0.2220212172471193]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18489048071118994		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.18489048071118994 | validation: 0.24140591138114367]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20228785985665682		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.20228785985665682 | validation: 0.32384585628334234]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2179740706533389		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.2179740706533389 | validation: 0.2246508890834106]
	TIME [epoch: 11.4 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19880361726210394		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.19880361726210394 | validation: 0.28289139380096506]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2007288005074102		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.2007288005074102 | validation: 0.17629491558038912]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_689.pth
	Model improved!!!
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16927757727901152		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.16927757727901152 | validation: 0.19447194354336386]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1990868045168873		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.1990868045168873 | validation: 0.2727827587405458]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.197794030939102		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.197794030939102 | validation: 0.22851558832842753]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838009398809686		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.1838009398809686 | validation: 0.19057142365500615]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18126264903122213		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.18126264903122213 | validation: 0.2638681471976951]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21305407598219295		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.21305407598219295 | validation: 0.17941004312658201]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21500379746552922		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.21500379746552922 | validation: 0.20284847535190004]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18859846390003898		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.18859846390003898 | validation: 0.2425800986474839]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27459733761681815		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.27459733761681815 | validation: 0.2743795747978512]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22599843644616358		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.22599843644616358 | validation: 0.21049324449569196]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19000176682401398		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.19000176682401398 | validation: 0.19428058209756902]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17911699614749124		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.17911699614749124 | validation: 0.19022878914647043]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19543628604162291		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.19543628604162291 | validation: 0.1892856270908775]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620113641516596		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.1620113641516596 | validation: 0.17964956184746997]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19729590886621617		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.19729590886621617 | validation: 0.20019935426006139]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17912206782808632		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.17912206782808632 | validation: 0.25647014914215804]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2248614149130491		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.2248614149130491 | validation: 0.21309262783915173]
	TIME [epoch: 11.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20588596139603638		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.20588596139603638 | validation: 0.2745761171906008]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20222298118224497		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.20222298118224497 | validation: 0.20196702023193944]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21159615328585119		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.21159615328585119 | validation: 0.189899752976883]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18091420709680345		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.18091420709680345 | validation: 0.21112806775122045]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1819369304885535		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.1819369304885535 | validation: 0.1877576440099464]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1689318339265304		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.1689318339265304 | validation: 0.18870988620760862]
	TIME [epoch: 11.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16176702920862826		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.16176702920862826 | validation: 0.2000336833931852]
	TIME [epoch: 11.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19832712771213973		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.19832712771213973 | validation: 0.2031698483019532]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20449351926850773		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.20449351926850773 | validation: 0.2617376816198118]
	TIME [epoch: 11.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18510722029240817		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.18510722029240817 | validation: 0.2407320978252515]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23930625229986563		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.23930625229986563 | validation: 0.20764821240430628]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.160739802275734		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.160739802275734 | validation: 0.2424586914829452]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1912675098277851		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.1912675098277851 | validation: 0.24171282464429156]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1844277335893924		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.1844277335893924 | validation: 0.21109406819442014]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17877940740651282		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.17877940740651282 | validation: 0.20947767273974457]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17878636961307215		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.17878636961307215 | validation: 0.2331298602057]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1889391555282574		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.1889391555282574 | validation: 0.20686780858742182]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17869889355362728		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.17869889355362728 | validation: 0.2049352073484075]
	TIME [epoch: 11.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2007269361768707		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.2007269361768707 | validation: 0.20075308737092193]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16421478436367118		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.16421478436367118 | validation: 0.18625974425102806]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16634362390129104		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.16634362390129104 | validation: 0.18128835142411995]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1574288879377393		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1574288879377393 | validation: 0.17681492707237736]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19449452778526227		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.19449452778526227 | validation: 0.19387961149687616]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1801986710719797		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.1801986710719797 | validation: 0.19603786789047362]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21418745844796583		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.21418745844796583 | validation: 0.19136451407055255]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17037888494309553		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.17037888494309553 | validation: 0.19063932677547268]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1657167837734157		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.1657167837734157 | validation: 0.20555964811385188]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17776671551062598		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.17776671551062598 | validation: 0.198441614767779]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18675140458536688		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.18675140458536688 | validation: 0.27490251416502515]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18653217385753434		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.18653217385753434 | validation: 0.18245195180467427]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15451504863437054		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.15451504863437054 | validation: 0.182512513722301]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1705545169349783		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.1705545169349783 | validation: 0.22801895777859302]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17281592041031074		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.17281592041031074 | validation: 0.16342206371689486]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_739.pth
	Model improved!!!
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18245091517022052		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.18245091517022052 | validation: 0.18817943818585697]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20345575798740234		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.20345575798740234 | validation: 0.16803757595924182]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16677707694141042		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.16677707694141042 | validation: 0.23010969593355396]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18764340264062535		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.18764340264062535 | validation: 0.19510535660153974]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20516480557787725		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.20516480557787725 | validation: 0.17530103480364417]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15328329057002438		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.15328329057002438 | validation: 0.18666482009601063]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16728171150965657		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.16728171150965657 | validation: 0.19939986137626498]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18664562168109355		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.18664562168109355 | validation: 0.16607123568514331]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15445155619149242		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.15445155619149242 | validation: 0.1890444689305378]
	TIME [epoch: 11.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16866782748136344		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.16866782748136344 | validation: 0.18147372808169723]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19531656818428372		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.19531656818428372 | validation: 0.24513704904879088]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2525129107728532		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.2525129107728532 | validation: 0.2763189733906172]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20861019814832704		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.20861019814832704 | validation: 0.18549527444957042]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14913057227780457		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.14913057227780457 | validation: 0.18207825091241894]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18435750879155371		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.18435750879155371 | validation: 0.20661115144152248]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16292019585948042		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.16292019585948042 | validation: 0.16930179429666148]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17198188415415436		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.17198188415415436 | validation: 0.20576216087831284]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18566716319823304		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.18566716319823304 | validation: 0.28078674030460815]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21266400925008938		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.21266400925008938 | validation: 0.24740159196983988]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19952795566522705		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.19952795566522705 | validation: 0.16067784048058362]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_759.pth
	Model improved!!!
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590294623281886		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.1590294623281886 | validation: 0.25271996879919173]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2042922554455628		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.2042922554455628 | validation: 0.20680627178513766]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15570868287146322		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.15570868287146322 | validation: 0.18963917008816902]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17306879273801307		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.17306879273801307 | validation: 0.20777567789539447]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726909151838069		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.1726909151838069 | validation: 0.17279512721099216]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18646387107117765		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.18646387107117765 | validation: 0.16809730268665288]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488308193777011		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.1488308193777011 | validation: 0.2130774499824809]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17998489944043225		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.17998489944043225 | validation: 0.20529784117004402]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15882684394944713		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.15882684394944713 | validation: 0.1754496446016526]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14468475245201223		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.14468475245201223 | validation: 0.20186610518524092]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18054481261946073		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.18054481261946073 | validation: 0.1760128938537099]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17282994350050257		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.17282994350050257 | validation: 0.27774850895093256]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253330713773251		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.253330713773251 | validation: 0.22130117155715767]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17462784643613763		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.17462784643613763 | validation: 0.21223790439491524]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16292594837038565		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.16292594837038565 | validation: 0.18782283682048173]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15818055673950998		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.15818055673950998 | validation: 0.1966441934182055]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15807531995062693		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.15807531995062693 | validation: 0.1753462000707826]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15870969064228962		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.15870969064228962 | validation: 0.22633131581413504]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18025783802942513		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.18025783802942513 | validation: 0.16981866413510965]
	TIME [epoch: 11.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15772132167989755		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.15772132167989755 | validation: 0.1662217936798116]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14408402198543813		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.14408402198543813 | validation: 0.17178807826876014]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17294769447523523		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.17294769447523523 | validation: 0.20701089320143148]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18606253520159632		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.18606253520159632 | validation: 0.2903379768133754]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23767134902766937		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.23767134902766937 | validation: 0.21153807277446618]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18621517150251748		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.18621517150251748 | validation: 0.1917909182898808]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1850285545902769		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.1850285545902769 | validation: 0.23720076578193816]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1799349871730973		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.1799349871730973 | validation: 0.236346693856607]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16464596184671426		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.16464596184671426 | validation: 0.21074738865089387]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18777951134781973		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.18777951134781973 | validation: 0.23023009562077051]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1895236388339018		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.1895236388339018 | validation: 0.22396776695013562]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18039100255726626		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.18039100255726626 | validation: 0.18789547156375896]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1511638843107474		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.1511638843107474 | validation: 0.1912524729843798]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1657439599802976		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.1657439599802976 | validation: 0.19813742886102576]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1821010668144204		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.1821010668144204 | validation: 0.23991708923521504]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16946949192904465		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.16946949192904465 | validation: 0.1894369390770222]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17965329474772287		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.17965329474772287 | validation: 0.19511218525386198]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15047091233477816		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.15047091233477816 | validation: 0.17213125270561663]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18327267873871161		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.18327267873871161 | validation: 0.24716472350004737]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1752515542389251		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.1752515542389251 | validation: 0.17804331743626178]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15258134616963076		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.15258134616963076 | validation: 0.1732882476940487]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496780084532977		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.1496780084532977 | validation: 0.1776570977043166]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15669492925617046		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.15669492925617046 | validation: 0.20994264330772797]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20038755758543464		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.20038755758543464 | validation: 0.18942059782800905]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15736615526922126		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.15736615526922126 | validation: 0.18668839089355221]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18088996834884893		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.18088996834884893 | validation: 0.16817289015495515]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1701320329898604		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.1701320329898604 | validation: 0.3148962568520903]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19941593823782977		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.19941593823782977 | validation: 0.18027151484478515]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1561917408582385		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.1561917408582385 | validation: 0.1848323163732131]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16152329325166886		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.16152329325166886 | validation: 0.1828969823588534]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635053382927259		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.1635053382927259 | validation: 0.173746154642349]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1591658385557448		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.1591658385557448 | validation: 0.18058209476594503]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16056785366093837		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.16056785366093837 | validation: 0.2246020805547661]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17692120364597141		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.17692120364597141 | validation: 0.23151758346613108]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1795374782953624		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.1795374782953624 | validation: 0.20799327887500435]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17438711940140855		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.17438711940140855 | validation: 0.1788052374876783]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15044240438287204		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.15044240438287204 | validation: 0.1832552538710709]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.177659372837349		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.177659372837349 | validation: 0.21207687053940055]
	TIME [epoch: 11.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16585617542507922		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.16585617542507922 | validation: 0.17817538570571492]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15339271178744399		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.15339271178744399 | validation: 0.19635793446243835]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17474209162670157		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.17474209162670157 | validation: 0.23641567876958217]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17811111387090464		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.17811111387090464 | validation: 0.17166020053668826]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15059178949122537		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.15059178949122537 | validation: 0.18809264674892587]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15198123519744972		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.15198123519744972 | validation: 0.1865118110023839]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17847480878206684		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.17847480878206684 | validation: 0.21373689851081043]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16361428603386288		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.16361428603386288 | validation: 0.21392048908104971]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18779404991836204		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.18779404991836204 | validation: 0.21683610295422587]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16490708092759604		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.16490708092759604 | validation: 0.17005419927891777]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15385266765329966		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.15385266765329966 | validation: 0.1663193853034022]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15203627145512807		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.15203627145512807 | validation: 0.17103490622848938]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460602389970606		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.1460602389970606 | validation: 0.1784313851169695]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15972705897121348		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.15972705897121348 | validation: 0.22264155873594044]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17434421172170061		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.17434421172170061 | validation: 0.18078481250256034]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15180459703746432		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.15180459703746432 | validation: 0.20248833904196356]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17782212597026434		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.17782212597026434 | validation: 0.21515250942654177]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15987269523324155		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.15987269523324155 | validation: 0.1827754072396809]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15159193378393165		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.15159193378393165 | validation: 0.18662848545429472]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15574105193974272		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.15574105193974272 | validation: 0.18766346041934828]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.146509474640946		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.146509474640946 | validation: 0.1709946244909992]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478409270630719		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.1478409270630719 | validation: 0.1821330437425002]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14042109478084183		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.14042109478084183 | validation: 0.16796866406084526]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15484762012495523		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.15484762012495523 | validation: 0.17438097343410455]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1702474055245518		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.1702474055245518 | validation: 0.2446521232869304]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16442217717524515		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.16442217717524515 | validation: 0.17482483656876605]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486013964293122		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.1486013964293122 | validation: 0.16439750186530114]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505738973080768		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.1505738973080768 | validation: 0.1669687076887646]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14017366361018366		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.14017366361018366 | validation: 0.19797224572558064]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15864083394164405		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.15864083394164405 | validation: 0.22647918880337528]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16589046356805448		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.16589046356805448 | validation: 0.18348763733397813]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15483736220713		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.15483736220713 | validation: 0.18639608893049725]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17020874526482346		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.17020874526482346 | validation: 0.18449360379130753]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1482487184694762		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.1482487184694762 | validation: 0.19916139970788022]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1587123664224427		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.1587123664224427 | validation: 0.18271402544928841]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1450090143352646		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.1450090143352646 | validation: 0.20566687675880613]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19186574015540508		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.19186574015540508 | validation: 0.19720010173035785]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1575421717464947		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.1575421717464947 | validation: 0.18616869239900782]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1706025852918221		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.1706025852918221 | validation: 0.21197622456079512]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17717973980132587		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.17717973980132587 | validation: 0.2615669002294628]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17996145895322732		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.17996145895322732 | validation: 0.1967559807917232]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14871954089251602		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.14871954089251602 | validation: 0.16338812493713126]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1535711438069739		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.1535711438069739 | validation: 0.19168749617021977]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16090278669189514		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.16090278669189514 | validation: 0.19344106256644392]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15484939510021226		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.15484939510021226 | validation: 0.17345910280233287]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14404478975882354		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.14404478975882354 | validation: 0.17095301430507084]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14301240991558894		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.14301240991558894 | validation: 0.19153457789099687]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496525343780985		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.1496525343780985 | validation: 0.17191154482909338]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15420504989839612		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.15420504989839612 | validation: 0.18310024472948414]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14521576965410257		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.14521576965410257 | validation: 0.23495938979409003]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17825358695051705		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.17825358695051705 | validation: 0.16885241431313158]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1498924328798758		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.1498924328798758 | validation: 0.19897290415896687]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15483872016077582		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.15483872016077582 | validation: 0.1716539967709283]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15130117140283528		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.15130117140283528 | validation: 0.20349139067095245]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15364709993853143		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.15364709993853143 | validation: 0.17743773059698895]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1634483328892938		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.1634483328892938 | validation: 0.1965362798253301]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15106818471484956		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.15106818471484956 | validation: 0.1696393599512882]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15431019140447522		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.15431019140447522 | validation: 0.15592044429577714]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_874.pth
	Model improved!!!
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14598283244273424		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.14598283244273424 | validation: 0.23988602601076806]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1756679008087826		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.1756679008087826 | validation: 0.1811496641074209]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19396963803340167		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.19396963803340167 | validation: 0.2417033287898329]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1789228277955123		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.1789228277955123 | validation: 0.2010052376070621]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17830209289160978		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.17830209289160978 | validation: 0.19159058256474873]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156656295948066		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.156656295948066 | validation: 0.17781389932787187]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16116005163269423		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.16116005163269423 | validation: 0.18643022957937294]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517935161999906		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.1517935161999906 | validation: 0.1589277243528441]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1490365633088708		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.1490365633088708 | validation: 0.16639356266351638]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523993194717114		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.1523993194717114 | validation: 0.16688656851665287]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433160133985935		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.1433160133985935 | validation: 0.17981287062631293]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15950063622863236		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.15950063622863236 | validation: 0.1990836325597607]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17777952313520518		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.17777952313520518 | validation: 0.17690113847557717]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1480363031132675		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.1480363031132675 | validation: 0.1799888295626421]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15119217914281025		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.15119217914281025 | validation: 0.15880011149381]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14857495838201712		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.14857495838201712 | validation: 0.16135784259238392]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14862138803922384		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.14862138803922384 | validation: 0.22782762664985284]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18035593806454353		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.18035593806454353 | validation: 0.18157070246132725]
	TIME [epoch: 11.4 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16563029947656707		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.16563029947656707 | validation: 0.2098495217672079]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168238749434318		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.168238749434318 | validation: 0.18914868830693654]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18452539684223407		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.18452539684223407 | validation: 0.187467946397145]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15774616738228245		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.15774616738228245 | validation: 0.16853937278440104]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539760080730308		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.1539760080730308 | validation: 0.1791798781086537]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14447774491021778		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.14447774491021778 | validation: 0.16866171209495343]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16181374450720976		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.16181374450720976 | validation: 0.2207039635252521]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15484520033647226		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.15484520033647226 | validation: 0.17583699827839072]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15942800381505917		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.15942800381505917 | validation: 0.18705256079477217]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459250690665509		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.1459250690665509 | validation: 0.1684236669663403]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14491384208268276		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.14491384208268276 | validation: 0.1663008347718816]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15204672567128927		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.15204672567128927 | validation: 0.17035444027136457]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15117432249409435		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.15117432249409435 | validation: 0.21164585184859142]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1705582194004096		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.1705582194004096 | validation: 0.16935173742223428]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14793626822252184		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.14793626822252184 | validation: 0.18022045803605793]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15234933051655308		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.15234933051655308 | validation: 0.16966215345768823]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13941908275288495		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.13941908275288495 | validation: 0.16977457269721555]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14083774243595068		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.14083774243595068 | validation: 0.16754388570597833]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14510295510688231		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.14510295510688231 | validation: 0.1637978769682789]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403748793816182		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.1403748793816182 | validation: 0.16211812851431673]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13585220990355543		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.13585220990355543 | validation: 0.18535702636877935]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539071804171216		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.1539071804171216 | validation: 0.22665593973503678]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16586320570265528		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.16586320570265528 | validation: 0.17058747445386466]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14709445715820074		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.14709445715820074 | validation: 0.19422992715855705]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15704091885323607		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.15704091885323607 | validation: 0.1570777082703853]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1547415303661196		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.1547415303661196 | validation: 0.18187580629522004]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1426226255466961		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.1426226255466961 | validation: 0.1761069041013137]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14099248222660374		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.14099248222660374 | validation: 0.18570583583637684]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15129217769444417		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.15129217769444417 | validation: 0.18307674960946427]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1467785564200734		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.1467785564200734 | validation: 0.17498677179139385]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567609271659554		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.1567609271659554 | validation: 0.16383152588308125]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15559073887849206		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.15559073887849206 | validation: 0.17439778543116474]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486041818447471		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.1486041818447471 | validation: 0.1719367647528669]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16313363920868532		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.16313363920868532 | validation: 0.16832941241176508]
	TIME [epoch: 11.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15041054933641643		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.15041054933641643 | validation: 0.21485045343076137]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16382427754029966		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.16382427754029966 | validation: 0.18067881389985918]
	TIME [epoch: 11.4 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14604111287587584		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.14604111287587584 | validation: 0.15655148906983304]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14044386691238112		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.14044386691238112 | validation: 0.18301341466611856]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16182511695281634		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.16182511695281634 | validation: 0.18824218744818466]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1622069722668053		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.1622069722668053 | validation: 0.18260385071633867]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14281093239657888		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.14281093239657888 | validation: 0.18079558297064757]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14110079641644352		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.14110079641644352 | validation: 0.17888176738717115]
	TIME [epoch: 11.4 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393484200772023		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.1393484200772023 | validation: 0.15726612325956488]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14737378668556406		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.14737378668556406 | validation: 0.2095517831418008]
	TIME [epoch: 11.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1795267499664742		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.1795267499664742 | validation: 0.18291487271742513]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353921507303884		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.1353921507303884 | validation: 0.1610070498321898]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13481480908431936		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.13481480908431936 | validation: 0.1913658136611807]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14116466607744377		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.14116466607744377 | validation: 0.18719023886863045]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1534741760353038		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.1534741760353038 | validation: 0.16182798042219762]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14785908839733777		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.14785908839733777 | validation: 0.15975002379821812]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428077340553205		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.1428077340553205 | validation: 0.1670339143421205]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15511621090389432		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.15511621090389432 | validation: 0.220988980803966]
	TIME [epoch: 11.4 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612536582256449		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.1612536582256449 | validation: 0.1677074783685911]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15406615137680374		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.15406615137680374 | validation: 0.18119922692371135]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17802746543586917		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.17802746543586917 | validation: 0.16366856172619274]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365145710103955		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.1365145710103955 | validation: 0.1808956678390824]
	TIME [epoch: 11.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1593248852022191		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.1593248852022191 | validation: 0.15979066441416465]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13294995681169886		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.13294995681169886 | validation: 0.16620065116101856]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1472012563582531		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.1472012563582531 | validation: 0.2040008864713434]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617015826911754		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.1617015826911754 | validation: 0.17202620014902856]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1531989379050594		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.1531989379050594 | validation: 0.15767670388861219]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14145393500915093		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.14145393500915093 | validation: 0.18738758854396675]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16221327669272725		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.16221327669272725 | validation: 0.15787445292112043]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13891828183104765		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.13891828183104765 | validation: 0.15236884391663125]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_956.pth
	Model improved!!!
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1444183742245202		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.1444183742245202 | validation: 0.16773203630188754]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1399133905278258		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.1399133905278258 | validation: 0.1599506725852261]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1455408069674889		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.1455408069674889 | validation: 0.16944817822556069]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14313087250657558		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.14313087250657558 | validation: 0.178341401300362]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14112357229312908		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.14112357229312908 | validation: 0.1750301723986101]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17600368371445912		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.17600368371445912 | validation: 0.20522060396707553]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15715979317442966		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.15715979317442966 | validation: 0.17095043350118425]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13555249811932846		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.13555249811932846 | validation: 0.16483740294342134]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14186259967505277		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.14186259967505277 | validation: 0.165558389980195]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15623171016271947		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.15623171016271947 | validation: 0.18567598005776603]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14048662999834258		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.14048662999834258 | validation: 0.22113821581697088]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15735799802566805		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.15735799802566805 | validation: 0.16053530436881663]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13239282468200345		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.13239282468200345 | validation: 0.15228446417392952]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_969.pth
	Model improved!!!
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1469456252441223		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.1469456252441223 | validation: 0.16753576042183146]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14433405173431524		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.14433405173431524 | validation: 0.1589245070309994]
	TIME [epoch: 11.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1366100814795676		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.1366100814795676 | validation: 0.16418943442624953]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13713568931873216		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.13713568931873216 | validation: 0.16044214771266416]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13275886337529388		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.13275886337529388 | validation: 0.17988945134126183]
	TIME [epoch: 11.4 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543590011149307		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.1543590011149307 | validation: 0.15462259981124113]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530813622022294		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.1530813622022294 | validation: 0.22507109807736023]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1676201008859078		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.1676201008859078 | validation: 0.17770941506003213]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15576388403163133		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.15576388403163133 | validation: 0.16576515854073479]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14985698769573344		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.14985698769573344 | validation: 0.183926451143331]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13918021236957667		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.13918021236957667 | validation: 0.16432032236547348]
	TIME [epoch: 11.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15371856430062142		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.15371856430062142 | validation: 0.17729183554863717]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514382760175894		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.1514382760175894 | validation: 0.16149572862249045]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550934453007775		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.1550934453007775 | validation: 0.1836586907457539]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14268122429622382		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.14268122429622382 | validation: 0.16805245491775866]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133866250671309		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.133866250671309 | validation: 0.16611328686995844]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13545609361196678		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.13545609361196678 | validation: 0.16877693532883242]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601340666204567		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.1601340666204567 | validation: 0.16525894612125072]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13709206148579878		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.13709206148579878 | validation: 0.16006349865931022]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15056433005663158		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.15056433005663158 | validation: 0.1588944340649948]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14536352268711666		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.14536352268711666 | validation: 0.18130417892014747]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15039910774490903		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.15039910774490903 | validation: 0.1767391698627622]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14672766323945513		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.14672766323945513 | validation: 0.17179284015898777]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15529629014984875		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.15529629014984875 | validation: 0.2188511596035633]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16803370158563075		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.16803370158563075 | validation: 0.1796763647885446]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408708902783299		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.1408708902783299 | validation: 0.1689514897219452]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13700879988263603		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.13700879988263603 | validation: 0.18454117636547537]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14779312874825595		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.14779312874825595 | validation: 0.17127519101285926]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14030829181680066		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.14030829181680066 | validation: 0.16148515341685746]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13503451171475134		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.13503451171475134 | validation: 0.16107029540979967]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14262713766296276		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.14262713766296276 | validation: 0.1657432806333862]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14303376486962818		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.14303376486962818 | validation: 0.1642460418674259]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14794530821293642		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.14794530821293642 | validation: 0.1714864916216255]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13744472311231398		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.13744472311231398 | validation: 0.1619243393858458]
	TIME [epoch: 11.4 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13767394493079144		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.13767394493079144 | validation: 0.15892128414041334]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14047968624129695		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.14047968624129695 | validation: 0.1832141644889893]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408598778219693		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.1408598778219693 | validation: 0.15780606293093935]
	TIME [epoch: 11.4 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393501036787828		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.1393501036787828 | validation: 0.15890545566811007]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13301637081886414		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.13301637081886414 | validation: 0.15616939267429655]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15235354834217385		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.15235354834217385 | validation: 0.18649871544621655]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1655532349972684		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.1655532349972684 | validation: 0.1927772282490492]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446143501774837		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.1446143501774837 | validation: 0.16008366771144578]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14021909803220942		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.14021909803220942 | validation: 0.1616469771474869]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13250429702082175		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.13250429702082175 | validation: 0.1641931224356415]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15118171012668502		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.15118171012668502 | validation: 0.15414803235163915]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12666712174829206		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.12666712174829206 | validation: 0.16290354661092785]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13697834213648838		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.13697834213648838 | validation: 0.16492663774754568]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384941468162519		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.1384941468162519 | validation: 0.17562816177899532]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342695108081441		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.1342695108081441 | validation: 0.16302586357660406]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13988804030310767		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.13988804030310767 | validation: 0.15982614023983752]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13554276685433328		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.13554276685433328 | validation: 0.1618514954573212]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13804187646452643		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.13804187646452643 | validation: 0.15874793694192843]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12473708192547878		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.12473708192547878 | validation: 0.16583111458835773]
	TIME [epoch: 11.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141652475656694		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.141652475656694 | validation: 0.15398387643801825]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391497226287956		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.1391497226287956 | validation: 0.19049671599583715]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14758745848631855		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.14758745848631855 | validation: 0.1785332291338114]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150265590640217		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.150265590640217 | validation: 0.16786197242455855]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14745523012345596		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.14745523012345596 | validation: 0.14730742828539764]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_1027.pth
	Model improved!!!
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13467758432421323		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.13467758432421323 | validation: 0.1566873950681402]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13318554221094442		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.13318554221094442 | validation: 0.1488974414697496]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12914311329044056		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.12914311329044056 | validation: 0.15547478098373327]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13241005155496482		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.13241005155496482 | validation: 0.15688994314848448]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13868903588391013		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.13868903588391013 | validation: 0.16503974380383624]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341931228749871		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.1341931228749871 | validation: 0.17613349875273482]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14713965257236092		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.14713965257236092 | validation: 0.18986370572294348]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1444231854903254		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.1444231854903254 | validation: 0.1611384744104683]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13320909226665595		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.13320909226665595 | validation: 0.15762228387197685]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13843596426033095		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.13843596426033095 | validation: 0.18225299647974935]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15562605135911772		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.15562605135911772 | validation: 0.18201548877372628]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13861024019451118		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.13861024019451118 | validation: 0.15437842777261437]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13353926204549288		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.13353926204549288 | validation: 0.15816632797477817]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13811709595952065		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.13811709595952065 | validation: 0.17028428199908568]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1420266545808654		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.1420266545808654 | validation: 0.1826812140822817]
	TIME [epoch: 11.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15258169708692082		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.15258169708692082 | validation: 0.17709357949914523]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15633637388436028		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.15633637388436028 | validation: 0.16006231804441612]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14575565325938453		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.14575565325938453 | validation: 0.18177659397837884]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14989938928251206		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.14989938928251206 | validation: 0.15715041888559456]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13490103868320708		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.13490103868320708 | validation: 0.15915533983753996]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381638050967335		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.1381638050967335 | validation: 0.16721150369728677]
	TIME [epoch: 11.4 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13833253634533138		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.13833253634533138 | validation: 0.16234979562427893]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429670040070285		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.1429670040070285 | validation: 0.19298453723742956]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14453589361949715		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.14453589361949715 | validation: 0.15700640349477804]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14295667743388918		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.14295667743388918 | validation: 0.16931542887205153]
	TIME [epoch: 11.4 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12904867194312353		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.12904867194312353 | validation: 0.15428384563203337]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14020476470113483		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.14020476470113483 | validation: 0.17107636679431928]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13971849739691394		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.13971849739691394 | validation: 0.1581512435379763]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13408378100373838		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.13408378100373838 | validation: 0.152443246348517]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13809755852136363		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.13809755852136363 | validation: 0.16462918264395376]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13336211207106113		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.13336211207106113 | validation: 0.15806838634938547]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12972970605856943		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.12972970605856943 | validation: 0.16684533405320243]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343036630217026		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.1343036630217026 | validation: 0.1527993058222231]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287666956001812		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.1287666956001812 | validation: 0.16915216458477653]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14375798185640198		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.14375798185640198 | validation: 0.16798501133212476]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13433620203805663		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.13433620203805663 | validation: 0.1703593179683394]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13470666966538683		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.13470666966538683 | validation: 0.17994627689122922]
	TIME [epoch: 11.4 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13803019635890382		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.13803019635890382 | validation: 0.15525417985718015]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13601373942452383		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.13601373942452383 | validation: 0.1724643073073262]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142390295630195		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.142390295630195 | validation: 0.15780294469549558]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13781350415800436		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.13781350415800436 | validation: 0.1886757403395223]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526097104810846		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.1526097104810846 | validation: 0.17022407473463894]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14010144517317788		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.14010144517317788 | validation: 0.15788430698498165]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13430489639686996		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.13430489639686996 | validation: 0.1669986316062273]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14465989858154052		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.14465989858154052 | validation: 0.15693164756431274]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14733506076003114		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.14733506076003114 | validation: 0.16151311621082012]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13556359077046518		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.13556359077046518 | validation: 0.17748600306509288]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422506241099662		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.1422506241099662 | validation: 0.1605071556480388]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422146157346949		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.1422146157346949 | validation: 0.17367673707761797]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14766595375459482		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.14766595375459482 | validation: 0.16735740025239496]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14035531211769475		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.14035531211769475 | validation: 0.1539370543159368]
	TIME [epoch: 11.4 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12746673148753782		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.12746673148753782 | validation: 0.15272136373356981]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13200628751057888		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.13200628751057888 | validation: 0.17477372714766476]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394690220162407		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.1394690220162407 | validation: 0.16484880280622247]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13979531600072292		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.13979531600072292 | validation: 0.17790525849469294]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14554708507522687		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.14554708507522687 | validation: 0.17651138676169795]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478476054728392		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.1478476054728392 | validation: 0.16225069822884627]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14042424957365643		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.14042424957365643 | validation: 0.17985449265158387]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13901098137185425		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.13901098137185425 | validation: 0.1629444740580648]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13027137360912455		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.13027137360912455 | validation: 0.15136693213870583]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13003823748846086		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.13003823748846086 | validation: 0.15950809822486456]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13161454691831143		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.13161454691831143 | validation: 0.16607866915196898]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13264590239145813		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.13264590239145813 | validation: 0.17183729216465612]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17188505049214534		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.17188505049214534 | validation: 0.19026569485546993]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15050899610251764		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.15050899610251764 | validation: 0.16300625231159177]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13995161036179748		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.13995161036179748 | validation: 0.15554969998081009]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12902294486345184		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.12902294486345184 | validation: 0.15309292748041867]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13357579364998703		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.13357579364998703 | validation: 0.16232881396516718]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15025887597041243		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.15025887597041243 | validation: 0.19365125932101246]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14770454995636406		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.14770454995636406 | validation: 0.1487743733034725]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13247411131987957		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.13247411131987957 | validation: 0.15942149746710174]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334516074043198		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.1334516074043198 | validation: 0.14859431624905267]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143970135927748		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.143970135927748 | validation: 0.17015888431778453]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1465835688521574		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.1465835688521574 | validation: 0.1665213672149804]
	TIME [epoch: 11.4 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15088159839013598		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.15088159839013598 | validation: 0.14790838643572585]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13555794316652253		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.13555794316652253 | validation: 0.162366960060372]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13675148161080636		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.13675148161080636 | validation: 0.1576908443669702]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12428734907156899		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.12428734907156899 | validation: 0.15270943984267502]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297158101533694		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.1297158101533694 | validation: 0.17012415983388188]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394968008451709		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.1394968008451709 | validation: 0.17204021536175812]
	TIME [epoch: 11.4 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14391255721039248		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.14391255721039248 | validation: 0.16814415671385294]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14229139973978006		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.14229139973978006 | validation: 0.162159262845624]
	TIME [epoch: 11.4 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13729997253001108		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.13729997253001108 | validation: 0.16987227509176844]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13965195401349528		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.13965195401349528 | validation: 0.1598192149900955]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13932237802420952		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.13932237802420952 | validation: 0.181179481298866]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13615743749111686		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.13615743749111686 | validation: 0.1526594768791502]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12996019941464854		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.12996019941464854 | validation: 0.1600399498096186]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12312110967046583		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.12312110967046583 | validation: 0.1473628727811515]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13164367712592157		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.13164367712592157 | validation: 0.1683380774498368]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14331562564726663		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.14331562564726663 | validation: 0.16744986533879605]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13642145018533228		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.13642145018533228 | validation: 0.16008823136452968]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13117780247907523		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.13117780247907523 | validation: 0.15366047031161803]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12862535237949738		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.12862535237949738 | validation: 0.1572415622905383]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13712213965922398		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.13712213965922398 | validation: 0.15583514452075586]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12714626828705794		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.12714626828705794 | validation: 0.14897381707385512]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369417052608063		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.1369417052608063 | validation: 0.16342203195710192]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13277231903973066		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.13277231903973066 | validation: 0.15016084893548937]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12989863532823964		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.12989863532823964 | validation: 0.1715829767292539]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12797861296129442		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.12797861296129442 | validation: 0.1593089632946622]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13514459950146168		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.13514459950146168 | validation: 0.15859004976129684]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12617287565658133		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.12617287565658133 | validation: 0.16544913325082994]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350399599460819		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.1350399599460819 | validation: 0.16061744270153347]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14801106520450807		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.14801106520450807 | validation: 0.17987158013929858]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14207914990690954		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.14207914990690954 | validation: 0.17280731995316018]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322134521777175		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.1322134521777175 | validation: 0.17030264549820234]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317768813461606		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.1317768813461606 | validation: 0.15546216719541137]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12861390492107527		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.12861390492107527 | validation: 0.1599575842813998]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13676007450569608		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.13676007450569608 | validation: 0.17536540197488473]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429942881398885		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.1429942881398885 | validation: 0.15525679515020108]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12846613584703692		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.12846613584703692 | validation: 0.16039481080789833]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12919518915875694		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.12919518915875694 | validation: 0.15601220535903207]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323241423345878		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.1323241423345878 | validation: 0.16571778400623027]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13570282380446697		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.13570282380446697 | validation: 0.15562056884641706]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318306178229991		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.1318306178229991 | validation: 0.15311393651171507]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12799219742325246		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.12799219742325246 | validation: 0.14963360132880216]
	TIME [epoch: 11.4 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13285486151188924		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.13285486151188924 | validation: 0.16525619549947174]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13378829236321133		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.13378829236321133 | validation: 0.16535626278581306]
	TIME [epoch: 11.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13532301669288646		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.13532301669288646 | validation: 0.16496939111118422]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336010059500819		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.1336010059500819 | validation: 0.16202171636110158]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12513983872024576		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.12513983872024576 | validation: 0.15384536844322513]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13328981741454843		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.13328981741454843 | validation: 0.16934752986559723]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277268793203161		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.1277268793203161 | validation: 0.15985859414910525]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13375819636916825		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.13375819636916825 | validation: 0.17544493024535954]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14266591704183879		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.14266591704183879 | validation: 0.16167246346822092]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12824847623453334		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.12824847623453334 | validation: 0.1547627022915867]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130606435504508		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.130606435504508 | validation: 0.17026654269828814]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13988556447075995		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.13988556447075995 | validation: 0.16449081055781214]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12759778843047545		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.12759778843047545 | validation: 0.1579436824051956]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12919261830108908		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.12919261830108908 | validation: 0.17638639236585896]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13212242813456318		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.13212242813456318 | validation: 0.15798861889959037]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13231464722185074		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.13231464722185074 | validation: 0.16265922747092554]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14486362004663206		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.14486362004663206 | validation: 0.1571159220810337]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371647664000521		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.1371647664000521 | validation: 0.15631886475130058]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12706040967181392		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.12706040967181392 | validation: 0.15054285417006275]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1358835810048254		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.1358835810048254 | validation: 0.15861388123660897]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13004664311122352		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.13004664311122352 | validation: 0.1706287697657077]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316470822399146		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.1316470822399146 | validation: 0.1599300883562344]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12290993589364935		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.12290993589364935 | validation: 0.1558733780026151]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1399986634505116		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.1399986634505116 | validation: 0.16282904411903715]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14459524132628965		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.14459524132628965 | validation: 0.15443543960571332]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13556595769249452		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.13556595769249452 | validation: 0.16085207288044395]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13341489503554024		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.13341489503554024 | validation: 0.15736573515856023]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13234997329181827		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.13234997329181827 | validation: 0.16511526641660332]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13127026700449063		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.13127026700449063 | validation: 0.15469456245358978]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328201862958532		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.1328201862958532 | validation: 0.16292662708495467]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421760316377447		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.1421760316377447 | validation: 0.1732886595987356]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13773674836805103		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.13773674836805103 | validation: 0.15969730907939692]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13521261256140849		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.13521261256140849 | validation: 0.16714553702999577]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14242784088573665		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.14242784088573665 | validation: 0.15902531615743024]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1340382039254934		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.1340382039254934 | validation: 0.16566152555412625]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12957611226780258		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.12957611226780258 | validation: 0.15653025053555641]
	TIME [epoch: 11.4 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12878946802904293		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.12878946802904293 | validation: 0.15749874337583458]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13138237416413873		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.13138237416413873 | validation: 0.1625119018788461]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1249987835307336		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.1249987835307336 | validation: 0.15437440805850441]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12438457767254009		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.12438457767254009 | validation: 0.15514645193154705]
	TIME [epoch: 11.4 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13719540713192024		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.13719540713192024 | validation: 0.1530781541967016]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13028902368137263		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.13028902368137263 | validation: 0.14977842367318958]
	TIME [epoch: 11.4 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13124219451270086		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.13124219451270086 | validation: 0.16413280444842435]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13853783086346208		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.13853783086346208 | validation: 0.16120758808827632]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13362029744415888		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.13362029744415888 | validation: 0.15460570140185023]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12071953502981372		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.12071953502981372 | validation: 0.15204026996308487]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278471201568092		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.1278471201568092 | validation: 0.15913594727888067]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289247288236227		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.1289247288236227 | validation: 0.15729046586018502]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14059605501000727		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.14059605501000727 | validation: 0.15484443874776305]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12692922287837455		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.12692922287837455 | validation: 0.15745415497887194]
	TIME [epoch: 11.4 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13817414045804716		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.13817414045804716 | validation: 0.17425173757232468]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13256776213160848		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.13256776213160848 | validation: 0.15995056734055318]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12580235839697101		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.12580235839697101 | validation: 0.1543357171595601]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12649213172339357		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.12649213172339357 | validation: 0.15194325280206517]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12818465868399392		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.12818465868399392 | validation: 0.1686548932834048]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14468725849918054		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.14468725849918054 | validation: 0.16066863121128822]
	TIME [epoch: 11.4 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1246784014351567		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.1246784014351567 | validation: 0.16275926625576703]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13183557471514734		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.13183557471514734 | validation: 0.17311757098336195]
	TIME [epoch: 11.4 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13754906066249756		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.13754906066249756 | validation: 0.1563353713844528]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13038204017890673		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.13038204017890673 | validation: 0.16315743534774235]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13846413805787974		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.13846413805787974 | validation: 0.1747464838704576]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1367726985073353		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.1367726985073353 | validation: 0.15420605360159007]
	TIME [epoch: 11.4 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468445852356508		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.12468445852356508 | validation: 0.16474900500138817]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12941514363034923		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.12941514363034923 | validation: 0.15562892650683044]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12437847014480248		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.12437847014480248 | validation: 0.14593834857078578]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_1207.pth
	Model improved!!!
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12846702685268602		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.12846702685268602 | validation: 0.1495762126574042]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278845196557417		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.1278845196557417 | validation: 0.16194772925828718]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14141355278847642		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.14141355278847642 | validation: 0.1565487559251101]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13019689814995192		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.13019689814995192 | validation: 0.1639638504829404]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13195758866346383		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.13195758866346383 | validation: 0.1646674108626757]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13592885637905		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.13592885637905 | validation: 0.17175677131247433]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13635049285810064		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.13635049285810064 | validation: 0.15820384567327164]
	TIME [epoch: 11.4 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13326231439719222		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.13326231439719222 | validation: 0.15781029778030348]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12463377692471476		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.12463377692471476 | validation: 0.16897293873065367]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13008297118024328		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.13008297118024328 | validation: 0.16326317207626376]
	TIME [epoch: 11.4 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13400107509559522		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.13400107509559522 | validation: 0.16999662714797809]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12915882812389012		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.12915882812389012 | validation: 0.1494842402428329]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126466348973868		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.126466348973868 | validation: 0.15984230892155496]
	TIME [epoch: 11.4 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13366026683469678		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.13366026683469678 | validation: 0.16449112186170645]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13337489611424339		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.13337489611424339 | validation: 0.15612406090180306]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1299767071857225		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.1299767071857225 | validation: 0.15056515892566835]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13210729603219862		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.13210729603219862 | validation: 0.17084950805886465]
	TIME [epoch: 11.4 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13860698316047884		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.13860698316047884 | validation: 0.16165030537213132]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13332163833349603		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.13332163833349603 | validation: 0.17338717530454545]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13548919838628593		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.13548919838628593 | validation: 0.15439035566654574]
	TIME [epoch: 11.4 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251392539410329		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.1251392539410329 | validation: 0.1554875810989946]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270770890467962		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.1270770890467962 | validation: 0.1553410647287536]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12853960515007312		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.12853960515007312 | validation: 0.1562947550395726]
	TIME [epoch: 11.4 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12797353115890697		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.12797353115890697 | validation: 0.15534668954098785]
	TIME [epoch: 11.4 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13612893545493535		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.13612893545493535 | validation: 0.16608591413457138]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13995342011873765		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.13995342011873765 | validation: 0.15182904834759942]
	TIME [epoch: 11.4 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12831547643423416		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.12831547643423416 | validation: 0.15007486028347589]
	TIME [epoch: 11.4 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12723586851110122		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.12723586851110122 | validation: 0.1538487560032206]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281046357947801		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.1281046357947801 | validation: 0.1527230171222515]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276623583358222		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.1276623583358222 | validation: 0.1590156987437713]
	TIME [epoch: 11.4 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12558807623882023		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.12558807623882023 | validation: 0.15109428704338357]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12935870407164118		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.12935870407164118 | validation: 0.1560900491328898]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12793862957879407		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.12793862957879407 | validation: 0.15800913970705285]
	TIME [epoch: 11.4 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12832442849472137		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.12832442849472137 | validation: 0.1515135914613077]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283983427776592		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.1283983427776592 | validation: 0.15531222725451319]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13375360082990495		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.13375360082990495 | validation: 0.16346232692484786]
	TIME [epoch: 11.4 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312885878977019		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.1312885878977019 | validation: 0.15498947662297188]
	TIME [epoch: 11.4 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12809851671619069		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.12809851671619069 | validation: 0.16231632434107587]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13890930535164275		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.13890930535164275 | validation: 0.1662585211700364]
	TIME [epoch: 11.4 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15230581111458508		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.15230581111458508 | validation: 0.1767074892649667]
	TIME [epoch: 11.4 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15958220065850331		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.15958220065850331 | validation: 0.17458998889163924]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13445190202392043		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.13445190202392043 | validation: 0.15777666671596907]
	TIME [epoch: 11.4 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12922389495323275		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.12922389495323275 | validation: 0.15561423388977086]
	TIME [epoch: 11.4 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335779232951721		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.1335779232951721 | validation: 0.1640523032331636]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1288711675132454		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.1288711675132454 | validation: 0.15913922823508475]
	TIME [epoch: 11.4 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12522026187612667		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.12522026187612667 | validation: 0.150467405496587]
	TIME [epoch: 11.4 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13212512977356966		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.13212512977356966 | validation: 0.15681888225677507]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12563417726339643		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.12563417726339643 | validation: 0.15365284713298855]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277614070153238		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.1277614070153238 | validation: 0.14661577273252266]
	TIME [epoch: 11.4 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12606352603716733		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.12606352603716733 | validation: 0.14934932074788973]
	TIME [epoch: 11.4 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1366653748518649		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.1366653748518649 | validation: 0.1644006128507636]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14616748111290087		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.14616748111290087 | validation: 0.1525737370835446]
	TIME [epoch: 11.4 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1347578902766734		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.1347578902766734 | validation: 0.15185655563962097]
	TIME [epoch: 11.4 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12532956822500899		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.12532956822500899 | validation: 0.1589602592949379]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12339613747805703		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.12339613747805703 | validation: 0.15028306130475708]
	TIME [epoch: 11.4 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12486188119750162		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.12486188119750162 | validation: 0.14786221679742304]
	TIME [epoch: 11.4 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12825881284962554		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.12825881284962554 | validation: 0.16646185305191288]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12523986774907467		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.12523986774907467 | validation: 0.15813747185042368]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12807522086752304		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.12807522086752304 | validation: 0.15187900825968922]
	TIME [epoch: 11.4 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264490932949135		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.1264490932949135 | validation: 0.15695130274501065]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12520561767743982		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.12520561767743982 | validation: 0.15464337242324536]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13088199233575093		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.13088199233575093 | validation: 0.15641454557964496]
	TIME [epoch: 11.4 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298479717907567		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.1298479717907567 | validation: 0.14997674701193847]
	TIME [epoch: 11.4 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12313207706838233		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.12313207706838233 | validation: 0.15359131740058463]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13406391211564145		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.13406391211564145 | validation: 0.15849541264491093]
	TIME [epoch: 11.4 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255725258289846		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.1255725258289846 | validation: 0.15375457943395276]
	TIME [epoch: 11.4 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13168008482682858		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.13168008482682858 | validation: 0.16774841057581405]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334834918192439		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.1334834918192439 | validation: 0.16328200618286168]
	TIME [epoch: 11.4 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14272905811769449		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.14272905811769449 | validation: 0.15901104912363773]
	TIME [epoch: 11.4 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12515662186816848		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.12515662186816848 | validation: 0.16018240110736595]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13560488892565642		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.13560488892565642 | validation: 0.1613497828587065]
	TIME [epoch: 11.4 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131360227183868		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.131360227183868 | validation: 0.15267371822032316]
	TIME [epoch: 11.4 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126216619974163		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.126216619974163 | validation: 0.15344265651604885]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309669377765522		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.1309669377765522 | validation: 0.15821028767416473]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297131414732619		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.1297131414732619 | validation: 0.15005530376961634]
	TIME [epoch: 11.4 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12395482419906662		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.12395482419906662 | validation: 0.14790867448573805]
	TIME [epoch: 11.4 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12878946103609534		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.12878946103609534 | validation: 0.15853601090306094]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13489226999882392		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.13489226999882392 | validation: 0.1641399680618879]
	TIME [epoch: 11.4 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13429217548935937		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.13429217548935937 | validation: 0.16353819333259942]
	TIME [epoch: 11.4 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302152135371407		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.1302152135371407 | validation: 0.15763594614413465]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12372054967356566		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.12372054967356566 | validation: 0.1595892200241844]
	TIME [epoch: 11.4 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12211351677271971		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.12211351677271971 | validation: 0.1477097668587599]
	TIME [epoch: 11.4 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13336085735444791		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.13336085735444791 | validation: 0.15069367482699325]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13367066811098538		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.13367066811098538 | validation: 0.1717131487683468]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14571735047838436		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.14571735047838436 | validation: 0.17917169456731386]
	TIME [epoch: 11.4 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1399958455931285		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.1399958455931285 | validation: 0.17062028287071623]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14017429629526948		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.14017429629526948 | validation: 0.1829971311531073]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14551308389017062		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.14551308389017062 | validation: 0.1777153727194051]
	TIME [epoch: 11.4 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377748191941553		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.1377748191941553 | validation: 0.16112855830697087]
	TIME [epoch: 11.4 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12634452806491644		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.12634452806491644 | validation: 0.1594163671810097]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12853687208611758		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.12853687208611758 | validation: 0.16000830264345528]
	TIME [epoch: 11.4 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12641719173895774		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.12641719173895774 | validation: 0.14963746619131976]
	TIME [epoch: 11.4 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12264340630032229		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.12264340630032229 | validation: 0.1570524476623667]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12743326237957608		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.12743326237957608 | validation: 0.16787426645885903]
	TIME [epoch: 11.4 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12941372806510992		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.12941372806510992 | validation: 0.14917845598690047]
	TIME [epoch: 11.4 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12369785706139161		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.12369785706139161 | validation: 0.1547032714364407]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13691464635724832		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.13691464635724832 | validation: 0.15507350773357095]
	TIME [epoch: 11.4 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13460247361507754		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.13460247361507754 | validation: 0.1503665437290994]
	TIME [epoch: 11.4 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12878114848718744		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.12878114848718744 | validation: 0.14946758420252773]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296272514438146		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.1296272514438146 | validation: 0.1534782405196938]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12797408326995818		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.12797408326995818 | validation: 0.15669725752524338]
	TIME [epoch: 11.4 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12984940496195194		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.12984940496195194 | validation: 0.15980275607501757]
	TIME [epoch: 11.4 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13013049717896133		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.13013049717896133 | validation: 0.16325579272575147]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12252361144737173		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.12252361144737173 | validation: 0.15443324506643125]
	TIME [epoch: 11.4 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13116346227977302		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.13116346227977302 | validation: 0.1478695398191617]
	TIME [epoch: 11.4 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12879956401659512		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.12879956401659512 | validation: 0.15327356440401305]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12376128352261956		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.12376128352261956 | validation: 0.15182384331945065]
	TIME [epoch: 11.4 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12250719039888555		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.12250719039888555 | validation: 0.16740051328657735]
	TIME [epoch: 11.4 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13394319963483564		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.13394319963483564 | validation: 0.1633514983132178]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12888897123568852		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.12888897123568852 | validation: 0.15423903151140228]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304262231157905		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.1304262231157905 | validation: 0.1563319706160632]
	TIME [epoch: 11.4 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274796510115468		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.1274796510115468 | validation: 0.15841866533465113]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12971606778909722		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.12971606778909722 | validation: 0.14803935812247385]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12309484611493152		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.12309484611493152 | validation: 0.15526558147750688]
	TIME [epoch: 11.4 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12724863498472422		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.12724863498472422 | validation: 0.159653860087915]
	TIME [epoch: 11.4 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281318015361839		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.1281318015361839 | validation: 0.1435277097578876]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_1323.pth
	Model improved!!!
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262359681104817		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.1262359681104817 | validation: 0.1419510772293824]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_1324.pth
	Model improved!!!
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12236795488293058		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.12236795488293058 | validation: 0.1537765744758821]
	TIME [epoch: 11.4 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12822927402182316		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.12822927402182316 | validation: 0.16467004677614822]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14020966863562018		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.14020966863562018 | validation: 0.17987431718370572]
	TIME [epoch: 11.4 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13253048774952775		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.13253048774952775 | validation: 0.1549836639825281]
	TIME [epoch: 11.4 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12734703074923273		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.12734703074923273 | validation: 0.1635943895214809]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309511505762731		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.1309511505762731 | validation: 0.16230253791417754]
	TIME [epoch: 11.4 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12982302282064367		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.12982302282064367 | validation: 0.1536202955589685]
	TIME [epoch: 11.4 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12727474156297094		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.12727474156297094 | validation: 0.14790084707839488]
	TIME [epoch: 11.4 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12699657925835744		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.12699657925835744 | validation: 0.14748174388806087]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12459908459278533		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.12459908459278533 | validation: 0.15015472097939347]
	TIME [epoch: 11.4 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12657999181581026		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.12657999181581026 | validation: 0.15382560263397724]
	TIME [epoch: 11.7 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12618563267998667		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.12618563267998667 | validation: 0.16053020416493485]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274752562277499		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.1274752562277499 | validation: 0.14916807578136498]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13094185665350228		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.13094185665350228 | validation: 0.17398303615670827]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13691334826858426		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.13691334826858426 | validation: 0.15749087494806877]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12762753707518978		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.12762753707518978 | validation: 0.15400356124558187]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131826301852114		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.131826301852114 | validation: 0.15900511206756945]
	TIME [epoch: 11.4 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12687032155678019		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.12687032155678019 | validation: 0.161800196411938]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12834499370713245		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.12834499370713245 | validation: 0.157514957884775]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12397340334670694		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.12397340334670694 | validation: 0.1527204180476464]
	TIME [epoch: 11.4 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12424372980273352		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.12424372980273352 | validation: 0.14575240951530266]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12780952599999088		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.12780952599999088 | validation: 0.15391110973175223]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283246866915328		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.1283246866915328 | validation: 0.1549130704911291]
	TIME [epoch: 11.4 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12485761672868229		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.12485761672868229 | validation: 0.15056562406728194]
	TIME [epoch: 11.4 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12911187593367715		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.12911187593367715 | validation: 0.16359871624786432]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12543551207050596		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.12543551207050596 | validation: 0.15676712185615552]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12550994885350292		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.12550994885350292 | validation: 0.1606422222739485]
	TIME [epoch: 11.4 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12490839456978631		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.12490839456978631 | validation: 0.1593123550893935]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12733060824911585		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.12733060824911585 | validation: 0.15247556825795353]
	TIME [epoch: 11.4 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12248201379582442		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.12248201379582442 | validation: 0.1597190837400539]
	TIME [epoch: 11.4 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12758799114237607		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.12758799114237607 | validation: 0.14924255758201782]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12500019388864908		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.12500019388864908 | validation: 0.16102383378184443]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12563155225181516		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.12563155225181516 | validation: 0.14843554331927977]
	TIME [epoch: 11.4 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12956378991060719		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.12956378991060719 | validation: 0.1561619423843332]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327961584221356		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.1327961584221356 | validation: 0.15303351831143974]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12513945512913205		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.12513945512913205 | validation: 0.14620838463546787]
	TIME [epoch: 11.4 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12221237636595625		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.12221237636595625 | validation: 0.15303979199212223]
	TIME [epoch: 11.4 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12603819626062251		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.12603819626062251 | validation: 0.15519038173219799]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12414485657597282		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.12414485657597282 | validation: 0.15576864595791495]
	TIME [epoch: 11.4 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13109372615026205		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.13109372615026205 | validation: 0.15193467101806032]
	TIME [epoch: 11.4 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12543770824489586		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.12543770824489586 | validation: 0.15115399863865292]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12551622085098096		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.12551622085098096 | validation: 0.15162963970979185]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279809968302399		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.1279809968302399 | validation: 0.15202159422467704]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12301438432633621		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.12301438432633621 | validation: 0.1523346520416175]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12627140559936725		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.12627140559936725 | validation: 0.1586698103310212]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12925015330977396		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.12925015330977396 | validation: 0.16315131136819042]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289852006474469		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.1289852006474469 | validation: 0.1534207607317946]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325453381020622		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.1325453381020622 | validation: 0.16262041600284013]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131379633732157		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.131379633732157 | validation: 0.15339179273652603]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1239128834172342		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.1239128834172342 | validation: 0.1418216927736041]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_1374.pth
	Model improved!!!
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1248311574251331		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.1248311574251331 | validation: 0.14789002964452536]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12315003991705045		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.12315003991705045 | validation: 0.15703812488362803]
	TIME [epoch: 11.4 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12105071395745541		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.12105071395745541 | validation: 0.15480178922984644]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253398517166695		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.1253398517166695 | validation: 0.15465907351601194]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12899553747745263		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.12899553747745263 | validation: 0.1448150841379417]
	TIME [epoch: 11.4 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12754526037910857		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.12754526037910857 | validation: 0.15870915147100528]
	TIME [epoch: 11.4 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279926820420929		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.1279926820420929 | validation: 0.1588943882158351]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12830757860437486		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.12830757860437486 | validation: 0.1590197488942233]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13058321620821978		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.13058321620821978 | validation: 0.15598348236407097]
	TIME [epoch: 11.4 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12629936654093976		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.12629936654093976 | validation: 0.15456734450879694]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254913266079068		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.1254913266079068 | validation: 0.17055905887892894]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12421645205092319		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.12421645205092319 | validation: 0.14932433442507143]
	TIME [epoch: 11.4 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12574032999592455		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.12574032999592455 | validation: 0.15216306344716224]
	TIME [epoch: 11.4 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331861108727834		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.1331861108727834 | validation: 0.14380672772721143]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12198395034817355		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.12198395034817355 | validation: 0.15498100935552306]
	TIME [epoch: 11.4 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12102154691552375		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.12102154691552375 | validation: 0.16361526757594105]
	TIME [epoch: 11.4 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12248423756172515		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.12248423756172515 | validation: 0.15689669762093922]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12446029159039523		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.12446029159039523 | validation: 0.15387936730031854]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12827272171747137		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.12827272171747137 | validation: 0.156244377894765]
	TIME [epoch: 11.4 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13021918482488903		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.13021918482488903 | validation: 0.1497616048530259]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12461149307164898		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.12461149307164898 | validation: 0.1503324874150488]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12482266346626221		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.12482266346626221 | validation: 0.1691400730176352]
	TIME [epoch: 11.4 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12965585238633276		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.12965585238633276 | validation: 0.1527438426312061]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12541784122253408		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.12541784122253408 | validation: 0.162021746634675]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12787861085561017		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.12787861085561017 | validation: 0.15103565099204702]
	TIME [epoch: 11.4 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1187750824284518		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.1187750824284518 | validation: 0.15558552630288414]
	TIME [epoch: 11.4 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12216338388903837		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.12216338388903837 | validation: 0.15492738782141557]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12207287576340509		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.12207287576340509 | validation: 0.16064979114872824]
	TIME [epoch: 11.4 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266959387793295		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.1266959387793295 | validation: 0.1569389132517173]
	TIME [epoch: 11.4 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124257460306655		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.124257460306655 | validation: 0.15364225801412598]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126293060947402		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.126293060947402 | validation: 0.15933096112029513]
	TIME [epoch: 11.4 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12969720892515146		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.12969720892515146 | validation: 0.15123537967537082]
	TIME [epoch: 11.4 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12891657237967966		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.12891657237967966 | validation: 0.1528962288151232]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12321858491799037		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.12321858491799037 | validation: 0.14959224297074372]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12550225203374996		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.12550225203374996 | validation: 0.1581568756630427]
	TIME [epoch: 11.4 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13326119597725625		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.13326119597725625 | validation: 0.1488479268818669]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12704013766448147		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.12704013766448147 | validation: 0.15807653146954845]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12583868412307744		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.12583868412307744 | validation: 0.14887378674809784]
	TIME [epoch: 11.4 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12253239980673745		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.12253239980673745 | validation: 0.14581408418308384]
	TIME [epoch: 11.4 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13240344834874648		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.13240344834874648 | validation: 0.15735414310045895]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13994928065938544		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.13994928065938544 | validation: 0.14645580495380986]
	TIME [epoch: 11.4 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12587261199271832		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.12587261199271832 | validation: 0.14980031959928994]
	TIME [epoch: 11.4 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12856656164064278		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.12856656164064278 | validation: 0.16342368747327968]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13196103545405732		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.13196103545405732 | validation: 0.16949509082093964]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12755315217321847		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.12755315217321847 | validation: 0.1567397619941611]
	TIME [epoch: 11.4 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12481271326882125		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.12481271326882125 | validation: 0.14442951115570027]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12398954818267356		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.12398954818267356 | validation: 0.15220035387797398]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12248030508899055		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.12248030508899055 | validation: 0.1514296386814829]
	TIME [epoch: 11.4 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252859553549971		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.1252859553549971 | validation: 0.154657305175091]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12754999104408535		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.12754999104408535 | validation: 0.1466869668089714]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12894475266815417		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.12894475266815417 | validation: 0.14376001555449255]
	TIME [epoch: 11.4 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12652268977145495		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.12652268977145495 | validation: 0.14496127235305253]
	TIME [epoch: 11.4 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1306730787430816		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.1306730787430816 | validation: 0.1533503106564]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13436049823691099		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.13436049823691099 | validation: 0.15262884289121703]
	TIME [epoch: 11.4 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12645311016531585		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.12645311016531585 | validation: 0.15293561740573278]
	TIME [epoch: 11.4 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13864575586214464		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.13864575586214464 | validation: 0.15138162725884544]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294511580291885		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.1294511580291885 | validation: 0.1471916111917861]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13343724679759636		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.13343724679759636 | validation: 0.15006740676248725]
	TIME [epoch: 11.4 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260707351839055		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.1260707351839055 | validation: 0.14536383630569188]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12164874673412102		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.12164874673412102 | validation: 0.1433985544457817]
	TIME [epoch: 11.4 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12800569970254858		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.12800569970254858 | validation: 0.14839500412158035]
	TIME [epoch: 11.4 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12320189678858803		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.12320189678858803 | validation: 0.1526883978203135]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12072848436280069		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.12072848436280069 | validation: 0.15080160220203087]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13140721739585956		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.13140721739585956 | validation: 0.16125048731038072]
	TIME [epoch: 11.4 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287369677708814		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.1287369677708814 | validation: 0.16190176387212016]
	TIME [epoch: 11.4 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12744433877800854		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.12744433877800854 | validation: 0.15081924646144512]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275446610134176		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.1275446610134176 | validation: 0.15069101794290365]
	TIME [epoch: 11.4 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12650005734768996		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.12650005734768996 | validation: 0.14587938673123663]
	TIME [epoch: 11.4 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12794517556319537		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.12794517556319537 | validation: 0.15349264114965588]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13532746307931717		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.13532746307931717 | validation: 0.1527961999111294]
	TIME [epoch: 11.4 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355644569826284		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.1355644569826284 | validation: 0.1604731970270593]
	TIME [epoch: 11.4 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12870682020985666		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.12870682020985666 | validation: 0.1448148798927298]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12201364748007282		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.12201364748007282 | validation: 0.15533424267785387]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12497285058003478		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.12497285058003478 | validation: 0.15270671820874093]
	TIME [epoch: 11.4 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250025641395286		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.1250025641395286 | validation: 0.15218086528255778]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263539592008557		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.1263539592008557 | validation: 0.1518386092843522]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252603990195958		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.1252603990195958 | validation: 0.14838626176305802]
	TIME [epoch: 11.4 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12269485674051323		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.12269485674051323 | validation: 0.1512716827439981]
	TIME [epoch: 11.4 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12673293847749553		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.12673293847749553 | validation: 0.15162177349194453]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12570463652065106		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.12570463652065106 | validation: 0.1453863019233903]
	TIME [epoch: 11.4 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259382638799279		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.1259382638799279 | validation: 0.15355130964838226]
	TIME [epoch: 11.4 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12423394667634173		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.12423394667634173 | validation: 0.14983038226861445]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12469107136065433		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.12469107136065433 | validation: 0.15124849608748908]
	TIME [epoch: 11.4 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12364122247358149		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.12364122247358149 | validation: 0.16268580362502114]
	TIME [epoch: 11.4 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12089088080576572		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.12089088080576572 | validation: 0.15778767423224174]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12558818341000252		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.12558818341000252 | validation: 0.15495627408948737]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12286231849995492		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.12286231849995492 | validation: 0.14632398920897952]
	TIME [epoch: 11.4 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11929709269870392		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.11929709269870392 | validation: 0.15730599563402142]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253695031827651		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.1253695031827651 | validation: 0.15255964903495606]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12165970543567568		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.12165970543567568 | validation: 0.15043946110023337]
	TIME [epoch: 11.4 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12450351868135286		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.12450351868135286 | validation: 0.1481329412970069]
	TIME [epoch: 11.4 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298790088776943		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.1298790088776943 | validation: 0.15502025459437468]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12755006206667793		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.12755006206667793 | validation: 0.1507994438827059]
	TIME [epoch: 11.4 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125277209008761		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.125277209008761 | validation: 0.14976357634411103]
	TIME [epoch: 11.4 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12475311280729706		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.12475311280729706 | validation: 0.15694559178102946]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12401474117899608		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.12401474117899608 | validation: 0.1453897069137285]
	TIME [epoch: 11.4 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12099652863134079		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.12099652863134079 | validation: 0.14947138483165334]
	TIME [epoch: 11.4 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12276365873673642		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.12276365873673642 | validation: 0.156133799137414]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12773570205297435		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.12773570205297435 | validation: 0.14567297614544725]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257460570238292		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.1257460570238292 | validation: 0.15577861348554697]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12769575033868036		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.12769575033868036 | validation: 0.16114950717118806]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12217861196023598		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.12217861196023598 | validation: 0.1555157100569961]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125694984353321		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.125694984353321 | validation: 0.1544896862332844]
	TIME [epoch: 11.4 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11997042739443627		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.11997042739443627 | validation: 0.14868500029853163]
	TIME [epoch: 11.4 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12432862206715634		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.12432862206715634 | validation: 0.15796759626713464]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12035372133434813		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.12035372133434813 | validation: 0.14759514119013492]
	TIME [epoch: 11.4 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12359553470063749		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.12359553470063749 | validation: 0.14297900090150037]
	TIME [epoch: 11.4 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12335512025959378		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.12335512025959378 | validation: 0.15053458929136368]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12573178315278538		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.12573178315278538 | validation: 0.1500553950235905]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12322450813749952		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.12322450813749952 | validation: 0.15523482251178253]
	TIME [epoch: 11.4 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12068124643153455		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.12068124643153455 | validation: 0.1468094791921905]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12230448270990857		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.12230448270990857 | validation: 0.1539321721179554]
	TIME [epoch: 11.4 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12392745012331663		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.12392745012331663 | validation: 0.1484998426071262]
	TIME [epoch: 11.4 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1231656302304503		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.1231656302304503 | validation: 0.1576813736376666]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12516589497827907		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.12516589497827907 | validation: 0.1529237170372968]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1241495399703009		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.1241495399703009 | validation: 0.15427849299603158]
	TIME [epoch: 11.4 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274059568023118		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.12274059568023118 | validation: 0.1506020195987662]
	TIME [epoch: 11.4 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12620322296452346		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.12620322296452346 | validation: 0.1512762265694666]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12666190653066292		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.12666190653066292 | validation: 0.15933603405865862]
	TIME [epoch: 11.4 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12434799482905624		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.12434799482905624 | validation: 0.14836723818881875]
	TIME [epoch: 11.4 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11946770933224152		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.11946770933224152 | validation: 0.1461085661695711]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1229247606910058		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.1229247606910058 | validation: 0.149677876023496]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1246340961808402		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.1246340961808402 | validation: 0.1541805923447482]
	TIME [epoch: 11.4 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12088239966223395		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.12088239966223395 | validation: 0.14831853243630438]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12409088475245829		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.12409088475245829 | validation: 0.1551206963395541]
	TIME [epoch: 11.4 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468160139620413		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.12468160139620413 | validation: 0.15218483022116583]
	TIME [epoch: 11.4 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12637430560428542		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.12637430560428542 | validation: 0.15428738743233866]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12738376513749625		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.12738376513749625 | validation: 0.14914050284019187]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12592015683552854		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.12592015683552854 | validation: 0.15082975819821898]
	TIME [epoch: 11.4 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12324895242315165		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.12324895242315165 | validation: 0.15017774595381514]
	TIME [epoch: 11.4 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1246542809622925		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.1246542809622925 | validation: 0.15435996938362725]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12443794603234244		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.12443794603234244 | validation: 0.14870614148419814]
	TIME [epoch: 11.4 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12242857922742517		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.12242857922742517 | validation: 0.14232851683328132]
	TIME [epoch: 11.4 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12549860862405318		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.12549860862405318 | validation: 0.15646181835169412]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12419533090369608		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.12419533090369608 | validation: 0.15939045109483482]
	TIME [epoch: 11.4 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12463885358329721		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.12463885358329721 | validation: 0.15631950756468882]
	TIME [epoch: 11.4 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12209247168687377		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.12209247168687377 | validation: 0.14709559737841146]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12299923162237417		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.12299923162237417 | validation: 0.1545456894178335]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12382772765942374		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.12382772765942374 | validation: 0.14576967912735708]
	TIME [epoch: 11.4 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12504857022735621		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.12504857022735621 | validation: 0.1490008901440304]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12379854643747812		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.12379854643747812 | validation: 0.14524862326133609]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12141205936260342		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.12141205936260342 | validation: 0.15735196860940037]
	TIME [epoch: 11.4 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12611519497145748		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.12611519497145748 | validation: 0.1557547485147856]
	TIME [epoch: 11.4 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12670002152126666		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.12670002152126666 | validation: 0.1539189306127311]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11931089883499428		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.11931089883499428 | validation: 0.15196420869379687]
	TIME [epoch: 11.4 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12074443019240153		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.12074443019240153 | validation: 0.15633887976720875]
	TIME [epoch: 11.4 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1236202671568302		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.1236202671568302 | validation: 0.15785885607468522]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12477935355817876		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.12477935355817876 | validation: 0.15451789992616463]
	TIME [epoch: 11.4 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12651961694361283		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.12651961694361283 | validation: 0.16064855632114863]
	TIME [epoch: 11.4 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12528852977478397		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.12528852977478397 | validation: 0.14894989788331117]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12100015237145158		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.12100015237145158 | validation: 0.1629064042351182]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263793814193922		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.1263793814193922 | validation: 0.1533327694930246]
	TIME [epoch: 11.4 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12365424368711689		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.12365424368711689 | validation: 0.14258347571551525]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12127382223650633		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.12127382223650633 | validation: 0.14456016823785908]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1246394082855855		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.1246394082855855 | validation: 0.15280131534441746]
	TIME [epoch: 11.4 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13067230630351892		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.13067230630351892 | validation: 0.15998577072978581]
	TIME [epoch: 11.4 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325641788113182		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.1325641788113182 | validation: 0.1658555252016705]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12633570647146836		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.12633570647146836 | validation: 0.1597706883683771]
	TIME [epoch: 11.4 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12377060761202224		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.12377060761202224 | validation: 0.14690398027018556]
	TIME [epoch: 11.4 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12652638948570827		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.12652638948570827 | validation: 0.15709452506957802]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1239720545751765		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.1239720545751765 | validation: 0.14861905849754528]
	TIME [epoch: 11.4 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12310787040699342		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.12310787040699342 | validation: 0.15001796649645052]
	TIME [epoch: 11.4 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12444930421219058		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.12444930421219058 | validation: 0.15280105457370036]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12494319151265026		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.12494319151265026 | validation: 0.15875243080191617]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12704416699719265		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.12704416699719265 | validation: 0.15421373788935605]
	TIME [epoch: 11.4 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12510719446278748		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.12510719446278748 | validation: 0.1454702788906867]
	TIME [epoch: 11.4 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12565009207500155		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.12565009207500155 | validation: 0.1531361490956101]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12544488532979553		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.12544488532979553 | validation: 0.15045290557532434]
	TIME [epoch: 11.4 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11933420825579265		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.11933420825579265 | validation: 0.14860108484545412]
	TIME [epoch: 11.4 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12316535903469347		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.12316535903469347 | validation: 0.1516481043343951]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1241466955777171		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.1241466955777171 | validation: 0.14699427183215513]
	TIME [epoch: 11.4 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12478384114341035		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.12478384114341035 | validation: 0.15428088454450642]
	TIME [epoch: 11.4 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12318427772245427		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.12318427772245427 | validation: 0.15096443630477868]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12266567536450595		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.12266567536450595 | validation: 0.15842394851376576]
	TIME [epoch: 11.4 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11974861135576698		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.11974861135576698 | validation: 0.14944166572169523]
	TIME [epoch: 11.4 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12215336905432246		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.12215336905432246 | validation: 0.1541251890240015]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265486776416086		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.1265486776416086 | validation: 0.1537009026354431]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12119612345465532		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.12119612345465532 | validation: 0.1513286564004289]
	TIME [epoch: 11.4 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12358030347057315		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.12358030347057315 | validation: 0.1507381885299327]
	TIME [epoch: 11.4 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11821494140330105		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.11821494140330105 | validation: 0.15813133607635393]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12234436556138663		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.12234436556138663 | validation: 0.14784810508664845]
	TIME [epoch: 11.4 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12552994090497183		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.12552994090497183 | validation: 0.14501293426356207]
	TIME [epoch: 11.4 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268295980135835		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.1268295980135835 | validation: 0.15130148896954002]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1213209665260182		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.1213209665260182 | validation: 0.14588849515271038]
	TIME [epoch: 11.4 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12183338997053264		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.12183338997053264 | validation: 0.15051090910431986]
	TIME [epoch: 11.4 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12399935544976748		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.12399935544976748 | validation: 0.14232004070070572]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12375312695725019		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.12375312695725019 | validation: 0.14946545609078865]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12691851212155902		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.12691851212155902 | validation: 0.1467636375436521]
	TIME [epoch: 11.4 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12179729625766768		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.12179729625766768 | validation: 0.14666796260927387]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12294032391528427		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.12294032391528427 | validation: 0.14834608705266128]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11906405869273903		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.11906405869273903 | validation: 0.14626929039964953]
	TIME [epoch: 11.4 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12377869513095885		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.12377869513095885 | validation: 0.15237562262086854]
	TIME [epoch: 11.4 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12458348112622385		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.12458348112622385 | validation: 0.15344539097242543]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12873267376529543		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.12873267376529543 | validation: 0.15428461533700014]
	TIME [epoch: 11.4 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260732439352919		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.1260732439352919 | validation: 0.14675837213167342]
	TIME [epoch: 11.4 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12436694423323465		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.12436694423323465 | validation: 0.15383692320901873]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11945732753780722		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.11945732753780722 | validation: 0.1477732342231137]
	TIME [epoch: 11.4 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12363200890934642		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.12363200890934642 | validation: 0.15156710598295528]
	TIME [epoch: 11.4 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1216315113604784		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.1216315113604784 | validation: 0.1455298390565569]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12323638844780893		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.12323638844780893 | validation: 0.14815463170386015]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12174780820263581		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.12174780820263581 | validation: 0.1485798062116219]
	TIME [epoch: 11.4 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12240690285548797		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.12240690285548797 | validation: 0.15026351638478147]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12099223420074486		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.12099223420074486 | validation: 0.15053690233879966]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12172647101266135		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.12172647101266135 | validation: 0.1476845997972664]
	TIME [epoch: 11.4 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1198370015256257		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.1198370015256257 | validation: 0.1492069835313747]
	TIME [epoch: 11.4 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260406328865452		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.1260406328865452 | validation: 0.15863257938564707]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12480742621851847		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.12480742621851847 | validation: 0.15218445664675279]
	TIME [epoch: 11.4 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1214512661746959		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.1214512661746959 | validation: 0.14468935942959849]
	TIME [epoch: 11.4 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1214594591579697		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.1214594591579697 | validation: 0.1563726831634702]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12161884509091789		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.12161884509091789 | validation: 0.15469797929049975]
	TIME [epoch: 11.4 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12573821687671918		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.12573821687671918 | validation: 0.15008228471659096]
	TIME [epoch: 11.4 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1229735500713846		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.1229735500713846 | validation: 0.14693854594030092]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12312703512937359		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.12312703512937359 | validation: 0.15402978255826974]
	TIME [epoch: 11.4 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12427828255229542		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.12427828255229542 | validation: 0.15265571987166682]
	TIME [epoch: 11.4 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12279571010203472		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.12279571010203472 | validation: 0.15310341157597798]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12209850295896402		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.12209850295896402 | validation: 0.14784702580338682]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12141121337681007		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.12141121337681007 | validation: 0.14296774026284303]
	TIME [epoch: 11.4 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11992062189429767		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.11992062189429767 | validation: 0.15314258814813808]
	TIME [epoch: 11.4 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12337139207442326		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.12337139207442326 | validation: 0.14874456169930736]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12378287611358303		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.12378287611358303 | validation: 0.14692423440852095]
	TIME [epoch: 11.4 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12082027154681857		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.12082027154681857 | validation: 0.14653344071639177]
	TIME [epoch: 11.4 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12304634816766016		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.12304634816766016 | validation: 0.1494966210375818]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126610936088689		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.126610936088689 | validation: 0.14929436974262073]
	TIME [epoch: 11.4 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12536624337127755		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.12536624337127755 | validation: 0.14928477219231945]
	TIME [epoch: 11.4 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12140658128250324		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.12140658128250324 | validation: 0.15189836360583348]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12394513475723004		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.12394513475723004 | validation: 0.1577573380003435]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12381352528707465		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.12381352528707465 | validation: 0.15693739186704458]
	TIME [epoch: 11.4 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12641828984401632		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.12641828984401632 | validation: 0.1587375408662848]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1234397606379824		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.1234397606379824 | validation: 0.14593668327561177]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294193344032717		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.1294193344032717 | validation: 0.15422289861917407]
	TIME [epoch: 11.4 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12312903885450355		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.12312903885450355 | validation: 0.1610846728144159]
	TIME [epoch: 11.4 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293687333266744		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.1293687333266744 | validation: 0.16475699898330223]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12392146845714606		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.12392146845714606 | validation: 0.1582679520741119]
	TIME [epoch: 11.4 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12549661326598074		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.12549661326598074 | validation: 0.16513409913514743]
	TIME [epoch: 11.4 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12134533616661067		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.12134533616661067 | validation: 0.15270583961755604]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12184667752276833		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.12184667752276833 | validation: 0.15065312362325423]
	TIME [epoch: 11.4 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1209947174941888		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.1209947174941888 | validation: 0.15080986873586205]
	TIME [epoch: 11.4 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12369560009769692		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.12369560009769692 | validation: 0.15374352835803126]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11962124354410245		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.11962124354410245 | validation: 0.14969087612894716]
	TIME [epoch: 11.4 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12132783499558439		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.12132783499558439 | validation: 0.15524884924436116]
	TIME [epoch: 11.4 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12560833230252258		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.12560833230252258 | validation: 0.15435478835892663]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12486262628006935		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.12486262628006935 | validation: 0.14596634793386157]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12963459084623075		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.12963459084623075 | validation: 0.14826751694400347]
	TIME [epoch: 11.4 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12153950344947144		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.12153950344947144 | validation: 0.1445896253003244]
	TIME [epoch: 11.4 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1239177315609061		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.1239177315609061 | validation: 0.1568170344572724]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468586500947937		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.12468586500947937 | validation: 0.1485466112470518]
	TIME [epoch: 11.4 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12448241803386197		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.12448241803386197 | validation: 0.15295351592880166]
	TIME [epoch: 11.4 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12001711771825721		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.12001711771825721 | validation: 0.14823132616023582]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12477199358348737		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.12477199358348737 | validation: 0.14267527549681114]
	TIME [epoch: 11.4 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12089910344596068		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.12089910344596068 | validation: 0.15827978536356063]
	TIME [epoch: 11.4 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12127001666985013		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.12127001666985013 | validation: 0.1453307514521406]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250832351675585		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.1250832351675585 | validation: 0.15457885845864533]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11995277483174813		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.11995277483174813 | validation: 0.14558456800078992]
	TIME [epoch: 11.4 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12182707307789323		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.12182707307789323 | validation: 0.15621913462846293]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12471566712561657		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.12471566712561657 | validation: 0.14480027560486997]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12143861810643392		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.12143861810643392 | validation: 0.15610876460732415]
	TIME [epoch: 11.4 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12777476888411501		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.12777476888411501 | validation: 0.15385315879386383]
	TIME [epoch: 11.4 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12844429644013367		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.12844429644013367 | validation: 0.1450304366250759]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12272958411331418		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.12272958411331418 | validation: 0.15040185341576398]
	TIME [epoch: 11.4 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12481776576161693		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.12481776576161693 | validation: 0.15346596910678675]
	TIME [epoch: 11.4 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12111559775656161		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.12111559775656161 | validation: 0.14754063316117094]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12242076344941884		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.12242076344941884 | validation: 0.1562087365626971]
	TIME [epoch: 11.4 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1233691450002504		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.1233691450002504 | validation: 0.14969833907444838]
	TIME [epoch: 11.4 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11917485088469913		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.11917485088469913 | validation: 0.1470673847554584]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12140850169883595		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.12140850169883595 | validation: 0.1474476279859355]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12194273704396075		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.12194273704396075 | validation: 0.1522255115535748]
	TIME [epoch: 11.4 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11783671207868796		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.11783671207868796 | validation: 0.1467519343811471]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12159823376484076		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.12159823376484076 | validation: 0.14558977551723648]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12582314067192735		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.12582314067192735 | validation: 0.15620939234876122]
	TIME [epoch: 11.4 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11834238054833261		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.11834238054833261 | validation: 0.1592598451846788]
	TIME [epoch: 11.4 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12394238754523945		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.12394238754523945 | validation: 0.14906212669867325]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12548434580024787		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.12548434580024787 | validation: 0.14858382625273694]
	TIME [epoch: 11.4 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12169382898851597		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.12169382898851597 | validation: 0.15233656839639526]
	TIME [epoch: 11.4 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257578329543455		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.1257578329543455 | validation: 0.1541925170637093]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12349481607762278		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.12349481607762278 | validation: 0.1410993448083348]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_1649.pth
	Model improved!!!
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12432507887707597		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.12432507887707597 | validation: 0.14993538221854172]
	TIME [epoch: 11.4 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12417808155478476		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.12417808155478476 | validation: 0.14561515624943697]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12089101730997649		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.12089101730997649 | validation: 0.14592990401392314]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12342863702089815		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.12342863702089815 | validation: 0.15031957727204842]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12100917522763338		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.12100917522763338 | validation: 0.14742015251415097]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12316159552605263		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.12316159552605263 | validation: 0.14271854404438147]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12169992400027249		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.12169992400027249 | validation: 0.14667401293117782]
	TIME [epoch: 11.4 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12493850042184164		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.12493850042184164 | validation: 0.1491501786432225]
	TIME [epoch: 11.4 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1228484152255542		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.1228484152255542 | validation: 0.1506149720119433]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12486561486103728		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.12486561486103728 | validation: 0.15523816975625948]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12543258412633523		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.12543258412633523 | validation: 0.1505980209543959]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12204796619806108		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.12204796619806108 | validation: 0.14976540674605582]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12001930462822352		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.12001930462822352 | validation: 0.14461384730777252]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12478972136171695		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.12478972136171695 | validation: 0.15243375851297528]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282762423597735		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.1282762423597735 | validation: 0.15051371651188558]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12806582272542688		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.12806582272542688 | validation: 0.15287234459978366]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12738454555632153		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.12738454555632153 | validation: 0.13897842095419016]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_1666.pth
	Model improved!!!
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12398938429937403		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.12398938429937403 | validation: 0.15625690594992306]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256069415888107		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.1256069415888107 | validation: 0.15420106606471123]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12447859894575586		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.12447859894575586 | validation: 0.14843143493506436]
	TIME [epoch: 11.4 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12207325913816235		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.12207325913816235 | validation: 0.1504014917120411]
	TIME [epoch: 11.4 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12576193811245198		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.12576193811245198 | validation: 0.14718084920586344]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12067772857328697		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.12067772857328697 | validation: 0.15045914565948962]
	TIME [epoch: 11.4 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12204614862721323		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.12204614862721323 | validation: 0.14752915038476477]
	TIME [epoch: 11.4 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12503506721302465		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.12503506721302465 | validation: 0.15503080682477063]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12298809404490868		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.12298809404490868 | validation: 0.14756207625160747]
	TIME [epoch: 11.4 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12164452226506638		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.12164452226506638 | validation: 0.146744214718719]
	TIME [epoch: 11.4 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12429373902294553		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.12429373902294553 | validation: 0.1513572868666591]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12615212273484047		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.12615212273484047 | validation: 0.14602779658807927]
	TIME [epoch: 11.4 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12812974297414048		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.12812974297414048 | validation: 0.15223585962491903]
	TIME [epoch: 11.4 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263511017487501		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.1263511017487501 | validation: 0.14958760926809106]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12240689300235072		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.12240689300235072 | validation: 0.14493251168910487]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12419588537940349		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.12419588537940349 | validation: 0.15198897629020827]
	TIME [epoch: 11.4 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264759177984705		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.1264759177984705 | validation: 0.1525017773649791]
	TIME [epoch: 11.4 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12163595046917394		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.12163595046917394 | validation: 0.14391466819039284]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12086104390247457		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.12086104390247457 | validation: 0.15382410059384513]
	TIME [epoch: 11.4 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12510764761539778		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.12510764761539778 | validation: 0.1469441055853128]
	TIME [epoch: 11.4 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12461540036032628		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.12461540036032628 | validation: 0.1428666126052907]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12629396721619768		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.12629396721619768 | validation: 0.14986017736472415]
	TIME [epoch: 11.4 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12458227157016886		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.12458227157016886 | validation: 0.15125779950252716]
	TIME [epoch: 11.4 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1208869730864794		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.1208869730864794 | validation: 0.14960827976143845]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11914801921119142		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.11914801921119142 | validation: 0.1550311252431494]
	TIME [epoch: 11.4 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12052368329925361		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.12052368329925361 | validation: 0.14873959939766834]
	TIME [epoch: 11.4 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1235053251257481		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.1235053251257481 | validation: 0.1573569585611817]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12514165280930936		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.12514165280930936 | validation: 0.14940004307471066]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12261014966239518		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.12261014966239518 | validation: 0.1454573197108302]
	TIME [epoch: 11.4 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12306747099281519		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.12306747099281519 | validation: 0.158116458441724]
	TIME [epoch: 11.4 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12433116682830476		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.12433116682830476 | validation: 0.1403404593170143]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12042688536229314		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.12042688536229314 | validation: 0.1583206236822589]
	TIME [epoch: 11.4 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12355869924030173		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.12355869924030173 | validation: 0.15723738492005307]
	TIME [epoch: 11.4 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1221620265236453		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.1221620265236453 | validation: 0.1512790723400992]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12422633604669256		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.12422633604669256 | validation: 0.15044392493853365]
	TIME [epoch: 11.4 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12409921811821452		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.12409921811821452 | validation: 0.15154302029837008]
	TIME [epoch: 11.4 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12058827490508822		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.12058827490508822 | validation: 0.14728270874109606]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12713056205050466		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.12713056205050466 | validation: 0.14523482090256934]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12455036325361142		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.12455036325361142 | validation: 0.14650422346583908]
	TIME [epoch: 11.4 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12574609730664651		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.12574609730664651 | validation: 0.15399735256995462]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12204613233233284		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.12204613233233284 | validation: 0.14974011709060386]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12458765461103107		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.12458765461103107 | validation: 0.15171730575599646]
	TIME [epoch: 11.4 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12303011006866621		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.12303011006866621 | validation: 0.1499203595863906]
	TIME [epoch: 11.4 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12045877218269191		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.12045877218269191 | validation: 0.14925159065547935]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12273602885929141		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.12273602885929141 | validation: 0.1543367775922689]
	TIME [epoch: 11.4 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12049170695301478		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.12049170695301478 | validation: 0.14710287740370392]
	TIME [epoch: 11.4 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11781286493681356		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.11781286493681356 | validation: 0.14239735827567296]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12486337651373816		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.12486337651373816 | validation: 0.15014346599815018]
	TIME [epoch: 11.4 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12138247176033228		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.12138247176033228 | validation: 0.14878260357971018]
	TIME [epoch: 11.4 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12432566103773743		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.12432566103773743 | validation: 0.14658732763849017]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12238456535661482		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.12238456535661482 | validation: 0.1509722177912718]
	TIME [epoch: 11.4 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259518502640584		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.1259518502640584 | validation: 0.15596837792170287]
	TIME [epoch: 11.4 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12343820116384716		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.12343820116384716 | validation: 0.13980057218782396]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12426126656479426		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.12426126656479426 | validation: 0.14590711466381198]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12463501533527553		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.12463501533527553 | validation: 0.14134595426929586]
	TIME [epoch: 11.4 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12180206916513121		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.12180206916513121 | validation: 0.15336366816481004]
	TIME [epoch: 11.4 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207164231416001		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.1207164231416001 | validation: 0.147318911364439]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12440996759545285		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.12440996759545285 | validation: 0.14753093220820765]
	TIME [epoch: 11.4 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11992028208056518		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.11992028208056518 | validation: 0.15045085261804228]
	TIME [epoch: 11.4 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12273481498723716		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.12273481498723716 | validation: 0.14883186973752235]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12036268847995024		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.12036268847995024 | validation: 0.15018533608899504]
	TIME [epoch: 11.4 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12159047274098811		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.12159047274098811 | validation: 0.1548919138950095]
	TIME [epoch: 11.4 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12381833356948171		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.12381833356948171 | validation: 0.14924100628990783]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12068076315890941		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.12068076315890941 | validation: 0.15151173855870878]
	TIME [epoch: 11.4 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12057515584296061		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.12057515584296061 | validation: 0.15468775721681666]
	TIME [epoch: 11.4 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11536535505388223		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.11536535505388223 | validation: 0.1524129916289388]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11900423391176985		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.11900423391176985 | validation: 0.1503359923696416]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12250405912211562		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.12250405912211562 | validation: 0.15288805449834486]
	TIME [epoch: 11.4 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12458524678858429		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.12458524678858429 | validation: 0.16171626829042476]
	TIME [epoch: 11.4 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12239447690472162		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.12239447690472162 | validation: 0.1481201310516513]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12362452796592208		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.12362452796592208 | validation: 0.1485370589802612]
	TIME [epoch: 11.4 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1240214200744392		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.1240214200744392 | validation: 0.14949523370974419]
	TIME [epoch: 11.4 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12139995888339628		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.12139995888339628 | validation: 0.14791972397224468]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12448660027747163		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.12448660027747163 | validation: 0.15207970406325]
	TIME [epoch: 11.4 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12355051569164704		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.12355051569164704 | validation: 0.1411485597242138]
	TIME [epoch: 11.4 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12159201756851995		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.12159201756851995 | validation: 0.15591842181566506]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12249052079346255		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.12249052079346255 | validation: 0.1506990938164058]
	TIME [epoch: 11.4 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12233933228935705		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.12233933228935705 | validation: 0.15520264528088923]
	TIME [epoch: 11.4 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12098232931775135		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.12098232931775135 | validation: 0.15255375124919307]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12152156664744226		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.12152156664744226 | validation: 0.15283456785266838]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212902666487196		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.1212902666487196 | validation: 0.15545095252374924]
	TIME [epoch: 11.4 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1210461051867108		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.1210461051867108 | validation: 0.15293575243229743]
	TIME [epoch: 11.4 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12350967639703023		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.12350967639703023 | validation: 0.1474565142165671]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12295210862851205		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.12295210862851205 | validation: 0.1531914467711345]
	TIME [epoch: 11.4 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12280821779937576		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.12280821779937576 | validation: 0.14877268506525723]
	TIME [epoch: 11.4 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12320329723075227		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.12320329723075227 | validation: 0.14925244415966885]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12198361420133162		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.12198361420133162 | validation: 0.1461919397096551]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1217846916204309		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.1217846916204309 | validation: 0.1441259833493544]
	TIME [epoch: 11.4 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12194485394513385		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.12194485394513385 | validation: 0.15142817848736356]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12186429082512747		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.12186429082512747 | validation: 0.1575750677519607]
	TIME [epoch: 11.4 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11823971570813746		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.11823971570813746 | validation: 0.14456339149121383]
	TIME [epoch: 11.4 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12385218254119505		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.12385218254119505 | validation: 0.1510412564520363]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12263821501709497		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.12263821501709497 | validation: 0.1509502409665988]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1209626192210894		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.1209626192210894 | validation: 0.14821176957853247]
	TIME [epoch: 11.4 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12112994599582007		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.12112994599582007 | validation: 0.14634130565798542]
	TIME [epoch: 11.4 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11774240221645395		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.11774240221645395 | validation: 0.14289642377024966]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12201018334666824		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.12201018334666824 | validation: 0.1501738686294187]
	TIME [epoch: 11.4 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205157260922684		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.1205157260922684 | validation: 0.14584262627930047]
	TIME [epoch: 11.4 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12424335148246164		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.12424335148246164 | validation: 0.14596642926034217]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12162219206872121		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.12162219206872121 | validation: 0.1535836290393395]
	TIME [epoch: 11.4 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12389591515047864		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.12389591515047864 | validation: 0.15749878660626518]
	TIME [epoch: 11.4 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12180092804117187		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.12180092804117187 | validation: 0.1552944002267673]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12171769448159633		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.12171769448159633 | validation: 0.1512899687609772]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12667491346408447		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.12667491346408447 | validation: 0.14551046082151478]
	TIME [epoch: 11.4 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12194430646693387		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.12194430646693387 | validation: 0.1501303602674051]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12139583091658125		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.12139583091658125 | validation: 0.15743404581938628]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12358765088593701		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.12358765088593701 | validation: 0.15192348621411866]
	TIME [epoch: 11.4 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12247935615648434		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.12247935615648434 | validation: 0.14408974064511884]
	TIME [epoch: 11.4 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250207560605228		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.1250207560605228 | validation: 0.15035663750616837]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12186309035740417		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.12186309035740417 | validation: 0.1517703285277028]
	TIME [epoch: 11.4 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255047652507537		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.1255047652507537 | validation: 0.15555477234780107]
	TIME [epoch: 11.4 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12418261227186747		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.12418261227186747 | validation: 0.14765680339548518]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12197128368259566		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.12197128368259566 | validation: 0.1527290677365326]
	TIME [epoch: 11.4 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11961201615336912		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.11961201615336912 | validation: 0.14367618037336324]
	TIME [epoch: 11.4 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12299543954963947		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.12299543954963947 | validation: 0.1498734866534011]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11906512865595492		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.11906512865595492 | validation: 0.15365698305500206]
	TIME [epoch: 11.4 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12278488923284483		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.12278488923284483 | validation: 0.14960043398148803]
	TIME [epoch: 11.4 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12074885542289718		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.12074885542289718 | validation: 0.14854232179107854]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1208342621555983		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.1208342621555983 | validation: 0.15247369421156784]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12333308143671387		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.12333308143671387 | validation: 0.14497886738969637]
	TIME [epoch: 11.4 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11951225526608023		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.11951225526608023 | validation: 0.15132947621573486]
	TIME [epoch: 11.4 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12307912905097465		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.12307912905097465 | validation: 0.15650672586495407]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11999859926628466		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.11999859926628466 | validation: 0.1574009390248243]
	TIME [epoch: 11.4 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1224894452315763		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.1224894452315763 | validation: 0.14899503582292511]
	TIME [epoch: 11.4 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11980930919170402		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.11980930919170402 | validation: 0.1497045040282854]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12117573644454599		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.12117573644454599 | validation: 0.14473839096987295]
	TIME [epoch: 11.4 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11725147882727847		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.11725147882727847 | validation: 0.14986612999499765]
	TIME [epoch: 11.4 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12100200116235658		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.12100200116235658 | validation: 0.14901609123129922]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11899260226179979		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.11899260226179979 | validation: 0.15253459472214836]
	TIME [epoch: 11.4 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11856239866972301		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.11856239866972301 | validation: 0.15028381848077393]
	TIME [epoch: 11.4 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12243350046680374		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.12243350046680374 | validation: 0.15018643409853097]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12233141242930771		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.12233141242930771 | validation: 0.15340077514374778]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12109846094546521		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.12109846094546521 | validation: 0.14496402484816645]
	TIME [epoch: 11.4 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1210453078148996		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.1210453078148996 | validation: 0.14561316603822008]
	TIME [epoch: 11.4 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256984283680188		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.1256984283680188 | validation: 0.14283715723874355]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12250107902699073		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.12250107902699073 | validation: 0.1499183997385104]
	TIME [epoch: 11.4 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12136710476523345		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.12136710476523345 | validation: 0.14198370765267726]
	TIME [epoch: 11.4 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1210259595111679		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.1210259595111679 | validation: 0.1508331135058344]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12551822788668474		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.12551822788668474 | validation: 0.14397614454607052]
	TIME [epoch: 11.4 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12403330263388754		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.12403330263388754 | validation: 0.1365650241394399]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r4_20240310_050823/states/model_tr_study204_1806.pth
	Model improved!!!
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12134741421129816		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.12134741421129816 | validation: 0.15060882207098147]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12160487127252226		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.12160487127252226 | validation: 0.14830517166242188]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12487195778315927		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.12487195778315927 | validation: 0.15062440547293834]
	TIME [epoch: 11.4 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12020323789421081		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.12020323789421081 | validation: 0.15052235381502496]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12220434112748466		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.12220434112748466 | validation: 0.15101487928254284]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12513653985609924		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.12513653985609924 | validation: 0.1471040087247432]
	TIME [epoch: 11.4 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12550811313643845		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.12550811313643845 | validation: 0.1491272524178834]
	TIME [epoch: 11.4 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1236721811768731		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.1236721811768731 | validation: 0.151766731807339]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12296943282021103		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.12296943282021103 | validation: 0.15276586119356167]
	TIME [epoch: 11.4 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12108151238949172		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.12108151238949172 | validation: 0.14998662697125503]
	TIME [epoch: 11.4 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1243619333393782		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.1243619333393782 | validation: 0.15080630309935825]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1211710831875821		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.1211710831875821 | validation: 0.1514319136206768]
	TIME [epoch: 11.4 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11829626956259814		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.11829626956259814 | validation: 0.14958515670275685]
	TIME [epoch: 11.4 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1180190186373967		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.1180190186373967 | validation: 0.1493749589020058]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12005940066550308		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.12005940066550308 | validation: 0.1456168573174102]
	TIME [epoch: 11.4 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12225649453475594		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.12225649453475594 | validation: 0.1468922022115991]
	TIME [epoch: 11.4 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12503355719985165		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.12503355719985165 | validation: 0.14794173705318941]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12542691142219833		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.12542691142219833 | validation: 0.14397800413871545]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1228065717216283		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.1228065717216283 | validation: 0.15371812136192584]
	TIME [epoch: 11.4 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12230086505986279		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.12230086505986279 | validation: 0.15835662899414288]
	TIME [epoch: 11.4 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12588585388361523		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.12588585388361523 | validation: 0.14272134616662738]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12567409075591374		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.12567409075591374 | validation: 0.14475584195581204]
	TIME [epoch: 11.4 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12037693771188404		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.12037693771188404 | validation: 0.15934066152895893]
	TIME [epoch: 11.4 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12250635053807607		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.12250635053807607 | validation: 0.151805386727189]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12285465918027791		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.12285465918027791 | validation: 0.14717629805527538]
	TIME [epoch: 11.4 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12002699310469103		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.12002699310469103 | validation: 0.14993696953379665]
	TIME [epoch: 11.4 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274834887542933		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.12274834887542933 | validation: 0.1476042543302393]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12205594874933827		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.12205594874933827 | validation: 0.14482262911990298]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12186036558644778		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.12186036558644778 | validation: 0.14581548340332434]
	TIME [epoch: 11.4 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1203021587990693		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.1203021587990693 | validation: 0.1548171795861356]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12163792101531987		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.12163792101531987 | validation: 0.15036498894082795]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12484332840531916		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.12484332840531916 | validation: 0.15623878768093616]
	TIME [epoch: 11.4 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12071207140196487		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.12071207140196487 | validation: 0.15838465180748434]
	TIME [epoch: 11.4 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12503605557341171		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.12503605557341171 | validation: 0.14703996788507198]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1246643335894973		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.1246643335894973 | validation: 0.1507186732999118]
	TIME [epoch: 11.4 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12446462871612951		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.12446462871612951 | validation: 0.14900688062655568]
	TIME [epoch: 11.4 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12055062903052158		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.12055062903052158 | validation: 0.1552906469177608]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1225101316952196		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.1225101316952196 | validation: 0.15262124737460642]
	TIME [epoch: 11.4 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12034492320966214		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.12034492320966214 | validation: 0.15535502749709676]
	TIME [epoch: 11.4 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12144247711048123		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.12144247711048123 | validation: 0.1519489051207685]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12239248778369627		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.12239248778369627 | validation: 0.14972813777541594]
	TIME [epoch: 11.4 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.121709043774537		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.121709043774537 | validation: 0.15140993812619516]
	TIME [epoch: 11.4 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12217155158780951		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.12217155158780951 | validation: 0.14680403818448567]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.123969526737722		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.123969526737722 | validation: 0.15729852898628285]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12048754041385577		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.12048754041385577 | validation: 0.147775403650063]
	TIME [epoch: 11.4 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12150839544278556		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.12150839544278556 | validation: 0.14598235978494728]
	TIME [epoch: 11.4 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12093556612291274		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.12093556612291274 | validation: 0.14636170151354025]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1227032404114492		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.1227032404114492 | validation: 0.14591915203547887]
	TIME [epoch: 11.4 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12362991612507579		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.12362991612507579 | validation: 0.15180518549661798]
	TIME [epoch: 11.4 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12261597733254859		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.12261597733254859 | validation: 0.15369222847780395]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12186077877287346		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.12186077877287346 | validation: 0.1451469063986404]
	TIME [epoch: 11.4 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12370817273445754		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.12370817273445754 | validation: 0.1536075501506868]
	TIME [epoch: 11.4 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11818572151553504		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.11818572151553504 | validation: 0.15006763798619593]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12619190977427674		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.12619190977427674 | validation: 0.1539957508903035]
	TIME [epoch: 11.4 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12348853818949784		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.12348853818949784 | validation: 0.13964906053125845]
	TIME [epoch: 11.4 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11793801353068191		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.11793801353068191 | validation: 0.14667899763421235]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11978388576225285		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.11978388576225285 | validation: 0.14551411408702308]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12167686781113603		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.12167686781113603 | validation: 0.14470486129313048]
	TIME [epoch: 11.4 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12008339888182076		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.12008339888182076 | validation: 0.14815033986298554]
	TIME [epoch: 11.4 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12284124262997978		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.12284124262997978 | validation: 0.14255737601040339]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1222674472446067		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.1222674472446067 | validation: 0.15415276374674397]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12215317126925734		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.12215317126925734 | validation: 0.1459622948635213]
	TIME [epoch: 11.4 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12477603410501203		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.12477603410501203 | validation: 0.14603086797174242]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205712622451067		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.1205712622451067 | validation: 0.1583688774974989]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12365686379401952		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.12365686379401952 | validation: 0.14895731614365865]
	TIME [epoch: 11.4 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11819849685829209		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.11819849685829209 | validation: 0.14818794589745798]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12374381815683563		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.12374381815683563 | validation: 0.15095137998287692]
	TIME [epoch: 11.4 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12053016295735183		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.12053016295735183 | validation: 0.15004577758379875]
	TIME [epoch: 11.4 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1221673860874625		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.1221673860874625 | validation: 0.14923055054518317]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12322082630339817		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.12322082630339817 | validation: 0.15235129189513993]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11965025066944113		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.11965025066944113 | validation: 0.1459188876681624]
	TIME [epoch: 11.4 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12277334775134009		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.12277334775134009 | validation: 0.15082039937674147]
	TIME [epoch: 11.4 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12401667096987856		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.12401667096987856 | validation: 0.14814032919379727]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11935404293705563		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.11935404293705563 | validation: 0.14908705903780228]
	TIME [epoch: 11.4 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11842389298371757		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.11842389298371757 | validation: 0.16024270288546866]
	TIME [epoch: 11.4 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12043221795769403		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.12043221795769403 | validation: 0.1504457191898279]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12307986206554378		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.12307986206554378 | validation: 0.16031687365384698]
	TIME [epoch: 11.4 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12082533686625696		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.12082533686625696 | validation: 0.15062684325377712]
	TIME [epoch: 11.4 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12032518705783248		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.12032518705783248 | validation: 0.14965701993126138]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12288460925597351		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.12288460925597351 | validation: 0.15765080080009633]
	TIME [epoch: 11.4 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12183940939308388		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.12183940939308388 | validation: 0.1557396456801196]
	TIME [epoch: 11.4 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12372093982596925		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.12372093982596925 | validation: 0.15019034104684065]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1198013996563178		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.1198013996563178 | validation: 0.14217029213823204]
	TIME [epoch: 11.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11865900703136514		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.11865900703136514 | validation: 0.15233808940271648]
	TIME [epoch: 11.4 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12046974028403412		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.12046974028403412 | validation: 0.14814076766153447]
	TIME [epoch: 11.4 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12337290180865135		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.12337290180865135 | validation: 0.14992881723943302]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1198045520713367		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.1198045520713367 | validation: 0.1499282830135221]
	TIME [epoch: 11.4 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1228808208931915		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.1228808208931915 | validation: 0.14265631340168258]
	TIME [epoch: 11.4 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12045542913767344		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.12045542913767344 | validation: 0.15201406428995332]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12317243811262626		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.12317243811262626 | validation: 0.14917395766036717]
	TIME [epoch: 11.4 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11743340018554813		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.11743340018554813 | validation: 0.14887357923289174]
	TIME [epoch: 11.4 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1216594012993009		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.1216594012993009 | validation: 0.14347322786579722]
	TIME [epoch: 11.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12310159692034198		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.12310159692034198 | validation: 0.15275953496435749]
	TIME [epoch: 11.4 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11952543796355455		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.11952543796355455 | validation: 0.14766736233663122]
	TIME [epoch: 11.4 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12226911133026555		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.12226911133026555 | validation: 0.15423640551041853]
	TIME [epoch: 11.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12591045526326933		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.12591045526326933 | validation: 0.15664973848646244]
	TIME [epoch: 11.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12576497504501893		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.12576497504501893 | validation: 0.15655639580096747]
	TIME [epoch: 11.4 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12155087514438731		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.12155087514438731 | validation: 0.14424994752478218]
	TIME [epoch: 11.4 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12236232342147996		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.12236232342147996 | validation: 0.1484253914105234]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11902933394039503		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.11902933394039503 | validation: 0.15348972869951677]
	TIME [epoch: 11.4 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12096185216323752		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.12096185216323752 | validation: 0.15594450064865803]
	TIME [epoch: 11.4 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12207801916132545		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.12207801916132545 | validation: 0.15608157783567747]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12496296465366959		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.12496296465366959 | validation: 0.15320038489371127]
	TIME [epoch: 11.4 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1211250249500142		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.1211250249500142 | validation: 0.1554332052340508]
	TIME [epoch: 11.4 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12392729951306447		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.12392729951306447 | validation: 0.14799190859870265]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12156559581789014		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.12156559581789014 | validation: 0.1564117314800704]
	TIME [epoch: 11.4 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254653228583789		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.1254653228583789 | validation: 0.15124745219460628]
	TIME [epoch: 11.4 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12087046035193712		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.12087046035193712 | validation: 0.15587491910134918]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12081275603511227		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.12081275603511227 | validation: 0.1552480751647318]
	TIME [epoch: 11.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12318677503602066		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.12318677503602066 | validation: 0.14968616776352106]
	TIME [epoch: 11.4 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11905450508661451		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.11905450508661451 | validation: 0.15709698781747816]
	TIME [epoch: 11.4 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1192073653664941		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.1192073653664941 | validation: 0.1453427071369588]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12296123978521589		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.12296123978521589 | validation: 0.15119826927853594]
	TIME [epoch: 11.4 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11974125632328823		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.11974125632328823 | validation: 0.15235780372686356]
	TIME [epoch: 11.4 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254320437000473		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.1254320437000473 | validation: 0.14528311315334494]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12340567602086783		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.12340567602086783 | validation: 0.15294493202915665]
	TIME [epoch: 11.4 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12213863191362681		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.12213863191362681 | validation: 0.1537970751471334]
	TIME [epoch: 11.4 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12251125183822295		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.12251125183822295 | validation: 0.15125485817652615]
	TIME [epoch: 11.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205543076342192		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.1205543076342192 | validation: 0.1495885215235811]
	TIME [epoch: 11.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12376310606734789		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.12376310606734789 | validation: 0.14322030679755035]
	TIME [epoch: 11.4 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12420747255815162		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.12420747255815162 | validation: 0.14470652753946503]
	TIME [epoch: 11.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12305161610655482		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.12305161610655482 | validation: 0.1521450416255783]
	TIME [epoch: 11.5 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11963717161562579		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.11963717161562579 | validation: 0.15712815558428905]
	TIME [epoch: 11.4 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12650733890958446		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.12650733890958446 | validation: 0.15914757110091018]
	TIME [epoch: 11.4 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1194911403151589		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.1194911403151589 | validation: 0.144943454480686]
	TIME [epoch: 11.5 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11940493263841777		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.11940493263841777 | validation: 0.14203666254669284]
	TIME [epoch: 11.4 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11850900366128773		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.11850900366128773 | validation: 0.1409274005700589]
	TIME [epoch: 11.4 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12064915166035867		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.12064915166035867 | validation: 0.14121046917823993]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12096433709521233		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.12096433709521233 | validation: 0.15402055883300686]
	TIME [epoch: 11.4 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12015011037039931		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.12015011037039931 | validation: 0.1503356518061516]
	TIME [epoch: 11.4 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12207271470622681		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.12207271470622681 | validation: 0.1613259417973034]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12130664071028652		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.12130664071028652 | validation: 0.14448162659487235]
	TIME [epoch: 11.4 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12361991700258051		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.12361991700258051 | validation: 0.15443085375036172]
	TIME [epoch: 11.4 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12141415554068069		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.12141415554068069 | validation: 0.14540911050168415]
	TIME [epoch: 11.4 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12017735130436422		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.12017735130436422 | validation: 0.14442820397803002]
	TIME [epoch: 11.5 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12383563295228		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.12383563295228 | validation: 0.1458785734218063]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11872126893196414		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.11872126893196414 | validation: 0.14962862303116287]
	TIME [epoch: 11.4 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12198064613486465		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.12198064613486465 | validation: 0.14450132219838635]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12325232128371219		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.12325232128371219 | validation: 0.15645027011240675]
	TIME [epoch: 11.4 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12067739647549702		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.12067739647549702 | validation: 0.14811406225371884]
	TIME [epoch: 11.4 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12116960350640585		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.12116960350640585 | validation: 0.14800295759409116]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12320897832495747		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.12320897832495747 | validation: 0.14599255105369924]
	TIME [epoch: 11.4 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12425221535661835		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.12425221535661835 | validation: 0.14306009362915964]
	TIME [epoch: 11.4 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12071996924331976		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.12071996924331976 | validation: 0.146995783193893]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12374226878707176		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.12374226878707176 | validation: 0.15133401418859346]
	TIME [epoch: 11.4 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1183196894591391		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.1183196894591391 | validation: 0.14596435493653115]
	TIME [epoch: 11.4 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12428257723627834		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.12428257723627834 | validation: 0.14857155392087673]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12160997352140422		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.12160997352140422 | validation: 0.1457931818893475]
	TIME [epoch: 11.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12223628454221132		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.12223628454221132 | validation: 0.15646005288905]
	TIME [epoch: 11.4 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12436873269756846		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.12436873269756846 | validation: 0.15072573080726998]
	TIME [epoch: 11.4 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12132774842275292		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.12132774842275292 | validation: 0.14697431721021534]
	TIME [epoch: 11.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293133772637777		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.1293133772637777 | validation: 0.15253727279058749]
	TIME [epoch: 11.4 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12125849760757651		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.12125849760757651 | validation: 0.14800160921972494]
	TIME [epoch: 11.4 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11933515352331985		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.11933515352331985 | validation: 0.14960953788842177]
	TIME [epoch: 11.5 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11718593660535562		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.11718593660535562 | validation: 0.14837303755177922]
	TIME [epoch: 11.4 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12115997673412547		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.12115997673412547 | validation: 0.14960478750804238]
	TIME [epoch: 11.4 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1232030710351274		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.1232030710351274 | validation: 0.1431521880227017]
	TIME [epoch: 11.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1219310855258979		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.1219310855258979 | validation: 0.15810927208425496]
	TIME [epoch: 11.4 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1237640286182751		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.1237640286182751 | validation: 0.15782158184313405]
	TIME [epoch: 11.4 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1218411387310182		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.1218411387310182 | validation: 0.1439767063684359]
	TIME [epoch: 11.5 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1192628087452566		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.1192628087452566 | validation: 0.1484671996941501]
	TIME [epoch: 11.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12180997989994974		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.12180997989994974 | validation: 0.14995437788149743]
	TIME [epoch: 11.4 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12212142333960879		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.12212142333960879 | validation: 0.15218606012242955]
	TIME [epoch: 11.4 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12311121498258909		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.12311121498258909 | validation: 0.14846518959542454]
	TIME [epoch: 11.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12043071098237274		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.12043071098237274 | validation: 0.15034868180903282]
	TIME [epoch: 11.4 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12079679845821856		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.12079679845821856 | validation: 0.1506553340102068]
	TIME [epoch: 11.4 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12101485174197887		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.12101485174197887 | validation: 0.1414258807882091]
	TIME [epoch: 11.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12194581891365605		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.12194581891365605 | validation: 0.1494416333337766]
	TIME [epoch: 11.4 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1227565672132794		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.1227565672132794 | validation: 0.14763675861558256]
	TIME [epoch: 11.4 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1233560081657543		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.1233560081657543 | validation: 0.15224638217677858]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12413257237706136		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.12413257237706136 | validation: 0.1441971315914524]
	TIME [epoch: 11.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12142675310361213		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.12142675310361213 | validation: 0.14773392672269242]
	TIME [epoch: 11.4 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12616020482446139		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.12616020482446139 | validation: 0.14371734303015526]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11793312473646435		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.11793312473646435 | validation: 0.15620961701684807]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11805528255137322		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.11805528255137322 | validation: 0.1395867273079516]
	TIME [epoch: 11.4 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1225178798423977		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.1225178798423977 | validation: 0.1502373895337296]
	TIME [epoch: 11.4 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12043452264150026		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.12043452264150026 | validation: 0.1599130547587625]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11925817340599318		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.11925817340599318 | validation: 0.15703470167605774]
	TIME [epoch: 11.4 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12014505937558531		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.12014505937558531 | validation: 0.15229101258556832]
	TIME [epoch: 11.4 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12433344393885806		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.12433344393885806 | validation: 0.14435345794761995]
	TIME [epoch: 11.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12271116091754204		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.12271116091754204 | validation: 0.14834034057238188]
	TIME [epoch: 11.4 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12225848427045855		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.12225848427045855 | validation: 0.14898912574964832]
	TIME [epoch: 11.4 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12067291416619705		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.12067291416619705 | validation: 0.15196044477873227]
	TIME [epoch: 11.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12332431827238644		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.12332431827238644 | validation: 0.15170734211494305]
	TIME [epoch: 11.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12017996421044852		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.12017996421044852 | validation: 0.1479854144016902]
	TIME [epoch: 11.4 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1200392794603508		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.1200392794603508 | validation: 0.1456221272433355]
	TIME [epoch: 11.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12101647824708339		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.12101647824708339 | validation: 0.15770815791818674]
	TIME [epoch: 11.5 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1233749740114667		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.1233749740114667 | validation: 0.14855184861903267]
	TIME [epoch: 11.4 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12365331602607374		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.12365331602607374 | validation: 0.15443598257738245]
	TIME [epoch: 11.4 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1232827464315745		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.1232827464315745 | validation: 0.15051074501305858]
	TIME [epoch: 11.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12001504637323762		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.12001504637323762 | validation: 0.1535971162745401]
	TIME [epoch: 11.4 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468595373959875		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.12468595373959875 | validation: 0.15729979127809327]
	TIME [epoch: 11.4 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12346622397186165		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.12346622397186165 | validation: 0.15314640283385544]
	TIME [epoch: 11.5 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11857406220419597		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.11857406220419597 | validation: 0.15196055277690437]
	TIME [epoch: 11.4 sec]
Finished training in 23166.951 seconds.
