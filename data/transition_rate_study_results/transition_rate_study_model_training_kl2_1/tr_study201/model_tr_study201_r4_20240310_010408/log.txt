Args:
Namespace(name='model_tr_study201', outdir='out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4', training_data='data/transition_rate_studies/tr_study201/tr_study201_training/r4', validation_data='data/transition_rate_studies/tr_study201/tr_study201_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 444228199

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.204902688619722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.204902688619722 | validation: 14.121626705596352]
	TIME [epoch: 93.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.44041220113045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.44041220113045 | validation: 10.812473157527466]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.90329963095525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.90329963095525 | validation: 9.268403653898773]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.930184091496264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.930184091496264 | validation: 9.92225253604156]
	TIME [epoch: 5.73 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.135387975771074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.135387975771074 | validation: 8.535248749067934]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.529121721469147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.529121721469147 | validation: 6.225171680407739]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.300770038897344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.300770038897344 | validation: 10.213743651100073]
	TIME [epoch: 5.74 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.209420366169578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.209420366169578 | validation: 5.501207342458297]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.160460453372325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.160460453372325 | validation: 5.886099362000766]
	TIME [epoch: 5.74 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.873890339359482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.873890339359482 | validation: 5.832807201859132]
	TIME [epoch: 5.73 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.693062579379484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.693062579379484 | validation: 5.708077485254951]
	TIME [epoch: 5.73 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.766596601058238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.766596601058238 | validation: 4.6093254113042414]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.307749835703872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.307749835703872 | validation: 5.059256232075303]
	TIME [epoch: 5.74 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.395308524547342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.395308524547342 | validation: 4.4051798618578175]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.132882589103539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.132882589103539 | validation: 5.482036851673786]
	TIME [epoch: 5.73 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.238242713316236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.238242713316236 | validation: 4.300587049487864]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.195627714195085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.195627714195085 | validation: 4.372532821553519]
	TIME [epoch: 5.74 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.292805281293813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.292805281293813 | validation: 4.939420307212697]
	TIME [epoch: 5.75 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0540291059520355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0540291059520355 | validation: 4.510007266983181]
	TIME [epoch: 5.76 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9591082309367183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9591082309367183 | validation: 4.914160169091312]
	TIME [epoch: 5.74 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.02357453303195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.02357453303195 | validation: 4.2304597870452]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9681605591965576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9681605591965576 | validation: 4.280822054805466]
	TIME [epoch: 5.74 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.063442057909747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.063442057909747 | validation: 4.397818112738406]
	TIME [epoch: 5.74 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8492911196310446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8492911196310446 | validation: 4.551272816592482]
	TIME [epoch: 5.73 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9321736236662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9321736236662 | validation: 4.100097048334891]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.825665431953385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.825665431953385 | validation: 4.43530877395025]
	TIME [epoch: 5.75 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.185488832047977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.185488832047977 | validation: 4.067692464621675]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.992296127646088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.992296127646088 | validation: 3.9643705235918083]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7593658879639316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7593658879639316 | validation: 4.094599101836551]
	TIME [epoch: 5.73 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5821581815691905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5821581815691905 | validation: 5.289245055304224]
	TIME [epoch: 5.74 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.002555546847092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.002555546847092 | validation: 4.5062723478494044]
	TIME [epoch: 5.73 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.793063190689887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.793063190689887 | validation: 4.208261015281501]
	TIME [epoch: 5.78 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.698737261545969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.698737261545969 | validation: 4.146754525893216]
	TIME [epoch: 5.74 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6658646570340823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6658646570340823 | validation: 4.127047306188328]
	TIME [epoch: 5.73 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6558879542366696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6558879542366696 | validation: 4.362321326827819]
	TIME [epoch: 5.73 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.689097637441869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.689097637441869 | validation: 4.20010016773103]
	TIME [epoch: 5.73 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6134262746168733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6134262746168733 | validation: 4.23357422542119]
	TIME [epoch: 5.73 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.68460267011298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.68460267011298 | validation: 4.3534490323449715]
	TIME [epoch: 5.75 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7619886292568987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7619886292568987 | validation: 4.020987915755975]
	TIME [epoch: 5.76 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7717610117668383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7717610117668383 | validation: 4.116186764833172]
	TIME [epoch: 5.73 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4243105138205854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4243105138205854 | validation: 4.2863776689805855]
	TIME [epoch: 5.74 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6659502410702984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6659502410702984 | validation: 4.409983209920418]
	TIME [epoch: 5.74 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5893039054034506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5893039054034506 | validation: 4.02901408954149]
	TIME [epoch: 5.73 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4858027515956254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4858027515956254 | validation: 4.5889902608819275]
	TIME [epoch: 5.74 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.540723783029417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.540723783029417 | validation: 4.26003189738396]
	TIME [epoch: 5.76 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6266838121869216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6266838121869216 | validation: 4.434918609831727]
	TIME [epoch: 5.76 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5524561114626207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5524561114626207 | validation: 4.534290330520583]
	TIME [epoch: 5.73 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.510740955589395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.510740955589395 | validation: 4.308889490188398]
	TIME [epoch: 5.73 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.577023580754412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.577023580754412 | validation: 4.062189920169918]
	TIME [epoch: 5.73 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.488565624386072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.488565624386072 | validation: 4.080251349390113]
	TIME [epoch: 5.73 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.706758456984438		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.706758456984438 | validation: 3.9546243029768564]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.579672395537647		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.579672395537647 | validation: 3.674968069480684]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4315096912259535		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.4315096912259535 | validation: 4.57418479162168]
	TIME [epoch: 5.76 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6231212896670497		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.6231212896670497 | validation: 5.174995621525459]
	TIME [epoch: 5.74 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.839933848449156		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.839933848449156 | validation: 4.507919908393331]
	TIME [epoch: 5.72 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5369772955954457		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.5369772955954457 | validation: 4.1128543986646]
	TIME [epoch: 5.73 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4517600885860724		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.4517600885860724 | validation: 3.9571049720084295]
	TIME [epoch: 5.73 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4857084337970403		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.4857084337970403 | validation: 3.750918068092359]
	TIME [epoch: 5.76 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9461911822757982		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.9461911822757982 | validation: 3.7320574774423365]
	TIME [epoch: 5.75 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.594439612901228		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.594439612901228 | validation: 3.992291843474845]
	TIME [epoch: 5.73 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4352509355917493		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.4352509355917493 | validation: 3.814820609736539]
	TIME [epoch: 5.73 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3675055583718523		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.3675055583718523 | validation: 4.113464889548599]
	TIME [epoch: 5.73 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.663093780808308		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.663093780808308 | validation: 4.004019576060116]
	TIME [epoch: 5.73 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.385791093379228		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.385791093379228 | validation: 3.8269700745905575]
	TIME [epoch: 5.73 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8216529929267944		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.8216529929267944 | validation: 3.4788415527973466]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.876957887898867		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.876957887898867 | validation: 3.9310913576337816]
	TIME [epoch: 5.75 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.71054698426512		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.71054698426512 | validation: 3.7866711960088244]
	TIME [epoch: 5.73 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.311281561418365		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.311281561418365 | validation: 4.007306584086177]
	TIME [epoch: 5.73 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.143394348027674		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.143394348027674 | validation: 3.914957765396846]
	TIME [epoch: 5.73 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5095281928896704		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.5095281928896704 | validation: 3.880001667742464]
	TIME [epoch: 5.74 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4414778054562607		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.4414778054562607 | validation: 3.6114772636635792]
	TIME [epoch: 5.73 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.361860698386651		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.361860698386651 | validation: 4.197843702275743]
	TIME [epoch: 5.78 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4684363112370926		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.4684363112370926 | validation: 4.270633403837877]
	TIME [epoch: 5.73 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.515146582592113		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.515146582592113 | validation: 4.280808661312476]
	TIME [epoch: 5.74 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4168272210231514		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.4168272210231514 | validation: 3.5132892563303155]
	TIME [epoch: 5.73 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0872561619482357		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.0872561619482357 | validation: 4.4385956422821735]
	TIME [epoch: 5.74 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.176198528809026		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.176198528809026 | validation: 4.591730686034869]
	TIME [epoch: 5.73 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.649022191315187		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.649022191315187 | validation: 4.326542622078919]
	TIME [epoch: 5.74 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.315280256289282		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.315280256289282 | validation: 4.239917013093204]
	TIME [epoch: 5.78 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.240760048281265		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.240760048281265 | validation: 5.413943329041411]
	TIME [epoch: 5.74 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.565975574392295		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.565975574392295 | validation: 3.8736025009270025]
	TIME [epoch: 5.74 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1345233589071335		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.1345233589071335 | validation: 3.654943090405766]
	TIME [epoch: 5.73 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.186535324882759		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.186535324882759 | validation: 4.048414607896639]
	TIME [epoch: 5.73 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0934919444392057		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.0934919444392057 | validation: 3.532468805760395]
	TIME [epoch: 5.73 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4357709724245673		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.4357709724245673 | validation: 4.0661861108223665]
	TIME [epoch: 5.74 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.30095461634288		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.30095461634288 | validation: 3.760465285572006]
	TIME [epoch: 5.78 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.066896197197708		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.066896197197708 | validation: 4.35626392406965]
	TIME [epoch: 5.74 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.228982005262781		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.228982005262781 | validation: 3.7397431134507433]
	TIME [epoch: 5.73 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0688942433429895		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.0688942433429895 | validation: 3.4763979703679544]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.001160061373249		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.001160061373249 | validation: 4.229201637471654]
	TIME [epoch: 5.73 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1737419200940633		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.1737419200940633 | validation: 3.6518189644986694]
	TIME [epoch: 5.72 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.032801364193124		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.032801364193124 | validation: 3.950934936748804]
	TIME [epoch: 5.76 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.069876340059297		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.069876340059297 | validation: 3.9026752249044496]
	TIME [epoch: 5.75 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.083683892741379		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.083683892741379 | validation: 3.4079706125279645]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1469697986862304		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.1469697986862304 | validation: 3.323466956865465]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.076771542465143		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.076771542465143 | validation: 3.5999597224547064]
	TIME [epoch: 5.73 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.897637828192715		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.897637828192715 | validation: 4.148155788702503]
	TIME [epoch: 5.73 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1248284063802614		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.1248284063802614 | validation: 3.6626630300678746]
	TIME [epoch: 5.73 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.009840341271558		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.009840341271558 | validation: 3.686737787969105]
	TIME [epoch: 5.77 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9901533742316135		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.9901533742316135 | validation: 3.6084105126128008]
	TIME [epoch: 5.73 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0738846796723216		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.0738846796723216 | validation: 3.4674818295181282]
	TIME [epoch: 5.73 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0106953295306007		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.0106953295306007 | validation: 3.523511591149478]
	TIME [epoch: 5.73 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2594786065352324		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.2594786065352324 | validation: 4.211829716871415]
	TIME [epoch: 5.73 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0243861395521887		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.0243861395521887 | validation: 3.4274897499903982]
	TIME [epoch: 5.73 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9283238690066264		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.9283238690066264 | validation: 4.3723877425577005]
	TIME [epoch: 5.73 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.115108645956036		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.115108645956036 | validation: 3.2640431046909804]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.886943876682405		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.886943876682405 | validation: 3.7855822125534884]
	TIME [epoch: 5.73 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1813908908331503		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.1813908908331503 | validation: 3.4333092712394757]
	TIME [epoch: 5.73 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.974648771832525		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.974648771832525 | validation: 4.012885707800709]
	TIME [epoch: 5.73 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0014057227997197		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.0014057227997197 | validation: 3.762292781110899]
	TIME [epoch: 5.73 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.887943348851078		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.887943348851078 | validation: 3.9676615372694517]
	TIME [epoch: 5.73 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.021324623899701		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.021324623899701 | validation: 3.5277212687236887]
	TIME [epoch: 5.74 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8450078010676876		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.8450078010676876 | validation: 5.352050502830367]
	TIME [epoch: 5.76 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.083372484738631		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 4.083372484738631 | validation: 4.848557193935143]
	TIME [epoch: 5.73 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1761224289416976		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.1761224289416976 | validation: 4.318503949376371]
	TIME [epoch: 5.73 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0526706483590575		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.0526706483590575 | validation: 5.237861947790373]
	TIME [epoch: 5.73 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.353932022221596		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.353932022221596 | validation: 4.575656609270579]
	TIME [epoch: 5.73 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2781477892100055		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.2781477892100055 | validation: 4.67550090019908]
	TIME [epoch: 5.73 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2609914307295913		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.2609914307295913 | validation: 3.7031233904702408]
	TIME [epoch: 5.77 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.005945304596776		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.005945304596776 | validation: 3.5883038147636257]
	TIME [epoch: 5.73 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0083349744284535		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.0083349744284535 | validation: 3.2279273108220683]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.005495393647842		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.005495393647842 | validation: 3.1873008261418794]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.823561758830628		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.823561758830628 | validation: 3.524003116700931]
	TIME [epoch: 5.72 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.932833435339434		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.932833435339434 | validation: 3.3013934005381724]
	TIME [epoch: 5.73 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9466256489283897		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.9466256489283897 | validation: 3.459176947802729]
	TIME [epoch: 5.75 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.850984995057681		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.850984995057681 | validation: 4.263160910429541]
	TIME [epoch: 5.75 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1079233289150268		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.1079233289150268 | validation: 3.259302486088194]
	TIME [epoch: 5.73 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.021459345392005		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.021459345392005 | validation: 3.1709024999658495]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211215017306158		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.211215017306158 | validation: 3.3574155023954275]
	TIME [epoch: 5.73 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3910434173724644		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.3910434173724644 | validation: 4.089166071006786]
	TIME [epoch: 5.72 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.034183351437152		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.034183351437152 | validation: 3.1902494398668306]
	TIME [epoch: 5.73 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.903828332902087		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.903828332902087 | validation: 3.9199496392218296]
	TIME [epoch: 5.77 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.873112252350617		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 3.873112252350617 | validation: 3.7289204811561127]
	TIME [epoch: 5.73 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1775189201312286		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.1775189201312286 | validation: 3.237465295156395]
	TIME [epoch: 5.73 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.977137045749531		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.977137045749531 | validation: 3.9617593491630827]
	TIME [epoch: 5.73 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9962004053921505		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.9962004053921505 | validation: 4.17371923845531]
	TIME [epoch: 5.73 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0944650603797363		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.0944650603797363 | validation: 4.124677409576273]
	TIME [epoch: 5.73 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1430959176165603		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.1430959176165603 | validation: 3.6414873071431657]
	TIME [epoch: 5.75 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9114513257192915		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.9114513257192915 | validation: 3.3418136095161413]
	TIME [epoch: 5.74 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.842865981708073		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.842865981708073 | validation: 3.4052088451957583]
	TIME [epoch: 5.74 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7740525776094787		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.7740525776094787 | validation: 3.8723652641966453]
	TIME [epoch: 5.73 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.897747449201874		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.897747449201874 | validation: 4.549790409618054]
	TIME [epoch: 5.73 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.420343134840579		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.420343134840579 | validation: 4.146074845349265]
	TIME [epoch: 5.73 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0097624770357077		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.0097624770357077 | validation: 5.086950772024214]
	TIME [epoch: 5.73 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6050147685378535		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.6050147685378535 | validation: 3.4018650621248554]
	TIME [epoch: 5.78 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.302068161839082		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.302068161839082 | validation: 3.8170749017466097]
	TIME [epoch: 5.74 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.190169471967905		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.190169471967905 | validation: 3.8501739019455545]
	TIME [epoch: 5.73 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1878808284200137		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.1878808284200137 | validation: 3.263517475720804]
	TIME [epoch: 5.73 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7971974070942225		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.7971974070942225 | validation: 3.2197707785626197]
	TIME [epoch: 5.72 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1199026285902343		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.1199026285902343 | validation: 3.2700827375228947]
	TIME [epoch: 5.73 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1208886140519914		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.1208886140519914 | validation: 3.243894713778123]
	TIME [epoch: 5.77 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8180289078630953		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.8180289078630953 | validation: 3.2087823079675366]
	TIME [epoch: 5.75 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3193604719034786		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.3193604719034786 | validation: 3.6400887747907666]
	TIME [epoch: 5.73 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0408461003441065		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.0408461003441065 | validation: 3.592576730036323]
	TIME [epoch: 5.73 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7539673481672877		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.7539673481672877 | validation: 3.8182092731046215]
	TIME [epoch: 5.73 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.924085340843307		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.924085340843307 | validation: 4.798666005545784]
	TIME [epoch: 5.73 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2378126936396976		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.2378126936396976 | validation: 3.3065169233147063]
	TIME [epoch: 5.73 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7255693047819887		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.7255693047819887 | validation: 3.480906710261525]
	TIME [epoch: 5.78 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8299478672692433		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.8299478672692433 | validation: 3.653058606784815]
	TIME [epoch: 5.73 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8009279556646276		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.8009279556646276 | validation: 3.689874494999906]
	TIME [epoch: 5.73 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8470092716316824		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.8470092716316824 | validation: 5.090005470708681]
	TIME [epoch: 5.72 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2367861711548285		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.2367861711548285 | validation: 3.84974855375742]
	TIME [epoch: 5.73 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.842122883686334		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.842122883686334 | validation: 5.240913368544063]
	TIME [epoch: 5.73 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4011297174526938		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.4011297174526938 | validation: 3.341863122158096]
	TIME [epoch: 5.76 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.790868320485515		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.790868320485515 | validation: 4.624008458779778]
	TIME [epoch: 5.75 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.536919946089856		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.536919946089856 | validation: 4.241794086337864]
	TIME [epoch: 5.74 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.368144930030539		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.368144930030539 | validation: 4.054993412389239]
	TIME [epoch: 5.74 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.124141739325254		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.124141739325254 | validation: 4.501716809682866]
	TIME [epoch: 5.73 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2914627086136505		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.2914627086136505 | validation: 4.132868816931668]
	TIME [epoch: 5.72 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.251256084270229		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 3.251256084270229 | validation: 3.91473552788093]
	TIME [epoch: 5.73 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1124013767852867		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.1124013767852867 | validation: 4.504355095262467]
	TIME [epoch: 5.78 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2639459237830057		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.2639459237830057 | validation: 3.348451399481811]
	TIME [epoch: 5.74 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.711804904114511		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.711804904114511 | validation: 3.448240387159654]
	TIME [epoch: 5.74 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7129656570685543		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.7129656570685543 | validation: 3.4069009542359026]
	TIME [epoch: 5.73 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.897205690762089		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.897205690762089 | validation: 3.225837429468548]
	TIME [epoch: 5.73 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.929354127390618		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.929354127390618 | validation: 3.2250016612813375]
	TIME [epoch: 5.73 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.776222484815928		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.776222484815928 | validation: 3.3060301558109155]
	TIME [epoch: 5.77 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7829428037663417		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.7829428037663417 | validation: 3.20561729741944]
	TIME [epoch: 5.75 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9770860886193056		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.9770860886193056 | validation: 3.490851301566514]
	TIME [epoch: 5.73 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.065276018808998		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.065276018808998 | validation: 3.3897500130308518]
	TIME [epoch: 5.74 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.014935225941117		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.014935225941117 | validation: 3.6671078337164555]
	TIME [epoch: 5.74 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7800499363269324		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.7800499363269324 | validation: 3.358703971294342]
	TIME [epoch: 5.73 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5783152232012627		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.5783152232012627 | validation: 3.212090865602263]
	TIME [epoch: 5.73 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8892437822802672		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.8892437822802672 | validation: 3.371032195621117]
	TIME [epoch: 5.78 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8899311712652027		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.8899311712652027 | validation: 3.239095187580085]
	TIME [epoch: 5.73 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6545888354100593		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.6545888354100593 | validation: 3.3865809454762883]
	TIME [epoch: 5.74 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.920316121969785		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.920316121969785 | validation: 3.1630277394073762]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.039188819549227		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.039188819549227 | validation: 3.327966363143637]
	TIME [epoch: 5.73 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7731665373358783		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.7731665373358783 | validation: 3.157677651575434]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0413592838226498		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.0413592838226498 | validation: 3.522222329523737]
	TIME [epoch: 5.78 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.802525605129425		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.802525605129425 | validation: 3.48679210147424]
	TIME [epoch: 5.73 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7238533758814825		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.7238533758814825 | validation: 3.3987525752504575]
	TIME [epoch: 5.73 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.738343986963829		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.738343986963829 | validation: 3.2985434756525684]
	TIME [epoch: 5.73 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6466830589411954		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.6466830589411954 | validation: 3.521424727354569]
	TIME [epoch: 5.73 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.686199068194467		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.686199068194467 | validation: 3.3179527532331905]
	TIME [epoch: 5.74 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.583070401022179		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.583070401022179 | validation: 3.7876363483223052]
	TIME [epoch: 5.75 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.875889128316482		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.875889128316482 | validation: 4.310215608796954]
	TIME [epoch: 5.76 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0912649911194485		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 3.0912649911194485 | validation: 3.1662496644396514]
	TIME [epoch: 5.73 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5662598223811437		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.5662598223811437 | validation: 3.1285913373046594]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5811969310717195		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.5811969310717195 | validation: 3.2532036838125062]
	TIME [epoch: 5.73 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.631668458302231		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.631668458302231 | validation: 3.4651363318766157]
	TIME [epoch: 5.73 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5280234913953485		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.5280234913953485 | validation: 3.7421275201614117]
	TIME [epoch: 5.73 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7204938951771087		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.7204938951771087 | validation: 3.9897257795178502]
	TIME [epoch: 5.77 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6861051806062024		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.6861051806062024 | validation: 3.06478893975066]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.646385698667298		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.646385698667298 | validation: 3.2039496140711305]
	TIME [epoch: 5.74 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.549554721796519		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.549554721796519 | validation: 3.244898768317777]
	TIME [epoch: 5.74 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5262156433179945		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.5262156433179945 | validation: 3.9877651809612678]
	TIME [epoch: 5.74 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7273847589696754		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.7273847589696754 | validation: 3.670554360510715]
	TIME [epoch: 5.74 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.574869292343263		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.574869292343263 | validation: 3.643475368887379]
	TIME [epoch: 5.77 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7885791000342275		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.7885791000342275 | validation: 4.208852372552339]
	TIME [epoch: 5.75 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7787889506062724		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.7787889506062724 | validation: 3.298882085563713]
	TIME [epoch: 5.75 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.551503938002269		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.551503938002269 | validation: 3.971740359304086]
	TIME [epoch: 5.72 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.612507478784378		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.612507478784378 | validation: 3.228857898093813]
	TIME [epoch: 5.72 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.867502669634957		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.867502669634957 | validation: 3.2430014340066142]
	TIME [epoch: 5.73 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.919507060316412		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.919507060316412 | validation: 3.444367247909278]
	TIME [epoch: 5.72 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.652647216008262		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.652647216008262 | validation: 3.2917920890798347]
	TIME [epoch: 5.78 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801904687645773		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.801904687645773 | validation: 5.12571272600869]
	TIME [epoch: 5.73 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1742741001912522		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 3.1742741001912522 | validation: 4.4802084007223915]
	TIME [epoch: 5.74 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1016651313244368		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 3.1016651313244368 | validation: 3.8881191599300333]
	TIME [epoch: 5.74 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8841694447824873		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.8841694447824873 | validation: 3.5338183980088878]
	TIME [epoch: 5.73 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5278328243203396		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.5278328243203396 | validation: 3.381489880497993]
	TIME [epoch: 5.74 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.638554705042893		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.638554705042893 | validation: 3.258472275880567]
	TIME [epoch: 5.76 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5001318268188544		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.5001318268188544 | validation: 4.045247914878851]
	TIME [epoch: 5.75 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6727482434543184		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.6727482434543184 | validation: 3.4043290483571957]
	TIME [epoch: 5.73 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.866974831451689		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.866974831451689 | validation: 3.558949348349031]
	TIME [epoch: 5.74 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.805751653053101		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 2.805751653053101 | validation: 3.4306276224252876]
	TIME [epoch: 5.74 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.616971489234761		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.616971489234761 | validation: 3.5671831345576117]
	TIME [epoch: 5.74 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.853988207158352		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.853988207158352 | validation: 3.3452558079434573]
	TIME [epoch: 5.73 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.834414724972843		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.834414724972843 | validation: 3.369531377525459]
	TIME [epoch: 5.79 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6496588256124713		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.6496588256124713 | validation: 3.272592994293241]
	TIME [epoch: 5.75 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.496920969172456		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.496920969172456 | validation: 3.201862216239506]
	TIME [epoch: 5.75 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.519512970009606		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.519512970009606 | validation: 3.069200930073389]
	TIME [epoch: 5.72 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.561914015750237		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.561914015750237 | validation: 3.1953764857634166]
	TIME [epoch: 5.74 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4954792996515778		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 2.4954792996515778 | validation: 3.100647636566443]
	TIME [epoch: 5.74 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5185096704752286		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.5185096704752286 | validation: 3.0939989227355706]
	TIME [epoch: 5.76 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.461181900231394		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 2.461181900231394 | validation: 3.7820141415732325]
	TIME [epoch: 5.76 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.583005126338183		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.583005126338183 | validation: 3.079787230225106]
	TIME [epoch: 5.74 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.507166840047347		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 2.507166840047347 | validation: 3.231691236106531]
	TIME [epoch: 5.74 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4503406095985207		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.4503406095985207 | validation: 3.2055412636829907]
	TIME [epoch: 5.74 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9641546973844077		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.9641546973844077 | validation: 3.2001634603456313]
	TIME [epoch: 5.74 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.847331651857107		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.847331651857107 | validation: 3.384168792125]
	TIME [epoch: 5.75 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.625007943766027		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.625007943766027 | validation: 3.094712320287224]
	TIME [epoch: 5.79 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6426894421053935		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 2.6426894421053935 | validation: 3.1423492642692246]
	TIME [epoch: 5.75 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.625648603202019		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.625648603202019 | validation: 3.0643737965546847]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.507906330763515		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.507906330763515 | validation: 3.72874303117286]
	TIME [epoch: 5.74 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.758495561844148		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.758495561844148 | validation: 4.959539055763539]
	TIME [epoch: 5.75 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0955828063065054		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 3.0955828063065054 | validation: 3.8981828800968295]
	TIME [epoch: 5.72 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.738008638678431		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.738008638678431 | validation: 3.532478432755405]
	TIME [epoch: 5.78 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.633066338196037		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 2.633066338196037 | validation: 3.0350540320807657]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7360995204816247		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.7360995204816247 | validation: 3.495018615918638]
	TIME [epoch: 5.74 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.720805243996903		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 2.720805243996903 | validation: 3.167113338135333]
	TIME [epoch: 5.73 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6577101151164717		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 2.6577101151164717 | validation: 3.234267654107845]
	TIME [epoch: 5.73 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4857266919995693		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 2.4857266919995693 | validation: 3.7176432376240225]
	TIME [epoch: 5.73 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7733271607831296		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.7733271607831296 | validation: 3.648860494272991]
	TIME [epoch: 5.74 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6264494318874334		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.6264494318874334 | validation: 3.1691487514742143]
	TIME [epoch: 5.78 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.458140131948002		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.458140131948002 | validation: 3.190436984412727]
	TIME [epoch: 5.74 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1165377241243006		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 3.1165377241243006 | validation: 3.286056764484143]
	TIME [epoch: 5.74 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9048215921658		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.9048215921658 | validation: 3.159184509131043]
	TIME [epoch: 5.74 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.691012256143077		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.691012256143077 | validation: 3.115397434390601]
	TIME [epoch: 5.74 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5012951907069176		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.5012951907069176 | validation: 3.110973679446068]
	TIME [epoch: 5.73 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.476804624485802		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.476804624485802 | validation: 3.0366868854693947]
	TIME [epoch: 5.77 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4461179846436374		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 2.4461179846436374 | validation: 3.465000306409865]
	TIME [epoch: 5.75 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5453655026045157		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.5453655026045157 | validation: 3.1368063990569692]
	TIME [epoch: 5.74 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4312794393279398		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 2.4312794393279398 | validation: 3.452375408664857]
	TIME [epoch: 5.74 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.435267055656718		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.435267055656718 | validation: 3.703241251189303]
	TIME [epoch: 5.73 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7065300762255444		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 2.7065300762255444 | validation: 3.7286916031580404]
	TIME [epoch: 5.74 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8477095979907165		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 2.8477095979907165 | validation: 3.2056345156130837]
	TIME [epoch: 5.74 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5054312966222545		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 2.5054312966222545 | validation: 3.7620603835580297]
	TIME [epoch: 5.78 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7007047400935065		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 2.7007047400935065 | validation: 3.253274682021662]
	TIME [epoch: 5.74 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.585551402806912		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 2.585551402806912 | validation: 3.152701172077059]
	TIME [epoch: 5.74 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8082597854777425		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 2.8082597854777425 | validation: 3.3740532073249994]
	TIME [epoch: 5.73 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.53820115211857		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.53820115211857 | validation: 3.355411033226986]
	TIME [epoch: 5.73 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.481472550853335		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 2.481472550853335 | validation: 3.241620261729277]
	TIME [epoch: 5.73 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.503949941644299		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.503949941644299 | validation: 3.0704658335175634]
	TIME [epoch: 5.77 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7470777962859487		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.7470777962859487 | validation: 3.1711306499222647]
	TIME [epoch: 5.75 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4381857479290163		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 2.4381857479290163 | validation: 3.2385584821441227]
	TIME [epoch: 5.74 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5444252400370164		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.5444252400370164 | validation: 3.2565307750770853]
	TIME [epoch: 5.74 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.387877535208187		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.387877535208187 | validation: 3.651187035182335]
	TIME [epoch: 5.74 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5565277960747195		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 2.5565277960747195 | validation: 3.2658277889137683]
	TIME [epoch: 5.73 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4359223882741325		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 2.4359223882741325 | validation: 4.713128229002193]
	TIME [epoch: 5.74 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9980282314785347		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 2.9980282314785347 | validation: 3.4693039082026083]
	TIME [epoch: 5.78 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4571654232869977		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 2.4571654232869977 | validation: 3.1066728360517426]
	TIME [epoch: 5.74 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.585240789927359		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 2.585240789927359 | validation: 3.3178900554493556]
	TIME [epoch: 5.73 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.511465505465626		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.511465505465626 | validation: 3.108603601760365]
	TIME [epoch: 5.73 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.518572421959566		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.518572421959566 | validation: 3.3680797834061775]
	TIME [epoch: 5.73 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.468091604106064		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.468091604106064 | validation: 3.2298859854991906]
	TIME [epoch: 5.73 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.414946768884747		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.414946768884747 | validation: 3.9794878670111733]
	TIME [epoch: 5.77 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8220235185076072		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.8220235185076072 | validation: 3.0737702906991378]
	TIME [epoch: 5.75 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3827923639358737		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.3827923639358737 | validation: 3.1683892011771846]
	TIME [epoch: 5.74 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4166368287170474		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.4166368287170474 | validation: 3.215975819837345]
	TIME [epoch: 5.73 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7266326242997456		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 2.7266326242997456 | validation: 3.3568958800716273]
	TIME [epoch: 5.73 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5233415469215785		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.5233415469215785 | validation: 3.540624555418879]
	TIME [epoch: 5.73 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6131343343318796		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.6131343343318796 | validation: 3.222863696224824]
	TIME [epoch: 5.74 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4511121539130802		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.4511121539130802 | validation: 4.436152782126763]
	TIME [epoch: 5.77 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.764969694952319		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.764969694952319 | validation: 3.366207645620067]
	TIME [epoch: 5.74 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.618172122509691		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.618172122509691 | validation: 3.2242358227566603]
	TIME [epoch: 5.73 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4725702966819556		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 2.4725702966819556 | validation: 3.031836975286048]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_297.pth
	Model improved!!!
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.351805073347953		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 2.351805073347953 | validation: 3.091007421379861]
	TIME [epoch: 5.73 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.425327742909415		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 2.425327742909415 | validation: 3.2089432009144288]
	TIME [epoch: 5.73 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4643442786718035		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 2.4643442786718035 | validation: 3.406303219058522]
	TIME [epoch: 5.77 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6470064272489147		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 2.6470064272489147 | validation: 3.1288739505397407]
	TIME [epoch: 5.74 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4093070557710767		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.4093070557710767 | validation: 3.320664487294663]
	TIME [epoch: 5.73 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4744909967256263		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 2.4744909967256263 | validation: 3.0483376195546543]
	TIME [epoch: 5.73 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5669444299926814		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 2.5669444299926814 | validation: 3.056181879485645]
	TIME [epoch: 5.73 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.391934954954775		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 2.391934954954775 | validation: 3.204760519222928]
	TIME [epoch: 5.73 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3392983610237046		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 2.3392983610237046 | validation: 3.1116374999937966]
	TIME [epoch: 5.74 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6302255999418107		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 2.6302255999418107 | validation: 3.437129956601883]
	TIME [epoch: 5.76 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5099994244521477		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 2.5099994244521477 | validation: 3.1513712910191205]
	TIME [epoch: 5.73 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.490491155396591		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.490491155396591 | validation: 3.166270124709308]
	TIME [epoch: 5.73 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4645983224668626		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.4645983224668626 | validation: 3.135614455209419]
	TIME [epoch: 5.73 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5193356072073643		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 2.5193356072073643 | validation: 3.12058237386798]
	TIME [epoch: 5.73 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6118335744563925		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 2.6118335744563925 | validation: 3.3921531131729346]
	TIME [epoch: 5.73 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4626778069360635		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 2.4626778069360635 | validation: 3.155309555818525]
	TIME [epoch: 5.77 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5996967427449627		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 2.5996967427449627 | validation: 3.1841424473493736]
	TIME [epoch: 5.74 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3771045659979473		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 2.3771045659979473 | validation: 3.066070657600705]
	TIME [epoch: 5.73 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4961419700006697		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.4961419700006697 | validation: 3.185345006268751]
	TIME [epoch: 5.73 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4162644308877033		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 2.4162644308877033 | validation: 3.041697835484234]
	TIME [epoch: 5.73 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6418527763806874		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 2.6418527763806874 | validation: 3.07539419882547]
	TIME [epoch: 5.73 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.551131699148117		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 2.551131699148117 | validation: 3.491657001279127]
	TIME [epoch: 5.75 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4645935227784417		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 2.4645935227784417 | validation: 3.2970694363163364]
	TIME [epoch: 5.76 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.419524470431881		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 2.419524470431881 | validation: 4.460812639422858]
	TIME [epoch: 5.74 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.84088814414977		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.84088814414977 | validation: 3.757287144364504]
	TIME [epoch: 5.74 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.74034257631527		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 2.74034257631527 | validation: 3.43826317081516]
	TIME [epoch: 5.73 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4040640994876528		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 2.4040640994876528 | validation: 3.19463562708868]
	TIME [epoch: 5.74 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.584247141752571		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 2.584247141752571 | validation: 3.2497134748273577]
	TIME [epoch: 5.74 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.465821142903531		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 2.465821142903531 | validation: 3.1903647313017145]
	TIME [epoch: 5.78 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.429522451133644		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 2.429522451133644 | validation: 3.0249674425151603]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3675401246187344		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 2.3675401246187344 | validation: 3.006565804933138]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_328.pth
	Model improved!!!
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.498026563228344		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.498026563228344 | validation: 3.0792035814252676]
	TIME [epoch: 5.73 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7673232229716596		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 2.7673232229716596 | validation: 3.269659613337245]
	TIME [epoch: 5.73 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.562132683402014		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 2.562132683402014 | validation: 3.107537425394706]
	TIME [epoch: 5.73 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5154027461055803		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 2.5154027461055803 | validation: 3.14865121398788]
	TIME [epoch: 5.75 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3876109914751775		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 2.3876109914751775 | validation: 3.101508587006684]
	TIME [epoch: 5.76 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4211323466912704		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 2.4211323466912704 | validation: 3.3578566374465266]
	TIME [epoch: 5.73 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6329309905761757		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 2.6329309905761757 | validation: 3.3042990465993625]
	TIME [epoch: 5.73 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.374710182045256		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 2.374710182045256 | validation: 3.544780959922319]
	TIME [epoch: 5.73 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4746333464575687		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 2.4746333464575687 | validation: 3.0827970949229813]
	TIME [epoch: 5.73 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3979262196532005		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 2.3979262196532005 | validation: 3.0024744757399238]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4793143963023354		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 2.4793143963023354 | validation: 3.3717852082168775]
	TIME [epoch: 5.78 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.386695497092731		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 2.386695497092731 | validation: 3.51479541151544]
	TIME [epoch: 5.74 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4852400508363406		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 2.4852400508363406 | validation: 3.076569302236611]
	TIME [epoch: 5.73 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5470375077403866		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 2.5470375077403866 | validation: 3.1381358733433333]
	TIME [epoch: 5.74 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5166751252469592		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 2.5166751252469592 | validation: 3.1913718713993977]
	TIME [epoch: 5.73 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.408146084160385		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 2.408146084160385 | validation: 3.4225589753031898]
	TIME [epoch: 5.74 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3570080133185285		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 2.3570080133185285 | validation: 3.753046411587021]
	TIME [epoch: 5.76 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.565550843641635		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 2.565550843641635 | validation: 3.102999122801512]
	TIME [epoch: 5.75 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2683574971413973		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 2.2683574971413973 | validation: 3.2218672506751216]
	TIME [epoch: 5.73 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3707746592389434		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 2.3707746592389434 | validation: 3.150948042101449]
	TIME [epoch: 5.73 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3662595273161378		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 2.3662595273161378 | validation: 3.102845106932857]
	TIME [epoch: 5.74 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3737045377062875		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 2.3737045377062875 | validation: 3.126806642933964]
	TIME [epoch: 5.73 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3483111589964323		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 2.3483111589964323 | validation: 3.096379848166972]
	TIME [epoch: 5.74 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.371125862873742		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 2.371125862873742 | validation: 3.000246245760184]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5629349357279634		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 2.5629349357279634 | validation: 3.2112431676932762]
	TIME [epoch: 5.74 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3787789827909296		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 2.3787789827909296 | validation: 3.106708842542294]
	TIME [epoch: 5.73 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.483173058638868		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 2.483173058638868 | validation: 3.1274765887913607]
	TIME [epoch: 5.73 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7035427568485133		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 2.7035427568485133 | validation: 3.151812699026815]
	TIME [epoch: 5.73 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.589129569390636		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 2.589129569390636 | validation: 3.075620430072584]
	TIME [epoch: 5.74 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4483209300313296		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 2.4483209300313296 | validation: 3.3064916951655086]
	TIME [epoch: 5.76 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4395354526326174		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 2.4395354526326174 | validation: 3.785704562427441]
	TIME [epoch: 5.75 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.504688004634358		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 2.504688004634358 | validation: 3.0093766041165964]
	TIME [epoch: 5.73 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.394519149539109		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 2.394519149539109 | validation: 3.328416119397308]
	TIME [epoch: 5.73 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4626698904168873		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 2.4626698904168873 | validation: 3.1828944962956895]
	TIME [epoch: 5.74 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4208086478168385		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 2.4208086478168385 | validation: 3.3122928853098017]
	TIME [epoch: 5.73 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4747961574931447		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 2.4747961574931447 | validation: 3.185956730728874]
	TIME [epoch: 5.74 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4451704181748353		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 2.4451704181748353 | validation: 3.0090665801274463]
	TIME [epoch: 5.79 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4732393342967343		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 2.4732393342967343 | validation: 3.0416296330676516]
	TIME [epoch: 5.73 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.356747204308003		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 2.356747204308003 | validation: 3.02636066339525]
	TIME [epoch: 5.74 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.361604590572856		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 2.361604590572856 | validation: 3.259625295637909]
	TIME [epoch: 5.74 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3352540956648635		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 2.3352540956648635 | validation: 3.178442271763353]
	TIME [epoch: 5.74 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302600171534891		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 2.302600171534891 | validation: 3.119745754802415]
	TIME [epoch: 5.74 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3433939341840473		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 2.3433939341840473 | validation: 3.2024787348000894]
	TIME [epoch: 5.78 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.376987998911579		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 2.376987998911579 | validation: 3.2339091553612254]
	TIME [epoch: 5.76 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3338426407096526		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 2.3338426407096526 | validation: 3.0555493548654744]
	TIME [epoch: 5.73 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3842224942122314		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 2.3842224942122314 | validation: 3.253703183449419]
	TIME [epoch: 5.74 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288484887573855		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 2.288484887573855 | validation: 3.0741397079856903]
	TIME [epoch: 5.74 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3611062821484694		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 2.3611062821484694 | validation: 3.0603065389886575]
	TIME [epoch: 5.73 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.256625834030677		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 2.256625834030677 | validation: 3.047303702758153]
	TIME [epoch: 5.73 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4774833525218902		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 2.4774833525218902 | validation: 3.450955214009399]
	TIME [epoch: 5.78 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4761088999135104		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 2.4761088999135104 | validation: 3.3889437153809254]
	TIME [epoch: 5.74 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.467148649640213		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 2.467148649640213 | validation: 3.0350252276489744]
	TIME [epoch: 5.73 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.336378312622019		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 2.336378312622019 | validation: 3.4550482355804695]
	TIME [epoch: 5.74 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.490025038729257		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 2.490025038729257 | validation: 3.1170249113757915]
	TIME [epoch: 5.73 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4749447958658957		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 2.4749447958658957 | validation: 3.0471649817844355]
	TIME [epoch: 5.74 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3608758939400842		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 2.3608758939400842 | validation: 3.387250406503476]
	TIME [epoch: 5.76 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.319781269768475		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 2.319781269768475 | validation: 3.0656279465984664]
	TIME [epoch: 5.74 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312391731673942		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 2.312391731673942 | validation: 3.0421087081240024]
	TIME [epoch: 5.75 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.384699094425957		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 2.384699094425957 | validation: 3.22818895178497]
	TIME [epoch: 5.73 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3141060774652518		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 2.3141060774652518 | validation: 3.280975243249054]
	TIME [epoch: 5.72 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.465215415167872		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 2.465215415167872 | validation: 3.072439420108263]
	TIME [epoch: 5.73 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.443928154831317		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 2.443928154831317 | validation: 3.1572360076769996]
	TIME [epoch: 5.75 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286842107762985		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 2.286842107762985 | validation: 3.0992716358695023]
	TIME [epoch: 5.78 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4643093075673317		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 2.4643093075673317 | validation: 3.0665294405168027]
	TIME [epoch: 5.75 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296308940169281		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 2.296308940169281 | validation: 3.0240379564231756]
	TIME [epoch: 5.73 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.316783871183036		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 2.316783871183036 | validation: 3.0011279714773016]
	TIME [epoch: 5.73 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3316471261295044		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 2.3316471261295044 | validation: 3.0853345545905135]
	TIME [epoch: 5.75 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274938566130121		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 2.274938566130121 | validation: 3.6193479059358764]
	TIME [epoch: 5.74 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.555386017382679		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 2.555386017382679 | validation: 3.586723245132966]
	TIME [epoch: 5.77 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.522835227343152		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 2.522835227343152 | validation: 3.67964420842471]
	TIME [epoch: 5.75 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4753156303913775		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 2.4753156303913775 | validation: 3.1973043675319253]
	TIME [epoch: 5.73 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3216645611593902		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 2.3216645611593902 | validation: 3.126059153782719]
	TIME [epoch: 5.74 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308208708695695		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 2.308208708695695 | validation: 2.985139165144803]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2763734958397563		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 2.2763734958397563 | validation: 3.0662182210225626]
	TIME [epoch: 5.74 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.326885893617482		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 2.326885893617482 | validation: 3.0660607134646387]
	TIME [epoch: 5.76 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3038922430623736		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 2.3038922430623736 | validation: 3.0553318494235064]
	TIME [epoch: 5.78 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3202405076856683		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 2.3202405076856683 | validation: 3.308484918053184]
	TIME [epoch: 5.73 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.352075793371076		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 2.352075793371076 | validation: 3.356835017430784]
	TIME [epoch: 5.74 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3458075001259138		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 2.3458075001259138 | validation: 3.870512504578326]
	TIME [epoch: 5.74 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5828840501032113		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 2.5828840501032113 | validation: 3.7005198451793206]
	TIME [epoch: 5.73 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.435822211321967		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 2.435822211321967 | validation: 3.140933251895608]
	TIME [epoch: 5.75 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.545340445045307		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 2.545340445045307 | validation: 3.8690840506871154]
	TIME [epoch: 5.79 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.641085647879483		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 2.641085647879483 | validation: 3.1266680659477704]
	TIME [epoch: 5.74 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3584176102290932		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 2.3584176102290932 | validation: 3.070610112523436]
	TIME [epoch: 5.75 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2720545163249275		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 2.2720545163249275 | validation: 3.029193170237761]
	TIME [epoch: 5.73 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2871462929920403		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 2.2871462929920403 | validation: 3.239107719077847]
	TIME [epoch: 5.73 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3264191006562145		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 2.3264191006562145 | validation: 3.2084483578471277]
	TIME [epoch: 5.73 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.332935234961959		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 2.332935234961959 | validation: 3.230615718975877]
	TIME [epoch: 5.76 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.338822989106048		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 2.338822989106048 | validation: 3.79267212402646]
	TIME [epoch: 5.77 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.510962763124807		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 2.510962763124807 | validation: 3.492974402211488]
	TIME [epoch: 5.74 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4531192974148404		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 2.4531192974148404 | validation: 3.406828758012108]
	TIME [epoch: 5.75 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3500815264871933		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 2.3500815264871933 | validation: 3.5488957510204218]
	TIME [epoch: 5.72 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.453673929490206		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 2.453673929490206 | validation: 3.8173896988926503]
	TIME [epoch: 5.72 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5348528853118575		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 2.5348528853118575 | validation: 3.3447177005539164]
	TIME [epoch: 5.74 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.319377806111438		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 2.319377806111438 | validation: 2.9985052004671107]
	TIME [epoch: 5.79 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2911212523381455		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 2.2911212523381455 | validation: 3.0325154154903795]
	TIME [epoch: 5.73 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.515324778761058		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 2.515324778761058 | validation: 3.2169942629621766]
	TIME [epoch: 5.72 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.38684469604413		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 2.38684469604413 | validation: 3.13013951133726]
	TIME [epoch: 5.74 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3010373423963197		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 2.3010373423963197 | validation: 3.084339755889468]
	TIME [epoch: 5.74 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297999841367359		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 2.297999841367359 | validation: 2.9903639519273684]
	TIME [epoch: 5.73 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279745644934815		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 2.279745644934815 | validation: 3.129254131280908]
	TIME [epoch: 5.76 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307686142098882		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 2.307686142098882 | validation: 3.012200368791383]
	TIME [epoch: 5.77 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2690236055470514		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 2.2690236055470514 | validation: 3.810837500379474]
	TIME [epoch: 5.74 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4348056543593644		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 2.4348056543593644 | validation: 3.2347474494454764]
	TIME [epoch: 5.74 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3275834100752784		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 2.3275834100752784 | validation: 3.167261442882104]
	TIME [epoch: 5.74 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.359745129517066		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 2.359745129517066 | validation: 3.187845559995525]
	TIME [epoch: 5.74 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2737743321898405		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 2.2737743321898405 | validation: 3.0151825886088623]
	TIME [epoch: 5.74 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.376384896714824		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 2.376384896714824 | validation: 3.049036902433186]
	TIME [epoch: 5.78 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307670866042524		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 2.307670866042524 | validation: 3.545518599429814]
	TIME [epoch: 5.75 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3899619621045702		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 2.3899619621045702 | validation: 3.750353740806921]
	TIME [epoch: 5.72 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.504204190251789		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 2.504204190251789 | validation: 3.026252253086594]
	TIME [epoch: 5.74 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3309707203411962		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 2.3309707203411962 | validation: 3.03269647292689]
	TIME [epoch: 5.74 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.459222268046532		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 2.459222268046532 | validation: 3.0521465597678463]
	TIME [epoch: 5.74 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289292544970519		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 2.289292544970519 | validation: 3.178730094091277]
	TIME [epoch: 5.75 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262760746524785		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 2.262760746524785 | validation: 3.011459757666411]
	TIME [epoch: 5.77 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4405475427832606		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 2.4405475427832606 | validation: 3.0001956044168914]
	TIME [epoch: 5.74 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257797225702859		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 2.257797225702859 | validation: 3.2615866868430454]
	TIME [epoch: 5.74 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3128623183440817		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 2.3128623183440817 | validation: 3.354204297141792]
	TIME [epoch: 5.74 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2941135412830733		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 2.2941135412830733 | validation: 3.004567401760227]
	TIME [epoch: 5.74 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28426086105106		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 2.28426086105106 | validation: 3.1250970785443757]
	TIME [epoch: 5.74 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288403048293077		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 2.288403048293077 | validation: 3.0309292943883883]
	TIME [epoch: 5.79 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2267748919570236		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 2.2267748919570236 | validation: 3.0720599054516002]
	TIME [epoch: 5.75 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2742106410922234		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 2.2742106410922234 | validation: 3.6050580156268404]
	TIME [epoch: 5.74 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3879033186055088		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 2.3879033186055088 | validation: 3.2804484872294513]
	TIME [epoch: 5.74 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297407682643328		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 2.297407682643328 | validation: 3.221593685371216]
	TIME [epoch: 5.74 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2457443712375684		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 2.2457443712375684 | validation: 3.332787126263832]
	TIME [epoch: 5.74 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2616610011602565		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 2.2616610011602565 | validation: 3.0843837790503943]
	TIME [epoch: 5.76 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3025809652796028		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 2.3025809652796028 | validation: 3.2648464198500236]
	TIME [epoch: 5.77 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3634664832697174		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 2.3634664832697174 | validation: 3.033281602470794]
	TIME [epoch: 5.74 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281266007320677		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 2.281266007320677 | validation: 3.0657599351856253]
	TIME [epoch: 5.74 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297280951106261		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 2.297280951106261 | validation: 3.0262336380697525]
	TIME [epoch: 5.74 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3407909934902777		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 2.3407909934902777 | validation: 3.150070609750601]
	TIME [epoch: 5.73 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2484815095476827		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 2.2484815095476827 | validation: 3.1045021521439744]
	TIME [epoch: 5.73 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.381753907725207		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 2.381753907725207 | validation: 3.0677768989897505]
	TIME [epoch: 5.78 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2439022490786966		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 2.2439022490786966 | validation: 3.1920104247097476]
	TIME [epoch: 5.73 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279035948589432		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 2.279035948589432 | validation: 3.2772495103255825]
	TIME [epoch: 5.72 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.863238996679072		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 2.863238996679072 | validation: 4.560915944633222]
	TIME [epoch: 5.72 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7952998127653856		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 2.7952998127653856 | validation: 2.985071855335591]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3921183746160333		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 2.3921183746160333 | validation: 3.092122318834134]
	TIME [epoch: 5.72 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2800826132128957		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 2.2800826132128957 | validation: 2.9842297568128906]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2553697590440787		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 2.2553697590440787 | validation: 3.2470097467410812]
	TIME [epoch: 5.76 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2951244262884978		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 2.2951244262884978 | validation: 2.976296937886563]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_470.pth
	Model improved!!!
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.196817275061445		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 2.196817275061445 | validation: 3.023649407422528]
	TIME [epoch: 5.73 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2497891829141072		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 2.2497891829141072 | validation: 2.9956081820315625]
	TIME [epoch: 5.73 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2828225269172107		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 2.2828225269172107 | validation: 3.0016794081910536]
	TIME [epoch: 5.72 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30105513183738		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 2.30105513183738 | validation: 3.0245521312052834]
	TIME [epoch: 5.73 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2220067718563947		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 2.2220067718563947 | validation: 3.3081925629555746]
	TIME [epoch: 5.77 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3552881096446177		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 2.3552881096446177 | validation: 3.259882137948606]
	TIME [epoch: 5.72 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3523411993498997		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 2.3523411993498997 | validation: 3.0994701105225273]
	TIME [epoch: 5.72 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29766916679559		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 2.29766916679559 | validation: 3.043744513079032]
	TIME [epoch: 5.72 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.523979630592818		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 2.523979630592818 | validation: 3.0176890729160424]
	TIME [epoch: 5.72 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2391819478268125		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 2.2391819478268125 | validation: 3.0273092333398735]
	TIME [epoch: 5.72 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.223536345802247		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 2.223536345802247 | validation: 3.123657810517177]
	TIME [epoch: 5.75 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2291302729563847		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 2.2291302729563847 | validation: 3.071444996574687]
	TIME [epoch: 5.74 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3693151640204486		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 2.3693151640204486 | validation: 3.1579453661332435]
	TIME [epoch: 5.73 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315108329132518		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 2.315108329132518 | validation: 3.079194257616003]
	TIME [epoch: 5.72 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.351326243793438		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 2.351326243793438 | validation: 3.084126025518183]
	TIME [epoch: 5.72 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2592218906266677		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 2.2592218906266677 | validation: 3.0122486722650867]
	TIME [epoch: 5.73 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3471255842609535		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 2.3471255842609535 | validation: 3.7252940722019905]
	TIME [epoch: 5.73 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.485673957327381		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 2.485673957327381 | validation: 3.01988202914733]
	TIME [epoch: 5.77 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2440507487071923		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 2.2440507487071923 | validation: 3.0191001755388744]
	TIME [epoch: 5.72 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2997322146703505		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 2.2997322146703505 | validation: 3.0381630396750525]
	TIME [epoch: 5.74 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267666978354371		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 2.267666978354371 | validation: 3.2230002019090165]
	TIME [epoch: 5.73 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.362258465339152		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 2.362258465339152 | validation: 3.1308312496403876]
	TIME [epoch: 5.74 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281617827138909		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 2.281617827138909 | validation: 3.2246300261058565]
	TIME [epoch: 5.74 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4561063644706413		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 2.4561063644706413 | validation: 3.4584040029418723]
	TIME [epoch: 5.77 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3331838259893503		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 2.3331838259893503 | validation: 3.0904239856141436]
	TIME [epoch: 5.76 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284200217435373		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 2.284200217435373 | validation: 3.0469839909636773]
	TIME [epoch: 5.74 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2565872794590414		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 2.2565872794590414 | validation: 3.1083446132881627]
	TIME [epoch: 5.74 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2697149042278992		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 2.2697149042278992 | validation: 3.2886910171024857]
	TIME [epoch: 5.74 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277477614284588		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 2.277477614284588 | validation: 3.0907453367291504]
	TIME [epoch: 5.74 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2657570445678274		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 2.2657570445678274 | validation: 3.3041449752170706]
	TIME [epoch: 5.72 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2516403178636675		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 2.2516403178636675 | validation: 3.041731832855273]
	TIME [epoch: 5.77 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2277687617476714		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 2.2277687617476714 | validation: 3.030902839248334]
	TIME [epoch: 5.75 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3097614206614945		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 2.3097614206614945 | validation: 3.1591889249341434]
	TIME [epoch: 5.75 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257970515420584		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 2.257970515420584 | validation: 3.0181181405127866]
	TIME [epoch: 5.72 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3200465536726926		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 2.3200465536726926 | validation: 3.0027563612365418]
	TIME [epoch: 5.73 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281045057495392		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 2.281045057495392 | validation: 2.9543274567478193]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2673176185460213		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 2.2673176185460213 | validation: 2.977372087780259]
	TIME [epoch: 5.77 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2367324268751765		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 2.2367324268751765 | validation: 3.1970140053702667]
	TIME [epoch: 5.75 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2614361145369255		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 2.2614361145369255 | validation: 2.9524692113042286]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_509.pth
	Model improved!!!
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296893537210137		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 2.296893537210137 | validation: 3.036812564298565]
	TIME [epoch: 5.74 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299162064530811		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 2.299162064530811 | validation: 3.1035605595222897]
	TIME [epoch: 5.74 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2680908688141628		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 2.2680908688141628 | validation: 3.059959504326083]
	TIME [epoch: 5.74 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2751025039739843		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 2.2751025039739843 | validation: 2.989277786273401]
	TIME [epoch: 5.75 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.204267133408261		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 2.204267133408261 | validation: 3.4353397674653348]
	TIME [epoch: 5.77 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3848714906279045		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 2.3848714906279045 | validation: 3.0151118757501187]
	TIME [epoch: 5.74 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.204893561340939		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 2.204893561340939 | validation: 2.9984307235895247]
	TIME [epoch: 5.74 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2231879074221865		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 2.2231879074221865 | validation: 3.2638663663944505]
	TIME [epoch: 5.74 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.38683724264882		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 2.38683724264882 | validation: 3.2184195377165317]
	TIME [epoch: 5.74 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.440427968679741		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 2.440427968679741 | validation: 3.006600104930377]
	TIME [epoch: 5.74 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2651199332809204		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 2.2651199332809204 | validation: 3.131047333076166]
	TIME [epoch: 5.78 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279228701438627		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 2.279228701438627 | validation: 3.078913794535773]
	TIME [epoch: 5.74 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.348085851898113		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 2.348085851898113 | validation: 3.159270662333542]
	TIME [epoch: 5.74 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3172985550937124		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 2.3172985550937124 | validation: 3.0177803885411834]
	TIME [epoch: 5.74 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2969849847108135		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 2.2969849847108135 | validation: 3.383126758326792]
	TIME [epoch: 5.74 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.443275402373903		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 2.443275402373903 | validation: 3.0156427264086916]
	TIME [epoch: 5.74 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2595411949626474		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 2.2595411949626474 | validation: 3.0260537752272665]
	TIME [epoch: 5.75 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.339938861640444		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 2.339938861640444 | validation: 3.0561068814714805]
	TIME [epoch: 5.77 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.232032068940746		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 2.232032068940746 | validation: 2.987342366388258]
	TIME [epoch: 5.74 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3203896090359515		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 2.3203896090359515 | validation: 3.0367854015231353]
	TIME [epoch: 5.74 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2970276387124304		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 2.2970276387124304 | validation: 3.0533373316128407]
	TIME [epoch: 5.73 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.200014008422536		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 2.200014008422536 | validation: 3.0172646306161197]
	TIME [epoch: 5.74 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265132300311754		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 2.265132300311754 | validation: 3.138403531969977]
	TIME [epoch: 5.73 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1971616928876867		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 2.1971616928876867 | validation: 2.9703832510980535]
	TIME [epoch: 5.78 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2229699373070346		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 2.2229699373070346 | validation: 3.2593732550096757]
	TIME [epoch: 5.74 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2497293544566874		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 2.2497293544566874 | validation: 3.075299698798844]
	TIME [epoch: 5.74 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.201927464083777		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 2.201927464083777 | validation: 3.162373518817544]
	TIME [epoch: 5.74 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2322706455317833		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 2.2322706455317833 | validation: 2.995492090936051]
	TIME [epoch: 5.74 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2177973110142637		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 2.2177973110142637 | validation: 3.004345224420339]
	TIME [epoch: 5.74 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2089893270017864		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 2.2089893270017864 | validation: 3.0307822674000024]
	TIME [epoch: 5.75 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328894428296967		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 2.328894428296967 | validation: 2.9808281392851304]
	TIME [epoch: 5.77 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2504864963368942		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 2.2504864963368942 | validation: 2.9920711784886387]
	TIME [epoch: 5.74 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.191809045402083		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 2.191809045402083 | validation: 3.4246669913799472]
	TIME [epoch: 5.74 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3070151772471443		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 2.3070151772471443 | validation: 3.179395186701138]
	TIME [epoch: 5.74 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.23669679449557		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 2.23669679449557 | validation: 3.149377085582512]
	TIME [epoch: 5.74 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.234147508521896		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 2.234147508521896 | validation: 3.054668181764731]
	TIME [epoch: 5.73 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2053272547010465		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 2.2053272547010465 | validation: 2.9995519713094017]
	TIME [epoch: 5.78 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2095406134950273		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 2.2095406134950273 | validation: 3.061946483913763]
	TIME [epoch: 5.74 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2800885555739545		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 2.2800885555739545 | validation: 3.0472908407949753]
	TIME [epoch: 5.74 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30855162463058		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 2.30855162463058 | validation: 3.0210613898598595]
	TIME [epoch: 5.74 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2375664963172612		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 2.2375664963172612 | validation: 3.091428322453248]
	TIME [epoch: 5.74 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.209799307640441		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 2.209799307640441 | validation: 2.9538947115734278]
	TIME [epoch: 5.73 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2270483927292637		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 2.2270483927292637 | validation: 2.990834897478629]
	TIME [epoch: 5.75 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2112183170278854		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 2.2112183170278854 | validation: 3.1343915936871225]
	TIME [epoch: 5.77 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303210748690466		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 2.303210748690466 | validation: 2.9991940807724293]
	TIME [epoch: 5.74 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.231381438655122		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 2.231381438655122 | validation: 2.9877272454489776]
	TIME [epoch: 5.74 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2684085065151933		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 2.2684085065151933 | validation: 3.0145846615238443]
	TIME [epoch: 5.73 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2362715319263398		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 2.2362715319263398 | validation: 3.040145759937659]
	TIME [epoch: 5.74 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.23418731963441		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 2.23418731963441 | validation: 3.0052187934872485]
	TIME [epoch: 5.74 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.234070197813639		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 2.234070197813639 | validation: 3.0023726807443403]
	TIME [epoch: 5.78 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2181071146506293		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 2.2181071146506293 | validation: 2.9704047172627326]
	TIME [epoch: 5.74 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2294690592965303		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 2.2294690592965303 | validation: 3.0924797283050913]
	TIME [epoch: 5.74 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2099925407973338		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 2.2099925407973338 | validation: 3.127485905867676]
	TIME [epoch: 5.74 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2588079819174363		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 2.2588079819174363 | validation: 3.0170052326232555]
	TIME [epoch: 5.73 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.210652079932734		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 2.210652079932734 | validation: 2.986192399934669]
	TIME [epoch: 5.73 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.374129152994601		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 2.374129152994601 | validation: 3.125702049185564]
	TIME [epoch: 5.75 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3167651653503234		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 2.3167651653503234 | validation: 3.249577501037572]
	TIME [epoch: 5.77 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.385147843132247		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 2.385147843132247 | validation: 3.358340150859651]
	TIME [epoch: 5.74 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2987785814334223		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 2.2987785814334223 | validation: 3.157873128069405]
	TIME [epoch: 5.74 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2527451164790473		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 2.2527451164790473 | validation: 2.982626393330073]
	TIME [epoch: 5.73 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296250467159033		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 2.296250467159033 | validation: 2.985015393208737]
	TIME [epoch: 5.73 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2128050262174006		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 2.2128050262174006 | validation: 3.1765612457795056]
	TIME [epoch: 5.73 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28837490357711		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 2.28837490357711 | validation: 2.9931770541257743]
	TIME [epoch: 5.77 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.183959264523969		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 2.183959264523969 | validation: 2.9810964386512353]
	TIME [epoch: 5.74 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2202294496920643		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 2.2202294496920643 | validation: 2.969981435944067]
	TIME [epoch: 5.74 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.206581325970559		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 2.206581325970559 | validation: 3.0622710431031486]
	TIME [epoch: 5.73 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1536358917245844		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 2.1536358917245844 | validation: 3.019025500842905]
	TIME [epoch: 5.73 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2245712527097097		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 2.2245712527097097 | validation: 3.0306802862370605]
	TIME [epoch: 5.73 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2139751920762354		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 2.2139751920762354 | validation: 3.0570623004986306]
	TIME [epoch: 5.75 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2147139584059476		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 2.2147139584059476 | validation: 3.0741386650721747]
	TIME [epoch: 5.77 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5152716505773665		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 2.5152716505773665 | validation: 3.03113960618457]
	TIME [epoch: 5.74 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2123115370740756		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 2.2123115370740756 | validation: 3.0300028514947015]
	TIME [epoch: 5.74 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.178102944522802		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 2.178102944522802 | validation: 3.009218210799148]
	TIME [epoch: 5.74 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2257086896684832		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 2.2257086896684832 | validation: 3.0281236503418576]
	TIME [epoch: 5.74 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1935899467538493		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 2.1935899467538493 | validation: 2.9879175039073904]
	TIME [epoch: 5.73 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1866400936147743		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 2.1866400936147743 | validation: 2.9930704086809397]
	TIME [epoch: 5.78 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2272829876573597		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 2.2272829876573597 | validation: 2.95254811442084]
	TIME [epoch: 5.74 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3340009828999504		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 2.3340009828999504 | validation: 3.3628777262159693]
	TIME [epoch: 5.74 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3215566578323803		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 2.3215566578323803 | validation: 3.003618471723962]
	TIME [epoch: 5.73 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1938488286213897		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 2.1938488286213897 | validation: 2.993354982965849]
	TIME [epoch: 5.73 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.221937780274306		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 2.221937780274306 | validation: 3.3261633333911425]
	TIME [epoch: 5.73 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3341743608824284		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 2.3341743608824284 | validation: 3.0524164517569488]
	TIME [epoch: 5.75 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2335101537998883		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 2.2335101537998883 | validation: 2.9814693168404807]
	TIME [epoch: 5.77 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1591347842647326		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 2.1591347842647326 | validation: 3.2456240925853264]
	TIME [epoch: 5.74 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2656930417162955		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 2.2656930417162955 | validation: 3.063045079026866]
	TIME [epoch: 5.74 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2528382066065014		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 2.2528382066065014 | validation: 3.0427021706705237]
	TIME [epoch: 5.73 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.261171529344158		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 2.261171529344158 | validation: 3.085425916005189]
	TIME [epoch: 5.73 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.233121276272737		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 2.233121276272737 | validation: 3.1722465786088514]
	TIME [epoch: 5.74 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2322787359676592		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 2.2322787359676592 | validation: 3.039980134616146]
	TIME [epoch: 5.77 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1733383705312592		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 2.1733383705312592 | validation: 3.1985376105270222]
	TIME [epoch: 5.74 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2580262403009974		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 2.2580262403009974 | validation: 3.0000906188463445]
	TIME [epoch: 5.74 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1620452481501897		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 2.1620452481501897 | validation: 2.974481549285922]
	TIME [epoch: 5.73 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.155766469476146		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 2.155766469476146 | validation: 3.109185276077665]
	TIME [epoch: 5.73 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2341400651347154		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 2.2341400651347154 | validation: 3.029542171270812]
	TIME [epoch: 5.73 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1582450730233003		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 2.1582450730233003 | validation: 2.9673321985683576]
	TIME [epoch: 5.75 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1613999212907458		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 2.1613999212907458 | validation: 2.9587028874296393]
	TIME [epoch: 5.76 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2005298837036733		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 2.2005298837036733 | validation: 3.010046509975331]
	TIME [epoch: 5.74 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1946445716331064		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 2.1946445716331064 | validation: 3.118617035092094]
	TIME [epoch: 5.74 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1814433953278676		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 2.1814433953278676 | validation: 3.01072683823528]
	TIME [epoch: 5.73 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2491031963101764		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 2.2491031963101764 | validation: 3.048665342022016]
	TIME [epoch: 5.73 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2172818569252186		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 2.2172818569252186 | validation: 2.9993104214600788]
	TIME [epoch: 5.73 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2309225279387235		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 2.2309225279387235 | validation: 3.011073255941074]
	TIME [epoch: 5.78 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2008030591485865		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 2.2008030591485865 | validation: 3.0122006499350427]
	TIME [epoch: 5.74 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2250790348953196		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 2.2250790348953196 | validation: 3.0342255744837066]
	TIME [epoch: 5.73 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.196299381109751		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 2.196299381109751 | validation: 2.9714182281022308]
	TIME [epoch: 5.73 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.209815584799295		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 2.209815584799295 | validation: 2.9966101216202516]
	TIME [epoch: 5.73 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.215212538309168		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 2.215212538309168 | validation: 2.9960377934060762]
	TIME [epoch: 5.73 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.166026662710265		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 2.166026662710265 | validation: 3.0807095590902045]
	TIME [epoch: 5.75 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242728966427691		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 2.242728966427691 | validation: 3.0089517611575434]
	TIME [epoch: 5.76 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.183596951439963		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 2.183596951439963 | validation: 3.112199453553955]
	TIME [epoch: 5.74 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1857218139026635		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 2.1857218139026635 | validation: 3.26347121426405]
	TIME [epoch: 5.73 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.195109364369058		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 2.195109364369058 | validation: 3.006142158293595]
	TIME [epoch: 5.73 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.143728718886356		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 2.143728718886356 | validation: 3.019994185379236]
	TIME [epoch: 5.74 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.190230358345613		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 2.190230358345613 | validation: 2.9621101281103455]
	TIME [epoch: 5.74 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.155940065786325		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 2.155940065786325 | validation: 3.047163375806606]
	TIME [epoch: 5.78 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1645958955600344		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 2.1645958955600344 | validation: 2.9879662502042073]
	TIME [epoch: 5.75 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.194881355655304		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 2.194881355655304 | validation: 3.1165052757969436]
	TIME [epoch: 5.74 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2163300831206163		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 2.2163300831206163 | validation: 3.012496485921056]
	TIME [epoch: 5.74 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.164786056349497		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 2.164786056349497 | validation: 3.0778148646671366]
	TIME [epoch: 5.74 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1679422411189733		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 2.1679422411189733 | validation: 3.230357549896379]
	TIME [epoch: 5.74 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.232112024078869		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 2.232112024078869 | validation: 3.080795157441274]
	TIME [epoch: 5.75 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2132327249429915		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 2.2132327249429915 | validation: 3.0498622432606357]
	TIME [epoch: 5.77 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.138568769129578		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 2.138568769129578 | validation: 3.138145064808465]
	TIME [epoch: 5.74 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.197640841792249		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 2.197640841792249 | validation: 3.002413337253831]
	TIME [epoch: 5.74 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.198616916596994		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 2.198616916596994 | validation: 3.0053047984852554]
	TIME [epoch: 5.74 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.207843537289376		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 2.207843537289376 | validation: 3.100720941992367]
	TIME [epoch: 5.74 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.232396837508821		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 2.232396837508821 | validation: 3.012357122777014]
	TIME [epoch: 5.74 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.157679688946745		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 2.157679688946745 | validation: 3.02607486447919]
	TIME [epoch: 5.78 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1962108784132854		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 2.1962108784132854 | validation: 3.067097343480867]
	TIME [epoch: 5.75 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1921580788376698		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 2.1921580788376698 | validation: 2.987617131110393]
	TIME [epoch: 5.74 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2000990538992378		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 2.2000990538992378 | validation: 2.996647063371181]
	TIME [epoch: 5.74 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1753289190557044		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 2.1753289190557044 | validation: 3.0537460385117687]
	TIME [epoch: 5.74 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1717172297281797		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 2.1717172297281797 | validation: 2.988314257870492]
	TIME [epoch: 5.74 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.13821127800149		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 2.13821127800149 | validation: 3.205283564746755]
	TIME [epoch: 5.75 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2132967028582278		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 2.2132967028582278 | validation: 3.0510707527408147]
	TIME [epoch: 5.77 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.371097340654499		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 2.371097340654499 | validation: 3.0825824215352986]
	TIME [epoch: 5.74 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1617844322595925		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 2.1617844322595925 | validation: 3.038905623122631]
	TIME [epoch: 5.74 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1661475227606903		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 2.1661475227606903 | validation: 3.0347989662244435]
	TIME [epoch: 5.74 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.162752798436598		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 2.162752798436598 | validation: 3.141618681547196]
	TIME [epoch: 5.74 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.166166786017605		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 2.166166786017605 | validation: 3.1297911957421607]
	TIME [epoch: 5.74 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1595525247843015		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 2.1595525247843015 | validation: 2.967283466362716]
	TIME [epoch: 5.78 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1880590938468965		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 2.1880590938468965 | validation: 2.9765417704867914]
	TIME [epoch: 5.74 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1522599837743517		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 2.1522599837743517 | validation: 3.0773905836384503]
	TIME [epoch: 5.74 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1739911948316175		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 2.1739911948316175 | validation: 3.030698902441185]
	TIME [epoch: 5.74 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.169782034616741		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 2.169782034616741 | validation: 3.03407605430979]
	TIME [epoch: 5.74 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1895032110462154		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 2.1895032110462154 | validation: 3.103148939886809]
	TIME [epoch: 5.74 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.166175668003792		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 2.166175668003792 | validation: 3.080440621102023]
	TIME [epoch: 5.75 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1540219681158055		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 2.1540219681158055 | validation: 3.0618251897401625]
	TIME [epoch: 5.77 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1425833554936835		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 2.1425833554936835 | validation: 3.0006537898234287]
	TIME [epoch: 5.74 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1515208995311967		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 2.1515208995311967 | validation: 3.1631694020083856]
	TIME [epoch: 5.74 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.151490607354079		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 2.151490607354079 | validation: 3.1055720840786125]
	TIME [epoch: 5.74 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.152806270162565		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 2.152806270162565 | validation: 3.232034190033244]
	TIME [epoch: 5.74 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2701941397365695		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 2.2701941397365695 | validation: 2.9951037646761383]
	TIME [epoch: 5.74 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1422578439686584		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 2.1422578439686584 | validation: 2.989411752346664]
	TIME [epoch: 5.78 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.191385443298827		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 2.191385443298827 | validation: 3.04024130712432]
	TIME [epoch: 5.74 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1831473216199195		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 2.1831473216199195 | validation: 3.0309487676197264]
	TIME [epoch: 5.74 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.150362682590913		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 2.150362682590913 | validation: 3.0099134359952306]
	TIME [epoch: 5.74 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1784347859239714		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 2.1784347859239714 | validation: 3.056757727205643]
	TIME [epoch: 5.73 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.160333071618193		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 2.160333071618193 | validation: 3.2307825371914767]
	TIME [epoch: 5.73 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.191547033920771		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 2.191547033920771 | validation: 3.015532410652156]
	TIME [epoch: 5.77 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.203550213381435		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 2.203550213381435 | validation: 3.0047135608958366]
	TIME [epoch: 5.75 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.144600592527973		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 2.144600592527973 | validation: 3.1473571298346235]
	TIME [epoch: 5.74 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1668514067128744		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 2.1668514067128744 | validation: 2.9763972480725305]
	TIME [epoch: 5.74 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1608685947768462		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 2.1608685947768462 | validation: 3.01169457056177]
	TIME [epoch: 5.73 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1575025108506747		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 2.1575025108506747 | validation: 3.123983004124722]
	TIME [epoch: 5.74 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2595515903781562		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 2.2595515903781562 | validation: 3.0046412707851755]
	TIME [epoch: 5.74 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1490336683243134		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 2.1490336683243134 | validation: 3.009279457225838]
	TIME [epoch: 5.78 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.153069023759001		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 2.153069023759001 | validation: 3.207720611322849]
	TIME [epoch: 5.74 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3011063388794386		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 2.3011063388794386 | validation: 3.136306027941403]
	TIME [epoch: 5.74 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.231881734333732		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 2.231881734333732 | validation: 3.1050913327771994]
	TIME [epoch: 5.74 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296787710067051		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 2.296787710067051 | validation: 3.018757051352541]
	TIME [epoch: 5.73 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1319535323390673		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 2.1319535323390673 | validation: 3.017097108283305]
	TIME [epoch: 5.73 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.132647157208868		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 2.132647157208868 | validation: 3.1211745308198022]
	TIME [epoch: 5.77 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1558896000660397		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 2.1558896000660397 | validation: 3.182939493139451]
	TIME [epoch: 5.75 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.186049012669792		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 2.186049012669792 | validation: 3.0338002888555673]
	TIME [epoch: 5.74 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1941040305072783		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 2.1941040305072783 | validation: 3.0480620724497705]
	TIME [epoch: 5.74 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1648212474675663		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 2.1648212474675663 | validation: 2.9732503625027484]
	TIME [epoch: 5.73 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2442351897955266		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 2.2442351897955266 | validation: 3.019514503159997]
	TIME [epoch: 5.73 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1612178325237967		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 2.1612178325237967 | validation: 2.9497740890199458]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.125612906794555		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 2.125612906794555 | validation: 2.9732191714533363]
	TIME [epoch: 5.78 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.196940978645672		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 2.196940978645672 | validation: 2.989954020129068]
	TIME [epoch: 5.74 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1383615590857543		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 2.1383615590857543 | validation: 2.968273776483966]
	TIME [epoch: 5.74 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1421396875015106		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 2.1421396875015106 | validation: 2.9638250464345153]
	TIME [epoch: 5.73 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1642960493954218		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 2.1642960493954218 | validation: 3.105632012077641]
	TIME [epoch: 5.73 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.167017506441994		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 2.167017506441994 | validation: 2.966461432831849]
	TIME [epoch: 5.73 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.149576390841886		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 2.149576390841886 | validation: 3.0482521159773537]
	TIME [epoch: 5.76 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1863638165662005		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 2.1863638165662005 | validation: 2.9711357052671654]
	TIME [epoch: 5.75 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.165433930718846		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 2.165433930718846 | validation: 3.0584144333571794]
	TIME [epoch: 5.74 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.16096191118297		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 2.16096191118297 | validation: 2.952676921191602]
	TIME [epoch: 5.74 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.200027060899214		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 2.200027060899214 | validation: 3.005325199147461]
	TIME [epoch: 5.74 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1680311327012234		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 2.1680311327012234 | validation: 2.9876748825395056]
	TIME [epoch: 5.74 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.12815684708643		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 2.12815684708643 | validation: 2.971536738732318]
	TIME [epoch: 5.74 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.148963179043954		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 2.148963179043954 | validation: 3.050580605201434]
	TIME [epoch: 5.78 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.203538128687886		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 2.203538128687886 | validation: 3.1060533335302]
	TIME [epoch: 5.74 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1569326890937215		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 2.1569326890937215 | validation: 3.265246265134353]
	TIME [epoch: 5.74 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1822231928834057		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 2.1822231928834057 | validation: 3.0149443489070813]
	TIME [epoch: 5.74 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.154271588045891		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 2.154271588045891 | validation: 3.2028866266117473]
	TIME [epoch: 5.74 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1666934165771194		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 2.1666934165771194 | validation: 3.0101232230807287]
	TIME [epoch: 5.74 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1557195145949852		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 2.1557195145949852 | validation: 2.966785693479253]
	TIME [epoch: 5.76 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1434678106522758		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 2.1434678106522758 | validation: 2.969938559042429]
	TIME [epoch: 5.75 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1362616496253413		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 2.1362616496253413 | validation: 2.9900113398666246]
	TIME [epoch: 5.74 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.117948123657541		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 2.117948123657541 | validation: 2.9882721540268795]
	TIME [epoch: 5.74 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.129839976801464		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 2.129839976801464 | validation: 3.008875792970853]
	TIME [epoch: 5.74 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1724531684037243		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 2.1724531684037243 | validation: 3.041101379487409]
	TIME [epoch: 5.74 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1605219621430676		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 2.1605219621430676 | validation: 3.0786343171273005]
	TIME [epoch: 5.74 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.223122156056803		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 2.223122156056803 | validation: 2.995382742722094]
	TIME [epoch: 5.78 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1251448103090773		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 2.1251448103090773 | validation: 3.0534026250970694]
	TIME [epoch: 5.74 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.124243089318343		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 2.124243089318343 | validation: 3.0146175079851054]
	TIME [epoch: 5.74 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1799061032544405		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 2.1799061032544405 | validation: 2.9581919076347845]
	TIME [epoch: 5.74 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1364707774738214		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 2.1364707774738214 | validation: 2.9917906405632153]
	TIME [epoch: 5.74 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1494569593466095		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 2.1494569593466095 | validation: 3.0698800110219757]
	TIME [epoch: 5.73 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.12893235950866		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 2.12893235950866 | validation: 3.0730662717023574]
	TIME [epoch: 5.77 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1534661319995445		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 2.1534661319995445 | validation: 3.00227171489609]
	TIME [epoch: 5.75 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.118645102614531		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 2.118645102614531 | validation: 2.9611004917251726]
	TIME [epoch: 5.74 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.142101073626468		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 2.142101073626468 | validation: 3.0775366580874026]
	TIME [epoch: 5.74 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1421788574537297		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 2.1421788574537297 | validation: 3.0061358358323993]
	TIME [epoch: 5.74 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1248728145513254		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 2.1248728145513254 | validation: 3.1094523851421525]
	TIME [epoch: 5.74 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1719275306042016		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 2.1719275306042016 | validation: 2.954352114395926]
	TIME [epoch: 5.74 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.150667544483602		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 2.150667544483602 | validation: 2.986574580394044]
	TIME [epoch: 5.78 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.164869425875982		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 2.164869425875982 | validation: 3.0778187394245187]
	TIME [epoch: 5.74 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1225187454047756		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 2.1225187454047756 | validation: 3.0489355394104694]
	TIME [epoch: 5.74 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1294594913652767		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 2.1294594913652767 | validation: 2.9802745841661373]
	TIME [epoch: 5.74 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.130137915855288		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 2.130137915855288 | validation: 2.9614343557369476]
	TIME [epoch: 5.74 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1271420064587514		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 2.1271420064587514 | validation: 3.0147347827831847]
	TIME [epoch: 5.74 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.111820928596232		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 2.111820928596232 | validation: 2.9694740504331616]
	TIME [epoch: 5.77 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.116656334787521		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 2.116656334787521 | validation: 3.033980985340187]
	TIME [epoch: 5.75 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1306450124732517		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 2.1306450124732517 | validation: 3.0373098970126255]
	TIME [epoch: 5.74 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.162956029863022		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 2.162956029863022 | validation: 3.419389633093772]
	TIME [epoch: 5.74 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.255556854008874		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 2.255556854008874 | validation: 3.0043940035802406]
	TIME [epoch: 5.74 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1571302407325157		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 2.1571302407325157 | validation: 3.0846981536661104]
	TIME [epoch: 5.74 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1330159194123155		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 2.1330159194123155 | validation: 2.97497723599629]
	TIME [epoch: 5.74 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1376604873748093		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 2.1376604873748093 | validation: 2.976772552571714]
	TIME [epoch: 5.78 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1176633248192736		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 2.1176633248192736 | validation: 2.9893371773150648]
	TIME [epoch: 5.74 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1080913091530724		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 2.1080913091530724 | validation: 3.0036039956828438]
	TIME [epoch: 5.74 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2001426131183264		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 2.2001426131183264 | validation: 3.0842879308756346]
	TIME [epoch: 5.74 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.149166337777921		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 2.149166337777921 | validation: 3.0484908259090746]
	TIME [epoch: 5.74 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1617610191581957		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 2.1617610191581957 | validation: 2.9900240815617605]
	TIME [epoch: 5.74 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1230393474214786		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 2.1230393474214786 | validation: 3.0000151053147546]
	TIME [epoch: 5.77 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.143195200237458		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 2.143195200237458 | validation: 2.954814163638725]
	TIME [epoch: 5.75 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1600782526000017		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 2.1600782526000017 | validation: 3.104080727653759]
	TIME [epoch: 5.74 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.147006085945944		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 2.147006085945944 | validation: 3.0423945350864363]
	TIME [epoch: 5.74 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266472957808089		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 2.266472957808089 | validation: 3.093449497649582]
	TIME [epoch: 5.74 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.197053080561179		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 2.197053080561179 | validation: 3.1040355825439243]
	TIME [epoch: 5.74 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.148730608301464		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 2.148730608301464 | validation: 2.987833346962609]
	TIME [epoch: 5.74 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.130433075704186		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 2.130433075704186 | validation: 3.0763091309989568]
	TIME [epoch: 5.77 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1508382662073178		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 2.1508382662073178 | validation: 2.9884414720504346]
	TIME [epoch: 5.74 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.124028227566046		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 2.124028227566046 | validation: 2.962979583428404]
	TIME [epoch: 5.74 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2065778366245645		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 2.2065778366245645 | validation: 3.1445174575268817]
	TIME [epoch: 5.74 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1428491948156245		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 2.1428491948156245 | validation: 2.9517991612824255]
	TIME [epoch: 5.74 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.116132688604767		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 2.116132688604767 | validation: 2.9523590063074034]
	TIME [epoch: 5.74 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1132308219373037		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 2.1132308219373037 | validation: 2.9527295742630257]
	TIME [epoch: 5.77 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1196206221714857		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 2.1196206221714857 | validation: 2.9863671443823496]
	TIME [epoch: 5.75 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1153273036656426		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 2.1153273036656426 | validation: 3.023520455972425]
	TIME [epoch: 5.74 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1446915157109334		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 2.1446915157109334 | validation: 3.001416407638192]
	TIME [epoch: 5.73 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1112487293396605		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 2.1112487293396605 | validation: 2.9554800263403536]
	TIME [epoch: 5.74 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1322991487903957		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 2.1322991487903957 | validation: 2.964382367012439]
	TIME [epoch: 5.74 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1212457081306146		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 2.1212457081306146 | validation: 2.9621727542678595]
	TIME [epoch: 5.75 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.155508400066477		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 2.155508400066477 | validation: 3.0603498468871817]
	TIME [epoch: 5.77 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1109223191059243		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 2.1109223191059243 | validation: 2.9655533259934983]
	TIME [epoch: 5.74 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.102725286556937		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 2.102725286556937 | validation: 2.9604116385585635]
	TIME [epoch: 5.74 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1070811594175547		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 2.1070811594175547 | validation: 3.001800871298336]
	TIME [epoch: 5.74 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1008239046882933		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 2.1008239046882933 | validation: 3.0089243239857923]
	TIME [epoch: 5.73 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1127757357835817		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 2.1127757357835817 | validation: 2.980881287781098]
	TIME [epoch: 5.74 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.160031411186247		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 2.160031411186247 | validation: 2.9418955086361396]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_773.pth
	Model improved!!!
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.117651101709261		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 2.117651101709261 | validation: 2.9638690442613327]
	TIME [epoch: 5.74 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.126399535278691		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 2.126399535278691 | validation: 3.030699847258477]
	TIME [epoch: 5.73 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1243293754567536		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 2.1243293754567536 | validation: 2.9658702499155436]
	TIME [epoch: 5.72 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.234398594766356		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 2.234398594766356 | validation: 2.9691708418977414]
	TIME [epoch: 5.73 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.133051064880765		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 2.133051064880765 | validation: 2.9576919121381753]
	TIME [epoch: 5.72 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.107726134745119		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 2.107726134745119 | validation: 3.024991926762382]
	TIME [epoch: 5.74 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.157895500572087		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 2.157895500572087 | validation: 3.1195100086907224]
	TIME [epoch: 5.76 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1591942279911014		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 2.1591942279911014 | validation: 2.943814711320227]
	TIME [epoch: 5.73 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.13942869024034		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 2.13942869024034 | validation: 3.0136608652657233]
	TIME [epoch: 5.73 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1058835472223256		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 2.1058835472223256 | validation: 2.956927182816065]
	TIME [epoch: 5.73 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1262080958664646		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 2.1262080958664646 | validation: 2.9962447679233635]
	TIME [epoch: 5.73 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.14081289759204		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 2.14081289759204 | validation: 3.0957547617353]
	TIME [epoch: 5.72 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.145643431385033		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 2.145643431385033 | validation: 2.972003549028795]
	TIME [epoch: 5.77 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.112149246682065		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 2.112149246682065 | validation: 2.9476379665778554]
	TIME [epoch: 5.74 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.158601890302105		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 2.158601890302105 | validation: 2.941802242879033]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_788.pth
	Model improved!!!
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1240646101825456		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 2.1240646101825456 | validation: 2.9816628422710836]
	TIME [epoch: 5.73 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.111442599296665		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 2.111442599296665 | validation: 3.004095359080277]
	TIME [epoch: 5.73 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.107307960564331		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 2.107307960564331 | validation: 2.9633890804275267]
	TIME [epoch: 5.73 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1165767182171464		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 2.1165767182171464 | validation: 3.007133391134124]
	TIME [epoch: 5.76 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1284249510886037		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 2.1284249510886037 | validation: 2.94091929440271]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_793.pth
	Model improved!!!
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.130757655947841		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 2.130757655947841 | validation: 2.963548881619884]
	TIME [epoch: 5.73 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.13497860632859		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 2.13497860632859 | validation: 2.9440891732878516]
	TIME [epoch: 5.72 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.108896062580429		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 2.108896062580429 | validation: 3.1416870560759147]
	TIME [epoch: 5.72 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1353037701429702		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 2.1353037701429702 | validation: 2.9878190851287685]
	TIME [epoch: 5.72 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1178349571366026		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 2.1178349571366026 | validation: 3.0713239921450994]
	TIME [epoch: 5.73 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1554328202880084		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 2.1554328202880084 | validation: 2.969153292388304]
	TIME [epoch: 5.77 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.135955246950267		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 2.135955246950267 | validation: 2.9620537039307173]
	TIME [epoch: 5.72 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1400576060930536		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 2.1400576060930536 | validation: 2.9675760097547426]
	TIME [epoch: 5.72 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.103534391390065		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 2.103534391390065 | validation: 2.977937356136171]
	TIME [epoch: 5.72 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1104854696611017		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 2.1104854696611017 | validation: 2.9594895104194605]
	TIME [epoch: 5.72 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1325761248807655		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 2.1325761248807655 | validation: 2.9345890877496768]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_804.pth
	Model improved!!!
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1062993219178527		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 2.1062993219178527 | validation: 2.9386168788425606]
	TIME [epoch: 5.77 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1437416548899835		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 2.1437416548899835 | validation: 2.9636073669299416]
	TIME [epoch: 5.74 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1727717675664078		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 2.1727717675664078 | validation: 2.9485369678832605]
	TIME [epoch: 5.73 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1157691919270976		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 2.1157691919270976 | validation: 2.9318136287985896]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_808.pth
	Model improved!!!
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1113229071231325		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 2.1113229071231325 | validation: 2.9444449178671226]
	TIME [epoch: 5.73 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.106432153799642		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 2.106432153799642 | validation: 2.9493865824999204]
	TIME [epoch: 5.72 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.116521327514689		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 2.116521327514689 | validation: 2.9308830334830644]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_811.pth
	Model improved!!!
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1166139185971478		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 2.1166139185971478 | validation: 2.969190363161831]
	TIME [epoch: 5.78 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.119093883291293		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 2.119093883291293 | validation: 2.9441070753218916]
	TIME [epoch: 5.72 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.114366024493582		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 2.114366024493582 | validation: 2.9611669924443675]
	TIME [epoch: 5.74 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1007914430985495		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 2.1007914430985495 | validation: 2.9401007693319285]
	TIME [epoch: 5.72 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1832659586611776		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 2.1832659586611776 | validation: 3.1658081127837487]
	TIME [epoch: 5.72 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1379481136317953		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 2.1379481136317953 | validation: 2.9273606403740464]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_817.pth
	Model improved!!!
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1183902537184234		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 2.1183902537184234 | validation: 2.9871483278671507]
	TIME [epoch: 5.77 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1233732553841103		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 2.1233732553841103 | validation: 2.9626913397233974]
	TIME [epoch: 5.73 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1207229533016867		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 2.1207229533016867 | validation: 2.9801582360146712]
	TIME [epoch: 5.72 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.213909116593621		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 2.213909116593621 | validation: 3.008403023595527]
	TIME [epoch: 5.72 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1185778251918252		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 2.1185778251918252 | validation: 2.9434078468404983]
	TIME [epoch: 5.73 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.11361798920613		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 2.11361798920613 | validation: 2.931979369096566]
	TIME [epoch: 5.72 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094815179460639		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 2.094815179460639 | validation: 2.944766863374762]
	TIME [epoch: 5.75 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.132766030376753		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 2.132766030376753 | validation: 3.061941096930385]
	TIME [epoch: 5.74 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1504088895819		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 2.1504088895819 | validation: 2.977973256187121]
	TIME [epoch: 5.72 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.123308157526847		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 2.123308157526847 | validation: 2.9428482990678617]
	TIME [epoch: 5.72 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1093988177666243		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 2.1093988177666243 | validation: 3.020474015956103]
	TIME [epoch: 5.72 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1006029436445233		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 2.1006029436445233 | validation: 2.982132773491958]
	TIME [epoch: 5.72 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.108887533506747		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 2.108887533506747 | validation: 2.9669097382420726]
	TIME [epoch: 5.72 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0883423698943195		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 2.0883423698943195 | validation: 3.055411669270155]
	TIME [epoch: 5.77 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.114435121506019		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 2.114435121506019 | validation: 2.9429028441926177]
	TIME [epoch: 5.73 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1318527910565095		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 2.1318527910565095 | validation: 3.093284209231863]
	TIME [epoch: 5.72 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.141312996959029		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 2.141312996959029 | validation: 2.9381265184011913]
	TIME [epoch: 5.72 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.112508342105782		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 2.112508342105782 | validation: 2.9391970513098857]
	TIME [epoch: 5.72 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1314506146488066		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 2.1314506146488066 | validation: 2.942319443929365]
	TIME [epoch: 5.72 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1081842075297277		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 2.1081842075297277 | validation: 2.965861460366543]
	TIME [epoch: 5.75 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.102578499365711		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 2.102578499365711 | validation: 3.0063806652435767]
	TIME [epoch: 5.74 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.143628542410124		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 2.143628542410124 | validation: 2.9389854263769393]
	TIME [epoch: 5.73 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1476655470897548		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 2.1476655470897548 | validation: 2.9669208471334305]
	TIME [epoch: 5.72 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.114070578163597		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 2.114070578163597 | validation: 2.961056523023012]
	TIME [epoch: 5.72 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1044859960227664		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 2.1044859960227664 | validation: 2.939522809052145]
	TIME [epoch: 5.72 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.097314731457021		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 2.097314731457021 | validation: 2.9909253146622725]
	TIME [epoch: 5.73 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.148362118374545		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 2.148362118374545 | validation: 3.1239820218428895]
	TIME [epoch: 5.77 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1788041899096977		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 2.1788041899096977 | validation: 3.2255759532987742]
	TIME [epoch: 5.73 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.177617464689253		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 2.177617464689253 | validation: 2.9462475673256825]
	TIME [epoch: 5.72 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.129369642596352		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 2.129369642596352 | validation: 2.9829159123076816]
	TIME [epoch: 5.73 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1307142269448867		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 2.1307142269448867 | validation: 2.9620672029026696]
	TIME [epoch: 5.72 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1223487375659635		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 2.1223487375659635 | validation: 2.958929496142863]
	TIME [epoch: 5.72 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1250797431859874		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 2.1250797431859874 | validation: 2.9746766644557776]
	TIME [epoch: 5.75 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0898934072436384		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 2.0898934072436384 | validation: 2.9425633622096097]
	TIME [epoch: 5.74 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0843132512980636		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 2.0843132512980636 | validation: 3.05337287272131]
	TIME [epoch: 5.72 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.135975930810995		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 2.135975930810995 | validation: 2.98998339534905]
	TIME [epoch: 5.72 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1054767612677026		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 2.1054767612677026 | validation: 2.959742983842294]
	TIME [epoch: 5.72 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.109346811293183		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 2.109346811293183 | validation: 2.951257252082811]
	TIME [epoch: 5.72 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.095229823840359		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 2.095229823840359 | validation: 2.983880250091944]
	TIME [epoch: 5.72 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.107359647350765		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 2.107359647350765 | validation: 2.986572696717396]
	TIME [epoch: 5.78 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1245689979912363		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 2.1245689979912363 | validation: 2.9870626259285267]
	TIME [epoch: 5.72 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1148278971252314		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 2.1148278971252314 | validation: 2.933147401723645]
	TIME [epoch: 5.72 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.091889346926093		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 2.091889346926093 | validation: 2.9332615266116875]
	TIME [epoch: 5.72 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1021857301201554		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 2.1021857301201554 | validation: 2.9429813174670483]
	TIME [epoch: 5.74 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.11111001825808		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 2.11111001825808 | validation: 2.9605303495866035]
	TIME [epoch: 5.72 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.145817377775513		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 2.145817377775513 | validation: 3.1647991931054906]
	TIME [epoch: 5.78 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246654130212356		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 2.246654130212356 | validation: 2.9450025966008395]
	TIME [epoch: 5.76 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1510547741867847		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 2.1510547741867847 | validation: 2.9795846859957114]
	TIME [epoch: 5.74 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1044028520219915		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 2.1044028520219915 | validation: 2.942920368033376]
	TIME [epoch: 5.74 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.133831040317044		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 2.133831040317044 | validation: 2.9816663074768246]
	TIME [epoch: 5.72 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.129391719384487		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 2.129391719384487 | validation: 2.99386873189851]
	TIME [epoch: 5.72 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0946548173777795		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 2.0946548173777795 | validation: 2.973528752917007]
	TIME [epoch: 5.72 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.098268303231901		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 2.098268303231901 | validation: 2.961766717099288]
	TIME [epoch: 5.77 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.093120668692132		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 2.093120668692132 | validation: 3.073741252466973]
	TIME [epoch: 5.72 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1558062312621087		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 2.1558062312621087 | validation: 2.9335404338968547]
	TIME [epoch: 5.72 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.103992639967561		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 2.103992639967561 | validation: 2.9748169126414714]
	TIME [epoch: 5.72 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0974336540845346		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 2.0974336540845346 | validation: 3.0537956976588654]
	TIME [epoch: 5.72 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1310056415082497		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 2.1310056415082497 | validation: 3.089023397583427]
	TIME [epoch: 5.72 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.142040849410995		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 2.142040849410995 | validation: 2.9800529961962106]
	TIME [epoch: 5.75 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.117311533960517		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 2.117311533960517 | validation: 3.0430489992462784]
	TIME [epoch: 5.74 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1233149326968292		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 2.1233149326968292 | validation: 2.9396283557910716]
	TIME [epoch: 5.72 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.101652057234416		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 2.101652057234416 | validation: 2.9824440056862125]
	TIME [epoch: 5.72 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.167831067689756		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 2.167831067689756 | validation: 2.99053415720697]
	TIME [epoch: 5.72 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1067047806428247		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 2.1067047806428247 | validation: 2.991806687477721]
	TIME [epoch: 5.72 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1372373682970367		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 2.1372373682970367 | validation: 2.958576678663031]
	TIME [epoch: 5.72 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1070146021204654		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 2.1070146021204654 | validation: 2.9469072799192886]
	TIME [epoch: 5.77 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0994571635180574		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 2.0994571635180574 | validation: 2.9689087273350108]
	TIME [epoch: 5.72 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.098852072133724		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 2.098852072133724 | validation: 2.966053432501775]
	TIME [epoch: 5.72 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.106029182012952		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 2.106029182012952 | validation: 2.9830065433597137]
	TIME [epoch: 5.72 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1116189037914075		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 2.1116189037914075 | validation: 2.936512855894356]
	TIME [epoch: 5.74 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1125153459428727		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 2.1125153459428727 | validation: 2.9731198493261526]
	TIME [epoch: 5.73 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.099575757137822		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 2.099575757137822 | validation: 2.9476326012130074]
	TIME [epoch: 5.75 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.103564872767086		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 2.103564872767086 | validation: 2.930567345235062]
	TIME [epoch: 5.75 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.137089675237683		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 2.137089675237683 | validation: 2.9261940049467587]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_891.pth
	Model improved!!!
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.093069456182369		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 2.093069456182369 | validation: 2.9170827389614638]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_892.pth
	Model improved!!!
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086340961389862		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 2.086340961389862 | validation: 2.928095756282584]
	TIME [epoch: 5.74 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.10472438865437		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 2.10472438865437 | validation: 2.9478094338729894]
	TIME [epoch: 5.74 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0897069425236436		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 2.0897069425236436 | validation: 3.0218499895715567]
	TIME [epoch: 5.76 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.108725733959396		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 2.108725733959396 | validation: 3.0120247890040033]
	TIME [epoch: 5.77 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.092462515763999		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 2.092462515763999 | validation: 3.0585554725116673]
	TIME [epoch: 5.75 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1299083460696644		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 2.1299083460696644 | validation: 2.9601648557311706]
	TIME [epoch: 5.74 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.102175752735665		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 2.102175752735665 | validation: 3.0009512127131472]
	TIME [epoch: 5.74 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1101508891537977		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 2.1101508891537977 | validation: 2.929701753976868]
	TIME [epoch: 5.74 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1418799867476794		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 2.1418799867476794 | validation: 3.109599480908286]
	TIME [epoch: 5.74 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1335812594966725		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 2.1335812594966725 | validation: 2.9213259293339013]
	TIME [epoch: 5.78 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.093862916661193		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 2.093862916661193 | validation: 2.9527712631700207]
	TIME [epoch: 5.75 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1118527110825025		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 2.1118527110825025 | validation: 2.9413925267010734]
	TIME [epoch: 5.74 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1212826869801438		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 2.1212826869801438 | validation: 3.071899284701891]
	TIME [epoch: 5.74 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1190909169157104		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 2.1190909169157104 | validation: 3.0299492099817007]
	TIME [epoch: 5.74 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1770629958726877		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 2.1770629958726877 | validation: 3.001874620366673]
	TIME [epoch: 5.74 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.107736343951535		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 2.107736343951535 | validation: 2.9349722803240073]
	TIME [epoch: 5.75 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1092540580261505		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 2.1092540580261505 | validation: 3.1422415990642483]
	TIME [epoch: 5.77 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1171156918839147		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 2.1171156918839147 | validation: 2.9685954005756194]
	TIME [epoch: 5.74 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094157739129114		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 2.094157739129114 | validation: 2.9443793136211944]
	TIME [epoch: 5.74 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.10582322456679		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 2.10582322456679 | validation: 2.9379517368584924]
	TIME [epoch: 5.74 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1143426947795887		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 2.1143426947795887 | validation: 2.965054533541636]
	TIME [epoch: 5.74 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0807136708694216		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 2.0807136708694216 | validation: 2.9825006536073637]
	TIME [epoch: 5.74 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1111139257058884		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 2.1111139257058884 | validation: 2.9729476645369015]
	TIME [epoch: 5.78 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1003039492300304		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 2.1003039492300304 | validation: 2.9942963740067525]
	TIME [epoch: 5.75 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0846467478674593		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 2.0846467478674593 | validation: 3.0489902102182116]
	TIME [epoch: 5.74 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.111131144639095		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 2.111131144639095 | validation: 3.0210481254414856]
	TIME [epoch: 5.74 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0953663709355013		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 2.0953663709355013 | validation: 3.002723460429589]
	TIME [epoch: 5.74 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1015990514403544		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 2.1015990514403544 | validation: 2.9290366377620676]
	TIME [epoch: 5.74 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086505258763993		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 2.086505258763993 | validation: 2.961192419332333]
	TIME [epoch: 5.76 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1408741551056427		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 2.1408741551056427 | validation: 3.101825561370361]
	TIME [epoch: 5.77 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1193097260889613		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 2.1193097260889613 | validation: 3.0478492197280014]
	TIME [epoch: 5.75 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1263255851848806		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 2.1263255851848806 | validation: 3.0059496124415905]
	TIME [epoch: 5.74 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085819904229946		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 2.085819904229946 | validation: 2.965678547615997]
	TIME [epoch: 5.74 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.080425731105007		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 2.080425731105007 | validation: 2.9393684003258955]
	TIME [epoch: 5.74 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0919696873951388		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 2.0919696873951388 | validation: 2.9266017905029837]
	TIME [epoch: 5.74 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0955817775853633		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 2.0955817775853633 | validation: 2.980327625571878]
	TIME [epoch: 5.78 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0848826631474173		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 2.0848826631474173 | validation: 2.9753023542119736]
	TIME [epoch: 5.75 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0954864177451844		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 2.0954864177451844 | validation: 2.949170667001174]
	TIME [epoch: 5.74 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0860981945846744		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 2.0860981945846744 | validation: 2.947596909540364]
	TIME [epoch: 5.74 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.102349099002738		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 2.102349099002738 | validation: 2.9730185547991903]
	TIME [epoch: 5.74 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.081550250862251		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 2.081550250862251 | validation: 3.034508245535269]
	TIME [epoch: 5.74 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.096855799963032		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 2.096855799963032 | validation: 2.9836666832434093]
	TIME [epoch: 5.75 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0863184495493154		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 2.0863184495493154 | validation: 2.947203327487827]
	TIME [epoch: 5.77 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.095316388139213		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 2.095316388139213 | validation: 2.982799669673144]
	TIME [epoch: 5.75 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.127550081557973		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 2.127550081557973 | validation: 2.9325868924170972]
	TIME [epoch: 5.74 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0948915694039303		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 2.0948915694039303 | validation: 3.0044092411409418]
	TIME [epoch: 5.74 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.090328647101489		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 2.090328647101489 | validation: 2.992388689347674]
	TIME [epoch: 5.74 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0885393304554674		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 2.0885393304554674 | validation: 3.002784177944874]
	TIME [epoch: 5.75 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1121922322936046		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 2.1121922322936046 | validation: 2.9716315753134688]
	TIME [epoch: 5.79 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0936295626761927		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 2.0936295626761927 | validation: 2.9450860188425385]
	TIME [epoch: 5.75 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0891663677879855		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 2.0891663677879855 | validation: 2.947735837855326]
	TIME [epoch: 5.74 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.078155521013629		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 2.078155521013629 | validation: 3.043665029511875]
	TIME [epoch: 5.74 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.107135467696068		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 2.107135467696068 | validation: 2.983655844943485]
	TIME [epoch: 5.74 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.076065309372277		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 2.076065309372277 | validation: 2.934210068255287]
	TIME [epoch: 5.74 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0911613061835324		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 2.0911613061835324 | validation: 2.9383216238337626]
	TIME [epoch: 5.76 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0812417872272877		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 2.0812417872272877 | validation: 2.9474549163195127]
	TIME [epoch: 5.77 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.078904944191895		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 2.078904944191895 | validation: 2.9982675802766563]
	TIME [epoch: 5.74 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0828829640225033		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 2.0828829640225033 | validation: 2.9319399035185922]
	TIME [epoch: 5.74 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.118396947325818		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 2.118396947325818 | validation: 2.9364757452668226]
	TIME [epoch: 5.74 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085148602602887		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 2.085148602602887 | validation: 2.9308993564102814]
	TIME [epoch: 5.74 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0856940860575426		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 2.0856940860575426 | validation: 2.9806981783908912]
	TIME [epoch: 5.74 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1183547684835338		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 2.1183547684835338 | validation: 2.992054922171845]
	TIME [epoch: 5.78 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1035415376982876		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 2.1035415376982876 | validation: 2.9223605891700073]
	TIME [epoch: 5.74 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.121716438256249		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 2.121716438256249 | validation: 2.9459241768224023]
	TIME [epoch: 5.74 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.096238647116554		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 2.096238647116554 | validation: 2.9750038166195782]
	TIME [epoch: 5.74 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0766730562070235		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 2.0766730562070235 | validation: 2.9450372025450453]
	TIME [epoch: 5.74 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.088004692501614		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 2.088004692501614 | validation: 2.9660205062187743]
	TIME [epoch: 5.74 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1099897948141293		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 2.1099897948141293 | validation: 2.9489963588783787]
	TIME [epoch: 5.77 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0893532613767776		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 2.0893532613767776 | validation: 3.0531113458916797]
	TIME [epoch: 5.76 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1023094451611843		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 2.1023094451611843 | validation: 2.9471938982646515]
	TIME [epoch: 5.74 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07652824714934		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 2.07652824714934 | validation: 2.947250418617666]
	TIME [epoch: 5.74 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1341537104586012		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 2.1341537104586012 | validation: 2.9621251372300934]
	TIME [epoch: 5.74 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1276717657157205		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 2.1276717657157205 | validation: 3.0272189096979365]
	TIME [epoch: 5.74 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.124381316279622		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 2.124381316279622 | validation: 2.9246891296442694]
	TIME [epoch: 5.74 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0879368884128935		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 2.0879368884128935 | validation: 2.9650452400838287]
	TIME [epoch: 5.79 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.075186555010244		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 2.075186555010244 | validation: 2.932218667473739]
	TIME [epoch: 5.74 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.091493070458684		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 2.091493070458684 | validation: 2.9950179542005504]
	TIME [epoch: 5.74 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.11475083481501		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 2.11475083481501 | validation: 2.9227780372675807]
	TIME [epoch: 5.74 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085240593432751		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 2.085240593432751 | validation: 2.997492669991441]
	TIME [epoch: 5.74 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0890985842556735		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 2.0890985842556735 | validation: 2.966711231130788]
	TIME [epoch: 5.74 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083653073601963		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 2.083653073601963 | validation: 2.9501622451853713]
	TIME [epoch: 5.77 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094182744103047		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 2.094182744103047 | validation: 2.9277285075995985]
	TIME [epoch: 5.76 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0916170031767765		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 2.0916170031767765 | validation: 2.9834016911049055]
	TIME [epoch: 5.75 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.103432682447433		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 2.103432682447433 | validation: 3.001399171191928]
	TIME [epoch: 5.74 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.109309340225163		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 2.109309340225163 | validation: 2.954946942797061]
	TIME [epoch: 5.74 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0863997494744186		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 2.0863997494744186 | validation: 2.9509998944700273]
	TIME [epoch: 5.74 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0782819656221836		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 2.0782819656221836 | validation: 2.951009749088546]
	TIME [epoch: 5.74 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.087476310232851		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 2.087476310232851 | validation: 2.9881686022887735]
	TIME [epoch: 5.79 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083511648462039		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 2.083511648462039 | validation: 2.953766336089659]
	TIME [epoch: 5.74 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0968235620003832		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 2.0968235620003832 | validation: 2.934209633766911]
	TIME [epoch: 5.74 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0990342073926334		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 2.0990342073926334 | validation: 3.003744635731774]
	TIME [epoch: 5.74 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1050978062385552		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 2.1050978062385552 | validation: 2.951660477871117]
	TIME [epoch: 5.74 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0889112176140467		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 2.0889112176140467 | validation: 2.9601619930319294]
	TIME [epoch: 5.74 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071199715846577		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 2.071199715846577 | validation: 2.9527844655721855]
	TIME [epoch: 5.77 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074460964775798		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 2.074460964775798 | validation: 2.9645746539865745]
	TIME [epoch: 5.76 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.104474725026371		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 2.104474725026371 | validation: 2.94711421019067]
	TIME [epoch: 5.74 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0837329788407937		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 2.0837329788407937 | validation: 2.9329752889188785]
	TIME [epoch: 5.74 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1003418136250236		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 2.1003418136250236 | validation: 2.9533880082415114]
	TIME [epoch: 5.74 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0865924598331924		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 2.0865924598331924 | validation: 2.9429464603374518]
	TIME [epoch: 5.74 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0848684790767136		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 2.0848684790767136 | validation: 2.9322437544188302]
	TIME [epoch: 5.74 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0784105605283516		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 2.0784105605283516 | validation: 2.937447932839366]
	TIME [epoch: 5.78 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085747484669511		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 2.085747484669511 | validation: 2.9764293139039943]
	TIME [epoch: 5.74 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0756269113220003		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 2.0756269113220003 | validation: 2.9260957096049096]
	TIME [epoch: 5.74 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0885817533190116		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 2.0885817533190116 | validation: 2.962564287926158]
	TIME [epoch: 5.74 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0784413838167524		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 2.0784413838167524 | validation: 2.9685491064063756]
	TIME [epoch: 5.74 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0778068163104235		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 2.0778068163104235 | validation: 2.9382780281335363]
	TIME [epoch: 5.74 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0823398827430015		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 2.0823398827430015 | validation: 2.9469723100032925]
	TIME [epoch: 5.77 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0823387604708383		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 2.0823387604708383 | validation: 3.019451826649082]
	TIME [epoch: 5.76 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0858237066515057		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 2.0858237066515057 | validation: 2.937660850696391]
	TIME [epoch: 5.75 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.087186213201564		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 2.087186213201564 | validation: 2.944120404322614]
	TIME [epoch: 5.74 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0885418893765664		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 2.0885418893765664 | validation: 3.0323097990762906]
	TIME [epoch: 5.74 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1316570179323975		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 2.1316570179323975 | validation: 2.957324291341462]
	TIME [epoch: 5.74 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.082351390931553		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 2.082351390931553 | validation: 2.929460024077904]
	TIME [epoch: 5.74 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0895567383327953		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 2.0895567383327953 | validation: 3.0096641749953723]
	TIME [epoch: 5.79 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0882766943162068		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 2.0882766943162068 | validation: 2.949854315773001]
	TIME [epoch: 5.74 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0965634617316002		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 2.0965634617316002 | validation: 2.9344045484120342]
	TIME [epoch: 5.74 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073314733125666		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 2.073314733125666 | validation: 2.9393939971475835]
	TIME [epoch: 5.74 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085635183400673		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 2.085635183400673 | validation: 2.965908684385936]
	TIME [epoch: 5.74 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.102316468004722		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 2.102316468004722 | validation: 2.9662901819675125]
	TIME [epoch: 5.74 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.082197554028084		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 2.082197554028084 | validation: 3.0807723755695116]
	TIME [epoch: 5.77 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1684834029881905		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 2.1684834029881905 | validation: 2.9667649331049915]
	TIME [epoch: 5.75 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0812909978304535		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 2.0812909978304535 | validation: 2.9950165969208706]
	TIME [epoch: 5.74 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0889111514554486		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 2.0889111514554486 | validation: 2.9408340824439336]
	TIME [epoch: 5.74 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0731257488997104		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 2.0731257488997104 | validation: 2.968997955850999]
	TIME [epoch: 5.74 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.076340740955265		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 2.076340740955265 | validation: 2.950613629978229]
	TIME [epoch: 5.74 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074713307298978		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 2.074713307298978 | validation: 2.925698727497775]
	TIME [epoch: 5.74 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0807733664699994		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 2.0807733664699994 | validation: 2.968907434566744]
	TIME [epoch: 5.78 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.082420997756244		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 2.082420997756244 | validation: 2.9403330087557733]
	TIME [epoch: 5.74 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1053365002610045		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 2.1053365002610045 | validation: 2.9519635298033053]
	TIME [epoch: 5.75 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.079876869617518		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 2.079876869617518 | validation: 2.958029658942211]
	TIME [epoch: 5.74 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0785616822523854		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 2.0785616822523854 | validation: 3.0084640517371803]
	TIME [epoch: 5.75 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0761686747508836		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 2.0761686747508836 | validation: 2.9484852389886522]
	TIME [epoch: 5.75 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083428212752285		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 2.083428212752285 | validation: 2.9204613758322218]
	TIME [epoch: 5.78 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0843632653620947		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 2.0843632653620947 | validation: 3.0057278669163225]
	TIME [epoch: 5.75 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0749739066359663		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 2.0749739066359663 | validation: 2.9388093449333805]
	TIME [epoch: 5.75 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0725019150595756		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 2.0725019150595756 | validation: 2.961419296078875]
	TIME [epoch: 5.75 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0805507231043006		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 2.0805507231043006 | validation: 2.9763005631287127]
	TIME [epoch: 5.75 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0835927265876713		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 2.0835927265876713 | validation: 2.945189970598293]
	TIME [epoch: 5.75 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.076276006910191		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 2.076276006910191 | validation: 2.9463844776096297]
	TIME [epoch: 5.76 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0829377716534445		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 2.0829377716534445 | validation: 2.9744333553747966]
	TIME [epoch: 5.78 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.118656787315567		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 2.118656787315567 | validation: 2.9484421469031354]
	TIME [epoch: 5.75 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0837303354391596		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 2.0837303354391596 | validation: 2.956848646957924]
	TIME [epoch: 5.75 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0793520973182207		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 2.0793520973182207 | validation: 2.972762803558155]
	TIME [epoch: 5.75 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0790594644835725		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 2.0790594644835725 | validation: 2.9711407444780185]
	TIME [epoch: 5.75 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0739806283449327		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 2.0739806283449327 | validation: 2.9890689666920807]
	TIME [epoch: 5.75 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0739441617067955		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 2.0739441617067955 | validation: 2.9237427473358752]
	TIME [epoch: 5.78 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0746073858703533		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 2.0746073858703533 | validation: 2.9274089895875086]
	TIME [epoch: 5.75 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0737262444312		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 2.0737262444312 | validation: 2.968294516914981]
	TIME [epoch: 5.75 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.090398516190481		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 2.090398516190481 | validation: 2.9372758619255355]
	TIME [epoch: 5.75 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083986849454779		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 2.083986849454779 | validation: 2.930214762051643]
	TIME [epoch: 5.74 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0829068520828438		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 2.0829068520828438 | validation: 2.917190030727648]
	TIME [epoch: 5.75 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0780094413792396		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 2.0780094413792396 | validation: 2.9879201793622703]
	TIME [epoch: 5.76 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1025713247284843		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 2.1025713247284843 | validation: 2.998989432378935]
	TIME [epoch: 5.81 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0872983723413605		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 2.0872983723413605 | validation: 2.91100582342243]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_1046.pth
	Model improved!!!
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085434733614461		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 2.085434733614461 | validation: 2.9238396940562423]
	TIME [epoch: 5.74 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0942752780837828		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 2.0942752780837828 | validation: 2.952843421863015]
	TIME [epoch: 5.74 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0884486869632575		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 2.0884486869632575 | validation: 2.9321409148722513]
	TIME [epoch: 5.72 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0976449241386925		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 2.0976449241386925 | validation: 2.925710815465798]
	TIME [epoch: 5.74 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0730605702204645		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 2.0730605702204645 | validation: 2.935991796880278]
	TIME [epoch: 5.77 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0789811472488213		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 2.0789811472488213 | validation: 2.9424518689665775]
	TIME [epoch: 5.75 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.075613278190014		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 2.075613278190014 | validation: 2.914086616546388]
	TIME [epoch: 5.74 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.092227453903195		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 2.092227453903195 | validation: 2.9374757321185143]
	TIME [epoch: 5.74 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.09018148477511		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 2.09018148477511 | validation: 2.9476358130884424]
	TIME [epoch: 5.74 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0805259631022004		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 2.0805259631022004 | validation: 2.947830452346009]
	TIME [epoch: 5.74 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0834619220086013		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 2.0834619220086013 | validation: 2.940286338086153]
	TIME [epoch: 5.77 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.081147265959081		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 2.081147265959081 | validation: 2.9435534803614645]
	TIME [epoch: 5.74 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.092862387486724		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 2.092862387486724 | validation: 2.9478768671314324]
	TIME [epoch: 5.73 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.072816647437744		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 2.072816647437744 | validation: 2.9325195641684902]
	TIME [epoch: 5.75 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0946982054217615		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 2.0946982054217615 | validation: 2.9357093928442284]
	TIME [epoch: 5.73 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.116523227054863		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 2.116523227054863 | validation: 2.9565155932765306]
	TIME [epoch: 5.73 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086328408398906		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 2.086328408398906 | validation: 2.994866228554321]
	TIME [epoch: 5.74 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.08051954744117		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 2.08051954744117 | validation: 2.927484480945003]
	TIME [epoch: 5.79 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0763916297425524		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 2.0763916297425524 | validation: 2.93957517774277]
	TIME [epoch: 5.75 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.088807762668578		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 2.088807762668578 | validation: 3.020238038046142]
	TIME [epoch: 5.74 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.11255053610216		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 2.11255053610216 | validation: 3.046737423475368]
	TIME [epoch: 5.74 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.088339506255303		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 2.088339506255303 | validation: 2.9658206815896135]
	TIME [epoch: 5.74 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083786160795005		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 2.083786160795005 | validation: 2.9285689637787278]
	TIME [epoch: 5.74 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0724911112309448		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 2.0724911112309448 | validation: 2.932869104838978]
	TIME [epoch: 5.77 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.097127002308872		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 2.097127002308872 | validation: 2.9430368363460118]
	TIME [epoch: 5.76 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0889903078956182		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 2.0889903078956182 | validation: 2.940306342712205]
	TIME [epoch: 5.74 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0782750856734404		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 2.0782750856734404 | validation: 2.933656911221044]
	TIME [epoch: 5.74 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0801655605196734		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 2.0801655605196734 | validation: 2.955205351260837]
	TIME [epoch: 5.74 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085972995594059		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 2.085972995594059 | validation: 2.936827699140605]
	TIME [epoch: 5.74 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.088248210501139		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 2.088248210501139 | validation: 2.922557839576923]
	TIME [epoch: 5.74 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.077921575298746		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 2.077921575298746 | validation: 2.943449155722352]
	TIME [epoch: 5.79 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0846833563088643		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 2.0846833563088643 | validation: 2.9317621781049827]
	TIME [epoch: 5.75 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0714263480208954		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 2.0714263480208954 | validation: 2.939344694278268]
	TIME [epoch: 5.74 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0814768217105466		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 2.0814768217105466 | validation: 2.9307212587569746]
	TIME [epoch: 5.74 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.091084836900664		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 2.091084836900664 | validation: 2.9277296747849566]
	TIME [epoch: 5.74 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0818621871226433		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 2.0818621871226433 | validation: 2.908883643156938]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_1082.pth
	Model improved!!!
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073523577841664		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 2.073523577841664 | validation: 2.968646694366745]
	TIME [epoch: 5.77 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0765201325932763		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 2.0765201325932763 | validation: 2.918017932847531]
	TIME [epoch: 5.75 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.08423930238822		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 2.08423930238822 | validation: 2.917977938189447]
	TIME [epoch: 5.74 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0831181559924445		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 2.0831181559924445 | validation: 2.957606183881251]
	TIME [epoch: 5.73 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0811514334617613		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 2.0811514334617613 | validation: 2.965440423508302]
	TIME [epoch: 5.74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0676085680532936		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 2.0676085680532936 | validation: 2.9296452374370463]
	TIME [epoch: 5.72 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0677843389477424		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 2.0677843389477424 | validation: 2.925000523534018]
	TIME [epoch: 5.75 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0673616604088743		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 2.0673616604088743 | validation: 2.9464714443458377]
	TIME [epoch: 5.76 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0821255228143105		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 2.0821255228143105 | validation: 2.9691965405245937]
	TIME [epoch: 5.74 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083138160812258		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 2.083138160812258 | validation: 2.979808630757253]
	TIME [epoch: 5.74 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.100609639772764		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 2.100609639772764 | validation: 2.963965635125152]
	TIME [epoch: 5.73 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1428707411145167		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 2.1428707411145167 | validation: 2.978386758723664]
	TIME [epoch: 5.74 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1067254630733134		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 2.1067254630733134 | validation: 2.948937956330388]
	TIME [epoch: 5.72 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0796224649087387		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 2.0796224649087387 | validation: 3.02768169401091]
	TIME [epoch: 5.78 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.107508463911963		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 2.107508463911963 | validation: 2.959783269506252]
	TIME [epoch: 5.73 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073246789919134		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 2.073246789919134 | validation: 2.9367250564741663]
	TIME [epoch: 5.74 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071427246959584		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 2.071427246959584 | validation: 2.9902080802699333]
	TIME [epoch: 5.73 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0900813083582634		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 2.0900813083582634 | validation: 2.939805274941143]
	TIME [epoch: 5.74 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073845282392637		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 2.073845282392637 | validation: 2.9918436603606215]
	TIME [epoch: 5.72 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074737076110582		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 2.074737076110582 | validation: 2.9314198734343826]
	TIME [epoch: 5.75 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0725803499264113		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 2.0725803499264113 | validation: 2.929709756430873]
	TIME [epoch: 5.76 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086882784135448		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 2.086882784135448 | validation: 2.960073015819044]
	TIME [epoch: 5.74 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0782821166308194		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 2.0782821166308194 | validation: 2.9339117189891324]
	TIME [epoch: 5.74 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0710876927288373		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 2.0710876927288373 | validation: 2.942218615463228]
	TIME [epoch: 5.74 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071536717498139		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 2.071536717498139 | validation: 2.962169641974972]
	TIME [epoch: 5.73 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071866007959591		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 2.071866007959591 | validation: 2.9508111044489467]
	TIME [epoch: 5.73 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0826480849041857		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 2.0826480849041857 | validation: 2.9491780907484655]
	TIME [epoch: 5.76 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.084327380620356		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 2.084327380620356 | validation: 2.96848369751062]
	TIME [epoch: 5.74 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.079685500729443		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 2.079685500729443 | validation: 2.949895371958137]
	TIME [epoch: 5.73 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083337374432104		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 2.083337374432104 | validation: 3.0994418018155363]
	TIME [epoch: 5.73 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1198299992776946		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 2.1198299992776946 | validation: 2.933675199618258]
	TIME [epoch: 5.73 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069282198866863		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 2.069282198866863 | validation: 2.9662789689811553]
	TIME [epoch: 5.73 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0741836516008507		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 2.0741836516008507 | validation: 2.9169957096620296]
	TIME [epoch: 5.74 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0797370665091366		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 2.0797370665091366 | validation: 2.992952933571993]
	TIME [epoch: 5.77 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.082578610624652		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 2.082578610624652 | validation: 3.0165103581418373]
	TIME [epoch: 5.72 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085149059851492		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 2.085149059851492 | validation: 2.9345554493896064]
	TIME [epoch: 5.73 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0691239650248296		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 2.0691239650248296 | validation: 2.924697794327173]
	TIME [epoch: 5.74 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066821424090277		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 2.066821424090277 | validation: 2.9378418051563036]
	TIME [epoch: 5.73 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094718102088578		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 2.094718102088578 | validation: 2.967936135923659]
	TIME [epoch: 5.74 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0756118163982107		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 2.0756118163982107 | validation: 2.9449142178468684]
	TIME [epoch: 5.78 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0710338922567755		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 2.0710338922567755 | validation: 2.927566153785865]
	TIME [epoch: 5.74 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069086774924754		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 2.069086774924754 | validation: 2.985323982892504]
	TIME [epoch: 5.72 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0802891507523738		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 2.0802891507523738 | validation: 2.959013291278505]
	TIME [epoch: 5.72 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.079251527816346		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 2.079251527816346 | validation: 2.9435172764425364]
	TIME [epoch: 5.73 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0687459385569		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 2.0687459385569 | validation: 2.9460313132410714]
	TIME [epoch: 5.72 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073390348691948		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 2.073390348691948 | validation: 2.963241745812649]
	TIME [epoch: 5.74 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0697891356425075		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 2.0697891356425075 | validation: 2.9355224389459447]
	TIME [epoch: 5.75 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.115572767954432		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 2.115572767954432 | validation: 2.9483025570704693]
	TIME [epoch: 5.73 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0745908713782852		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 2.0745908713782852 | validation: 2.96030867190992]
	TIME [epoch: 5.72 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.070084570548204		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 2.070084570548204 | validation: 2.9481791154280548]
	TIME [epoch: 5.73 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0760993846272733		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 2.0760993846272733 | validation: 2.9658594826219873]
	TIME [epoch: 5.73 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0861183805638097		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 2.0861183805638097 | validation: 2.9700157291933493]
	TIME [epoch: 5.73 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0749935643636266		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 2.0749935643636266 | validation: 2.987630931055527]
	TIME [epoch: 5.78 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067745113463217		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 2.067745113463217 | validation: 2.946810765747955]
	TIME [epoch: 5.73 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0693065176751535		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 2.0693065176751535 | validation: 2.9711339929127734]
	TIME [epoch: 5.74 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066507996600636		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 2.066507996600636 | validation: 3.0181627433400657]
	TIME [epoch: 5.72 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0868075744299337		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 2.0868075744299337 | validation: 2.942040642411047]
	TIME [epoch: 5.73 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0840126111982102		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 2.0840126111982102 | validation: 2.9706229248045295]
	TIME [epoch: 5.74 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.103057210944498		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 2.103057210944498 | validation: 2.9535587480552112]
	TIME [epoch: 5.73 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0683640109717727		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 2.0683640109717727 | validation: 2.940809169676195]
	TIME [epoch: 5.77 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0850664500895824		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 2.0850664500895824 | validation: 2.981141304914627]
	TIME [epoch: 5.72 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1019512863356455		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 2.1019512863356455 | validation: 2.9658979076802336]
	TIME [epoch: 5.72 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0950208497286638		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 2.0950208497286638 | validation: 2.9644138986960265]
	TIME [epoch: 5.72 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1041014950189063		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 2.1041014950189063 | validation: 2.944152824851354]
	TIME [epoch: 5.73 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0711133682845655		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 2.0711133682845655 | validation: 2.9580591456932415]
	TIME [epoch: 5.72 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07192505499365		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 2.07192505499365 | validation: 2.94482188439516]
	TIME [epoch: 5.77 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0748375448476106		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 2.0748375448476106 | validation: 2.944053958091738]
	TIME [epoch: 5.73 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07756364030005		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 2.07756364030005 | validation: 2.940538252068585]
	TIME [epoch: 5.73 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.08230590475168		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 2.08230590475168 | validation: 2.968972110284206]
	TIME [epoch: 5.74 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.084795757799702		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 2.084795757799702 | validation: 2.9270493528120496]
	TIME [epoch: 5.73 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074454419839423		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 2.074454419839423 | validation: 3.018124003669931]
	TIME [epoch: 5.74 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.101663245059121		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 2.101663245059121 | validation: 2.9763498594139794]
	TIME [epoch: 5.75 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0679250355556125		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 2.0679250355556125 | validation: 2.9360102909497345]
	TIME [epoch: 5.75 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0648982452930977		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 2.0648982452930977 | validation: 2.9504943803000914]
	TIME [epoch: 5.73 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0859169629982093		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 2.0859169629982093 | validation: 2.9440582153781385]
	TIME [epoch: 5.73 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.107097545917673		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 2.107097545917673 | validation: 2.90678102944963]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r4_20240310_010408/states/model_tr_study201_1158.pth
	Model improved!!!
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.08388549087017		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 2.08388549087017 | validation: 2.9800056568649973]
	TIME [epoch: 5.72 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0702365795158526		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 2.0702365795158526 | validation: 2.924262600280238]
	TIME [epoch: 5.72 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0705907399853523		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 2.0705907399853523 | validation: 2.959465406523879]
	TIME [epoch: 5.76 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.078911538107931		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 2.078911538107931 | validation: 2.9894087920089945]
	TIME [epoch: 5.74 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0728955920673684		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 2.0728955920673684 | validation: 2.953905450398373]
	TIME [epoch: 5.72 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064296452944899		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 2.064296452944899 | validation: 2.934927796007697]
	TIME [epoch: 5.72 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.070271074352129		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 2.070271074352129 | validation: 2.9477876902771096]
	TIME [epoch: 5.72 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0728440076766383		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 2.0728440076766383 | validation: 2.9238702301754467]
	TIME [epoch: 5.73 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0602346642844127		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 2.0602346642844127 | validation: 2.9533826392288485]
	TIME [epoch: 5.76 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066391554699166		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 2.066391554699166 | validation: 2.9832204700863736]
	TIME [epoch: 5.73 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069411356791414		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 2.069411356791414 | validation: 2.9351860428280707]
	TIME [epoch: 5.72 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.075310387558694		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 2.075310387558694 | validation: 2.953953568011723]
	TIME [epoch: 5.73 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066961927276915		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 2.066961927276915 | validation: 2.9247826926616955]
	TIME [epoch: 5.71 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0777188767250383		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 2.0777188767250383 | validation: 2.9366122007887574]
	TIME [epoch: 5.73 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0659240382059165		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 2.0659240382059165 | validation: 2.993217209167398]
	TIME [epoch: 5.74 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0868325465951716		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 2.0868325465951716 | validation: 2.9593281337941244]
	TIME [epoch: 5.77 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0643408709446556		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 2.0643408709446556 | validation: 2.9401863495378895]
	TIME [epoch: 5.74 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071008539556436		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 2.071008539556436 | validation: 2.9466737538867562]
	TIME [epoch: 5.72 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0685816150987293		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 2.0685816150987293 | validation: 2.970304524420118]
	TIME [epoch: 5.74 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065338015742546		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 2.065338015742546 | validation: 2.934014960953026]
	TIME [epoch: 5.72 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0649845996262113		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 2.0649845996262113 | validation: 2.953042488465419]
	TIME [epoch: 5.74 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0715033601803876		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 2.0715033601803876 | validation: 2.9473379199526604]
	TIME [epoch: 5.75 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.092432189922153		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 2.092432189922153 | validation: 2.9552564770073118]
	TIME [epoch: 5.73 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067444697438412		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 2.067444697438412 | validation: 2.9364476484449757]
	TIME [epoch: 5.73 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0697648939038267		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 2.0697648939038267 | validation: 2.9488972290370827]
	TIME [epoch: 5.72 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0770150652655763		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 2.0770150652655763 | validation: 2.939849273215216]
	TIME [epoch: 5.73 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.068146890230239		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 2.068146890230239 | validation: 2.9897647264868614]
	TIME [epoch: 5.72 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0918783700672203		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 2.0918783700672203 | validation: 2.976933895030212]
	TIME [epoch: 5.73 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069264881923649		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 2.069264881923649 | validation: 2.937437524677908]
	TIME [epoch: 5.77 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0748138036932264		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 2.0748138036932264 | validation: 2.9410613020301604]
	TIME [epoch: 5.73 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0722965673776375		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 2.0722965673776375 | validation: 3.0019007629710632]
	TIME [epoch: 5.72 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0919202508818886		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 2.0919202508818886 | validation: 2.943830939578709]
	TIME [epoch: 5.73 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073847737984725		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 2.073847737984725 | validation: 2.953361496288548]
	TIME [epoch: 5.72 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063657537389847		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 2.063657537389847 | validation: 2.9401008254590955]
	TIME [epoch: 5.74 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0682083716291384		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 2.0682083716291384 | validation: 2.9408095590939265]
	TIME [epoch: 5.76 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06954040135297		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 2.06954040135297 | validation: 2.9489236412427107]
	TIME [epoch: 5.75 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0765335866036905		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 2.0765335866036905 | validation: 2.965399327206533]
	TIME [epoch: 5.73 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0680806208814544		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 2.0680806208814544 | validation: 2.9326999036203216]
	TIME [epoch: 5.72 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0752979939759078		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 2.0752979939759078 | validation: 2.952088869762679]
	TIME [epoch: 5.73 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0694730684813742		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 2.0694730684813742 | validation: 2.9608407455094308]
	TIME [epoch: 5.74 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07161788750647		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 2.07161788750647 | validation: 2.9377047407078067]
	TIME [epoch: 5.72 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067312089390369		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 2.067312089390369 | validation: 2.997837339526958]
	TIME [epoch: 5.78 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094297109914966		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 2.094297109914966 | validation: 2.9784382393468105]
	TIME [epoch: 5.72 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0830617973497514		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 2.0830617973497514 | validation: 2.9455544286241127]
	TIME [epoch: 5.74 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0636521004963306		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 2.0636521004963306 | validation: 2.9493178779051066]
	TIME [epoch: 5.72 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066504843157197		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 2.066504843157197 | validation: 2.920945285258581]
	TIME [epoch: 5.74 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.082598467628227		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 2.082598467628227 | validation: 3.031751124429278]
	TIME [epoch: 5.73 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1069978763819583		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 2.1069978763819583 | validation: 2.9852502263888416]
	TIME [epoch: 5.77 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0695588865809453		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 2.0695588865809453 | validation: 2.950275169184672]
	TIME [epoch: 5.75 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0674634955114186		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 2.0674634955114186 | validation: 2.93851626585745]
	TIME [epoch: 5.74 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063559430770396		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 2.063559430770396 | validation: 2.9333782844097596]
	TIME [epoch: 5.74 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0631132718875764		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 2.0631132718875764 | validation: 2.9309932081061385]
	TIME [epoch: 5.74 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0679248713536156		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 2.0679248713536156 | validation: 2.9907061904608145]
	TIME [epoch: 5.73 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069730658382946		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 2.069730658382946 | validation: 2.9773180226376583]
	TIME [epoch: 5.74 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069742408770546		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 2.069742408770546 | validation: 2.936055393075155]
	TIME [epoch: 5.78 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071994171736073		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 2.071994171736073 | validation: 2.9748861720436204]
	TIME [epoch: 5.73 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0836933546592435		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 2.0836933546592435 | validation: 2.950133823158925]
	TIME [epoch: 5.72 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07000190456911		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 2.07000190456911 | validation: 2.951569612026091]
	TIME [epoch: 5.73 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0708269026202286		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 2.0708269026202286 | validation: 2.948875588460045]
	TIME [epoch: 5.74 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0749901379061324		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 2.0749901379061324 | validation: 2.9371033322615574]
	TIME [epoch: 5.73 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.078037162906543		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 2.078037162906543 | validation: 2.943117673775627]
	TIME [epoch: 5.77 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059480857301171		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 2.059480857301171 | validation: 2.953281387684043]
	TIME [epoch: 5.75 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0853829364729406		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 2.0853829364729406 | validation: 2.9836426574894666]
	TIME [epoch: 5.74 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0779837985718332		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 2.0779837985718332 | validation: 2.950033594836083]
	TIME [epoch: 5.74 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061553774960041		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 2.061553774960041 | validation: 2.9377476058054124]
	TIME [epoch: 5.74 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063376038727063		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 2.063376038727063 | validation: 2.9536458952917766]
	TIME [epoch: 5.74 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0594614809917826		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 2.0594614809917826 | validation: 2.9493317534566548]
	TIME [epoch: 5.73 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0653194043009324		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 2.0653194043009324 | validation: 2.9865512136813117]
	TIME [epoch: 5.78 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067056102910062		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 2.067056102910062 | validation: 2.9471850158907853]
	TIME [epoch: 5.74 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0734112352152416		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 2.0734112352152416 | validation: 2.952385101244904]
	TIME [epoch: 5.73 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074773887702398		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 2.074773887702398 | validation: 2.9664299435758337]
	TIME [epoch: 5.72 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0683081271121297		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 2.0683081271121297 | validation: 2.9436497827512693]
	TIME [epoch: 5.73 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071009251358094		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 2.071009251358094 | validation: 2.9331583847117795]
	TIME [epoch: 5.72 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065936158101829		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 2.065936158101829 | validation: 2.9400174324474633]
	TIME [epoch: 5.77 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0681386833472257		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 2.0681386833472257 | validation: 2.9221338412182276]
	TIME [epoch: 5.74 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0731262625439335		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 2.0731262625439335 | validation: 2.9356044098296925]
	TIME [epoch: 5.72 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064599253815179		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 2.064599253815179 | validation: 2.9587560849042727]
	TIME [epoch: 5.73 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0650979889592023		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 2.0650979889592023 | validation: 2.9165767652145997]
	TIME [epoch: 5.72 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.068362389568262		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 2.068362389568262 | validation: 2.9497346644666846]
	TIME [epoch: 5.73 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086667142232302		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 2.086667142232302 | validation: 2.9324689094169902]
	TIME [epoch: 5.74 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0683640210489753		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 2.0683640210489753 | validation: 2.9464245421773514]
	TIME [epoch: 5.76 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0664241565496617		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 2.0664241565496617 | validation: 2.921758511197723]
	TIME [epoch: 5.74 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086424007490951		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 2.086424007490951 | validation: 2.916447643040152]
	TIME [epoch: 5.72 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0662682951192197		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 2.0662682951192197 | validation: 2.975546293684861]
	TIME [epoch: 5.72 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0697489675659435		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 2.0697489675659435 | validation: 2.9287438205975356]
	TIME [epoch: 5.72 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0570038819481824		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 2.0570038819481824 | validation: 2.9506735596819293]
	TIME [epoch: 5.73 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0588800435914063		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 2.0588800435914063 | validation: 2.94930242753813]
	TIME [epoch: 5.77 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0663035192219015		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 2.0663035192219015 | validation: 2.967043009296375]
	TIME [epoch: 5.74 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0632978637456034		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 2.0632978637456034 | validation: 2.9419053366261343]
	TIME [epoch: 5.73 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061054115741922		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 2.061054115741922 | validation: 2.9640100335271877]
	TIME [epoch: 5.74 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063880556299732		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 2.063880556299732 | validation: 2.923758289795824]
	TIME [epoch: 5.73 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0641677204411093		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 2.0641677204411093 | validation: 2.9511948478955765]
	TIME [epoch: 5.74 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.068962021970176		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 2.068962021970176 | validation: 2.920423942463703]
	TIME [epoch: 5.74 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067896851305697		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 2.067896851305697 | validation: 2.949782134557277]
	TIME [epoch: 5.77 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059575287111305		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 2.059575287111305 | validation: 2.946879614598446]
	TIME [epoch: 5.74 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0611337676700443		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 2.0611337676700443 | validation: 2.949634635568575]
	TIME [epoch: 5.73 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063377358754801		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 2.063377358754801 | validation: 2.9561635419925625]
	TIME [epoch: 5.73 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0634867513374364		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 2.0634867513374364 | validation: 2.9288606244991087]
	TIME [epoch: 5.74 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0609811452461058		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 2.0609811452461058 | validation: 2.97883694905422]
	TIME [epoch: 5.73 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06600164036855		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 2.06600164036855 | validation: 2.9161009926283294]
	TIME [epoch: 5.79 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065985690858489		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 2.065985690858489 | validation: 2.9382166360374735]
	TIME [epoch: 5.73 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0689379114898054		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 2.0689379114898054 | validation: 2.959805627748458]
	TIME [epoch: 5.74 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0639511546553218		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 2.0639511546553218 | validation: 2.943399254341521]
	TIME [epoch: 5.72 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0689844209655326		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 2.0689844209655326 | validation: 2.9303535383498787]
	TIME [epoch: 5.72 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0700511793030056		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 2.0700511793030056 | validation: 2.973704322183279]
	TIME [epoch: 5.72 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0797457397228047		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 2.0797457397228047 | validation: 2.9802623547600984]
	TIME [epoch: 5.74 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0782145916478774		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 2.0782145916478774 | validation: 2.9557422784667184]
	TIME [epoch: 5.75 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.100859409711677		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 2.100859409711677 | validation: 2.9630668668128357]
	TIME [epoch: 5.73 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.072587997059728		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 2.072587997059728 | validation: 2.936692890568107]
	TIME [epoch: 5.73 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065292668027157		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 2.065292668027157 | validation: 2.9328457827964587]
	TIME [epoch: 5.73 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071520468419915		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 2.071520468419915 | validation: 2.9132472738613298]
	TIME [epoch: 5.72 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0655067595891965		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 2.0655067595891965 | validation: 2.958836192908617]
	TIME [epoch: 5.74 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0802121624821526		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 2.0802121624821526 | validation: 2.954658823024798]
	TIME [epoch: 5.77 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0854022594640145		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 2.0854022594640145 | validation: 2.9345278515872826]
	TIME [epoch: 5.73 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0653746746538104		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 2.0653746746538104 | validation: 2.936748327136535]
	TIME [epoch: 5.74 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059043940735711		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 2.059043940735711 | validation: 2.941099592311886]
	TIME [epoch: 5.74 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0630918921100894		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 2.0630918921100894 | validation: 2.9642827668789393]
	TIME [epoch: 5.72 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071625483272244		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 2.071625483272244 | validation: 2.9603705093859936]
	TIME [epoch: 5.72 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0859821003003227		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 2.0859821003003227 | validation: 2.9517672981738823]
	TIME [epoch: 5.74 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0580483506791367		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 2.0580483506791367 | validation: 2.941681945219685]
	TIME [epoch: 5.75 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0607299987330223		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 2.0607299987330223 | validation: 2.9594037734615433]
	TIME [epoch: 5.74 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060088124432014		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 2.060088124432014 | validation: 2.930230299611056]
	TIME [epoch: 5.72 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06095870288071		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 2.06095870288071 | validation: 2.9259675186197978]
	TIME [epoch: 5.74 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067377282404166		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 2.067377282404166 | validation: 2.9370685384155775]
	TIME [epoch: 5.74 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057488377366634		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 2.057488377366634 | validation: 2.935761357693949]
	TIME [epoch: 5.73 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0577276209413453		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 2.0577276209413453 | validation: 2.930943996862114]
	TIME [epoch: 5.77 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06447847398916		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 2.06447847398916 | validation: 2.9212941407012742]
	TIME [epoch: 5.73 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0653884148406636		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 2.0653884148406636 | validation: 2.9307872716082084]
	TIME [epoch: 5.73 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0658215686829977		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 2.0658215686829977 | validation: 2.9511060046198594]
	TIME [epoch: 5.73 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062369846139216		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 2.062369846139216 | validation: 2.9230384099103235]
	TIME [epoch: 5.72 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0596677535141934		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 2.0596677535141934 | validation: 2.9264419963724646]
	TIME [epoch: 5.73 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064186665181676		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 2.064186665181676 | validation: 2.9452769764078375]
	TIME [epoch: 5.74 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0601557313043166		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 2.0601557313043166 | validation: 2.956452563525239]
	TIME [epoch: 5.75 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062117232120162		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 2.062117232120162 | validation: 2.9449908226583243]
	TIME [epoch: 5.72 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065938807730245		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 2.065938807730245 | validation: 2.953726374265758]
	TIME [epoch: 5.72 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0633160380816955		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 2.0633160380816955 | validation: 2.9550625478844315]
	TIME [epoch: 5.72 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062847709420865		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 2.062847709420865 | validation: 2.926806720208347]
	TIME [epoch: 5.72 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.070817316961529		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 2.070817316961529 | validation: 2.935996559468535]
	TIME [epoch: 5.74 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0612047874572332		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 2.0612047874572332 | validation: 2.947085705346342]
	TIME [epoch: 5.77 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063632661883518		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 2.063632661883518 | validation: 2.9224713151866006]
	TIME [epoch: 5.74 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0682032736186047		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 2.0682032736186047 | validation: 2.976396891248034]
	TIME [epoch: 5.72 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.068272585342971		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 2.068272585342971 | validation: 2.943787854012061]
	TIME [epoch: 5.73 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0614572076478597		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 2.0614572076478597 | validation: 2.9225615499104993]
	TIME [epoch: 5.72 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0643469367809564		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 2.0643469367809564 | validation: 2.911679336263266]
	TIME [epoch: 5.74 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059187555405445		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 2.059187555405445 | validation: 2.9516289063751184]
	TIME [epoch: 5.74 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066730210017901		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 2.066730210017901 | validation: 2.9236163785936355]
	TIME [epoch: 5.75 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0640000736681725		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 2.0640000736681725 | validation: 2.9260299236283402]
	TIME [epoch: 5.73 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067053069146956		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 2.067053069146956 | validation: 3.001586260277337]
	TIME [epoch: 5.72 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0731626473494704		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 2.0731626473494704 | validation: 2.9616877346535286]
	TIME [epoch: 5.74 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0590092195186838		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 2.0590092195186838 | validation: 2.938857579240795]
	TIME [epoch: 5.72 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062245584726342		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 2.062245584726342 | validation: 2.9373997119023967]
	TIME [epoch: 5.73 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0730157292962135		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 2.0730157292962135 | validation: 2.9371239337566624]
	TIME [epoch: 5.77 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0600932679119572		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 2.0600932679119572 | validation: 2.9540590897087236]
	TIME [epoch: 5.73 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059152246056388		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 2.059152246056388 | validation: 2.955965953643988]
	TIME [epoch: 5.73 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0567332353493164		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 2.0567332353493164 | validation: 2.9501452611067522]
	TIME [epoch: 5.72 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0587101710971645		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 2.0587101710971645 | validation: 2.940754893688063]
	TIME [epoch: 5.72 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0676230855874165		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 2.0676230855874165 | validation: 2.9826585614942505]
	TIME [epoch: 5.72 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066711331997673		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 2.066711331997673 | validation: 2.9395185134192388]
	TIME [epoch: 5.75 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0631138363308352		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 2.0631138363308352 | validation: 2.9403541932904638]
	TIME [epoch: 5.77 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0627538687182634		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 2.0627538687182634 | validation: 3.0170751440531336]
	TIME [epoch: 5.74 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0753748808537447		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 2.0753748808537447 | validation: 2.934287977141254]
	TIME [epoch: 5.73 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057387337708274		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 2.057387337708274 | validation: 2.9528869539934703]
	TIME [epoch: 5.72 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0670340549331834		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 2.0670340549331834 | validation: 2.9865173729969503]
	TIME [epoch: 5.73 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0614829871217646		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 2.0614829871217646 | validation: 2.946401056134862]
	TIME [epoch: 5.73 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0590091474744874		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 2.0590091474744874 | validation: 2.9569318340644326]
	TIME [epoch: 5.77 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0666682168956845		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 2.0666682168956845 | validation: 2.9529408600937415]
	TIME [epoch: 5.73 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0642873883530877		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 2.0642873883530877 | validation: 2.9121785297468024]
	TIME [epoch: 5.72 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0635813277202195		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 2.0635813277202195 | validation: 2.9646543156854035]
	TIME [epoch: 5.73 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0651967699687774		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 2.0651967699687774 | validation: 2.934576055224766]
	TIME [epoch: 5.72 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0623327028048823		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 2.0623327028048823 | validation: 2.975033322667839]
	TIME [epoch: 5.73 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0654510269890363		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 2.0654510269890363 | validation: 2.9545422930199816]
	TIME [epoch: 5.77 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063321277929459		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 2.063321277929459 | validation: 2.9375285694619926]
	TIME [epoch: 5.75 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0587110468338876		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 2.0587110468338876 | validation: 2.9522299709607673]
	TIME [epoch: 5.74 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0663699859306903		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 2.0663699859306903 | validation: 2.9315958239733386]
	TIME [epoch: 5.72 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0591622765515387		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 2.0591622765515387 | validation: 2.931237744358081]
	TIME [epoch: 5.73 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0633762631463344		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 2.0633762631463344 | validation: 2.931198381889451]
	TIME [epoch: 5.73 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0617215053703792		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 2.0617215053703792 | validation: 2.9417327023103765]
	TIME [epoch: 5.74 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066730509928659		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 2.066730509928659 | validation: 2.9619055587813774]
	TIME [epoch: 5.78 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067643203753214		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 2.067643203753214 | validation: 2.9434704121194812]
	TIME [epoch: 5.74 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06072667410986		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 2.06072667410986 | validation: 2.94798691008886]
	TIME [epoch: 5.72 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0622818721511127		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 2.0622818721511127 | validation: 2.939213893564747]
	TIME [epoch: 5.73 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069047184938515		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 2.069047184938515 | validation: 2.9606924836389306]
	TIME [epoch: 5.72 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063124549726857		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 2.063124549726857 | validation: 2.9439358557866586]
	TIME [epoch: 5.73 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060616228416523		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 2.060616228416523 | validation: 2.9381875467753287]
	TIME [epoch: 5.76 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061143692441753		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 2.061143692441753 | validation: 2.94141898056699]
	TIME [epoch: 5.75 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061500988064322		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 2.061500988064322 | validation: 2.9945378737218813]
	TIME [epoch: 5.73 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0732427246689813		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 2.0732427246689813 | validation: 2.944235793110867]
	TIME [epoch: 5.73 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06318599665289		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 2.06318599665289 | validation: 2.9436944959747064]
	TIME [epoch: 5.72 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060084638366206		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 2.060084638366206 | validation: 2.9582461606476516]
	TIME [epoch: 5.73 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0608068883113515		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 2.0608068883113515 | validation: 2.93468080721769]
	TIME [epoch: 5.73 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06295349603343		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 2.06295349603343 | validation: 2.934698755000696]
	TIME [epoch: 5.78 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05999906586766		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 2.05999906586766 | validation: 2.943007327634621]
	TIME [epoch: 5.73 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0629121238976844		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 2.0629121238976844 | validation: 2.9709531877084827]
	TIME [epoch: 5.73 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0607089464375563		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 2.0607089464375563 | validation: 2.950395472464397]
	TIME [epoch: 5.72 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060443382701131		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 2.060443382701131 | validation: 2.9275022735984098]
	TIME [epoch: 5.73 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062444732735908		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 2.062444732735908 | validation: 2.925683690098249]
	TIME [epoch: 5.72 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0556298284237036		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 2.0556298284237036 | validation: 2.9440690341498885]
	TIME [epoch: 5.76 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0604490495172585		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 2.0604490495172585 | validation: 2.938365721591302]
	TIME [epoch: 5.75 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0575488865771874		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 2.0575488865771874 | validation: 2.934069293145674]
	TIME [epoch: 5.73 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0603213006381917		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 2.0603213006381917 | validation: 2.952883764568843]
	TIME [epoch: 5.72 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062929476351203		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 2.062929476351203 | validation: 2.929766819949725]
	TIME [epoch: 5.74 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05943240648911		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 2.05943240648911 | validation: 2.943061929179628]
	TIME [epoch: 5.73 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0592299736200004		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 2.0592299736200004 | validation: 2.929798861263708]
	TIME [epoch: 5.72 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06771931228006		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 2.06771931228006 | validation: 2.9167698024966926]
	TIME [epoch: 5.77 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0614134514802953		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 2.0614134514802953 | validation: 2.927961506670247]
	TIME [epoch: 5.72 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0590659299151386		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 2.0590659299151386 | validation: 2.9733952721091415]
	TIME [epoch: 5.73 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0652216554237546		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 2.0652216554237546 | validation: 2.959056725761931]
	TIME [epoch: 5.72 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0640453774280165		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 2.0640453774280165 | validation: 2.949132673243672]
	TIME [epoch: 5.72 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066596980864735		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 2.066596980864735 | validation: 2.9533522958736125]
	TIME [epoch: 5.74 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.068405037781003		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 2.068405037781003 | validation: 2.9500601742495283]
	TIME [epoch: 5.76 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0582237176952387		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 2.0582237176952387 | validation: 2.9563259884951436]
	TIME [epoch: 5.75 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059708451878727		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 2.059708451878727 | validation: 2.9457726758325458]
	TIME [epoch: 5.73 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0593427698269546		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 2.0593427698269546 | validation: 2.939783967233432]
	TIME [epoch: 5.73 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063090526289924		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 2.063090526289924 | validation: 2.9494475749836067]
	TIME [epoch: 5.74 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057428942007687		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 2.057428942007687 | validation: 2.945355622473106]
	TIME [epoch: 5.72 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0572590374651996		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 2.0572590374651996 | validation: 2.9270652794580476]
	TIME [epoch: 5.74 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0602793614277473		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 2.0602793614277473 | validation: 2.9595585935498145]
	TIME [epoch: 5.77 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0574354076946006		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 2.0574354076946006 | validation: 2.9324066455130526]
	TIME [epoch: 5.73 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07614247460267		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 2.07614247460267 | validation: 2.9437577920613114]
	TIME [epoch: 5.73 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073590569731484		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 2.073590569731484 | validation: 2.9464548097098704]
	TIME [epoch: 5.73 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0623389826244107		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 2.0623389826244107 | validation: 2.9551504218296585]
	TIME [epoch: 5.73 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05873531984426		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 2.05873531984426 | validation: 2.9538032161320564]
	TIME [epoch: 5.73 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055810759661474		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 2.055810759661474 | validation: 2.9318430280957792]
	TIME [epoch: 5.77 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0639820677730465		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 2.0639820677730465 | validation: 2.9194761679316024]
	TIME [epoch: 5.75 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062143927469963		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 2.062143927469963 | validation: 2.928040038849781]
	TIME [epoch: 5.73 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0595388610639787		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 2.0595388610639787 | validation: 2.940385695802063]
	TIME [epoch: 5.72 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0567854880859695		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 2.0567854880859695 | validation: 2.944655542650859]
	TIME [epoch: 5.73 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058259454641911		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 2.058259454641911 | validation: 2.9370395810577454]
	TIME [epoch: 5.73 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0690156434327833		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 2.0690156434327833 | validation: 2.9727637091750263]
	TIME [epoch: 5.74 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.079130952038659		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 2.079130952038659 | validation: 2.978722650654844]
	TIME [epoch: 5.78 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.070961783213172		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 2.070961783213172 | validation: 2.9795811364694136]
	TIME [epoch: 5.74 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057459380714281		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 2.057459380714281 | validation: 2.9256046555280624]
	TIME [epoch: 5.73 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0573509669217387		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 2.0573509669217387 | validation: 2.927325162467013]
	TIME [epoch: 5.73 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058564121601489		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 2.058564121601489 | validation: 2.9617612253875767]
	TIME [epoch: 5.74 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062447210210886		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 2.062447210210886 | validation: 2.9588681471339315]
	TIME [epoch: 5.73 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0654999413899713		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 2.0654999413899713 | validation: 2.9613274656288446]
	TIME [epoch: 5.76 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0641906651838493		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 2.0641906651838493 | validation: 2.961546511779297]
	TIME [epoch: 5.75 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0676717037240344		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 2.0676717037240344 | validation: 2.9713406613123188]
	TIME [epoch: 5.72 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057774054014984		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 2.057774054014984 | validation: 2.940833002919332]
	TIME [epoch: 5.74 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0639685539647665		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 2.0639685539647665 | validation: 2.936549635906025]
	TIME [epoch: 5.73 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0619164466590125		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 2.0619164466590125 | validation: 2.931201401576325]
	TIME [epoch: 5.73 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0620609848387934		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 2.0620609848387934 | validation: 2.9322116657853234]
	TIME [epoch: 5.75 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062089514224329		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 2.062089514224329 | validation: 2.9181768557593086]
	TIME [epoch: 5.76 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0655247273762587		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 2.0655247273762587 | validation: 2.9482357077111794]
	TIME [epoch: 5.74 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.075265717860887		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 2.075265717860887 | validation: 2.9374144433775995]
	TIME [epoch: 5.73 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0605933426561758		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 2.0605933426561758 | validation: 2.961323657631721]
	TIME [epoch: 5.73 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060309202667762		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 2.060309202667762 | validation: 2.9453612891841074]
	TIME [epoch: 5.73 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0544992833740565		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 2.0544992833740565 | validation: 2.925004323513415]
	TIME [epoch: 5.74 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059891990155779		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 2.059891990155779 | validation: 2.944535715074309]
	TIME [epoch: 5.77 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064894705314743		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 2.064894705314743 | validation: 2.926477733438302]
	TIME [epoch: 5.74 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060884445983671		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 2.060884445983671 | validation: 2.949986020388962]
	TIME [epoch: 5.73 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0598129358488606		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 2.0598129358488606 | validation: 2.9579555344535273]
	TIME [epoch: 5.73 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0589019995098914		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 2.0589019995098914 | validation: 2.944306125131275]
	TIME [epoch: 5.73 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0574089577409542		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 2.0574089577409542 | validation: 2.9554334435617298]
	TIME [epoch: 5.74 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0606410461501516		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 2.0606410461501516 | validation: 2.9410777799199472]
	TIME [epoch: 5.74 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061183469739692		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 2.061183469739692 | validation: 2.9545647515704925]
	TIME [epoch: 5.75 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06318831705212		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 2.06318831705212 | validation: 2.9302702471995508]
	TIME [epoch: 5.73 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0582081495286473		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 2.0582081495286473 | validation: 2.9336402315082637]
	TIME [epoch: 5.72 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058026065086935		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 2.058026065086935 | validation: 2.9274689624191974]
	TIME [epoch: 5.73 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0589496672057908		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 2.0589496672057908 | validation: 2.9094631484554534]
	TIME [epoch: 5.73 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0630926093723456		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 2.0630926093723456 | validation: 2.9196851856980004]
	TIME [epoch: 5.73 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0618511394414507		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 2.0618511394414507 | validation: 2.924791970750576]
	TIME [epoch: 5.78 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055665840511925		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 2.055665840511925 | validation: 2.9307557865527976]
	TIME [epoch: 5.73 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055766029264374		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 2.055766029264374 | validation: 2.922249180527207]
	TIME [epoch: 5.73 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06063793416053		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 2.06063793416053 | validation: 2.930518159160545]
	TIME [epoch: 5.72 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0591930839576733		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 2.0591930839576733 | validation: 2.9210887099388607]
	TIME [epoch: 5.72 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0637331591459436		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 2.0637331591459436 | validation: 2.924452516245953]
	TIME [epoch: 5.72 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062406599645902		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 2.062406599645902 | validation: 2.921943736346399]
	TIME [epoch: 5.74 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066151523538348		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 2.066151523538348 | validation: 2.9129300535140783]
	TIME [epoch: 5.76 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061404205860047		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 2.061404205860047 | validation: 2.9242001108569253]
	TIME [epoch: 5.72 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0562121080180686		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 2.0562121080180686 | validation: 2.9247460855024747]
	TIME [epoch: 5.72 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0653941089045804		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 2.0653941089045804 | validation: 2.9759947122673345]
	TIME [epoch: 5.72 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0762179719814693		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 2.0762179719814693 | validation: 2.971187353064536]
	TIME [epoch: 5.72 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0623541675988606		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 2.0623541675988606 | validation: 2.925582792644551]
	TIME [epoch: 5.73 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0577831930234662		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 2.0577831930234662 | validation: 2.9355902713135618]
	TIME [epoch: 5.77 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0570746978078667		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 2.0570746978078667 | validation: 2.937486686531539]
	TIME [epoch: 5.73 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057022028167192		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 2.057022028167192 | validation: 2.9351291486627327]
	TIME [epoch: 5.74 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056900383787571		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 2.056900383787571 | validation: 2.917698018457802]
	TIME [epoch: 5.73 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05637223898125		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 2.05637223898125 | validation: 2.9343540669754793]
	TIME [epoch: 5.72 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061744862054434		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 2.061744862054434 | validation: 2.936342975025839]
	TIME [epoch: 5.74 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05700644388488		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 2.05700644388488 | validation: 2.9189904911974702]
	TIME [epoch: 5.74 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0592480093997065		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 2.0592480093997065 | validation: 2.9198520868977824]
	TIME [epoch: 5.75 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0579135420847487		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 2.0579135420847487 | validation: 2.949021976548755]
	TIME [epoch: 5.73 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060003550453851		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 2.060003550453851 | validation: 2.9507054232388947]
	TIME [epoch: 5.73 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059998677986291		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 2.059998677986291 | validation: 2.9268878351258967]
	TIME [epoch: 5.74 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064130765333198		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 2.064130765333198 | validation: 2.9242388175633596]
	TIME [epoch: 5.73 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062412440805952		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 2.062412440805952 | validation: 2.9331767119345704]
	TIME [epoch: 5.73 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05861356237026		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 2.05861356237026 | validation: 2.922744017478471]
	TIME [epoch: 5.78 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05869705340282		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 2.05869705340282 | validation: 2.9244871696006305]
	TIME [epoch: 5.73 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062077976298203		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 2.062077976298203 | validation: 2.925102991948862]
	TIME [epoch: 5.73 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0579932870052344		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 2.0579932870052344 | validation: 2.9313665548230494]
	TIME [epoch: 5.73 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05740688625865		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 2.05740688625865 | validation: 2.9320758166825978]
	TIME [epoch: 5.72 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051693673973851		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 2.051693673973851 | validation: 2.940615702146715]
	TIME [epoch: 5.73 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057097857399966		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 2.057097857399966 | validation: 2.9321456204154344]
	TIME [epoch: 5.75 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0657816020850257		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 2.0657816020850257 | validation: 2.9443795334099296]
	TIME [epoch: 5.76 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0645073308753745		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 2.0645073308753745 | validation: 2.933862171352913]
	TIME [epoch: 5.73 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0578343182217984		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 2.0578343182217984 | validation: 2.924032802074495]
	TIME [epoch: 5.72 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064509307504986		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 2.064509307504986 | validation: 2.913941655548252]
	TIME [epoch: 5.74 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05994778840929		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 2.05994778840929 | validation: 2.93817574962874]
	TIME [epoch: 5.72 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054135331892896		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 2.054135331892896 | validation: 2.952532344169949]
	TIME [epoch: 5.72 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059480165127592		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 2.059480165127592 | validation: 2.9532309490311723]
	TIME [epoch: 5.78 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0549062031217233		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 2.0549062031217233 | validation: 2.9589451900154926]
	TIME [epoch: 5.73 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0583628076517075		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 2.0583628076517075 | validation: 2.9384653765912345]
	TIME [epoch: 5.74 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055603210164324		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 2.055603210164324 | validation: 2.9311276435394986]
	TIME [epoch: 5.72 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053073082951465		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 2.053073082951465 | validation: 2.946142504858279]
	TIME [epoch: 5.73 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0533140734588295		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 2.0533140734588295 | validation: 2.9396413057332467]
	TIME [epoch: 5.73 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0619365715813824		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 2.0619365715813824 | validation: 2.9246236134103807]
	TIME [epoch: 5.76 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051614758617863		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 2.051614758617863 | validation: 2.9309371490187033]
	TIME [epoch: 5.74 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055730560850953		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 2.055730560850953 | validation: 2.9396318921961813]
	TIME [epoch: 5.72 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0572161422880892		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 2.0572161422880892 | validation: 2.9256475378263382]
	TIME [epoch: 5.72 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0600484146907907		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 2.0600484146907907 | validation: 2.9294427481953913]
	TIME [epoch: 5.73 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0585181793372276		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 2.0585181793372276 | validation: 2.9343866874012488]
	TIME [epoch: 5.72 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0577354619442896		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 2.0577354619442896 | validation: 2.9537203573214685]
	TIME [epoch: 5.72 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0596988735630006		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 2.0596988735630006 | validation: 2.929459797906244]
	TIME [epoch: 5.78 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056023622687339		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 2.056023622687339 | validation: 2.944932377868537]
	TIME [epoch: 5.72 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056034282912893		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 2.056034282912893 | validation: 2.948620648113683]
	TIME [epoch: 5.73 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0609607048599177		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 2.0609607048599177 | validation: 2.948802254712121]
	TIME [epoch: 5.72 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0557531090461745		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 2.0557531090461745 | validation: 2.9367334245514702]
	TIME [epoch: 5.72 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0529742484606976		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 2.0529742484606976 | validation: 2.9287611276148455]
	TIME [epoch: 5.73 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0591660144511454		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 2.0591660144511454 | validation: 2.951408483877178]
	TIME [epoch: 5.76 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056244968920275		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 2.056244968920275 | validation: 2.9511504058489835]
	TIME [epoch: 5.74 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0628705754221595		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 2.0628705754221595 | validation: 2.9352315359473966]
	TIME [epoch: 5.72 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0554856928340586		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 2.0554856928340586 | validation: 2.941413660899847]
	TIME [epoch: 5.74 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0567051850162894		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 2.0567051850162894 | validation: 2.9372490832283784]
	TIME [epoch: 5.72 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056430072071497		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 2.056430072071497 | validation: 2.9435246111164632]
	TIME [epoch: 5.72 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064776248814424		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 2.064776248814424 | validation: 2.9583195166934444]
	TIME [epoch: 5.73 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0568413870590443		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 2.0568413870590443 | validation: 2.9361162762363997]
	TIME [epoch: 5.78 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0590945279460784		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 2.0590945279460784 | validation: 2.93607357986936]
	TIME [epoch: 5.72 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0584447952856313		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 2.0584447952856313 | validation: 2.9300495713730577]
	TIME [epoch: 5.73 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06328198375471		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 2.06328198375471 | validation: 2.935206562291431]
	TIME [epoch: 5.74 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064154972159464		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 2.064154972159464 | validation: 2.9328060302911276]
	TIME [epoch: 5.73 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0579697095625256		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 2.0579697095625256 | validation: 2.922834557994355]
	TIME [epoch: 5.72 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0596140149309643		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 2.0596140149309643 | validation: 2.9302833157850112]
	TIME [epoch: 5.76 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056212415854088		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 2.056212415854088 | validation: 2.959414218897077]
	TIME [epoch: 5.74 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0635629772555646		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 2.0635629772555646 | validation: 2.954427767691921]
	TIME [epoch: 5.72 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0663115235135336		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 2.0663115235135336 | validation: 2.934929905698005]
	TIME [epoch: 5.72 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0655431303690026		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 2.0655431303690026 | validation: 2.9373914720659524]
	TIME [epoch: 5.72 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0633224389548306		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 2.0633224389548306 | validation: 2.959457482593485]
	TIME [epoch: 5.72 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0694130255519254		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 2.0694130255519254 | validation: 2.9762581338955]
	TIME [epoch: 5.73 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0678811394136822		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 2.0678811394136822 | validation: 2.968286147114844]
	TIME [epoch: 5.77 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0594828747909384		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 2.0594828747909384 | validation: 2.9362559237540675]
	TIME [epoch: 5.72 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0585868508906886		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 2.0585868508906886 | validation: 2.9306089548929353]
	TIME [epoch: 5.73 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0561680882898714		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 2.0561680882898714 | validation: 2.9604898458547866]
	TIME [epoch: 5.72 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062381151419266		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 2.062381151419266 | validation: 2.9457016760635875]
	TIME [epoch: 5.74 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05982312447369		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 2.05982312447369 | validation: 2.925330068038386]
	TIME [epoch: 5.72 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0598413471148613		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 2.0598413471148613 | validation: 2.921983948222078]
	TIME [epoch: 5.77 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0603107728879424		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 2.0603107728879424 | validation: 2.9167294608389462]
	TIME [epoch: 5.73 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057344649599251		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 2.057344649599251 | validation: 2.93167157288985]
	TIME [epoch: 5.72 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054437137052035		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 2.054437137052035 | validation: 2.947955692631465]
	TIME [epoch: 5.72 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0550718372495584		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 2.0550718372495584 | validation: 2.9446888315602346]
	TIME [epoch: 5.73 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0567128587562387		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 2.0567128587562387 | validation: 2.9179403075020565]
	TIME [epoch: 5.72 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0578746565293535		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 2.0578746565293535 | validation: 2.937322230165712]
	TIME [epoch: 5.74 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0521926546359253		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 2.0521926546359253 | validation: 2.9405783743664675]
	TIME [epoch: 5.76 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056851980772066		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 2.056851980772066 | validation: 2.9293443902033993]
	TIME [epoch: 5.73 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0533814399497263		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 2.0533814399497263 | validation: 2.9315233445176694]
	TIME [epoch: 5.72 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0545798503950676		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 2.0545798503950676 | validation: 2.919809399134986]
	TIME [epoch: 5.73 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0566310266835632		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 2.0566310266835632 | validation: 2.9429951397363348]
	TIME [epoch: 5.72 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055446621705374		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 2.055446621705374 | validation: 2.9443706918121255]
	TIME [epoch: 5.74 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0611199391881576		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 2.0611199391881576 | validation: 2.9272057138628047]
	TIME [epoch: 5.75 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053589957878794		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 2.053589957878794 | validation: 2.9384438734101024]
	TIME [epoch: 5.74 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0500718032048764		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 2.0500718032048764 | validation: 2.947876729726649]
	TIME [epoch: 5.72 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0567143063763593		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 2.0567143063763593 | validation: 2.936049407320122]
	TIME [epoch: 5.72 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056035369004211		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 2.056035369004211 | validation: 2.944244682850425]
	TIME [epoch: 5.73 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055730827756098		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 2.055730827756098 | validation: 2.958898298196648]
	TIME [epoch: 5.73 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0536037118255357		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 2.0536037118255357 | validation: 2.943008148846292]
	TIME [epoch: 5.72 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0539257442218877		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 2.0539257442218877 | validation: 2.9471072304985273]
	TIME [epoch: 5.77 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0587341041410925		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 2.0587341041410925 | validation: 2.926558990650045]
	TIME [epoch: 5.74 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0548793507325205		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 2.0548793507325205 | validation: 2.9402236066345804]
	TIME [epoch: 5.72 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0577389310477385		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 2.0577389310477385 | validation: 2.934581222215633]
	TIME [epoch: 5.73 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0646903068217695		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 2.0646903068217695 | validation: 2.938075962769558]
	TIME [epoch: 5.72 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06057294584282		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 2.06057294584282 | validation: 2.9300690184627776]
	TIME [epoch: 5.72 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053424708809878		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 2.053424708809878 | validation: 2.940796304639307]
	TIME [epoch: 5.75 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0546305106677027		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 2.0546305106677027 | validation: 2.961026565234403]
	TIME [epoch: 5.75 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063525215354398		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 2.063525215354398 | validation: 2.957345102984116]
	TIME [epoch: 5.74 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0563205888043683		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 2.0563205888043683 | validation: 2.9666858873789796]
	TIME [epoch: 5.73 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0580143183948922		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 2.0580143183948922 | validation: 2.9611791240038023]
	TIME [epoch: 5.72 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05980491811492		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 2.05980491811492 | validation: 2.933219638791179]
	TIME [epoch: 5.73 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0533411400362382		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 2.0533411400362382 | validation: 2.9265431189930804]
	TIME [epoch: 5.74 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0608093785961104		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 2.0608093785961104 | validation: 2.93024492808241]
	TIME [epoch: 5.77 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060379849511611		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 2.060379849511611 | validation: 2.9245493858993656]
	TIME [epoch: 5.73 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055266359306497		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 2.055266359306497 | validation: 2.9356694824572833]
	TIME [epoch: 5.73 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053643866056272		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 2.053643866056272 | validation: 2.953008283375322]
	TIME [epoch: 5.72 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0558107772249548		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 2.0558107772249548 | validation: 2.9415304514612037]
	TIME [epoch: 5.72 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0569266801926647		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 2.0569266801926647 | validation: 2.9319449935828414]
	TIME [epoch: 5.72 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05263311249111		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 2.05263311249111 | validation: 2.9459669539413618]
	TIME [epoch: 5.77 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062701116808407		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 2.062701116808407 | validation: 2.9631150833578968]
	TIME [epoch: 5.73 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065347896959988		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 2.065347896959988 | validation: 2.97666190540224]
	TIME [epoch: 5.73 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0671844343179275		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 2.0671844343179275 | validation: 2.944191136360178]
	TIME [epoch: 5.72 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059558506263976		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 2.059558506263976 | validation: 2.9270231688600394]
	TIME [epoch: 5.73 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058054047888137		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 2.058054047888137 | validation: 2.9316387418558576]
	TIME [epoch: 5.73 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053586522230563		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 2.053586522230563 | validation: 2.9283536569336275]
	TIME [epoch: 5.75 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050538147129721		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 2.050538147129721 | validation: 2.9284144442158904]
	TIME [epoch: 5.76 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056912633801001		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 2.056912633801001 | validation: 2.9289575411999555]
	TIME [epoch: 5.73 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056794298252581		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 2.056794298252581 | validation: 2.9339020002272673]
	TIME [epoch: 5.72 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057601365068156		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 2.057601365068156 | validation: 2.926344677760247]
	TIME [epoch: 5.73 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05965598380073		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 2.05965598380073 | validation: 2.926611331213568]
	TIME [epoch: 5.73 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0592880779432097		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 2.0592880779432097 | validation: 2.928567294542837]
	TIME [epoch: 5.73 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0563872610155927		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 2.0563872610155927 | validation: 2.9166944386576152]
	TIME [epoch: 5.77 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0625531658578904		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 2.0625531658578904 | validation: 2.931160319742509]
	TIME [epoch: 5.73 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0586265906167935		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 2.0586265906167935 | validation: 2.9350657357576906]
	TIME [epoch: 5.72 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056454539893826		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 2.056454539893826 | validation: 2.9276512911222947]
	TIME [epoch: 5.72 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052659927893407		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 2.052659927893407 | validation: 2.955717970092652]
	TIME [epoch: 5.72 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059513731729708		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 2.059513731729708 | validation: 2.937823287153729]
	TIME [epoch: 5.73 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060589060649206		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 2.060589060649206 | validation: 2.941586464128574]
	TIME [epoch: 5.73 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064657196327046		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 2.064657196327046 | validation: 2.9300371947698114]
	TIME [epoch: 5.76 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0594696505802617		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 2.0594696505802617 | validation: 2.9591747926857024]
	TIME [epoch: 5.72 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0581733594665836		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 2.0581733594665836 | validation: 2.951543709394483]
	TIME [epoch: 5.74 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0588908387431153		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 2.0588908387431153 | validation: 2.947187184267665]
	TIME [epoch: 5.72 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0566795033344265		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 2.0566795033344265 | validation: 2.9642441335564684]
	TIME [epoch: 5.73 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0575779245238226		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 2.0575779245238226 | validation: 2.9319932660284986]
	TIME [epoch: 5.73 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05266949790856		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 2.05266949790856 | validation: 2.9355065708687653]
	TIME [epoch: 5.78 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055552041870868		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 2.055552041870868 | validation: 2.9277079733032885]
	TIME [epoch: 5.73 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056373072131733		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 2.056373072131733 | validation: 2.9205925038229874]
	TIME [epoch: 5.73 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054878508765431		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 2.054878508765431 | validation: 2.9411122480306147]
	TIME [epoch: 5.73 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058687792555618		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 2.058687792555618 | validation: 2.9195829627669476]
	TIME [epoch: 5.73 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059870402570757		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 2.059870402570757 | validation: 2.9258555168514384]
	TIME [epoch: 5.73 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056974234820527		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 2.056974234820527 | validation: 2.925655264038018]
	TIME [epoch: 5.74 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0594312565861284		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 2.0594312565861284 | validation: 2.9263367008540118]
	TIME [epoch: 5.75 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061286841885021		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 2.061286841885021 | validation: 2.9274393190247916]
	TIME [epoch: 5.74 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0612741860537573		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 2.0612741860537573 | validation: 2.927015060805297]
	TIME [epoch: 5.73 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056221029301634		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 2.056221029301634 | validation: 2.9221137446416185]
	TIME [epoch: 5.73 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05800574710854		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 2.05800574710854 | validation: 2.933168991074886]
	TIME [epoch: 5.73 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056691341327115		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 2.056691341327115 | validation: 2.9497002779990082]
	TIME [epoch: 5.74 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0575445857271433		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 2.0575445857271433 | validation: 2.937974272378261]
	TIME [epoch: 5.78 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05689338455708		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 2.05689338455708 | validation: 2.9592427478133185]
	TIME [epoch: 5.74 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0548938702055795		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 2.0548938702055795 | validation: 2.952003213315709]
	TIME [epoch: 5.72 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0530536547160914		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 2.0530536547160914 | validation: 2.9316230917539734]
	TIME [epoch: 5.74 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0533836356805377		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 2.0533836356805377 | validation: 2.921234930964557]
	TIME [epoch: 5.73 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0543580161785924		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 2.0543580161785924 | validation: 2.9320731263082145]
	TIME [epoch: 5.72 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0548616717596144		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 2.0548616717596144 | validation: 2.936713043775612]
	TIME [epoch: 5.75 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0578207914205766		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 2.0578207914205766 | validation: 2.932942302455017]
	TIME [epoch: 5.75 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063937520312651		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 2.063937520312651 | validation: 2.941176773303681]
	TIME [epoch: 5.74 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0650447352354977		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 2.0650447352354977 | validation: 2.9427261996653638]
	TIME [epoch: 5.72 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0600319386951025		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 2.0600319386951025 | validation: 2.967702583339655]
	TIME [epoch: 5.74 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0574453250054363		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 2.0574453250054363 | validation: 2.9495834025931105]
	TIME [epoch: 5.73 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0557327852979794		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 2.0557327852979794 | validation: 2.928714330788547]
	TIME [epoch: 5.72 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06036229290362		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 2.06036229290362 | validation: 2.9420989307681613]
	TIME [epoch: 5.76 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052490682961207		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 2.052490682961207 | validation: 2.951656786469207]
	TIME [epoch: 5.72 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056569007782374		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 2.056569007782374 | validation: 2.9582999208726353]
	TIME [epoch: 5.72 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0582739184915764		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 2.0582739184915764 | validation: 2.946766103152153]
	TIME [epoch: 5.71 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053859605222181		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 2.053859605222181 | validation: 2.9296408427802647]
	TIME [epoch: 5.72 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053840628753044		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 2.053840628753044 | validation: 2.936166330694574]
	TIME [epoch: 5.73 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0549487622112146		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 2.0549487622112146 | validation: 2.935666664090183]
	TIME [epoch: 5.77 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0562119657090396		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 2.0562119657090396 | validation: 2.9406113650822716]
	TIME [epoch: 5.74 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0575110691933003		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 2.0575110691933003 | validation: 2.9302015696966586]
	TIME [epoch: 5.72 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0528966254585805		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 2.0528966254585805 | validation: 2.933127133054796]
	TIME [epoch: 5.72 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056504867156645		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 2.056504867156645 | validation: 2.9353771790653598]
	TIME [epoch: 5.72 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0563547977402026		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 2.0563547977402026 | validation: 2.9323225254439262]
	TIME [epoch: 5.72 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0567140652366236		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 2.0567140652366236 | validation: 2.925817783859301]
	TIME [epoch: 5.72 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052367421110746		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 2.052367421110746 | validation: 2.9386153905379193]
	TIME [epoch: 5.76 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0546394401442214		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 2.0546394401442214 | validation: 2.945886264175915]
	TIME [epoch: 5.72 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0584194920026238		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 2.0584194920026238 | validation: 2.9203222556729016]
	TIME [epoch: 5.72 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059941219435644		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 2.059941219435644 | validation: 2.925882023938361]
	TIME [epoch: 5.71 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060824662069778		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 2.060824662069778 | validation: 2.9375210078058003]
	TIME [epoch: 5.71 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053913334599714		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 2.053913334599714 | validation: 2.932529539732982]
	TIME [epoch: 5.72 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0534033548768824		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 2.0534033548768824 | validation: 2.9381022991527272]
	TIME [epoch: 5.76 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0563426978069472		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 2.0563426978069472 | validation: 2.9349886198745945]
	TIME [epoch: 5.73 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0566907814638444		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 2.0566907814638444 | validation: 2.9279292483153467]
	TIME [epoch: 5.72 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0570160868103087		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 2.0570160868103087 | validation: 2.933752051190286]
	TIME [epoch: 5.72 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05428032862348		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 2.05428032862348 | validation: 2.921803809573394]
	TIME [epoch: 5.73 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0582338380787837		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 2.0582338380787837 | validation: 2.9190876215290054]
	TIME [epoch: 5.73 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05446418094577		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 2.05446418094577 | validation: 2.939484373456979]
	TIME [epoch: 5.73 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0546606246497285		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 2.0546606246497285 | validation: 2.9357302676623545]
	TIME [epoch: 5.78 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052118337939345		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 2.052118337939345 | validation: 2.942073565047812]
	TIME [epoch: 5.73 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056940869420762		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 2.056940869420762 | validation: 2.9393759710470824]
	TIME [epoch: 5.72 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0590607960718965		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 2.0590607960718965 | validation: 2.9457364749178705]
	TIME [epoch: 5.73 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053353696711807		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 2.053353696711807 | validation: 2.9386301054585613]
	TIME [epoch: 5.72 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058833474556688		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 2.058833474556688 | validation: 2.929705737291307]
	TIME [epoch: 5.72 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0514073833886424		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 2.0514073833886424 | validation: 2.9329283360809746]
	TIME [epoch: 5.75 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0591760089398807		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 2.0591760089398807 | validation: 2.9342363031593526]
	TIME [epoch: 5.73 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055065712061438		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 2.055065712061438 | validation: 2.9400770134397156]
	TIME [epoch: 5.72 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0586283354252375		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 2.0586283354252375 | validation: 2.9410973322439213]
	TIME [epoch: 5.72 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054720729800159		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 2.054720729800159 | validation: 2.9510914950847598]
	TIME [epoch: 5.71 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0543498819754147		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 2.0543498819754147 | validation: 2.939686177107694]
	TIME [epoch: 5.72 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052446542510264		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 2.052446542510264 | validation: 2.9441791428059365]
	TIME [epoch: 5.73 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0562240365992075		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 2.0562240365992075 | validation: 2.9273985672100444]
	TIME [epoch: 5.78 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0585253395648957		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 2.0585253395648957 | validation: 2.9437608173782372]
	TIME [epoch: 5.74 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0654550308343906		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 2.0654550308343906 | validation: 2.9311945692834036]
	TIME [epoch: 5.73 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0624425843818366		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 2.0624425843818366 | validation: 2.9549557946351275]
	TIME [epoch: 5.73 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0637576631551577		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 2.0637576631551577 | validation: 2.958556449341978]
	TIME [epoch: 5.73 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060087592219254		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 2.060087592219254 | validation: 2.9444906545089964]
	TIME [epoch: 5.72 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059766284852654		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 2.059766284852654 | validation: 2.964711092479384]
	TIME [epoch: 5.77 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059484563794774		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 2.059484563794774 | validation: 2.9423830926204193]
	TIME [epoch: 5.73 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055067227768844		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 2.055067227768844 | validation: 2.9397793801550853]
	TIME [epoch: 5.73 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053562202966368		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 2.053562202966368 | validation: 2.9314230132122954]
	TIME [epoch: 5.74 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057116353405415		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 2.057116353405415 | validation: 2.9122800292227056]
	TIME [epoch: 5.73 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0600890730281907		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 2.0600890730281907 | validation: 2.91591413860211]
	TIME [epoch: 5.72 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055290415133506		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 2.055290415133506 | validation: 2.938679097504089]
	TIME [epoch: 5.73 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0611382195562937		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 2.0611382195562937 | validation: 2.93088530400795]
	TIME [epoch: 5.78 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056423770360411		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 2.056423770360411 | validation: 2.9355149635027704]
	TIME [epoch: 5.73 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056101262609386		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 2.056101262609386 | validation: 2.928546664540583]
	TIME [epoch: 5.74 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05769836817999		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 2.05769836817999 | validation: 2.9289562997648377]
	TIME [epoch: 5.73 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0531302096291837		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 2.0531302096291837 | validation: 2.9359902918202185]
	TIME [epoch: 5.74 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053986960774545		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 2.053986960774545 | validation: 2.92865376316385]
	TIME [epoch: 5.72 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057121050867849		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 2.057121050867849 | validation: 2.9291791123217865]
	TIME [epoch: 5.75 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059274291505186		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 2.059274291505186 | validation: 2.9374729374114517]
	TIME [epoch: 5.73 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053677938605609		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 2.053677938605609 | validation: 2.93726317011648]
	TIME [epoch: 5.72 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052274057918534		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 2.052274057918534 | validation: 2.9415225318472893]
	TIME [epoch: 5.73 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0546060941881588		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 2.0546060941881588 | validation: 2.9296075568186426]
	TIME [epoch: 5.72 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059426781862081		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 2.059426781862081 | validation: 2.9404478393967994]
	TIME [epoch: 5.71 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0566115901781665		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 2.0566115901781665 | validation: 2.9530635254907485]
	TIME [epoch: 5.72 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0591678499416775		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 2.0591678499416775 | validation: 2.9502568920377543]
	TIME [epoch: 5.76 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056159024290473		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 2.056159024290473 | validation: 2.938514810793109]
	TIME [epoch: 5.74 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052543493262511		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 2.052543493262511 | validation: 2.949630133975909]
	TIME [epoch: 5.74 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056136300265697		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 2.056136300265697 | validation: 2.9413262302989334]
	TIME [epoch: 5.73 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0513318866681653		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 2.0513318866681653 | validation: 2.9397784362823143]
	TIME [epoch: 5.72 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0584618927726144		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 2.0584618927726144 | validation: 2.9438604077576658]
	TIME [epoch: 5.72 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0625629153149543		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 2.0625629153149543 | validation: 2.9574027569230923]
	TIME [epoch: 5.76 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059443523538212		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 2.059443523538212 | validation: 2.9591951310650906]
	TIME [epoch: 5.73 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0560802619548166		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 2.0560802619548166 | validation: 2.9403876668535545]
	TIME [epoch: 5.72 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0555955916224895		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 2.0555955916224895 | validation: 2.935259042418212]
	TIME [epoch: 5.72 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0576581857168215		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 2.0576581857168215 | validation: 2.9451974003810197]
	TIME [epoch: 5.72 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0581699280917265		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 2.0581699280917265 | validation: 2.941243703827055]
	TIME [epoch: 5.72 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0582516025591158		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 2.0582516025591158 | validation: 2.958914541615138]
	TIME [epoch: 5.74 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0636062809310585		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 2.0636062809310585 | validation: 2.956395428849485]
	TIME [epoch: 5.76 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064745131135357		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 2.064745131135357 | validation: 2.9530238523843413]
	TIME [epoch: 5.74 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066747047538856		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 2.066747047538856 | validation: 2.9524437000434847]
	TIME [epoch: 5.72 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0567893754575617		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 2.0567893754575617 | validation: 2.9420694295234298]
	TIME [epoch: 5.72 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0530506808482127		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 2.0530506808482127 | validation: 2.9504107580724632]
	TIME [epoch: 5.72 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0573971027124065		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 2.0573971027124065 | validation: 2.945898165869747]
	TIME [epoch: 5.72 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054347579749502		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 2.054347579749502 | validation: 2.9453972884061885]
	TIME [epoch: 5.78 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0561053054969975		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 2.0561053054969975 | validation: 2.941151586425924]
	TIME [epoch: 5.73 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05977255921972		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 2.05977255921972 | validation: 2.9447718362895343]
	TIME [epoch: 5.72 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0537872921942757		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 2.0537872921942757 | validation: 2.9267826124714986]
	TIME [epoch: 5.73 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057815886050294		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 2.057815886050294 | validation: 2.9286629947091263]
	TIME [epoch: 5.73 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054530915606568		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 2.054530915606568 | validation: 2.92742362796417]
	TIME [epoch: 5.72 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0550106628038503		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 2.0550106628038503 | validation: 2.9339480026838487]
	TIME [epoch: 5.74 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0582635929661612		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 2.0582635929661612 | validation: 2.9401597509384207]
	TIME [epoch: 5.75 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057571278842009		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 2.057571278842009 | validation: 2.933513392126747]
	TIME [epoch: 5.72 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0571757149548127		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 2.0571757149548127 | validation: 2.949992375906642]
	TIME [epoch: 5.73 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0531676892796296		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 2.0531676892796296 | validation: 2.9414003624837246]
	TIME [epoch: 5.72 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0545407728689		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 2.0545407728689 | validation: 2.929373097145768]
	TIME [epoch: 5.72 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0522040199179283		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 2.0522040199179283 | validation: 2.930565040406916]
	TIME [epoch: 5.73 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0564050689088846		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 2.0564050689088846 | validation: 2.924133973393132]
	TIME [epoch: 5.78 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0548560217066387		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 2.0548560217066387 | validation: 2.9399396919710483]
	TIME [epoch: 5.74 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0500051304525373		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 2.0500051304525373 | validation: 2.927303483760486]
	TIME [epoch: 5.73 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0565367208853282		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 2.0565367208853282 | validation: 2.9297575123761463]
	TIME [epoch: 5.72 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0503786948890683		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 2.0503786948890683 | validation: 2.93361454801796]
	TIME [epoch: 5.72 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057901994910324		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 2.057901994910324 | validation: 2.926510884891093]
	TIME [epoch: 5.72 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052634656462544		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 2.052634656462544 | validation: 2.932713829198341]
	TIME [epoch: 5.74 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0547160222758443		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 2.0547160222758443 | validation: 2.9143053839385265]
	TIME [epoch: 5.76 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0547133311224304		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 2.0547133311224304 | validation: 2.9394167791799464]
	TIME [epoch: 5.74 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054081860369423		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 2.054081860369423 | validation: 2.9378439359458826]
	TIME [epoch: 5.72 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053528365809692		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 2.053528365809692 | validation: 2.93469247284807]
	TIME [epoch: 5.73 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0549734553428736		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 2.0549734553428736 | validation: 2.9299885775571575]
	TIME [epoch: 5.74 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0533756537747485		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 2.0533756537747485 | validation: 2.9307442325821933]
	TIME [epoch: 5.72 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05743878616427		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 2.05743878616427 | validation: 2.9457608129991844]
	TIME [epoch: 5.76 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0526616936960758		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 2.0526616936960758 | validation: 2.9338255193737077]
	TIME [epoch: 5.74 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0580869048761112		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 2.0580869048761112 | validation: 2.9303287835464777]
	TIME [epoch: 5.74 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0542062315452174		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 2.0542062315452174 | validation: 2.9286530623245883]
	TIME [epoch: 5.76 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0523266078808216		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 2.0523266078808216 | validation: 2.918405900821865]
	TIME [epoch: 5.73 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0562086607793955		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 2.0562086607793955 | validation: 2.931690138053813]
	TIME [epoch: 5.72 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0561725570614957		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 2.0561725570614957 | validation: 2.927262075294867]
	TIME [epoch: 5.74 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053860357357724		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 2.053860357357724 | validation: 2.9320988993328987]
	TIME [epoch: 5.75 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0559729193879255		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 2.0559729193879255 | validation: 2.9335919919087967]
	TIME [epoch: 5.72 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052980149741167		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 2.052980149741167 | validation: 2.9348858491368732]
	TIME [epoch: 5.72 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0528848496133807		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 2.0528848496133807 | validation: 2.9202579651115617]
	TIME [epoch: 5.72 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0553656426865237		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 2.0553656426865237 | validation: 2.9181969292238823]
	TIME [epoch: 5.72 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055435314513684		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 2.055435314513684 | validation: 2.9281394559464866]
	TIME [epoch: 5.74 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054626970323464		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 2.054626970323464 | validation: 2.9360854719865745]
	TIME [epoch: 5.76 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055056350829237		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 2.055056350829237 | validation: 2.942861336894948]
	TIME [epoch: 5.72 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057266615851237		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 2.057266615851237 | validation: 2.94920764603363]
	TIME [epoch: 5.72 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056713776945303		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 2.056713776945303 | validation: 2.9408170255510577]
	TIME [epoch: 5.72 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058172572058772		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 2.058172572058772 | validation: 2.9516894092139507]
	TIME [epoch: 5.72 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056925754323895		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 2.056925754323895 | validation: 2.951397316567953]
	TIME [epoch: 5.74 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0550023761762257		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 2.0550023761762257 | validation: 2.936732188135684]
	TIME [epoch: 5.76 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0542023271223746		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 2.0542023271223746 | validation: 2.936349589708369]
	TIME [epoch: 5.75 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0556846396728465		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 2.0556846396728465 | validation: 2.923232809180996]
	TIME [epoch: 5.73 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055490022375773		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 2.055490022375773 | validation: 2.932088931664843]
	TIME [epoch: 5.74 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0551125732164706		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 2.0551125732164706 | validation: 2.9366585599370127]
	TIME [epoch: 5.73 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0562828802520245		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 2.0562828802520245 | validation: 2.9194998617091676]
	TIME [epoch: 5.74 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055086634070603		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 2.055086634070603 | validation: 2.912868440972571]
	TIME [epoch: 5.73 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0541376581898363		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 2.0541376581898363 | validation: 2.9323057698570723]
	TIME [epoch: 5.78 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0514772376988044		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 2.0514772376988044 | validation: 2.93699590205398]
	TIME [epoch: 5.73 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0515979286428068		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 2.0515979286428068 | validation: 2.94244798708527]
	TIME [epoch: 5.74 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0529374651256234		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 2.0529374651256234 | validation: 2.93252439949054]
	TIME [epoch: 5.73 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056221374001171		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 2.056221374001171 | validation: 2.9365092697694273]
	TIME [epoch: 5.74 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0555388226500377		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 2.0555388226500377 | validation: 2.936566775311698]
	TIME [epoch: 5.72 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055464604168195		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 2.055464604168195 | validation: 2.939403972118749]
	TIME [epoch: 5.75 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053744656314544		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 2.053744656314544 | validation: 2.927903133301419]
	TIME [epoch: 5.75 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0553922020153594		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 2.0553922020153594 | validation: 2.9281617773937763]
	TIME [epoch: 5.72 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052251067913685		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 2.052251067913685 | validation: 2.92233008817876]
	TIME [epoch: 5.74 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052113153500717		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 2.052113153500717 | validation: 2.9332951260943707]
	TIME [epoch: 5.72 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051805661804087		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 2.051805661804087 | validation: 2.9384697077794733]
	TIME [epoch: 5.74 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055828388874848		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 2.055828388874848 | validation: 2.940918807827153]
	TIME [epoch: 5.73 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0556877191881737		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 2.0556877191881737 | validation: 2.9422485219077386]
	TIME [epoch: 5.77 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060404859810129		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 2.060404859810129 | validation: 2.9311084538736316]
	TIME [epoch: 5.73 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049372379173836		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 2.049372379173836 | validation: 2.9329040934653547]
	TIME [epoch: 5.73 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0531606996291027		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 2.0531606996291027 | validation: 2.9308486367794733]
	TIME [epoch: 5.72 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0558957974202845		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 2.0558957974202845 | validation: 2.918312912172609]
	TIME [epoch: 5.73 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0552603480039013		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 2.0552603480039013 | validation: 2.925465004985863]
	TIME [epoch: 5.72 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0561912291282676		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 2.0561912291282676 | validation: 2.9261300385632114]
	TIME [epoch: 5.76 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055461192310955		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 2.055461192310955 | validation: 2.932377097209636]
	TIME [epoch: 5.74 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0548440437125666		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 2.0548440437125666 | validation: 2.9249184101193646]
	TIME [epoch: 5.72 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055712775304493		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 2.055712775304493 | validation: 2.939139241127043]
	TIME [epoch: 5.74 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056065258626383		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 2.056065258626383 | validation: 2.9245354148476825]
	TIME [epoch: 5.74 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060901805003372		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 2.060901805003372 | validation: 2.926482755320178]
	TIME [epoch: 5.71 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059609620556163		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 2.059609620556163 | validation: 2.93243335392306]
	TIME [epoch: 5.72 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0578223787702		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 2.0578223787702 | validation: 2.9347066226351513]
	TIME [epoch: 5.76 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052572828318455		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 2.052572828318455 | validation: 2.9285437255996043]
	TIME [epoch: 5.72 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0569696125101182		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 2.0569696125101182 | validation: 2.9175472507818165]
	TIME [epoch: 5.73 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0573192901740742		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 2.0573192901740742 | validation: 2.936860841282767]
	TIME [epoch: 5.72 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059086877336334		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 2.059086877336334 | validation: 2.938734789245842]
	TIME [epoch: 5.73 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056877166131506		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 2.056877166131506 | validation: 2.9199985512062177]
	TIME [epoch: 5.72 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0538844809351744		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 2.0538844809351744 | validation: 2.9268681486794583]
	TIME [epoch: 5.76 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0551296369789354		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 2.0551296369789354 | validation: 2.926228700295494]
	TIME [epoch: 5.75 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0559887118969744		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 2.0559887118969744 | validation: 2.9200615365634848]
	TIME [epoch: 5.73 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057486971963086		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 2.057486971963086 | validation: 2.9293887883712593]
	TIME [epoch: 5.72 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0550375278873094		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 2.0550375278873094 | validation: 2.9354762789985775]
	TIME [epoch: 5.72 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063173776085893		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 2.063173776085893 | validation: 2.927417997334785]
	TIME [epoch: 5.73 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0610026108374964		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 2.0610026108374964 | validation: 2.930182757539352]
	TIME [epoch: 5.73 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0545298937155256		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 2.0545298937155256 | validation: 2.9305403203976597]
	TIME [epoch: 5.76 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054972056425746		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 2.054972056425746 | validation: 2.9374291340716754]
	TIME [epoch: 5.74 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0491813047322234		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 2.0491813047322234 | validation: 2.936989043578051]
	TIME [epoch: 5.72 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0576879666210224		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 2.0576879666210224 | validation: 2.9253570447710815]
	TIME [epoch: 5.73 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055831925521167		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 2.055831925521167 | validation: 2.918921782236085]
	TIME [epoch: 5.72 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0529700603808525		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 2.0529700603808525 | validation: 2.9316347153800884]
	TIME [epoch: 5.73 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051876389240924		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 2.051876389240924 | validation: 2.9328684023193214]
	TIME [epoch: 5.76 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0557576448369472		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 2.0557576448369472 | validation: 2.9352756026117572]
	TIME [epoch: 5.73 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0544689180641673		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 2.0544689180641673 | validation: 2.924991805521754]
	TIME [epoch: 5.73 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054206677396481		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 2.054206677396481 | validation: 2.9306123331704357]
	TIME [epoch: 5.73 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0512864401934228		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 2.0512864401934228 | validation: 2.924225618036012]
	TIME [epoch: 5.73 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0533708779914104		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 2.0533708779914104 | validation: 2.9212233112931334]
	TIME [epoch: 5.73 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0538146394770167		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 2.0538146394770167 | validation: 2.926659473560154]
	TIME [epoch: 5.74 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0540182693271607		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 2.0540182693271607 | validation: 2.9436385103048317]
	TIME [epoch: 5.75 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0565642083115314		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 2.0565642083115314 | validation: 2.94073000675931]
	TIME [epoch: 5.73 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058706380669637		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 2.058706380669637 | validation: 2.9435584532409416]
	TIME [epoch: 5.72 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053607271212929		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 2.053607271212929 | validation: 2.947414385652879]
	TIME [epoch: 5.73 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0539516451360975		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 2.0539516451360975 | validation: 2.951567682952062]
	TIME [epoch: 5.73 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05249569602245		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 2.05249569602245 | validation: 2.9489620012135402]
	TIME [epoch: 5.71 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0546438004770855		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 2.0546438004770855 | validation: 2.94618939189716]
	TIME [epoch: 5.76 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0562932615076095		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 2.0562932615076095 | validation: 2.9459541650588115]
	TIME [epoch: 5.74 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0535193954650346		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 2.0535193954650346 | validation: 2.9397571495674226]
	TIME [epoch: 5.72 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054386020099215		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 2.054386020099215 | validation: 2.9365990033566733]
	TIME [epoch: 5.72 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055978655239276		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 2.055978655239276 | validation: 2.934166226822817]
	TIME [epoch: 5.73 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0550050413670817		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 2.0550050413670817 | validation: 2.944480273053748]
	TIME [epoch: 5.74 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0561065473326394		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 2.0561065473326394 | validation: 2.9421804419884747]
	TIME [epoch: 5.75 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0571646067437066		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 2.0571646067437066 | validation: 2.9507196819560693]
	TIME [epoch: 5.77 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0597609054578894		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 2.0597609054578894 | validation: 2.9564687620421]
	TIME [epoch: 5.73 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056676716692975		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 2.056676716692975 | validation: 2.960362549407547]
	TIME [epoch: 5.74 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0576284112379586		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 2.0576284112379586 | validation: 2.9513819571538384]
	TIME [epoch: 5.73 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05156105031512		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 2.05156105031512 | validation: 2.936827906749253]
	TIME [epoch: 5.73 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0484168497789987		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 2.0484168497789987 | validation: 2.941857634912123]
	TIME [epoch: 5.74 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054201968525932		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 2.054201968525932 | validation: 2.9288933669015513]
	TIME [epoch: 5.78 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0575116810976013		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 2.0575116810976013 | validation: 2.9356805178812704]
	TIME [epoch: 5.74 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053607659192881		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 2.053607659192881 | validation: 2.9202045444757254]
	TIME [epoch: 5.73 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0519417196269463		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 2.0519417196269463 | validation: 2.924843048660268]
	TIME [epoch: 5.74 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054723388747596		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 2.054723388747596 | validation: 2.9317547113700915]
	TIME [epoch: 5.72 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053293237817939		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 2.053293237817939 | validation: 2.931689664545988]
	TIME [epoch: 5.73 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0521929072378553		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 2.0521929072378553 | validation: 2.93460399051295]
	TIME [epoch: 5.75 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050579212735303		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 2.050579212735303 | validation: 2.936969206761696]
	TIME [epoch: 5.77 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0500620797857287		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 2.0500620797857287 | validation: 2.9409083201358066]
	TIME [epoch: 5.74 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05287291061075		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 2.05287291061075 | validation: 2.9255752613836696]
	TIME [epoch: 5.74 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0537756335486947		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 2.0537756335486947 | validation: 2.930892047936147]
	TIME [epoch: 5.73 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0527857566377676		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 2.0527857566377676 | validation: 2.9293946764721457]
	TIME [epoch: 5.72 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0541444795336408		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 2.0541444795336408 | validation: 2.9278391292454145]
	TIME [epoch: 5.73 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053203547169698		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 2.053203547169698 | validation: 2.936248745997186]
	TIME [epoch: 5.76 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0493632249324927		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 2.0493632249324927 | validation: 2.9285928495062676]
	TIME [epoch: 5.74 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0567538646105175		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 2.0567538646105175 | validation: 2.9214756311715617]
	TIME [epoch: 5.74 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0563442449091998		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 2.0563442449091998 | validation: 2.923032057071041]
	TIME [epoch: 5.73 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0526869420724037		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 2.0526869420724037 | validation: 2.9272059191636326]
	TIME [epoch: 5.73 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0517061737691886		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 2.0517061737691886 | validation: 2.9101755880215907]
	TIME [epoch: 5.73 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058406244267027		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 2.058406244267027 | validation: 2.9208710638378017]
	TIME [epoch: 5.76 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0518800412469282		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 2.0518800412469282 | validation: 2.926950707491835]
	TIME [epoch: 5.75 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0559310799409847		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 2.0559310799409847 | validation: 2.927083808090355]
	TIME [epoch: 5.72 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055413903812529		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 2.055413903812529 | validation: 2.9326014148358714]
	TIME [epoch: 5.73 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0539305261287177		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 2.0539305261287177 | validation: 2.9311715744423843]
	TIME [epoch: 5.72 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051102371897989		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 2.051102371897989 | validation: 2.929532313145117]
	TIME [epoch: 5.72 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0538371329213074		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 2.0538371329213074 | validation: 2.926550375886243]
	TIME [epoch: 5.73 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0547019582702726		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 2.0547019582702726 | validation: 2.919369285306918]
	TIME [epoch: 5.77 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057652121534517		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 2.057652121534517 | validation: 2.9270392977510564]
	TIME [epoch: 5.73 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05217086708042		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 2.05217086708042 | validation: 2.9290569760092633]
	TIME [epoch: 5.73 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056677255581586		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 2.056677255581586 | validation: 2.9409519976387197]
	TIME [epoch: 5.72 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05626605989023		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 2.05626605989023 | validation: 2.941810443613265]
	TIME [epoch: 5.72 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055587976285241		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 2.055587976285241 | validation: 2.9376629188170886]
	TIME [epoch: 5.72 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0525494976818854		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 2.0525494976818854 | validation: 2.9270481973054427]
	TIME [epoch: 5.75 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0531518675648934		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 2.0531518675648934 | validation: 2.9277471748647645]
	TIME [epoch: 5.74 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0537818281724953		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 2.0537818281724953 | validation: 2.929916698470189]
	TIME [epoch: 5.72 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.04887086101182		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 2.04887086101182 | validation: 2.9356091433696703]
	TIME [epoch: 5.72 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053948052072782		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 2.053948052072782 | validation: 2.9395475632448442]
	TIME [epoch: 5.73 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0537877866309118		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 2.0537877866309118 | validation: 2.9353554267426363]
	TIME [epoch: 5.72 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051680179651684		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 2.051680179651684 | validation: 2.9301746110895226]
	TIME [epoch: 5.72 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0528999853107104		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 2.0528999853107104 | validation: 2.9433268445643694]
	TIME [epoch: 5.77 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0546961142117652		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 2.0546961142117652 | validation: 2.940639671421565]
	TIME [epoch: 5.73 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0485954431320987		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 2.0485954431320987 | validation: 2.9583416655216515]
	TIME [epoch: 5.74 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055193019003002		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 2.055193019003002 | validation: 2.9505373168137785]
	TIME [epoch: 5.74 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0597688547315505		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 2.0597688547315505 | validation: 2.938707585151178]
	TIME [epoch: 5.74 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051772343045913		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 2.051772343045913 | validation: 2.9330142322365567]
	TIME [epoch: 5.74 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051995056278261		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 2.051995056278261 | validation: 2.9510402747041207]
	TIME [epoch: 5.77 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053936697296402		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 2.053936697296402 | validation: 2.935809620423695]
	TIME [epoch: 5.75 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056860258957893		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 2.056860258957893 | validation: 2.9372697608561316]
	TIME [epoch: 5.73 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051931467659095		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 2.051931467659095 | validation: 2.934382835823101]
	TIME [epoch: 5.72 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053303608485709		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 2.053303608485709 | validation: 2.93788614846834]
	TIME [epoch: 5.73 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054213964790065		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 2.054213964790065 | validation: 2.9318943145382805]
	TIME [epoch: 5.73 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0563949514603		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 2.0563949514603 | validation: 2.934205194823907]
	TIME [epoch: 5.72 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056143461740628		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 2.056143461740628 | validation: 2.9365198875991285]
	TIME [epoch: 5.77 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0539874989703644		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 2.0539874989703644 | validation: 2.928421787203074]
	TIME [epoch: 5.72 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0567438905929594		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 2.0567438905929594 | validation: 2.9238378834450565]
	TIME [epoch: 5.72 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0569468171889915		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 2.0569468171889915 | validation: 2.920282770731884]
	TIME [epoch: 5.72 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053604465463759		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 2.053604465463759 | validation: 2.928336406825845]
	TIME [epoch: 5.73 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053981558464728		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 2.053981558464728 | validation: 2.922540473018097]
	TIME [epoch: 5.72 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0531458380083105		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 2.0531458380083105 | validation: 2.9281496733150987]
	TIME [epoch: 5.76 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0521589379197045		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 2.0521589379197045 | validation: 2.932064002682787]
	TIME [epoch: 5.74 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052769562542202		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 2.052769562542202 | validation: 2.9375718994984483]
	TIME [epoch: 5.72 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05761105586764		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 2.05761105586764 | validation: 2.9334972834445234]
	TIME [epoch: 5.73 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0532316273626687		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 2.0532316273626687 | validation: 2.9264403811822763]
	TIME [epoch: 5.73 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0556671739124694		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 2.0556671739124694 | validation: 2.9523946890594632]
	TIME [epoch: 5.73 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051903722755464		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 2.051903722755464 | validation: 2.938074753111308]
	TIME [epoch: 5.72 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059197419310173		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 2.059197419310173 | validation: 2.9429640433365543]
	TIME [epoch: 5.77 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052702684009181		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 2.052702684009181 | validation: 2.9414782832986326]
	TIME [epoch: 5.73 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055027691074286		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 2.055027691074286 | validation: 2.9301134159426887]
	TIME [epoch: 5.73 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055750452824777		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 2.055750452824777 | validation: 2.933576493451138]
	TIME [epoch: 5.72 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05272577460277		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 2.05272577460277 | validation: 2.937885940240173]
	TIME [epoch: 5.72 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0574158810001117		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 2.0574158810001117 | validation: 2.9318373516729337]
	TIME [epoch: 5.73 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0527075523614897		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 2.0527075523614897 | validation: 2.9394264997904394]
	TIME [epoch: 5.78 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059051797169892		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 2.059051797169892 | validation: 2.9500017793453357]
	TIME [epoch: 5.74 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0575019656369387		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 2.0575019656369387 | validation: 2.9457604495937906]
	TIME [epoch: 5.73 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0554293821717042		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 2.0554293821717042 | validation: 2.9411052910921693]
	TIME [epoch: 5.71 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0552896255708424		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 2.0552896255708424 | validation: 2.9461476260756236]
	TIME [epoch: 5.72 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055955360296389		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 2.055955360296389 | validation: 2.9256065057033216]
	TIME [epoch: 5.72 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0509472170995036		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 2.0509472170995036 | validation: 2.9327844835092134]
	TIME [epoch: 5.74 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053270106351686		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 2.053270106351686 | validation: 2.9181534823565936]
	TIME [epoch: 5.77 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0548584185493586		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 2.0548584185493586 | validation: 2.918170330083452]
	TIME [epoch: 5.73 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0566203647318013		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 2.0566203647318013 | validation: 2.9340738138819984]
	TIME [epoch: 5.72 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0550255980289727		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 2.0550255980289727 | validation: 2.926400163204543]
	TIME [epoch: 5.73 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0542061415291313		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 2.0542061415291313 | validation: 2.9192747254872238]
	TIME [epoch: 5.74 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052968486496688		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 2.052968486496688 | validation: 2.9234470486119375]
	TIME [epoch: 5.73 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0547138856447287		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 2.0547138856447287 | validation: 2.9218214972358414]
	TIME [epoch: 5.78 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055213694989175		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 2.055213694989175 | validation: 2.9276353645741544]
	TIME [epoch: 5.72 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056636590546185		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 2.056636590546185 | validation: 2.9337131269613757]
	TIME [epoch: 5.73 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053867816459201		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 2.053867816459201 | validation: 2.9287811269274915]
	TIME [epoch: 5.72 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054964505408851		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 2.054964505408851 | validation: 2.9169646375970832]
	TIME [epoch: 5.73 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0546560185335547		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 2.0546560185335547 | validation: 2.9226078399879247]
	TIME [epoch: 5.72 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051740382484237		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 2.051740382484237 | validation: 2.9308085489384035]
	TIME [epoch: 5.73 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055555369917182		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 2.055555369917182 | validation: 2.9210563807633494]
	TIME [epoch: 5.75 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0560532458086254		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 2.0560532458086254 | validation: 2.928973369920117]
	TIME [epoch: 5.72 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0554770694151925		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 2.0554770694151925 | validation: 2.9357538287854332]
	TIME [epoch: 5.72 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0513894182092685		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 2.0513894182092685 | validation: 2.9410536881383154]
	TIME [epoch: 5.73 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0538264013090086		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 2.0538264013090086 | validation: 2.9364205753605312]
	TIME [epoch: 5.72 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051213035056731		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 2.051213035056731 | validation: 2.9383316736048917]
	TIME [epoch: 5.72 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0557033172409405		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 2.0557033172409405 | validation: 2.930381576643449]
	TIME [epoch: 5.76 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0570454884870237		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 2.0570454884870237 | validation: 2.934284308509981]
	TIME [epoch: 5.73 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052381637844707		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 2.052381637844707 | validation: 2.943206335593401]
	TIME [epoch: 5.73 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052079638886928		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 2.052079638886928 | validation: 2.9343739674646607]
	TIME [epoch: 5.73 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0512995273559893		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 2.0512995273559893 | validation: 2.9264148679069373]
	TIME [epoch: 5.72 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0511545895952934		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 2.0511545895952934 | validation: 2.9450392359618127]
	TIME [epoch: 5.73 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0516273885628262		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 2.0516273885628262 | validation: 2.945052035364619]
	TIME [epoch: 5.75 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05287860635194		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 2.05287860635194 | validation: 2.9418757070030916]
	TIME [epoch: 5.76 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0549571962829423		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 2.0549571962829423 | validation: 2.934506698108146]
	TIME [epoch: 5.72 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0487569663925362		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 2.0487569663925362 | validation: 2.924766867156463]
	TIME [epoch: 5.74 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05256395139496		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 2.05256395139496 | validation: 2.9324716920492655]
	TIME [epoch: 5.73 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0549452278623703		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 2.0549452278623703 | validation: 2.9379005275664833]
	TIME [epoch: 5.73 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0493689110492324		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 2.0493689110492324 | validation: 2.937243012785474]
	TIME [epoch: 5.72 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056368722714266		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 2.056368722714266 | validation: 2.9451477256317022]
	TIME [epoch: 5.78 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053873054788519		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 2.053873054788519 | validation: 2.949544645898168]
	TIME [epoch: 5.74 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0551072601854337		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 2.0551072601854337 | validation: 2.941940806880032]
	TIME [epoch: 5.73 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058411018956247		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 2.058411018956247 | validation: 2.94192523719124]
	TIME [epoch: 5.74 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0574499082863493		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 2.0574499082863493 | validation: 2.9447256535923167]
	TIME [epoch: 5.72 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054189747856428		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 2.054189747856428 | validation: 2.9456753542316245]
	TIME [epoch: 5.73 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0555758789264558		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 2.0555758789264558 | validation: 2.9534353191419793]
	TIME [epoch: 5.76 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055984176656533		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 2.055984176656533 | validation: 2.9431048999233282]
	TIME [epoch: 5.73 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0542837216510743		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 2.0542837216510743 | validation: 2.9442866401282077]
	TIME [epoch: 5.73 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0534568964771602		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 2.0534568964771602 | validation: 2.9385689703087405]
	TIME [epoch: 5.73 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050921570396686		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 2.050921570396686 | validation: 2.9438943319336]
	TIME [epoch: 5.73 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055720358992586		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 2.055720358992586 | validation: 2.9413443172825255]
	TIME [epoch: 5.71 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0510974961475426		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 2.0510974961475426 | validation: 2.9403660524055932]
	TIME [epoch: 5.71 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05328474356001		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 2.05328474356001 | validation: 2.9370860737505944]
	TIME [epoch: 5.77 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055066978282924		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 2.055066978282924 | validation: 2.936760405433808]
	TIME [epoch: 5.73 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0540509759608976		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 2.0540509759608976 | validation: 2.930851068290292]
	TIME [epoch: 5.73 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0558614484679696		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 2.0558614484679696 | validation: 2.929393706470729]
	TIME [epoch: 5.72 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0519549453446304		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 2.0519549453446304 | validation: 2.94689327021326]
	TIME [epoch: 5.73 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053911649778688		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 2.053911649778688 | validation: 2.9425749746828824]
	TIME [epoch: 5.71 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055890158054645		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 2.055890158054645 | validation: 2.93886689137881]
	TIME [epoch: 5.76 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0552551004640347		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 2.0552551004640347 | validation: 2.9428935932075877]
	TIME [epoch: 5.74 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049269017655397		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 2.049269017655397 | validation: 2.9450638096170167]
	TIME [epoch: 5.74 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054015315669255		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 2.054015315669255 | validation: 2.9345310553381796]
	TIME [epoch: 5.72 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0503938983470773		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 2.0503938983470773 | validation: 2.928276849097882]
	TIME [epoch: 5.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0522593978471777		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 2.0522593978471777 | validation: 2.942906728148044]
	TIME [epoch: 5.74 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05645751066357		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 2.05645751066357 | validation: 2.947680973051322]
	TIME [epoch: 5.73 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0502959111388854		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 2.0502959111388854 | validation: 2.9417981758555753]
	TIME [epoch: 5.78 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052366098560154		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 2.052366098560154 | validation: 2.937809082441453]
	TIME [epoch: 5.73 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0525917649451917		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 2.0525917649451917 | validation: 2.9352876664696703]
	TIME [epoch: 5.72 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0546299195427293		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 2.0546299195427293 | validation: 2.9402326731054225]
	TIME [epoch: 5.72 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052166393426755		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 2.052166393426755 | validation: 2.93472992467307]
	TIME [epoch: 5.72 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0536458974906875		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 2.0536458974906875 | validation: 2.9384267548041816]
	TIME [epoch: 5.72 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053219227806456		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 2.053219227806456 | validation: 2.931207091221078]
	TIME [epoch: 5.76 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.046432859902907		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 2.046432859902907 | validation: 2.945315149938784]
	TIME [epoch: 5.74 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0520976805887616		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 2.0520976805887616 | validation: 2.9441340085611434]
	TIME [epoch: 5.73 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0535551789657798		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 2.0535551789657798 | validation: 2.9453662984279068]
	TIME [epoch: 5.72 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0515850223951015		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 2.0515850223951015 | validation: 2.9550570962050133]
	TIME [epoch: 5.73 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0579598799115786		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 2.0579598799115786 | validation: 2.93996987655308]
	TIME [epoch: 5.73 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0528983386303663		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 2.0528983386303663 | validation: 2.9417453947841263]
	TIME [epoch: 5.72 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0523791020987368		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 2.0523791020987368 | validation: 2.9471194342683042]
	TIME [epoch: 5.78 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0528426283426873		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 2.0528426283426873 | validation: 2.9401128593889974]
	TIME [epoch: 5.72 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055589873260099		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 2.055589873260099 | validation: 2.933348094752274]
	TIME [epoch: 5.73 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0543462467773876		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 2.0543462467773876 | validation: 2.9233632748028606]
	TIME [epoch: 5.73 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0525135813302366		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 2.0525135813302366 | validation: 2.9521309478162845]
	TIME [epoch: 5.72 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0528590292495026		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 2.0528590292495026 | validation: 2.9440655380185468]
	TIME [epoch: 5.72 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0537278993493198		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 2.0537278993493198 | validation: 2.937222040628801]
	TIME [epoch: 5.75 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055075075457252		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 2.055075075457252 | validation: 2.9336814771177946]
	TIME [epoch: 5.73 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052852823162116		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 2.052852823162116 | validation: 2.944257552373699]
	TIME [epoch: 5.72 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054477138367026		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 2.054477138367026 | validation: 2.9410274149143154]
	TIME [epoch: 5.72 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0498533088559863		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 2.0498533088559863 | validation: 2.9334973174368764]
	TIME [epoch: 5.73 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052600664682755		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 2.052600664682755 | validation: 2.92422720692421]
	TIME [epoch: 5.74 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0532217042935565		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 2.0532217042935565 | validation: 2.9338668439115327]
	TIME [epoch: 5.74 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050643303050356		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 2.050643303050356 | validation: 2.9349011528349553]
	TIME [epoch: 5.75 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0543085290753074		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 2.0543085290753074 | validation: 2.9309342800536924]
	TIME [epoch: 5.73 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0505860845257797		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 2.0505860845257797 | validation: 2.9370750558367593]
	TIME [epoch: 5.72 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05395813665187		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 2.05395813665187 | validation: 2.9416249049698946]
	TIME [epoch: 5.72 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0517008450389		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 2.0517008450389 | validation: 2.93335565010056]
	TIME [epoch: 5.72 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055075924416635		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 2.055075924416635 | validation: 2.9458153964958638]
	TIME [epoch: 5.73 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054062104895295		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 2.054062104895295 | validation: 2.9457842723984973]
	TIME [epoch: 5.76 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0524135282866616		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 2.0524135282866616 | validation: 2.9364325612801805]
	TIME [epoch: 5.73 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0530321312669653		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 2.0530321312669653 | validation: 2.933931115242831]
	TIME [epoch: 5.72 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052554349958301		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 2.052554349958301 | validation: 2.929985670875684]
	TIME [epoch: 5.71 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053395900034261		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 2.053395900034261 | validation: 2.94066131862325]
	TIME [epoch: 5.72 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0522140079518874		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 2.0522140079518874 | validation: 2.939269793812463]
	TIME [epoch: 5.72 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051282108274939		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 2.051282108274939 | validation: 2.9314554954730307]
	TIME [epoch: 5.73 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0507831929173275		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 2.0507831929173275 | validation: 2.933933088626875]
	TIME [epoch: 5.76 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0558141040609317		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 2.0558141040609317 | validation: 2.9265555418111786]
	TIME [epoch: 5.73 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054788455719389		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 2.054788455719389 | validation: 2.925525006456798]
	TIME [epoch: 5.73 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05740399816677		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 2.05740399816677 | validation: 2.923219782745462]
	TIME [epoch: 5.72 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0539307986875954		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 2.0539307986875954 | validation: 2.925069983127761]
	TIME [epoch: 5.72 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0539272136358218		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 2.0539272136358218 | validation: 2.929478062076521]
	TIME [epoch: 5.72 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052643235221757		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 2.052643235221757 | validation: 2.923410649073462]
	TIME [epoch: 5.76 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0536424359360597		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 2.0536424359360597 | validation: 2.9245962300174306]
	TIME [epoch: 5.73 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0502806983349826		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 2.0502806983349826 | validation: 2.9310123942992163]
	TIME [epoch: 5.73 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0543723314629814		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 2.0543723314629814 | validation: 2.938577450532355]
	TIME [epoch: 5.73 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0530956229306927		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 2.0530956229306927 | validation: 2.929829451040006]
	TIME [epoch: 5.73 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05399598078846		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 2.05399598078846 | validation: 2.9305657535866136]
	TIME [epoch: 5.73 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0492189944432044		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 2.0492189944432044 | validation: 2.9251982629893756]
	TIME [epoch: 5.75 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0510366018369632		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 2.0510366018369632 | validation: 2.9359611644915407]
	TIME [epoch: 5.76 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0539496149647567		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 2.0539496149647567 | validation: 2.940075196649734]
	TIME [epoch: 5.72 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0535354418698746		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 2.0535354418698746 | validation: 2.935716967829762]
	TIME [epoch: 5.72 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0521823483418036		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 2.0521823483418036 | validation: 2.9376785995957926]
	TIME [epoch: 5.72 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052299891617794		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 2.052299891617794 | validation: 2.934555000374351]
	TIME [epoch: 5.72 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051606841265091		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 2.051606841265091 | validation: 2.9309136464251204]
	TIME [epoch: 5.71 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.048291493986258		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 2.048291493986258 | validation: 2.936030353866563]
	TIME [epoch: 5.76 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0541469546567503		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 2.0541469546567503 | validation: 2.9360044198088042]
	TIME [epoch: 5.72 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051520642909355		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 2.051520642909355 | validation: 2.9413117237440223]
	TIME [epoch: 5.72 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051903447813338		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 2.051903447813338 | validation: 2.9328815958366996]
	TIME [epoch: 5.71 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0531163934532		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 2.0531163934532 | validation: 2.9265589747129663]
	TIME [epoch: 5.72 sec]
Finished training in 11664.568 seconds.
