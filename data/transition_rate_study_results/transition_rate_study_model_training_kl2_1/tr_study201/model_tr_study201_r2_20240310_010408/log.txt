Args:
Namespace(name='model_tr_study201', outdir='out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2', training_data='data/transition_rate_studies/tr_study201/tr_study201_training/r2', validation_data='data/transition_rate_studies/tr_study201/tr_study201_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1452760551

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.85636275073007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.85636275073007 | validation: 13.49037684168488]
	TIME [epoch: 93.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.58556541964338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.58556541964338 | validation: 13.363144582479736]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.848717000307081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.848717000307081 | validation: 11.858153961238987]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.030253708406374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.030253708406374 | validation: 8.677175001393035]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.679192919380411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.679192919380411 | validation: 7.3071509734213125]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2799594571681165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2799594571681165 | validation: 5.907277263901502]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.965624446687231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.965624446687231 | validation: 5.992024312983077]
	TIME [epoch: 5.69 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.527515519218199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.527515519218199 | validation: 7.146777416416662]
	TIME [epoch: 5.74 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.210958365502768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.210958365502768 | validation: 4.9736319964769296]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.479667363373885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.479667363373885 | validation: 5.26930554094514]
	TIME [epoch: 5.7 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.352633079326947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.352633079326947 | validation: 4.463323744456685]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.140528329985132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.140528329985132 | validation: 4.943830900139234]
	TIME [epoch: 5.71 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.837958656473569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.837958656473569 | validation: 6.305399465763418]
	TIME [epoch: 5.71 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.038981888566257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.038981888566257 | validation: 5.162449470601216]
	TIME [epoch: 5.71 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.873443188063259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.873443188063259 | validation: 4.476825122596639]
	TIME [epoch: 5.75 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.746047550441244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.746047550441244 | validation: 4.92708438105873]
	TIME [epoch: 5.72 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.867099117017452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.867099117017452 | validation: 7.828640961577787]
	TIME [epoch: 5.71 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.151390287298385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.151390287298385 | validation: 6.10284822456247]
	TIME [epoch: 5.71 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.068233640156482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.068233640156482 | validation: 5.3877021103525475]
	TIME [epoch: 5.71 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.668632821408095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.668632821408095 | validation: 4.520893245709353]
	TIME [epoch: 5.71 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.646809172091702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.646809172091702 | validation: 4.4011185097104795]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.783210252068974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.783210252068974 | validation: 4.35371000323034]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.650161084287412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.650161084287412 | validation: 5.0105457198897385]
	TIME [epoch: 5.71 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.908279610031315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.908279610031315 | validation: 4.774438996531398]
	TIME [epoch: 5.71 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.620181640003697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.620181640003697 | validation: 6.664252147862036]
	TIME [epoch: 5.71 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.927193516926289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.927193516926289 | validation: 4.884180067607263]
	TIME [epoch: 5.71 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.63951892746845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.63951892746845 | validation: 5.011786200445027]
	TIME [epoch: 5.71 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.66405506256266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.66405506256266 | validation: 4.044736989296419]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.571167810227123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.571167810227123 | validation: 4.322692450439105]
	TIME [epoch: 5.72 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.159315176936984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.159315176936984 | validation: 4.5468994300407095]
	TIME [epoch: 5.71 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.834429114202232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.834429114202232 | validation: 4.997719250396268]
	TIME [epoch: 5.71 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480499589151075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.480499589151075 | validation: 4.709511537775191]
	TIME [epoch: 5.71 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.151817385949018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.151817385949018 | validation: 4.055106789005066]
	TIME [epoch: 5.71 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.292855463708228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.292855463708228 | validation: 4.446589945696368]
	TIME [epoch: 5.71 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.164983955752638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.164983955752638 | validation: 5.2625755149644355]
	TIME [epoch: 5.75 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.714798661864119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.714798661864119 | validation: 5.2457536937799505]
	TIME [epoch: 5.71 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.526168492069754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.526168492069754 | validation: 4.086715817079035]
	TIME [epoch: 5.71 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.000511395789987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.000511395789987 | validation: 4.375431669407749]
	TIME [epoch: 5.71 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.295204410263103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.295204410263103 | validation: 3.6153596459705004]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2314381914231225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2314381914231225 | validation: 3.83228866279258]
	TIME [epoch: 5.71 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.174996565989362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.174996565989362 | validation: 4.488657531804879]
	TIME [epoch: 5.72 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.119831961443006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.119831961443006 | validation: 4.962074152719366]
	TIME [epoch: 5.73 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4245009595384595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4245009595384595 | validation: 3.654363513937286]
	TIME [epoch: 5.71 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2886157205318245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2886157205318245 | validation: 4.369532479580949]
	TIME [epoch: 5.71 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.354004092391917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.354004092391917 | validation: 3.8120828480221647]
	TIME [epoch: 5.7 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.091868600569106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.091868600569106 | validation: 3.97245027531642]
	TIME [epoch: 5.71 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8527379353508775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8527379353508775 | validation: 5.972432555012115]
	TIME [epoch: 5.7 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1695812147094085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1695812147094085 | validation: 3.9749260918500857]
	TIME [epoch: 5.73 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7985675483808934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7985675483808934 | validation: 5.346506385254941]
	TIME [epoch: 5.72 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9283874155669225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9283874155669225 | validation: 3.6604544714300435]
	TIME [epoch: 5.71 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.287482924804474		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.287482924804474 | validation: 3.713120978954153]
	TIME [epoch: 5.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9149723537107968		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.9149723537107968 | validation: 4.076609409703854]
	TIME [epoch: 5.7 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.772867000581602		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.772867000581602 | validation: 3.3926843929547985]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.636634501410674		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.636634501410674 | validation: 4.393047619160628]
	TIME [epoch: 5.71 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6358143047190348		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.6358143047190348 | validation: 4.205322870630873]
	TIME [epoch: 5.73 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.811441533597594		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.811441533597594 | validation: 3.7285956349943876]
	TIME [epoch: 5.71 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6287574358339008		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.6287574358339008 | validation: 3.648756801062371]
	TIME [epoch: 5.71 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.497812991961421		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.497812991961421 | validation: 4.283662939848681]
	TIME [epoch: 5.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8500298814630174		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.8500298814630174 | validation: 3.3923331893006843]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.424485965872755		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.424485965872755 | validation: 5.7637389342593295]
	TIME [epoch: 5.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.038362396003303		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.038362396003303 | validation: 3.56148224502777]
	TIME [epoch: 5.71 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5667907451856755		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.5667907451856755 | validation: 3.706012359145839]
	TIME [epoch: 5.74 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.518993473443902		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.518993473443902 | validation: 3.4913834818652063]
	TIME [epoch: 5.71 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5089227677086727		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.5089227677086727 | validation: 3.873744580379658]
	TIME [epoch: 5.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3668183745063276		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.3668183745063276 | validation: 3.3254641472623785]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.385256562748479		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.385256562748479 | validation: 3.5299164220904613]
	TIME [epoch: 5.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.427547014218283		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.427547014218283 | validation: 3.9013802381181355]
	TIME [epoch: 5.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.419969213992573		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.419969213992573 | validation: 3.0094498909831917]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3144673728705545		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.3144673728705545 | validation: 3.5760378802240194]
	TIME [epoch: 5.75 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.351872336320103		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.351872336320103 | validation: 3.360713018249329]
	TIME [epoch: 5.71 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4671779735462276		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.4671779735462276 | validation: 3.037697144372056]
	TIME [epoch: 5.71 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3412358839171294		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.3412358839171294 | validation: 3.3531542663770946]
	TIME [epoch: 5.71 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.349824607837986		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.349824607837986 | validation: 3.17520161721519]
	TIME [epoch: 5.71 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.160122812638824		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.160122812638824 | validation: 2.8879506211862274]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2276065954986093		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.2276065954986093 | validation: 2.917292858826335]
	TIME [epoch: 5.74 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7314614052065953		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.7314614052065953 | validation: 2.8819057352569986]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8771541977382		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.8771541977382 | validation: 3.0547783042379253]
	TIME [epoch: 5.7 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9645841092021183		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.9645841092021183 | validation: 3.929027813343986]
	TIME [epoch: 5.7 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.277226334115723		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.277226334115723 | validation: 3.127092887248924]
	TIME [epoch: 5.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.036052848375383		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.036052848375383 | validation: 3.1689611303157914]
	TIME [epoch: 5.7 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.376894623948901		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.376894623948901 | validation: 3.077516919674659]
	TIME [epoch: 5.73 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.344089512603821		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.344089512603821 | validation: 3.281647374411906]
	TIME [epoch: 5.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9505592719170206		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.9505592719170206 | validation: 4.007003821721382]
	TIME [epoch: 5.71 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.281206685602531		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.281206685602531 | validation: 3.083080590454082]
	TIME [epoch: 5.7 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.015029071199981		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.015029071199981 | validation: 3.5705868492267014]
	TIME [epoch: 5.7 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1761380767803655		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.1761380767803655 | validation: 3.977053824984211]
	TIME [epoch: 5.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.070110873151326		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.070110873151326 | validation: 3.46729915394017]
	TIME [epoch: 5.71 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.23445457445192		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.23445457445192 | validation: 2.8296561816321355]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.895912556567435		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.895912556567435 | validation: 3.358837094150985]
	TIME [epoch: 5.71 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2446540194147775		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.2446540194147775 | validation: 3.788245512268249]
	TIME [epoch: 5.7 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1467481140883615		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.1467481140883615 | validation: 2.8402173727373414]
	TIME [epoch: 5.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9028503512052204		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.9028503512052204 | validation: 3.167190877983551]
	TIME [epoch: 5.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.990521722711478		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.990521722711478 | validation: 2.9384819900031354]
	TIME [epoch: 5.71 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.968059333704654		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.968059333704654 | validation: 3.5362123109459653]
	TIME [epoch: 5.73 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9031364159537603		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.9031364159537603 | validation: 2.8860749131044856]
	TIME [epoch: 5.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.87332453851409		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.87332453851409 | validation: 2.743422610024359]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9891646691391713		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.9891646691391713 | validation: 3.5149161859339872]
	TIME [epoch: 5.7 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.342995811959785		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.342995811959785 | validation: 2.610687104781835]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.357898097834599		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.357898097834599 | validation: 4.448807476447792]
	TIME [epoch: 5.71 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2222360558883505		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.2222360558883505 | validation: 2.9798918124220712]
	TIME [epoch: 5.73 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6923517939627355		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.6923517939627355 | validation: 3.5272462375507394]
	TIME [epoch: 5.71 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8973000960999307		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.8973000960999307 | validation: 3.15409231912703]
	TIME [epoch: 5.7 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.072866678231001		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.072866678231001 | validation: 3.809250219944761]
	TIME [epoch: 5.7 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0924654370945484		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.0924654370945484 | validation: 3.2918871006561767]
	TIME [epoch: 5.7 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7304958363344944		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.7304958363344944 | validation: 3.600022017450936]
	TIME [epoch: 5.71 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.009477502490581		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.009477502490581 | validation: 2.6253588379384816]
	TIME [epoch: 5.73 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.554266540449435		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.554266540449435 | validation: 2.9480422830102295]
	TIME [epoch: 5.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0467647818534562		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.0467647818534562 | validation: 3.3221576451592942]
	TIME [epoch: 5.71 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9128105976234897		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.9128105976234897 | validation: 3.1637790558699863]
	TIME [epoch: 5.7 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8538912744378253		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.8538912744378253 | validation: 2.916968803440186]
	TIME [epoch: 5.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7228025048612046		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.7228025048612046 | validation: 3.1789799817907327]
	TIME [epoch: 5.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0313069105846657		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.0313069105846657 | validation: 3.635248958320749]
	TIME [epoch: 5.74 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.326595616882561		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.326595616882561 | validation: 2.58632304802568]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7756442239729475		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.7756442239729475 | validation: 5.255372470949742]
	TIME [epoch: 5.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5966425328712686		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.5966425328712686 | validation: 3.90179002017493]
	TIME [epoch: 5.7 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2585085352310057		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.2585085352310057 | validation: 2.3251664699266836]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.632627043592203		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.632627043592203 | validation: 2.5041820468723617]
	TIME [epoch: 5.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.577131824675255		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.577131824675255 | validation: 2.490405471425273]
	TIME [epoch: 5.73 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6522938122702913		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.6522938122702913 | validation: 3.1087942353543556]
	TIME [epoch: 5.73 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8376075487824073		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.8376075487824073 | validation: 2.5799440276419694]
	TIME [epoch: 5.71 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7933629715134325		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.7933629715134325 | validation: 2.4918536521464887]
	TIME [epoch: 5.72 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6271534066833784		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.6271534066833784 | validation: 2.576823095638533]
	TIME [epoch: 5.72 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7395862186016258		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.7395862186016258 | validation: 2.429541753136551]
	TIME [epoch: 5.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.590071121381931		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.590071121381931 | validation: 3.0422131947401354]
	TIME [epoch: 5.71 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7257117423764603		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.7257117423764603 | validation: 2.5775986857651687]
	TIME [epoch: 5.73 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.572494936530716		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.572494936530716 | validation: 2.629834462377586]
	TIME [epoch: 5.72 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.908782281071896		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.908782281071896 | validation: 2.7829180138019787]
	TIME [epoch: 5.7 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6774560231674442		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.6774560231674442 | validation: 2.64207127665764]
	TIME [epoch: 5.69 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.550834476340074		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.550834476340074 | validation: 2.525419016510304]
	TIME [epoch: 5.71 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5758110509716627		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.5758110509716627 | validation: 2.618172833751202]
	TIME [epoch: 5.71 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.509405441804151		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.509405441804151 | validation: 3.085562927000691]
	TIME [epoch: 5.75 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6844922988020046		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.6844922988020046 | validation: 2.866950705198301]
	TIME [epoch: 5.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7161626888599018		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.7161626888599018 | validation: 2.589199034215075]
	TIME [epoch: 5.71 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4416448442122363		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.4416448442122363 | validation: 2.9846274215336233]
	TIME [epoch: 5.71 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7312480228727716		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.7312480228727716 | validation: 2.4358604292417207]
	TIME [epoch: 5.71 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.90577474432333		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.90577474432333 | validation: 2.1905698838618166]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7790459422805496		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.7790459422805496 | validation: 2.9144698944734055]
	TIME [epoch: 5.72 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6150772578930783		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.6150772578930783 | validation: 2.6142661387294948]
	TIME [epoch: 5.74 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.482534331261323		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.482534331261323 | validation: 3.2812611274694756]
	TIME [epoch: 5.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.71865282890479		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.71865282890479 | validation: 2.3345502843252]
	TIME [epoch: 5.71 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2864766726630203		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.2864766726630203 | validation: 2.9763690176897035]
	TIME [epoch: 5.69 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5771243222931037		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.5771243222931037 | validation: 2.5223694144601563]
	TIME [epoch: 5.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.866747283890054		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.866747283890054 | validation: 2.3453693931525557]
	TIME [epoch: 5.71 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4706427670874804		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.4706427670874804 | validation: 2.5528291993965717]
	TIME [epoch: 5.73 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.546083139971998		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.546083139971998 | validation: 3.4064893502604945]
	TIME [epoch: 5.7 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7783766916801063		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.7783766916801063 | validation: 2.1656882655282708]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.457282385094441		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.457282385094441 | validation: 3.4885617536982783]
	TIME [epoch: 5.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5762511665528085		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 2.5762511665528085 | validation: 2.8226890054901634]
	TIME [epoch: 5.72 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.471667077458362		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.471667077458362 | validation: 2.6130866457276283]
	TIME [epoch: 5.73 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3023269602157668		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.3023269602157668 | validation: 3.2339915197201576]
	TIME [epoch: 5.73 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5794298906788664		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.5794298906788664 | validation: 2.386113415600596]
	TIME [epoch: 5.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.574330795350201		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.574330795350201 | validation: 2.1120225745258456]
	TIME [epoch: 5.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.371518711893155		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.371518711893155 | validation: 2.329273347279646]
	TIME [epoch: 5.71 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1796810324032223		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.1796810324032223 | validation: 3.323825246714055]
	TIME [epoch: 5.71 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.416673115117132		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.416673115117132 | validation: 3.4057627105770236]
	TIME [epoch: 5.72 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9816067994095237		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.9816067994095237 | validation: 4.519975883219445]
	TIME [epoch: 5.72 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1274138416604678		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.1274138416604678 | validation: 3.078207581639406]
	TIME [epoch: 5.7 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4156858496220015		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.4156858496220015 | validation: 2.6551875480395837]
	TIME [epoch: 5.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3326195694521266		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.3326195694521266 | validation: 2.6480509291304193]
	TIME [epoch: 5.71 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3530156445059505		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.3530156445059505 | validation: 2.255026410288638]
	TIME [epoch: 5.71 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3269380800255863		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.3269380800255863 | validation: 2.8820725547696577]
	TIME [epoch: 5.73 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4738589287436574		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.4738589287436574 | validation: 2.460228245881399]
	TIME [epoch: 5.73 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5103181786309774		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.5103181786309774 | validation: 2.259508882485567]
	TIME [epoch: 5.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.621789588990537		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.621789588990537 | validation: 2.169532425171567]
	TIME [epoch: 5.71 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2325847977752407		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.2325847977752407 | validation: 2.203835251798342]
	TIME [epoch: 5.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4142783420544025		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.4142783420544025 | validation: 2.137633291500269]
	TIME [epoch: 5.71 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.21147663883238		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.21147663883238 | validation: 2.375073930815956]
	TIME [epoch: 5.72 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2356234401892245		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.2356234401892245 | validation: 2.8658386079641436]
	TIME [epoch: 5.73 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.206958640562514		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.206958640562514 | validation: 2.985396636636382]
	TIME [epoch: 5.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8074880071952824		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.8074880071952824 | validation: 1.8887853228039522]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2372152094244138		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.2372152094244138 | validation: 2.944300485922505]
	TIME [epoch: 5.7 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3955990912605065		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.3955990912605065 | validation: 2.5398002584080546]
	TIME [epoch: 5.69 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2993534373201343		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.2993534373201343 | validation: 2.2835786075355506]
	TIME [epoch: 5.71 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4119640242044516		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.4119640242044516 | validation: 2.1236146917729024]
	TIME [epoch: 5.74 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1856324688979796		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.1856324688979796 | validation: 2.3546791003824343]
	TIME [epoch: 5.72 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2712732474672106		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.2712732474672106 | validation: 2.302918775931342]
	TIME [epoch: 5.7 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.532470294753131		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 3.532470294753131 | validation: 5.464533035221783]
	TIME [epoch: 5.71 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.258299901316846		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.258299901316846 | validation: 2.798444854008135]
	TIME [epoch: 5.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3994832363485097		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.3994832363485097 | validation: 2.376722484688591]
	TIME [epoch: 5.69 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4198218597752286		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.4198218597752286 | validation: 2.082044815342422]
	TIME [epoch: 5.74 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1918945205943707		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.1918945205943707 | validation: 2.0611149785501097]
	TIME [epoch: 5.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0615622013710904		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.0615622013710904 | validation: 2.4014084484786062]
	TIME [epoch: 5.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2798561574371807		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.2798561574371807 | validation: 2.355514983591508]
	TIME [epoch: 5.69 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.236798488652468		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.236798488652468 | validation: 1.9398956618573886]
	TIME [epoch: 5.69 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1254108507075036		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.1254108507075036 | validation: 2.4631169129528754]
	TIME [epoch: 5.69 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.152009963824563		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.152009963824563 | validation: 2.56558985332695]
	TIME [epoch: 5.71 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6361477120976975		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.6361477120976975 | validation: 1.845280272714125]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1898827054617978		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.1898827054617978 | validation: 2.2725733487197806]
	TIME [epoch: 5.71 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.193442213264943		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.193442213264943 | validation: 3.0484912783519618]
	TIME [epoch: 5.69 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2528480351837215		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 2.2528480351837215 | validation: 2.009495511312016]
	TIME [epoch: 5.71 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.082666393217735		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.082666393217735 | validation: 2.735675385243723]
	TIME [epoch: 5.71 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.187551792110724		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.187551792110724 | validation: 2.1330058854186493]
	TIME [epoch: 5.71 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.239819069305903		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.239819069305903 | validation: 1.8953724093596724]
	TIME [epoch: 5.73 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.103852194172898		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.103852194172898 | validation: 2.0825352361297176]
	TIME [epoch: 5.71 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2329683728773695		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.2329683728773695 | validation: 1.8565761493150996]
	TIME [epoch: 5.71 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0817463320917433		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.0817463320917433 | validation: 2.030752892498838]
	TIME [epoch: 5.71 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.212606745298188		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.212606745298188 | validation: 2.7987247599035956]
	TIME [epoch: 5.71 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.21943155889032		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.21943155889032 | validation: 2.09098134673084]
	TIME [epoch: 5.71 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0027852486783253		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.0027852486783253 | validation: 2.586243679656487]
	TIME [epoch: 5.73 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.028994802582918		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.028994802582918 | validation: 2.259724022737474]
	TIME [epoch: 5.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1821726770985235		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.1821726770985235 | validation: 2.7270911263580895]
	TIME [epoch: 5.69 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1312777121606796		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.1312777121606796 | validation: 1.8800007866779411]
	TIME [epoch: 5.69 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1153935828189248		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.1153935828189248 | validation: 2.1150730866789313]
	TIME [epoch: 5.71 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2556695334113925		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.2556695334113925 | validation: 1.913827834855811]
	TIME [epoch: 5.69 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.886367210627529		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.886367210627529 | validation: 1.9281019546475013]
	TIME [epoch: 5.74 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1227246001496596		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.1227246001496596 | validation: 1.9551585426052691]
	TIME [epoch: 5.71 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.96843607482418		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.96843607482418 | validation: 1.7781300569391265]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0005720269601754		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.0005720269601754 | validation: 2.4665146176889654]
	TIME [epoch: 5.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9855378098336982		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.9855378098336982 | validation: 2.749718284031632]
	TIME [epoch: 5.71 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312868497785613		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.312868497785613 | validation: 1.725494554116911]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9922682331233346		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.9922682331233346 | validation: 1.8951113617322635]
	TIME [epoch: 5.75 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9923232381656835		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.9923232381656835 | validation: 2.246624630570233]
	TIME [epoch: 5.73 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0773536935959656		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.0773536935959656 | validation: 1.9448595493003356]
	TIME [epoch: 5.72 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9047006362156833		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.9047006362156833 | validation: 2.461942732741528]
	TIME [epoch: 5.72 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9727768548462568		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.9727768548462568 | validation: 2.5016322267747273]
	TIME [epoch: 5.72 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.044326935619545		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.044326935619545 | validation: 3.049417700386747]
	TIME [epoch: 5.72 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284307953950978		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.284307953950978 | validation: 1.703147973670396]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8899081545641898		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.8899081545641898 | validation: 2.278893678860995]
	TIME [epoch: 5.74 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0577930928306443		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.0577930928306443 | validation: 1.7360615234725116]
	TIME [epoch: 5.72 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8781021023204123		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.8781021023204123 | validation: 1.7076745513051446]
	TIME [epoch: 5.72 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.941799467380667		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.941799467380667 | validation: 2.18455862913827]
	TIME [epoch: 5.71 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.957741461174144		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.957741461174144 | validation: 1.8215142563591533]
	TIME [epoch: 5.72 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26163930378071		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.26163930378071 | validation: 2.8092763242966727]
	TIME [epoch: 5.74 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1865455674404446		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.1865455674404446 | validation: 4.424276127670551]
	TIME [epoch: 5.73 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9080934415343833		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.9080934415343833 | validation: 2.6952451716587076]
	TIME [epoch: 5.72 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083587396252078		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 2.083587396252078 | validation: 1.81606380839383]
	TIME [epoch: 5.72 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.036217802076126		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.036217802076126 | validation: 3.247524405769059]
	TIME [epoch: 5.71 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.452200018307657		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.452200018307657 | validation: 1.9789975917808686]
	TIME [epoch: 5.71 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9740582977303438		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.9740582977303438 | validation: 1.621819151627102]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.176863718195793		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.176863718195793 | validation: 1.7794976390656985]
	TIME [epoch: 5.73 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.918219173640246		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.918219173640246 | validation: 1.7663254400692279]
	TIME [epoch: 5.72 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9154197709578074		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.9154197709578074 | validation: 1.716126947497051]
	TIME [epoch: 5.72 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.813985445086606		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.813985445086606 | validation: 1.7882266135178946]
	TIME [epoch: 5.71 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9041218736960381		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.9041218736960381 | validation: 1.8246845454950893]
	TIME [epoch: 5.72 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9993201007522021		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.9993201007522021 | validation: 1.8929544384662302]
	TIME [epoch: 5.74 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.842444898163476		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.842444898163476 | validation: 1.8240448117102963]
	TIME [epoch: 5.73 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8888063109621474		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.8888063109621474 | validation: 1.759487488106505]
	TIME [epoch: 5.72 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8578997780241602		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.8578997780241602 | validation: 1.937174647860478]
	TIME [epoch: 5.71 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074501644383222		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.074501644383222 | validation: 1.5282404947136254]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731975372406367		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.731975372406367 | validation: 1.7487284973302628]
	TIME [epoch: 5.71 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8204962402013738		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.8204962402013738 | validation: 1.6298210170465615]
	TIME [epoch: 5.71 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9306142210329358		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.9306142210329358 | validation: 1.3180831441160112]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9121752021033815		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.9121752021033815 | validation: 2.4000269714385105]
	TIME [epoch: 5.72 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9986850698468326		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.9986850698468326 | validation: 1.3552820931628935]
	TIME [epoch: 5.71 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7258370804835852		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.7258370804835852 | validation: 1.6737618004229027]
	TIME [epoch: 5.71 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.10909332641731		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.10909332641731 | validation: 2.9921340571229598]
	TIME [epoch: 5.71 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.644415271804908		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 2.644415271804908 | validation: 2.0092942172452437]
	TIME [epoch: 5.72 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.091716889784231		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.091716889784231 | validation: 1.28647448877164]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6584051702738944		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.6584051702738944 | validation: 1.1866509854149743]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7812294492104177		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.7812294492104177 | validation: 1.1340917928274497]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6316932504974806		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.6316932504974806 | validation: 1.185295099372855]
	TIME [epoch: 5.72 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8142843852135104		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.8142843852135104 | validation: 1.219751637771463]
	TIME [epoch: 5.71 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7075842722741537		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.7075842722741537 | validation: 1.5598689497038642]
	TIME [epoch: 5.72 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7186978049247934		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.7186978049247934 | validation: 1.3451706417371616]
	TIME [epoch: 5.74 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.872455037108101		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.872455037108101 | validation: 1.1635674771202924]
	TIME [epoch: 5.72 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4635999813501535		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.4635999813501535 | validation: 1.1270407763534664]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7282121897138119		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.7282121897138119 | validation: 1.1180149469206606]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.615133860383639		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.615133860383639 | validation: 1.2490011531032126]
	TIME [epoch: 5.71 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.63804491582688		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.63804491582688 | validation: 1.028363768720442]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5893059384836477		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.5893059384836477 | validation: 1.0750984864604334]
	TIME [epoch: 5.74 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4889184505642938		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.4889184505642938 | validation: 1.393936096529976]
	TIME [epoch: 5.72 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7737275991761756		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.7737275991761756 | validation: 1.3623721249675569]
	TIME [epoch: 5.72 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6980674694690776		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.6980674694690776 | validation: 0.9811247518192725]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.665917605787932		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.665917605787932 | validation: 1.5280387477762987]
	TIME [epoch: 5.72 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6247605149097466		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.6247605149097466 | validation: 1.2608274061122955]
	TIME [epoch: 5.75 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7027180013951362		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.7027180013951362 | validation: 1.546892764642116]
	TIME [epoch: 5.72 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.59235730038559		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.59235730038559 | validation: 1.2710548391852357]
	TIME [epoch: 5.71 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.824321929808841		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.824321929808841 | validation: 1.2228427289340678]
	TIME [epoch: 5.72 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7975415594662696		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.7975415594662696 | validation: 1.0791670567409402]
	TIME [epoch: 5.72 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.541391799082831		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.541391799082831 | validation: 1.35719801258414]
	TIME [epoch: 5.72 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5927251124156274		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.5927251124156274 | validation: 1.6751448895423742]
	TIME [epoch: 5.75 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6110297179013093		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.6110297179013093 | validation: 1.3024031843583455]
	TIME [epoch: 5.72 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6206940351525638		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.6206940351525638 | validation: 1.89079594380064]
	TIME [epoch: 5.72 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.527714072244431		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.527714072244431 | validation: 1.655076051766784]
	TIME [epoch: 5.72 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5414383871807413		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.5414383871807413 | validation: 1.0519368720803866]
	TIME [epoch: 5.71 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.412743292617136		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.412743292617136 | validation: 2.0432236224356304]
	TIME [epoch: 5.71 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1594837528423256		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.1594837528423256 | validation: 1.2732528018647034]
	TIME [epoch: 5.75 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.019789723858926		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.019789723858926 | validation: 0.9926323953564925]
	TIME [epoch: 5.72 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.517813081063522		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.517813081063522 | validation: 1.289088835428688]
	TIME [epoch: 5.71 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4241421037067103		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.4241421037067103 | validation: 1.2397365907629065]
	TIME [epoch: 5.71 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6384386444546		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.6384386444546 | validation: 1.0062519207435943]
	TIME [epoch: 5.71 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4003887619378153		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.4003887619378153 | validation: 1.4374262783292102]
	TIME [epoch: 5.72 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.553944651258961		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.553944651258961 | validation: 1.0164466988144418]
	TIME [epoch: 5.74 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4081477965416516		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.4081477965416516 | validation: 1.0633147616513878]
	TIME [epoch: 5.73 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.426085665575354		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.426085665575354 | validation: 0.9916612170563931]
	TIME [epoch: 5.72 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.422723654458959		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.422723654458959 | validation: 0.8889877252808782]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3713284929488165		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.3713284929488165 | validation: 0.9297142326202001]
	TIME [epoch: 5.72 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5028308338554308		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.5028308338554308 | validation: 1.5828394084960054]
	TIME [epoch: 5.72 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4887717198653934		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.4887717198653934 | validation: 0.9269379406718536]
	TIME [epoch: 5.75 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4894339279443412		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.4894339279443412 | validation: 0.8554127601912191]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4061862430420677		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.4061862430420677 | validation: 0.9500149709403194]
	TIME [epoch: 5.71 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3863769519354103		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.3863769519354103 | validation: 1.5185073676923537]
	TIME [epoch: 5.71 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8799816388850608		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.8799816388850608 | validation: 2.317998948879305]
	TIME [epoch: 5.71 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9172110582052708		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.9172110582052708 | validation: 1.5124225203686086]
	TIME [epoch: 5.71 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4297597796030925		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.4297597796030925 | validation: 2.4630639594716004]
	TIME [epoch: 5.75 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6955448835470899		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.6955448835470899 | validation: 1.1195760209638588]
	TIME [epoch: 5.72 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3295094278058344		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.3295094278058344 | validation: 0.9128820028004125]
	TIME [epoch: 5.71 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3834827910242764		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.3834827910242764 | validation: 2.0345802515080345]
	TIME [epoch: 5.71 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6724336588345006		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.6724336588345006 | validation: 0.8889950841963549]
	TIME [epoch: 5.71 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3338044557700897		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.3338044557700897 | validation: 0.9816098300593534]
	TIME [epoch: 5.71 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5980930676143807		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.5980930676143807 | validation: 0.9683825319342739]
	TIME [epoch: 5.75 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4354241634826481		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.4354241634826481 | validation: 1.1851474001209779]
	TIME [epoch: 5.72 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3044786294469142		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.3044786294469142 | validation: 0.8585729728375495]
	TIME [epoch: 5.71 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6044391615453342		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.6044391615453342 | validation: 0.9842995924835566]
	TIME [epoch: 5.71 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3412858326300525		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.3412858326300525 | validation: 1.8465178684075887]
	TIME [epoch: 5.71 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4823602601553532		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.4823602601553532 | validation: 1.036366287889371]
	TIME [epoch: 5.71 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3929114140107444		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.3929114140107444 | validation: 1.2967808120658868]
	TIME [epoch: 5.75 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4711655777839443		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.4711655777839443 | validation: 1.1784667494176468]
	TIME [epoch: 5.72 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.419096099855464		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.419096099855464 | validation: 1.5370333772579767]
	TIME [epoch: 5.71 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4148588844328134		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.4148588844328134 | validation: 1.189569647630842]
	TIME [epoch: 5.71 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4100474684466284		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.4100474684466284 | validation: 0.9170061221806599]
	TIME [epoch: 5.71 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3414196001436252		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.3414196001436252 | validation: 0.7974666640283609]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4514283812848428		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.4514283812848428 | validation: 1.0783775290869069]
	TIME [epoch: 5.75 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3587561784021225		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.3587561784021225 | validation: 1.1759523761678843]
	TIME [epoch: 5.72 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3428285855303912		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.3428285855303912 | validation: 1.0215238128109092]
	TIME [epoch: 5.71 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7228702833717884		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.7228702833717884 | validation: 0.913388183168296]
	TIME [epoch: 5.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.599946623486924		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.599946623486924 | validation: 0.8717617982029813]
	TIME [epoch: 5.71 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3572592220099722		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.3572592220099722 | validation: 1.0048578166861735]
	TIME [epoch: 5.71 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.385411170575368		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.385411170575368 | validation: 1.0926863800791853]
	TIME [epoch: 5.75 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2432815349878497		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.2432815349878497 | validation: 1.0754070803790523]
	TIME [epoch: 5.72 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4098427545726373		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.4098427545726373 | validation: 1.616729002801573]
	TIME [epoch: 5.71 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3418028624467613		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.3418028624467613 | validation: 0.9944257032871483]
	TIME [epoch: 5.71 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3326634537729363		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.3326634537729363 | validation: 0.8539824483672712]
	TIME [epoch: 5.71 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1992629907677912		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.1992629907677912 | validation: 0.994859953180329]
	TIME [epoch: 5.71 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4594999251409932		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.4594999251409932 | validation: 0.7654089478524]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2358995669927033		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.2358995669927033 | validation: 0.7990697041965202]
	TIME [epoch: 5.72 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2549843111676329		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.2549843111676329 | validation: 0.9964260488234982]
	TIME [epoch: 5.71 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2547136456513028		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.2547136456513028 | validation: 0.9372176911717465]
	TIME [epoch: 5.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1963465249725826		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.1963465249725826 | validation: 0.9284877510658649]
	TIME [epoch: 5.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1626830535790587		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.1626830535790587 | validation: 1.0175636543632138]
	TIME [epoch: 5.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1136877604664293		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.1136877604664293 | validation: 1.1839699831372357]
	TIME [epoch: 5.75 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2202869875816753		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.2202869875816753 | validation: 0.7735010782990801]
	TIME [epoch: 5.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3069440211776184		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.3069440211776184 | validation: 0.7930402442811305]
	TIME [epoch: 5.71 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.100193919877535		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.100193919877535 | validation: 0.7789119239701102]
	TIME [epoch: 5.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144118748943596		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.144118748943596 | validation: 1.4252151133034403]
	TIME [epoch: 5.71 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1459815467989618		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.1459815467989618 | validation: 0.8195847344073969]
	TIME [epoch: 5.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.014312694049533		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.014312694049533 | validation: 0.8910378902186643]
	TIME [epoch: 5.75 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1520565024404876		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.1520565024404876 | validation: 0.7686398006240428]
	TIME [epoch: 5.72 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.04862765132953		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.04862765132953 | validation: 1.5194113602556605]
	TIME [epoch: 5.71 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1977671708592756		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.1977671708592756 | validation: 1.4186696029165726]
	TIME [epoch: 5.71 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1610210365929154		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.1610210365929154 | validation: 1.2552333669745293]
	TIME [epoch: 5.71 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.145252980726871		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.145252980726871 | validation: 1.2381842840389194]
	TIME [epoch: 5.71 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0873650469735892		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.0873650469735892 | validation: 0.9838734090591009]
	TIME [epoch: 5.75 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0669498327510523		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.0669498327510523 | validation: 1.3788678728707704]
	TIME [epoch: 5.71 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1851947724662202		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.1851947724662202 | validation: 0.9748310678098708]
	TIME [epoch: 5.71 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0090993676921762		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.0090993676921762 | validation: 0.9882754946653108]
	TIME [epoch: 5.69 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0246267288043143		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.0246267288043143 | validation: 1.4604099061323645]
	TIME [epoch: 5.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1751351153273761		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.1751351153273761 | validation: 1.319699593097835]
	TIME [epoch: 5.71 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1875394275653155		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.1875394275653155 | validation: 0.7984401421314395]
	TIME [epoch: 5.74 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0122589818515282		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.0122589818515282 | validation: 1.0970314979999822]
	TIME [epoch: 5.71 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.026798226353744		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.026798226353744 | validation: 1.937544130507214]
	TIME [epoch: 5.71 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.316624314791143		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.316624314791143 | validation: 0.7892367495736491]
	TIME [epoch: 5.7 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0620190776416403		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.0620190776416403 | validation: 1.0023863760621756]
	TIME [epoch: 5.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1250395851115258		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.1250395851115258 | validation: 0.7948713853416456]
	TIME [epoch: 5.69 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5812625596704066		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.5812625596704066 | validation: 0.8897534365095413]
	TIME [epoch: 5.73 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2721249898704765		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.2721249898704765 | validation: 0.9045175790399079]
	TIME [epoch: 5.72 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.081767610215451		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.081767610215451 | validation: 0.7901973919218045]
	TIME [epoch: 5.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2876722211552685		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.2876722211552685 | validation: 0.8720784367472407]
	TIME [epoch: 5.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2653905021962684		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.2653905021962684 | validation: 0.8005235656612112]
	TIME [epoch: 5.69 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1067824431183761		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.1067824431183761 | validation: 0.9158079451031018]
	TIME [epoch: 5.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9067817688155494		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.9067817688155494 | validation: 1.2683767781230213]
	TIME [epoch: 5.72 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1737921074723263		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.1737921074723263 | validation: 1.1218436736955748]
	TIME [epoch: 5.73 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1597685033249623		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.1597685033249623 | validation: 0.965636991499766]
	TIME [epoch: 5.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9804162391237996		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.9804162391237996 | validation: 0.9710006701267477]
	TIME [epoch: 5.71 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0051991168732015		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.0051991168732015 | validation: 1.1886097390198918]
	TIME [epoch: 5.69 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1719604856658585		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.1719604856658585 | validation: 1.1419224434394266]
	TIME [epoch: 5.71 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9706417444785914		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.9706417444785914 | validation: 1.0833177029074146]
	TIME [epoch: 5.72 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9446459858687779		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.9446459858687779 | validation: 1.166122531140734]
	TIME [epoch: 5.73 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07671385842148		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.07671385842148 | validation: 1.185448015297108]
	TIME [epoch: 5.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9638231571067224		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.9638231571067224 | validation: 1.0487091529360622]
	TIME [epoch: 5.71 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0187009207931261		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.0187009207931261 | validation: 1.2175390273220084]
	TIME [epoch: 5.69 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.004248932398625		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.004248932398625 | validation: 2.0604434689199906]
	TIME [epoch: 5.71 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1741680507453118		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.1741680507453118 | validation: 1.0086604367623968]
	TIME [epoch: 5.73 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9722623528849319		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.9722623528849319 | validation: 0.9303425165023929]
	TIME [epoch: 5.72 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1326232848114628		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.1326232848114628 | validation: 1.0509629732680617]
	TIME [epoch: 5.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9972063004786968		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.9972063004786968 | validation: 1.1009732674559305]
	TIME [epoch: 5.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9356678074327303		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.9356678074327303 | validation: 1.036639895122495]
	TIME [epoch: 5.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9745468976923455		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.9745468976923455 | validation: 1.0552803077140096]
	TIME [epoch: 5.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9867183246983091		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.9867183246983091 | validation: 1.58305512297821]
	TIME [epoch: 5.74 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1821977014617673		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.1821977014617673 | validation: 1.689844218453062]
	TIME [epoch: 5.71 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364950806095662		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.1364950806095662 | validation: 0.7571911224663964]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0119982055175898		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.0119982055175898 | validation: 1.0171554565290237]
	TIME [epoch: 5.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9496809398852097		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.9496809398852097 | validation: 1.0811303389004134]
	TIME [epoch: 5.69 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0015443194006868		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.0015443194006868 | validation: 1.0479719979453272]
	TIME [epoch: 5.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.952154755785184		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.952154755785184 | validation: 1.2189872992604682]
	TIME [epoch: 5.72 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8782921599846994		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.8782921599846994 | validation: 0.8440170106537497]
	TIME [epoch: 5.71 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0174506994700045		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.0174506994700045 | validation: 1.4439169295951577]
	TIME [epoch: 5.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0746270403929175		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.0746270403929175 | validation: 0.8041452276028107]
	TIME [epoch: 5.69 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8601779611922794		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.8601779611922794 | validation: 0.8065709861341313]
	TIME [epoch: 5.69 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9297780719992135		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.9297780719992135 | validation: 1.2837806144449289]
	TIME [epoch: 5.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9792598763112921		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.9792598763112921 | validation: 1.287361583666406]
	TIME [epoch: 5.72 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0142006522445368		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.0142006522445368 | validation: 0.7723935368093264]
	TIME [epoch: 5.71 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9153990113960215		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.9153990113960215 | validation: 0.857726291534499]
	TIME [epoch: 5.72 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8378020195978202		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.8378020195978202 | validation: 0.9438105618173055]
	TIME [epoch: 5.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9292029770332586		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.9292029770332586 | validation: 1.7432010411481813]
	TIME [epoch: 5.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1042714199774493		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.1042714199774493 | validation: 1.4631072638162517]
	TIME [epoch: 5.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1763897477957181		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.1763897477957181 | validation: 0.7112857128295644]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9694188287110465		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.9694188287110465 | validation: 0.8180459072606359]
	TIME [epoch: 5.72 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1463726076744152		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.1463726076744152 | validation: 0.815786627656533]
	TIME [epoch: 5.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2413639034970168		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.2413639034970168 | validation: 0.7703990000945078]
	TIME [epoch: 5.71 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0593788039601684		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.0593788039601684 | validation: 0.8228182571703255]
	TIME [epoch: 5.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8826659979055229		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.8826659979055229 | validation: 1.2716523363230874]
	TIME [epoch: 5.71 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.985126906605314		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.985126906605314 | validation: 1.3821720233534824]
	TIME [epoch: 5.72 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9635369905657805		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.9635369905657805 | validation: 1.0439746455720536]
	TIME [epoch: 5.72 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0087812354741146		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.0087812354741146 | validation: 1.0438032517341502]
	TIME [epoch: 5.71 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9042854293942357		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.9042854293942357 | validation: 1.3442356008382812]
	TIME [epoch: 5.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2584511891440653		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.2584511891440653 | validation: 1.6135126123352315]
	TIME [epoch: 5.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0433662253884426		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.0433662253884426 | validation: 1.8794065928446781]
	TIME [epoch: 5.71 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0448171897228342		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.0448171897228342 | validation: 0.938045159783469]
	TIME [epoch: 5.72 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8038715335310223		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.8038715335310223 | validation: 0.9701420198486294]
	TIME [epoch: 5.72 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8473392152096634		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.8473392152096634 | validation: 1.0118476216960308]
	TIME [epoch: 5.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9649505425846626		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.9649505425846626 | validation: 0.6918442983960018]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8152279682411874		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.8152279682411874 | validation: 0.7937114613738118]
	TIME [epoch: 5.69 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8233651165929571		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.8233651165929571 | validation: 0.9871220961665601]
	TIME [epoch: 5.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8377469148781123		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.8377469148781123 | validation: 0.7860748080654503]
	TIME [epoch: 5.73 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8270294373949744		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.8270294373949744 | validation: 2.2321332606728066]
	TIME [epoch: 5.71 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2425114473989818		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.2425114473989818 | validation: 1.0275872424850874]
	TIME [epoch: 5.71 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8469513774639783		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.8469513774639783 | validation: 0.7238507726911404]
	TIME [epoch: 5.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0643609616934668		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.0643609616934668 | validation: 0.7514998037290707]
	TIME [epoch: 5.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8929954466458154		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.8929954466458154 | validation: 1.0245269907849381]
	TIME [epoch: 5.71 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8255155589885091		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.8255155589885091 | validation: 0.7794307672264903]
	TIME [epoch: 5.74 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1542782756936938		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.1542782756936938 | validation: 0.9636417091052576]
	TIME [epoch: 5.72 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029501549197648		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.029501549197648 | validation: 0.9317699345944607]
	TIME [epoch: 5.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9164291775680574		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.9164291775680574 | validation: 0.9707627177119398]
	TIME [epoch: 5.71 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9065018087439204		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.9065018087439204 | validation: 1.4079166513396149]
	TIME [epoch: 5.72 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8347585380617257		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.8347585380617257 | validation: 1.2059758673173342]
	TIME [epoch: 5.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8034029104949554		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.8034029104949554 | validation: 1.0568011954220973]
	TIME [epoch: 5.72 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9746935609307601		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.9746935609307601 | validation: 0.8497234141172098]
	TIME [epoch: 5.73 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9041120145275396		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.9041120145275396 | validation: 0.8166272849433232]
	TIME [epoch: 5.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7921454208244302		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.7921454208244302 | validation: 0.7760743026682202]
	TIME [epoch: 5.71 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9739810229401514		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.9739810229401514 | validation: 0.7480773157543115]
	TIME [epoch: 5.71 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9587211487736877		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.9587211487736877 | validation: 0.7578300923763984]
	TIME [epoch: 5.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.811169690468736		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.811169690468736 | validation: 0.754579028915983]
	TIME [epoch: 5.71 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8398013007087856		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.8398013007087856 | validation: 1.0907975357201904]
	TIME [epoch: 5.73 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7672317919654921		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.7672317919654921 | validation: 1.7810977552247653]
	TIME [epoch: 5.71 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13672589709138		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.13672589709138 | validation: 1.3504896738499337]
	TIME [epoch: 5.71 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8728835356101329		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.8728835356101329 | validation: 1.1875951483858107]
	TIME [epoch: 5.69 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8785231017640609		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.8785231017640609 | validation: 1.2648799699276314]
	TIME [epoch: 5.69 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0580636468001154		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.0580636468001154 | validation: 0.6955402774746657]
	TIME [epoch: 5.71 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.837235459919907		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.837235459919907 | validation: 0.7195944766454204]
	TIME [epoch: 5.72 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8544955386957465		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.8544955386957465 | validation: 1.144498731826411]
	TIME [epoch: 5.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9183627601576722		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.9183627601576722 | validation: 0.8717495731537344]
	TIME [epoch: 5.69 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8489711187530345		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.8489711187530345 | validation: 0.8740417029274269]
	TIME [epoch: 5.71 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.817602191754079		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.817602191754079 | validation: 0.8552593419962403]
	TIME [epoch: 5.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0036178211767814		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.0036178211767814 | validation: 0.8642106544774888]
	TIME [epoch: 5.72 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9189793943185773		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.9189793943185773 | validation: 0.8437651008701532]
	TIME [epoch: 5.73 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8824360700619084		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.8824360700619084 | validation: 0.7230599189161108]
	TIME [epoch: 5.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7320845663779152		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.7320845663779152 | validation: 0.8446117889426359]
	TIME [epoch: 5.71 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8191989387107184		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.8191989387107184 | validation: 0.865830945606159]
	TIME [epoch: 5.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8140990659718904		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.8140990659718904 | validation: 0.9716837434484421]
	TIME [epoch: 5.71 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7458650379441416		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.7458650379441416 | validation: 1.0599274813827693]
	TIME [epoch: 5.72 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7487418128631148		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.7487418128631148 | validation: 0.7697796676862376]
	TIME [epoch: 5.72 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.976268470920731		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.976268470920731 | validation: 0.7197952858494404]
	TIME [epoch: 5.71 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7119405537705429		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.7119405537705429 | validation: 1.1613301597522563]
	TIME [epoch: 5.71 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.904605041075153		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.904605041075153 | validation: 0.836020068086113]
	TIME [epoch: 5.71 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7337327535853936		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.7337327535853936 | validation: 0.7646919759724038]
	TIME [epoch: 5.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.842821739366915		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.842821739366915 | validation: 0.8233601957204104]
	TIME [epoch: 5.71 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.865683272622141		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.865683272622141 | validation: 0.9142545169663018]
	TIME [epoch: 5.72 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9911100427336254		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.9911100427336254 | validation: 0.6713265590163318]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.011010368247864		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.011010368247864 | validation: 0.6768024111389163]
	TIME [epoch: 5.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8028667687903663		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.8028667687903663 | validation: 0.7603132383081325]
	TIME [epoch: 5.69 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7361741489238844		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.7361741489238844 | validation: 0.5821849077718965]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.69807825644886		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.69807825644886 | validation: 0.8350767371315447]
	TIME [epoch: 5.73 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8581638054026489		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.8581638054026489 | validation: 0.7020028461625555]
	TIME [epoch: 5.72 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1398406270429275		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.1398406270429275 | validation: 0.886970291541555]
	TIME [epoch: 5.71 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8904236611816195		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.8904236611816195 | validation: 0.7619135073303431]
	TIME [epoch: 5.72 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9153254022912002		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.9153254022912002 | validation: 0.7257810347827336]
	TIME [epoch: 5.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211672016603919		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.7211672016603919 | validation: 0.6819879383058386]
	TIME [epoch: 5.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7894828331396857		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.7894828331396857 | validation: 0.7044798715048336]
	TIME [epoch: 5.72 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937060422835244		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.6937060422835244 | validation: 0.7047374078607976]
	TIME [epoch: 5.73 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7031369837099095		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.7031369837099095 | validation: 1.048232830742465]
	TIME [epoch: 5.71 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7606878237174619		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.7606878237174619 | validation: 0.6406339794502454]
	TIME [epoch: 5.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845188197118101		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.6845188197118101 | validation: 0.841955079944662]
	TIME [epoch: 5.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7277903388290308		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.7277903388290308 | validation: 0.7557989411432986]
	TIME [epoch: 5.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7142967008097576		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.7142967008097576 | validation: 0.5801870619227986]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_475.pth
	Model improved!!!
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6642746176136634		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.6642746176136634 | validation: 0.8262835882752814]
	TIME [epoch: 5.73 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.715756979834099		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.715756979834099 | validation: 0.5858460985655675]
	TIME [epoch: 5.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7832724379596585		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.7832724379596585 | validation: 0.8830890339952495]
	TIME [epoch: 5.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970960427132007		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.6970960427132007 | validation: 1.018266083209569]
	TIME [epoch: 5.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7606099370516922		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.7606099370516922 | validation: 0.5960070605263649]
	TIME [epoch: 5.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7371899256196148		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.7371899256196148 | validation: 0.7041162373465789]
	TIME [epoch: 5.72 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064369526836023		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.7064369526836023 | validation: 0.8210767551547145]
	TIME [epoch: 5.73 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8262407520168359		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.8262407520168359 | validation: 0.5861031904448687]
	TIME [epoch: 5.71 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7103079573487362		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.7103079573487362 | validation: 0.5517221492398982]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_484.pth
	Model improved!!!
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6608693466726699		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.6608693466726699 | validation: 1.0709378256873239]
	TIME [epoch: 5.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8534615391774371		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.8534615391774371 | validation: 0.9667234303570694]
	TIME [epoch: 5.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7103461896794955		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.7103461896794955 | validation: 0.8590403272041848]
	TIME [epoch: 5.73 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6570283329855193		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.6570283329855193 | validation: 0.7198391104261973]
	TIME [epoch: 5.71 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6421225010338372		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.6421225010338372 | validation: 0.8222452454246642]
	TIME [epoch: 5.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657008744237616		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.6657008744237616 | validation: 0.8382667638947954]
	TIME [epoch: 5.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8603214692956095		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.8603214692956095 | validation: 0.6631409234102862]
	TIME [epoch: 5.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6758230619994492		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.6758230619994492 | validation: 0.599505567688573]
	TIME [epoch: 5.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6140526296370455		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.6140526296370455 | validation: 0.5137935839711149]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_493.pth
	Model improved!!!
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.651915235732083		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.651915235732083 | validation: 0.7734405171828423]
	TIME [epoch: 5.72 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7038981910886981		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.7038981910886981 | validation: 0.6387247934528135]
	TIME [epoch: 5.71 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6943144051043023		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.6943144051043023 | validation: 0.6385405011125821]
	TIME [epoch: 5.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970118895020475		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.6970118895020475 | validation: 1.1695722836403883]
	TIME [epoch: 5.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9781313890105177		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.9781313890105177 | validation: 0.9835430041158221]
	TIME [epoch: 5.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8077441994421761		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.8077441994421761 | validation: 0.6193603676296277]
	TIME [epoch: 5.73 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7659813364866341		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.7659813364866341 | validation: 0.5416674154008797]
	TIME [epoch: 5.72 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189874793802973		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.7189874793802973 | validation: 0.8560671037714034]
	TIME [epoch: 5.71 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6315566381618661		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.6315566381618661 | validation: 1.4290774118743494]
	TIME [epoch: 5.71 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639321575719134		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.0639321575719134 | validation: 0.8469389595608919]
	TIME [epoch: 5.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7142627512454679		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.7142627512454679 | validation: 0.9049259382301762]
	TIME [epoch: 5.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241255990538744		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.7241255990538744 | validation: 0.8905988366485477]
	TIME [epoch: 5.73 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.789453705466343		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.789453705466343 | validation: 0.482890340928418]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7899256914684096		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.7899256914684096 | validation: 0.5492801882197251]
	TIME [epoch: 5.71 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.660530190424943		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.660530190424943 | validation: 0.5947594536984195]
	TIME [epoch: 5.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6299843657776697		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.6299843657776697 | validation: 0.8455540839159167]
	TIME [epoch: 5.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6892007650126177		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.6892007650126177 | validation: 0.732744507398037]
	TIME [epoch: 5.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.732346695785243		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.732346695785243 | validation: 0.8144232756712576]
	TIME [epoch: 5.72 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7178914292112015		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.7178914292112015 | validation: 1.2464530831905212]
	TIME [epoch: 5.71 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265739397043968		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.7265739397043968 | validation: 0.6611274526200575]
	TIME [epoch: 5.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8324851582982602		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.8324851582982602 | validation: 1.1206402661801063]
	TIME [epoch: 5.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8097468071079299		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.8097468071079299 | validation: 0.6256306451040173]
	TIME [epoch: 5.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6131913508555934		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.6131913508555934 | validation: 0.7243707864477997]
	TIME [epoch: 5.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7160619633026403		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.7160619633026403 | validation: 0.5928714061389111]
	TIME [epoch: 5.73 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6792309364764024		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.6792309364764024 | validation: 0.6324621341861731]
	TIME [epoch: 5.71 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5834977746600476		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.5834977746600476 | validation: 0.5503056466752447]
	TIME [epoch: 5.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6265775293882349		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.6265775293882349 | validation: 0.7416787139002915]
	TIME [epoch: 5.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6342390104748592		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.6342390104748592 | validation: 0.6913019493106548]
	TIME [epoch: 5.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6293945276206535		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.6293945276206535 | validation: 0.7257674568879828]
	TIME [epoch: 5.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6289439708289939		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.6289439708289939 | validation: 1.634830624805524]
	TIME [epoch: 5.73 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2050926357906684		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.2050926357906684 | validation: 0.6484338062054953]
	TIME [epoch: 5.71 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.57367267971406		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.57367267971406 | validation: 0.5461163278839467]
	TIME [epoch: 5.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5989226790012483		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.5989226790012483 | validation: 0.6827539754404036]
	TIME [epoch: 5.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5697129565409154		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.5697129565409154 | validation: 0.6465194132039437]
	TIME [epoch: 5.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6268672915053524		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.6268672915053524 | validation: 0.5948114570129165]
	TIME [epoch: 5.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6155649559773155		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.6155649559773155 | validation: 0.8475193880930664]
	TIME [epoch: 5.71 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8605287726569594		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.8605287726569594 | validation: 0.8552586510050941]
	TIME [epoch: 5.73 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6665071329934337		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.6665071329934337 | validation: 0.5651911868766462]
	TIME [epoch: 5.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6992619842924219		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.6992619842924219 | validation: 0.6301793192018846]
	TIME [epoch: 5.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6112943285891739		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.6112943285891739 | validation: 0.6399029944974447]
	TIME [epoch: 5.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.666698050656245		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.666698050656245 | validation: 0.8294821642712276]
	TIME [epoch: 5.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6111694032878452		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.6111694032878452 | validation: 1.5722853952561757]
	TIME [epoch: 5.71 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9031208966437614		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.9031208966437614 | validation: 0.9438228211647727]
	TIME [epoch: 5.73 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6112142186908164		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.6112142186908164 | validation: 1.0634623909189072]
	TIME [epoch: 5.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312398162056811		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.6312398162056811 | validation: 1.1520628382132503]
	TIME [epoch: 5.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6370281300033657		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.6370281300033657 | validation: 0.7514305784075422]
	TIME [epoch: 5.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5848624383101699		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.5848624383101699 | validation: 0.7267099024807303]
	TIME [epoch: 5.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5385734081010377		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.5385734081010377 | validation: 0.921945082829205]
	TIME [epoch: 5.71 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.622319209263656		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.622319209263656 | validation: 0.5532495917258904]
	TIME [epoch: 5.73 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6300315166379237		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.6300315166379237 | validation: 0.8459902589725766]
	TIME [epoch: 5.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8151143963467691		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.8151143963467691 | validation: 0.9257881716219769]
	TIME [epoch: 5.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6208097702952713		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.6208097702952713 | validation: 0.6412156125264952]
	TIME [epoch: 5.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641956304384327		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.5641956304384327 | validation: 0.6311143364242107]
	TIME [epoch: 5.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.589434093693015		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.589434093693015 | validation: 0.6838028315801822]
	TIME [epoch: 5.71 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956100725918279		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.6956100725918279 | validation: 0.6273966763819521]
	TIME [epoch: 5.73 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6692509274395364		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.6692509274395364 | validation: 0.5157757300632466]
	TIME [epoch: 5.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6035426236907202		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.6035426236907202 | validation: 0.5997702650448897]
	TIME [epoch: 5.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6014017914298986		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.6014017914298986 | validation: 1.141864726601381]
	TIME [epoch: 5.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6333015350777088		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.6333015350777088 | validation: 0.6483849365833984]
	TIME [epoch: 5.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7088091860600922		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.7088091860600922 | validation: 0.8162328101129817]
	TIME [epoch: 5.71 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6649053158516574		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.6649053158516574 | validation: 0.7485315649265678]
	TIME [epoch: 5.73 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5481513105022701		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.5481513105022701 | validation: 0.742008563676176]
	TIME [epoch: 5.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6165202533954672		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.6165202533954672 | validation: 0.655199453594529]
	TIME [epoch: 5.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6098059500428096		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.6098059500428096 | validation: 0.6881695691668478]
	TIME [epoch: 5.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881147291333248		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.6881147291333248 | validation: 0.5375692173077292]
	TIME [epoch: 5.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7379263573593683		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.7379263573593683 | validation: 0.5829003256253024]
	TIME [epoch: 5.71 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593331631785183		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.5593331631785183 | validation: 0.7758902501862102]
	TIME [epoch: 5.73 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6757416674370044		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.6757416674370044 | validation: 0.6380278339658607]
	TIME [epoch: 5.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5703739117025097		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.5703739117025097 | validation: 0.7337778719883947]
	TIME [epoch: 5.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5241707100854087		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.5241707100854087 | validation: 0.8059662538696077]
	TIME [epoch: 5.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859177401687807		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.6859177401687807 | validation: 0.7761435050632653]
	TIME [epoch: 5.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232618901235723		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.7232618901235723 | validation: 0.9378728416944437]
	TIME [epoch: 5.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6015612578554232		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.6015612578554232 | validation: 0.6287679541826696]
	TIME [epoch: 5.74 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5588997003253573		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.5588997003253573 | validation: 0.6210868109173413]
	TIME [epoch: 5.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390088506722095		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.6390088506722095 | validation: 0.657205363644028]
	TIME [epoch: 5.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.523387042064907		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.523387042064907 | validation: 0.8683865689736958]
	TIME [epoch: 5.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6350471683459655		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.6350471683459655 | validation: 0.9645589598329823]
	TIME [epoch: 5.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5605572649245778		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.5605572649245778 | validation: 0.546083600495952]
	TIME [epoch: 5.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507013165227934		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.5507013165227934 | validation: 0.671121717512313]
	TIME [epoch: 5.74 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.54692793213048		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.54692793213048 | validation: 0.5717764963170624]
	TIME [epoch: 5.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6012811636857892		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.6012811636857892 | validation: 0.6313723460210097]
	TIME [epoch: 5.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5674651230206832		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.5674651230206832 | validation: 0.9883246299025291]
	TIME [epoch: 5.71 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6466329814205585		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.6466329814205585 | validation: 0.49002211389234773]
	TIME [epoch: 5.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490585336373099		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.5490585336373099 | validation: 0.5413220384678491]
	TIME [epoch: 5.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5631950981525042		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.5631950981525042 | validation: 0.5179019260958683]
	TIME [epoch: 5.74 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5203297998175294		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.5203297998175294 | validation: 0.5927384607490896]
	TIME [epoch: 5.71 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5271803221900786		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.5271803221900786 | validation: 0.7038179496271632]
	TIME [epoch: 5.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467078348283656		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.5467078348283656 | validation: 0.47408210185198163]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_581.pth
	Model improved!!!
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516188055930262		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.516188055930262 | validation: 0.44954927177916026]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5983418719353627		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.5983418719353627 | validation: 0.7754944411271711]
	TIME [epoch: 5.73 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7503547272335678		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.7503547272335678 | validation: 0.47100111342416207]
	TIME [epoch: 5.74 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5863687285032144		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.5863687285032144 | validation: 0.5187082110378985]
	TIME [epoch: 5.71 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6047017210002195		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.6047017210002195 | validation: 0.6722548527690327]
	TIME [epoch: 5.71 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5434866708000765		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.5434866708000765 | validation: 0.6639415766698943]
	TIME [epoch: 5.71 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6695292357591085		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.6695292357591085 | validation: 0.5648070195944965]
	TIME [epoch: 5.71 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5797238277041075		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.5797238277041075 | validation: 0.6683944340883028]
	TIME [epoch: 5.71 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014052564877504		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.7014052564877504 | validation: 0.673708817229371]
	TIME [epoch: 5.74 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5243733267912095		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.5243733267912095 | validation: 0.4721128028065723]
	TIME [epoch: 5.71 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5548257943030106		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.5548257943030106 | validation: 0.4388921571161118]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_592.pth
	Model improved!!!
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6400929723938453		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.6400929723938453 | validation: 0.548000602224188]
	TIME [epoch: 5.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5716042884633634		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.5716042884633634 | validation: 0.603437103712485]
	TIME [epoch: 5.69 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5740093878454329		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.5740093878454329 | validation: 0.6382671696064379]
	TIME [epoch: 5.73 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6292947227860786		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.6292947227860786 | validation: 0.4747382936098339]
	TIME [epoch: 5.72 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677968910212278		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.5677968910212278 | validation: 0.4818524431166003]
	TIME [epoch: 5.69 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.540046922097409		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.540046922097409 | validation: 0.572778117721322]
	TIME [epoch: 5.71 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6022151724495173		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.6022151724495173 | validation: 0.49324742693078]
	TIME [epoch: 5.69 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5602229009001873		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.5602229009001873 | validation: 0.7388766069021067]
	TIME [epoch: 5.69 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6177503523793837		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.6177503523793837 | validation: 0.6015045523196538]
	TIME [epoch: 5.71 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5615196142318677		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.5615196142318677 | validation: 0.5968661858839834]
	TIME [epoch: 5.73 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.452763282471614		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.452763282471614 | validation: 0.6103437268812357]
	TIME [epoch: 5.69 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6548740262312465		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.6548740262312465 | validation: 0.5033277955859102]
	TIME [epoch: 5.69 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5128748902068423		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.5128748902068423 | validation: 0.5056202067448112]
	TIME [epoch: 5.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5339806808512526		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.5339806808512526 | validation: 0.8170418826090442]
	TIME [epoch: 5.69 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.580061803777453		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.580061803777453 | validation: 0.49916001229212187]
	TIME [epoch: 5.71 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5326711725496531		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.5326711725496531 | validation: 0.760214825492433]
	TIME [epoch: 5.72 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7288940799696737		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.7288940799696737 | validation: 0.5016371946885382]
	TIME [epoch: 5.71 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5575948754906522		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.5575948754906522 | validation: 0.7125113393253828]
	TIME [epoch: 5.71 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8156988939751114		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.8156988939751114 | validation: 0.42648293011717664]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_611.pth
	Model improved!!!
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5739138398914645		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.5739138398914645 | validation: 0.4461233034189948]
	TIME [epoch: 5.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5943106099865129		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.5943106099865129 | validation: 0.42143325682607513]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_613.pth
	Model improved!!!
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4798366389372301		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.4798366389372301 | validation: 0.5460515780718597]
	TIME [epoch: 5.72 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46856749897838323		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.46856749897838323 | validation: 0.48564259733100557]
	TIME [epoch: 5.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5187989173042414		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5187989173042414 | validation: 0.41236133537934894]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5143919070079509		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.5143919070079509 | validation: 0.7668313001965251]
	TIME [epoch: 5.71 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5427290704432417		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.5427290704432417 | validation: 0.6461964502897931]
	TIME [epoch: 5.71 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49423588201829594		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.49423588201829594 | validation: 0.6949950579644488]
	TIME [epoch: 5.71 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4832216167523919		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.4832216167523919 | validation: 0.5421440383094044]
	TIME [epoch: 5.72 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5558375092472371		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.5558375092472371 | validation: 0.5657263288168526]
	TIME [epoch: 5.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5510762197232517		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.5510762197232517 | validation: 0.4749088486586506]
	TIME [epoch: 5.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6205000490887298		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.6205000490887298 | validation: 0.49041865101207793]
	TIME [epoch: 5.71 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5162273778261405		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.5162273778261405 | validation: 1.338241407838072]
	TIME [epoch: 5.71 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7538074418672596		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.7538074418672596 | validation: 0.6938652614573101]
	TIME [epoch: 5.71 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4813167207489879		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.4813167207489879 | validation: 0.46903478837973]
	TIME [epoch: 5.72 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4901377426446164		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.4901377426446164 | validation: 0.7507538722854858]
	TIME [epoch: 5.71 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5069452444735587		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.5069452444735587 | validation: 0.7060293218188531]
	TIME [epoch: 5.71 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5382755939347135		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5382755939347135 | validation: 0.6668282466848646]
	TIME [epoch: 5.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5730874238275558		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.5730874238275558 | validation: 0.730321825638306]
	TIME [epoch: 5.69 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4943570785677203		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.4943570785677203 | validation: 0.6002104808850097]
	TIME [epoch: 5.72 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46288704032177114		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.46288704032177114 | validation: 0.887537274384474]
	TIME [epoch: 5.72 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.615425697831745		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.615425697831745 | validation: 0.7188712223136707]
	TIME [epoch: 5.71 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5854889642983974		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.5854889642983974 | validation: 0.6185058724529887]
	TIME [epoch: 5.71 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5129183243999248		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.5129183243999248 | validation: 0.44167686341566276]
	TIME [epoch: 5.69 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.464480314353809		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.464480314353809 | validation: 0.5771244837014223]
	TIME [epoch: 5.69 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5385044332903419		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.5385044332903419 | validation: 0.501690229246935]
	TIME [epoch: 5.71 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5231345406877592		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.5231345406877592 | validation: 0.5219654245399497]
	TIME [epoch: 5.72 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5432049335942606		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.5432049335942606 | validation: 0.71537042306877]
	TIME [epoch: 5.69 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48581973470896384		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.48581973470896384 | validation: 0.5296087139698039]
	TIME [epoch: 5.71 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5159318761770372		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.5159318761770372 | validation: 0.5041346381997392]
	TIME [epoch: 5.71 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49564516455519736		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.49564516455519736 | validation: 0.46032508953462514]
	TIME [epoch: 5.71 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446488450051474		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.5446488450051474 | validation: 0.6050505442086325]
	TIME [epoch: 5.71 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5236825588973416		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.5236825588973416 | validation: 0.6148750429765594]
	TIME [epoch: 5.72 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5285300257823998		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.5285300257823998 | validation: 0.7464456071010224]
	TIME [epoch: 5.71 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.590681502934995		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.590681502934995 | validation: 0.5220717091783018]
	TIME [epoch: 5.71 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4985427008797609		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.4985427008797609 | validation: 0.4460682024186381]
	TIME [epoch: 5.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4446056279213337		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.4446056279213337 | validation: 0.40580437090039156]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4863952555328557		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.4863952555328557 | validation: 0.4221373863135349]
	TIME [epoch: 5.74 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4756306597402833		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.4756306597402833 | validation: 0.49254629764055746]
	TIME [epoch: 5.75 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44770433800268494		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.44770433800268494 | validation: 0.8739232667165241]
	TIME [epoch: 5.72 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6231313007863007		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.6231313007863007 | validation: 0.5248966242638382]
	TIME [epoch: 5.72 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49633218494434034		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.49633218494434034 | validation: 0.7826679907481244]
	TIME [epoch: 5.72 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501329403800847		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.501329403800847 | validation: 0.5323795511107604]
	TIME [epoch: 5.72 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013975470544399		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.7013975470544399 | validation: 0.631073340557533]
	TIME [epoch: 5.73 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5424176502163736		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.5424176502163736 | validation: 0.5376358948202836]
	TIME [epoch: 5.75 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49625803546000347		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.49625803546000347 | validation: 0.7539013044128031]
	TIME [epoch: 5.72 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5401270026380603		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.5401270026380603 | validation: 0.6761594219610859]
	TIME [epoch: 5.72 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5117594839849444		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.5117594839849444 | validation: 0.5989782362235834]
	TIME [epoch: 5.72 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5501342999123254		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.5501342999123254 | validation: 0.9706205251417739]
	TIME [epoch: 5.72 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5792581843397586		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.5792581843397586 | validation: 0.7730797852701073]
	TIME [epoch: 5.73 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5312875063324274		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.5312875063324274 | validation: 0.5277656578256759]
	TIME [epoch: 5.75 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5864364121929709		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.5864364121929709 | validation: 0.6044653191087737]
	TIME [epoch: 5.72 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47529551572347223		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.47529551572347223 | validation: 0.6030154974344011]
	TIME [epoch: 5.72 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5668611880034392		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.5668611880034392 | validation: 0.6083967528353792]
	TIME [epoch: 5.72 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451566567607958		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.5451566567607958 | validation: 0.498498696548891]
	TIME [epoch: 5.72 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48306022146072397		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.48306022146072397 | validation: 0.6891836854499189]
	TIME [epoch: 5.73 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47614859211974636		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.47614859211974636 | validation: 0.4318107358328072]
	TIME [epoch: 5.75 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4301695228175047		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.4301695228175047 | validation: 0.539852036170233]
	TIME [epoch: 5.72 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4797966480677407		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.4797966480677407 | validation: 0.3953733026109863]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5797555232429981		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.5797555232429981 | validation: 0.5571683415389755]
	TIME [epoch: 5.71 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.482280601242044		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.482280601242044 | validation: 0.5748578662544077]
	TIME [epoch: 5.72 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45486518865511993		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.45486518865511993 | validation: 0.5168054533942621]
	TIME [epoch: 5.73 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4656976878682405		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.4656976878682405 | validation: 0.737560723972614]
	TIME [epoch: 5.74 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490762277575236		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.5490762277575236 | validation: 0.6903180790487101]
	TIME [epoch: 5.72 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5438590183122569		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.5438590183122569 | validation: 0.46503547222767166]
	TIME [epoch: 5.71 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44115703591803823		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.44115703591803823 | validation: 0.5851780467665331]
	TIME [epoch: 5.71 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49294533919531297		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.49294533919531297 | validation: 0.5626837766785394]
	TIME [epoch: 5.72 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5110022759779389		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.5110022759779389 | validation: 0.49807831608166403]
	TIME [epoch: 5.73 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4335375428748216		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.4335375428748216 | validation: 0.6559415398363992]
	TIME [epoch: 5.74 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47983956682644524		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.47983956682644524 | validation: 0.6586389803383307]
	TIME [epoch: 5.72 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5197985449530191		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.5197985449530191 | validation: 0.4769102326214752]
	TIME [epoch: 5.72 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41321322153512013		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.41321322153512013 | validation: 0.4558507916569059]
	TIME [epoch: 5.71 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4975424603644875		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.4975424603644875 | validation: 0.6033281363692902]
	TIME [epoch: 5.72 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49853698013130177		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.49853698013130177 | validation: 0.6369242658375079]
	TIME [epoch: 5.73 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4545721927826397		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.4545721927826397 | validation: 0.5214304437823898]
	TIME [epoch: 5.74 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.486821660502452		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.486821660502452 | validation: 0.6130998935457763]
	TIME [epoch: 5.72 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.567057939074659		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.567057939074659 | validation: 0.5201231851861341]
	TIME [epoch: 5.72 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4158212914887367		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.4158212914887367 | validation: 0.46139498265496703]
	TIME [epoch: 5.72 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5486775380827151		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5486775380827151 | validation: 0.5544688094947992]
	TIME [epoch: 5.72 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46812703140452017		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.46812703140452017 | validation: 0.698591424437837]
	TIME [epoch: 5.73 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46365222554610447		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.46365222554610447 | validation: 0.5956532556920621]
	TIME [epoch: 5.74 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727049654120842		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.4727049654120842 | validation: 0.5323581182842309]
	TIME [epoch: 5.72 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4311268952501368		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.4311268952501368 | validation: 0.503858444926229]
	TIME [epoch: 5.72 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4331602156462504		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.4331602156462504 | validation: 0.5394890557940512]
	TIME [epoch: 5.71 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5158278457036114		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.5158278457036114 | validation: 0.6177682171110862]
	TIME [epoch: 5.71 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5398841756831425		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.5398841756831425 | validation: 0.4351350713735157]
	TIME [epoch: 5.73 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4832748012865974		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.4832748012865974 | validation: 0.7314757011506509]
	TIME [epoch: 5.74 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48334668102046563		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.48334668102046563 | validation: 0.4873644509060542]
	TIME [epoch: 5.72 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46106316098470795		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.46106316098470795 | validation: 0.48982420194253473]
	TIME [epoch: 5.71 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.511258230304059		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.511258230304059 | validation: 0.6882692439256322]
	TIME [epoch: 5.71 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45667400858279983		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.45667400858279983 | validation: 0.444957894323111]
	TIME [epoch: 5.71 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4451607685394503		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.4451607685394503 | validation: 0.40757788014969154]
	TIME [epoch: 5.73 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5736789197268398		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.5736789197268398 | validation: 0.7633511005130769]
	TIME [epoch: 5.74 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5154974373066006		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.5154974373066006 | validation: 0.49392146144558513]
	TIME [epoch: 5.72 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5200381327072331		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.5200381327072331 | validation: 0.49105208117228616]
	TIME [epoch: 5.72 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4400643264049118		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.4400643264049118 | validation: 0.5514041211307459]
	TIME [epoch: 5.71 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41776662393105135		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.41776662393105135 | validation: 0.4208371847483225]
	TIME [epoch: 5.71 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5085090165699818		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.5085090165699818 | validation: 1.1290435686175726]
	TIME [epoch: 5.73 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984111328123654		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.6984111328123654 | validation: 0.588153035409477]
	TIME [epoch: 5.75 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5158129693381958		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.5158129693381958 | validation: 0.4790044647604856]
	TIME [epoch: 5.72 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4405869912999825		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.4405869912999825 | validation: 0.5092934730854569]
	TIME [epoch: 5.72 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43937375177537596		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.43937375177537596 | validation: 0.6321006679221495]
	TIME [epoch: 5.71 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4564351613773162		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.4564351613773162 | validation: 0.5401090956341752]
	TIME [epoch: 5.72 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48125869905853347		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.48125869905853347 | validation: 0.6007623186049672]
	TIME [epoch: 5.73 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.578445753180794		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.578445753180794 | validation: 0.5744240207099472]
	TIME [epoch: 5.74 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47684612054479947		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.47684612054479947 | validation: 0.54867065954434]
	TIME [epoch: 5.72 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46435137139232885		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.46435137139232885 | validation: 0.6028164580928673]
	TIME [epoch: 5.72 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42684434938579185		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.42684434938579185 | validation: 0.5130158183540668]
	TIME [epoch: 5.71 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44077066079820404		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.44077066079820404 | validation: 0.4716633308599525]
	TIME [epoch: 5.72 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4293020717975063		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.4293020717975063 | validation: 0.5819663197656925]
	TIME [epoch: 5.73 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4650503912437095		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.4650503912437095 | validation: 0.5381802582592691]
	TIME [epoch: 5.74 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4204113660230806		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.4204113660230806 | validation: 0.4400391181916048]
	TIME [epoch: 5.72 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.451474226102964		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.451474226102964 | validation: 0.46330415882990866]
	TIME [epoch: 5.72 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5380124747112449		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.5380124747112449 | validation: 0.4301620676498742]
	TIME [epoch: 5.72 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4424450529265572		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.4424450529265572 | validation: 0.42777072880716455]
	TIME [epoch: 5.72 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44186987360073304		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.44186987360073304 | validation: 0.8071512907658405]
	TIME [epoch: 5.73 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4886208597758319		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.4886208597758319 | validation: 0.8650027156254972]
	TIME [epoch: 5.74 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5134250346144522		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.5134250346144522 | validation: 0.5716832657509139]
	TIME [epoch: 5.72 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4261501995939797		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.4261501995939797 | validation: 0.5101104405078722]
	TIME [epoch: 5.72 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41961868193592233		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.41961868193592233 | validation: 0.6392966621331703]
	TIME [epoch: 5.72 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071501937021058		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.5071501937021058 | validation: 0.49481710885434177]
	TIME [epoch: 5.72 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40217540838154475		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.40217540838154475 | validation: 0.40630264305498404]
	TIME [epoch: 5.73 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45377103671656444		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.45377103671656444 | validation: 0.5188654811212646]
	TIME [epoch: 5.74 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4205420953692382		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.4205420953692382 | validation: 0.5058780267740064]
	TIME [epoch: 5.72 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4522615520094647		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.4522615520094647 | validation: 1.4652110081607435]
	TIME [epoch: 5.72 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7973572089545411		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.7973572089545411 | validation: 0.697810725136978]
	TIME [epoch: 5.72 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5600414976920485		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.5600414976920485 | validation: 0.6727845902408062]
	TIME [epoch: 5.72 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5091088936665789		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.5091088936665789 | validation: 0.6947782883225213]
	TIME [epoch: 5.73 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43392005626572927		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.43392005626572927 | validation: 0.6185786870388911]
	TIME [epoch: 5.74 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43331344048611986		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.43331344048611986 | validation: 0.4996838334096076]
	TIME [epoch: 5.72 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.541584358746738		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.541584358746738 | validation: 0.5323258554673741]
	TIME [epoch: 5.72 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5492552460312115		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.5492552460312115 | validation: 0.4905546229523645]
	TIME [epoch: 5.72 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5146739706997505		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.5146739706997505 | validation: 0.38889507688041736]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_744.pth
	Model improved!!!
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44187372541637476		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.44187372541637476 | validation: 0.43769505381787344]
	TIME [epoch: 5.73 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4986152543610216		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.4986152543610216 | validation: 0.3686803164568444]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_746.pth
	Model improved!!!
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4263261488303123		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.4263261488303123 | validation: 0.37577060251911365]
	TIME [epoch: 5.72 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4004537445292484		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.4004537445292484 | validation: 0.4473523653828474]
	TIME [epoch: 5.72 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43607001745689467		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.43607001745689467 | validation: 0.4948926150744133]
	TIME [epoch: 5.72 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4075866390023455		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.4075866390023455 | validation: 0.5217499017789184]
	TIME [epoch: 5.72 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4461608079446292		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.4461608079446292 | validation: 0.42532669106007037]
	TIME [epoch: 5.73 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41521467991356475		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.41521467991356475 | validation: 0.679524356413697]
	TIME [epoch: 5.74 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.491755808833459		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.491755808833459 | validation: 0.4205054004286488]
	TIME [epoch: 5.72 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4465552330257828		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.4465552330257828 | validation: 0.5135358769129927]
	TIME [epoch: 5.71 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47831694835545957		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.47831694835545957 | validation: 0.6617755320909882]
	TIME [epoch: 5.72 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5181866272299342		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.5181866272299342 | validation: 0.4412643027759428]
	TIME [epoch: 5.71 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992756254924747		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.3992756254924747 | validation: 0.4568826999598703]
	TIME [epoch: 5.73 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40793760657710043		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.40793760657710043 | validation: 0.5813007381513562]
	TIME [epoch: 5.74 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4572918432405897		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.4572918432405897 | validation: 0.35178070992927596]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_759.pth
	Model improved!!!
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44964233650448543		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.44964233650448543 | validation: 0.5258843732770816]
	TIME [epoch: 5.72 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42523364676472963		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.42523364676472963 | validation: 0.4740298640848481]
	TIME [epoch: 5.71 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42987534953617956		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.42987534953617956 | validation: 0.454682434271126]
	TIME [epoch: 5.71 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39523551090189085		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.39523551090189085 | validation: 0.4241460380967651]
	TIME [epoch: 5.74 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4066629582189652		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.4066629582189652 | validation: 0.6597759983008177]
	TIME [epoch: 5.73 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42307485877588114		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.42307485877588114 | validation: 0.4587693059419711]
	TIME [epoch: 5.72 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4360644272639095		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.4360644272639095 | validation: 0.5120018532552248]
	TIME [epoch: 5.72 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39915119227072593		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.39915119227072593 | validation: 0.500987292762169]
	TIME [epoch: 5.71 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48075818651794977		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.48075818651794977 | validation: 0.5320403813426234]
	TIME [epoch: 5.71 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39731372793627356		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.39731372793627356 | validation: 0.44492195713625643]
	TIME [epoch: 5.74 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46170396914876755		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.46170396914876755 | validation: 0.4494221581289601]
	TIME [epoch: 5.73 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4744091575773979		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.4744091575773979 | validation: 0.4426356286152037]
	TIME [epoch: 5.72 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44762268648685866		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.44762268648685866 | validation: 0.5251441206676545]
	TIME [epoch: 5.72 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4555035074229461		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.4555035074229461 | validation: 0.4177213150976297]
	TIME [epoch: 5.71 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44103232815518656		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.44103232815518656 | validation: 0.5130945077115252]
	TIME [epoch: 5.72 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4428211079741242		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.4428211079741242 | validation: 0.4976253893047229]
	TIME [epoch: 5.73 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.421775505593756		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.421775505593756 | validation: 0.43686539506465705]
	TIME [epoch: 5.74 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40375195405143915		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.40375195405143915 | validation: 0.6187675488979719]
	TIME [epoch: 5.72 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44701310398889116		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.44701310398889116 | validation: 0.4888186307600323]
	TIME [epoch: 5.72 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46876253673229445		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.46876253673229445 | validation: 0.37253152989623417]
	TIME [epoch: 5.72 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3801318364980465		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.3801318364980465 | validation: 0.46214719345513544]
	TIME [epoch: 5.72 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3887031357489513		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.3887031357489513 | validation: 0.42879840203485103]
	TIME [epoch: 5.73 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42762786784885		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.42762786784885 | validation: 0.4805032018047098]
	TIME [epoch: 5.74 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4916062539868323		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.4916062539868323 | validation: 0.4964897563855824]
	TIME [epoch: 5.72 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3872655033093574		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.3872655033093574 | validation: 0.43872122381590273]
	TIME [epoch: 5.72 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4096528526117401		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.4096528526117401 | validation: 0.46783839934528415]
	TIME [epoch: 5.71 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40960061048579655		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.40960061048579655 | validation: 0.5233647458887987]
	TIME [epoch: 5.72 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5590391958546154		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.5590391958546154 | validation: 0.4579713536666739]
	TIME [epoch: 5.73 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4279857979517137		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.4279857979517137 | validation: 0.549438428520906]
	TIME [epoch: 5.74 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4235254592271498		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.4235254592271498 | validation: 0.4149953890893526]
	TIME [epoch: 5.72 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393817358397909		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.393817358397909 | validation: 0.5086556674759026]
	TIME [epoch: 5.72 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42507791695887404		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.42507791695887404 | validation: 0.5198872160916135]
	TIME [epoch: 5.72 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39344401320850175		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.39344401320850175 | validation: 0.44116340868937387]
	TIME [epoch: 5.72 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3880521989540914		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.3880521989540914 | validation: 0.40658135462924855]
	TIME [epoch: 5.73 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37027448946019426		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.37027448946019426 | validation: 0.3621839341588526]
	TIME [epoch: 5.74 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43063443790929706		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.43063443790929706 | validation: 0.5252673985254904]
	TIME [epoch: 5.72 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43818561425876595		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.43818561425876595 | validation: 0.438675725377244]
	TIME [epoch: 5.71 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41282994687856045		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.41282994687856045 | validation: 0.433136275143592]
	TIME [epoch: 5.72 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3935792359462743		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.3935792359462743 | validation: 0.44166060849654487]
	TIME [epoch: 5.72 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43534328206214873		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.43534328206214873 | validation: 0.5068088553741811]
	TIME [epoch: 5.72 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40668103032842073		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.40668103032842073 | validation: 0.4169330971616475]
	TIME [epoch: 5.74 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3674897334683382		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.3674897334683382 | validation: 0.44096048322132986]
	TIME [epoch: 5.72 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4202133516414717		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.4202133516414717 | validation: 0.40805477689220937]
	TIME [epoch: 5.72 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42053416010675726		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.42053416010675726 | validation: 0.3919284711617222]
	TIME [epoch: 5.72 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4214233694013267		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.4214233694013267 | validation: 0.5076349505711181]
	TIME [epoch: 5.71 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3773909209329184		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.3773909209329184 | validation: 0.6877384482060624]
	TIME [epoch: 5.73 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44724262280021493		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.44724262280021493 | validation: 0.44849236662736935]
	TIME [epoch: 5.74 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.405697045466339		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.405697045466339 | validation: 0.5567598453852152]
	TIME [epoch: 5.72 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37343771616520083		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.37343771616520083 | validation: 0.5429218621260999]
	TIME [epoch: 5.71 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3986596165794915		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.3986596165794915 | validation: 0.5764806250599669]
	TIME [epoch: 5.71 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47876372795887584		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.47876372795887584 | validation: 0.5383336278749143]
	TIME [epoch: 5.71 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3887425326839691		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.3887425326839691 | validation: 0.561485694702093]
	TIME [epoch: 5.73 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4181748498091172		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.4181748498091172 | validation: 0.4690881682968]
	TIME [epoch: 5.74 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37372886582851034		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.37372886582851034 | validation: 0.42571560579023215]
	TIME [epoch: 5.72 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3733482432727362		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.3733482432727362 | validation: 0.6502566033426603]
	TIME [epoch: 5.71 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41226496047649863		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.41226496047649863 | validation: 0.42282162449549054]
	TIME [epoch: 5.71 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38017176866157776		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.38017176866157776 | validation: 0.46267277529641276]
	TIME [epoch: 5.71 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4003994360099289		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.4003994360099289 | validation: 0.4926703737182608]
	TIME [epoch: 5.72 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933542482196948		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.3933542482196948 | validation: 0.4722171934977897]
	TIME [epoch: 5.74 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4218542713475603		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.4218542713475603 | validation: 0.4309316002036501]
	TIME [epoch: 5.72 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44148142474687285		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.44148142474687285 | validation: 0.6438786413866234]
	TIME [epoch: 5.71 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41340153579954514		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.41340153579954514 | validation: 0.6314634763305899]
	TIME [epoch: 5.71 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45683628165196344		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.45683628165196344 | validation: 0.4688537813438727]
	TIME [epoch: 5.71 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49520194698557796		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.49520194698557796 | validation: 0.41693529256647266]
	TIME [epoch: 5.72 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4512564071137413		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.4512564071137413 | validation: 0.43715976113492494]
	TIME [epoch: 5.74 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36830684999542646		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.36830684999542646 | validation: 0.46630606357182997]
	TIME [epoch: 5.71 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4171884247067383		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.4171884247067383 | validation: 0.49545894220807923]
	TIME [epoch: 5.71 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4357182896359846		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.4357182896359846 | validation: 0.5105912893044453]
	TIME [epoch: 5.71 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3974110242025677		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.3974110242025677 | validation: 0.5152405487890528]
	TIME [epoch: 5.71 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43873176078671144		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.43873176078671144 | validation: 0.6052739672733229]
	TIME [epoch: 5.72 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43015775827916647		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.43015775827916647 | validation: 0.5143447458905217]
	TIME [epoch: 5.73 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4197053884537763		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.4197053884537763 | validation: 0.49104037937179457]
	TIME [epoch: 5.72 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41909475440047356		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.41909475440047356 | validation: 0.6491584705754737]
	TIME [epoch: 5.71 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44164252238556095		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.44164252238556095 | validation: 0.37482931639347217]
	TIME [epoch: 5.71 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3986487840536681		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.3986487840536681 | validation: 0.45624847914347294]
	TIME [epoch: 5.72 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3843092518492973		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.3843092518492973 | validation: 0.40752251370573406]
	TIME [epoch: 5.73 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4077828346734802		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.4077828346734802 | validation: 0.3905767119795732]
	TIME [epoch: 5.74 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4037739228810494		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.4037739228810494 | validation: 0.4635333165092436]
	TIME [epoch: 5.7 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3864082875094461		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.3864082875094461 | validation: 0.43779884659450147]
	TIME [epoch: 5.71 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4459095344655473		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.4459095344655473 | validation: 0.5587012189651364]
	TIME [epoch: 5.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40113138817541455		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.40113138817541455 | validation: 0.39860541141241923]
	TIME [epoch: 5.71 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36754063940159754		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.36754063940159754 | validation: 0.39917023959426134]
	TIME [epoch: 5.71 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37605076981766167		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.37605076981766167 | validation: 0.44763153542205886]
	TIME [epoch: 5.74 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3629909286716266		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.3629909286716266 | validation: 0.40504796147559796]
	TIME [epoch: 5.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37110910079989906		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.37110910079989906 | validation: 0.46517193533213635]
	TIME [epoch: 5.71 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373146777108048		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.373146777108048 | validation: 0.4476414992582676]
	TIME [epoch: 5.71 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4046721535064629		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.4046721535064629 | validation: 0.34577777696323336]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_846.pth
	Model improved!!!
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40137751442548564		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.40137751442548564 | validation: 0.6113335811327406]
	TIME [epoch: 5.73 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44717437029104057		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.44717437029104057 | validation: 0.48246213002425015]
	TIME [epoch: 5.73 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3645268061999269		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.3645268061999269 | validation: 0.4683034024233197]
	TIME [epoch: 5.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3786866320783584		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.3786866320783584 | validation: 0.45372854099234944]
	TIME [epoch: 5.71 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39441624684294885		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.39441624684294885 | validation: 0.41098771540990653]
	TIME [epoch: 5.71 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4273724894602602		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.4273724894602602 | validation: 0.45030734190285104]
	TIME [epoch: 5.71 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37505539744025324		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.37505539744025324 | validation: 0.4073225287009494]
	TIME [epoch: 5.72 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35730945025651456		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.35730945025651456 | validation: 0.42905168294072243]
	TIME [epoch: 5.74 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3704648103949248		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.3704648103949248 | validation: 0.45203577901920633]
	TIME [epoch: 5.72 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4078308102423462		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.4078308102423462 | validation: 0.39111358465049906]
	TIME [epoch: 5.72 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40420788918125666		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.40420788918125666 | validation: 0.4510013072339375]
	TIME [epoch: 5.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35020589331860313		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.35020589331860313 | validation: 0.48318282893429854]
	TIME [epoch: 5.71 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3966514265472012		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.3966514265472012 | validation: 0.432037004337928]
	TIME [epoch: 5.71 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43330561245867316		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.43330561245867316 | validation: 0.41228104799179505]
	TIME [epoch: 5.74 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4363696187014635		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.4363696187014635 | validation: 0.47133429015055683]
	TIME [epoch: 5.71 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3813493687002116		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.3813493687002116 | validation: 0.42883016956653663]
	TIME [epoch: 5.73 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36706647545401494		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.36706647545401494 | validation: 0.36246213625036083]
	TIME [epoch: 5.71 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37921237255579315		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.37921237255579315 | validation: 0.3584606975952171]
	TIME [epoch: 5.71 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3891077332144769		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.3891077332144769 | validation: 0.36598522115259696]
	TIME [epoch: 5.72 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3722113078510294		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.3722113078510294 | validation: 0.52015077731561]
	TIME [epoch: 5.75 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695713235543614		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.3695713235543614 | validation: 0.5013482257911442]
	TIME [epoch: 5.71 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4011435482181605		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.4011435482181605 | validation: 0.47339763940449003]
	TIME [epoch: 5.71 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3910055059075816		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.3910055059075816 | validation: 0.4022089460198126]
	TIME [epoch: 5.69 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3555191171030023		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.3555191171030023 | validation: 0.37643607988368283]
	TIME [epoch: 5.71 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36870432297007116		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.36870432297007116 | validation: 0.3700034521316509]
	TIME [epoch: 5.71 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3828969382467221		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.3828969382467221 | validation: 0.35926320308240534]
	TIME [epoch: 5.74 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4060334285631479		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.4060334285631479 | validation: 0.3533281913400645]
	TIME [epoch: 5.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37112724024437127		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.37112724024437127 | validation: 0.35968219849378275]
	TIME [epoch: 5.71 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3755066110402285		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.3755066110402285 | validation: 0.35268699652163676]
	TIME [epoch: 5.71 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.369567542031078		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.369567542031078 | validation: 0.38275818547606405]
	TIME [epoch: 5.69 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4013150292932261		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.4013150292932261 | validation: 0.3720052288419741]
	TIME [epoch: 5.71 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4096621837832555		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.4096621837832555 | validation: 0.5824940752211666]
	TIME [epoch: 5.73 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687970957555574		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.4687970957555574 | validation: 0.41033090597126043]
	TIME [epoch: 5.71 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34824327671950994		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.34824327671950994 | validation: 0.43224252467608304]
	TIME [epoch: 5.71 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42695936488071184		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.42695936488071184 | validation: 0.4553703935322443]
	TIME [epoch: 5.71 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3980529198555926		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.3980529198555926 | validation: 0.4419608306206632]
	TIME [epoch: 5.71 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3890473257838626		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.3890473257838626 | validation: 0.4380080144407461]
	TIME [epoch: 5.71 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5233617295888737		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.5233617295888737 | validation: 0.43229166812641373]
	TIME [epoch: 5.75 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4083706330096729		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.4083706330096729 | validation: 0.3579479897960769]
	TIME [epoch: 5.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3586483688304183		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.3586483688304183 | validation: 0.46684555990272286]
	TIME [epoch: 5.71 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44932517118974197		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.44932517118974197 | validation: 0.42322269217653996]
	TIME [epoch: 5.69 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38729323393995096		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.38729323393995096 | validation: 0.4340984522121082]
	TIME [epoch: 5.71 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3647124314007817		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.3647124314007817 | validation: 0.4251155097530795]
	TIME [epoch: 5.69 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37046611976514415		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.37046611976514415 | validation: 0.44158523158675517]
	TIME [epoch: 5.75 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40153686323883636		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.40153686323883636 | validation: 0.36915653977719787]
	TIME [epoch: 5.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36585786809611764		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.36585786809611764 | validation: 0.38284565740718024]
	TIME [epoch: 5.69 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518854976709448		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.3518854976709448 | validation: 0.4694177333366259]
	TIME [epoch: 5.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.413737832957608		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.413737832957608 | validation: 0.432090205461874]
	TIME [epoch: 5.69 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3767330623970155		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.3767330623970155 | validation: 0.4308293897638081]
	TIME [epoch: 5.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35176372413638957		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.35176372413638957 | validation: 0.42506577945934376]
	TIME [epoch: 5.74 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436525721857363		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.3436525721857363 | validation: 0.39657464870483844]
	TIME [epoch: 5.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34941271106505856		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.34941271106505856 | validation: 0.6639848251233292]
	TIME [epoch: 5.69 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41824476867173116		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.41824476867173116 | validation: 0.41161779171465396]
	TIME [epoch: 5.69 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3398833219369435		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.3398833219369435 | validation: 0.42870121298064234]
	TIME [epoch: 5.69 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35078157578533403		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.35078157578533403 | validation: 0.42519968337952707]
	TIME [epoch: 5.69 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860680820911746		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.3860680820911746 | validation: 0.43703458853025245]
	TIME [epoch: 5.73 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34357883077427015		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.34357883077427015 | validation: 0.42931082044177465]
	TIME [epoch: 5.7 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36013214634029556		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.36013214634029556 | validation: 0.4301742899206822]
	TIME [epoch: 5.69 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38366422032941727		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.38366422032941727 | validation: 0.42712280587209406]
	TIME [epoch: 5.69 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362339921457993		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.362339921457993 | validation: 0.6344366668532628]
	TIME [epoch: 5.69 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45721439559861154		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.45721439559861154 | validation: 0.5327603654961175]
	TIME [epoch: 5.69 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3683476426171134		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.3683476426171134 | validation: 0.3577472177080325]
	TIME [epoch: 5.73 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3834095870485324		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.3834095870485324 | validation: 0.3905147191684325]
	TIME [epoch: 5.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575837263121773		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.3575837263121773 | validation: 0.4123521348831894]
	TIME [epoch: 5.71 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3862366418820242		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.3862366418820242 | validation: 0.39678609222225647]
	TIME [epoch: 5.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692154394409569		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.3692154394409569 | validation: 0.4426539106352332]
	TIME [epoch: 5.69 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34548480826559813		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.34548480826559813 | validation: 0.3681711016690575]
	TIME [epoch: 5.69 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41641492365159394		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.41641492365159394 | validation: 0.39950211847204964]
	TIME [epoch: 5.74 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3768813010318725		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.3768813010318725 | validation: 0.4016836907865008]
	TIME [epoch: 5.69 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37893635901353206		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.37893635901353206 | validation: 0.41038698405805585]
	TIME [epoch: 5.69 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3659039827488023		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.3659039827488023 | validation: 0.46745704100563573]
	TIME [epoch: 5.69 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4272381501955011		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.4272381501955011 | validation: 0.40297080399534324]
	TIME [epoch: 5.69 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4506118704675544		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.4506118704675544 | validation: 0.5730144617338222]
	TIME [epoch: 5.69 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37110977856995253		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.37110977856995253 | validation: 0.45427106471365347]
	TIME [epoch: 5.73 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39194378830137744		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.39194378830137744 | validation: 0.4241507269032461]
	TIME [epoch: 5.7 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3562769857462719		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.3562769857462719 | validation: 0.3480177520361846]
	TIME [epoch: 5.69 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3561910160823833		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.3561910160823833 | validation: 0.4141087621553314]
	TIME [epoch: 5.69 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3880450726342093		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.3880450726342093 | validation: 0.40789941098484095]
	TIME [epoch: 5.69 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34989461380152775		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.34989461380152775 | validation: 0.3720666800131078]
	TIME [epoch: 5.69 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35326264159978776		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.35326264159978776 | validation: 0.385546694374803]
	TIME [epoch: 5.73 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35674134480520686		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.35674134480520686 | validation: 0.4473196151331481]
	TIME [epoch: 5.71 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609147994267459		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.3609147994267459 | validation: 0.46012737105747403]
	TIME [epoch: 5.69 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3803474481266736		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.3803474481266736 | validation: 0.4442039501685151]
	TIME [epoch: 5.69 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4189189861818382		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.4189189861818382 | validation: 0.4015733336999056]
	TIME [epoch: 5.71 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37737400626787637		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.37737400626787637 | validation: 0.41986841427136484]
	TIME [epoch: 5.69 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37596489913378905		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.37596489913378905 | validation: 0.39888175739584064]
	TIME [epoch: 5.75 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40129459896733266		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.40129459896733266 | validation: 0.4401998886864864]
	TIME [epoch: 5.72 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35179250443445786		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.35179250443445786 | validation: 0.50600413181735]
	TIME [epoch: 5.71 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805883817055668		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.3805883817055668 | validation: 0.46045961390207524]
	TIME [epoch: 5.69 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524984847624856		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.3524984847624856 | validation: 0.39312266756099135]
	TIME [epoch: 5.71 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3411655044932844		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.3411655044932844 | validation: 0.40852435449647145]
	TIME [epoch: 5.71 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472274490028849		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.3472274490028849 | validation: 0.34592450087296256]
	TIME [epoch: 5.75 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3545412981834629		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.3545412981834629 | validation: 0.3916261046079818]
	TIME [epoch: 5.69 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3675423303660935		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.3675423303660935 | validation: 0.3560228636721531]
	TIME [epoch: 5.69 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3369192391440834		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.3369192391440834 | validation: 0.37542768009338295]
	TIME [epoch: 5.69 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35727549550959575		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.35727549550959575 | validation: 0.32616455549487183]
	TIME [epoch: 5.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_942.pth
	Model improved!!!
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3862116768739504		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.3862116768739504 | validation: 0.413903223170622]
	TIME [epoch: 5.69 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34316049151312183		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.34316049151312183 | validation: 0.4226008642797608]
	TIME [epoch: 5.73 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3946473167556711		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.3946473167556711 | validation: 0.4398093244388911]
	TIME [epoch: 5.69 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41657615797771963		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.41657615797771963 | validation: 0.33850916908385187]
	TIME [epoch: 5.69 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35267297580006246		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.35267297580006246 | validation: 0.33642408138565233]
	TIME [epoch: 5.69 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3708935958834138		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.3708935958834138 | validation: 0.3603485488938509]
	TIME [epoch: 5.69 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34396031700171814		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.34396031700171814 | validation: 0.3505188491105025]
	TIME [epoch: 5.69 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3470974170124473		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.3470974170124473 | validation: 0.3666172726595733]
	TIME [epoch: 5.73 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35122350749996467		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.35122350749996467 | validation: 0.33039594367547087]
	TIME [epoch: 5.72 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3451096902003905		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.3451096902003905 | validation: 0.3338335985369473]
	TIME [epoch: 5.71 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3444161160668924		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.3444161160668924 | validation: 0.4121313879407573]
	TIME [epoch: 5.69 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3381937947172388		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.3381937947172388 | validation: 0.3909943254534]
	TIME [epoch: 5.71 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.374634234701794		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.374634234701794 | validation: 0.3517625966960292]
	TIME [epoch: 5.71 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3487849822784843		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.3487849822784843 | validation: 0.3167886154462239]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_956.pth
	Model improved!!!
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372766814260759		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.3372766814260759 | validation: 0.5352753915428579]
	TIME [epoch: 5.72 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4095978352757602		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.4095978352757602 | validation: 0.4351347151435405]
	TIME [epoch: 5.71 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40992803302828157		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.40992803302828157 | validation: 0.3719772739551645]
	TIME [epoch: 5.71 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33486944791854023		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.33486944791854023 | validation: 0.3986258073726639]
	TIME [epoch: 5.71 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331509937131563		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.331509937131563 | validation: 0.5301177568867708]
	TIME [epoch: 5.69 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39322808872687465		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.39322808872687465 | validation: 0.5116249575356184]
	TIME [epoch: 5.75 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36228871791716655		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.36228871791716655 | validation: 0.3836000151092581]
	TIME [epoch: 5.71 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33428046160168423		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.33428046160168423 | validation: 0.5234792744693796]
	TIME [epoch: 5.71 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4342456215380461		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.4342456215380461 | validation: 0.38695330890899826]
	TIME [epoch: 5.69 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373370623030645		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.373370623030645 | validation: 0.40057622043179664]
	TIME [epoch: 5.69 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3455375017803276		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.3455375017803276 | validation: 0.4007263179973167]
	TIME [epoch: 5.71 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34926123424194633		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.34926123424194633 | validation: 0.3690068163037503]
	TIME [epoch: 5.76 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3958727512798013		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.3958727512798013 | validation: 0.4066166686362422]
	TIME [epoch: 5.72 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3331985988758096		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.3331985988758096 | validation: 0.3944031074293424]
	TIME [epoch: 5.71 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31541135634317896		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.31541135634317896 | validation: 0.3397389833780291]
	TIME [epoch: 5.71 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3812419914967966		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.3812419914967966 | validation: 0.39783799101884254]
	TIME [epoch: 5.71 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3473385951708411		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.3473385951708411 | validation: 0.36977546421447327]
	TIME [epoch: 5.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3504406828739478		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.3504406828739478 | validation: 0.4220031638719224]
	TIME [epoch: 5.75 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3490165835459053		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.3490165835459053 | validation: 0.36844065995150765]
	TIME [epoch: 5.72 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3396688016854499		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.3396688016854499 | validation: 0.4002308383275633]
	TIME [epoch: 5.69 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3500551297087739		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.3500551297087739 | validation: 0.4513795391131443]
	TIME [epoch: 5.71 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4873061019451076		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.4873061019451076 | validation: 0.450310300298036]
	TIME [epoch: 5.71 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3712225053481697		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.3712225053481697 | validation: 0.34389153582441695]
	TIME [epoch: 5.71 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552319095809514		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.3552319095809514 | validation: 0.3865651053849986]
	TIME [epoch: 5.75 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37754106169249524		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.37754106169249524 | validation: 0.4069330873526482]
	TIME [epoch: 5.72 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628970147448885		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.3628970147448885 | validation: 0.3278536160218617]
	TIME [epoch: 5.69 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3741716914790001		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.3741716914790001 | validation: 0.3509003600820661]
	TIME [epoch: 5.69 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3597488041727801		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.3597488041727801 | validation: 0.4286771269017058]
	TIME [epoch: 5.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540148592491651		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.3540148592491651 | validation: 0.42183288120589724]
	TIME [epoch: 5.71 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.344636794584873		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.344636794584873 | validation: 0.36899204382033846]
	TIME [epoch: 5.74 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35453648269241783		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.35453648269241783 | validation: 0.39552030223260504]
	TIME [epoch: 5.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3723093780727274		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.3723093780727274 | validation: 0.43514181402957014]
	TIME [epoch: 5.69 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3388598413993159		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.3388598413993159 | validation: 0.4493659951250734]
	TIME [epoch: 5.69 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49060559678329363		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.49060559678329363 | validation: 0.535897112231807]
	TIME [epoch: 5.69 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36531786962382606		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.36531786962382606 | validation: 0.3857730440184539]
	TIME [epoch: 5.71 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3393272780826909		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.3393272780826909 | validation: 0.37419127328674995]
	TIME [epoch: 5.73 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33230790644526653		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.33230790644526653 | validation: 0.44256626998614096]
	TIME [epoch: 5.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3337598100181468		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.3337598100181468 | validation: 0.4452518251323319]
	TIME [epoch: 5.69 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3311907086213164		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.3311907086213164 | validation: 0.45457646494524184]
	TIME [epoch: 5.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34361134628126305		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.34361134628126305 | validation: 0.4706144599969011]
	TIME [epoch: 5.69 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3544407701752606		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.3544407701752606 | validation: 0.4162369895234834]
	TIME [epoch: 5.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3421534940038888		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.3421534940038888 | validation: 0.46284929855222506]
	TIME [epoch: 5.75 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34936164031644656		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.34936164031644656 | validation: 0.4777775953690104]
	TIME [epoch: 5.71 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33993302519668933		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.33993302519668933 | validation: 0.4005634418033124]
	TIME [epoch: 5.71 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543607074130257		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.3543607074130257 | validation: 0.39428838475227324]
	TIME [epoch: 5.71 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3451665542943668		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.3451665542943668 | validation: 0.5167613522501031]
	TIME [epoch: 5.71 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36926723392814964		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.36926723392814964 | validation: 0.35331743703389507]
	TIME [epoch: 5.71 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36487226693601743		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.36487226693601743 | validation: 0.39184021545216996]
	TIME [epoch: 5.75 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33487510269955867		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.33487510269955867 | validation: 0.42117145275936607]
	TIME [epoch: 5.71 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3624881637701597		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.3624881637701597 | validation: 0.38330504072790844]
	TIME [epoch: 5.71 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33324778404825783		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.33324778404825783 | validation: 0.426394279009061]
	TIME [epoch: 5.71 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3228315101922679		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.3228315101922679 | validation: 0.4443998047553789]
	TIME [epoch: 5.71 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34941678766536494		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.34941678766536494 | validation: 0.4150234563565944]
	TIME [epoch: 5.71 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559605203985946		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.3559605203985946 | validation: 0.45491855604877096]
	TIME [epoch: 5.75 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3418731309195503		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.3418731309195503 | validation: 0.38166094111071774]
	TIME [epoch: 5.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3381507348423441		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.3381507348423441 | validation: 0.4134593010390735]
	TIME [epoch: 5.69 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36187565278363804		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.36187565278363804 | validation: 0.40365807164062567]
	TIME [epoch: 5.69 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32690999615220295		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.32690999615220295 | validation: 0.4092950394334896]
	TIME [epoch: 5.69 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36620317165764027		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.36620317165764027 | validation: 0.46923302044869525]
	TIME [epoch: 5.69 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3457821871809708		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.3457821871809708 | validation: 0.4169671452667328]
	TIME [epoch: 5.74 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36187354086036083		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.36187354086036083 | validation: 0.3632225865862527]
	TIME [epoch: 5.7 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3394112569683377		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.3394112569683377 | validation: 0.4504588861688029]
	TIME [epoch: 5.69 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3438943399030433		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.3438943399030433 | validation: 0.43175769842788386]
	TIME [epoch: 5.69 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3393883703775049		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.3393883703775049 | validation: 0.4528832994254879]
	TIME [epoch: 5.69 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34533049570011115		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.34533049570011115 | validation: 0.45059699778484674]
	TIME [epoch: 5.69 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3685573434848946		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.3685573434848946 | validation: 0.38018876360253756]
	TIME [epoch: 5.73 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3717900462526884		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.3717900462526884 | validation: 0.3832332944107097]
	TIME [epoch: 5.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3197026229702113		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.3197026229702113 | validation: 0.4515949403461422]
	TIME [epoch: 5.69 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32818977605072747		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.32818977605072747 | validation: 0.4247093193668157]
	TIME [epoch: 5.69 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3399305104730249		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.3399305104730249 | validation: 0.3944517133466398]
	TIME [epoch: 5.69 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3578830474824482		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.3578830474824482 | validation: 0.5487373803809353]
	TIME [epoch: 5.71 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3642964550902782		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.3642964550902782 | validation: 0.3417694685592086]
	TIME [epoch: 5.72 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552472413269621		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.3552472413269621 | validation: 0.3521877438814478]
	TIME [epoch: 5.71 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32760420770752635		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.32760420770752635 | validation: 0.39675586240360006]
	TIME [epoch: 5.69 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3314052516141238		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.3314052516141238 | validation: 0.40474528229849316]
	TIME [epoch: 5.69 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34335172711989903		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.34335172711989903 | validation: 0.39702781214249927]
	TIME [epoch: 5.71 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3384912596014206		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.3384912596014206 | validation: 0.41529328547836103]
	TIME [epoch: 5.71 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34823561619410237		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.34823561619410237 | validation: 0.5999131524132337]
	TIME [epoch: 5.72 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4064163428654508		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.4064163428654508 | validation: 0.4403773499565679]
	TIME [epoch: 5.71 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32955904681119386		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.32955904681119386 | validation: 0.39034525803480163]
	TIME [epoch: 5.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32219353978759596		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.32219353978759596 | validation: 0.35151284779031244]
	TIME [epoch: 5.71 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33520087883558525		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.33520087883558525 | validation: 0.4052565912249398]
	TIME [epoch: 5.69 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3373656839862953		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.3373656839862953 | validation: 0.40798983153831214]
	TIME [epoch: 5.71 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3452630321537953		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.3452630321537953 | validation: 0.4651515661515242]
	TIME [epoch: 5.72 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3505397030631194		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.3505397030631194 | validation: 0.3548516168971304]
	TIME [epoch: 5.71 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35069581171806424		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.35069581171806424 | validation: 0.3882979179496951]
	TIME [epoch: 5.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3260950512474021		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.3260950512474021 | validation: 0.3590258428591338]
	TIME [epoch: 5.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3341173923693539		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.3341173923693539 | validation: 0.3520361650028427]
	TIME [epoch: 5.69 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32227456111055264		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.32227456111055264 | validation: 0.3431668780726696]
	TIME [epoch: 5.69 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33523861390939547		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.33523861390939547 | validation: 0.38217606883935956]
	TIME [epoch: 5.72 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3354364226831546		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.3354364226831546 | validation: 0.39965450503210065]
	TIME [epoch: 5.72 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3330979847707506		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.3330979847707506 | validation: 0.41313076843844726]
	TIME [epoch: 5.69 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34051735780627573		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.34051735780627573 | validation: 0.4455591881888115]
	TIME [epoch: 5.69 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34344719198678314		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.34344719198678314 | validation: 0.40686738250380794]
	TIME [epoch: 5.69 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33845509070606916		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.33845509070606916 | validation: 0.35889258436534577]
	TIME [epoch: 5.71 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33560586613367827		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.33560586613367827 | validation: 0.37433605226625755]
	TIME [epoch: 5.72 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33233569274836383		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.33233569274836383 | validation: 0.425324372643119]
	TIME [epoch: 5.71 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35261715647763425		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.35261715647763425 | validation: 0.39093245722008646]
	TIME [epoch: 5.69 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32843464122156585		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.32843464122156585 | validation: 0.3641376983082717]
	TIME [epoch: 5.71 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3274824040300713		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.3274824040300713 | validation: 0.4034047748463314]
	TIME [epoch: 5.71 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3340713930185097		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.3340713930185097 | validation: 0.4522908124351224]
	TIME [epoch: 5.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.322168449721769		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.322168449721769 | validation: 0.46721002255049326]
	TIME [epoch: 5.73 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34369295544767453		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.34369295544767453 | validation: 0.35822918477483484]
	TIME [epoch: 5.72 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3194486686180712		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.3194486686180712 | validation: 0.33724776395799166]
	TIME [epoch: 5.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32999818709990064		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.32999818709990064 | validation: 0.382518204074539]
	TIME [epoch: 5.71 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3242763555070064		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.3242763555070064 | validation: 0.45818183399627627]
	TIME [epoch: 5.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34227771370437454		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.34227771370437454 | validation: 0.3903226963553817]
	TIME [epoch: 5.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3324744312581179		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.3324744312581179 | validation: 0.42649217228203]
	TIME [epoch: 5.73 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3280852388318101		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.3280852388318101 | validation: 0.4210921498123801]
	TIME [epoch: 5.72 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34083897387088014		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.34083897387088014 | validation: 0.3617187230462895]
	TIME [epoch: 5.71 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3199793326665172		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.3199793326665172 | validation: 0.39560471851177736]
	TIME [epoch: 5.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338998956633224		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.3338998956633224 | validation: 0.35217512516441074]
	TIME [epoch: 5.71 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3463264497563622		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.3463264497563622 | validation: 0.36385431648375544]
	TIME [epoch: 5.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.321579251427992		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.321579251427992 | validation: 0.3869960448495358]
	TIME [epoch: 5.72 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336694859405066		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.3336694859405066 | validation: 0.41346710812123444]
	TIME [epoch: 5.72 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35323088296596067		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.35323088296596067 | validation: 0.3919719570360563]
	TIME [epoch: 5.69 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3471166662973169		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.3471166662973169 | validation: 0.3831920891765399]
	TIME [epoch: 5.71 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32485214653860334		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.32485214653860334 | validation: 0.3878304930985833]
	TIME [epoch: 5.71 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3140872503500726		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.3140872503500726 | validation: 0.33965961507605535]
	TIME [epoch: 5.69 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3445500922574962		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.3445500922574962 | validation: 0.367589561755395]
	TIME [epoch: 5.74 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3423549589709768		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.3423549589709768 | validation: 0.3656250319030281]
	TIME [epoch: 5.71 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3293355222976013		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.3293355222976013 | validation: 0.3627961951609844]
	TIME [epoch: 5.71 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35828773016234067		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.35828773016234067 | validation: 0.4121476898879599]
	TIME [epoch: 5.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318722348372881		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.3318722348372881 | validation: 0.36783074207096234]
	TIME [epoch: 5.71 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3161720173285254		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.3161720173285254 | validation: 0.36961975478346687]
	TIME [epoch: 5.69 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.368505896361304		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.368505896361304 | validation: 0.38471271356442216]
	TIME [epoch: 5.74 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3192297099915131		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.3192297099915131 | validation: 0.3780532166418537]
	TIME [epoch: 5.71 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3239009562552849		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.3239009562552849 | validation: 0.33475588986390803]
	TIME [epoch: 5.71 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33036330500596617		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.33036330500596617 | validation: 0.4175492270795085]
	TIME [epoch: 5.7 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31188850194589623		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.31188850194589623 | validation: 0.37706822345948937]
	TIME [epoch: 5.71 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.337399704066243		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.337399704066243 | validation: 0.44755473389424083]
	TIME [epoch: 5.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32706315767933974		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.32706315767933974 | validation: 0.36876330509548877]
	TIME [epoch: 5.71 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31188536809673817		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.31188536809673817 | validation: 0.3715216518238735]
	TIME [epoch: 5.73 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3333738210112361		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.3333738210112361 | validation: 0.3841090824473102]
	TIME [epoch: 5.71 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3169992019230472		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.3169992019230472 | validation: 0.3775354661383123]
	TIME [epoch: 5.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33655770223554116		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.33655770223554116 | validation: 0.4563323181317741]
	TIME [epoch: 5.71 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3192622823429831		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.3192622823429831 | validation: 0.3992941269056138]
	TIME [epoch: 5.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3258463245413131		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.3258463245413131 | validation: 0.419145618717673]
	TIME [epoch: 5.73 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343264145423964		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.3343264145423964 | validation: 0.33186972281411825]
	TIME [epoch: 5.73 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30875902032334357		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.30875902032334357 | validation: 0.35608523750421556]
	TIME [epoch: 5.71 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32164453514164504		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.32164453514164504 | validation: 0.40097881428574617]
	TIME [epoch: 5.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35208120779581026		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.35208120779581026 | validation: 0.3777360392552868]
	TIME [epoch: 5.71 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30709617882131846		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.30709617882131846 | validation: 0.3814788845831836]
	TIME [epoch: 5.69 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3161251964341558		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.3161251964341558 | validation: 0.4182175057567459]
	TIME [epoch: 5.72 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103444870803089		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.3103444870803089 | validation: 0.35556443698058376]
	TIME [epoch: 5.72 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3106236678135328		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.3106236678135328 | validation: 0.3967167979646883]
	TIME [epoch: 5.71 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33016221479020036		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.33016221479020036 | validation: 0.4125124141006723]
	TIME [epoch: 5.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3212459639629214		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.3212459639629214 | validation: 0.38111617474663456]
	TIME [epoch: 5.71 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3227490117915598		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.3227490117915598 | validation: 0.5423855978637362]
	TIME [epoch: 5.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36027762840465916		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.36027762840465916 | validation: 0.3814130667112029]
	TIME [epoch: 5.73 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30881294245994273		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.30881294245994273 | validation: 0.43797157694513333]
	TIME [epoch: 5.72 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32175706486181865		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.32175706486181865 | validation: 0.39908307477481414]
	TIME [epoch: 5.71 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30731412728824387		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.30731412728824387 | validation: 0.4012966470404689]
	TIME [epoch: 5.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.326467936694166		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.326467936694166 | validation: 0.3719639287800716]
	TIME [epoch: 5.69 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32749735965797844		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.32749735965797844 | validation: 0.3697076068013919]
	TIME [epoch: 5.7 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363345274121617		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.363345274121617 | validation: 0.4359905841929426]
	TIME [epoch: 5.71 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31944652389878303		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.31944652389878303 | validation: 0.3557125025982857]
	TIME [epoch: 5.74 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36706831574939425		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.36706831574939425 | validation: 0.3712784707418559]
	TIME [epoch: 5.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3141895641792477		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.3141895641792477 | validation: 0.39111973384867316]
	TIME [epoch: 5.71 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31469805732857736		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.31469805732857736 | validation: 0.3840871830131775]
	TIME [epoch: 5.69 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3177991190856711		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.3177991190856711 | validation: 0.3687451902488074]
	TIME [epoch: 5.71 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30714193549116175		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.30714193549116175 | validation: 0.3881746539553502]
	TIME [epoch: 5.73 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3166307584719774		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.3166307584719774 | validation: 0.3986071579207092]
	TIME [epoch: 5.73 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31378050418990155		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.31378050418990155 | validation: 0.44156990195824636]
	TIME [epoch: 5.71 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3181976075714504		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.3181976075714504 | validation: 0.38200452044314215]
	TIME [epoch: 5.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3172821326653946		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.3172821326653946 | validation: 0.39064991255870807]
	TIME [epoch: 5.69 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32716193153420375		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.32716193153420375 | validation: 0.36119006730344694]
	TIME [epoch: 5.71 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3184369638857491		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.3184369638857491 | validation: 0.3672710634245824]
	TIME [epoch: 5.71 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31342014771118004		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.31342014771118004 | validation: 0.3392579408641565]
	TIME [epoch: 5.74 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3195557479368225		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.3195557479368225 | validation: 0.35953547238483]
	TIME [epoch: 5.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30835947813997133		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.30835947813997133 | validation: 0.3627067210782871]
	TIME [epoch: 5.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3175242404511543		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.3175242404511543 | validation: 0.3501495464031921]
	TIME [epoch: 5.71 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352697075707096		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.3352697075707096 | validation: 0.32264221970399787]
	TIME [epoch: 5.7 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143509462909163		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.3143509462909163 | validation: 0.33980542408138903]
	TIME [epoch: 5.73 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31276702305765225		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.31276702305765225 | validation: 0.394930058653184]
	TIME [epoch: 5.73 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3171984920590126		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.3171984920590126 | validation: 0.44627145128333456]
	TIME [epoch: 5.71 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32376990986656196		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.32376990986656196 | validation: 0.3839382801803208]
	TIME [epoch: 5.71 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.323734511646926		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.323734511646926 | validation: 0.37092773355280934]
	TIME [epoch: 5.71 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3255066105916886		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.3255066105916886 | validation: 0.38756910721854476]
	TIME [epoch: 5.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3957180067669759		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.3957180067669759 | validation: 0.40579866091124345]
	TIME [epoch: 5.73 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34708012932410237		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.34708012932410237 | validation: 0.4410168485850946]
	TIME [epoch: 5.73 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31521832296928354		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.31521832296928354 | validation: 0.4295257067266368]
	TIME [epoch: 5.71 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3075380245237403		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.3075380245237403 | validation: 0.4056295584653183]
	TIME [epoch: 5.71 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3203176285855991		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.3203176285855991 | validation: 0.42745156011080154]
	TIME [epoch: 5.71 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049465532731282		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.3049465532731282 | validation: 0.35162156423327057]
	TIME [epoch: 5.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.314721411855908		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.314721411855908 | validation: 0.36343040438737506]
	TIME [epoch: 5.73 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3133170511928707		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.3133170511928707 | validation: 0.42437945400513644]
	TIME [epoch: 5.73 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3204911433811982		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.3204911433811982 | validation: 0.48011601214041305]
	TIME [epoch: 5.71 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3190305648748198		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.3190305648748198 | validation: 0.35941694290854836]
	TIME [epoch: 5.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3166558359751509		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.3166558359751509 | validation: 0.43818947011544146]
	TIME [epoch: 5.71 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3260874165831942		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.3260874165831942 | validation: 0.37010656468926656]
	TIME [epoch: 5.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33390862710294666		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.33390862710294666 | validation: 0.3684499510384878]
	TIME [epoch: 5.71 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3209137453402817		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.3209137453402817 | validation: 0.35868312017137266]
	TIME [epoch: 5.74 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30247303987431334		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.30247303987431334 | validation: 0.38105911162476597]
	TIME [epoch: 5.71 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3151094425636293		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.3151094425636293 | validation: 0.3220067569190455]
	TIME [epoch: 5.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3184117068815947		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.3184117068815947 | validation: 0.35893412759117715]
	TIME [epoch: 5.71 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3110245468818491		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.3110245468818491 | validation: 0.39995735546945327]
	TIME [epoch: 5.69 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3078235065614026		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.3078235065614026 | validation: 0.3658036450209681]
	TIME [epoch: 5.71 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31953955748212737		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.31953955748212737 | validation: 0.39680808186627203]
	TIME [epoch: 5.73 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34358911103452244		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.34358911103452244 | validation: 0.3351138906226713]
	TIME [epoch: 5.71 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3067155046301993		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.3067155046301993 | validation: 0.33334552846226345]
	TIME [epoch: 5.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34596376754032176		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.34596376754032176 | validation: 0.32944096174785]
	TIME [epoch: 5.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3061791399065904		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.3061791399065904 | validation: 0.3715073879591178]
	TIME [epoch: 5.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000806162485639		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.3000806162485639 | validation: 0.3583214965187513]
	TIME [epoch: 5.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33311700534810784		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.33311700534810784 | validation: 0.3794762024924593]
	TIME [epoch: 5.73 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3160275912781536		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.3160275912781536 | validation: 0.302769973712685]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_1162.pth
	Model improved!!!
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3241122310199502		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.3241122310199502 | validation: 0.36124666980423853]
	TIME [epoch: 5.7 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29903108930046396		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.29903108930046396 | validation: 0.30503356746100174]
	TIME [epoch: 5.71 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32134231375885014		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.32134231375885014 | validation: 0.30369270154424655]
	TIME [epoch: 5.71 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31178560238231956		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.31178560238231956 | validation: 0.3278040931653341]
	TIME [epoch: 5.71 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757605769255827		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.3757605769255827 | validation: 0.34800929818589976]
	TIME [epoch: 5.72 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31568422662897716		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.31568422662897716 | validation: 0.3442374169857527]
	TIME [epoch: 5.71 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3207855912470762		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.3207855912470762 | validation: 0.3477290292641328]
	TIME [epoch: 5.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31646708253309974		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.31646708253309974 | validation: 0.3589120403792077]
	TIME [epoch: 5.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3076745882631144		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.3076745882631144 | validation: 0.31027193470390557]
	TIME [epoch: 5.7 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3137207650721837		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.3137207650721837 | validation: 0.318318541389417]
	TIME [epoch: 5.71 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3158197771873755		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.3158197771873755 | validation: 0.35774989848165645]
	TIME [epoch: 5.73 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3197778970610703		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.3197778970610703 | validation: 0.3780842721693249]
	TIME [epoch: 5.71 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31753932777861266		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.31753932777861266 | validation: 0.3871934855273639]
	TIME [epoch: 5.69 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30848594057110934		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.30848594057110934 | validation: 0.36433441288193813]
	TIME [epoch: 5.71 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031878663977555		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.3031878663977555 | validation: 0.3507580981048936]
	TIME [epoch: 5.7 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3146291388182238		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.3146291388182238 | validation: 0.3654210494578538]
	TIME [epoch: 5.71 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34919638811386344		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.34919638811386344 | validation: 0.3245478611912461]
	TIME [epoch: 5.73 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31428759741375023		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.31428759741375023 | validation: 0.30738717677053123]
	TIME [epoch: 5.71 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3221552273431891		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.3221552273431891 | validation: 0.3737607993329676]
	TIME [epoch: 5.71 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30653104709778434		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.30653104709778434 | validation: 0.36543003582464795]
	TIME [epoch: 5.71 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31703047029354753		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.31703047029354753 | validation: 0.39616129239699166]
	TIME [epoch: 5.71 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3198179243990328		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.3198179243990328 | validation: 0.37637138849814056]
	TIME [epoch: 5.71 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3155305631043659		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.3155305631043659 | validation: 0.35374043475483485]
	TIME [epoch: 5.74 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143845520724856		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.3143845520724856 | validation: 0.39043794469864945]
	TIME [epoch: 5.71 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31046765173955715		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.31046765173955715 | validation: 0.41262101758430875]
	TIME [epoch: 5.71 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31879902937531984		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.31879902937531984 | validation: 0.4991274396696874]
	TIME [epoch: 5.69 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508689712737716		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.3508689712737716 | validation: 0.40083844437095645]
	TIME [epoch: 5.71 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000432524882332		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.3000432524882332 | validation: 0.3588387707697986]
	TIME [epoch: 5.71 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3107771179951616		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.3107771179951616 | validation: 0.4058926476742238]
	TIME [epoch: 5.74 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3019834783088138		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.3019834783088138 | validation: 0.3756523091423922]
	TIME [epoch: 5.69 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30991025108841175		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.30991025108841175 | validation: 0.3973559029261706]
	TIME [epoch: 5.69 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31053866907212363		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.31053866907212363 | validation: 0.35155425867289397]
	TIME [epoch: 5.7 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3063858633101618		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.3063858633101618 | validation: 0.35861285446234403]
	TIME [epoch: 5.71 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30340307496813235		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.30340307496813235 | validation: 0.3525054819098946]
	TIME [epoch: 5.69 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32101877003219303		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.32101877003219303 | validation: 0.37727626836080064]
	TIME [epoch: 5.74 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33197439798791556		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.33197439798791556 | validation: 0.34645974276770064]
	TIME [epoch: 5.69 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31131937571807966		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.31131937571807966 | validation: 0.365192639440299]
	TIME [epoch: 5.69 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3140689303300624		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.3140689303300624 | validation: 0.43799585837055516]
	TIME [epoch: 5.69 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318048847137983		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.3318048847137983 | validation: 0.37702226752886736]
	TIME [epoch: 5.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143032541919038		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.3143032541919038 | validation: 0.3373086299647845]
	TIME [epoch: 5.7 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30283718274383675		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.30283718274383675 | validation: 0.37167774366963235]
	TIME [epoch: 5.73 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30515447046856836		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.30515447046856836 | validation: 0.3611172391120917]
	TIME [epoch: 5.69 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3177092531776066		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.3177092531776066 | validation: 0.3886512574622284]
	TIME [epoch: 5.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31922499458106846		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.31922499458106846 | validation: 0.3516411653881332]
	TIME [epoch: 5.69 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2937844564388015		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.2937844564388015 | validation: 0.3796582563662514]
	TIME [epoch: 5.69 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30530262087054993		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.30530262087054993 | validation: 0.35734648078550174]
	TIME [epoch: 5.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3022849160730189		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.3022849160730189 | validation: 0.33203058300034466]
	TIME [epoch: 5.75 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30329913013088566		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.30329913013088566 | validation: 0.3424698693258333]
	TIME [epoch: 5.69 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2988592173212023		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.2988592173212023 | validation: 0.3682700693170711]
	TIME [epoch: 5.69 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30551091770164973		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.30551091770164973 | validation: 0.39375925743274964]
	TIME [epoch: 5.69 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31737036393347146		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.31737036393347146 | validation: 0.334661600496783]
	TIME [epoch: 5.71 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30272953626612625		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.30272953626612625 | validation: 0.35524433942370964]
	TIME [epoch: 5.69 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30893071069946576		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.30893071069946576 | validation: 0.3285100139609991]
	TIME [epoch: 5.75 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30517203064470433		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.30517203064470433 | validation: 0.2975990505537528]
	TIME [epoch: 5.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r2_20240310_010408/states/model_tr_study201_1216.pth
	Model improved!!!
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3104197604038987		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.3104197604038987 | validation: 0.3372101595610921]
	TIME [epoch: 5.72 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2992371096938362		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.2992371096938362 | validation: 0.3639136458061512]
	TIME [epoch: 5.71 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3035197035393038		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.3035197035393038 | validation: 0.3336515095881657]
	TIME [epoch: 5.71 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29626054994499745		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.29626054994499745 | validation: 0.33642005693660587]
	TIME [epoch: 5.72 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3055863976985562		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.3055863976985562 | validation: 0.43276626151475933]
	TIME [epoch: 5.74 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3069837132979669		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.3069837132979669 | validation: 0.37312503482412807]
	TIME [epoch: 5.72 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29531370707830706		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.29531370707830706 | validation: 0.4193241313314262]
	TIME [epoch: 5.71 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31910403064958937		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.31910403064958937 | validation: 0.3905628336442205]
	TIME [epoch: 5.71 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3068532109743666		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.3068532109743666 | validation: 0.3622873501013515]
	TIME [epoch: 5.71 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29535471573858335		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.29535471573858335 | validation: 0.3427344264391726]
	TIME [epoch: 5.72 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.301850043459426		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.301850043459426 | validation: 0.3958120368407559]
	TIME [epoch: 5.74 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3236058078307834		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.3236058078307834 | validation: 0.31962638164974555]
	TIME [epoch: 5.71 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30230118313428317		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.30230118313428317 | validation: 0.3362653866235246]
	TIME [epoch: 5.71 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3019830413221933		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.3019830413221933 | validation: 0.3504017044056788]
	TIME [epoch: 5.71 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30001373180052765		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.30001373180052765 | validation: 0.35424721497915573]
	TIME [epoch: 5.71 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30195655047144365		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.30195655047144365 | validation: 0.39265174991384644]
	TIME [epoch: 5.71 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3056281817492714		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.3056281817492714 | validation: 0.384781806001755]
	TIME [epoch: 5.75 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3065866935936026		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.3065866935936026 | validation: 0.36050104520633947]
	TIME [epoch: 5.71 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30177304524358306		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.30177304524358306 | validation: 0.387049738019802]
	TIME [epoch: 5.71 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29498343207770356		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.29498343207770356 | validation: 0.3829779061646048]
	TIME [epoch: 5.71 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2948695184307993		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.2948695184307993 | validation: 0.3856762217587176]
	TIME [epoch: 5.71 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30662545440142774		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.30662545440142774 | validation: 0.3493479097829257]
	TIME [epoch: 5.71 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31265469597940654		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.31265469597940654 | validation: 0.3637746768132219]
	TIME [epoch: 5.75 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30933623136414146		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.30933623136414146 | validation: 0.33477004801333843]
	TIME [epoch: 5.71 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2985698664591808		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.2985698664591808 | validation: 0.3589287864595579]
	TIME [epoch: 5.71 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3089054067254711		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.3089054067254711 | validation: 0.34327833768989763]
	TIME [epoch: 5.71 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29847512218864725		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.29847512218864725 | validation: 0.3381412032061921]
	TIME [epoch: 5.71 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30484907074498924		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.30484907074498924 | validation: 0.3447106243282882]
	TIME [epoch: 5.71 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.316707435684821		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.316707435684821 | validation: 0.34801953136399283]
	TIME [epoch: 5.75 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3223568984275357		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.3223568984275357 | validation: 0.3489586153606302]
	TIME [epoch: 5.71 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30220868119836475		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.30220868119836475 | validation: 0.3653900711393096]
	TIME [epoch: 5.71 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29808165620076854		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.29808165620076854 | validation: 0.35854769852901297]
	TIME [epoch: 5.71 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29886837177706904		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.29886837177706904 | validation: 0.36046428154146853]
	TIME [epoch: 5.71 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3035989765491439		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.3035989765491439 | validation: 0.33065511209490633]
	TIME [epoch: 5.71 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2964559888342534		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.2964559888342534 | validation: 0.330671951200449]
	TIME [epoch: 5.75 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3084641731388171		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.3084641731388171 | validation: 0.32630327220209565]
	TIME [epoch: 5.72 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2999279856264811		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.2999279856264811 | validation: 0.35062353413936137]
	TIME [epoch: 5.72 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3240676774411616		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.3240676774411616 | validation: 0.3229441118675549]
	TIME [epoch: 5.72 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3232712111502225		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.3232712111502225 | validation: 0.37580359522713075]
	TIME [epoch: 5.72 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3109806792719278		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.3109806792719278 | validation: 0.34482940762830394]
	TIME [epoch: 5.72 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3016233460464399		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.3016233460464399 | validation: 0.33681920339182514]
	TIME [epoch: 5.75 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000588119130064		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.3000588119130064 | validation: 0.35707455992668474]
	TIME [epoch: 5.72 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29052789890235337		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.29052789890235337 | validation: 0.34604449255135245]
	TIME [epoch: 5.72 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29999085787017526		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.29999085787017526 | validation: 0.37129833219000924]
	TIME [epoch: 5.72 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3006835498438644		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.3006835498438644 | validation: 0.36303987136610216]
	TIME [epoch: 5.72 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3005343949676763		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.3005343949676763 | validation: 0.33851583828299725]
	TIME [epoch: 5.72 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003070395874323		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.3003070395874323 | validation: 0.32375521865707313]
	TIME [epoch: 5.76 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2967618875447379		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.2967618875447379 | validation: 0.32886122400409035]
	TIME [epoch: 5.72 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031778782698684		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.3031778782698684 | validation: 0.37536887759921]
	TIME [epoch: 5.72 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.295494438422831		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.295494438422831 | validation: 0.34486315752958857]
	TIME [epoch: 5.72 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2914168013999664		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.2914168013999664 | validation: 0.3878885993502972]
	TIME [epoch: 5.72 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038057966923713		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.3038057966923713 | validation: 0.36991451322768304]
	TIME [epoch: 5.72 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30015134804058563		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.30015134804058563 | validation: 0.3506339939177309]
	TIME [epoch: 5.76 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29411866392416813		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.29411866392416813 | validation: 0.3541565306999124]
	TIME [epoch: 5.72 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2977916843271502		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.2977916843271502 | validation: 0.3936079147764982]
	TIME [epoch: 5.72 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3144417641333349		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.3144417641333349 | validation: 0.3223669275141461]
	TIME [epoch: 5.72 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29601632723431115		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.29601632723431115 | validation: 0.35632580254494556]
	TIME [epoch: 5.72 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039962495409559		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.3039962495409559 | validation: 0.39791546327458593]
	TIME [epoch: 5.72 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29703119452137083		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.29703119452137083 | validation: 0.3720854875948868]
	TIME [epoch: 5.76 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2995290094706966		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.2995290094706966 | validation: 0.37066313365049297]
	TIME [epoch: 5.72 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32297243734685743		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.32297243734685743 | validation: 0.38442013452239737]
	TIME [epoch: 5.72 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2967261385282777		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.2967261385282777 | validation: 0.3791535006673988]
	TIME [epoch: 5.72 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30433409098132347		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.30433409098132347 | validation: 0.3699413164496448]
	TIME [epoch: 5.72 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3059281948511785		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.3059281948511785 | validation: 0.34199228309239293]
	TIME [epoch: 5.72 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2975896298116132		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.2975896298116132 | validation: 0.3551808633363781]
	TIME [epoch: 5.75 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30368315134970747		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.30368315134970747 | validation: 0.36535349258537836]
	TIME [epoch: 5.72 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29574267452728087		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.29574267452728087 | validation: 0.358694766518899]
	TIME [epoch: 5.72 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30127940878990217		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.30127940878990217 | validation: 0.39003835543571513]
	TIME [epoch: 5.72 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31155839075954883		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.31155839075954883 | validation: 0.367732404095139]
	TIME [epoch: 5.72 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3089991577658952		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.3089991577658952 | validation: 0.4827469943098889]
	TIME [epoch: 5.72 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32736358258562037		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.32736358258562037 | validation: 0.3672609210559598]
	TIME [epoch: 5.76 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3051674739796003		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.3051674739796003 | validation: 0.3832500629867097]
	TIME [epoch: 5.72 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29945294596382793		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.29945294596382793 | validation: 0.37274385966165713]
	TIME [epoch: 5.72 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3188103172541744		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.3188103172541744 | validation: 0.36143595910436943]
	TIME [epoch: 5.72 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3026577732126363		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.3026577732126363 | validation: 0.38115053974720303]
	TIME [epoch: 5.72 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2994348930461009		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.2994348930461009 | validation: 0.3905484314151758]
	TIME [epoch: 5.72 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3048224812095274		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.3048224812095274 | validation: 0.4241213516650551]
	TIME [epoch: 5.76 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3159539982455839		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.3159539982455839 | validation: 0.3622504228367325]
	TIME [epoch: 5.72 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29562580450396		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.29562580450396 | validation: 0.3758206896469827]
	TIME [epoch: 5.72 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29478591735210924		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.29478591735210924 | validation: 0.3589840076335467]
	TIME [epoch: 5.72 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3267131557399995		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.3267131557399995 | validation: 0.3946031578008007]
	TIME [epoch: 5.71 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3060485132792109		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.3060485132792109 | validation: 0.3634605043408889]
	TIME [epoch: 5.72 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2914386369353187		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.2914386369353187 | validation: 0.3574278938259909]
	TIME [epoch: 5.75 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29745240828912817		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.29745240828912817 | validation: 0.31931420019965084]
	TIME [epoch: 5.72 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30298198861789216		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.30298198861789216 | validation: 0.4156761957082546]
	TIME [epoch: 5.71 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30686945401447346		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.30686945401447346 | validation: 0.3560070855041815]
	TIME [epoch: 5.72 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29908803248347804		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.29908803248347804 | validation: 0.360491423046359]
	TIME [epoch: 5.72 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2931713751113847		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.2931713751113847 | validation: 0.37550644059423177]
	TIME [epoch: 5.72 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30163166769427174		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.30163166769427174 | validation: 0.3498690496981511]
	TIME [epoch: 5.75 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2963611909426738		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.2963611909426738 | validation: 0.3421565291744129]
	TIME [epoch: 5.72 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2890261096298923		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.2890261096298923 | validation: 0.34841378266969125]
	TIME [epoch: 5.71 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2951555799919116		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.2951555799919116 | validation: 0.3802850700228217]
	TIME [epoch: 5.71 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3126700018160207		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.3126700018160207 | validation: 0.3747097739424258]
	TIME [epoch: 5.71 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039945806287633		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.3039945806287633 | validation: 0.3516883703522376]
	TIME [epoch: 5.72 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2919062541323233		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.2919062541323233 | validation: 0.3683867111060959]
	TIME [epoch: 5.75 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32068056512858184		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.32068056512858184 | validation: 0.3983294485541869]
	TIME [epoch: 5.72 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3078630308153666		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.3078630308153666 | validation: 0.46613244584044544]
	TIME [epoch: 5.71 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30974101229761497		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.30974101229761497 | validation: 0.4022369820533192]
	TIME [epoch: 5.71 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.306357696757418		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.306357696757418 | validation: 0.3943000567172822]
	TIME [epoch: 5.71 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29369493050601847		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.29369493050601847 | validation: 0.3667241574095479]
	TIME [epoch: 5.72 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29934252017135005		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.29934252017135005 | validation: 0.34379519316898993]
	TIME [epoch: 5.75 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2940479516424316		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.2940479516424316 | validation: 0.35502534485068354]
	TIME [epoch: 5.71 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3024251232258708		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.3024251232258708 | validation: 0.33746897440779833]
	TIME [epoch: 5.71 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2942522346230275		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.2942522346230275 | validation: 0.35148989677819586]
	TIME [epoch: 5.72 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2857279785539073		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.2857279785539073 | validation: 0.32865439184023304]
	TIME [epoch: 5.71 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29135382501514284		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.29135382501514284 | validation: 0.33452812398085463]
	TIME [epoch: 5.71 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29175712206138454		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.29175712206138454 | validation: 0.3809136825177388]
	TIME [epoch: 5.75 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30349136547691946		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.30349136547691946 | validation: 0.369579645048445]
	TIME [epoch: 5.71 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3017619263569873		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.3017619263569873 | validation: 0.34803461579319656]
	TIME [epoch: 5.71 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3046822669595198		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.3046822669595198 | validation: 0.3493811447198895]
	TIME [epoch: 5.71 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2965604291085119		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.2965604291085119 | validation: 0.36731737911760226]
	TIME [epoch: 5.71 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3010368755413739		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.3010368755413739 | validation: 0.35048304437350297]
	TIME [epoch: 5.71 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2926505378952655		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.2926505378952655 | validation: 0.34718329046341595]
	TIME [epoch: 5.75 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29928812161526813		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.29928812161526813 | validation: 0.3581877088821533]
	TIME [epoch: 5.71 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2889887178549182		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.2889887178549182 | validation: 0.31241145236116835]
	TIME [epoch: 5.71 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2999886537129077		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.2999886537129077 | validation: 0.3136460820868313]
	TIME [epoch: 5.71 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30387422196247776		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.30387422196247776 | validation: 0.3340186392877939]
	TIME [epoch: 5.71 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28619543561273686		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.28619543561273686 | validation: 0.3520845486916396]
	TIME [epoch: 5.71 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28803400369624654		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.28803400369624654 | validation: 0.3192789654423705]
	TIME [epoch: 5.75 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3064229173146055		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.3064229173146055 | validation: 0.3323926044867781]
	TIME [epoch: 5.7 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.286211553303789		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.286211553303789 | validation: 0.34947330857077674]
	TIME [epoch: 5.7 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29757537739098555		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.29757537739098555 | validation: 0.33463160007021614]
	TIME [epoch: 5.7 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.292214478949942		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.292214478949942 | validation: 0.41072286821446385]
	TIME [epoch: 5.7 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31075662667772025		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.31075662667772025 | validation: 0.42747916135695174]
	TIME [epoch: 5.7 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29513041823267505		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.29513041823267505 | validation: 0.3999258885563847]
	TIME [epoch: 5.74 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31278477783078396		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.31278477783078396 | validation: 0.37555879642495876]
	TIME [epoch: 5.7 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29752855595512884		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.29752855595512884 | validation: 0.373929572859505]
	TIME [epoch: 5.7 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295230302022267		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.3295230302022267 | validation: 0.36823008210322916]
	TIME [epoch: 5.7 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29251857967284345		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.29251857967284345 | validation: 0.3648681030890413]
	TIME [epoch: 5.7 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29101781897114093		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.29101781897114093 | validation: 0.3834870762440366]
	TIME [epoch: 5.7 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2932110922717568		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.2932110922717568 | validation: 0.38673745087578054]
	TIME [epoch: 5.74 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3009537071189825		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.3009537071189825 | validation: 0.3646685320671977]
	TIME [epoch: 5.7 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2929520239310784		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.2929520239310784 | validation: 0.382976168201042]
	TIME [epoch: 5.7 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29335219334949036		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.29335219334949036 | validation: 0.3571215676554828]
	TIME [epoch: 5.7 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29722604054917606		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.29722604054917606 | validation: 0.3499406080653891]
	TIME [epoch: 5.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2993345189078836		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.2993345189078836 | validation: 0.35228753990298717]
	TIME [epoch: 5.7 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288531219517892		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.288531219517892 | validation: 0.3530282902332456]
	TIME [epoch: 5.73 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2941893915168069		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.2941893915168069 | validation: 0.33546417249340116]
	TIME [epoch: 5.7 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.295126985275437		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.295126985275437 | validation: 0.3761928904316869]
	TIME [epoch: 5.7 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29616873612877315		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.29616873612877315 | validation: 0.34674671478467267]
	TIME [epoch: 5.7 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31067446338747906		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.31067446338747906 | validation: 0.3624127099626546]
	TIME [epoch: 5.69 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2890257176233218		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.2890257176233218 | validation: 0.3570642184105245]
	TIME [epoch: 5.7 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2935095683026336		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.2935095683026336 | validation: 0.3309086139800743]
	TIME [epoch: 5.73 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29013715211869096		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.29013715211869096 | validation: 0.31617941704238667]
	TIME [epoch: 5.7 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29921402141631437		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.29921402141631437 | validation: 0.3097445234490818]
	TIME [epoch: 5.7 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28299012400268997		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.28299012400268997 | validation: 0.3572851214681492]
	TIME [epoch: 5.7 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943796564568714		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.2943796564568714 | validation: 0.32908061930745774]
	TIME [epoch: 5.7 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915455428036268		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.2915455428036268 | validation: 0.3405433109240892]
	TIME [epoch: 5.7 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29791402179930143		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.29791402179930143 | validation: 0.3664605343065979]
	TIME [epoch: 5.74 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30119723612760035		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.30119723612760035 | validation: 0.3723505671995103]
	TIME [epoch: 5.7 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093786728083285		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.3093786728083285 | validation: 0.3499439373190267]
	TIME [epoch: 5.7 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2951651459459599		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.2951651459459599 | validation: 0.3773644854040066]
	TIME [epoch: 5.7 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29421129102855625		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.29421129102855625 | validation: 0.31340846665096883]
	TIME [epoch: 5.72 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2902560880413207		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.2902560880413207 | validation: 0.3281238901215479]
	TIME [epoch: 5.7 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878282662520383		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.2878282662520383 | validation: 0.3467787856642043]
	TIME [epoch: 5.76 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29595853783478876		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.29595853783478876 | validation: 0.33131125238476006]
	TIME [epoch: 5.7 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3007040582450668		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.3007040582450668 | validation: 0.37100206767257277]
	TIME [epoch: 5.72 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966050252392214		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.2966050252392214 | validation: 0.3219908369006369]
	TIME [epoch: 5.71 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28960584088565416		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.28960584088565416 | validation: 0.3190708574845295]
	TIME [epoch: 5.7 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998700093150669		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.2998700093150669 | validation: 0.3203735964854333]
	TIME [epoch: 5.7 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29356078346120745		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.29356078346120745 | validation: 0.3346906530296638]
	TIME [epoch: 5.76 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285603258028995		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.285603258028995 | validation: 0.3507904561362689]
	TIME [epoch: 5.7 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29986162137278183		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.29986162137278183 | validation: 0.3669895175006232]
	TIME [epoch: 5.72 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038983341563626		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.3038983341563626 | validation: 0.3520219049758634]
	TIME [epoch: 5.71 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2989608668487178		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.2989608668487178 | validation: 0.3741913303212233]
	TIME [epoch: 5.69 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.296802727999065		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.296802727999065 | validation: 0.4195128038608029]
	TIME [epoch: 5.7 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2973824496741323		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.2973824496741323 | validation: 0.3868226096806158]
	TIME [epoch: 5.74 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2929753495876495		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.2929753495876495 | validation: 0.3835949877831192]
	TIME [epoch: 5.71 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28925334599014285		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.28925334599014285 | validation: 0.3977849555965385]
	TIME [epoch: 5.7 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2928201786054861		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.2928201786054861 | validation: 0.39780961778201473]
	TIME [epoch: 5.71 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28748395893171164		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.28748395893171164 | validation: 0.39369135235309727]
	TIME [epoch: 5.71 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29207718515137426		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.29207718515137426 | validation: 0.36400559495892154]
	TIME [epoch: 5.7 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29216467947869734		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.29216467947869734 | validation: 0.3862214271180303]
	TIME [epoch: 5.74 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998803318270396		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.2998803318270396 | validation: 0.4027404535189074]
	TIME [epoch: 5.72 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29531395543689964		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.29531395543689964 | validation: 0.3462167317195413]
	TIME [epoch: 5.7 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28547552119603725		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.28547552119603725 | validation: 0.36057158635176095]
	TIME [epoch: 5.7 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2914929821106791		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.2914929821106791 | validation: 0.33936034574937834]
	TIME [epoch: 5.71 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2906822126356923		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.2906822126356923 | validation: 0.3608835410096359]
	TIME [epoch: 5.71 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858299211222567		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.2858299211222567 | validation: 0.3730961961891766]
	TIME [epoch: 5.74 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29812061984805005		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.29812061984805005 | validation: 0.3970014703425702]
	TIME [epoch: 5.7 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29188579065660075		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.29188579065660075 | validation: 0.37435841889944427]
	TIME [epoch: 5.7 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853377319377483		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.2853377319377483 | validation: 0.35024152211999465]
	TIME [epoch: 5.7 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28940928842946		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.28940928842946 | validation: 0.3434506347933283]
	TIME [epoch: 5.7 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28947470219669025		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.28947470219669025 | validation: 0.36463122824001515]
	TIME [epoch: 5.7 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3075013426104342		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.3075013426104342 | validation: 0.358055140045317]
	TIME [epoch: 5.73 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071614340696449		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.3071614340696449 | validation: 0.30937636290412146]
	TIME [epoch: 5.71 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28935681140917197		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.28935681140917197 | validation: 0.33831898723747655]
	TIME [epoch: 5.7 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2908367943741087		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.2908367943741087 | validation: 0.34131507899828023]
	TIME [epoch: 5.7 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2918370535989309		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.2918370535989309 | validation: 0.3599678005421728]
	TIME [epoch: 5.71 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3083852690045936		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.3083852690045936 | validation: 0.3697275271081586]
	TIME [epoch: 5.71 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878487744096558		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.2878487744096558 | validation: 0.3592908717702575]
	TIME [epoch: 5.75 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29190321899622984		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.29190321899622984 | validation: 0.36612639275315906]
	TIME [epoch: 5.71 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29700457274348535		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.29700457274348535 | validation: 0.3354554703001128]
	TIME [epoch: 5.7 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2916419325513383		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.2916419325513383 | validation: 0.3265397995219182]
	TIME [epoch: 5.7 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2916291916375597		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.2916291916375597 | validation: 0.3597754983694407]
	TIME [epoch: 5.69 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29642754784131775		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.29642754784131775 | validation: 0.3504089385393336]
	TIME [epoch: 5.71 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2964941669683328		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.2964941669683328 | validation: 0.3462762004420945]
	TIME [epoch: 5.74 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30285128416144536		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.30285128416144536 | validation: 0.3385256148162708]
	TIME [epoch: 5.71 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29483715266841515		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.29483715266841515 | validation: 0.32087618790666805]
	TIME [epoch: 5.71 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29870124887663935		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.29870124887663935 | validation: 0.3403593462702206]
	TIME [epoch: 5.7 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2986482725235414		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.2986482725235414 | validation: 0.34994887295093674]
	TIME [epoch: 5.71 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2942162802176964		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.2942162802176964 | validation: 0.3509044134485953]
	TIME [epoch: 5.71 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29081333536284126		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.29081333536284126 | validation: 0.3477589541688]
	TIME [epoch: 5.73 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907687288222608		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.2907687288222608 | validation: 0.37736831220397166]
	TIME [epoch: 5.71 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28886295820148816		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.28886295820148816 | validation: 0.367930806751024]
	TIME [epoch: 5.69 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29432098979552374		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.29432098979552374 | validation: 0.3800863353207021]
	TIME [epoch: 5.71 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2899107499246784		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.2899107499246784 | validation: 0.3596072945238034]
	TIME [epoch: 5.69 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2815762875367443		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.2815762875367443 | validation: 0.35911356305909153]
	TIME [epoch: 5.7 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2927025532952696		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.2927025532952696 | validation: 0.36934426132523557]
	TIME [epoch: 5.73 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2900888161493885		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.2900888161493885 | validation: 0.37705024294220546]
	TIME [epoch: 5.7 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28507154013279556		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.28507154013279556 | validation: 0.35343674035484113]
	TIME [epoch: 5.71 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848437634855676		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.2848437634855676 | validation: 0.342655396011318]
	TIME [epoch: 5.71 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2819759481152783		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.2819759481152783 | validation: 0.33601662226047035]
	TIME [epoch: 5.71 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28928227956587677		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.28928227956587677 | validation: 0.31968085203051977]
	TIME [epoch: 5.71 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2867098743602775		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.2867098743602775 | validation: 0.36377175746381213]
	TIME [epoch: 5.73 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939376440772639		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.2939376440772639 | validation: 0.38082957093631165]
	TIME [epoch: 5.7 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29512621807185		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.29512621807185 | validation: 0.3701999752093961]
	TIME [epoch: 5.7 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2951125081842048		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.2951125081842048 | validation: 0.34850128503859557]
	TIME [epoch: 5.71 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2977595511365301		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.2977595511365301 | validation: 0.3394035898607606]
	TIME [epoch: 5.71 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3005517965500245		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.3005517965500245 | validation: 0.3316900000656755]
	TIME [epoch: 5.72 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28771674686110954		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.28771674686110954 | validation: 0.35518327077581474]
	TIME [epoch: 5.75 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2910576377388981		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.2910576377388981 | validation: 0.3051933864145508]
	TIME [epoch: 5.72 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2901200498445514		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.2901200498445514 | validation: 0.33521176580083184]
	TIME [epoch: 5.7 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30403153397355265		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.30403153397355265 | validation: 0.3402850221003888]
	TIME [epoch: 5.71 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29796053997705163		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.29796053997705163 | validation: 0.3174455745292525]
	TIME [epoch: 5.7 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2908272592576832		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.2908272592576832 | validation: 0.3373555139985824]
	TIME [epoch: 5.71 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29255121171612125		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.29255121171612125 | validation: 0.34359028226599014]
	TIME [epoch: 5.73 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28705036359353864		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.28705036359353864 | validation: 0.3886583299350278]
	TIME [epoch: 5.7 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2962078536384487		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.2962078536384487 | validation: 0.3358446162917926]
	TIME [epoch: 5.69 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28616917145268567		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.28616917145268567 | validation: 0.38205723382535073]
	TIME [epoch: 5.69 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2857659228249938		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.2857659228249938 | validation: 0.3544607185950289]
	TIME [epoch: 5.69 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28870881761301576		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.28870881761301576 | validation: 0.41070077487129]
	TIME [epoch: 5.69 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3055218713250624		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.3055218713250624 | validation: 0.38677371892424545]
	TIME [epoch: 5.73 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29185824773543906		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.29185824773543906 | validation: 0.343661617063312]
	TIME [epoch: 5.7 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2864550788182848		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.2864550788182848 | validation: 0.332781461928554]
	TIME [epoch: 5.7 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2938834290168897		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.2938834290168897 | validation: 0.3201896840196036]
	TIME [epoch: 5.71 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29201983765393696		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.29201983765393696 | validation: 0.33049949203105555]
	TIME [epoch: 5.71 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30025348715711564		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.30025348715711564 | validation: 0.31860483553701147]
	TIME [epoch: 5.71 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996564853581412		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.2996564853581412 | validation: 0.32840491281565926]
	TIME [epoch: 5.75 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.289749710975564		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.289749710975564 | validation: 0.35879418610515545]
	TIME [epoch: 5.71 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28499089405231776		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.28499089405231776 | validation: 0.33920093678473584]
	TIME [epoch: 5.72 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2894277347763137		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.2894277347763137 | validation: 0.34931703215119686]
	TIME [epoch: 5.7 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2882441381597301		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.2882441381597301 | validation: 0.32667437749240275]
	TIME [epoch: 5.71 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28512500027156895		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.28512500027156895 | validation: 0.34796091714499605]
	TIME [epoch: 5.71 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856000699980569		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.2856000699980569 | validation: 0.3558678524627116]
	TIME [epoch: 5.75 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2866289049314659		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.2866289049314659 | validation: 0.3854363976826038]
	TIME [epoch: 5.72 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28897491915648366		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.28897491915648366 | validation: 0.36210267909202815]
	TIME [epoch: 5.71 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28901399307583836		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.28901399307583836 | validation: 0.3643478663326553]
	TIME [epoch: 5.71 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28711637597542583		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.28711637597542583 | validation: 0.35108694253498757]
	TIME [epoch: 5.71 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2823668278346385		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.2823668278346385 | validation: 0.3368654178655528]
	TIME [epoch: 5.71 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2934685036312915		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.2934685036312915 | validation: 0.3375132953173447]
	TIME [epoch: 5.73 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28916200117858615		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.28916200117858615 | validation: 0.37424916180079704]
	TIME [epoch: 5.7 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29184735901842507		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.29184735901842507 | validation: 0.389405159316501]
	TIME [epoch: 5.7 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2883290796781047		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.2883290796781047 | validation: 0.40427016620216594]
	TIME [epoch: 5.7 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2903367017801353		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.2903367017801353 | validation: 0.3603945147634886]
	TIME [epoch: 5.7 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2838343383027746		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.2838343383027746 | validation: 0.35738672857203213]
	TIME [epoch: 5.7 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2820953813773087		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.2820953813773087 | validation: 0.36551788356768244]
	TIME [epoch: 5.74 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28154711518689046		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.28154711518689046 | validation: 0.3671693544189185]
	TIME [epoch: 5.7 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28655138776080585		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.28655138776080585 | validation: 0.35932992650349527]
	TIME [epoch: 5.7 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2870613845357094		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.2870613845357094 | validation: 0.3587127342560534]
	TIME [epoch: 5.71 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2819532729719522		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.2819532729719522 | validation: 0.3366432944630238]
	TIME [epoch: 5.69 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28790790999612814		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.28790790999612814 | validation: 0.3435274097730924]
	TIME [epoch: 5.7 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.294642855698753		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.294642855698753 | validation: 0.36051224748393784]
	TIME [epoch: 5.73 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2883663828876458		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.2883663828876458 | validation: 0.3602211586015852]
	TIME [epoch: 5.7 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2850669965286163		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.2850669965286163 | validation: 0.357885579305639]
	TIME [epoch: 5.69 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842289030206274		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.2842289030206274 | validation: 0.3305418109257867]
	TIME [epoch: 5.69 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3130570957186103		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.3130570957186103 | validation: 0.3389975800995033]
	TIME [epoch: 5.69 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848870082824973		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.2848870082824973 | validation: 0.343879656915307]
	TIME [epoch: 5.69 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28024542363222915		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.28024542363222915 | validation: 0.32917608633151463]
	TIME [epoch: 5.73 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28391797811222497		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.28391797811222497 | validation: 0.33307392379669765]
	TIME [epoch: 5.7 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28230124958044156		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.28230124958044156 | validation: 0.32156692620004207]
	TIME [epoch: 5.71 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28817323237170045		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.28817323237170045 | validation: 0.3408761601790919]
	TIME [epoch: 5.7 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28518216117128237		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.28518216117128237 | validation: 0.3318450922915499]
	TIME [epoch: 5.71 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29434171987069313		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.29434171987069313 | validation: 0.3580528840480291]
	TIME [epoch: 5.71 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2932761527718173		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.2932761527718173 | validation: 0.3268661534781295]
	TIME [epoch: 5.75 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2886540503700968		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.2886540503700968 | validation: 0.3770694047006856]
	TIME [epoch: 5.7 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29592320373088915		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.29592320373088915 | validation: 0.33892435165106116]
	TIME [epoch: 5.69 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.291074823268501		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.291074823268501 | validation: 0.3260220798705317]
	TIME [epoch: 5.69 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2818549194264119		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.2818549194264119 | validation: 0.3312839205649607]
	TIME [epoch: 5.69 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28903177995798623		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.28903177995798623 | validation: 0.34328458096466713]
	TIME [epoch: 5.7 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30536301154821155		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.30536301154821155 | validation: 0.3448018726343601]
	TIME [epoch: 5.73 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897442800919212		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.2897442800919212 | validation: 0.33745487789716394]
	TIME [epoch: 5.72 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2840340124881661		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.2840340124881661 | validation: 0.34929022833919915]
	TIME [epoch: 5.7 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28237216830399586		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.28237216830399586 | validation: 0.3318094228002272]
	TIME [epoch: 5.7 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2899112605709593		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.2899112605709593 | validation: 0.3343586112017522]
	TIME [epoch: 5.7 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2834958143182618		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.2834958143182618 | validation: 0.38213787112760733]
	TIME [epoch: 5.7 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.295761538104361		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.295761538104361 | validation: 0.3617567999509977]
	TIME [epoch: 5.74 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2835461062901061		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.2835461062901061 | validation: 0.33858757100677195]
	TIME [epoch: 5.7 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2882393121253158		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.2882393121253158 | validation: 0.35364486578094423]
	TIME [epoch: 5.71 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2921342427951277		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.2921342427951277 | validation: 0.37439393624729705]
	TIME [epoch: 5.71 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2794759418094118		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.2794759418094118 | validation: 0.36443654362882993]
	TIME [epoch: 5.71 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2872040865254678		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.2872040865254678 | validation: 0.37309351730133195]
	TIME [epoch: 5.71 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789909462960902		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.2789909462960902 | validation: 0.3450965786436867]
	TIME [epoch: 5.75 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285802001542931		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.285802001542931 | validation: 0.3741134983534511]
	TIME [epoch: 5.72 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2837979206067437		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.2837979206067437 | validation: 0.38214659621544583]
	TIME [epoch: 5.69 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822824898340627		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.2822824898340627 | validation: 0.3635541898893216]
	TIME [epoch: 5.69 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28547144108884515		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.28547144108884515 | validation: 0.33478646200095585]
	TIME [epoch: 5.69 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2767598174526263		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.2767598174526263 | validation: 0.35442397246703417]
	TIME [epoch: 5.7 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28390476511535023		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.28390476511535023 | validation: 0.35625649990377384]
	TIME [epoch: 5.72 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2772694366106281		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.2772694366106281 | validation: 0.3345201925303843]
	TIME [epoch: 5.71 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2841821867970463		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.2841821867970463 | validation: 0.3302745103821524]
	TIME [epoch: 5.7 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2787413713253224		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.2787413713253224 | validation: 0.31573172783234144]
	TIME [epoch: 5.69 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.289997531437242		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.289997531437242 | validation: 0.30856270137534303]
	TIME [epoch: 5.7 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2784021574184339		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.2784021574184339 | validation: 0.32748554759648]
	TIME [epoch: 5.71 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2916035166649773		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.2916035166649773 | validation: 0.34902728820335716]
	TIME [epoch: 5.74 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28956378613645345		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.28956378613645345 | validation: 0.3439949030010135]
	TIME [epoch: 5.72 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2830050347527611		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.2830050347527611 | validation: 0.34026955757111793]
	TIME [epoch: 5.71 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29035957968568515		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.29035957968568515 | validation: 0.33463853890634865]
	TIME [epoch: 5.71 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28580174941627695		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.28580174941627695 | validation: 0.3560521327480934]
	TIME [epoch: 5.71 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2873574795615432		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.2873574795615432 | validation: 0.3748385450462247]
	TIME [epoch: 5.71 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2965414661738851		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.2965414661738851 | validation: 0.34366738580733386]
	TIME [epoch: 5.74 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28645931129169916		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.28645931129169916 | validation: 0.34885768409830364]
	TIME [epoch: 5.72 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2796048659252629		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.2796048659252629 | validation: 0.35299887665089785]
	TIME [epoch: 5.71 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28491900551671523		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.28491900551671523 | validation: 0.33233924415446653]
	TIME [epoch: 5.71 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848409677391972		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.2848409677391972 | validation: 0.33899978741950676]
	TIME [epoch: 5.71 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2792564457552589		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.2792564457552589 | validation: 0.33730150981411994]
	TIME [epoch: 5.71 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28389107043450784		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.28389107043450784 | validation: 0.3214056298857512]
	TIME [epoch: 5.74 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853653520206096		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.2853653520206096 | validation: 0.32829922766896624]
	TIME [epoch: 5.7 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28341913420792314		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.28341913420792314 | validation: 0.3378065837369409]
	TIME [epoch: 5.69 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28606633376400603		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.28606633376400603 | validation: 0.3447316132903441]
	TIME [epoch: 5.71 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27855076443769816		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.27855076443769816 | validation: 0.33957513395133276]
	TIME [epoch: 5.71 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2909073389003687		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.2909073389003687 | validation: 0.34354205287416606]
	TIME [epoch: 5.71 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2827981325621351		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.2827981325621351 | validation: 0.3190948555475244]
	TIME [epoch: 5.74 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2850480909235699		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.2850480909235699 | validation: 0.34413643963678725]
	TIME [epoch: 5.72 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28190596331437456		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.28190596331437456 | validation: 0.3450718779131357]
	TIME [epoch: 5.71 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2781869763105364		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.2781869763105364 | validation: 0.33712926898791756]
	TIME [epoch: 5.71 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2864969836770197		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.2864969836770197 | validation: 0.3568661524162478]
	TIME [epoch: 5.71 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2852965219817335		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.2852965219817335 | validation: 0.3537654039084507]
	TIME [epoch: 5.71 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28420477288344564		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.28420477288344564 | validation: 0.36398377801200454]
	TIME [epoch: 5.74 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2895059700448221		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.2895059700448221 | validation: 0.3631742739007598]
	TIME [epoch: 5.72 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28275577369729943		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.28275577369729943 | validation: 0.37065850588900634]
	TIME [epoch: 5.71 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28302314419984315		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.28302314419984315 | validation: 0.37779744399159676]
	TIME [epoch: 5.7 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29161237802437495		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.29161237802437495 | validation: 0.37067974401457465]
	TIME [epoch: 5.7 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28547227208549353		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.28547227208549353 | validation: 0.3739371305441809]
	TIME [epoch: 5.7 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28406417354091495		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.28406417354091495 | validation: 0.3527769291026385]
	TIME [epoch: 5.72 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2875920548668158		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.2875920548668158 | validation: 0.3329888893959022]
	TIME [epoch: 5.72 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.281965106264493		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.281965106264493 | validation: 0.3402662610283919]
	TIME [epoch: 5.72 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.289625310094495		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.289625310094495 | validation: 0.38083617584472396]
	TIME [epoch: 5.71 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28606002359870114		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.28606002359870114 | validation: 0.34076921366728086]
	TIME [epoch: 5.71 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748381975132986		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.2748381975132986 | validation: 0.33757897021824335]
	TIME [epoch: 5.71 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28619444987437564		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.28619444987437564 | validation: 0.33444803546004237]
	TIME [epoch: 5.74 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821981817251694		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.2821981817251694 | validation: 0.337678653270511]
	TIME [epoch: 5.72 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28131812825086244		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.28131812825086244 | validation: 0.33771407710354223]
	TIME [epoch: 5.71 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28193434529527117		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.28193434529527117 | validation: 0.36406277369142337]
	TIME [epoch: 5.7 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28667376014960755		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.28667376014960755 | validation: 0.3599253642409303]
	TIME [epoch: 5.71 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2877899762827289		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.2877899762827289 | validation: 0.3545997102648626]
	TIME [epoch: 5.71 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28412727526534826		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.28412727526534826 | validation: 0.3550100139019435]
	TIME [epoch: 5.74 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28271654186981504		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.28271654186981504 | validation: 0.37161329869801424]
	TIME [epoch: 5.72 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2922836385994906		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.2922836385994906 | validation: 0.3784184497564293]
	TIME [epoch: 5.71 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2974815414778383		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.2974815414778383 | validation: 0.35294548606463055]
	TIME [epoch: 5.71 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3015788068204103		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.3015788068204103 | validation: 0.36204392426314497]
	TIME [epoch: 5.71 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29982874865132386		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.29982874865132386 | validation: 0.35609030338039366]
	TIME [epoch: 5.71 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28288349976575367		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.28288349976575367 | validation: 0.3522191774003525]
	TIME [epoch: 5.74 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28101256768070915		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.28101256768070915 | validation: 0.33174400560198586]
	TIME [epoch: 5.72 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2851504475648704		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.2851504475648704 | validation: 0.33194864183955786]
	TIME [epoch: 5.71 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27827563555132556		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.27827563555132556 | validation: 0.33999333415579297]
	TIME [epoch: 5.71 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2841929203185921		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.2841929203185921 | validation: 0.32705157148842545]
	TIME [epoch: 5.7 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28679201117411923		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.28679201117411923 | validation: 0.3229138989263097]
	TIME [epoch: 5.7 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2892104331988086		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.2892104331988086 | validation: 0.3279650917105101]
	TIME [epoch: 5.72 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29497703174572043		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.29497703174572043 | validation: 0.3359994878669552]
	TIME [epoch: 5.71 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28534836991748935		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.28534836991748935 | validation: 0.3294103062728418]
	TIME [epoch: 5.7 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.283066827044673		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.283066827044673 | validation: 0.3482435750323346]
	TIME [epoch: 5.71 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28533549493722404		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.28533549493722404 | validation: 0.34906670036363124]
	TIME [epoch: 5.69 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859686721339399		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.2859686721339399 | validation: 0.3425796775001757]
	TIME [epoch: 5.7 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2865214491841759		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.2865214491841759 | validation: 0.3397678240380341]
	TIME [epoch: 5.72 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2816958257879186		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.2816958257879186 | validation: 0.3436220577524425]
	TIME [epoch: 5.71 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790841966398019		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.2790841966398019 | validation: 0.33831257858303565]
	TIME [epoch: 5.7 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790442967705512		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.2790442967705512 | validation: 0.32142010863085363]
	TIME [epoch: 5.7 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822927997149514		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.2822927997149514 | validation: 0.33134830377064084]
	TIME [epoch: 5.71 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821367211462743		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.2821367211462743 | validation: 0.34272342638825676]
	TIME [epoch: 5.7 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2814715763491493		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.2814715763491493 | validation: 0.35761424840078854]
	TIME [epoch: 5.72 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2807430978453426		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.2807430978453426 | validation: 0.34403796360242195]
	TIME [epoch: 5.72 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27972491218290696		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.27972491218290696 | validation: 0.3401828141104534]
	TIME [epoch: 5.71 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2811164904600595		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.2811164904600595 | validation: 0.3370587906965505]
	TIME [epoch: 5.71 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28369916776992055		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.28369916776992055 | validation: 0.356747542238633]
	TIME [epoch: 5.7 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2909298347202526		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.2909298347202526 | validation: 0.37640536299185956]
	TIME [epoch: 5.7 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2837356334194172		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.2837356334194172 | validation: 0.39295802216078307]
	TIME [epoch: 5.73 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28640502944182034		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.28640502944182034 | validation: 0.35306345647299325]
	TIME [epoch: 5.71 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2851716468172606		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.2851716468172606 | validation: 0.35331961580205745]
	TIME [epoch: 5.72 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28031409193906287		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.28031409193906287 | validation: 0.3483583307347753]
	TIME [epoch: 5.7 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2797486318242571		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.2797486318242571 | validation: 0.3642326294653459]
	TIME [epoch: 5.71 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822816712587774		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.2822816712587774 | validation: 0.35400415280499015]
	TIME [epoch: 5.7 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842877452445519		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.2842877452445519 | validation: 0.34304323491938604]
	TIME [epoch: 5.72 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28802692926431667		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.28802692926431667 | validation: 0.34075208473814317]
	TIME [epoch: 5.72 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2813166336636318		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.2813166336636318 | validation: 0.35349083962207145]
	TIME [epoch: 5.71 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2912229026224076		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.2912229026224076 | validation: 0.33157049072804495]
	TIME [epoch: 5.69 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28087780929656325		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.28087780929656325 | validation: 0.35253856498368374]
	TIME [epoch: 5.71 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2831341209139613		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.2831341209139613 | validation: 0.33076080720569484]
	TIME [epoch: 5.7 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27686295735445754		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.27686295735445754 | validation: 0.3549181694085244]
	TIME [epoch: 5.72 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282754592710132		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.282754592710132 | validation: 0.37004318252749746]
	TIME [epoch: 5.71 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2816420078647134		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.2816420078647134 | validation: 0.3509770160640649]
	TIME [epoch: 5.7 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28029419120119714		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.28029419120119714 | validation: 0.3547881018031697]
	TIME [epoch: 5.69 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27859387457151913		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.27859387457151913 | validation: 0.34633285192731467]
	TIME [epoch: 5.69 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788607614471929		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.2788607614471929 | validation: 0.324293008370459]
	TIME [epoch: 5.71 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2781737811339799		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.2781737811339799 | validation: 0.3465645316322059]
	TIME [epoch: 5.72 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28773315345290484		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.28773315345290484 | validation: 0.3356918714716204]
	TIME [epoch: 5.71 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27767862480707023		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.27767862480707023 | validation: 0.35134553080430253]
	TIME [epoch: 5.72 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28324736384700094		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.28324736384700094 | validation: 0.33919583568407013]
	TIME [epoch: 5.69 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282650196532176		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.282650196532176 | validation: 0.35076273101026717]
	TIME [epoch: 5.71 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28119619863304834		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.28119619863304834 | validation: 0.3386487388467236]
	TIME [epoch: 5.7 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2843030764469823		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.2843030764469823 | validation: 0.35064751139373146]
	TIME [epoch: 5.73 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28220204770125124		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.28220204770125124 | validation: 0.34767579397487913]
	TIME [epoch: 5.73 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2841208335931445		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.2841208335931445 | validation: 0.3389018279359696]
	TIME [epoch: 5.71 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822768209550751		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.2822768209550751 | validation: 0.33761623789380907]
	TIME [epoch: 5.71 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28571006469089477		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.28571006469089477 | validation: 0.3327554244791577]
	TIME [epoch: 5.7 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766335493446929		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.2766335493446929 | validation: 0.34340348638985946]
	TIME [epoch: 5.7 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28205701924724524		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.28205701924724524 | validation: 0.3378592077012191]
	TIME [epoch: 5.73 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2829888795091312		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.2829888795091312 | validation: 0.33903099230868095]
	TIME [epoch: 5.71 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27417692532491733		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.27417692532491733 | validation: 0.362659736715113]
	TIME [epoch: 5.71 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27932417475633964		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.27932417475633964 | validation: 0.3529634587120468]
	TIME [epoch: 5.71 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2863558810072621		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.2863558810072621 | validation: 0.3477975791484216]
	TIME [epoch: 5.71 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2831510472610479		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.2831510472610479 | validation: 0.36125851488219723]
	TIME [epoch: 5.71 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28106812127909986		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.28106812127909986 | validation: 0.3461711105072366]
	TIME [epoch: 5.72 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28336718543647377		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.28336718543647377 | validation: 0.3438261199785792]
	TIME [epoch: 5.71 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788951637639316		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.2788951637639316 | validation: 0.35497461026572014]
	TIME [epoch: 5.71 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28786746152340226		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.28786746152340226 | validation: 0.35329799693196245]
	TIME [epoch: 5.7 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2888678885254795		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.2888678885254795 | validation: 0.337703423922849]
	TIME [epoch: 5.7 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853343164675713		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.2853343164675713 | validation: 0.35399760575699346]
	TIME [epoch: 5.69 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28361669146763396		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.28361669146763396 | validation: 0.35987408746149785]
	TIME [epoch: 5.73 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766039523823215		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.2766039523823215 | validation: 0.358683887100405]
	TIME [epoch: 5.71 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.281176924057908		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.281176924057908 | validation: 0.3746344353634732]
	TIME [epoch: 5.71 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2792499568721213		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.2792499568721213 | validation: 0.36686141987188764]
	TIME [epoch: 5.69 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2774199778045049		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.2774199778045049 | validation: 0.3376480661067433]
	TIME [epoch: 5.7 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802129441891253		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.2802129441891253 | validation: 0.3558283559215118]
	TIME [epoch: 5.71 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2832702824436627		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.2832702824436627 | validation: 0.3067895562512745]
	TIME [epoch: 5.72 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2860631043559947		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.2860631043559947 | validation: 0.32442408517944205]
	TIME [epoch: 5.71 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27634066458073714		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.27634066458073714 | validation: 0.32247343967383557]
	TIME [epoch: 5.71 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274893274232913		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.274893274232913 | validation: 0.3277330458032789]
	TIME [epoch: 5.71 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28348570308427		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.28348570308427 | validation: 0.3147661031346082]
	TIME [epoch: 5.7 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28119548219347024		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.28119548219347024 | validation: 0.33121009868066464]
	TIME [epoch: 5.71 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.281472569354415		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.281472569354415 | validation: 0.3306726843110947]
	TIME [epoch: 5.73 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2784459165137814		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.2784459165137814 | validation: 0.34239760018223236]
	TIME [epoch: 5.72 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802564592888538		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.2802564592888538 | validation: 0.332166540510375]
	TIME [epoch: 5.71 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.281649163247246		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.281649163247246 | validation: 0.32108140454653994]
	TIME [epoch: 5.7 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2814834172889088		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.2814834172889088 | validation: 0.3409771327245788]
	TIME [epoch: 5.71 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28271908903173554		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.28271908903173554 | validation: 0.32983598177952916]
	TIME [epoch: 5.71 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27988991630641746		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.27988991630641746 | validation: 0.33380426674215335]
	TIME [epoch: 5.73 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28292537610067436		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.28292537610067436 | validation: 0.35339993469707465]
	TIME [epoch: 5.72 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2867161903434808		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.2867161903434808 | validation: 0.32131055300889805]
	TIME [epoch: 5.7 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2799460275614038		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.2799460275614038 | validation: 0.3404513989818963]
	TIME [epoch: 5.69 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28177493960558275		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.28177493960558275 | validation: 0.32701480883182527]
	TIME [epoch: 5.7 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28144907645913403		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.28144907645913403 | validation: 0.32688614291579704]
	TIME [epoch: 5.69 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2867027163704187		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.2867027163704187 | validation: 0.3305547921860374]
	TIME [epoch: 5.72 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27850163330752675		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.27850163330752675 | validation: 0.32813335598834054]
	TIME [epoch: 5.71 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.279100017614974		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.279100017614974 | validation: 0.3420639911444428]
	TIME [epoch: 5.7 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785101928726422		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.2785101928726422 | validation: 0.3413124707019717]
	TIME [epoch: 5.7 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28641779597708505		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.28641779597708505 | validation: 0.33426601490283586]
	TIME [epoch: 5.7 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2772560203924108		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.2772560203924108 | validation: 0.3444839817827425]
	TIME [epoch: 5.7 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.281180063158619		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.281180063158619 | validation: 0.3420893267726065]
	TIME [epoch: 5.73 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2840530178823201		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.2840530178823201 | validation: 0.3669071419596947]
	TIME [epoch: 5.72 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2837463300021431		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.2837463300021431 | validation: 0.3680603720369313]
	TIME [epoch: 5.7 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.281118289553563		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.281118289553563 | validation: 0.3553116610454618]
	TIME [epoch: 5.7 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27767143370784475		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.27767143370784475 | validation: 0.34987853370539035]
	TIME [epoch: 5.69 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27363813403319426		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.27363813403319426 | validation: 0.3469201287031594]
	TIME [epoch: 5.7 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2808843827982077		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.2808843827982077 | validation: 0.3343985229142455]
	TIME [epoch: 5.73 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28493963749395934		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.28493963749395934 | validation: 0.3399521914430006]
	TIME [epoch: 5.73 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28229263314830444		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.28229263314830444 | validation: 0.3298771158236054]
	TIME [epoch: 5.7 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789330478879212		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.2789330478879212 | validation: 0.3324564522934611]
	TIME [epoch: 5.71 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27820793682107386		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.27820793682107386 | validation: 0.3312625160083509]
	TIME [epoch: 5.7 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28224031407738226		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.28224031407738226 | validation: 0.34140262810347877]
	TIME [epoch: 5.69 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28477859164212616		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.28477859164212616 | validation: 0.3488997962515627]
	TIME [epoch: 5.73 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2798425778348179		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.2798425778348179 | validation: 0.3490401019318027]
	TIME [epoch: 5.72 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28175241255607897		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.28175241255607897 | validation: 0.331022726215907]
	TIME [epoch: 5.7 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27732469399481957		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.27732469399481957 | validation: 0.34960063203023056]
	TIME [epoch: 5.7 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2765613483709358		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.2765613483709358 | validation: 0.3476969092898355]
	TIME [epoch: 5.7 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27610582617089563		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.27610582617089563 | validation: 0.3137914229403576]
	TIME [epoch: 5.7 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27879268322155215		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.27879268322155215 | validation: 0.32631508238152407]
	TIME [epoch: 5.73 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28287368451144884		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.28287368451144884 | validation: 0.33829843339716564]
	TIME [epoch: 5.71 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28382087184677046		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.28382087184677046 | validation: 0.33762692689418705]
	TIME [epoch: 5.7 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.278705037373796		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.278705037373796 | validation: 0.33593909245923587]
	TIME [epoch: 5.7 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789683519745557		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.2789683519745557 | validation: 0.3552264310645864]
	TIME [epoch: 5.7 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2833375689410783		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.2833375689410783 | validation: 0.3513962912940397]
	TIME [epoch: 5.7 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27707472092287533		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.27707472092287533 | validation: 0.34304298407799794]
	TIME [epoch: 5.74 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27870813960564134		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.27870813960564134 | validation: 0.3482641095020293]
	TIME [epoch: 5.72 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2827489358702666		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.2827489358702666 | validation: 0.3704473152431861]
	TIME [epoch: 5.7 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.281571340684427		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.281571340684427 | validation: 0.33003090589511064]
	TIME [epoch: 5.71 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2762686761236992		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.2762686761236992 | validation: 0.3246349171945582]
	TIME [epoch: 5.7 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2810779347289082		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.2810779347289082 | validation: 0.32850721047535253]
	TIME [epoch: 5.7 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27653261089456654		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.27653261089456654 | validation: 0.34124681998151646]
	TIME [epoch: 5.73 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27860983409158957		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.27860983409158957 | validation: 0.3332792885348124]
	TIME [epoch: 5.71 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28036805017687405		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.28036805017687405 | validation: 0.3175945517153002]
	TIME [epoch: 5.71 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27990738685556105		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.27990738685556105 | validation: 0.32343056833084893]
	TIME [epoch: 5.71 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28287724627778976		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.28287724627778976 | validation: 0.3193569280386284]
	TIME [epoch: 5.71 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2828149060925604		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.2828149060925604 | validation: 0.32562027890829565]
	TIME [epoch: 5.7 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2752260770585196		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.2752260770585196 | validation: 0.3292923440752707]
	TIME [epoch: 5.74 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27934990949849015		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.27934990949849015 | validation: 0.33687380100252384]
	TIME [epoch: 5.71 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2794949795655939		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.2794949795655939 | validation: 0.33005946154227855]
	TIME [epoch: 5.71 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27554769441460003		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.27554769441460003 | validation: 0.3301959439280862]
	TIME [epoch: 5.7 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788788179640923		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.2788788179640923 | validation: 0.3304802719249987]
	TIME [epoch: 5.7 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2798965535596444		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.2798965535596444 | validation: 0.32966006302566025]
	TIME [epoch: 5.7 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27715472981546846		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.27715472981546846 | validation: 0.3341802882146658]
	TIME [epoch: 5.73 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274189625922237		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.274189625922237 | validation: 0.32056495743128366]
	TIME [epoch: 5.72 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285864237585133		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.285864237585133 | validation: 0.32731211252678244]
	TIME [epoch: 5.71 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285471386419994		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.285471386419994 | validation: 0.3215902690960364]
	TIME [epoch: 5.7 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770098241666064		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.2770098241666064 | validation: 0.322032280545949]
	TIME [epoch: 5.71 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28600061190870446		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.28600061190870446 | validation: 0.3169252535833621]
	TIME [epoch: 5.7 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.281247660675465		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.281247660675465 | validation: 0.3279941290858791]
	TIME [epoch: 5.74 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2816185510179559		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.2816185510179559 | validation: 0.3330990561226429]
	TIME [epoch: 5.72 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.276879977131525		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.276879977131525 | validation: 0.32096086874944235]
	TIME [epoch: 5.71 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27625243974159724		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.27625243974159724 | validation: 0.3282274689256389]
	TIME [epoch: 5.71 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2749932056877612		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.2749932056877612 | validation: 0.32744975254496905]
	TIME [epoch: 5.7 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27407283043363345		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.27407283043363345 | validation: 0.33953052206393]
	TIME [epoch: 5.71 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2801493738526446		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.2801493738526446 | validation: 0.34172091598720555]
	TIME [epoch: 5.73 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28095474854289126		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.28095474854289126 | validation: 0.3502412442757938]
	TIME [epoch: 5.73 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28743033826117925		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.28743033826117925 | validation: 0.3319106313514962]
	TIME [epoch: 5.72 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28706178823866946		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.28706178823866946 | validation: 0.32329568563430755]
	TIME [epoch: 5.71 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28577348352983445		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.28577348352983445 | validation: 0.3092097349171367]
	TIME [epoch: 5.71 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28139968352730726		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.28139968352730726 | validation: 0.3331734355041665]
	TIME [epoch: 5.71 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27928506082811666		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.27928506082811666 | validation: 0.3397807479956074]
	TIME [epoch: 5.74 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27474080049769667		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.27474080049769667 | validation: 0.3238791487560676]
	TIME [epoch: 5.71 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764902268423818		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.2764902268423818 | validation: 0.32397040966089286]
	TIME [epoch: 5.71 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2767779456737306		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.2767779456737306 | validation: 0.3217867471169257]
	TIME [epoch: 5.71 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2792815460196209		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.2792815460196209 | validation: 0.3225501147892419]
	TIME [epoch: 5.7 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27556807942220085		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.27556807942220085 | validation: 0.33956772773991006]
	TIME [epoch: 5.71 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27667274530300556		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.27667274530300556 | validation: 0.34335657848211126]
	TIME [epoch: 5.73 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28315671721405633		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.28315671721405633 | validation: 0.3198775826794843]
	TIME [epoch: 5.73 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2796638094967367		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.2796638094967367 | validation: 0.3278093988200505]
	TIME [epoch: 5.7 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2812441755364632		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.2812441755364632 | validation: 0.33054527709352455]
	TIME [epoch: 5.71 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27542809276195157		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.27542809276195157 | validation: 0.33719612641368146]
	TIME [epoch: 5.7 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27559110811626697		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.27559110811626697 | validation: 0.33433580855582873]
	TIME [epoch: 5.71 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2816603849359085		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.2816603849359085 | validation: 0.30669593549906926]
	TIME [epoch: 5.73 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2807073953885717		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.2807073953885717 | validation: 0.33377061196351626]
	TIME [epoch: 5.71 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802276992451262		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.2802276992451262 | validation: 0.3436302907851166]
	TIME [epoch: 5.71 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2838377424080822		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.2838377424080822 | validation: 0.3278244332211537]
	TIME [epoch: 5.69 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2751558361119795		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.2751558361119795 | validation: 0.3223475671303866]
	TIME [epoch: 5.71 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2797437621092632		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.2797437621092632 | validation: 0.33973344439286174]
	TIME [epoch: 5.7 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27740772146396		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.27740772146396 | validation: 0.3185390485683057]
	TIME [epoch: 5.73 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2746359265477913		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.2746359265477913 | validation: 0.341258634919712]
	TIME [epoch: 5.72 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27953947226277587		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.27953947226277587 | validation: 0.3286786705909869]
	TIME [epoch: 5.71 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2793461143436545		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.2793461143436545 | validation: 0.31786263948234106]
	TIME [epoch: 5.71 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2786738671403427		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.2786738671403427 | validation: 0.3452510635606106]
	TIME [epoch: 5.71 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2805071112618367		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.2805071112618367 | validation: 0.3458155917692112]
	TIME [epoch: 5.69 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28104637052314485		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.28104637052314485 | validation: 0.31192675709517165]
	TIME [epoch: 5.73 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853484749020395		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.2853484749020395 | validation: 0.3168849489307583]
	TIME [epoch: 5.71 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27578814757891273		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.27578814757891273 | validation: 0.3326733333278421]
	TIME [epoch: 5.71 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747652572899734		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.2747652572899734 | validation: 0.3294268089317785]
	TIME [epoch: 5.7 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27960685116549633		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.27960685116549633 | validation: 0.34711576654898224]
	TIME [epoch: 5.7 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2817777928216128		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.2817777928216128 | validation: 0.35628682876798123]
	TIME [epoch: 5.71 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2803702618990625		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.2803702618990625 | validation: 0.35215948416945764]
	TIME [epoch: 5.73 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2815131726652184		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.2815131726652184 | validation: 0.3355644350957715]
	TIME [epoch: 5.71 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2810314747761755		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.2810314747761755 | validation: 0.32557024107081556]
	TIME [epoch: 5.7 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27687297452264487		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.27687297452264487 | validation: 0.3417944539295107]
	TIME [epoch: 5.7 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27750633503989214		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.27750633503989214 | validation: 0.3358247952623632]
	TIME [epoch: 5.69 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27790089902775167		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.27790089902775167 | validation: 0.3247188640680511]
	TIME [epoch: 5.7 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2732567016249106		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.2732567016249106 | validation: 0.33487548741384204]
	TIME [epoch: 5.74 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27412811959984673		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.27412811959984673 | validation: 0.32641840101548736]
	TIME [epoch: 5.72 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28207589497951174		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.28207589497951174 | validation: 0.3337692879560504]
	TIME [epoch: 5.71 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27640493246114467		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.27640493246114467 | validation: 0.3347964518205566]
	TIME [epoch: 5.7 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27685101092783443		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.27685101092783443 | validation: 0.34236652014090907]
	TIME [epoch: 5.7 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2749844873960849		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.2749844873960849 | validation: 0.3389337047220566]
	TIME [epoch: 5.69 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.280459085563419		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.280459085563419 | validation: 0.3501951671872793]
	TIME [epoch: 5.74 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28061835399542434		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.28061835399542434 | validation: 0.3553620857064057]
	TIME [epoch: 5.71 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2767552823328321		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.2767552823328321 | validation: 0.33080234137294523]
	TIME [epoch: 5.71 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27732660594665964		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.27732660594665964 | validation: 0.34153437827364413]
	TIME [epoch: 5.7 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802064940754084		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.2802064940754084 | validation: 0.3550022624429325]
	TIME [epoch: 5.7 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27514898460259346		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.27514898460259346 | validation: 0.3397503176534523]
	TIME [epoch: 5.69 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2765445434295096		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.2765445434295096 | validation: 0.3494224886457242]
	TIME [epoch: 5.73 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27740592353701704		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.27740592353701704 | validation: 0.3185533016269991]
	TIME [epoch: 5.71 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27531007592117374		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.27531007592117374 | validation: 0.32533436209697364]
	TIME [epoch: 5.69 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27755560890743813		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.27755560890743813 | validation: 0.3404886451888066]
	TIME [epoch: 5.7 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27678316660687086		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.27678316660687086 | validation: 0.33780446729056857]
	TIME [epoch: 5.71 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.280941756864363		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.280941756864363 | validation: 0.3441633723925125]
	TIME [epoch: 5.7 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770669939684143		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.2770669939684143 | validation: 0.34912010975520735]
	TIME [epoch: 5.74 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768093376673268		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.2768093376673268 | validation: 0.34372829883547457]
	TIME [epoch: 5.71 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2847572777517788		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.2847572777517788 | validation: 0.3366789080029028]
	TIME [epoch: 5.7 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28032400756258513		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.28032400756258513 | validation: 0.3364516436860334]
	TIME [epoch: 5.7 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28188295935580765		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.28188295935580765 | validation: 0.3468541996414841]
	TIME [epoch: 5.7 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27634235310284383		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.27634235310284383 | validation: 0.34878627225439796]
	TIME [epoch: 5.7 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.284424653238591		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.284424653238591 | validation: 0.3493238417131643]
	TIME [epoch: 5.74 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28155775946711864		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.28155775946711864 | validation: 0.346761766619464]
	TIME [epoch: 5.72 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28161563186297167		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.28161563186297167 | validation: 0.34571626873369554]
	TIME [epoch: 5.71 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719007147152285		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.2719007147152285 | validation: 0.33739120699763303]
	TIME [epoch: 5.7 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766016954719752		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.2766016954719752 | validation: 0.347488069772121]
	TIME [epoch: 5.71 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2757761052686865		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.2757761052686865 | validation: 0.3558842322331747]
	TIME [epoch: 5.71 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27797038811833813		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.27797038811833813 | validation: 0.3664836767801351]
	TIME [epoch: 5.74 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2817319344497604		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.2817319344497604 | validation: 0.35220639889997724]
	TIME [epoch: 5.71 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27950676942841507		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.27950676942841507 | validation: 0.35122895811165655]
	TIME [epoch: 5.71 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28039034673707286		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.28039034673707286 | validation: 0.34255027699745133]
	TIME [epoch: 5.7 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2812043718725586		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.2812043718725586 | validation: 0.3302230188944835]
	TIME [epoch: 5.69 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28044037434926317		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.28044037434926317 | validation: 0.3357147722142888]
	TIME [epoch: 5.71 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2759738452374915		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.2759738452374915 | validation: 0.33856623553357806]
	TIME [epoch: 5.74 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2769476994742903		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.2769476994742903 | validation: 0.33779227018785213]
	TIME [epoch: 5.72 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27650411434514927		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.27650411434514927 | validation: 0.3459472222807078]
	TIME [epoch: 5.71 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2796280470603341		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.2796280470603341 | validation: 0.3396470965357837]
	TIME [epoch: 5.72 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27981958708112376		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.27981958708112376 | validation: 0.3345998404625321]
	TIME [epoch: 5.71 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27530520740211917		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.27530520740211917 | validation: 0.3361544891578618]
	TIME [epoch: 5.7 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27900860878090195		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.27900860878090195 | validation: 0.34530379142175305]
	TIME [epoch: 5.74 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27524272759297363		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.27524272759297363 | validation: 0.3333980804310653]
	TIME [epoch: 5.71 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27492826511430385		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.27492826511430385 | validation: 0.33415184243586976]
	TIME [epoch: 5.7 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27982607463165565		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.27982607463165565 | validation: 0.3227792657780633]
	TIME [epoch: 5.71 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28008474216005436		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.28008474216005436 | validation: 0.3212943231380546]
	TIME [epoch: 5.71 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27876674504617605		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.27876674504617605 | validation: 0.33275556472181295]
	TIME [epoch: 5.69 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28096491340902807		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.28096491340902807 | validation: 0.3227661179367917]
	TIME [epoch: 5.74 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27384752221151015		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.27384752221151015 | validation: 0.3252663125879704]
	TIME [epoch: 5.71 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2811823842931767		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.2811823842931767 | validation: 0.3370141321052064]
	TIME [epoch: 5.7 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789553202426908		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.2789553202426908 | validation: 0.31522946486973885]
	TIME [epoch: 5.71 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28464684148443364		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.28464684148443364 | validation: 0.3454818230955412]
	TIME [epoch: 5.71 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.284815246573138		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.284815246573138 | validation: 0.3486238125549902]
	TIME [epoch: 5.69 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28855220602631826		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.28855220602631826 | validation: 0.3602591659514006]
	TIME [epoch: 5.71 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27959575371003764		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.27959575371003764 | validation: 0.3447835689796449]
	TIME [epoch: 5.73 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27887259684263366		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.27887259684263366 | validation: 0.3448810036983025]
	TIME [epoch: 5.7 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27740312033394116		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.27740312033394116 | validation: 0.325311010073747]
	TIME [epoch: 5.7 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2803434768020006		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.2803434768020006 | validation: 0.33949349679785534]
	TIME [epoch: 5.7 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27650539257809603		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.27650539257809603 | validation: 0.32790587851633385]
	TIME [epoch: 5.69 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739736033482445		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.2739736033482445 | validation: 0.3322785225978844]
	TIME [epoch: 5.71 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745951359721178		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.2745951359721178 | validation: 0.32113918943105313]
	TIME [epoch: 5.72 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27694682779325996		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.27694682779325996 | validation: 0.31985920855166816]
	TIME [epoch: 5.69 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768709054071166		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.2768709054071166 | validation: 0.3223429474023433]
	TIME [epoch: 5.71 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2795953994190889		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.2795953994190889 | validation: 0.34057194267259716]
	TIME [epoch: 5.7 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2757691817627477		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.2757691817627477 | validation: 0.35199074119521323]
	TIME [epoch: 5.71 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27395544861170457		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.27395544861170457 | validation: 0.3342344334715411]
	TIME [epoch: 5.71 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856287944182609		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.2856287944182609 | validation: 0.32461282153240834]
	TIME [epoch: 5.72 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2767052792690586		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.2767052792690586 | validation: 0.3275376448081326]
	TIME [epoch: 5.7 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27907654799779225		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.27907654799779225 | validation: 0.3328040107845925]
	TIME [epoch: 5.7 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27836513502436167		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.27836513502436167 | validation: 0.3299203448617951]
	TIME [epoch: 5.69 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783767700115433		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.2783767700115433 | validation: 0.3269182312175164]
	TIME [epoch: 5.7 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2804266733152889		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.2804266733152889 | validation: 0.3262622421194121]
	TIME [epoch: 5.71 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27444292739011095		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.27444292739011095 | validation: 0.33753891301918854]
	TIME [epoch: 5.72 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28242421075558904		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.28242421075558904 | validation: 0.3337200526847361]
	TIME [epoch: 5.69 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27695685105633944		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.27695685105633944 | validation: 0.32316889668959725]
	TIME [epoch: 5.69 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27534838387803867		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.27534838387803867 | validation: 0.3306723854780095]
	TIME [epoch: 5.69 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2797416624162331		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.2797416624162331 | validation: 0.3223680335164164]
	TIME [epoch: 5.7 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768401200913547		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.2768401200913547 | validation: 0.3243988981440704]
	TIME [epoch: 5.72 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2775778027601934		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.2775778027601934 | validation: 0.326698597095773]
	TIME [epoch: 5.72 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27408361538830406		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.27408361538830406 | validation: 0.32412756662039555]
	TIME [epoch: 5.69 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748852410487536		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.2748852410487536 | validation: 0.3446834402631073]
	TIME [epoch: 5.69 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27757156213023976		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.27757156213023976 | validation: 0.3378783016674927]
	TIME [epoch: 5.71 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27874106674092536		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.27874106674092536 | validation: 0.33936520561662187]
	TIME [epoch: 5.71 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2811178489235296		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.2811178489235296 | validation: 0.3421260143420824]
	TIME [epoch: 5.71 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2792925333081852		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.2792925333081852 | validation: 0.3422173394791595]
	TIME [epoch: 5.72 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2723845055677283		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.2723845055677283 | validation: 0.3307151223517443]
	TIME [epoch: 5.71 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2742080494534132		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.2742080494534132 | validation: 0.33963350543443]
	TIME [epoch: 5.69 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2797963089258173		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.2797963089258173 | validation: 0.3415712522230311]
	TIME [epoch: 5.69 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27417732500087033		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.27417732500087033 | validation: 0.351630646445411]
	TIME [epoch: 5.69 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27719411586006837		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.27719411586006837 | validation: 0.3512107282617425]
	TIME [epoch: 5.7 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2807563706454873		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.2807563706454873 | validation: 0.32429008530902564]
	TIME [epoch: 5.72 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782513441326493		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.2782513441326493 | validation: 0.3370011949263352]
	TIME [epoch: 5.7 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2737427901363772		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.2737427901363772 | validation: 0.3247915889274322]
	TIME [epoch: 5.7 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2762832259122796		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.2762832259122796 | validation: 0.32413158114662777]
	TIME [epoch: 5.69 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282403657897843		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.282403657897843 | validation: 0.31849368243735987]
	TIME [epoch: 5.69 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821133016164322		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.2821133016164322 | validation: 0.3451524210021427]
	TIME [epoch: 5.7 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27453664226515606		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.27453664226515606 | validation: 0.335044610316603]
	TIME [epoch: 5.72 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703662425588608		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.2703662425588608 | validation: 0.3376333154855415]
	TIME [epoch: 5.69 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2784833436316676		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.2784833436316676 | validation: 0.34153110328608255]
	TIME [epoch: 5.69 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27721422331998075		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.27721422331998075 | validation: 0.34311795375723775]
	TIME [epoch: 5.69 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.276783591645004		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.276783591645004 | validation: 0.34626939917494043]
	TIME [epoch: 5.69 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756046319139305		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.2756046319139305 | validation: 0.341454831618146]
	TIME [epoch: 5.7 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27653374460143415		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.27653374460143415 | validation: 0.3467513731464152]
	TIME [epoch: 5.72 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.276593531823777		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.276593531823777 | validation: 0.32723580124855645]
	TIME [epoch: 5.69 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27737351491128237		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.27737351491128237 | validation: 0.3324104893868239]
	TIME [epoch: 5.69 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27466090811323024		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.27466090811323024 | validation: 0.3321991996994658]
	TIME [epoch: 5.69 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748301671315163		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.2748301671315163 | validation: 0.33801305312067315]
	TIME [epoch: 5.69 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27601414015680625		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.27601414015680625 | validation: 0.3306180478199169]
	TIME [epoch: 5.7 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28011464395285335		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.28011464395285335 | validation: 0.336234445402793]
	TIME [epoch: 5.72 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.272567435042684		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.272567435042684 | validation: 0.335770855871007]
	TIME [epoch: 5.69 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2757179796974441		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.2757179796974441 | validation: 0.33129916601323955]
	TIME [epoch: 5.69 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2773455136001676		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.2773455136001676 | validation: 0.33700685764197646]
	TIME [epoch: 5.69 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27709546249790007		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.27709546249790007 | validation: 0.3445752382457632]
	TIME [epoch: 5.69 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27958480910414774		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.27958480910414774 | validation: 0.33503455499157014]
	TIME [epoch: 5.7 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27736010390048993		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.27736010390048993 | validation: 0.34448349057789357]
	TIME [epoch: 5.72 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748808374368764		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.2748808374368764 | validation: 0.33234958410698484]
	TIME [epoch: 5.69 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2724855189262501		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.2724855189262501 | validation: 0.3370149714144665]
	TIME [epoch: 5.69 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27827404955949053		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.27827404955949053 | validation: 0.33723830064829713]
	TIME [epoch: 5.69 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27966952539091416		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.27966952539091416 | validation: 0.33301709188432754]
	TIME [epoch: 5.69 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747148474999677		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.2747148474999677 | validation: 0.3483844846996106]
	TIME [epoch: 5.7 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27945385986636034		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.27945385986636034 | validation: 0.33801128872960695]
	TIME [epoch: 5.72 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788741174521111		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.2788741174521111 | validation: 0.3429508458606512]
	TIME [epoch: 5.69 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2772659431308648		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.2772659431308648 | validation: 0.34981458466113485]
	TIME [epoch: 5.69 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2843302822815939		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.2843302822815939 | validation: 0.34941637210659693]
	TIME [epoch: 5.69 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27219517419776357		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.27219517419776357 | validation: 0.33761560323324047]
	TIME [epoch: 5.69 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27723714262298677		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.27723714262298677 | validation: 0.3297650022776395]
	TIME [epoch: 5.7 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2786739044589742		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.2786739044589742 | validation: 0.35089075571623535]
	TIME [epoch: 5.73 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27848334994029683		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.27848334994029683 | validation: 0.3555827446116311]
	TIME [epoch: 5.71 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27671242705641824		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.27671242705641824 | validation: 0.35686191879957263]
	TIME [epoch: 5.71 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764064134423841		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.2764064134423841 | validation: 0.3389179922296148]
	TIME [epoch: 5.71 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770214068824601		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.2770214068824601 | validation: 0.3476544779325188]
	TIME [epoch: 5.71 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770740742373974		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.2770740742373974 | validation: 0.34532509106570336]
	TIME [epoch: 5.72 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2754814042949153		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.2754814042949153 | validation: 0.3334983541419845]
	TIME [epoch: 5.73 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27624162359267634		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.27624162359267634 | validation: 0.33627190398320567]
	TIME [epoch: 5.71 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770189566378674		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.2770189566378674 | validation: 0.3321591220041165]
	TIME [epoch: 5.71 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2738693829348425		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.2738693829348425 | validation: 0.3378554321260066]
	TIME [epoch: 5.7 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745584190957464		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.2745584190957464 | validation: 0.3272745541412133]
	TIME [epoch: 5.71 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28104004351326006		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.28104004351326006 | validation: 0.3224986519135558]
	TIME [epoch: 5.72 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.275528887365162		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.275528887365162 | validation: 0.3223457990774082]
	TIME [epoch: 5.74 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.273609729169068		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.273609729169068 | validation: 0.32060653973134406]
	TIME [epoch: 5.71 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27904737136324975		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.27904737136324975 | validation: 0.3370697606120932]
	TIME [epoch: 5.71 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733766005145913		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.2733766005145913 | validation: 0.3286678345674618]
	TIME [epoch: 5.71 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2762004841880865		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.2762004841880865 | validation: 0.33734245825180337]
	TIME [epoch: 5.71 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27384018358235274		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.27384018358235274 | validation: 0.34713032165345964]
	TIME [epoch: 5.72 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27793438390590863		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.27793438390590863 | validation: 0.34435365739469886]
	TIME [epoch: 5.74 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27821179035709664		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.27821179035709664 | validation: 0.3242940509110594]
	TIME [epoch: 5.71 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771176617319238		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.2771176617319238 | validation: 0.32315405494186317]
	TIME [epoch: 5.71 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28000101265355914		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.28000101265355914 | validation: 0.31845213669467975]
	TIME [epoch: 5.71 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.276396753647976		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.276396753647976 | validation: 0.3253489784899692]
	TIME [epoch: 5.71 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27628817069347356		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.27628817069347356 | validation: 0.32576835623250683]
	TIME [epoch: 5.73 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27304447700983875		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.27304447700983875 | validation: 0.3211288198697899]
	TIME [epoch: 5.74 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2752538147664814		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.2752538147664814 | validation: 0.3152284176989321]
	TIME [epoch: 5.71 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.276083412415114		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.276083412415114 | validation: 0.31966910967294104]
	TIME [epoch: 5.71 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27634583282598324		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.27634583282598324 | validation: 0.3263055786727126]
	TIME [epoch: 5.71 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27585960004094884		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.27585960004094884 | validation: 0.31722747861679657]
	TIME [epoch: 5.71 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27406960228960486		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.27406960228960486 | validation: 0.3306022315809801]
	TIME [epoch: 5.72 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2759725589818923		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.2759725589818923 | validation: 0.3173908297390849]
	TIME [epoch: 5.74 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27386251489211616		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.27386251489211616 | validation: 0.32258025372597815]
	TIME [epoch: 5.7 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27217175842305075		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.27217175842305075 | validation: 0.31664606288364966]
	TIME [epoch: 5.71 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2729395771872785		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.2729395771872785 | validation: 0.31571479022604926]
	TIME [epoch: 5.71 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27495698523369916		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.27495698523369916 | validation: 0.32203695720330283]
	TIME [epoch: 5.71 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745757679982251		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.2745757679982251 | validation: 0.32233549108444154]
	TIME [epoch: 5.72 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27502861984691035		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.27502861984691035 | validation: 0.3107315139361901]
	TIME [epoch: 5.73 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27617529045890904		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.27617529045890904 | validation: 0.3228993663369769]
	TIME [epoch: 5.71 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2708123367340244		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.2708123367340244 | validation: 0.3167998234115074]
	TIME [epoch: 5.69 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2798546441047025		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.2798546441047025 | validation: 0.3331348368633699]
	TIME [epoch: 5.71 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27489580843188877		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.27489580843188877 | validation: 0.3275909520938113]
	TIME [epoch: 5.7 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768705992708673		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.2768705992708673 | validation: 0.3346476201026984]
	TIME [epoch: 5.72 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2738095841219962		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.2738095841219962 | validation: 0.3279838691546648]
	TIME [epoch: 5.73 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758133768013752		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.2758133768013752 | validation: 0.3134298078617768]
	TIME [epoch: 5.7 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27631513637231797		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.27631513637231797 | validation: 0.3229354842516191]
	TIME [epoch: 5.7 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27795069309655296		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.27795069309655296 | validation: 0.32521281465357876]
	TIME [epoch: 5.71 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2743251331746243		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.2743251331746243 | validation: 0.32065938524930515]
	TIME [epoch: 5.7 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.275589200038371		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.275589200038371 | validation: 0.32733036307908786]
	TIME [epoch: 5.72 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2744868289167877		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.2744868289167877 | validation: 0.32609503860022343]
	TIME [epoch: 5.72 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27444259848274477		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.27444259848274477 | validation: 0.32444042793617867]
	TIME [epoch: 5.71 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27635648080151076		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.27635648080151076 | validation: 0.32571878515027664]
	TIME [epoch: 5.7 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782770220418383		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.2782770220418383 | validation: 0.32760084460402283]
	TIME [epoch: 5.71 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2753152047466832		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.2753152047466832 | validation: 0.32081725034589786]
	TIME [epoch: 5.71 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27924639118603534		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.27924639118603534 | validation: 0.32687122213420233]
	TIME [epoch: 5.72 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27216386794682207		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.27216386794682207 | validation: 0.3134734322980786]
	TIME [epoch: 5.73 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766252002987939		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.2766252002987939 | validation: 0.32537313489102715]
	TIME [epoch: 5.71 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27531956789333356		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.27531956789333356 | validation: 0.33575711208087256]
	TIME [epoch: 5.7 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758409049152219		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.2758409049152219 | validation: 0.33097202401331105]
	TIME [epoch: 5.7 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2711848958020907		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.2711848958020907 | validation: 0.32279867592442385]
	TIME [epoch: 5.71 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28148381387327176		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.28148381387327176 | validation: 0.3254834155747059]
	TIME [epoch: 5.72 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2769208271745022		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.2769208271745022 | validation: 0.32529231739735814]
	TIME [epoch: 5.73 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745068016006531		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.2745068016006531 | validation: 0.3250114027708796]
	TIME [epoch: 5.71 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821565785792877		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.2821565785792877 | validation: 0.3303246822320777]
	TIME [epoch: 5.7 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27840114433660157		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.27840114433660157 | validation: 0.3498539406622401]
	TIME [epoch: 5.7 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27792129901335616		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.27792129901335616 | validation: 0.3311084390544052]
	TIME [epoch: 5.71 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2784889570242146		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.2784889570242146 | validation: 0.327297409441305]
	TIME [epoch: 5.71 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28010020692166493		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.28010020692166493 | validation: 0.34111480125046156]
	TIME [epoch: 5.74 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2800980324326529		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.2800980324326529 | validation: 0.33318633540751164]
	TIME [epoch: 5.69 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2743763195072409		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.2743763195072409 | validation: 0.3285735418499292]
	TIME [epoch: 5.7 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2750646048867313		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.2750646048867313 | validation: 0.3270706127903752]
	TIME [epoch: 5.71 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2759636998132567		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.2759636998132567 | validation: 0.3169784235736319]
	TIME [epoch: 5.7 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27114873528435735		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.27114873528435735 | validation: 0.3403406312788738]
	TIME [epoch: 5.7 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766725027362681		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.2766725027362681 | validation: 0.32958954867631124]
	TIME [epoch: 5.72 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27508646782869145		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.27508646782869145 | validation: 0.3250084658915791]
	TIME [epoch: 5.69 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27462657809413443		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.27462657809413443 | validation: 0.32009491001382434]
	TIME [epoch: 5.7 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740994434775868		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.2740994434775868 | validation: 0.32888116863391703]
	TIME [epoch: 5.71 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2725277710646176		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.2725277710646176 | validation: 0.3342791504745344]
	TIME [epoch: 5.7 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771641739056946		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.2771641739056946 | validation: 0.3404877144809732]
	TIME [epoch: 5.72 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27537280035438894		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.27537280035438894 | validation: 0.3386273168573217]
	TIME [epoch: 5.72 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27154203007918604		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.27154203007918604 | validation: 0.33828430743818344]
	TIME [epoch: 5.71 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2726891034000264		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.2726891034000264 | validation: 0.3320322586813157]
	TIME [epoch: 5.69 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2779613825327093		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.2779613825327093 | validation: 0.32475433884078564]
	TIME [epoch: 5.69 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778698079733534		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.2778698079733534 | validation: 0.3427494472489028]
	TIME [epoch: 5.7 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2751887678353533		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.2751887678353533 | validation: 0.3271032707704549]
	TIME [epoch: 5.71 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26885519067969155		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.26885519067969155 | validation: 0.3247751575881883]
	TIME [epoch: 5.72 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27530585250895484		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.27530585250895484 | validation: 0.3277949654359633]
	TIME [epoch: 5.69 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28040507996117114		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.28040507996117114 | validation: 0.32001880129266785]
	TIME [epoch: 5.7 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733024806094069		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.2733024806094069 | validation: 0.323815421150883]
	TIME [epoch: 5.69 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27970645689806395		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.27970645689806395 | validation: 0.3231159564254179]
	TIME [epoch: 5.7 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770670342394843		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.2770670342394843 | validation: 0.32539414550259155]
	TIME [epoch: 5.71 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27835031654804554		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.27835031654804554 | validation: 0.3286413772994597]
	TIME [epoch: 5.71 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27246058365991427		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.27246058365991427 | validation: 0.33784742728529865]
	TIME [epoch: 5.69 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27691780092349927		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.27691780092349927 | validation: 0.3245626366426428]
	TIME [epoch: 5.69 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2757322702512658		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.2757322702512658 | validation: 0.32761641846833967]
	TIME [epoch: 5.69 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2759409932879973		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.2759409932879973 | validation: 0.33963144649197335]
	TIME [epoch: 5.69 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2723952690987453		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.2723952690987453 | validation: 0.32782925648094724]
	TIME [epoch: 5.71 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748527865690709		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.2748527865690709 | validation: 0.33771620803172125]
	TIME [epoch: 5.72 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745657607100516		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.2745657607100516 | validation: 0.3209589983419909]
	TIME [epoch: 5.7 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747173287201691		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.2747173287201691 | validation: 0.3389272098989818]
	TIME [epoch: 5.69 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2759499151250665		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.2759499151250665 | validation: 0.33760411785159683]
	TIME [epoch: 5.71 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2761658884757451		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.2761658884757451 | validation: 0.3331032244165428]
	TIME [epoch: 5.71 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27237590926946026		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.27237590926946026 | validation: 0.327365004675157]
	TIME [epoch: 5.71 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2732409094051896		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.2732409094051896 | validation: 0.324329865177693]
	TIME [epoch: 5.74 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2729899136740902		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.2729899136740902 | validation: 0.31451481155892713]
	TIME [epoch: 5.7 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783887168574303		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.2783887168574303 | validation: 0.3302459934939182]
	TIME [epoch: 5.71 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2751869778273534		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.2751869778273534 | validation: 0.3179959325349153]
	TIME [epoch: 5.69 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2738328026591184		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.2738328026591184 | validation: 0.3247549511210105]
	TIME [epoch: 5.7 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27296433954740495		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.27296433954740495 | validation: 0.3233752744045579]
	TIME [epoch: 5.71 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739494389960091		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.2739494389960091 | validation: 0.3285486772699548]
	TIME [epoch: 5.72 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2773805272214489		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.2773805272214489 | validation: 0.32812025408254436]
	TIME [epoch: 5.71 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2780764375535259		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.2780764375535259 | validation: 0.3198782574294926]
	TIME [epoch: 5.71 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747204593591714		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.2747204593591714 | validation: 0.323521249625295]
	TIME [epoch: 5.71 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27385977052878474		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.27385977052878474 | validation: 0.32892201471928656]
	TIME [epoch: 5.71 sec]
Finished training in 11624.022 seconds.
