Args:
Namespace(name='model_tr_study201', outdir='out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1', training_data='data/transition_rate_studies/tr_study201/tr_study201_training/r1', validation_data='data/transition_rate_studies/tr_study201/tr_study201_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2693132481

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.255386907091374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.255386907091374 | validation: 11.20283649940895]
	TIME [epoch: 91.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.774895303091633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.774895303091633 | validation: 12.663521977264223]
	TIME [epoch: 5.76 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.066467054539986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.066467054539986 | validation: 9.593219442976823]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.248853991201333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.248853991201333 | validation: 6.69277765525781]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.757183131339552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.757183131339552 | validation: 5.408762973821082]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.122067415620071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.122067415620071 | validation: 4.8975039437546135]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.658617563764813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.658617563764813 | validation: 4.724611623283718]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.829366134680324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.829366134680324 | validation: 5.404038357452753]
	TIME [epoch: 5.76 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.149917286948148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.149917286948148 | validation: 3.712133564755648]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.889692458127302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.889692458127302 | validation: 3.534662755261922]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525689619303137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.525689619303137 | validation: 3.4576418444997876]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.74871198527865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.74871198527865 | validation: 3.4243687224032255]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.773992744830906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.773992744830906 | validation: 3.242645476474212]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.283844188290944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.283844188290944 | validation: 2.980057015143358]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.165936031487789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.165936031487789 | validation: 4.570375009890809]
	TIME [epoch: 5.73 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3645871047628795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3645871047628795 | validation: 3.9543531245044345]
	TIME [epoch: 5.72 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3595070305997865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3595070305997865 | validation: 3.3793054883994667]
	TIME [epoch: 5.72 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.049663222964577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.049663222964577 | validation: 2.687100181273425]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.033802863772018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.033802863772018 | validation: 3.302333756117375]
	TIME [epoch: 5.72 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.017471215150334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.017471215150334 | validation: 3.1984172980469565]
	TIME [epoch: 5.74 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.023951729775035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.023951729775035 | validation: 2.915337220887029]
	TIME [epoch: 5.72 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.775473614849971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.775473614849971 | validation: 2.4781733404542563]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.224501748175743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.224501748175743 | validation: 2.711357820366039]
	TIME [epoch: 5.72 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9780055536082504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9780055536082504 | validation: 2.651067748456676]
	TIME [epoch: 5.71 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8489363562875973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8489363562875973 | validation: 2.5364171858180447]
	TIME [epoch: 5.71 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8166907938039807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8166907938039807 | validation: 2.7467774129460056]
	TIME [epoch: 5.72 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.84164514224981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.84164514224981 | validation: 2.7254249486325772]
	TIME [epoch: 5.74 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.722643642672395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.722643642672395 | validation: 2.753936717211865]
	TIME [epoch: 5.72 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7285716830640667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7285716830640667 | validation: 3.1428403877148936]
	TIME [epoch: 5.71 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.720209375483466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.720209375483466 | validation: 2.32155637230531]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7857408193801736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7857408193801736 | validation: 2.6610948402548993]
	TIME [epoch: 5.71 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6579799010717213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6579799010717213 | validation: 2.9415966177744433]
	TIME [epoch: 5.72 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.945814127945316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.945814127945316 | validation: 2.457375832921344]
	TIME [epoch: 5.75 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3029049847039946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3029049847039946 | validation: 3.48934526524023]
	TIME [epoch: 5.71 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7484317747074236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7484317747074236 | validation: 2.393332894937741]
	TIME [epoch: 5.72 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.564293937195757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.564293937195757 | validation: 3.7640906778291536]
	TIME [epoch: 5.71 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7961059055257227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7961059055257227 | validation: 2.5088093078643445]
	TIME [epoch: 5.71 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.607653314902076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.607653314902076 | validation: 2.3014358987725023]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6913545082494914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6913545082494914 | validation: 2.326572488892457]
	TIME [epoch: 5.76 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.403643533334466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.403643533334466 | validation: 2.408846045262101]
	TIME [epoch: 5.72 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3443788315335863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3443788315335863 | validation: 3.0206240454229145]
	TIME [epoch: 5.72 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5649984454170713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5649984454170713 | validation: 2.378090395974532]
	TIME [epoch: 5.71 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.428784342951559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.428784342951559 | validation: 2.2569191097218426]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.501533783929504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.501533783929504 | validation: 2.2457115363138307]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3665598164492456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3665598164492456 | validation: 2.307708365013374]
	TIME [epoch: 5.75 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4084866005978363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4084866005978363 | validation: 1.9699449462785217]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39986599118211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.39986599118211 | validation: 2.5753293610633357]
	TIME [epoch: 5.71 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3457651469611007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3457651469611007 | validation: 2.753518694797769]
	TIME [epoch: 5.7 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2112814074606852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2112814074606852 | validation: 2.467782433135419]
	TIME [epoch: 5.7 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.565479700993277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.565479700993277 | validation: 3.647793459312725]
	TIME [epoch: 5.7 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5729272756838757		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.5729272756838757 | validation: 2.390857317620724]
	TIME [epoch: 5.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3677069164900795		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.3677069164900795 | validation: 2.613015349307012]
	TIME [epoch: 5.74 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.349784461990039		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.349784461990039 | validation: 2.330207960854608]
	TIME [epoch: 5.7 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.730442120014959		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.730442120014959 | validation: 1.8435756753054993]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0704510535151535		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.0704510535151535 | validation: 2.239464899100665]
	TIME [epoch: 5.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.61588356778711		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.61588356778711 | validation: 4.237831625724582]
	TIME [epoch: 5.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5279626652825113		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.5279626652825113 | validation: 2.9530134043649]
	TIME [epoch: 5.7 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.359588632889281		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.359588632889281 | validation: 2.280658031194924]
	TIME [epoch: 5.73 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2613397569394773		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.2613397569394773 | validation: 1.8275879153641412]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.17494656920379		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.17494656920379 | validation: 2.144829189136438]
	TIME [epoch: 5.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208482078530152		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.208482078530152 | validation: 2.218705511224613]
	TIME [epoch: 5.7 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9981008255120223		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.9981008255120223 | validation: 2.0175399741547055]
	TIME [epoch: 5.7 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.173452086985071		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.173452086985071 | validation: 2.991317497611273]
	TIME [epoch: 5.7 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.255988063205722		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.255988063205722 | validation: 1.8580246037055355]
	TIME [epoch: 5.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.272615092686072		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.272615092686072 | validation: 2.6784040354508343]
	TIME [epoch: 5.74 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.140023296823603		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.140023296823603 | validation: 2.975055460737347]
	TIME [epoch: 5.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3756590200623524		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.3756590200623524 | validation: 3.615983970863277]
	TIME [epoch: 5.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.395960609259814		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.395960609259814 | validation: 2.3329936871819674]
	TIME [epoch: 5.7 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0884386982850387		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.0884386982850387 | validation: 2.0788452525513295]
	TIME [epoch: 5.7 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.275486476623828		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.275486476623828 | validation: 3.78880276035557]
	TIME [epoch: 5.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.388840823772849		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.388840823772849 | validation: 2.12387579249236]
	TIME [epoch: 5.73 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2192135935575297		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.2192135935575297 | validation: 2.189185065063768]
	TIME [epoch: 5.71 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1099786205204616		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.1099786205204616 | validation: 1.9996784494518955]
	TIME [epoch: 5.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.980297900204433		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.980297900204433 | validation: 1.7108272666647475]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.206629841233442		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.206629841233442 | validation: 2.332361241549398]
	TIME [epoch: 5.71 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.35815590027641		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.35815590027641 | validation: 2.1733740912841095]
	TIME [epoch: 5.71 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9230454277444493		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.9230454277444493 | validation: 1.774597290001745]
	TIME [epoch: 5.71 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8690181822587055		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.8690181822587055 | validation: 1.7946262804617292]
	TIME [epoch: 5.75 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.232217934136314		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.232217934136314 | validation: 1.828570196794029]
	TIME [epoch: 5.72 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.05774827565771		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.05774827565771 | validation: 1.7489060720987357]
	TIME [epoch: 5.71 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9581126043066774		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.9581126043066774 | validation: 1.8479265760490626]
	TIME [epoch: 5.71 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9731347565237005		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.9731347565237005 | validation: 1.6486610430086288]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9199182706462117		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.9199182706462117 | validation: 2.040508783700925]
	TIME [epoch: 5.71 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9306232549977658		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.9306232549977658 | validation: 2.063636207932289]
	TIME [epoch: 5.75 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.895063136133417		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.895063136133417 | validation: 2.608634033187599]
	TIME [epoch: 5.73 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.001861641475445		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.001861641475445 | validation: 1.7511076250734605]
	TIME [epoch: 5.71 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6687903321445474		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.6687903321445474 | validation: 1.6575079251639766]
	TIME [epoch: 5.71 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.06182188640536		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.06182188640536 | validation: 1.7116951956088304]
	TIME [epoch: 5.71 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.834871921533065		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.834871921533065 | validation: 1.946023416351527]
	TIME [epoch: 5.71 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0744771596325635		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.0744771596325635 | validation: 2.966326269580666]
	TIME [epoch: 5.71 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.408134403162772		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.408134403162772 | validation: 1.9510937522585199]
	TIME [epoch: 5.76 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.811481252602945		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.811481252602945 | validation: 1.2864434900722146]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8205674942981505		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.8205674942981505 | validation: 2.7355286450836354]
	TIME [epoch: 5.72 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.451086752787802		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.451086752787802 | validation: 1.749777955368751]
	TIME [epoch: 5.71 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.792973665400303		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.792973665400303 | validation: 1.7065475421749403]
	TIME [epoch: 5.71 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.814361032465391		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.814361032465391 | validation: 2.357044643051708]
	TIME [epoch: 5.71 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7071605071307046		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.7071605071307046 | validation: 1.7618948695378924]
	TIME [epoch: 5.76 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7438923027197903		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.7438923027197903 | validation: 2.112088109974157]
	TIME [epoch: 5.72 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.362701276930883		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.362701276930883 | validation: 1.7048223434376226]
	TIME [epoch: 5.71 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.035045718215162		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.035045718215162 | validation: 1.4792159242073972]
	TIME [epoch: 5.71 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7595155540979945		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.7595155540979945 | validation: 1.816741369918513]
	TIME [epoch: 5.71 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7970126752907665		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.7970126752907665 | validation: 1.874575102674686]
	TIME [epoch: 5.71 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.734573867766161		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.734573867766161 | validation: 1.8086379337520913]
	TIME [epoch: 5.72 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7312889077082056		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.7312889077082056 | validation: 1.8184545582707707]
	TIME [epoch: 5.74 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7370484845356025		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.7370484845356025 | validation: 2.0651047021361975]
	TIME [epoch: 5.72 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.87654859150038		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.87654859150038 | validation: 1.7092244282791154]
	TIME [epoch: 5.71 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.741652149633296		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.741652149633296 | validation: 1.3137038042982772]
	TIME [epoch: 5.72 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.672931849601121		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.672931849601121 | validation: 1.4417642494627705]
	TIME [epoch: 5.71 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0349332088985186		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.0349332088985186 | validation: 1.2442021125407625]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0262580077421792		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.0262580077421792 | validation: 1.388404500554413]
	TIME [epoch: 5.77 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.751949115358739		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.751949115358739 | validation: 1.4377263274102519]
	TIME [epoch: 5.73 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301494543072955		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.301494543072955 | validation: 3.1502469572560177]
	TIME [epoch: 5.72 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7154069144005915		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.7154069144005915 | validation: 2.307461027983381]
	TIME [epoch: 5.71 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.697584498551877		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.697584498551877 | validation: 1.616209566462266]
	TIME [epoch: 5.71 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1439018490473933		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.1439018490473933 | validation: 2.658145445624869]
	TIME [epoch: 5.71 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.418803881655455		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.418803881655455 | validation: 1.4703055474799336]
	TIME [epoch: 5.72 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7536396353516386		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.7536396353516386 | validation: 1.705601687382565]
	TIME [epoch: 5.74 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8880915199685937		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.8880915199685937 | validation: 1.5473817674225507]
	TIME [epoch: 5.71 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.953875397115362		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.953875397115362 | validation: 1.1848073580631246]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7405435840291046		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.7405435840291046 | validation: 2.5755439594620584]
	TIME [epoch: 5.71 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059145766311559		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.059145766311559 | validation: 1.5262275418936713]
	TIME [epoch: 5.72 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9430020355768753		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.9430020355768753 | validation: 1.2483863823898358]
	TIME [epoch: 5.71 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8371344027051995		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.8371344027051995 | validation: 1.1785867452065577]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9448429472066477		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.9448429472066477 | validation: 1.7477975841117097]
	TIME [epoch: 5.72 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6834436576022311		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.6834436576022311 | validation: 1.4097760264565316]
	TIME [epoch: 5.72 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8184154106620738		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.8184154106620738 | validation: 1.5432180901423107]
	TIME [epoch: 5.71 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7628241060785521		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.7628241060785521 | validation: 1.4053802157257838]
	TIME [epoch: 5.71 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6587313887953665		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.6587313887953665 | validation: 1.1051809649225057]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.375920158095309		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.375920158095309 | validation: 1.017504792271233]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0260513929959654		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.0260513929959654 | validation: 0.996669033363672]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9562280139012291		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.9562280139012291 | validation: 1.3055952292150466]
	TIME [epoch: 5.71 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5671889524953295		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.5671889524953295 | validation: 1.6264853776357968]
	TIME [epoch: 5.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.707003704173691		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.707003704173691 | validation: 1.8558208332520292]
	TIME [epoch: 5.7 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5651294235590298		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.5651294235590298 | validation: 1.2923155662447632]
	TIME [epoch: 5.7 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6398677331971818		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.6398677331971818 | validation: 1.308769054405362]
	TIME [epoch: 5.72 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5819187982970315		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.5819187982970315 | validation: 1.7365762051538949]
	TIME [epoch: 5.73 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6895584861201807		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.6895584861201807 | validation: 1.4788488728436098]
	TIME [epoch: 5.71 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.603612959107832		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.603612959107832 | validation: 1.542852825763481]
	TIME [epoch: 5.7 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6681841724474147		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.6681841724474147 | validation: 1.0324183930121758]
	TIME [epoch: 5.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5129785339312436		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.5129785339312436 | validation: 1.0697358161672597]
	TIME [epoch: 5.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.374367143601304		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.374367143601304 | validation: 1.3472320965733662]
	TIME [epoch: 5.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6643573067757242		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.6643573067757242 | validation: 1.9338048034909645]
	TIME [epoch: 5.73 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7688231186847982		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.7688231186847982 | validation: 2.6579362814152545]
	TIME [epoch: 5.72 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.86790493399754		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.86790493399754 | validation: 3.375564263201634]
	TIME [epoch: 5.71 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.206750760369367		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.206750760369367 | validation: 0.9536045963830597]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8122808557978458		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.8122808557978458 | validation: 1.3448607903436531]
	TIME [epoch: 5.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5277538202593552		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.5277538202593552 | validation: 2.017069702963185]
	TIME [epoch: 5.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.751744501841713		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.751744501841713 | validation: 1.0193127385913359]
	TIME [epoch: 5.72 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3847255204219318		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.3847255204219318 | validation: 1.2482032488437962]
	TIME [epoch: 5.73 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.524573156917		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.524573156917 | validation: 1.3996753179481454]
	TIME [epoch: 5.72 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3826517806751402		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.3826517806751402 | validation: 2.799337022629401]
	TIME [epoch: 5.71 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7452658767898617		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.7452658767898617 | validation: 1.1381728892920049]
	TIME [epoch: 5.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4942562861836346		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.4942562861836346 | validation: 1.1304212965742273]
	TIME [epoch: 5.71 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5145753511155304		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.5145753511155304 | validation: 1.2372318266433053]
	TIME [epoch: 5.71 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5415547537357117		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.5415547537357117 | validation: 1.6115944669614346]
	TIME [epoch: 5.74 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5494584302908097		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.5494584302908097 | validation: 0.7854146356921381]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.448912972545852		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.448912972545852 | validation: 0.9894014832300385]
	TIME [epoch: 5.71 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.497797244014578		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.497797244014578 | validation: 0.875100396814055]
	TIME [epoch: 5.71 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4524621306776542		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.4524621306776542 | validation: 0.959631011631807]
	TIME [epoch: 5.72 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3651052185826127		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.3651052185826127 | validation: 1.371685955021689]
	TIME [epoch: 5.71 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4053490519253737		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.4053490519253737 | validation: 1.2540224756754774]
	TIME [epoch: 5.71 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3474009445755248		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.3474009445755248 | validation: 1.3449165591963432]
	TIME [epoch: 5.73 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5574140700310286		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.5574140700310286 | validation: 0.9378231855956021]
	TIME [epoch: 5.71 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.591926163526416		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.591926163526416 | validation: 1.401530550396708]
	TIME [epoch: 5.71 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3893703709900664		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.3893703709900664 | validation: 1.549233065822541]
	TIME [epoch: 5.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4075359867964814		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.4075359867964814 | validation: 1.2205025259307574]
	TIME [epoch: 5.71 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3965560868128333		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.3965560868128333 | validation: 1.5123996468895866]
	TIME [epoch: 5.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4533922877447663		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.4533922877447663 | validation: 1.2783449613261488]
	TIME [epoch: 5.74 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.30436704870083		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.30436704870083 | validation: 1.3197506422697802]
	TIME [epoch: 5.71 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4485749629800333		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.4485749629800333 | validation: 0.6944572850105328]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.884279440025661		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.884279440025661 | validation: 1.2009962978435809]
	TIME [epoch: 5.74 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3794875608614088		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.3794875608614088 | validation: 0.8388910770077062]
	TIME [epoch: 5.71 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.450360516936643		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.450360516936643 | validation: 0.914608571905133]
	TIME [epoch: 5.72 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5418205099366546		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.5418205099366546 | validation: 0.7256907925525082]
	TIME [epoch: 5.72 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.267910413451107		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.267910413451107 | validation: 0.6775682491671262]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7872125972806985		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.7872125972806985 | validation: 0.6719225704361875]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5741234098803165		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.5741234098803165 | validation: 0.9328479867299362]
	TIME [epoch: 5.72 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3463273665062412		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.3463273665062412 | validation: 2.244780172228854]
	TIME [epoch: 5.71 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.569456709980722		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.569456709980722 | validation: 1.6688372694272147]
	TIME [epoch: 5.71 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.450148302472233		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.450148302472233 | validation: 0.8805613218367626]
	TIME [epoch: 5.72 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2974436743665474		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.2974436743665474 | validation: 0.7857086015304617]
	TIME [epoch: 5.75 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1425655583018126		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.1425655583018126 | validation: 1.7791599568042546]
	TIME [epoch: 5.72 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.557338127785624		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.557338127785624 | validation: 1.2195840023487698]
	TIME [epoch: 5.71 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7339028562929868		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.7339028562929868 | validation: 1.1872230080011152]
	TIME [epoch: 5.71 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2958907785391023		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.2958907785391023 | validation: 0.7110094632132393]
	TIME [epoch: 5.72 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3956827755099104		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.3956827755099104 | validation: 0.7154336173045357]
	TIME [epoch: 5.71 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2585385405113028		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.2585385405113028 | validation: 1.0018940725022234]
	TIME [epoch: 5.73 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2484257161113932		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.2484257161113932 | validation: 0.957769130057694]
	TIME [epoch: 5.74 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3512389143049437		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.3512389143049437 | validation: 1.109875846284864]
	TIME [epoch: 5.72 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2557266856620763		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.2557266856620763 | validation: 0.8685136471591711]
	TIME [epoch: 5.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1542880672718274		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.1542880672718274 | validation: 0.8854631743924597]
	TIME [epoch: 5.7 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.177570680116135		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.177570680116135 | validation: 1.239820145561969]
	TIME [epoch: 5.71 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3386790168040446		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.3386790168040446 | validation: 0.8889466874902172]
	TIME [epoch: 5.71 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1314351748670122		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.1314351748670122 | validation: 0.7867034441569666]
	TIME [epoch: 5.75 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3364134099471532		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.3364134099471532 | validation: 0.9926756043741781]
	TIME [epoch: 5.71 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5607876987138325		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.5607876987138325 | validation: 0.8400608308159571]
	TIME [epoch: 5.71 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3207735789718478		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.3207735789718478 | validation: 1.441548095683176]
	TIME [epoch: 5.72 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4228394384119933		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.4228394384119933 | validation: 0.7150640946265144]
	TIME [epoch: 5.72 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1480971366504444		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.1480971366504444 | validation: 0.9134742055215435]
	TIME [epoch: 5.71 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1765944726527449		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.1765944726527449 | validation: 0.8629886164690243]
	TIME [epoch: 5.73 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5191477979766264		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.5191477979766264 | validation: 0.7291474584141512]
	TIME [epoch: 5.75 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1931092012884277		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.1931092012884277 | validation: 1.2502745481526298]
	TIME [epoch: 5.73 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4188851786159429		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.4188851786159429 | validation: 0.5860575489845256]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0661211558791674		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.0661211558791674 | validation: 1.399361991465227]
	TIME [epoch: 5.71 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5933104257849124		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.5933104257849124 | validation: 1.6669654591442287]
	TIME [epoch: 5.71 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5129205931147756		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.5129205931147756 | validation: 1.1746631817692594]
	TIME [epoch: 5.71 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5044550667584786		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.5044550667584786 | validation: 1.7242457229751633]
	TIME [epoch: 5.75 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.326200251166171		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.326200251166171 | validation: 0.6536835128026641]
	TIME [epoch: 5.72 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9991231210771542		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.9991231210771542 | validation: 2.8275402726954257]
	TIME [epoch: 5.71 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.721912409842664		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.721912409842664 | validation: 2.4817409661866807]
	TIME [epoch: 5.71 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.527789271163264		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.527789271163264 | validation: 1.586282450778259]
	TIME [epoch: 5.71 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3177495512061301		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.3177495512061301 | validation: 1.9327820516082148]
	TIME [epoch: 5.71 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5961072015951887		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.5961072015951887 | validation: 1.1416499176600392]
	TIME [epoch: 5.73 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2457872344132954		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.2457872344132954 | validation: 0.7655417622337055]
	TIME [epoch: 5.74 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1351147616296167		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.1351147616296167 | validation: 0.7645681006104382]
	TIME [epoch: 5.71 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0934471050163306		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.0934471050163306 | validation: 0.709947997459585]
	TIME [epoch: 5.71 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.098841404197691		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.098841404197691 | validation: 0.5954409252469601]
	TIME [epoch: 5.71 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0567563944850877		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.0567563944850877 | validation: 1.8736487438205578]
	TIME [epoch: 5.71 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4595495818768498		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.4595495818768498 | validation: 1.0777538988380198]
	TIME [epoch: 5.71 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.211418199400523		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.211418199400523 | validation: 0.5793339766138526]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174778724283573		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.174778724283573 | validation: 0.7662431427028638]
	TIME [epoch: 5.72 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1728122583755245		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.1728122583755245 | validation: 0.6112166467266927]
	TIME [epoch: 5.71 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2017892276330995		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.2017892276330995 | validation: 1.0270162387188042]
	TIME [epoch: 5.71 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0964673229701447		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.0964673229701447 | validation: 0.7237283334184759]
	TIME [epoch: 5.71 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2240129913467774		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.2240129913467774 | validation: 0.7216506455275817]
	TIME [epoch: 5.71 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3557479751624444		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.3557479751624444 | validation: 0.691280355148313]
	TIME [epoch: 5.74 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1446401433988274		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.1446401433988274 | validation: 0.8440405419327108]
	TIME [epoch: 5.73 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6418883867654563		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.6418883867654563 | validation: 0.5953444406125428]
	TIME [epoch: 5.71 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1939597936652375		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.1939597936652375 | validation: 0.8697371630106873]
	TIME [epoch: 5.71 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1078423094405307		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.1078423094405307 | validation: 0.9593475913883446]
	TIME [epoch: 5.71 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.126191205421263		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.126191205421263 | validation: 0.9187374723496455]
	TIME [epoch: 5.71 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1897006582245884		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.1897006582245884 | validation: 1.7300864516856818]
	TIME [epoch: 5.71 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.476982035670598		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.476982035670598 | validation: 0.9513461274436651]
	TIME [epoch: 5.76 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1301713270198241		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.1301713270198241 | validation: 0.673205434217879]
	TIME [epoch: 5.72 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1404288399713607		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.1404288399713607 | validation: 1.117650430633385]
	TIME [epoch: 5.71 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.389182219531522		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.389182219531522 | validation: 1.8607784423651044]
	TIME [epoch: 5.71 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.588452544061251		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.588452544061251 | validation: 0.872816209394255]
	TIME [epoch: 5.72 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1924608187399572		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.1924608187399572 | validation: 1.5203999459538784]
	TIME [epoch: 5.71 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2444738237055633		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.2444738237055633 | validation: 1.038604291871809]
	TIME [epoch: 5.73 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0951773873556805		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.0951773873556805 | validation: 0.5768115857813478]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1221695426837113		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.1221695426837113 | validation: 0.6715380144237223]
	TIME [epoch: 5.72 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.113535268887028		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.113535268887028 | validation: 0.9019482461929448]
	TIME [epoch: 5.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057958696785686		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.057958696785686 | validation: 1.0457294135952913]
	TIME [epoch: 5.71 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3019016378565929		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.3019016378565929 | validation: 0.5223379737229769]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141805334499365		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.141805334499365 | validation: 0.6051704714503692]
	TIME [epoch: 5.73 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0162207340004494		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.0162207340004494 | validation: 0.6850262804680322]
	TIME [epoch: 5.77 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1320599108055782		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.1320599108055782 | validation: 0.6130850676933254]
	TIME [epoch: 5.73 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1598896576174016		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.1598896576174016 | validation: 0.9462135660348139]
	TIME [epoch: 5.73 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0167071180187703		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.0167071180187703 | validation: 0.8239289726643165]
	TIME [epoch: 5.73 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9984774171903449		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.9984774171903449 | validation: 1.601846647143006]
	TIME [epoch: 5.73 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.179006094387936		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.179006094387936 | validation: 0.9724615871466773]
	TIME [epoch: 5.73 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3426332864594386		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.3426332864594386 | validation: 0.539929220566804]
	TIME [epoch: 5.76 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8637409029362916		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.8637409029362916 | validation: 0.6401012176309152]
	TIME [epoch: 5.74 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051568786646301		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.051568786646301 | validation: 0.5393865231250204]
	TIME [epoch: 5.73 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.001025955714111		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.001025955714111 | validation: 0.46498550814286677]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2645487355413632		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.2645487355413632 | validation: 0.5668741939977835]
	TIME [epoch: 5.73 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3676893984490994		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.3676893984490994 | validation: 0.5969006876236843]
	TIME [epoch: 5.72 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.954051702750763		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.954051702750763 | validation: 0.6252384763301516]
	TIME [epoch: 5.73 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1649736607584666		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.1649736607584666 | validation: 0.5361791354034408]
	TIME [epoch: 5.76 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.09679773930631		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.09679773930631 | validation: 1.0510017859003986]
	TIME [epoch: 5.73 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9878748698859376		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.9878748698859376 | validation: 0.6976825669863829]
	TIME [epoch: 5.72 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.950350384170273		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.950350384170273 | validation: 0.6272904662645302]
	TIME [epoch: 5.73 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0493297766883352		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.0493297766883352 | validation: 0.8579019871105952]
	TIME [epoch: 5.72 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.068303917014363		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.068303917014363 | validation: 1.056428174610914]
	TIME [epoch: 5.72 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2290104105528696		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.2290104105528696 | validation: 0.5213666397503223]
	TIME [epoch: 5.75 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9806703167695393		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.9806703167695393 | validation: 0.7636552069460198]
	TIME [epoch: 5.74 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0871752672846144		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.0871752672846144 | validation: 1.2343383128518033]
	TIME [epoch: 5.72 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.22166347772135		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.22166347772135 | validation: 0.4711675938280908]
	TIME [epoch: 5.72 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9605032743873745		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.9605032743873745 | validation: 1.1279395906841672]
	TIME [epoch: 5.72 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0466662980427157		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.0466662980427157 | validation: 0.5101547458662185]
	TIME [epoch: 5.72 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.982766347081797		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.982766347081797 | validation: 0.8880152094166678]
	TIME [epoch: 5.72 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9754805026756319		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.9754805026756319 | validation: 1.0825858217100008]
	TIME [epoch: 5.77 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.040838604661588		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.040838604661588 | validation: 0.8790981894525872]
	TIME [epoch: 5.73 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9581615259616658		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.9581615259616658 | validation: 0.4896084560013354]
	TIME [epoch: 5.72 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9664127495149067		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.9664127495149067 | validation: 0.8233697940334599]
	TIME [epoch: 5.73 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9702159280749351		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.9702159280749351 | validation: 0.5311870608601017]
	TIME [epoch: 5.72 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9858574123983977		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.9858574123983977 | validation: 0.5988307998879884]
	TIME [epoch: 5.72 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064097475811434		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.064097475811434 | validation: 0.5610026931409461]
	TIME [epoch: 5.75 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2034657885904232		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.2034657885904232 | validation: 0.48242535567759876]
	TIME [epoch: 5.74 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3855189776206933		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.3855189776206933 | validation: 0.7930909587026497]
	TIME [epoch: 5.73 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1281365937229806		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.1281365937229806 | validation: 0.7123116271275864]
	TIME [epoch: 5.72 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9687861500392907		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.9687861500392907 | validation: 0.7201814951590327]
	TIME [epoch: 5.72 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1970109767336485		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.1970109767336485 | validation: 0.48274694527783085]
	TIME [epoch: 5.73 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067097381182478		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.067097381182478 | validation: 0.555188368378522]
	TIME [epoch: 5.73 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8722550432291623		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.8722550432291623 | validation: 0.7940830988707631]
	TIME [epoch: 5.76 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9409738821478811		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.9409738821478811 | validation: 1.0087339819026502]
	TIME [epoch: 5.73 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1023976254909402		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.1023976254909402 | validation: 0.4906751263429833]
	TIME [epoch: 5.73 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9012021448155269		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.9012021448155269 | validation: 0.7139885848374945]
	TIME [epoch: 5.72 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9794491569834021		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.9794491569834021 | validation: 0.6012334371064738]
	TIME [epoch: 5.72 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8514294635955983		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.8514294635955983 | validation: 1.3464828057055325]
	TIME [epoch: 5.72 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.252700767177037		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.252700767177037 | validation: 1.0748199224206496]
	TIME [epoch: 5.75 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0893958821999141		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.0893958821999141 | validation: 0.4487684503065515]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0227858259600946		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.0227858259600946 | validation: 1.3569079130105381]
	TIME [epoch: 5.73 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1356854579174689		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.1356854579174689 | validation: 1.0527869582744827]
	TIME [epoch: 5.73 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0858311901562812		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.0858311901562812 | validation: 0.5448106309356996]
	TIME [epoch: 5.72 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0938150079855709		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.0938150079855709 | validation: 0.6323723709791701]
	TIME [epoch: 5.72 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0447788293922342		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.0447788293922342 | validation: 0.4683434092859492]
	TIME [epoch: 5.74 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4404664284775073		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.4404664284775073 | validation: 0.8769517128932222]
	TIME [epoch: 5.75 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.979787112801115		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.979787112801115 | validation: 1.1563412214821904]
	TIME [epoch: 5.73 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.163050005627108		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.163050005627108 | validation: 0.5802932021396487]
	TIME [epoch: 5.72 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8800359175422292		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.8800359175422292 | validation: 0.5192907898995703]
	TIME [epoch: 5.72 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9194309306917715		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.9194309306917715 | validation: 0.6143495559022921]
	TIME [epoch: 5.72 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0385420122522708		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.0385420122522708 | validation: 0.697462932169036]
	TIME [epoch: 5.72 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9430219057964341		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.9430219057964341 | validation: 0.8393945405416128]
	TIME [epoch: 5.75 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8758356681620307		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.8758356681620307 | validation: 0.9805097831263347]
	TIME [epoch: 5.74 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2199403888968503		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.2199403888968503 | validation: 1.0786289223973535]
	TIME [epoch: 5.73 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1410202062420265		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.1410202062420265 | validation: 1.6798981028969031]
	TIME [epoch: 5.72 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2704205039055751		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.2704205039055751 | validation: 0.8478574234797729]
	TIME [epoch: 5.72 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.008521565055335		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.008521565055335 | validation: 0.5307244954307668]
	TIME [epoch: 5.72 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8834024870087893		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.8834024870087893 | validation: 0.6329165154791236]
	TIME [epoch: 5.72 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9124224296884497		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.9124224296884497 | validation: 1.1717618602009494]
	TIME [epoch: 5.76 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2337405802392292		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.2337405802392292 | validation: 0.707607208598988]
	TIME [epoch: 5.73 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051960577842493		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.051960577842493 | validation: 0.5424526407634972]
	TIME [epoch: 5.72 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8249467566697157		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.8249467566697157 | validation: 0.5572476039394276]
	TIME [epoch: 5.72 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9975720300240564		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.9975720300240564 | validation: 0.5168107223640315]
	TIME [epoch: 5.72 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8699001112935136		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.8699001112935136 | validation: 0.6713386074457757]
	TIME [epoch: 5.72 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0368936496568024		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.0368936496568024 | validation: 0.4862586739794322]
	TIME [epoch: 5.75 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9254203498648395		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.9254203498648395 | validation: 0.5181590950409003]
	TIME [epoch: 5.74 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8761159165290056		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.8761159165290056 | validation: 0.5255119648289379]
	TIME [epoch: 5.72 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.002619146646222		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.002619146646222 | validation: 0.6219312201898054]
	TIME [epoch: 5.72 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8612259798356636		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.8612259798356636 | validation: 0.47964395810805227]
	TIME [epoch: 5.72 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8542407654950338		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.8542407654950338 | validation: 1.4997159683989538]
	TIME [epoch: 5.72 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0724848196132526		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.0724848196132526 | validation: 1.1514059509262649]
	TIME [epoch: 5.72 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9049436747733541		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.9049436747733541 | validation: 0.9850010570273958]
	TIME [epoch: 5.76 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8793770354505522		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.8793770354505522 | validation: 0.5121513377093286]
	TIME [epoch: 5.73 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8824932234585204		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.8824932234585204 | validation: 0.5685418642194586]
	TIME [epoch: 5.72 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8399947716837286		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.8399947716837286 | validation: 0.5030906953628016]
	TIME [epoch: 5.72 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9166647715932008		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.9166647715932008 | validation: 0.391108857216666]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_328.pth
	Model improved!!!
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7963429276763472		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.7963429276763472 | validation: 0.6566676941260972]
	TIME [epoch: 5.72 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9724043881623025		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.9724043881623025 | validation: 0.44403600660044973]
	TIME [epoch: 5.75 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9382486740735245		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.9382486740735245 | validation: 0.5118021329505603]
	TIME [epoch: 5.72 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7526577872156541		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.7526577872156541 | validation: 0.4932841695026361]
	TIME [epoch: 5.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9253210581864607		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.9253210581864607 | validation: 0.9997498927051441]
	TIME [epoch: 5.71 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0591762864583827		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.0591762864583827 | validation: 1.0422714862207383]
	TIME [epoch: 5.71 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9907621109250082		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.9907621109250082 | validation: 0.46178476057708023]
	TIME [epoch: 5.71 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8951099557186373		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.8951099557186373 | validation: 0.820016308648048]
	TIME [epoch: 5.71 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8295347928623311		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.8295347928623311 | validation: 0.6132302745105491]
	TIME [epoch: 5.75 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9677608988814959		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.9677608988814959 | validation: 0.49112823635874614]
	TIME [epoch: 5.72 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8467158878925831		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.8467158878925831 | validation: 0.5137730371223438]
	TIME [epoch: 5.71 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8478407061297806		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.8478407061297806 | validation: 0.9566262907211014]
	TIME [epoch: 5.72 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.034739005530958		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.034739005530958 | validation: 0.6620838775459704]
	TIME [epoch: 5.71 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7765035008469754		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.7765035008469754 | validation: 0.727882840606933]
	TIME [epoch: 5.72 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7899779769421313		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.7899779769421313 | validation: 0.619809594191401]
	TIME [epoch: 5.74 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7934041532133277		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.7934041532133277 | validation: 0.42719918889980923]
	TIME [epoch: 5.71 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8301529974923231		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.8301529974923231 | validation: 0.4708411390382845]
	TIME [epoch: 5.71 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8926039560458789		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.8926039560458789 | validation: 0.6224430514350641]
	TIME [epoch: 5.72 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8061630263323664		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.8061630263323664 | validation: 0.7878655035709438]
	TIME [epoch: 5.71 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.814908154725132		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.814908154725132 | validation: 0.47691997192016905]
	TIME [epoch: 5.7 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8154869228981518		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.8154869228981518 | validation: 0.8423825767478165]
	TIME [epoch: 5.71 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8612846992298085		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.8612846992298085 | validation: 0.41145969618292116]
	TIME [epoch: 5.75 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7428236516741538		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.7428236516741538 | validation: 0.8464967622764854]
	TIME [epoch: 5.72 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9042740776908363		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.9042740776908363 | validation: 0.46993481440263796]
	TIME [epoch: 5.71 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0150748547529524		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.0150748547529524 | validation: 1.295247976660306]
	TIME [epoch: 5.72 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.08785072690418		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.08785072690418 | validation: 1.0136232747998375]
	TIME [epoch: 5.72 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9444520023909505		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.9444520023909505 | validation: 1.2721120248133575]
	TIME [epoch: 5.72 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2575899941291226		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.2575899941291226 | validation: 0.7947210222107479]
	TIME [epoch: 5.75 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9011413400054222		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.9011413400054222 | validation: 0.40699517554662296]
	TIME [epoch: 5.73 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9320463887112147		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.9320463887112147 | validation: 0.529351594149397]
	TIME [epoch: 5.72 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7885489336696061		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.7885489336696061 | validation: 0.6037410009173874]
	TIME [epoch: 5.72 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.808545731055589		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.808545731055589 | validation: 0.6947684969616552]
	TIME [epoch: 5.72 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.791049406720114		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.791049406720114 | validation: 0.958545969631997]
	TIME [epoch: 5.72 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7917514553029524		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.7917514553029524 | validation: 0.41732006155077567]
	TIME [epoch: 5.72 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9506418048632181		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.9506418048632181 | validation: 0.5937148754328712]
	TIME [epoch: 5.76 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.97313664126746		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.97313664126746 | validation: 0.4594555162911895]
	TIME [epoch: 5.72 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.343537175846962		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.343537175846962 | validation: 0.5272856517776219]
	TIME [epoch: 5.72 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0282891979012327		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.0282891979012327 | validation: 0.445597228410603]
	TIME [epoch: 5.72 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9694443437144474		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.9694443437144474 | validation: 0.4313726404003031]
	TIME [epoch: 5.72 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8536673286132546		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.8536673286132546 | validation: 0.41113703057468676]
	TIME [epoch: 5.72 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7824678596941435		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.7824678596941435 | validation: 0.6823555402659127]
	TIME [epoch: 5.74 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1017867270633501		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.1017867270633501 | validation: 0.41214416258884246]
	TIME [epoch: 5.73 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8416359656836259		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.8416359656836259 | validation: 0.41338905342422466]
	TIME [epoch: 5.72 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8337733607064814		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.8337733607064814 | validation: 0.43511682943189195]
	TIME [epoch: 5.72 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9551287342359336		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.9551287342359336 | validation: 0.45066797145694665]
	TIME [epoch: 5.72 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8021617203054829		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.8021617203054829 | validation: 0.4756214984681806]
	TIME [epoch: 5.72 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7429402700881609		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.7429402700881609 | validation: 0.4957336597168633]
	TIME [epoch: 5.73 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7484011142327598		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.7484011142327598 | validation: 0.43650911257188346]
	TIME [epoch: 5.76 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812760577610774		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.6812760577610774 | validation: 0.6542527917002311]
	TIME [epoch: 5.73 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7411719662514127		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.7411719662514127 | validation: 0.5985651357677003]
	TIME [epoch: 5.73 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8966813491694821		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.8966813491694821 | validation: 0.6705090273770723]
	TIME [epoch: 5.72 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.966060134216525		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.966060134216525 | validation: 0.6835836679505735]
	TIME [epoch: 5.73 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7436436605909038		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.7436436605909038 | validation: 0.9318697590022181]
	TIME [epoch: 5.72 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0044088058911087		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.0044088058911087 | validation: 0.4006449207750293]
	TIME [epoch: 5.75 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7936365174340441		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.7936365174340441 | validation: 2.147183675751399]
	TIME [epoch: 5.74 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2374588712174517		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.2374588712174517 | validation: 0.5898642142614305]
	TIME [epoch: 5.72 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7977500818032179		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.7977500818032179 | validation: 0.45332190416214757]
	TIME [epoch: 5.71 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7691538683269076		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.7691538683269076 | validation: 0.9416366549327618]
	TIME [epoch: 5.71 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8794572309556995		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.8794572309556995 | validation: 0.5876904076925662]
	TIME [epoch: 5.71 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7862158661000005		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.7862158661000005 | validation: 0.7000241061874172]
	TIME [epoch: 5.73 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9252975435443385		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.9252975435443385 | validation: 0.43273320155508954]
	TIME [epoch: 5.75 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7385251030346316		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.7385251030346316 | validation: 0.5443588199943128]
	TIME [epoch: 5.72 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8643010522215007		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.8643010522215007 | validation: 0.6630296056473498]
	TIME [epoch: 5.72 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7577116127901917		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.7577116127901917 | validation: 0.4028219814387605]
	TIME [epoch: 5.71 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7581970993768828		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.7581970993768828 | validation: 1.232687493193748]
	TIME [epoch: 5.71 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1765916280771436		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.1765916280771436 | validation: 0.9628802351437022]
	TIME [epoch: 5.72 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8825325743941066		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.8825325743941066 | validation: 0.43911522171645956]
	TIME [epoch: 5.74 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7716460861894692		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.7716460861894692 | validation: 0.35931873070422965]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9825632980101803		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.9825632980101803 | validation: 0.638327223921892]
	TIME [epoch: 5.72 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8714927256297014		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.8714927256297014 | validation: 0.5473843165370877]
	TIME [epoch: 5.71 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9876923028972813		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.9876923028972813 | validation: 0.5046423543970551]
	TIME [epoch: 5.71 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9326012373161588		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.9326012373161588 | validation: 0.4502942555879972]
	TIME [epoch: 5.71 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.808108962047335		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.808108962047335 | validation: 0.5611248632121618]
	TIME [epoch: 5.72 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0556251661146945		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.0556251661146945 | validation: 0.4200386219575378]
	TIME [epoch: 5.75 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8605247246697311		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.8605247246697311 | validation: 0.6803881327390496]
	TIME [epoch: 5.71 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8974530532089482		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.8974530532089482 | validation: 0.3867759740121871]
	TIME [epoch: 5.71 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6756711797081849		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.6756711797081849 | validation: 0.5024696097206873]
	TIME [epoch: 5.71 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993667131279043		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.6993667131279043 | validation: 0.838443593151247]
	TIME [epoch: 5.71 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9679604497499444		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.9679604497499444 | validation: 0.4018947811281842]
	TIME [epoch: 5.72 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6802072182375976		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.6802072182375976 | validation: 0.39462224351141856]
	TIME [epoch: 5.75 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7027761794120179		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.7027761794120179 | validation: 0.48346267538384313]
	TIME [epoch: 5.72 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6945574172800255		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.6945574172800255 | validation: 0.7649610234512669]
	TIME [epoch: 5.72 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.950715688483503		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.950715688483503 | validation: 0.868795611253855]
	TIME [epoch: 5.72 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9737508218750681		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.9737508218750681 | validation: 0.3915281085463465]
	TIME [epoch: 5.71 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6716838015139726		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.6716838015139726 | validation: 0.5813297030995789]
	TIME [epoch: 5.72 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842006311776291		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.6842006311776291 | validation: 0.46453389318629024]
	TIME [epoch: 5.71 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7783961621835314		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.7783961621835314 | validation: 0.6733720249740986]
	TIME [epoch: 5.75 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7183430492043859		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.7183430492043859 | validation: 0.33177179403342805]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7581173270065021		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.7581173270065021 | validation: 0.42759378829888306]
	TIME [epoch: 5.71 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7653639447746914		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.7653639447746914 | validation: 0.3624331681855085]
	TIME [epoch: 5.71 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7179483627402788		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.7179483627402788 | validation: 0.34811393397158]
	TIME [epoch: 5.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8371527280660356		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.8371527280660356 | validation: 0.5407018734044098]
	TIME [epoch: 5.71 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9167820072512269		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.9167820072512269 | validation: 0.6671389366712234]
	TIME [epoch: 5.73 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.813605460563339		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.813605460563339 | validation: 0.41226797159329376]
	TIME [epoch: 5.72 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7133785751011701		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.7133785751011701 | validation: 0.3283100892328723]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_423.pth
	Model improved!!!
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6799525905232033		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.6799525905232033 | validation: 0.6433130924229371]
	TIME [epoch: 5.72 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9588150090894967		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.9588150090894967 | validation: 0.3523857279585472]
	TIME [epoch: 5.71 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8482791792646414		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.8482791792646414 | validation: 0.46697349947106914]
	TIME [epoch: 5.71 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9836656853232695		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.9836656853232695 | validation: 0.52449102705685]
	TIME [epoch: 5.73 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8265412740351936		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.8265412740351936 | validation: 0.36847373980960885]
	TIME [epoch: 5.74 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236150371504224		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.7236150371504224 | validation: 0.44539927666233625]
	TIME [epoch: 5.71 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6800876806229161		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.6800876806229161 | validation: 0.392602312928301]
	TIME [epoch: 5.71 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6788035979792664		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.6788035979792664 | validation: 0.4610299847107717]
	TIME [epoch: 5.72 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7262409767649461		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.7262409767649461 | validation: 0.4549176189943516]
	TIME [epoch: 5.72 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7722549519236155		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.7722549519236155 | validation: 0.5131205835861942]
	TIME [epoch: 5.71 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7360365304874368		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.7360365304874368 | validation: 1.1271544907175335]
	TIME [epoch: 5.74 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9434212119915655		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.9434212119915655 | validation: 2.014767558235293]
	TIME [epoch: 5.72 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2675956260051484		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.2675956260051484 | validation: 0.49696929731813927]
	TIME [epoch: 5.71 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7130537345129726		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.7130537345129726 | validation: 0.4700082281768876]
	TIME [epoch: 5.71 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690054359689871		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.690054359689871 | validation: 0.3805267501792492]
	TIME [epoch: 5.71 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9122487183765473		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.9122487183765473 | validation: 0.4483145979362192]
	TIME [epoch: 5.71 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.748811479170725		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.748811479170725 | validation: 0.6132976235626231]
	TIME [epoch: 5.71 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7664467150984386		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.7664467150984386 | validation: 0.4613643502183576]
	TIME [epoch: 5.75 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7971721032950866		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.7971721032950866 | validation: 0.4782340317172461]
	TIME [epoch: 5.72 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8349549021099243		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.8349549021099243 | validation: 0.45976478993910874]
	TIME [epoch: 5.71 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7557060755211275		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.7557060755211275 | validation: 0.3827749382136976]
	TIME [epoch: 5.72 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7572306126072108		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.7572306126072108 | validation: 0.6086947413560259]
	TIME [epoch: 5.72 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9092021684736418		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.9092021684736418 | validation: 0.5879646573309729]
	TIME [epoch: 5.71 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8249226634798057		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.8249226634798057 | validation: 0.45362708920762046]
	TIME [epoch: 5.74 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8956852460217262		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.8956852460217262 | validation: 0.5274267108674109]
	TIME [epoch: 5.73 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7717548567694349		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.7717548567694349 | validation: 0.39305706581577105]
	TIME [epoch: 5.72 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720966159999451		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.720966159999451 | validation: 0.3657848173235243]
	TIME [epoch: 5.71 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8973970828205164		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.8973970828205164 | validation: 0.5203714630195646]
	TIME [epoch: 5.71 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7702435985967233		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.7702435985967233 | validation: 0.6226633840433848]
	TIME [epoch: 5.71 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8281390885003832		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.8281390885003832 | validation: 0.3914458114202099]
	TIME [epoch: 5.71 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893843436651079		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.6893843436651079 | validation: 0.398062154635308]
	TIME [epoch: 5.75 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1130824720737784		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.1130824720737784 | validation: 0.5514684601385593]
	TIME [epoch: 5.72 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7551866531522734		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.7551866531522734 | validation: 0.3497588526122181]
	TIME [epoch: 5.71 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834326624178466		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.6834326624178466 | validation: 0.5083381134820687]
	TIME [epoch: 5.71 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227198834223507		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.7227198834223507 | validation: 0.4395604024312764]
	TIME [epoch: 5.71 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701013618743696		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.701013618743696 | validation: 0.45230146826396045]
	TIME [epoch: 5.71 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6513227958070996		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.6513227958070996 | validation: 0.4218563403206263]
	TIME [epoch: 5.74 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876789011165241		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.6876789011165241 | validation: 0.5343229884489457]
	TIME [epoch: 5.72 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7748498812452231		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.7748498812452231 | validation: 0.37939224904420144]
	TIME [epoch: 5.71 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.651038613560725		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.651038613560725 | validation: 0.3205154408352357]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_463.pth
	Model improved!!!
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7751277651540335		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.7751277651540335 | validation: 0.3480717718657054]
	TIME [epoch: 5.71 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7142857757887209		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.7142857757887209 | validation: 0.3901442572779867]
	TIME [epoch: 5.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7509823860381474		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.7509823860381474 | validation: 0.5391106270666485]
	TIME [epoch: 5.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7163671252932453		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.7163671252932453 | validation: 0.400535165749528]
	TIME [epoch: 5.74 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7880453504737814		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.7880453504737814 | validation: 0.42222299333858815]
	TIME [epoch: 5.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.61174233371291		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.61174233371291 | validation: 0.4175078610847987]
	TIME [epoch: 5.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7347736457052786		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.7347736457052786 | validation: 0.3138377242446708]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_470.pth
	Model improved!!!
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6677231474382391		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.6677231474382391 | validation: 0.5236973743872432]
	TIME [epoch: 5.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6651070576788272		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.6651070576788272 | validation: 0.5648152476774455]
	TIME [epoch: 5.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042372076526151		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.7042372076526151 | validation: 0.3453983888872742]
	TIME [epoch: 5.74 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830697785619746		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.6830697785619746 | validation: 0.32376668186412266]
	TIME [epoch: 5.71 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7019335727509333		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.7019335727509333 | validation: 0.355721219665692]
	TIME [epoch: 5.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694761054323636		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.694761054323636 | validation: 0.3403314483128335]
	TIME [epoch: 5.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8052941187620588		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.8052941187620588 | validation: 0.365861744132166]
	TIME [epoch: 5.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823944411473587		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.6823944411473587 | validation: 0.3111179815374893]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000179540785466		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.7000179540785466 | validation: 0.493361729972759]
	TIME [epoch: 5.72 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6591856407669199		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.6591856407669199 | validation: 0.3750785531624908]
	TIME [epoch: 5.73 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6411465914710799		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.6411465914710799 | validation: 0.3272069357482043]
	TIME [epoch: 5.71 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7066259896120018		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.7066259896120018 | validation: 0.3557063412680388]
	TIME [epoch: 5.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.672131513773317		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.672131513773317 | validation: 0.7730316791044257]
	TIME [epoch: 5.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8083040495881255		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.8083040495881255 | validation: 0.36019156865537905]
	TIME [epoch: 5.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866051271416762		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.6866051271416762 | validation: 0.3325625009268095]
	TIME [epoch: 5.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7962965776936949		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.7962965776936949 | validation: 0.6887574236850469]
	TIME [epoch: 5.74 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6582212640907444		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.6582212640907444 | validation: 0.39055183845626673]
	TIME [epoch: 5.71 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6447722045943794		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.6447722045943794 | validation: 0.3144497832166521]
	TIME [epoch: 5.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9451753651680233		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.9451753651680233 | validation: 0.5461474779434097]
	TIME [epoch: 5.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7623767547551903		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.7623767547551903 | validation: 0.6604886897098063]
	TIME [epoch: 5.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8227662293201361		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.8227662293201361 | validation: 0.4110572187293757]
	TIME [epoch: 5.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861780879928713		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.6861780879928713 | validation: 0.45545496859701096]
	TIME [epoch: 5.71 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7370535026737088		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.7370535026737088 | validation: 0.6023688147353743]
	TIME [epoch: 5.73 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7107333431284183		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.7107333431284183 | validation: 0.6127181626485213]
	TIME [epoch: 5.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68387283220646		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.68387283220646 | validation: 0.4992375511743837]
	TIME [epoch: 5.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7625716523698158		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.7625716523698158 | validation: 0.3390040803961205]
	TIME [epoch: 5.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6247398896231772		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.6247398896231772 | validation: 0.73772392196656]
	TIME [epoch: 5.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7808852025697537		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.7808852025697537 | validation: 0.329746228785383]
	TIME [epoch: 5.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7891464794803243		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.7891464794803243 | validation: 0.31151680594074704]
	TIME [epoch: 5.73 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6668398786509036		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.6668398786509036 | validation: 0.3529236325475021]
	TIME [epoch: 5.71 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6276873040190986		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.6276873040190986 | validation: 0.7460698172795172]
	TIME [epoch: 5.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8572591236657409		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.8572591236657409 | validation: 0.46734480103592646]
	TIME [epoch: 5.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6643721617299031		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.6643721617299031 | validation: 0.5331065548920078]
	TIME [epoch: 5.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6535227125517199		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.6535227125517199 | validation: 0.360828452883635]
	TIME [epoch: 5.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6469884246547244		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.6469884246547244 | validation: 0.2945526358473225]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194088093362707		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.7194088093362707 | validation: 0.6451832857306525]
	TIME [epoch: 5.74 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1005869916722666		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.1005869916722666 | validation: 0.44549014820054894]
	TIME [epoch: 5.71 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6780711118934928		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.6780711118934928 | validation: 0.31539556507972233]
	TIME [epoch: 5.71 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5983618455763001		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.5983618455763001 | validation: 0.46456776678860034]
	TIME [epoch: 5.71 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6440428444316506		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.6440428444316506 | validation: 0.4999709939713954]
	TIME [epoch: 5.71 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6403729135363221		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.6403729135363221 | validation: 0.3109107579909197]
	TIME [epoch: 5.71 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7074322871305878		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.7074322871305878 | validation: 0.5910125805271552]
	TIME [epoch: 5.74 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8322326229489426		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.8322326229489426 | validation: 0.586703240222063]
	TIME [epoch: 5.71 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680573132845727		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.680573132845727 | validation: 0.6580963973168844]
	TIME [epoch: 5.71 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6581491184264313		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.6581491184264313 | validation: 0.818143934533548]
	TIME [epoch: 5.71 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.630835582765968		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.630835582765968 | validation: 0.37269052626708193]
	TIME [epoch: 5.71 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7130765679283961		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.7130765679283961 | validation: 0.38513998263633414]
	TIME [epoch: 5.71 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.662350471147841		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.662350471147841 | validation: 0.2973889720975504]
	TIME [epoch: 5.72 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5893883624222815		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.5893883624222815 | validation: 0.3449376932683761]
	TIME [epoch: 5.74 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6096207050921738		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.6096207050921738 | validation: 0.3266707078408065]
	TIME [epoch: 5.71 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6609319901770004		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.6609319901770004 | validation: 0.6494029912398213]
	TIME [epoch: 5.71 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6737323267119069		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.6737323267119069 | validation: 0.6496413949284268]
	TIME [epoch: 5.71 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6287895097333799		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.6287895097333799 | validation: 0.30856063934479133]
	TIME [epoch: 5.71 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5334911805143185		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.5334911805143185 | validation: 0.40123557465089593]
	TIME [epoch: 5.71 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.575306448281287		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.575306448281287 | validation: 0.2990333303647425]
	TIME [epoch: 5.75 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826741435700727		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.6826741435700727 | validation: 0.36165913672796335]
	TIME [epoch: 5.72 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6552192352535583		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.6552192352535583 | validation: 0.3083130629910104]
	TIME [epoch: 5.71 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6202645853096366		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.6202645853096366 | validation: 0.3293889926659357]
	TIME [epoch: 5.71 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5834835605770436		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.5834835605770436 | validation: 0.355196561422141]
	TIME [epoch: 5.71 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6485672044940692		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.6485672044940692 | validation: 0.4803628770693685]
	TIME [epoch: 5.71 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7011780139587425		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.7011780139587425 | validation: 1.123450063686443]
	TIME [epoch: 5.71 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8476357031387999		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.8476357031387999 | validation: 0.44559225613077663]
	TIME [epoch: 5.74 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6105895885660204		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.6105895885660204 | validation: 0.5507475242735048]
	TIME [epoch: 5.71 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7803355343156114		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.7803355343156114 | validation: 0.29819190881100555]
	TIME [epoch: 5.71 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6088118375556059		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.6088118375556059 | validation: 0.3936916102298548]
	TIME [epoch: 5.71 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5838861253844173		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.5838861253844173 | validation: 1.0085889193187731]
	TIME [epoch: 5.71 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9841470308300018		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.9841470308300018 | validation: 0.3946136037106867]
	TIME [epoch: 5.71 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6932418484011837		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.6932418484011837 | validation: 0.37722932275186544]
	TIME [epoch: 5.74 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7330819933519251		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.7330819933519251 | validation: 0.35002045996686504]
	TIME [epoch: 5.72 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706407974477288		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.6706407974477288 | validation: 0.410742387806457]
	TIME [epoch: 5.71 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6542452579700374		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.6542452579700374 | validation: 0.33454250036336564]
	TIME [epoch: 5.71 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6068105872529532		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.6068105872529532 | validation: 0.4576439013080736]
	TIME [epoch: 5.71 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6088765874513488		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.6088765874513488 | validation: 0.34629582832214967]
	TIME [epoch: 5.71 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6040303230377675		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.6040303230377675 | validation: 0.3108636455255515]
	TIME [epoch: 5.71 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.645778904288627		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.645778904288627 | validation: 0.3548216549930255]
	TIME [epoch: 5.75 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5755359929931645		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.5755359929931645 | validation: 0.4511142713469118]
	TIME [epoch: 5.71 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6211398064236001		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.6211398064236001 | validation: 0.35619805158152046]
	TIME [epoch: 5.71 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536633218282818		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.6536633218282818 | validation: 0.3395531349583365]
	TIME [epoch: 5.71 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5703875575481517		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.5703875575481517 | validation: 0.3148853718564962]
	TIME [epoch: 5.71 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5987677652039524		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.5987677652039524 | validation: 0.3455155436377466]
	TIME [epoch: 5.71 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.633062435720944		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.633062435720944 | validation: 0.3173494418665434]
	TIME [epoch: 5.74 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6311456147208918		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.6311456147208918 | validation: 0.5775502982754346]
	TIME [epoch: 5.73 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6482835838242142		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.6482835838242142 | validation: 0.5320134789732194]
	TIME [epoch: 5.71 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801155669450857		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.6801155669450857 | validation: 0.4552192282594295]
	TIME [epoch: 5.71 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827270391587178		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.6827270391587178 | validation: 0.4036086699499979]
	TIME [epoch: 5.71 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214590188536275		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.7214590188536275 | validation: 0.2923280573014741]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952605511633162		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.6952605511633162 | validation: 0.5569590188216831]
	TIME [epoch: 5.71 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706194161450506		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.6706194161450506 | validation: 0.34920562888223466]
	TIME [epoch: 5.74 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5937774208808964		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.5937774208808964 | validation: 0.33431033208636135]
	TIME [epoch: 5.71 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5813887986332248		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.5813887986332248 | validation: 0.7038044436714412]
	TIME [epoch: 5.71 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6667413973827826		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.6667413973827826 | validation: 0.3145514051724519]
	TIME [epoch: 5.71 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5449220053608431		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.5449220053608431 | validation: 0.3660580809712954]
	TIME [epoch: 5.71 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5653412153473887		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.5653412153473887 | validation: 0.3255709019322585]
	TIME [epoch: 5.71 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5997192973445857		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.5997192973445857 | validation: 0.36309098217700886]
	TIME [epoch: 5.73 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5662270024482492		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.5662270024482492 | validation: 0.6483726779086351]
	TIME [epoch: 5.72 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6723737433436255		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.6723737433436255 | validation: 0.3662572089408448]
	TIME [epoch: 5.71 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572550304950074		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.572550304950074 | validation: 0.30644516379678494]
	TIME [epoch: 5.71 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.627735390517333		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.627735390517333 | validation: 0.3074685943676149]
	TIME [epoch: 5.71 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6553459994883375		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.6553459994883375 | validation: 0.3386728510952578]
	TIME [epoch: 5.71 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6130686364448824		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.6130686364448824 | validation: 0.41372220477445326]
	TIME [epoch: 5.71 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5807034417778448		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.5807034417778448 | validation: 0.6942612416682841]
	TIME [epoch: 5.75 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6669065201200484		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.6669065201200484 | validation: 0.5293702879270599]
	TIME [epoch: 5.71 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228327472797466		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.6228327472797466 | validation: 0.32238136487469166]
	TIME [epoch: 5.71 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6144375261087003		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.6144375261087003 | validation: 0.34635742330843783]
	TIME [epoch: 5.71 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810896024002905		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.5810896024002905 | validation: 0.5163405814961]
	TIME [epoch: 5.71 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6263475574718455		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.6263475574718455 | validation: 0.3810018240136679]
	TIME [epoch: 5.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5615377994860065		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.5615377994860065 | validation: 0.4297898759265014]
	TIME [epoch: 5.73 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5802468623234126		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.5802468623234126 | validation: 0.41851391125716475]
	TIME [epoch: 5.72 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5929558051575042		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.5929558051575042 | validation: 0.2846059280499757]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_579.pth
	Model improved!!!
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6185971720403141		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.6185971720403141 | validation: 0.3799215953718518]
	TIME [epoch: 5.71 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6067340616329865		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.6067340616329865 | validation: 0.35862792023229434]
	TIME [epoch: 5.71 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7678017168625003		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.7678017168625003 | validation: 0.3842578426177549]
	TIME [epoch: 5.71 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6322845831586996		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.6322845831586996 | validation: 0.449734331164394]
	TIME [epoch: 5.72 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6298071396269266		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.6298071396269266 | validation: 0.3964567265215016]
	TIME [epoch: 5.75 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5578129495873752		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.5578129495873752 | validation: 0.40774515708735976]
	TIME [epoch: 5.71 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5547702148054335		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.5547702148054335 | validation: 0.28694773619828307]
	TIME [epoch: 5.71 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5350576498749592		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.5350576498749592 | validation: 0.30095093318036564]
	TIME [epoch: 5.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5910851731465219		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.5910851731465219 | validation: 0.3251362141036816]
	TIME [epoch: 5.71 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6202269918193992		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.6202269918193992 | validation: 0.32860165431585286]
	TIME [epoch: 5.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5647665091033891		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.5647665091033891 | validation: 0.31899407400754476]
	TIME [epoch: 5.74 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6239069541263959		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.6239069541263959 | validation: 0.4648518121378952]
	TIME [epoch: 5.73 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6533879543588443		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.6533879543588443 | validation: 0.30554070362336605]
	TIME [epoch: 5.71 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5405119822489777		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.5405119822489777 | validation: 0.36861690541754455]
	TIME [epoch: 5.71 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5670644331231498		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.5670644331231498 | validation: 0.2753530171996317]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_594.pth
	Model improved!!!
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5917020791595761		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.5917020791595761 | validation: 0.2974515505225796]
	TIME [epoch: 5.72 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5817883621725388		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.5817883621725388 | validation: 0.27819403723131997]
	TIME [epoch: 5.72 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6128619616256932		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.6128619616256932 | validation: 0.43479347303273247]
	TIME [epoch: 5.74 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6165857734201241		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.6165857734201241 | validation: 0.34719476842721103]
	TIME [epoch: 5.71 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5637511604074207		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.5637511604074207 | validation: 0.2771666376454969]
	TIME [epoch: 5.72 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.58118298354292		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.58118298354292 | validation: 0.30393123038193764]
	TIME [epoch: 5.71 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.761565488008451		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.761565488008451 | validation: 0.299912434907628]
	TIME [epoch: 5.71 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7558105663290366		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.7558105663290366 | validation: 0.41555023650953915]
	TIME [epoch: 5.71 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6020788812955136		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.6020788812955136 | validation: 0.3275119106475563]
	TIME [epoch: 5.75 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5366263936285771		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.5366263936285771 | validation: 0.3806927189953311]
	TIME [epoch: 5.72 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5728488738155882		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.5728488738155882 | validation: 0.28927023235773874]
	TIME [epoch: 5.71 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6332695204783738		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.6332695204783738 | validation: 0.32765129345752014]
	TIME [epoch: 5.73 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5365525119218895		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.5365525119218895 | validation: 0.2964049143186758]
	TIME [epoch: 5.71 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5989500984022872		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.5989500984022872 | validation: 0.2728073449061826]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_608.pth
	Model improved!!!
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5679478858406477		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.5679478858406477 | validation: 0.3622294772451963]
	TIME [epoch: 5.71 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6037940407720005		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.6037940407720005 | validation: 0.29340315534237527]
	TIME [epoch: 5.74 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6407521626277298		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.6407521626277298 | validation: 0.4255091109834625]
	TIME [epoch: 5.71 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6038125884213505		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.6038125884213505 | validation: 0.40704888077307905]
	TIME [epoch: 5.71 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6069135684454942		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.6069135684454942 | validation: 0.49680564976841013]
	TIME [epoch: 5.72 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5685762979006594		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.5685762979006594 | validation: 0.29341722448218444]
	TIME [epoch: 5.72 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5303967488294338		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.5303967488294338 | validation: 0.2728391449620555]
	TIME [epoch: 5.72 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5268220928259394		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5268220928259394 | validation: 0.2796984486581042]
	TIME [epoch: 5.76 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.525369006987134		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.525369006987134 | validation: 0.2943316584458117]
	TIME [epoch: 5.72 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.614665154137898		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.614665154137898 | validation: 0.35968902563420313]
	TIME [epoch: 5.72 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5862978289847278		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.5862978289847278 | validation: 0.27686279161188604]
	TIME [epoch: 5.72 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5316203355433914		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.5316203355433914 | validation: 0.7587943463808248]
	TIME [epoch: 5.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6797566201649686		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.6797566201649686 | validation: 0.3315094230875822]
	TIME [epoch: 5.72 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5930873672680944		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.5930873672680944 | validation: 0.3240773362700575]
	TIME [epoch: 5.71 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5328867402853519		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.5328867402853519 | validation: 0.36647725240054013]
	TIME [epoch: 5.75 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5582455020867391		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.5582455020867391 | validation: 0.3229618316949168]
	TIME [epoch: 5.72 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467230095224674		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.5467230095224674 | validation: 0.5483379360404267]
	TIME [epoch: 5.72 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.035800071653825		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 1.035800071653825 | validation: 0.3595972216777372]
	TIME [epoch: 5.71 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5638405154904892		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5638405154904892 | validation: 0.36325672728762587]
	TIME [epoch: 5.71 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5606570548639741		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.5606570548639741 | validation: 0.2999124493888753]
	TIME [epoch: 5.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269484205464691		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5269484205464691 | validation: 0.35716716786911945]
	TIME [epoch: 5.75 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5683888702891202		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.5683888702891202 | validation: 0.37466123311797944]
	TIME [epoch: 5.72 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112410681893769		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.5112410681893769 | validation: 0.3473798026276709]
	TIME [epoch: 5.72 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5515677081765566		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.5515677081765566 | validation: 0.3362010579518238]
	TIME [epoch: 5.71 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5405850813774515		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.5405850813774515 | validation: 0.3704888632369655]
	TIME [epoch: 5.72 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5664901588825888		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.5664901588825888 | validation: 0.285669730596648]
	TIME [epoch: 5.72 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5369532723656937		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.5369532723656937 | validation: 0.2965290202369442]
	TIME [epoch: 5.73 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.566046554296362		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.566046554296362 | validation: 0.34134014574180915]
	TIME [epoch: 5.75 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5821748836422033		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.5821748836422033 | validation: 0.2687237430451512]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5589195553225859		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.5589195553225859 | validation: 0.3073027513669579]
	TIME [epoch: 5.73 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033299378828161		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.5033299378828161 | validation: 0.27858716843111636]
	TIME [epoch: 5.71 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5158087940771628		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.5158087940771628 | validation: 0.3711389749483513]
	TIME [epoch: 5.72 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6032739880407534		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.6032739880407534 | validation: 0.3250343348729794]
	TIME [epoch: 5.71 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6396167030995751		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.6396167030995751 | validation: 0.2640238841958879]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_642.pth
	Model improved!!!
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269050221157413		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.5269050221157413 | validation: 0.3891589137170029]
	TIME [epoch: 5.72 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5513380219194756		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.5513380219194756 | validation: 0.5181420801275555]
	TIME [epoch: 5.72 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5794156672725358		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.5794156672725358 | validation: 0.2860034103870862]
	TIME [epoch: 5.71 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5062600332457646		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.5062600332457646 | validation: 0.28959367278185744]
	TIME [epoch: 5.72 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5004768735076544		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.5004768735076544 | validation: 0.3035503945048119]
	TIME [epoch: 5.71 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5289400466024565		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.5289400466024565 | validation: 0.3184605191109]
	TIME [epoch: 5.73 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5260998278711394		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.5260998278711394 | validation: 0.4206523570415254]
	TIME [epoch: 5.74 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254990338970641		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.6254990338970641 | validation: 0.33083778788954005]
	TIME [epoch: 5.72 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568683144745902		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.568683144745902 | validation: 0.36418317730705796]
	TIME [epoch: 5.72 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5897327881970933		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5897327881970933 | validation: 0.2609992768628019]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_652.pth
	Model improved!!!
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5173273860239271		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.5173273860239271 | validation: 0.40396332321382417]
	TIME [epoch: 5.71 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5350932963342202		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.5350932963342202 | validation: 0.33406166976679413]
	TIME [epoch: 5.71 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6434339517371124		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.6434339517371124 | validation: 0.4795164467430778]
	TIME [epoch: 5.74 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5623888915079147		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.5623888915079147 | validation: 0.26719532010187047]
	TIME [epoch: 5.71 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5675260267337279		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.5675260267337279 | validation: 0.3334097344298806]
	TIME [epoch: 5.71 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5309494202184734		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.5309494202184734 | validation: 0.370998378689738]
	TIME [epoch: 5.71 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.631160569224704		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.631160569224704 | validation: 0.403760507737268]
	TIME [epoch: 5.71 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5609677334526598		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.5609677334526598 | validation: 0.26402610522783415]
	TIME [epoch: 5.71 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.526175070557404		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.526175070557404 | validation: 0.4115740437978638]
	TIME [epoch: 5.73 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.586860675916858		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.586860675916858 | validation: 0.2721005663875085]
	TIME [epoch: 5.73 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.526607864804664		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.526607864804664 | validation: 0.3444576240503086]
	TIME [epoch: 5.72 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5988754776970522		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.5988754776970522 | validation: 0.29302166293542686]
	TIME [epoch: 5.72 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5164134562299679		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.5164134562299679 | validation: 0.40283215208348533]
	TIME [epoch: 5.71 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676671443595447		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.5676671443595447 | validation: 0.2525926134030008]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_666.pth
	Model improved!!!
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6180261042948004		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.6180261042948004 | validation: 0.5356347309160921]
	TIME [epoch: 5.72 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.508144064224129		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.508144064224129 | validation: 0.5042973075411965]
	TIME [epoch: 5.75 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5648055810895505		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.5648055810895505 | validation: 0.33021337100456405]
	TIME [epoch: 5.71 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4861303548744634		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.4861303548744634 | validation: 0.3111230764097526]
	TIME [epoch: 5.71 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5635910304702636		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.5635910304702636 | validation: 0.495955061429228]
	TIME [epoch: 5.71 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5390442665311228		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.5390442665311228 | validation: 0.30066496640190765]
	TIME [epoch: 5.71 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5227980829713704		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.5227980829713704 | validation: 0.3000085199967653]
	TIME [epoch: 5.71 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5092262810644315		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.5092262810644315 | validation: 0.3070458625745833]
	TIME [epoch: 5.73 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4985144388745907		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.4985144388745907 | validation: 0.35090239642838156]
	TIME [epoch: 5.72 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5196957947701961		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.5196957947701961 | validation: 0.37079255421678553]
	TIME [epoch: 5.72 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5149224801789357		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.5149224801789357 | validation: 0.4106001883244433]
	TIME [epoch: 5.71 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5627856299105941		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.5627856299105941 | validation: 0.280366754753793]
	TIME [epoch: 5.71 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5290247129798616		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.5290247129798616 | validation: 0.49304246538286606]
	TIME [epoch: 5.72 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5223977592183598		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.5223977592183598 | validation: 0.25910727334183487]
	TIME [epoch: 5.73 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6771882435301388		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.6771882435301388 | validation: 0.38547659664474254]
	TIME [epoch: 5.76 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6157276441096695		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.6157276441096695 | validation: 0.541617076572017]
	TIME [epoch: 5.72 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5546849855794977		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.5546849855794977 | validation: 0.30928348385884996]
	TIME [epoch: 5.72 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5154656119047383		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.5154656119047383 | validation: 0.24948632361994505]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_684.pth
	Model improved!!!
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47492386321935165		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.47492386321935165 | validation: 0.32958153509916105]
	TIME [epoch: 5.71 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5853277915293043		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.5853277915293043 | validation: 0.4915143504343493]
	TIME [epoch: 5.72 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5460447103534348		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.5460447103534348 | validation: 0.5311340905509278]
	TIME [epoch: 5.74 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071265132455747		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.5071265132455747 | validation: 0.2493731698142738]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4888453808258879		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.4888453808258879 | validation: 0.3064273665132119]
	TIME [epoch: 5.71 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5681734906442486		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5681734906442486 | validation: 0.27375707746988015]
	TIME [epoch: 5.71 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.517740246405824		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.517740246405824 | validation: 0.3137622714446712]
	TIME [epoch: 5.71 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5057724407988244		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.5057724407988244 | validation: 0.2770478646073717]
	TIME [epoch: 5.72 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46930981257910276		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.46930981257910276 | validation: 0.3575576225696434]
	TIME [epoch: 5.72 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5047286357184035		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.5047286357184035 | validation: 0.31244920522196157]
	TIME [epoch: 5.74 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5052029091654946		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.5052029091654946 | validation: 0.5193441462627667]
	TIME [epoch: 5.71 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48939591577858554		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.48939591577858554 | validation: 0.28112420309174146]
	TIME [epoch: 5.71 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4673389358324306		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.4673389358324306 | validation: 0.3741779348244981]
	TIME [epoch: 5.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49082211680246396		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.49082211680246396 | validation: 0.49693756868133404]
	TIME [epoch: 5.71 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6436847761296944		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.6436847761296944 | validation: 0.27684291920093496]
	TIME [epoch: 5.71 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47820539227241726		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.47820539227241726 | validation: 0.25851133350097827]
	TIME [epoch: 5.74 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46594020987265716		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.46594020987265716 | validation: 0.33042996921867923]
	TIME [epoch: 5.72 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4833877243622529		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.4833877243622529 | validation: 0.2434722136742661]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_702.pth
	Model improved!!!
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5031426086778743		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.5031426086778743 | validation: 0.4859572348298923]
	TIME [epoch: 5.73 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5180632513937184		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.5180632513937184 | validation: 0.7941112828199474]
	TIME [epoch: 5.73 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6515685659426897		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.6515685659426897 | validation: 0.3309172826752104]
	TIME [epoch: 5.73 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4608817003832167		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.4608817003832167 | validation: 0.2568887240459593]
	TIME [epoch: 5.74 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5105715536976996		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.5105715536976996 | validation: 0.29054689784337856]
	TIME [epoch: 5.76 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48913598483265047		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.48913598483265047 | validation: 0.6913931154278342]
	TIME [epoch: 5.73 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8387766845533455		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.8387766845533455 | validation: 0.2727573605070963]
	TIME [epoch: 5.73 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5554836180265676		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.5554836180265676 | validation: 0.25239902345788506]
	TIME [epoch: 5.73 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5427695568467168		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.5427695568467168 | validation: 0.2912570798759942]
	TIME [epoch: 5.73 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4999520863867207		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.4999520863867207 | validation: 0.28042922019360433]
	TIME [epoch: 5.73 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4891106933507537		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.4891106933507537 | validation: 0.2655828487051258]
	TIME [epoch: 5.77 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.498430796928931		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.498430796928931 | validation: 0.32336470386472976]
	TIME [epoch: 5.73 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5601173138911282		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.5601173138911282 | validation: 0.2403476991695433]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_715.pth
	Model improved!!!
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47948094547615844		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.47948094547615844 | validation: 0.26135635133184093]
	TIME [epoch: 5.73 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47847191231606584		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.47847191231606584 | validation: 0.24428335809682597]
	TIME [epoch: 5.72 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49171091537013273		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.49171091537013273 | validation: 0.3723908599800208]
	TIME [epoch: 5.72 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5559907731577032		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.5559907731577032 | validation: 0.25041799311331764]
	TIME [epoch: 5.73 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5248592378512		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.5248592378512 | validation: 0.31488803597379]
	TIME [epoch: 5.75 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6087699214892387		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.6087699214892387 | validation: 0.3364090479361282]
	TIME [epoch: 5.73 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48325161979041564		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.48325161979041564 | validation: 0.4006197131553354]
	TIME [epoch: 5.72 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5696605317419702		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.5696605317419702 | validation: 0.21851838852084426]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_723.pth
	Model improved!!!
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4932902176808704		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.4932902176808704 | validation: 0.22957771142308986]
	TIME [epoch: 5.73 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5042460559071111		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.5042460559071111 | validation: 0.2481202033787208]
	TIME [epoch: 5.72 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4613507611957533		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.4613507611957533 | validation: 0.3830322449484632]
	TIME [epoch: 5.76 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5865949517846365		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.5865949517846365 | validation: 0.27571243959079467]
	TIME [epoch: 5.72 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5430330697544011		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.5430330697544011 | validation: 0.3103862291254029]
	TIME [epoch: 5.72 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189294243453744		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.5189294243453744 | validation: 0.34599069797886584]
	TIME [epoch: 5.72 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.475848319639523		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.475848319639523 | validation: 0.2637209147378353]
	TIME [epoch: 5.72 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5272446541569479		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.5272446541569479 | validation: 0.32274105290580474]
	TIME [epoch: 5.72 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4746011658066105		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.4746011658066105 | validation: 0.2573179382909341]
	TIME [epoch: 5.75 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4686643985196723		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.4686643985196723 | validation: 0.2722148103972668]
	TIME [epoch: 5.74 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46511607710495956		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.46511607710495956 | validation: 0.40111994707413057]
	TIME [epoch: 5.73 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5237810464046887		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.5237810464046887 | validation: 0.4464131665894934]
	TIME [epoch: 5.72 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5076094048073959		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.5076094048073959 | validation: 0.23641597904454223]
	TIME [epoch: 5.73 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4905438782800189		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.4905438782800189 | validation: 0.2658148466963923]
	TIME [epoch: 5.72 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4804319402236197		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.4804319402236197 | validation: 0.2769419618975486]
	TIME [epoch: 5.73 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44805454571126313		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.44805454571126313 | validation: 0.3224413300545335]
	TIME [epoch: 5.76 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4626324394614918		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.4626324394614918 | validation: 0.33476793899360063]
	TIME [epoch: 5.73 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5372880656108348		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.5372880656108348 | validation: 0.28107370785072966]
	TIME [epoch: 5.72 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4695183648777384		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.4695183648777384 | validation: 0.2645408086212317]
	TIME [epoch: 5.73 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301969715872632		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.5301969715872632 | validation: 0.41612321745372727]
	TIME [epoch: 5.72 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4994026725000562		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.4994026725000562 | validation: 0.3758551065257943]
	TIME [epoch: 5.73 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.488071799899637		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.488071799899637 | validation: 0.2789205372041193]
	TIME [epoch: 5.75 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45379625924914657		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.45379625924914657 | validation: 0.31005286977574165]
	TIME [epoch: 5.74 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4528667460684336		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.4528667460684336 | validation: 0.3036953129509066]
	TIME [epoch: 5.73 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5134106335322789		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.5134106335322789 | validation: 0.3672023962665679]
	TIME [epoch: 5.72 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5695573917284019		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.5695573917284019 | validation: 0.3668454411239074]
	TIME [epoch: 5.72 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5699002959191255		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.5699002959191255 | validation: 0.3839186886658865]
	TIME [epoch: 5.72 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5303760739639567		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.5303760739639567 | validation: 0.3337868877189152]
	TIME [epoch: 5.72 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.591079928290899		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.591079928290899 | validation: 0.2873509780117323]
	TIME [epoch: 5.76 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46966518273547025		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.46966518273547025 | validation: 0.2542060882460898]
	TIME [epoch: 5.73 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6257181967669139		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.6257181967669139 | validation: 0.2700907647371521]
	TIME [epoch: 5.73 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5115085701538029		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.5115085701538029 | validation: 0.43944763704186485]
	TIME [epoch: 5.72 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49340042810689744		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.49340042810689744 | validation: 0.3114629236440586]
	TIME [epoch: 5.72 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269760308244078		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.5269760308244078 | validation: 0.26376689106675755]
	TIME [epoch: 5.72 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4879060479086017		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.4879060479086017 | validation: 0.28501890262366814]
	TIME [epoch: 5.76 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4445837163482693		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.4445837163482693 | validation: 0.24393295760347716]
	TIME [epoch: 5.74 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4538688444797191		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.4538688444797191 | validation: 0.2409534267405636]
	TIME [epoch: 5.72 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5046545560904672		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.5046545560904672 | validation: 0.27617358473397935]
	TIME [epoch: 5.72 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46822190354914844		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.46822190354914844 | validation: 0.31423303378027834]
	TIME [epoch: 5.72 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.517901521235688		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.517901521235688 | validation: 0.6375455952791029]
	TIME [epoch: 5.72 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5912747657668418		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.5912747657668418 | validation: 0.3025301742481012]
	TIME [epoch: 5.72 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399394524349225		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.5399394524349225 | validation: 0.27304257620073913]
	TIME [epoch: 5.76 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4543739141393236		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.4543739141393236 | validation: 0.25021605214722564]
	TIME [epoch: 5.73 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46776615627965856		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.46776615627965856 | validation: 0.27380539109551927]
	TIME [epoch: 5.73 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5850801221942488		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.5850801221942488 | validation: 0.26944398561132205]
	TIME [epoch: 5.72 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48982756619899265		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.48982756619899265 | validation: 0.28494152752243396]
	TIME [epoch: 5.72 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4534179767175321		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.4534179767175321 | validation: 0.2805247794616524]
	TIME [epoch: 5.73 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4960421915284948		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.4960421915284948 | validation: 0.26858344541288987]
	TIME [epoch: 5.75 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4832319710426459		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.4832319710426459 | validation: 0.25140439207896675]
	TIME [epoch: 5.74 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4967946491927815		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.4967946491927815 | validation: 0.25043970360614715]
	TIME [epoch: 5.73 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4515876448928447		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.4515876448928447 | validation: 0.2799956921587928]
	TIME [epoch: 5.72 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4684785417902977		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.4684785417902977 | validation: 0.2739135054734732]
	TIME [epoch: 5.73 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.442817246732256		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.442817246732256 | validation: 0.24647559282962694]
	TIME [epoch: 5.72 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46711105678329645		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.46711105678329645 | validation: 0.29341108903007396]
	TIME [epoch: 5.72 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112613370709331		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.5112613370709331 | validation: 0.2595314248600341]
	TIME [epoch: 5.76 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4648072794203182		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.4648072794203182 | validation: 0.28632374146341855]
	TIME [epoch: 5.72 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49860302745198404		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.49860302745198404 | validation: 0.28070370815078904]
	TIME [epoch: 5.72 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43507506625631137		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.43507506625631137 | validation: 0.2990620038827569]
	TIME [epoch: 5.72 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.472154895129712		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.472154895129712 | validation: 0.23422649146922056]
	TIME [epoch: 5.72 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46285035898319227		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.46285035898319227 | validation: 0.38584360514565064]
	TIME [epoch: 5.73 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5286795079093373		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.5286795079093373 | validation: 0.316223596255192]
	TIME [epoch: 5.75 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44447478055813794		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.44447478055813794 | validation: 0.249525425918387]
	TIME [epoch: 5.74 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4660276217308284		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.4660276217308284 | validation: 0.4009152975568573]
	TIME [epoch: 5.73 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5883446138538894		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.5883446138538894 | validation: 0.3054294663505693]
	TIME [epoch: 5.72 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5589164096977504		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.5589164096977504 | validation: 0.24635982726687694]
	TIME [epoch: 5.72 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44749345111832084		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.44749345111832084 | validation: 0.301913795439637]
	TIME [epoch: 5.73 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43489897613303335		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.43489897613303335 | validation: 0.2474517649933271]
	TIME [epoch: 5.73 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4637938227227175		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.4637938227227175 | validation: 0.31987868388134416]
	TIME [epoch: 5.78 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5337970811823833		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.5337970811823833 | validation: 0.22634540140961512]
	TIME [epoch: 5.75 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4567208083948914		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.4567208083948914 | validation: 0.22490208024668307]
	TIME [epoch: 5.74 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4617374206217816		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.4617374206217816 | validation: 0.24970213488037107]
	TIME [epoch: 5.73 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43971905986772275		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.43971905986772275 | validation: 0.2497643343513348]
	TIME [epoch: 5.74 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46044104228737875		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.46044104228737875 | validation: 0.26056964244739084]
	TIME [epoch: 5.74 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4741340635883119		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.4741340635883119 | validation: 0.3126927359825214]
	TIME [epoch: 5.77 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46310273349040987		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.46310273349040987 | validation: 0.30462465569759245]
	TIME [epoch: 5.75 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5232156004276313		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.5232156004276313 | validation: 0.23647430964837196]
	TIME [epoch: 5.74 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4537283722524906		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.4537283722524906 | validation: 0.2484362011802751]
	TIME [epoch: 5.74 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44680025755481473		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.44680025755481473 | validation: 0.25586578522722275]
	TIME [epoch: 5.73 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45091263259521785		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.45091263259521785 | validation: 0.2644372217432111]
	TIME [epoch: 5.74 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4623444213337813		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.4623444213337813 | validation: 0.2243331441613989]
	TIME [epoch: 5.73 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43890931426992047		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.43890931426992047 | validation: 0.264841217488177]
	TIME [epoch: 5.78 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4652978109234501		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.4652978109234501 | validation: 0.2211666998595608]
	TIME [epoch: 5.75 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46676823673182305		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.46676823673182305 | validation: 0.2792682708075293]
	TIME [epoch: 5.74 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4699426818158634		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.4699426818158634 | validation: 0.2830729036331831]
	TIME [epoch: 5.73 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.532506739178779		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.532506739178779 | validation: 0.2612858171589739]
	TIME [epoch: 5.73 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41954620337680515		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.41954620337680515 | validation: 0.21908047963891666]
	TIME [epoch: 5.73 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44787582646217855		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.44787582646217855 | validation: 0.28500614058898294]
	TIME [epoch: 5.75 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45435442124766146		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.45435442124766146 | validation: 0.2717212757188196]
	TIME [epoch: 5.74 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5030471010005109		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.5030471010005109 | validation: 0.21372316864253513]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_812.pth
	Model improved!!!
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4588838010636007		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.4588838010636007 | validation: 0.5713375470559722]
	TIME [epoch: 5.73 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5483618312084103		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.5483618312084103 | validation: 0.225776172661188]
	TIME [epoch: 5.73 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43707186396736886		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.43707186396736886 | validation: 0.21992200646817314]
	TIME [epoch: 5.73 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42999481341353585		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.42999481341353585 | validation: 0.21092668422853655]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_816.pth
	Model improved!!!
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4371675926192642		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.4371675926192642 | validation: 0.25352175592815696]
	TIME [epoch: 5.75 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.434380687494687		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.434380687494687 | validation: 0.23827082350129705]
	TIME [epoch: 5.72 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4172889666889954		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.4172889666889954 | validation: 0.2940774354324408]
	TIME [epoch: 5.72 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5575354191053896		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.5575354191053896 | validation: 0.26810393093779517]
	TIME [epoch: 5.72 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516271866720134		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.516271866720134 | validation: 0.22400539193487354]
	TIME [epoch: 5.72 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42044755456029714		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.42044755456029714 | validation: 0.28563641326603284]
	TIME [epoch: 5.72 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4518117358482949		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.4518117358482949 | validation: 0.24717008976234028]
	TIME [epoch: 5.75 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4621802080971301		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.4621802080971301 | validation: 0.2537935967452158]
	TIME [epoch: 5.73 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4371444234538012		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.4371444234538012 | validation: 0.22485013840516613]
	TIME [epoch: 5.72 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4083903750556027		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.4083903750556027 | validation: 0.3093166965825346]
	TIME [epoch: 5.72 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4756111235960484		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.4756111235960484 | validation: 0.32230523316492254]
	TIME [epoch: 5.71 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48104973941648377		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.48104973941648377 | validation: 0.2959974731925098]
	TIME [epoch: 5.72 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4433894576595888		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.4433894576595888 | validation: 0.25587080529527234]
	TIME [epoch: 5.73 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4705110339377979		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.4705110339377979 | validation: 0.2717369643675335]
	TIME [epoch: 5.75 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4267198044844012		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.4267198044844012 | validation: 0.24889101271150593]
	TIME [epoch: 5.72 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4550575716947643		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.4550575716947643 | validation: 0.22827343541426295]
	TIME [epoch: 5.71 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4556102332378671		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.4556102332378671 | validation: 0.21887843594583103]
	TIME [epoch: 5.72 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4390601726696792		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.4390601726696792 | validation: 0.35796675422593033]
	TIME [epoch: 5.72 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46230276031362794		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.46230276031362794 | validation: 0.23115404427000655]
	TIME [epoch: 5.72 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46119979229696784		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.46119979229696784 | validation: 0.25485453439880634]
	TIME [epoch: 5.75 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46864385537525244		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.46864385537525244 | validation: 0.24233292044369614]
	TIME [epoch: 5.72 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5630241217569785		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.5630241217569785 | validation: 0.2846791536193491]
	TIME [epoch: 5.72 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43745287004318856		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.43745287004318856 | validation: 0.3423904706163042]
	TIME [epoch: 5.72 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4629856666697262		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.4629856666697262 | validation: 0.21730298541507115]
	TIME [epoch: 5.72 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367275167044083		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.4367275167044083 | validation: 0.23749273722466452]
	TIME [epoch: 5.72 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44706774238758606		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.44706774238758606 | validation: 0.2917608752909732]
	TIME [epoch: 5.73 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4697558651971918		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.4697558651971918 | validation: 0.235066558589808]
	TIME [epoch: 5.74 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43290960942203116		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.43290960942203116 | validation: 0.28385090837049276]
	TIME [epoch: 5.72 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43864491087008856		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.43864491087008856 | validation: 0.259664093157823]
	TIME [epoch: 5.72 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4415605206632311		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.4415605206632311 | validation: 0.2705609895361763]
	TIME [epoch: 5.71 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4184071646731784		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.4184071646731784 | validation: 0.22229302277625415]
	TIME [epoch: 5.72 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42383133561835085		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.42383133561835085 | validation: 0.24949335287804147]
	TIME [epoch: 5.71 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4408420194129165		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.4408420194129165 | validation: 0.2277970153225018]
	TIME [epoch: 5.75 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4043639109576246		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.4043639109576246 | validation: 0.2320988468880244]
	TIME [epoch: 5.71 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4268195515717931		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.4268195515717931 | validation: 0.277139197041422]
	TIME [epoch: 5.71 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44629567084848804		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.44629567084848804 | validation: 0.2306449775063567]
	TIME [epoch: 5.71 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4320002064377376		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.4320002064377376 | validation: 0.2985244189802827]
	TIME [epoch: 5.71 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4211378951069633		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.4211378951069633 | validation: 0.291496743446526]
	TIME [epoch: 5.71 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4309413318896826		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.4309413318896826 | validation: 0.4911681827898394]
	TIME [epoch: 5.73 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5038870270087843		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.5038870270087843 | validation: 0.24519449218279363]
	TIME [epoch: 5.74 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4978888221627001		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.4978888221627001 | validation: 0.23601135361606546]
	TIME [epoch: 5.71 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4607923852903788		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.4607923852903788 | validation: 0.49286949266051466]
	TIME [epoch: 5.71 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48931019333079157		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.48931019333079157 | validation: 0.21661494021011973]
	TIME [epoch: 5.71 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40837320912191144		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.40837320912191144 | validation: 0.21720568899409246]
	TIME [epoch: 5.72 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4265602754306739		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.4265602754306739 | validation: 0.2974081526049588]
	TIME [epoch: 5.71 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43916322117534384		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.43916322117534384 | validation: 0.3972756474878338]
	TIME [epoch: 5.73 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5196282803951235		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.5196282803951235 | validation: 0.36117435591769015]
	TIME [epoch: 5.72 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47516697750016323		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.47516697750016323 | validation: 0.27225098095145783]
	TIME [epoch: 5.72 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40139964630455427		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.40139964630455427 | validation: 0.44617170464017863]
	TIME [epoch: 5.71 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.457226566883974		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.457226566883974 | validation: 0.27480729931654524]
	TIME [epoch: 5.72 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4294639949387597		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.4294639949387597 | validation: 0.323552464030717]
	TIME [epoch: 5.71 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4156572169320707		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.4156572169320707 | validation: 0.24339718558739004]
	TIME [epoch: 5.71 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43157537710552607		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.43157537710552607 | validation: 0.293168417872157]
	TIME [epoch: 5.75 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367084051954835		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.4367084051954835 | validation: 0.36774665268276396]
	TIME [epoch: 5.72 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41254364775351515		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.41254364775351515 | validation: 0.224286898837156]
	TIME [epoch: 5.71 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4147174489985772		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.4147174489985772 | validation: 0.32482634507923097]
	TIME [epoch: 5.72 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4453359034818545		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.4453359034818545 | validation: 0.23653896776966116]
	TIME [epoch: 5.72 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4307048314802516		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.4307048314802516 | validation: 0.2307022567307716]
	TIME [epoch: 5.72 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41971646327316303		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.41971646327316303 | validation: 0.2575175250712049]
	TIME [epoch: 5.75 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44318573393625715		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.44318573393625715 | validation: 0.24928069959699617]
	TIME [epoch: 5.72 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3936435723585171		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.3936435723585171 | validation: 0.25822772180934833]
	TIME [epoch: 5.72 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.470316073218768		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.470316073218768 | validation: 0.2201770779784024]
	TIME [epoch: 5.72 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40737362542221134		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.40737362542221134 | validation: 0.2167469211764375]
	TIME [epoch: 5.71 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.408669458962027		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.408669458962027 | validation: 0.22335176321167727]
	TIME [epoch: 5.72 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4224156146264883		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.4224156146264883 | validation: 0.23200039560968708]
	TIME [epoch: 5.71 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4038643607883058		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.4038643607883058 | validation: 0.3164113011691236]
	TIME [epoch: 5.76 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45697873063283023		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.45697873063283023 | validation: 0.23938163209778282]
	TIME [epoch: 5.72 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4746420829554869		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.4746420829554869 | validation: 0.22547118519680998]
	TIME [epoch: 5.71 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42719375223979594		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.42719375223979594 | validation: 0.2242471124938173]
	TIME [epoch: 5.71 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44674185204468037		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.44674185204468037 | validation: 0.22170637747543204]
	TIME [epoch: 5.71 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4332153660880832		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.4332153660880832 | validation: 0.26579377630750695]
	TIME [epoch: 5.71 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47753623050735117		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.47753623050735117 | validation: 0.2346624224711708]
	TIME [epoch: 5.74 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4315390626411991		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.4315390626411991 | validation: 0.2750880493590271]
	TIME [epoch: 5.72 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4343437089599359		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.4343437089599359 | validation: 0.34212453090862044]
	TIME [epoch: 5.73 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5395904496429769		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.5395904496429769 | validation: 0.20908167423389937]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_891.pth
	Model improved!!!
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4281116275132014		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.4281116275132014 | validation: 0.23735481350026139]
	TIME [epoch: 5.71 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42285921775283697		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.42285921775283697 | validation: 0.22192429001656608]
	TIME [epoch: 5.71 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45586679370112826		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.45586679370112826 | validation: 0.2891171939071306]
	TIME [epoch: 5.73 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41342930608009365		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.41342930608009365 | validation: 0.21086626574091413]
	TIME [epoch: 5.75 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41064003707129443		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.41064003707129443 | validation: 0.2413468803614441]
	TIME [epoch: 5.71 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4183172600402346		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.4183172600402346 | validation: 0.2210712586592608]
	TIME [epoch: 5.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42737511913658		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.42737511913658 | validation: 0.23667332148955322]
	TIME [epoch: 5.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918782376560951		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.3918782376560951 | validation: 0.20745568206601805]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_899.pth
	Model improved!!!
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3884157068450304		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.3884157068450304 | validation: 0.4613931578680882]
	TIME [epoch: 5.72 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.509380099180626		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.509380099180626 | validation: 0.2207881093809296]
	TIME [epoch: 5.76 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41507508961749084		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.41507508961749084 | validation: 0.2533124703039732]
	TIME [epoch: 5.73 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40175118595152304		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.40175118595152304 | validation: 0.21939197789022832]
	TIME [epoch: 5.72 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41317866714351315		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.41317866714351315 | validation: 0.25675640641895825]
	TIME [epoch: 5.72 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4380157903182357		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.4380157903182357 | validation: 0.24254723906951892]
	TIME [epoch: 5.73 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4077995604503561		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.4077995604503561 | validation: 0.2772321647305337]
	TIME [epoch: 5.72 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39852425791512996		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.39852425791512996 | validation: 0.2062957061662464]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_907.pth
	Model improved!!!
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43024336564633126		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.43024336564633126 | validation: 0.21669362823223912]
	TIME [epoch: 5.74 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39529720312179595		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.39529720312179595 | validation: 0.23347748097632987]
	TIME [epoch: 5.73 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.403054628750436		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.403054628750436 | validation: 0.3472952594575817]
	TIME [epoch: 5.72 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4440159244675758		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.4440159244675758 | validation: 0.22140012817689753]
	TIME [epoch: 5.71 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40908931510749436		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.40908931510749436 | validation: 0.3085731094636865]
	TIME [epoch: 5.72 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4845977527398082		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.4845977527398082 | validation: 0.25492361569495975]
	TIME [epoch: 5.72 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.454226154541734		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.454226154541734 | validation: 0.24738392505826856]
	TIME [epoch: 5.76 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4146233266278274		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.4146233266278274 | validation: 0.29267389192890864]
	TIME [epoch: 5.72 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40118945380099735		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.40118945380099735 | validation: 0.2119264464267614]
	TIME [epoch: 5.71 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40532224902599806		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.40532224902599806 | validation: 0.21482611608669408]
	TIME [epoch: 5.71 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4584894753239501		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.4584894753239501 | validation: 0.3360093412341836]
	TIME [epoch: 5.72 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42850463719737397		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.42850463719737397 | validation: 0.2753655721736852]
	TIME [epoch: 5.71 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4255466769510555		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.4255466769510555 | validation: 0.25588746286246067]
	TIME [epoch: 5.73 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4112149569459705		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.4112149569459705 | validation: 0.24937979456737006]
	TIME [epoch: 5.74 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4191198147461614		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.4191198147461614 | validation: 0.19884254396047535]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_922.pth
	Model improved!!!
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4201828577061462		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.4201828577061462 | validation: 0.20235037376966322]
	TIME [epoch: 5.72 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4257772166134195		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.4257772166134195 | validation: 0.29975818866560433]
	TIME [epoch: 5.72 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4236860680890223		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.4236860680890223 | validation: 0.22224125592679117]
	TIME [epoch: 5.72 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42645087549736604		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.42645087549736604 | validation: 0.23014580438204085]
	TIME [epoch: 5.72 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3887360536631466		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.3887360536631466 | validation: 0.19838840954674353]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_927.pth
	Model improved!!!
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3963048749038954		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.3963048749038954 | validation: 0.20194705497572835]
	TIME [epoch: 5.73 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39674146018381495		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.39674146018381495 | validation: 0.2136499318160158]
	TIME [epoch: 5.72 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4018377788014894		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.4018377788014894 | validation: 0.2330273815124782]
	TIME [epoch: 5.71 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41829255069400695		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.41829255069400695 | validation: 0.20473929566392432]
	TIME [epoch: 5.72 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4122387236413956		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.4122387236413956 | validation: 0.26740781683291637]
	TIME [epoch: 5.72 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.441382113096233		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.441382113096233 | validation: 0.20826348217939056]
	TIME [epoch: 5.75 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38831476168729995		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.38831476168729995 | validation: 0.26035035030513015]
	TIME [epoch: 5.72 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4237741474654663		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.4237741474654663 | validation: 0.24970527093380127]
	TIME [epoch: 5.72 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4320198403164406		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.4320198403164406 | validation: 0.3021923262645578]
	TIME [epoch: 5.72 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43044621819558604		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.43044621819558604 | validation: 0.28142131423671773]
	TIME [epoch: 5.72 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4012315697253414		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.4012315697253414 | validation: 0.29617215281746107]
	TIME [epoch: 5.72 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44480160005724867		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.44480160005724867 | validation: 0.2904764073963845]
	TIME [epoch: 5.71 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4507774226407981		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.4507774226407981 | validation: 0.2371562054540208]
	TIME [epoch: 5.76 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3859193659576085		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.3859193659576085 | validation: 0.3425058179572983]
	TIME [epoch: 5.72 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4208266124113434		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.4208266124113434 | validation: 0.2954222514764164]
	TIME [epoch: 5.72 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4076105428359831		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.4076105428359831 | validation: 0.20157303040637053]
	TIME [epoch: 5.71 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4099189159356383		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.4099189159356383 | validation: 0.26560677482862277]
	TIME [epoch: 5.7 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4157088181282341		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.4157088181282341 | validation: 0.23564755744771104]
	TIME [epoch: 5.71 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43836230230510953		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.43836230230510953 | validation: 0.2874332522064136]
	TIME [epoch: 5.73 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40159634963524743		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.40159634963524743 | validation: 0.2686254303911783]
	TIME [epoch: 5.72 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4346074010427893		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.4346074010427893 | validation: 0.23804258058273384]
	TIME [epoch: 5.71 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40564269646604606		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.40564269646604606 | validation: 0.29796238891704563]
	TIME [epoch: 5.71 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39914623868578086		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.39914623868578086 | validation: 0.2632161554486392]
	TIME [epoch: 5.72 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41755531750608		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.41755531750608 | validation: 0.2087988880078555]
	TIME [epoch: 5.71 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4344662913719707		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.4344662913719707 | validation: 0.2964362033725924]
	TIME [epoch: 5.71 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41804176744568156		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.41804176744568156 | validation: 0.20170822207297734]
	TIME [epoch: 5.75 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38901979060577196		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.38901979060577196 | validation: 0.23114066565845978]
	TIME [epoch: 5.72 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42858365114226094		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.42858365114226094 | validation: 0.20485595271650142]
	TIME [epoch: 5.71 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4222533014016442		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.4222533014016442 | validation: 0.22577778905866985]
	TIME [epoch: 5.72 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4113111920764311		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.4113111920764311 | validation: 0.2121981314162123]
	TIME [epoch: 5.72 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42151029809055557		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.42151029809055557 | validation: 0.22621268945652712]
	TIME [epoch: 5.71 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4148999679207698		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.4148999679207698 | validation: 0.20782990415117047]
	TIME [epoch: 5.75 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4040636238078747		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.4040636238078747 | validation: 0.24849455045671207]
	TIME [epoch: 5.73 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.408362702441506		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.408362702441506 | validation: 0.20089122350961572]
	TIME [epoch: 5.72 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42054428963562773		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.42054428963562773 | validation: 0.20181797057215417]
	TIME [epoch: 5.71 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42760934001531714		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.42760934001531714 | validation: 0.21573461851153986]
	TIME [epoch: 5.71 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4219579740141456		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.4219579740141456 | validation: 0.30446587191854707]
	TIME [epoch: 5.71 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40625793688520057		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.40625793688520057 | validation: 0.23500988278550636]
	TIME [epoch: 5.71 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42485360169259323		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.42485360169259323 | validation: 0.28899160998493784]
	TIME [epoch: 5.75 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43842570782381607		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.43842570782381607 | validation: 0.2024212553729458]
	TIME [epoch: 5.72 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3961349151843754		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.3961349151843754 | validation: 0.2040058573034859]
	TIME [epoch: 5.72 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39468355176567627		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.39468355176567627 | validation: 0.2334957070579134]
	TIME [epoch: 5.71 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4276293328895363		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.4276293328895363 | validation: 0.25420977092503594]
	TIME [epoch: 5.72 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3924872499505975		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.3924872499505975 | validation: 0.19638821931913122]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_971.pth
	Model improved!!!
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925538767435279		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.3925538767435279 | validation: 0.19012043217618613]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_972.pth
	Model improved!!!
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4060728271993942		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.4060728271993942 | validation: 0.24179690559458802]
	TIME [epoch: 5.74 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43425837472417306		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.43425837472417306 | validation: 0.22549528294749166]
	TIME [epoch: 5.73 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4266654321892452		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.4266654321892452 | validation: 0.23675156861130464]
	TIME [epoch: 5.73 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41719540170947034		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.41719540170947034 | validation: 0.23000417778358284]
	TIME [epoch: 5.73 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43453178560635775		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.43453178560635775 | validation: 0.20415568546182067]
	TIME [epoch: 5.73 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41015234171041304		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.41015234171041304 | validation: 0.31537089197302914]
	TIME [epoch: 5.74 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4143149987657421		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.4143149987657421 | validation: 0.19910214572114351]
	TIME [epoch: 5.76 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3871951109390869		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.3871951109390869 | validation: 0.3134157981373901]
	TIME [epoch: 5.73 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4554387734048498		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.4554387734048498 | validation: 0.2068943856343764]
	TIME [epoch: 5.73 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4138986950179814		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.4138986950179814 | validation: 0.23821546657406964]
	TIME [epoch: 5.73 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.390283022983269		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.390283022983269 | validation: 0.21356271879646252]
	TIME [epoch: 5.73 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3891371609289405		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.3891371609289405 | validation: 0.2026738173074525]
	TIME [epoch: 5.73 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3979066403485944		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.3979066403485944 | validation: 0.22886330435356847]
	TIME [epoch: 5.77 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42361876826809175		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.42361876826809175 | validation: 0.21817405900389072]
	TIME [epoch: 5.73 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40758720710327107		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.40758720710327107 | validation: 0.19479953525111696]
	TIME [epoch: 5.73 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39721709242768427		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.39721709242768427 | validation: 0.22685815634402495]
	TIME [epoch: 5.73 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39901793354303156		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.39901793354303156 | validation: 0.2436371278129607]
	TIME [epoch: 5.73 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40657589184888615		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.40657589184888615 | validation: 0.2060688874541144]
	TIME [epoch: 5.73 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39807356156189133		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.39807356156189133 | validation: 0.3142069307825267]
	TIME [epoch: 5.74 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4135518247997404		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.4135518247997404 | validation: 0.2451194197349514]
	TIME [epoch: 5.76 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4207689427977871		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.4207689427977871 | validation: 0.2745859830728692]
	TIME [epoch: 5.73 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39494765725786873		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.39494765725786873 | validation: 0.297273621536025]
	TIME [epoch: 5.73 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39592936364665965		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.39592936364665965 | validation: 0.24932824091385275]
	TIME [epoch: 5.73 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4378751983414751		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.4378751983414751 | validation: 0.4346061561373649]
	TIME [epoch: 5.73 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4558009025371095		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.4558009025371095 | validation: 0.20653822022095233]
	TIME [epoch: 5.73 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3873879933605162		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.3873879933605162 | validation: 0.18824051520757032]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_998.pth
	Model improved!!!
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3798187477700751		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.3798187477700751 | validation: 0.23166523639851289]
	TIME [epoch: 5.73 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409366139778624		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.409366139778624 | validation: 0.2196898820235523]
	TIME [epoch: 5.72 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39282244104434183		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.39282244104434183 | validation: 0.224054988793323]
	TIME [epoch: 5.72 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3938427017923983		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.3938427017923983 | validation: 0.20795162218167185]
	TIME [epoch: 5.73 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4221631590375131		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.4221631590375131 | validation: 0.24478157960737673]
	TIME [epoch: 5.73 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3881975354352948		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.3881975354352948 | validation: 0.2926950487662495]
	TIME [epoch: 5.74 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39676107131565286		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.39676107131565286 | validation: 0.2950273717489676]
	TIME [epoch: 5.75 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48985655004487516		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.48985655004487516 | validation: 0.21877517741300628]
	TIME [epoch: 5.73 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39123384964050556		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.39123384964050556 | validation: 0.2084826664290409]
	TIME [epoch: 5.73 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39170863898972474		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.39170863898972474 | validation: 0.22560526835885167]
	TIME [epoch: 5.72 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4769434172593009		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.4769434172593009 | validation: 0.20360184386789523]
	TIME [epoch: 5.73 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38817739584295474		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.38817739584295474 | validation: 0.20696288526983722]
	TIME [epoch: 5.72 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38413089794138455		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.38413089794138455 | validation: 0.29498940983678196]
	TIME [epoch: 5.76 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3996030576062088		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.3996030576062088 | validation: 0.23478809356486857]
	TIME [epoch: 5.73 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3994610460335105		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.3994610460335105 | validation: 0.19829829386779246]
	TIME [epoch: 5.73 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3955951947350629		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.3955951947350629 | validation: 0.22756471669396694]
	TIME [epoch: 5.72 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45317790611548797		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.45317790611548797 | validation: 0.21942449019099142]
	TIME [epoch: 5.72 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765636972019326		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.3765636972019326 | validation: 0.2055582012782475]
	TIME [epoch: 5.73 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.387456999772044		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.387456999772044 | validation: 0.2451045198805699]
	TIME [epoch: 5.74 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40737854166206233		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.40737854166206233 | validation: 0.19286575957000282]
	TIME [epoch: 5.75 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3841128839733018		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.3841128839733018 | validation: 0.19475826230183058]
	TIME [epoch: 5.73 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40440916765088153		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.40440916765088153 | validation: 0.2258927482031993]
	TIME [epoch: 5.72 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4028604814371779		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.4028604814371779 | validation: 0.23297567095460006]
	TIME [epoch: 5.72 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41506238266090434		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.41506238266090434 | validation: 0.31319510193527345]
	TIME [epoch: 5.72 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4094329202985941		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.4094329202985941 | validation: 0.20730664072545188]
	TIME [epoch: 5.73 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40138329423287356		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.40138329423287356 | validation: 0.20694184014984174]
	TIME [epoch: 5.76 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38690655978315386		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.38690655978315386 | validation: 0.24185251943568958]
	TIME [epoch: 5.73 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38692994690557025		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.38692994690557025 | validation: 0.3471414828600554]
	TIME [epoch: 5.72 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42137012924672673		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.42137012924672673 | validation: 0.23548861963877854]
	TIME [epoch: 5.73 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37321370116048036		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.37321370116048036 | validation: 0.23592258519566883]
	TIME [epoch: 5.72 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3737045703287333		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.3737045703287333 | validation: 0.20136136512222044]
	TIME [epoch: 5.73 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3749099906011508		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.3749099906011508 | validation: 0.21077261361188065]
	TIME [epoch: 5.75 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40412584856426614		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.40412584856426614 | validation: 0.29081372293213004]
	TIME [epoch: 5.74 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38222095865149325		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.38222095865149325 | validation: 0.21090232627316816]
	TIME [epoch: 5.73 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38363937230101786		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.38363937230101786 | validation: 0.22653429498001046]
	TIME [epoch: 5.72 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37821885878380873		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.37821885878380873 | validation: 0.24665975831356085]
	TIME [epoch: 5.72 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3744576388348512		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.3744576388348512 | validation: 0.21750308598589876]
	TIME [epoch: 5.73 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38411535188273804		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.38411535188273804 | validation: 0.2918670381648261]
	TIME [epoch: 5.72 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3964811807223138		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.3964811807223138 | validation: 0.2030219431539465]
	TIME [epoch: 5.76 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38656106392571155		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.38656106392571155 | validation: 0.20479004095071987]
	TIME [epoch: 5.73 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3760072389788729		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.3760072389788729 | validation: 0.2156478628690928]
	TIME [epoch: 5.72 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37926449362531206		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.37926449362531206 | validation: 0.20280115730547216]
	TIME [epoch: 5.72 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37358590992003293		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.37358590992003293 | validation: 0.27200501596480503]
	TIME [epoch: 5.72 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3866938890826764		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.3866938890826764 | validation: 0.19437446462015218]
	TIME [epoch: 5.73 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39081856956284466		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.39081856956284466 | validation: 0.19905518962600327]
	TIME [epoch: 5.75 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3955655047501249		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.3955655047501249 | validation: 0.21397428856909614]
	TIME [epoch: 5.74 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3833609101826503		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.3833609101826503 | validation: 0.22701550387736538]
	TIME [epoch: 5.73 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39311695190865004		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.39311695190865004 | validation: 0.23877004910361202]
	TIME [epoch: 5.72 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37404728255668074		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.37404728255668074 | validation: 0.23139292221396385]
	TIME [epoch: 5.72 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42097855011823077		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.42097855011823077 | validation: 0.19637532842705052]
	TIME [epoch: 5.72 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3842439408364491		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.3842439408364491 | validation: 0.19394893994125476]
	TIME [epoch: 5.72 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3710586461880984		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.3710586461880984 | validation: 0.19415069601213084]
	TIME [epoch: 5.76 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38801395139920486		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.38801395139920486 | validation: 0.21735823690401712]
	TIME [epoch: 5.73 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40484246487913195		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.40484246487913195 | validation: 0.2262689046534467]
	TIME [epoch: 5.72 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38470936866823097		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.38470936866823097 | validation: 0.2482461483350717]
	TIME [epoch: 5.72 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39166503704611494		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.39166503704611494 | validation: 0.2175214090521304]
	TIME [epoch: 5.71 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39518223797959035		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.39518223797959035 | validation: 0.22012226348368585]
	TIME [epoch: 5.71 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933318481681752		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.3933318481681752 | validation: 0.23145295233211807]
	TIME [epoch: 5.74 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39781486748094574		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.39781486748094574 | validation: 0.22257315863390306]
	TIME [epoch: 5.73 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3703374199948762		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.3703374199948762 | validation: 0.281160386853165]
	TIME [epoch: 5.72 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38921092903635657		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.38921092903635657 | validation: 0.21528103248964114]
	TIME [epoch: 5.72 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4221004687671096		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.4221004687671096 | validation: 0.26140161375721704]
	TIME [epoch: 5.72 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3954095985427868		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.3954095985427868 | validation: 0.1859686520238701]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_1061.pth
	Model improved!!!
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3793648502696824		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.3793648502696824 | validation: 0.2037187049958455]
	TIME [epoch: 5.72 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889755302079954		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.3889755302079954 | validation: 0.1874142677153293]
	TIME [epoch: 5.75 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3727243098087181		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.3727243098087181 | validation: 0.19586638383414978]
	TIME [epoch: 5.71 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37965253867274995		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.37965253867274995 | validation: 0.2678453446607547]
	TIME [epoch: 5.71 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3977215238635481		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.3977215238635481 | validation: 0.19313681642744335]
	TIME [epoch: 5.71 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3829103801691906		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.3829103801691906 | validation: 0.18980849360802773]
	TIME [epoch: 5.72 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39768785534545736		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.39768785534545736 | validation: 0.20003359806158724]
	TIME [epoch: 5.71 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4232701190108231		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.4232701190108231 | validation: 0.20820709423945574]
	TIME [epoch: 5.74 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39613452973361024		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.39613452973361024 | validation: 0.21440512509539844]
	TIME [epoch: 5.72 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37232389448568354		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.37232389448568354 | validation: 0.20342153198256036]
	TIME [epoch: 5.71 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3716119527598265		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.3716119527598265 | validation: 0.19124350961158548]
	TIME [epoch: 5.71 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3800667515930455		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.3800667515930455 | validation: 0.20498712316720602]
	TIME [epoch: 5.71 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39448963001889126		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.39448963001889126 | validation: 0.20459917103535802]
	TIME [epoch: 5.71 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4128236956751229		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.4128236956751229 | validation: 0.19929406858173468]
	TIME [epoch: 5.71 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37183756319035455		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.37183756319035455 | validation: 0.2292518602309242]
	TIME [epoch: 5.75 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39079036412223445		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.39079036412223445 | validation: 0.18613793922977437]
	TIME [epoch: 5.72 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3993211389380843		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.3993211389380843 | validation: 0.2372390025185501]
	TIME [epoch: 5.71 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4131170987492008		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.4131170987492008 | validation: 0.2198409603186503]
	TIME [epoch: 5.71 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36551017261265584		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.36551017261265584 | validation: 0.20786177846835976]
	TIME [epoch: 5.72 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3693655772463802		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.3693655772463802 | validation: 0.22127272660555555]
	TIME [epoch: 5.71 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43160384118941225		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.43160384118941225 | validation: 0.2114338698208557]
	TIME [epoch: 5.74 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37085674068575614		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.37085674068575614 | validation: 0.21483612679618042]
	TIME [epoch: 5.72 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37066588052928856		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.37066588052928856 | validation: 0.20063081623776047]
	TIME [epoch: 5.71 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3867177022627496		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.3867177022627496 | validation: 0.23527425080640144]
	TIME [epoch: 5.73 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3681563339948489		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.3681563339948489 | validation: 0.21123311781316814]
	TIME [epoch: 5.71 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38759923280667874		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.38759923280667874 | validation: 0.20723143927788065]
	TIME [epoch: 5.71 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37256146907489707		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.37256146907489707 | validation: 0.19949996452914917]
	TIME [epoch: 5.71 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36369206888793465		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.36369206888793465 | validation: 0.21829888626448501]
	TIME [epoch: 5.75 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36854048083251545		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.36854048083251545 | validation: 0.2595724761345934]
	TIME [epoch: 5.71 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37659401643288554		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.37659401643288554 | validation: 0.2024931016809581]
	TIME [epoch: 5.71 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3797579483173069		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.3797579483173069 | validation: 0.2476645223608364]
	TIME [epoch: 5.71 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3774522402429024		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.3774522402429024 | validation: 0.2028535319758724]
	TIME [epoch: 5.71 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695675991601052		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.3695675991601052 | validation: 0.2272953659914767]
	TIME [epoch: 5.71 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3833303224021064		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.3833303224021064 | validation: 0.3112025437918784]
	TIME [epoch: 5.74 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38809442580766323		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.38809442580766323 | validation: 0.24318754073094057]
	TIME [epoch: 5.72 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40590378269148597		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.40590378269148597 | validation: 0.21744966277146602]
	TIME [epoch: 5.71 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36310510667063123		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.36310510667063123 | validation: 0.20132868632002052]
	TIME [epoch: 5.71 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3874205872573589		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.3874205872573589 | validation: 0.2704319440839627]
	TIME [epoch: 5.71 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46296481872028017		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.46296481872028017 | validation: 0.23316310941264476]
	TIME [epoch: 5.72 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3764605139446348		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.3764605139446348 | validation: 0.21495009891316122]
	TIME [epoch: 5.71 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3661372182945768		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.3661372182945768 | validation: 0.21566404682746498]
	TIME [epoch: 5.75 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692312030811745		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.3692312030811745 | validation: 0.24359580166765493]
	TIME [epoch: 5.71 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37827700363627		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.37827700363627 | validation: 0.20126566784748626]
	TIME [epoch: 5.71 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36649524520131016		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.36649524520131016 | validation: 0.22633269318999985]
	TIME [epoch: 5.71 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41752053892712715		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.41752053892712715 | validation: 0.3442641716451644]
	TIME [epoch: 5.71 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39133135610011704		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.39133135610011704 | validation: 0.22773431703250674]
	TIME [epoch: 5.71 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38629988540059906		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.38629988540059906 | validation: 0.20777938592441256]
	TIME [epoch: 5.73 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3850347366528745		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.3850347366528745 | validation: 0.30161092910971776]
	TIME [epoch: 5.73 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38550579464371126		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.38550579464371126 | validation: 0.24851324736670571]
	TIME [epoch: 5.71 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39169019153643403		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.39169019153643403 | validation: 0.23642577463254932]
	TIME [epoch: 5.72 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3818448876855683		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.3818448876855683 | validation: 0.2208939427316571]
	TIME [epoch: 5.71 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37392161074882513		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.37392161074882513 | validation: 0.20923435258047018]
	TIME [epoch: 5.71 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3775077754662709		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.3775077754662709 | validation: 0.19812089226350488]
	TIME [epoch: 5.71 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4255865876203382		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.4255865876203382 | validation: 0.43956421382334315]
	TIME [epoch: 5.75 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43845547969173043		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.43845547969173043 | validation: 0.1961911804515587]
	TIME [epoch: 5.71 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37773898221844115		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.37773898221844115 | validation: 0.1982536263322924]
	TIME [epoch: 5.71 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38309894983498005		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.38309894983498005 | validation: 0.193148707953754]
	TIME [epoch: 5.71 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3814529159107119		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.3814529159107119 | validation: 0.23450215785695122]
	TIME [epoch: 5.72 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36552618111374835		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.36552618111374835 | validation: 0.19752295942645468]
	TIME [epoch: 5.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.376911905955507		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.376911905955507 | validation: 0.20810271600351662]
	TIME [epoch: 5.75 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3733887649012041		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.3733887649012041 | validation: 0.21199051944506692]
	TIME [epoch: 5.72 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736964232338821		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.3736964232338821 | validation: 0.21154659015154373]
	TIME [epoch: 5.72 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36291073191017914		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.36291073191017914 | validation: 0.18436799369454293]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_1124.pth
	Model improved!!!
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3783576637879079		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.3783576637879079 | validation: 0.19162632834027038]
	TIME [epoch: 5.72 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36056455955073813		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.36056455955073813 | validation: 0.18663907894987916]
	TIME [epoch: 5.72 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38542082344946693		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.38542082344946693 | validation: 0.23953936449809482]
	TIME [epoch: 5.71 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37548162095947923		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.37548162095947923 | validation: 0.21348762636814506]
	TIME [epoch: 5.75 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706090481213597		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.3706090481213597 | validation: 0.2135541041654552]
	TIME [epoch: 5.71 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925118814297126		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.3925118814297126 | validation: 0.1876861709359696]
	TIME [epoch: 5.72 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36344602292064776		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.36344602292064776 | validation: 0.2386677108211309]
	TIME [epoch: 5.72 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37729821127830554		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.37729821127830554 | validation: 0.2029206769945111]
	TIME [epoch: 5.71 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36250151740030034		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.36250151740030034 | validation: 0.19933024495785406]
	TIME [epoch: 5.71 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3597772712157956		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.3597772712157956 | validation: 0.20067391214721814]
	TIME [epoch: 5.75 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3655540380393708		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.3655540380393708 | validation: 0.2056035484877247]
	TIME [epoch: 5.74 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38246786607888794		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.38246786607888794 | validation: 0.21799164945880273]
	TIME [epoch: 5.72 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3916954826393099		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.3916954826393099 | validation: 0.21429337743711216]
	TIME [epoch: 5.72 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.376242120905232		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.376242120905232 | validation: 0.2129842524801849]
	TIME [epoch: 5.72 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38043423122607417		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.38043423122607417 | validation: 0.2004666822915685]
	TIME [epoch: 5.72 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36238797866208333		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.36238797866208333 | validation: 0.24434341219398936]
	TIME [epoch: 5.71 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36764190039660755		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.36764190039660755 | validation: 0.2186528496449111]
	TIME [epoch: 5.77 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702829167745741		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.3702829167745741 | validation: 0.19131700596940376]
	TIME [epoch: 5.72 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3659709562170802		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.3659709562170802 | validation: 0.20319885175112165]
	TIME [epoch: 5.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3871680143093947		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.3871680143093947 | validation: 0.2015345341878144]
	TIME [epoch: 5.72 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36627705666297095		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.36627705666297095 | validation: 0.19251663528112686]
	TIME [epoch: 5.72 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37397261425489403		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.37397261425489403 | validation: 0.2613410249985468]
	TIME [epoch: 5.7 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3856610107142773		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.3856610107142773 | validation: 0.24810601015597228]
	TIME [epoch: 5.75 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36357424791047105		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.36357424791047105 | validation: 0.20839532782288644]
	TIME [epoch: 5.71 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3650126534305813		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.3650126534305813 | validation: 0.23345832872530672]
	TIME [epoch: 5.71 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36904001388480046		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.36904001388480046 | validation: 0.2625525809466306]
	TIME [epoch: 5.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3891612067825826		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.3891612067825826 | validation: 0.21350024088659805]
	TIME [epoch: 5.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38170171517255824		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.38170171517255824 | validation: 0.20393062969079467]
	TIME [epoch: 5.7 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37822159736628397		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.37822159736628397 | validation: 0.1990823330433831]
	TIME [epoch: 5.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3672620558204693		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.3672620558204693 | validation: 0.19667134692012148]
	TIME [epoch: 5.74 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36538728941695514		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.36538728941695514 | validation: 0.2162569026426761]
	TIME [epoch: 5.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3563992176175022		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.3563992176175022 | validation: 0.2335535613524646]
	TIME [epoch: 5.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36703884436398027		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.36703884436398027 | validation: 0.22634663814712952]
	TIME [epoch: 5.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3746098577944473		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.3746098577944473 | validation: 0.2153695279092177]
	TIME [epoch: 5.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38480495698831885		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.38480495698831885 | validation: 0.2054512721823928]
	TIME [epoch: 5.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37004321549295754		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.37004321549295754 | validation: 0.19283079541597545]
	TIME [epoch: 5.73 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652089213651136		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.3652089213651136 | validation: 0.2860242031170743]
	TIME [epoch: 5.71 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4192009748605023		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.4192009748605023 | validation: 0.1986699830571146]
	TIME [epoch: 5.71 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38153213106635897		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.38153213106635897 | validation: 0.2570294019103351]
	TIME [epoch: 5.7 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38524889449782873		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.38524889449782873 | validation: 0.2133158147065904]
	TIME [epoch: 5.7 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3599262576703536		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.3599262576703536 | validation: 0.25692589829909257]
	TIME [epoch: 5.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37702051935870057		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.37702051935870057 | validation: 0.22475869799119294]
	TIME [epoch: 5.7 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36658644272074986		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.36658644272074986 | validation: 0.18737978168826652]
	TIME [epoch: 5.74 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37793696370879903		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.37793696370879903 | validation: 0.27870521908756424]
	TIME [epoch: 5.71 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3758679946930068		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.3758679946930068 | validation: 0.19026395833003432]
	TIME [epoch: 5.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3682664422049573		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.3682664422049573 | validation: 0.1986246492533459]
	TIME [epoch: 5.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37184506721076405		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.37184506721076405 | validation: 0.21502198953345444]
	TIME [epoch: 5.7 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36458467318068355		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.36458467318068355 | validation: 0.20323347721781113]
	TIME [epoch: 5.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3725620692760622		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.3725620692760622 | validation: 0.21531085642246717]
	TIME [epoch: 5.73 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38911671734183145		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.38911671734183145 | validation: 0.24028534262950377]
	TIME [epoch: 5.72 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3615239755038846		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.3615239755038846 | validation: 0.23653884300440425]
	TIME [epoch: 5.71 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36705515999750066		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.36705515999750066 | validation: 0.19226773135656913]
	TIME [epoch: 5.7 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35769242787999356		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.35769242787999356 | validation: 0.19178380557190777]
	TIME [epoch: 5.7 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3788058699406239		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.3788058699406239 | validation: 0.26334958085289795]
	TIME [epoch: 5.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37354369406239746		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.37354369406239746 | validation: 0.23746522578308252]
	TIME [epoch: 5.7 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38423040342529785		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.38423040342529785 | validation: 0.19907821772890427]
	TIME [epoch: 5.74 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601042680800858		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.3601042680800858 | validation: 0.17904715463063015]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_1181.pth
	Model improved!!!
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3605541965718888		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.3605541965718888 | validation: 0.2601169590069373]
	TIME [epoch: 5.71 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3735245782839999		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.3735245782839999 | validation: 0.18667782420247064]
	TIME [epoch: 5.7 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40901410229341634		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.40901410229341634 | validation: 0.1845953398714978]
	TIME [epoch: 5.7 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3605261976461344		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.3605261976461344 | validation: 0.19654599626824848]
	TIME [epoch: 5.7 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3978659913791485		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.3978659913791485 | validation: 0.20557987352117377]
	TIME [epoch: 5.73 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36552062891649617		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.36552062891649617 | validation: 0.18341852397244082]
	TIME [epoch: 5.71 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3704907561670322		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.3704907561670322 | validation: 0.186458960392033]
	TIME [epoch: 5.71 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36053948332241975		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.36053948332241975 | validation: 0.2079621597154657]
	TIME [epoch: 5.7 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38144993214000944		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.38144993214000944 | validation: 0.2584768281334485]
	TIME [epoch: 5.7 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37304031977765983		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.37304031977765983 | validation: 0.19264830987496587]
	TIME [epoch: 5.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3572112351983331		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.3572112351983331 | validation: 0.19526997188759965]
	TIME [epoch: 5.7 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3516258274818608		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.3516258274818608 | validation: 0.20877957744636155]
	TIME [epoch: 5.74 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35683074660646674		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.35683074660646674 | validation: 0.2079877678685072]
	TIME [epoch: 5.71 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3649887032872582		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.3649887032872582 | validation: 0.21562446416906583]
	TIME [epoch: 5.71 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.376055356879895		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.376055356879895 | validation: 0.19971373097846262]
	TIME [epoch: 5.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35848722058743304		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.35848722058743304 | validation: 0.2291008878699833]
	TIME [epoch: 5.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3664619905407913		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.3664619905407913 | validation: 0.21174547564602905]
	TIME [epoch: 5.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37239472313341093		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.37239472313341093 | validation: 0.20869225709039924]
	TIME [epoch: 5.73 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36822788105425375		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.36822788105425375 | validation: 0.1958391578520487]
	TIME [epoch: 5.72 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3658458518278598		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.3658458518278598 | validation: 0.30127540059169244]
	TIME [epoch: 5.71 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40690919666415515		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.40690919666415515 | validation: 0.18753902267411846]
	TIME [epoch: 5.7 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36112328184992715		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.36112328184992715 | validation: 0.22629185412034467]
	TIME [epoch: 5.7 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36595138826766366		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.36595138826766366 | validation: 0.1967501581093223]
	TIME [epoch: 5.7 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36348354795541055		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.36348354795541055 | validation: 0.2299094058676083]
	TIME [epoch: 5.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361178623605341		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.361178623605341 | validation: 0.18619465434323373]
	TIME [epoch: 5.74 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3596788229108374		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.3596788229108374 | validation: 0.19002693895170425]
	TIME [epoch: 5.71 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36468094558477476		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.36468094558477476 | validation: 0.18055612700345108]
	TIME [epoch: 5.71 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607373589298699		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.3607373589298699 | validation: 0.20379814509455949]
	TIME [epoch: 5.71 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36485507798991307		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.36485507798991307 | validation: 0.2047214877617003]
	TIME [epoch: 5.7 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39794922062953364		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.39794922062953364 | validation: 0.23241472985939715]
	TIME [epoch: 5.71 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37010928022632344		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.37010928022632344 | validation: 0.21008522808901361]
	TIME [epoch: 5.73 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3730477746081499		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.3730477746081499 | validation: 0.1904374505676641]
	TIME [epoch: 5.72 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3637806920112031		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.3637806920112031 | validation: 0.19321992460908582]
	TIME [epoch: 5.71 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36322339811150406		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.36322339811150406 | validation: 0.22915653151240736]
	TIME [epoch: 5.71 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3542570693449878		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.3542570693449878 | validation: 0.183715723818843]
	TIME [epoch: 5.7 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35670732456739845		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.35670732456739845 | validation: 0.25307055021164326]
	TIME [epoch: 5.71 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41355174722069776		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.41355174722069776 | validation: 0.20023763451235208]
	TIME [epoch: 5.7 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3606670501399938		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.3606670501399938 | validation: 0.1946341912531426]
	TIME [epoch: 5.74 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35597482037622363		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.35597482037622363 | validation: 0.1904197341480552]
	TIME [epoch: 5.71 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34818026729412943		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.34818026729412943 | validation: 0.18764919805592642]
	TIME [epoch: 5.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3630258225859482		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.3630258225859482 | validation: 0.20453824999755427]
	TIME [epoch: 5.7 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3698757708643724		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.3698757708643724 | validation: 0.2314935926277959]
	TIME [epoch: 5.71 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36445356683900243		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.36445356683900243 | validation: 0.18298019037396798]
	TIME [epoch: 5.7 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3726371473527029		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.3726371473527029 | validation: 0.19619006882773007]
	TIME [epoch: 5.73 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35717732094902954		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.35717732094902954 | validation: 0.2288148661308074]
	TIME [epoch: 5.72 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3639128847213722		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.3639128847213722 | validation: 0.19385512155761267]
	TIME [epoch: 5.71 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3568027782482174		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.3568027782482174 | validation: 0.2110467215387196]
	TIME [epoch: 5.7 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3653585752683852		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.3653585752683852 | validation: 0.20445681500197155]
	TIME [epoch: 5.7 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628485989814868		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.3628485989814868 | validation: 0.19530252183310728]
	TIME [epoch: 5.71 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3681385889806805		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.3681385889806805 | validation: 0.2217072382713517]
	TIME [epoch: 5.71 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361558725036928		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.361558725036928 | validation: 0.18269719234593304]
	TIME [epoch: 5.74 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3719750651217632		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.3719750651217632 | validation: 0.1695177142764033]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_1233.pth
	Model improved!!!
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36166840608833567		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.36166840608833567 | validation: 0.18623372726331114]
	TIME [epoch: 5.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36905931997123376		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.36905931997123376 | validation: 0.21107005823923763]
	TIME [epoch: 5.7 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3513737399593918		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.3513737399593918 | validation: 0.18513901771677738]
	TIME [epoch: 5.7 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363647565396195		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.363647565396195 | validation: 0.21518637876320187]
	TIME [epoch: 5.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351555521183999		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.351555521183999 | validation: 0.1851936895949021]
	TIME [epoch: 5.73 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632653009115939		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.3632653009115939 | validation: 0.1853449449043404]
	TIME [epoch: 5.71 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35248203606276474		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.35248203606276474 | validation: 0.17791151178383974]
	TIME [epoch: 5.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36137089856911003		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.36137089856911003 | validation: 0.18985833064945457]
	TIME [epoch: 5.7 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36177372328427393		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.36177372328427393 | validation: 0.17907814839758535]
	TIME [epoch: 5.7 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36924540472383566		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.36924540472383566 | validation: 0.2785012693390222]
	TIME [epoch: 5.7 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36723493775809707		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.36723493775809707 | validation: 0.1774040954516913]
	TIME [epoch: 5.7 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.353519930651521		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.353519930651521 | validation: 0.1898557915283489]
	TIME [epoch: 5.74 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34936747480963626		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.34936747480963626 | validation: 0.21572392547420316]
	TIME [epoch: 5.71 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34779507291883094		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.34779507291883094 | validation: 0.1820334211684273]
	TIME [epoch: 5.7 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3456346527163149		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.3456346527163149 | validation: 0.19669344704542455]
	TIME [epoch: 5.7 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3484534514284129		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.3484534514284129 | validation: 0.20512840444160063]
	TIME [epoch: 5.7 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37765340738137937		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.37765340738137937 | validation: 0.21701201075972454]
	TIME [epoch: 5.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3704824336211241		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.3704824336211241 | validation: 0.29407096817103856]
	TIME [epoch: 5.73 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3832454431459408		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.3832454431459408 | validation: 0.20331476170430654]
	TIME [epoch: 5.72 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35015127543946223		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.35015127543946223 | validation: 0.21082791446090504]
	TIME [epoch: 5.71 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576491778051263		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.3576491778051263 | validation: 0.1919411420372785]
	TIME [epoch: 5.7 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35544281822697144		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.35544281822697144 | validation: 0.1976931455387559]
	TIME [epoch: 5.7 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3492204518157782		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.3492204518157782 | validation: 0.2001160090216468]
	TIME [epoch: 5.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607034501707369		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.3607034501707369 | validation: 0.19458025561584558]
	TIME [epoch: 5.7 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36030794291527013		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.36030794291527013 | validation: 0.23704939213323847]
	TIME [epoch: 5.74 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3486569135734722		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.3486569135734722 | validation: 0.20549274642524687]
	TIME [epoch: 5.71 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3516093047168689		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.3516093047168689 | validation: 0.22344736527496764]
	TIME [epoch: 5.7 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3678916253266828		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.3678916253266828 | validation: 0.1969396569485805]
	TIME [epoch: 5.7 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3587351428772813		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.3587351428772813 | validation: 0.22604732160785332]
	TIME [epoch: 5.7 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3592669146727956		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.3592669146727956 | validation: 0.21140026033109077]
	TIME [epoch: 5.7 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37562238318425656		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.37562238318425656 | validation: 0.21599035346589332]
	TIME [epoch: 5.73 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35428347413102407		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.35428347413102407 | validation: 0.2156789737239935]
	TIME [epoch: 5.72 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3515596595361725		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.3515596595361725 | validation: 0.20132949979624498]
	TIME [epoch: 5.71 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3676026545054111		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.3676026545054111 | validation: 0.1872099253709704]
	TIME [epoch: 5.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3499507762530737		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.3499507762530737 | validation: 0.20084228258221273]
	TIME [epoch: 5.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3516509166073086		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.3516509166073086 | validation: 0.20110300762471872]
	TIME [epoch: 5.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3490510304125914		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.3490510304125914 | validation: 0.19941124740794777]
	TIME [epoch: 5.71 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36131260807466337		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.36131260807466337 | validation: 0.24992210369554813]
	TIME [epoch: 5.74 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612284458958398		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.3612284458958398 | validation: 0.2002798613027792]
	TIME [epoch: 5.71 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3561579061118756		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.3561579061118756 | validation: 0.19482111787369566]
	TIME [epoch: 5.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36224768713808786		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.36224768713808786 | validation: 0.19231378780407063]
	TIME [epoch: 5.7 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35316828222522173		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.35316828222522173 | validation: 0.21687408575351597]
	TIME [epoch: 5.7 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528432741479269		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.3528432741479269 | validation: 0.20394343936811588]
	TIME [epoch: 5.7 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3572922759500109		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.3572922759500109 | validation: 0.1850189990913291]
	TIME [epoch: 5.73 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475095768719038		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.3475095768719038 | validation: 0.222744803412969]
	TIME [epoch: 5.72 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35161645123016766		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.35161645123016766 | validation: 0.20389845859885156]
	TIME [epoch: 5.71 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601478053690061		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.3601478053690061 | validation: 0.19439062312969732]
	TIME [epoch: 5.7 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461798033815482		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.3461798033815482 | validation: 0.23100916203906038]
	TIME [epoch: 5.7 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35557373469145626		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.35557373469145626 | validation: 0.18144482911268145]
	TIME [epoch: 5.7 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36081564917959436		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.36081564917959436 | validation: 0.2048530935626444]
	TIME [epoch: 5.7 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34912413369420714		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.34912413369420714 | validation: 0.18554172682831285]
	TIME [epoch: 5.74 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3537177572936466		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.3537177572936466 | validation: 0.18972547267372747]
	TIME [epoch: 5.71 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35885201895594937		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.35885201895594937 | validation: 0.19978652034446537]
	TIME [epoch: 5.7 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34815314841160216		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.34815314841160216 | validation: 0.17996949474996782]
	TIME [epoch: 5.7 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36049393423731935		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.36049393423731935 | validation: 0.27956177294084766]
	TIME [epoch: 5.7 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3851237056722102		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.3851237056722102 | validation: 0.17888230674008015]
	TIME [epoch: 5.7 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36246146299039084		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.36246146299039084 | validation: 0.18248797528011287]
	TIME [epoch: 5.73 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34834677398624825		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.34834677398624825 | validation: 0.20569284884903202]
	TIME [epoch: 5.71 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35231967907924067		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.35231967907924067 | validation: 0.20029849691828971]
	TIME [epoch: 5.71 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3504785315100775		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.3504785315100775 | validation: 0.1990850624870764]
	TIME [epoch: 5.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453950319666154		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.3453950319666154 | validation: 0.19698970024435888]
	TIME [epoch: 5.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35122506286411626		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.35122506286411626 | validation: 0.18083187323006622]
	TIME [epoch: 5.7 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34872765336674777		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.34872765336674777 | validation: 0.19404344638624602]
	TIME [epoch: 5.7 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3499955323349623		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.3499955323349623 | validation: 0.19589336150451198]
	TIME [epoch: 5.74 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35589765891707725		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.35589765891707725 | validation: 0.2032902794645966]
	TIME [epoch: 5.7 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489639909659068		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.3489639909659068 | validation: 0.1924270290678384]
	TIME [epoch: 5.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706816658003719		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.3706816658003719 | validation: 0.18131371695504264]
	TIME [epoch: 5.7 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36886283144917026		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.36886283144917026 | validation: 0.21921456125969724]
	TIME [epoch: 5.7 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612954742760579		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.3612954742760579 | validation: 0.20487292063990917]
	TIME [epoch: 5.7 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491854049511154		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.3491854049511154 | validation: 0.23712164800636246]
	TIME [epoch: 5.73 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362004991257552		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.362004991257552 | validation: 0.2222267044847778]
	TIME [epoch: 5.72 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667603669774192		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.3667603669774192 | validation: 0.2264815192599908]
	TIME [epoch: 5.71 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3479038753580255		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.3479038753580255 | validation: 0.23646638425717]
	TIME [epoch: 5.7 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521986360941073		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.3521986360941073 | validation: 0.21486018427850287]
	TIME [epoch: 5.7 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3564140196836026		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.3564140196836026 | validation: 0.2237710295439438]
	TIME [epoch: 5.7 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3597707510389624		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.3597707510389624 | validation: 0.20460143639176667]
	TIME [epoch: 5.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453800151596777		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.3453800151596777 | validation: 0.2311804716174717]
	TIME [epoch: 5.74 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34993240795565606		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.34993240795565606 | validation: 0.20604261598542717]
	TIME [epoch: 5.71 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35464253269326873		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.35464253269326873 | validation: 0.2016010112726723]
	TIME [epoch: 5.7 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34972961524037044		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.34972961524037044 | validation: 0.19580618784404988]
	TIME [epoch: 5.7 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3438963872082033		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.3438963872082033 | validation: 0.19765063280149775]
	TIME [epoch: 5.7 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35062350077806803		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.35062350077806803 | validation: 0.18535820504126604]
	TIME [epoch: 5.7 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540049750214049		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.3540049750214049 | validation: 0.20045158977180622]
	TIME [epoch: 5.72 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37722148332881794		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.37722148332881794 | validation: 0.27941866114881986]
	TIME [epoch: 5.73 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3698560892579417		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.3698560892579417 | validation: 0.18655048099216154]
	TIME [epoch: 5.71 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35538191545993697		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.35538191545993697 | validation: 0.20619233504228157]
	TIME [epoch: 5.7 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.345295412877474		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.345295412877474 | validation: 0.23582031596142905]
	TIME [epoch: 5.7 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3761367415553118		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.3761367415553118 | validation: 0.2095449536987535]
	TIME [epoch: 5.7 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35071622610720476		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.35071622610720476 | validation: 0.18540170308506823]
	TIME [epoch: 5.7 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3544942011593585		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.3544942011593585 | validation: 0.23596446237462634]
	TIME [epoch: 5.74 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36314437742537525		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.36314437742537525 | validation: 0.24191093886896461]
	TIME [epoch: 5.71 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35495292159898834		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.35495292159898834 | validation: 0.20057088158668002]
	TIME [epoch: 5.7 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35478130905877014		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.35478130905877014 | validation: 0.18451442997885725]
	TIME [epoch: 5.7 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35497835869540656		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.35497835869540656 | validation: 0.1887773681769042]
	TIME [epoch: 5.7 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34178297834349486		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.34178297834349486 | validation: 0.22337744753652114]
	TIME [epoch: 5.7 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36999357964312074		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.36999357964312074 | validation: 0.19876652191778946]
	TIME [epoch: 5.71 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3512989246764936		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.3512989246764936 | validation: 0.18927732913205222]
	TIME [epoch: 5.73 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489745530355294		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.3489745530355294 | validation: 0.18954499831182253]
	TIME [epoch: 5.7 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34841339748588107		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.34841339748588107 | validation: 0.24654239709220746]
	TIME [epoch: 5.7 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3685162899055498		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.3685162899055498 | validation: 0.19913384909113002]
	TIME [epoch: 5.7 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442180342892792		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.3442180342892792 | validation: 0.19652991936777156]
	TIME [epoch: 5.7 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35332593494971143		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.35332593494971143 | validation: 0.1822335994337931]
	TIME [epoch: 5.7 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3466763608896616		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.3466763608896616 | validation: 0.18405660295997733]
	TIME [epoch: 5.74 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524806306357566		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.3524806306357566 | validation: 0.20273535148471197]
	TIME [epoch: 5.71 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3550261444033361		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.3550261444033361 | validation: 0.1881491228073211]
	TIME [epoch: 5.7 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3483242982134722		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.3483242982134722 | validation: 0.179064304495053]
	TIME [epoch: 5.7 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3480812366715197		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.3480812366715197 | validation: 0.18630138047064854]
	TIME [epoch: 5.7 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3418980446800497		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.3418980446800497 | validation: 0.21392338007641093]
	TIME [epoch: 5.7 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34851397761479797		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.34851397761479797 | validation: 0.18654915342698203]
	TIME [epoch: 5.71 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35167489937021734		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.35167489937021734 | validation: 0.18032575848997634]
	TIME [epoch: 5.73 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3483156255586949		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.3483156255586949 | validation: 0.2011548285891024]
	TIME [epoch: 5.7 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33998375050690843		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.33998375050690843 | validation: 0.1987653533789257]
	TIME [epoch: 5.7 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34328626471057855		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.34328626471057855 | validation: 0.20530739760142125]
	TIME [epoch: 5.7 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489367173975785		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.3489367173975785 | validation: 0.1777765202678743]
	TIME [epoch: 5.7 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34526066876956696		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.34526066876956696 | validation: 0.1809574390547442]
	TIME [epoch: 5.7 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3444310849743445		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.3444310849743445 | validation: 0.19402357785906713]
	TIME [epoch: 5.74 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35131730033730796		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.35131730033730796 | validation: 0.17143649609327674]
	TIME [epoch: 5.71 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34037241731617346		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.34037241731617346 | validation: 0.1754228004064997]
	TIME [epoch: 5.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3520152337713906		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.3520152337713906 | validation: 0.18151080440925543]
	TIME [epoch: 5.7 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3490317879123999		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.3490317879123999 | validation: 0.20908643149196005]
	TIME [epoch: 5.7 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3423683653682822		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.3423683653682822 | validation: 0.19842736939442376]
	TIME [epoch: 5.7 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3499939735823905		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.3499939735823905 | validation: 0.1940409980599565]
	TIME [epoch: 5.71 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34374079619617154		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.34374079619617154 | validation: 0.20269302221814386]
	TIME [epoch: 5.73 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3602574247477019		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.3602574247477019 | validation: 0.18321438269407422]
	TIME [epoch: 5.7 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440922625271525		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.3440922625271525 | validation: 0.18179936355105836]
	TIME [epoch: 5.7 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3509123867313668		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.3509123867313668 | validation: 0.20528148929142348]
	TIME [epoch: 5.7 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538509452332349		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.3538509452332349 | validation: 0.1908512856928463]
	TIME [epoch: 5.7 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3476003434885755		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.3476003434885755 | validation: 0.2021914562950506]
	TIME [epoch: 5.7 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34794380818187737		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.34794380818187737 | validation: 0.2166482479310398]
	TIME [epoch: 5.74 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3700722338663921		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.3700722338663921 | validation: 0.18325184705170017]
	TIME [epoch: 5.71 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3450809194477479		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.3450809194477479 | validation: 0.18612371152996382]
	TIME [epoch: 5.7 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552550765416959		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.3552550765416959 | validation: 0.1836467376559964]
	TIME [epoch: 5.7 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34342689757858585		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.34342689757858585 | validation: 0.18346520737226732]
	TIME [epoch: 5.7 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3419766302275712		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.3419766302275712 | validation: 0.22155082161888381]
	TIME [epoch: 5.7 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3779920230278137		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.3779920230278137 | validation: 0.31412866733794803]
	TIME [epoch: 5.71 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4102904772713245		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.4102904772713245 | validation: 0.2155037842808828]
	TIME [epoch: 5.73 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35034977553874763		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.35034977553874763 | validation: 0.1896543184056114]
	TIME [epoch: 5.71 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34442733347824434		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.34442733347824434 | validation: 0.21929539720394872]
	TIME [epoch: 5.7 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37060403608602943		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.37060403608602943 | validation: 0.20946064646707335]
	TIME [epoch: 5.7 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352832344058515		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.352832344058515 | validation: 0.1815837267629214]
	TIME [epoch: 5.7 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34744851716093467		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.34744851716093467 | validation: 0.19181855643595738]
	TIME [epoch: 5.7 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3486980485319829		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.3486980485319829 | validation: 0.18302669295291382]
	TIME [epoch: 5.74 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3426373225308829		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.3426373225308829 | validation: 0.18420393831821522]
	TIME [epoch: 5.71 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3449716111729319		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.3449716111729319 | validation: 0.1780543451422751]
	TIME [epoch: 5.7 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3392346779951427		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.3392346779951427 | validation: 0.18420507384015822]
	TIME [epoch: 5.7 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34435191332016235		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.34435191332016235 | validation: 0.1916459113899606]
	TIME [epoch: 5.7 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3415898673102407		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.3415898673102407 | validation: 0.1756099863250948]
	TIME [epoch: 5.7 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33586488162678585		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.33586488162678585 | validation: 0.18186674476941542]
	TIME [epoch: 5.71 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351035099868633		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.351035099868633 | validation: 0.17871104063392143]
	TIME [epoch: 5.73 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35210204455207306		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.35210204455207306 | validation: 0.17977302672663753]
	TIME [epoch: 5.71 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3556719303685874		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.3556719303685874 | validation: 0.1766303936847501]
	TIME [epoch: 5.7 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3499544147003423		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.3499544147003423 | validation: 0.19791348698264383]
	TIME [epoch: 5.7 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34620924896708827		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.34620924896708827 | validation: 0.1942100181674763]
	TIME [epoch: 5.7 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489009974839373		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.3489009974839373 | validation: 0.18061657052539057]
	TIME [epoch: 5.7 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3562124597802482		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.3562124597802482 | validation: 0.17846819451051435]
	TIME [epoch: 5.74 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.342288869062798		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.342288869062798 | validation: 0.18601512251166163]
	TIME [epoch: 5.71 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34200153296359714		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.34200153296359714 | validation: 0.1812876315879042]
	TIME [epoch: 5.7 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34710436820413265		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.34710436820413265 | validation: 0.1724528388172182]
	TIME [epoch: 5.7 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472317400768701		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.3472317400768701 | validation: 0.19620322614734098]
	TIME [epoch: 5.7 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35000744214151663		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.35000744214151663 | validation: 0.17670322303991362]
	TIME [epoch: 5.7 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33995920610205016		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.33995920610205016 | validation: 0.22147710185798616]
	TIME [epoch: 5.71 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3605053284328214		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.3605053284328214 | validation: 0.19472066282885778]
	TIME [epoch: 5.73 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34687185540291127		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.34687185540291127 | validation: 0.20493652378185204]
	TIME [epoch: 5.7 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35439182303529787		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.35439182303529787 | validation: 0.1889574302587274]
	TIME [epoch: 5.7 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35243939355199316		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.35243939355199316 | validation: 0.20210693046507197]
	TIME [epoch: 5.7 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35619333246536855		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.35619333246536855 | validation: 0.2306290617802076]
	TIME [epoch: 5.7 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347449784783799		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.347449784783799 | validation: 0.17887757245647692]
	TIME [epoch: 5.7 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34688415672656664		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.34688415672656664 | validation: 0.1864518152530069]
	TIME [epoch: 5.73 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34887131190557735		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.34887131190557735 | validation: 0.21064665068238234]
	TIME [epoch: 5.71 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35762719120264147		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.35762719120264147 | validation: 0.258443034413742]
	TIME [epoch: 5.7 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3668433075982193		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.3668433075982193 | validation: 0.18974286296558812]
	TIME [epoch: 5.7 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461035559919534		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.3461035559919534 | validation: 0.1891306477592356]
	TIME [epoch: 5.7 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34689414065523183		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.34689414065523183 | validation: 0.22230165578762376]
	TIME [epoch: 5.7 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491988184436664		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.3491988184436664 | validation: 0.20231685607504987]
	TIME [epoch: 5.71 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501453893216889		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.3501453893216889 | validation: 0.22497114699959844]
	TIME [epoch: 5.73 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34563146190013905		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.34563146190013905 | validation: 0.18551571911139994]
	TIME [epoch: 5.7 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365043293632672		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.365043293632672 | validation: 0.18421815745745002]
	TIME [epoch: 5.7 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34692892548996934		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.34692892548996934 | validation: 0.18245346313651367]
	TIME [epoch: 5.7 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34136833222702423		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.34136833222702423 | validation: 0.18851348076734492]
	TIME [epoch: 5.7 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34464041390345473		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.34464041390345473 | validation: 0.21802507359302925]
	TIME [epoch: 5.7 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3384750853608355		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.3384750853608355 | validation: 0.20337288449079624]
	TIME [epoch: 5.73 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.355151703154462		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.355151703154462 | validation: 0.21451446252940198]
	TIME [epoch: 5.71 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34062966291633756		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.34062966291633756 | validation: 0.18019454375453936]
	TIME [epoch: 5.7 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3510080032517345		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.3510080032517345 | validation: 0.1925920624805333]
	TIME [epoch: 5.7 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347876067543516		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.347876067543516 | validation: 0.21254346594336537]
	TIME [epoch: 5.7 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3488645057837166		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.3488645057837166 | validation: 0.19035225357248223]
	TIME [epoch: 5.7 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34724374402337943		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.34724374402337943 | validation: 0.21667244033510222]
	TIME [epoch: 5.71 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34749942542551		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.34749942542551 | validation: 0.19129282561365876]
	TIME [epoch: 5.73 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3464819618267325		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.3464819618267325 | validation: 0.19852374225783426]
	TIME [epoch: 5.7 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34323317170681017		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.34323317170681017 | validation: 0.18127237947833108]
	TIME [epoch: 5.7 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34849405176056547		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.34849405176056547 | validation: 0.21793398455662755]
	TIME [epoch: 5.7 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35586349512078896		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.35586349512078896 | validation: 0.188135209753374]
	TIME [epoch: 5.7 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35362182885539456		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.35362182885539456 | validation: 0.18705319059280517]
	TIME [epoch: 5.7 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3429247388650883		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.3429247388650883 | validation: 0.19722013685523165]
	TIME [epoch: 5.74 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3389619365634255		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.3389619365634255 | validation: 0.19420579340581914]
	TIME [epoch: 5.71 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34236484649088705		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.34236484649088705 | validation: 0.2252645968683964]
	TIME [epoch: 5.7 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3512071279017224		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.3512071279017224 | validation: 0.19264321201405138]
	TIME [epoch: 5.7 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3456592046816353		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.3456592046816353 | validation: 0.23000395224779868]
	TIME [epoch: 5.7 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.350407574443155		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.350407574443155 | validation: 0.1917508494110895]
	TIME [epoch: 5.7 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34513392067242005		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.34513392067242005 | validation: 0.18676204125284726]
	TIME [epoch: 5.71 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3425742666456599		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.3425742666456599 | validation: 0.18800799906366003]
	TIME [epoch: 5.73 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34420004635907464		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.34420004635907464 | validation: 0.2177168250899131]
	TIME [epoch: 5.71 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.342290162393767		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.342290162393767 | validation: 0.2019562138151545]
	TIME [epoch: 5.7 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34277994452978855		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.34277994452978855 | validation: 0.20029297428695544]
	TIME [epoch: 5.7 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34973986527970463		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.34973986527970463 | validation: 0.19795057298400923]
	TIME [epoch: 5.7 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34309503975632877		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.34309503975632877 | validation: 0.1978204910724817]
	TIME [epoch: 5.7 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34560561303894366		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.34560561303894366 | validation: 0.19311564647892482]
	TIME [epoch: 5.73 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34048759354061026		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.34048759354061026 | validation: 0.21563978092690972]
	TIME [epoch: 5.71 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3405416339536523		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.3405416339536523 | validation: 0.1943863809798797]
	TIME [epoch: 5.7 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34505218891383327		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.34505218891383327 | validation: 0.20434436426425184]
	TIME [epoch: 5.7 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435763391590203		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.3435763391590203 | validation: 0.18948473714082925]
	TIME [epoch: 5.7 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3375945928865042		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.3375945928865042 | validation: 0.18746694603420325]
	TIME [epoch: 5.7 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3469297746660563		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.3469297746660563 | validation: 0.23641043267200013]
	TIME [epoch: 5.71 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34924356983290333		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.34924356983290333 | validation: 0.18515863760315726]
	TIME [epoch: 5.73 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34321746925832436		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.34321746925832436 | validation: 0.18829940862680605]
	TIME [epoch: 5.7 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3413855399710319		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.3413855399710319 | validation: 0.1777173654422934]
	TIME [epoch: 5.7 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33978651170524915		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.33978651170524915 | validation: 0.19971429992606024]
	TIME [epoch: 5.7 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3371755779903595		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.3371755779903595 | validation: 0.18831079276601073]
	TIME [epoch: 5.7 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3402782168177472		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.3402782168177472 | validation: 0.1976290805904924]
	TIME [epoch: 5.7 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3463598758824518		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.3463598758824518 | validation: 0.19860816168145065]
	TIME [epoch: 5.74 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34970372578753384		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.34970372578753384 | validation: 0.1908321962760138]
	TIME [epoch: 5.71 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33774084417547845		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.33774084417547845 | validation: 0.18922397789560397]
	TIME [epoch: 5.7 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3404068629696141		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.3404068629696141 | validation: 0.1911880392504487]
	TIME [epoch: 5.7 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33670636703617074		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.33670636703617074 | validation: 0.18815205153601675]
	TIME [epoch: 5.7 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34819469829873917		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.34819469829873917 | validation: 0.22071131315203446]
	TIME [epoch: 5.7 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3649812779255617		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.3649812779255617 | validation: 0.233033347305024]
	TIME [epoch: 5.71 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35164165633988037		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.35164165633988037 | validation: 0.19041610579759116]
	TIME [epoch: 5.73 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33895462486063466		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.33895462486063466 | validation: 0.1930225033921348]
	TIME [epoch: 5.7 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33552024556395443		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.33552024556395443 | validation: 0.19904298766471634]
	TIME [epoch: 5.7 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3409389440089651		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.3409389440089651 | validation: 0.17715553943562448]
	TIME [epoch: 5.7 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3474997673003453		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.3474997673003453 | validation: 0.19192104201793148]
	TIME [epoch: 5.7 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3493090782950452		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.3493090782950452 | validation: 0.1719315240366671]
	TIME [epoch: 5.7 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3437210697432373		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.3437210697432373 | validation: 0.1907483148710449]
	TIME [epoch: 5.74 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538225838873013		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.3538225838873013 | validation: 0.18303310246774332]
	TIME [epoch: 5.71 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35402480283867704		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.35402480283867704 | validation: 0.1882486349076431]
	TIME [epoch: 5.7 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3537461838572151		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.3537461838572151 | validation: 0.20283597484505161]
	TIME [epoch: 5.7 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3388989111653333		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.3388989111653333 | validation: 0.18555058953025672]
	TIME [epoch: 5.7 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33988244203278606		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.33988244203278606 | validation: 0.18269869763571295]
	TIME [epoch: 5.7 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34051939417316496		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.34051939417316496 | validation: 0.18715093293882035]
	TIME [epoch: 5.71 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33559290242350637		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.33559290242350637 | validation: 0.19848300643488032]
	TIME [epoch: 5.73 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33956469414772444		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.33956469414772444 | validation: 0.20509516725478158]
	TIME [epoch: 5.71 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34281239402943786		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.34281239402943786 | validation: 0.2042059092652894]
	TIME [epoch: 5.7 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3406961349739376		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.3406961349739376 | validation: 0.19300687971947908]
	TIME [epoch: 5.7 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33966286851082883		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.33966286851082883 | validation: 0.18376214071978772]
	TIME [epoch: 5.7 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33965810654165385		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.33965810654165385 | validation: 0.18427825655835237]
	TIME [epoch: 5.7 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3420131786776634		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.3420131786776634 | validation: 0.181667507306228]
	TIME [epoch: 5.73 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33887878473201105		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.33887878473201105 | validation: 0.1908482364929531]
	TIME [epoch: 5.7 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34471073896753635		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.34471073896753635 | validation: 0.18750025214141489]
	TIME [epoch: 5.7 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3434702248289724		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.3434702248289724 | validation: 0.19572040677125827]
	TIME [epoch: 5.7 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3400697588765989		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.3400697588765989 | validation: 0.1852095698945303]
	TIME [epoch: 5.7 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34130905666286976		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.34130905666286976 | validation: 0.1990086836356589]
	TIME [epoch: 5.7 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34714017042455003		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.34714017042455003 | validation: 0.21647696707924863]
	TIME [epoch: 5.71 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3421276742930049		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.3421276742930049 | validation: 0.18800787855219817]
	TIME [epoch: 5.72 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34886850758875027		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.34886850758875027 | validation: 0.18187618199515698]
	TIME [epoch: 5.7 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34623987557170705		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.34623987557170705 | validation: 0.17996652710964647]
	TIME [epoch: 5.7 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352892234579138		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.3352892234579138 | validation: 0.17447857540230138]
	TIME [epoch: 5.7 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3391893729699687		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.3391893729699687 | validation: 0.18407918269763707]
	TIME [epoch: 5.7 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33842243832035196		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.33842243832035196 | validation: 0.21122369589830758]
	TIME [epoch: 5.7 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33998119720810427		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.33998119720810427 | validation: 0.20198905181357046]
	TIME [epoch: 5.73 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34176485612971197		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.34176485612971197 | validation: 0.17999289855901107]
	TIME [epoch: 5.71 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3441372067536596		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.3441372067536596 | validation: 0.19244231315382856]
	TIME [epoch: 5.7 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3418473891826533		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.3418473891826533 | validation: 0.21040083147996252]
	TIME [epoch: 5.7 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34690631356389967		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.34690631356389967 | validation: 0.20556732942602424]
	TIME [epoch: 5.7 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34021912424133915		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.34021912424133915 | validation: 0.18788122607420946]
	TIME [epoch: 5.7 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33784783221359926		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.33784783221359926 | validation: 0.20861176493958788]
	TIME [epoch: 5.7 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34213231337264033		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.34213231337264033 | validation: 0.20515224245372707]
	TIME [epoch: 5.73 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33963996338753266		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.33963996338753266 | validation: 0.19873789852354365]
	TIME [epoch: 5.7 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33856075122087564		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.33856075122087564 | validation: 0.18830907231870517]
	TIME [epoch: 5.7 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3417098025844034		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.3417098025844034 | validation: 0.20512440405294674]
	TIME [epoch: 5.7 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35161196909753056		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.35161196909753056 | validation: 0.20068941381328975]
	TIME [epoch: 5.7 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34787348852347455		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.34787348852347455 | validation: 0.20910909879409445]
	TIME [epoch: 5.7 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3505052490370666		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.3505052490370666 | validation: 0.19560482612945485]
	TIME [epoch: 5.73 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3448078271539456		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.3448078271539456 | validation: 0.18924675421997358]
	TIME [epoch: 5.71 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3422000726979604		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.3422000726979604 | validation: 0.19268628698199677]
	TIME [epoch: 5.7 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3400448546374843		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.3400448546374843 | validation: 0.1976002783874542]
	TIME [epoch: 5.7 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3342086224049451		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.3342086224049451 | validation: 0.17727016454429112]
	TIME [epoch: 5.7 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436510761906429		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.3436510761906429 | validation: 0.18881750817054282]
	TIME [epoch: 5.7 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3427440276182033		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.3427440276182033 | validation: 0.17056619030252546]
	TIME [epoch: 5.7 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356357196620201		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.3356357196620201 | validation: 0.18528150940731433]
	TIME [epoch: 5.73 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3410594217535155		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.3410594217535155 | validation: 0.2051912164662094]
	TIME [epoch: 5.7 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3506368158426293		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.3506368158426293 | validation: 0.19835855492357646]
	TIME [epoch: 5.7 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3408643044631211		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.3408643044631211 | validation: 0.19825631920971667]
	TIME [epoch: 5.7 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34906810583477826		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.34906810583477826 | validation: 0.20121526017570407]
	TIME [epoch: 5.7 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3388181550820855		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.3388181550820855 | validation: 0.18475495572499998]
	TIME [epoch: 5.7 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33827856650109467		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.33827856650109467 | validation: 0.20313599768338556]
	TIME [epoch: 5.73 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3389874628696875		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.3389874628696875 | validation: 0.19453636021901968]
	TIME [epoch: 5.71 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3390682269614331		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.3390682269614331 | validation: 0.20208461958153268]
	TIME [epoch: 5.7 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3354267583443064		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.3354267583443064 | validation: 0.19890635720842081]
	TIME [epoch: 5.7 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3350266119028308		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.3350266119028308 | validation: 0.19230013264607165]
	TIME [epoch: 5.7 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3419229527867288		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.3419229527867288 | validation: 0.18583345592113318]
	TIME [epoch: 5.7 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34300387497367857		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.34300387497367857 | validation: 0.1828545230952847]
	TIME [epoch: 5.7 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3360805743805526		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.3360805743805526 | validation: 0.18613976799693266]
	TIME [epoch: 5.73 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34376532791687064		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.34376532791687064 | validation: 0.19291418141669542]
	TIME [epoch: 5.7 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3421268620626555		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.3421268620626555 | validation: 0.1729674497576972]
	TIME [epoch: 5.7 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436098486453205		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.3436098486453205 | validation: 0.18224307811368903]
	TIME [epoch: 5.7 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34223158667612047		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.34223158667612047 | validation: 0.1745547565292853]
	TIME [epoch: 5.7 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3404365335829323		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.3404365335829323 | validation: 0.1909255286986241]
	TIME [epoch: 5.7 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453518870924877		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.3453518870924877 | validation: 0.2023476350111035]
	TIME [epoch: 5.73 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3444889866958534		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.3444889866958534 | validation: 0.18523288155686196]
	TIME [epoch: 5.71 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3432271279167226		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.3432271279167226 | validation: 0.19631837417214953]
	TIME [epoch: 5.7 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3405653455648804		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.3405653455648804 | validation: 0.18942207435377684]
	TIME [epoch: 5.7 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3395696585475698		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.3395696585475698 | validation: 0.18597320805229642]
	TIME [epoch: 5.7 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3376401929190511		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.3376401929190511 | validation: 0.18276187304812233]
	TIME [epoch: 5.7 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.337026843252367		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.337026843252367 | validation: 0.20126877152396333]
	TIME [epoch: 5.7 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33890416232970333		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.33890416232970333 | validation: 0.20134810116749358]
	TIME [epoch: 5.74 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34342616248095637		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.34342616248095637 | validation: 0.2005474809763162]
	TIME [epoch: 5.71 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33843899027557506		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.33843899027557506 | validation: 0.21034251210373456]
	TIME [epoch: 5.7 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3409454962660277		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.3409454962660277 | validation: 0.19088000443655737]
	TIME [epoch: 5.7 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3393447683854608		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.3393447683854608 | validation: 0.18774505595981894]
	TIME [epoch: 5.7 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3426689212609333		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.3426689212609333 | validation: 0.17573940018603332]
	TIME [epoch: 5.7 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3490423716591065		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.3490423716591065 | validation: 0.17546842137207697]
	TIME [epoch: 5.73 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34151716376080365		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.34151716376080365 | validation: 0.1793707988058941]
	TIME [epoch: 5.71 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33627584043613423		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.33627584043613423 | validation: 0.19082733855007078]
	TIME [epoch: 5.7 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.339223006499067		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.339223006499067 | validation: 0.18749694195632793]
	TIME [epoch: 5.7 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3355318806368578		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.3355318806368578 | validation: 0.1879884983635023]
	TIME [epoch: 5.7 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3370039978560429		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.3370039978560429 | validation: 0.19584524558368682]
	TIME [epoch: 5.7 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33325479708172323		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.33325479708172323 | validation: 0.1791737096726422]
	TIME [epoch: 5.7 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34100402380915995		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.34100402380915995 | validation: 0.18441496199130739]
	TIME [epoch: 5.73 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33248897842218417		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.33248897842218417 | validation: 0.17932350860438695]
	TIME [epoch: 5.7 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3361767354191928		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.3361767354191928 | validation: 0.17140782678380143]
	TIME [epoch: 5.7 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3408460665381327		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.3408460665381327 | validation: 0.19482954713296594]
	TIME [epoch: 5.7 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3395909150470656		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.3395909150470656 | validation: 0.1965184472935419]
	TIME [epoch: 5.7 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412654710643286		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.3412654710643286 | validation: 0.20750689296711466]
	TIME [epoch: 5.7 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454533919728772		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.3454533919728772 | validation: 0.1925855317780376]
	TIME [epoch: 5.73 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3369080841890634		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.3369080841890634 | validation: 0.18310945037290857]
	TIME [epoch: 5.71 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33495068884713103		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.33495068884713103 | validation: 0.183912587035013]
	TIME [epoch: 5.7 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34423963609955677		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.34423963609955677 | validation: 0.1818428258646587]
	TIME [epoch: 5.7 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33910020075977687		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.33910020075977687 | validation: 0.19714197900868546]
	TIME [epoch: 5.7 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3426287558310313		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.3426287558310313 | validation: 0.19323599074275305]
	TIME [epoch: 5.7 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3377033280326308		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.3377033280326308 | validation: 0.187590534649081]
	TIME [epoch: 5.7 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3354797231539227		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.3354797231539227 | validation: 0.21733297851427824]
	TIME [epoch: 5.73 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34180376008459057		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.34180376008459057 | validation: 0.2198564722384883]
	TIME [epoch: 5.7 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.340851818832132		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.340851818832132 | validation: 0.20191747626047132]
	TIME [epoch: 5.7 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33333280887922934		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.33333280887922934 | validation: 0.18656598057520846]
	TIME [epoch: 5.7 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3425790549187169		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.3425790549187169 | validation: 0.18552067366712624]
	TIME [epoch: 5.7 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33544498257423744		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.33544498257423744 | validation: 0.18952616713108852]
	TIME [epoch: 5.7 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3360000903348548		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.3360000903348548 | validation: 0.17572680662805426]
	TIME [epoch: 5.73 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33710705756979864		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.33710705756979864 | validation: 0.18309979589055808]
	TIME [epoch: 5.71 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333874765162426		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.333874765162426 | validation: 0.17897088208458597]
	TIME [epoch: 5.7 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33837144407506614		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.33837144407506614 | validation: 0.18640720219492493]
	TIME [epoch: 5.7 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33250917167645105		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.33250917167645105 | validation: 0.20232246955169722]
	TIME [epoch: 5.7 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3383235217827988		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.3383235217827988 | validation: 0.19645372036362763]
	TIME [epoch: 5.7 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3368349302577477		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.3368349302577477 | validation: 0.19503245749063347]
	TIME [epoch: 5.7 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3345901931987457		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.3345901931987457 | validation: 0.1945558323576411]
	TIME [epoch: 5.73 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3397508832293709		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.3397508832293709 | validation: 0.20001514020968927]
	TIME [epoch: 5.71 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3408388722335432		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.3408388722335432 | validation: 0.20485296304934303]
	TIME [epoch: 5.7 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33501008551220546		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.33501008551220546 | validation: 0.1885068570455595]
	TIME [epoch: 5.7 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3364128857874463		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.3364128857874463 | validation: 0.19416799176839486]
	TIME [epoch: 5.7 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33732506133947854		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.33732506133947854 | validation: 0.18351611550348268]
	TIME [epoch: 5.7 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3426455722354009		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.3426455722354009 | validation: 0.17731405885878132]
	TIME [epoch: 5.73 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3380048810135359		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.3380048810135359 | validation: 0.1664766008266111]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_1584.pth
	Model improved!!!
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435873060187623		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.3435873060187623 | validation: 0.17323399918618393]
	TIME [epoch: 5.7 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34011382295942055		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.34011382295942055 | validation: 0.18184113606421975]
	TIME [epoch: 5.7 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33467954866187966		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.33467954866187966 | validation: 0.20322053034777288]
	TIME [epoch: 5.7 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3351666187088723		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.3351666187088723 | validation: 0.19499398916539132]
	TIME [epoch: 5.7 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3382702010939401		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.3382702010939401 | validation: 0.19102361679618965]
	TIME [epoch: 5.71 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33473482962476436		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.33473482962476436 | validation: 0.1977059218550553]
	TIME [epoch: 5.73 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3357809290049071		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.3357809290049071 | validation: 0.18952316358257928]
	TIME [epoch: 5.7 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3315523118535817		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.3315523118535817 | validation: 0.17858670228390772]
	TIME [epoch: 5.7 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34268033082041394		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.34268033082041394 | validation: 0.17542259196333504]
	TIME [epoch: 5.7 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33776097799475147		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.33776097799475147 | validation: 0.17982071566651495]
	TIME [epoch: 5.7 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3393929996503283		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.3393929996503283 | validation: 0.173645979009469]
	TIME [epoch: 5.7 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3360957683573473		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.3360957683573473 | validation: 0.19658368270366042]
	TIME [epoch: 5.73 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3342017102295928		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.3342017102295928 | validation: 0.18685709601237135]
	TIME [epoch: 5.71 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3374556472846778		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.3374556472846778 | validation: 0.17497953378443754]
	TIME [epoch: 5.7 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33697405749195297		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.33697405749195297 | validation: 0.19250941380906988]
	TIME [epoch: 5.7 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33930279279696296		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.33930279279696296 | validation: 0.19628206977753956]
	TIME [epoch: 5.7 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33541041739889454		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.33541041739889454 | validation: 0.18156736869554727]
	TIME [epoch: 5.7 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3332667143567239		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.3332667143567239 | validation: 0.19990387516466077]
	TIME [epoch: 5.71 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33561693004167303		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.33561693004167303 | validation: 0.17913177304296696]
	TIME [epoch: 5.72 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3333511783267462		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.3333511783267462 | validation: 0.18745994486869033]
	TIME [epoch: 5.7 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3395322738006447		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.3395322738006447 | validation: 0.1836861385488084]
	TIME [epoch: 5.7 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3355991593775881		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.3355991593775881 | validation: 0.18686989288653028]
	TIME [epoch: 5.7 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3333782305348215		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.3333782305348215 | validation: 0.18711079658598104]
	TIME [epoch: 5.7 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3334879570211855		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.3334879570211855 | validation: 0.1880187030137419]
	TIME [epoch: 5.7 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33912555746371553		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.33912555746371553 | validation: 0.18981506056398445]
	TIME [epoch: 5.73 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3361306563200901		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.3361306563200901 | validation: 0.19034847512872696]
	TIME [epoch: 5.71 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33458522822735426		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.33458522822735426 | validation: 0.17710297867482258]
	TIME [epoch: 5.7 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33468516798799747		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.33468516798799747 | validation: 0.18905823199607127]
	TIME [epoch: 5.7 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352654490221714		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.3352654490221714 | validation: 0.18332466331130964]
	TIME [epoch: 5.7 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33608487930987246		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.33608487930987246 | validation: 0.19328039094628152]
	TIME [epoch: 5.7 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3345188997202275		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.3345188997202275 | validation: 0.1828264761254486]
	TIME [epoch: 5.71 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33671119231245633		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.33671119231245633 | validation: 0.17765687547827594]
	TIME [epoch: 5.73 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33301839640361247		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.33301839640361247 | validation: 0.18428016133756941]
	TIME [epoch: 5.7 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33766817930828474		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.33766817930828474 | validation: 0.20088659020790847]
	TIME [epoch: 5.7 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.338397579356315		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.338397579356315 | validation: 0.19951052506774056]
	TIME [epoch: 5.7 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.339276263148871		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.339276263148871 | validation: 0.19918456663117973]
	TIME [epoch: 5.7 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3344362675421658		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.3344362675421658 | validation: 0.18254582610135997]
	TIME [epoch: 5.7 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3344341225399813		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.3344341225399813 | validation: 0.19267767168514557]
	TIME [epoch: 5.73 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34632682323847075		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.34632682323847075 | validation: 0.2058771217097929]
	TIME [epoch: 5.71 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34352612865150506		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.34352612865150506 | validation: 0.22912347794223087]
	TIME [epoch: 5.7 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468398257422538		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.3468398257422538 | validation: 0.2073549182383464]
	TIME [epoch: 5.7 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33707054455869173		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.33707054455869173 | validation: 0.17640765035931277]
	TIME [epoch: 5.7 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3358086055441691		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.3358086055441691 | validation: 0.18689488830243242]
	TIME [epoch: 5.7 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329355318945849		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.3329355318945849 | validation: 0.18026121657544358]
	TIME [epoch: 5.71 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33219902782247024		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.33219902782247024 | validation: 0.1908979593283622]
	TIME [epoch: 5.72 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34099623978565785		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.34099623978565785 | validation: 0.20842876901150173]
	TIME [epoch: 5.7 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3370007566454176		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.3370007566454176 | validation: 0.2099510755268076]
	TIME [epoch: 5.7 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3470796483201234		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.3470796483201234 | validation: 0.20702031010167016]
	TIME [epoch: 5.7 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34392441549774866		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.34392441549774866 | validation: 0.20675810096680805]
	TIME [epoch: 5.7 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33396722612021196		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.33396722612021196 | validation: 0.18554986167090268]
	TIME [epoch: 5.7 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3380985363424466		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.3380985363424466 | validation: 0.1869811785602665]
	TIME [epoch: 5.73 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33757474704253115		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.33757474704253115 | validation: 0.17176469865446276]
	TIME [epoch: 5.7 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3403089616711635		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.3403089616711635 | validation: 0.1839118206725037]
	TIME [epoch: 5.7 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3312003214323277		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.3312003214323277 | validation: 0.18517080145759543]
	TIME [epoch: 5.7 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3370376185121159		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.3370376185121159 | validation: 0.17639874225283567]
	TIME [epoch: 5.7 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385006367518372		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.3385006367518372 | validation: 0.17646335155578727]
	TIME [epoch: 5.7 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3311767668535831		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.3311767668535831 | validation: 0.1813628250853107]
	TIME [epoch: 5.71 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3342861957472537		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.3342861957472537 | validation: 0.18468640803475495]
	TIME [epoch: 5.73 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3411538445330572		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.3411538445330572 | validation: 0.18286969547563445]
	TIME [epoch: 5.7 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33649207070002385		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.33649207070002385 | validation: 0.1817472063482071]
	TIME [epoch: 5.7 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307186427107502		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.3307186427107502 | validation: 0.1853702639835072]
	TIME [epoch: 5.7 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3369022438161457		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.3369022438161457 | validation: 0.20260540082488795]
	TIME [epoch: 5.7 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3458093031707753		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.3458093031707753 | validation: 0.20185029759081397]
	TIME [epoch: 5.7 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3330646081380332		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.3330646081380332 | validation: 0.18973216888096928]
	TIME [epoch: 5.73 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3360225348118741		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.3360225348118741 | validation: 0.19016139700373194]
	TIME [epoch: 5.7 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32912937874289383		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.32912937874289383 | validation: 0.17373085203812685]
	TIME [epoch: 5.7 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3387524060337807		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.3387524060337807 | validation: 0.17975925807235882]
	TIME [epoch: 5.7 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3348450553974387		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.3348450553974387 | validation: 0.1871794679999301]
	TIME [epoch: 5.7 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33926442985622063		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.33926442985622063 | validation: 0.18916712972136168]
	TIME [epoch: 5.7 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33118980036857926		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.33118980036857926 | validation: 0.19249524644911759]
	TIME [epoch: 5.71 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3390646414033443		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.3390646414033443 | validation: 0.19874356007368646]
	TIME [epoch: 5.72 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33985336465803057		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.33985336465803057 | validation: 0.18550740019131085]
	TIME [epoch: 5.7 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33177596695228084		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.33177596695228084 | validation: 0.17891399661397714]
	TIME [epoch: 5.7 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362267000822874		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.3362267000822874 | validation: 0.17629420599386214]
	TIME [epoch: 5.7 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331487231552162		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.331487231552162 | validation: 0.1937616216594373]
	TIME [epoch: 5.7 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33781086513274217		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.33781086513274217 | validation: 0.1822748568103657]
	TIME [epoch: 5.7 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33236228059560236		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.33236228059560236 | validation: 0.1715523788107678]
	TIME [epoch: 5.73 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3358361173950417		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.3358361173950417 | validation: 0.1800503201984269]
	TIME [epoch: 5.7 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.337664552016369		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.337664552016369 | validation: 0.18250599649925392]
	TIME [epoch: 5.7 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33578510385805327		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.33578510385805327 | validation: 0.18742585632567035]
	TIME [epoch: 5.7 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3396697958455595		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.3396697958455595 | validation: 0.16798928146137904]
	TIME [epoch: 5.7 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33529856740713276		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.33529856740713276 | validation: 0.18865467860643692]
	TIME [epoch: 5.7 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3377662589637		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.3377662589637 | validation: 0.17955050403192832]
	TIME [epoch: 5.71 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3369026508235452		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.3369026508235452 | validation: 0.17715012219099366]
	TIME [epoch: 5.72 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33264584946864745		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.33264584946864745 | validation: 0.17812490258643693]
	TIME [epoch: 5.7 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3354692059213878		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.3354692059213878 | validation: 0.1845926203096583]
	TIME [epoch: 5.7 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33728234824202996		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.33728234824202996 | validation: 0.17890554484524185]
	TIME [epoch: 5.7 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33632695270463897		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.33632695270463897 | validation: 0.17770169495250593]
	TIME [epoch: 5.7 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3381928093252773		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.3381928093252773 | validation: 0.18763743892718515]
	TIME [epoch: 5.7 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33665269735191033		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.33665269735191033 | validation: 0.17752049543415765]
	TIME [epoch: 5.73 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3373007496967705		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.3373007496967705 | validation: 0.17914951327804868]
	TIME [epoch: 5.71 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33054759258666283		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.33054759258666283 | validation: 0.18006989322308287]
	TIME [epoch: 5.7 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3332338493287458		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.3332338493287458 | validation: 0.18108907402219224]
	TIME [epoch: 5.7 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3376305029178746		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.3376305029178746 | validation: 0.1805797823246357]
	TIME [epoch: 5.7 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3358959311543619		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.3358959311543619 | validation: 0.1739995305918304]
	TIME [epoch: 5.7 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34427483185547214		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.34427483185547214 | validation: 0.17850092371311288]
	TIME [epoch: 5.71 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3389254075208834		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.3389254075208834 | validation: 0.1722307575853453]
	TIME [epoch: 5.73 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33417470891113404		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.33417470891113404 | validation: 0.18456898670278896]
	TIME [epoch: 5.7 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33749808423201305		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.33749808423201305 | validation: 0.17760797664168956]
	TIME [epoch: 5.7 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3331584200429403		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.3331584200429403 | validation: 0.17726424616568914]
	TIME [epoch: 5.7 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33835676581766283		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.33835676581766283 | validation: 0.1749532642607182]
	TIME [epoch: 5.7 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3314754868786001		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.3314754868786001 | validation: 0.17381106945430908]
	TIME [epoch: 5.7 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3357558220158157		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.3357558220158157 | validation: 0.1679392764612123]
	TIME [epoch: 5.73 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3425224588345736		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.3425224588345736 | validation: 0.17888069895540554]
	TIME [epoch: 5.71 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3358547140061606		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.3358547140061606 | validation: 0.16768634626107015]
	TIME [epoch: 5.7 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3323266307473522		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.3323266307473522 | validation: 0.17036178797498985]
	TIME [epoch: 5.7 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3370523522396529		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.3370523522396529 | validation: 0.17950788955999297]
	TIME [epoch: 5.7 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33269947562343727		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.33269947562343727 | validation: 0.18074477540858]
	TIME [epoch: 5.7 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3381970322483361		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.3381970322483361 | validation: 0.1859478231962209]
	TIME [epoch: 5.71 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3359806515517223		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.3359806515517223 | validation: 0.17990254898055694]
	TIME [epoch: 5.72 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3328226963898125		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.3328226963898125 | validation: 0.1882174392773346]
	TIME [epoch: 5.7 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33072430672070846		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.33072430672070846 | validation: 0.17871910468173582]
	TIME [epoch: 5.7 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33577048403169896		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.33577048403169896 | validation: 0.17578746696088277]
	TIME [epoch: 5.7 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33605877196107026		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.33605877196107026 | validation: 0.177250913014416]
	TIME [epoch: 5.7 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3323418248528232		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.3323418248528232 | validation: 0.1759059557622698]
	TIME [epoch: 5.7 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33033360338967577		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.33033360338967577 | validation: 0.17428796884387623]
	TIME [epoch: 5.73 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3309923133910886		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.3309923133910886 | validation: 0.17504706074540408]
	TIME [epoch: 5.71 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3313533714975323		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.3313533714975323 | validation: 0.17849726337530392]
	TIME [epoch: 5.7 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33557075417472215		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.33557075417472215 | validation: 0.17355021989183136]
	TIME [epoch: 5.7 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33641125014757256		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.33641125014757256 | validation: 0.17723753179498936]
	TIME [epoch: 5.7 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33439997123644927		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.33439997123644927 | validation: 0.16939029172418438]
	TIME [epoch: 5.7 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33740530398383706		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.33740530398383706 | validation: 0.17419684421246934]
	TIME [epoch: 5.71 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33302779535100063		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.33302779535100063 | validation: 0.18924454041898642]
	TIME [epoch: 5.73 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299000132069315		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.3299000132069315 | validation: 0.18246999353648563]
	TIME [epoch: 5.7 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33219952518555373		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.33219952518555373 | validation: 0.1868225495046101]
	TIME [epoch: 5.7 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.330267309297456		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.330267309297456 | validation: 0.18344935651026853]
	TIME [epoch: 5.7 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33791603921571167		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.33791603921571167 | validation: 0.1850729979559245]
	TIME [epoch: 5.7 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3311470213765913		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.3311470213765913 | validation: 0.18022464471596344]
	TIME [epoch: 5.7 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.337617660043912		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.337617660043912 | validation: 0.17888085551687014]
	TIME [epoch: 5.73 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33739550408011326		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.33739550408011326 | validation: 0.19525928052601757]
	TIME [epoch: 5.7 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3359126637011985		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.3359126637011985 | validation: 0.18929693837934075]
	TIME [epoch: 5.7 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3392626383316535		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.3392626383316535 | validation: 0.18599814348033725]
	TIME [epoch: 5.7 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362817465589205		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.3362817465589205 | validation: 0.18123278813417149]
	TIME [epoch: 5.7 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336466893471575		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.3336466893471575 | validation: 0.17168738320899699]
	TIME [epoch: 5.7 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33489033382789984		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.33489033382789984 | validation: 0.17866674065976715]
	TIME [epoch: 5.71 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3359724382398859		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.3359724382398859 | validation: 0.1775443146799034]
	TIME [epoch: 5.73 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3328315340275398		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.3328315340275398 | validation: 0.18353844215672246]
	TIME [epoch: 5.7 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316374406683401		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.3316374406683401 | validation: 0.1918971967388673]
	TIME [epoch: 5.7 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318764820257587		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.3318764820257587 | validation: 0.17653939574501057]
	TIME [epoch: 5.7 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33496836132652735		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.33496836132652735 | validation: 0.17637830480161146]
	TIME [epoch: 5.7 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316616497081607		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.3316616497081607 | validation: 0.1767049086219108]
	TIME [epoch: 5.7 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3333170471307256		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.3333170471307256 | validation: 0.1741069472119893]
	TIME [epoch: 5.73 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3363018851631827		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.3363018851631827 | validation: 0.17371600533729617]
	TIME [epoch: 5.7 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33412333138563655		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.33412333138563655 | validation: 0.1800130327170534]
	TIME [epoch: 5.7 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3349438540903632		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.3349438540903632 | validation: 0.17763199991329562]
	TIME [epoch: 5.7 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33082378223210557		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.33082378223210557 | validation: 0.19396893741142357]
	TIME [epoch: 5.7 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33443194531132775		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.33443194531132775 | validation: 0.1824633113394248]
	TIME [epoch: 5.7 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33524762985823137		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.33524762985823137 | validation: 0.17300403244298806]
	TIME [epoch: 5.71 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33352247443810357		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.33352247443810357 | validation: 0.18771621844770803]
	TIME [epoch: 5.73 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33299572491922913		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.33299572491922913 | validation: 0.17634740839181035]
	TIME [epoch: 5.7 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33555749276219204		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.33555749276219204 | validation: 0.18510028063380496]
	TIME [epoch: 5.7 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33066493575400596		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.33066493575400596 | validation: 0.19047864857314328]
	TIME [epoch: 5.7 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33557692976277254		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.33557692976277254 | validation: 0.18448482804611094]
	TIME [epoch: 5.7 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3350245859767367		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.3350245859767367 | validation: 0.18706595576693386]
	TIME [epoch: 5.7 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301504585137945		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.3301504585137945 | validation: 0.18024393588986937]
	TIME [epoch: 5.73 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3337205795344664		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.3337205795344664 | validation: 0.19553641786364093]
	TIME [epoch: 5.7 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33561509100193126		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.33561509100193126 | validation: 0.19197343690255778]
	TIME [epoch: 5.7 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3368287504168923		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.3368287504168923 | validation: 0.19458238346400422]
	TIME [epoch: 5.7 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3390345185832268		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.3390345185832268 | validation: 0.18196591173197746]
	TIME [epoch: 5.7 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3346943669214637		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.3346943669214637 | validation: 0.1895419259681667]
	TIME [epoch: 5.7 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336007443763452		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.3336007443763452 | validation: 0.1904556503969913]
	TIME [epoch: 5.71 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33345041987111546		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.33345041987111546 | validation: 0.18480174374910902]
	TIME [epoch: 5.72 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3351856647367471		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.3351856647367471 | validation: 0.18780909982513863]
	TIME [epoch: 5.7 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362466934321637		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.3362466934321637 | validation: 0.1674812517557308]
	TIME [epoch: 5.7 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33558672555216473		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.33558672555216473 | validation: 0.18258754673703556]
	TIME [epoch: 5.72 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33246157282128574		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.33246157282128574 | validation: 0.1686741200437016]
	TIME [epoch: 5.7 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307129131884424		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.3307129131884424 | validation: 0.1750525042493224]
	TIME [epoch: 5.7 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372077017411428		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.3372077017411428 | validation: 0.17900815373901816]
	TIME [epoch: 5.73 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3323894867369491		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.3323894867369491 | validation: 0.18164492862612364]
	TIME [epoch: 5.71 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316989654365751		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.3316989654365751 | validation: 0.19206229068478217]
	TIME [epoch: 5.7 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3354309455961072		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.3354309455961072 | validation: 0.189746523400214]
	TIME [epoch: 5.7 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329905173155199		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.3329905173155199 | validation: 0.188527293557307]
	TIME [epoch: 5.7 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33283594058587185		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.33283594058587185 | validation: 0.1819800001506468]
	TIME [epoch: 5.7 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3349371194536678		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.3349371194536678 | validation: 0.17879490739127957]
	TIME [epoch: 5.71 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3341693321455582		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.3341693321455582 | validation: 0.18819716616027535]
	TIME [epoch: 5.73 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3402894644247964		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.3402894644247964 | validation: 0.18605054853871683]
	TIME [epoch: 5.7 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307634138446115		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.3307634138446115 | validation: 0.17857154018852087]
	TIME [epoch: 5.7 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3286083804218121		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.3286083804218121 | validation: 0.18322133542855384]
	TIME [epoch: 5.7 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3341381314110369		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.3341381314110369 | validation: 0.1877573176610224]
	TIME [epoch: 5.7 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.330892750827458		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.330892750827458 | validation: 0.1803411349144779]
	TIME [epoch: 5.7 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3324004954567901		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.3324004954567901 | validation: 0.17219440038278955]
	TIME [epoch: 5.73 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33416980400020374		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.33416980400020374 | validation: 0.1748679096799195]
	TIME [epoch: 5.71 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33493958330284695		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.33493958330284695 | validation: 0.18446792670621961]
	TIME [epoch: 5.7 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32709668478742915		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.32709668478742915 | validation: 0.18331462588415653]
	TIME [epoch: 5.7 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33379126448657903		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.33379126448657903 | validation: 0.17281545796794082]
	TIME [epoch: 5.7 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3328076237746781		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.3328076237746781 | validation: 0.17705402921660185]
	TIME [epoch: 5.7 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.336178671124722		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.336178671124722 | validation: 0.18478079215615675]
	TIME [epoch: 5.71 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33200893399015674		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.33200893399015674 | validation: 0.18157371044569412]
	TIME [epoch: 5.73 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33621506921759997		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.33621506921759997 | validation: 0.19176833960870185]
	TIME [epoch: 5.7 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3293387578169993		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.3293387578169993 | validation: 0.18500157406274184]
	TIME [epoch: 5.7 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301121795188603		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.3301121795188603 | validation: 0.19223728519914848]
	TIME [epoch: 5.7 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372227705773158		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.3372227705773158 | validation: 0.19096558144436984]
	TIME [epoch: 5.7 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33420511608712455		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.33420511608712455 | validation: 0.18674918897386028]
	TIME [epoch: 5.7 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33094428589820263		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.33094428589820263 | validation: 0.19541453782571871]
	TIME [epoch: 5.73 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33319062705496855		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.33319062705496855 | validation: 0.1832981544322909]
	TIME [epoch: 5.71 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33169674072608835		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.33169674072608835 | validation: 0.17732350070405636]
	TIME [epoch: 5.7 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3302065109070131		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.3302065109070131 | validation: 0.19037220773987287]
	TIME [epoch: 5.7 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3309120135948835		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.3309120135948835 | validation: 0.18161066223650849]
	TIME [epoch: 5.7 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33026006730770063		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.33026006730770063 | validation: 0.19740649760973447]
	TIME [epoch: 5.7 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33417443699770466		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.33417443699770466 | validation: 0.20074275699293864]
	TIME [epoch: 5.71 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3417904703038559		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.3417904703038559 | validation: 0.20982351369973398]
	TIME [epoch: 5.73 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3428296644444565		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.3428296644444565 | validation: 0.19637783861002273]
	TIME [epoch: 5.7 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3347926172862116		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.3347926172862116 | validation: 0.20234628592944565]
	TIME [epoch: 5.7 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33259666137306937		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.33259666137306937 | validation: 0.20088724500132685]
	TIME [epoch: 5.7 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326965245031353		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.3326965245031353 | validation: 0.18821036216355413]
	TIME [epoch: 5.7 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316432463778941		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.3316432463778941 | validation: 0.18699626528356128]
	TIME [epoch: 5.7 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33506083757074406		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.33506083757074406 | validation: 0.1794371402623707]
	TIME [epoch: 5.73 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32941895692652545		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.32941895692652545 | validation: 0.18322257686179957]
	TIME [epoch: 5.7 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33464641142220175		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.33464641142220175 | validation: 0.17414109785546145]
	TIME [epoch: 5.7 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3303315145815256		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.3303315145815256 | validation: 0.17335871907899567]
	TIME [epoch: 5.7 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3302114548143094		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.3302114548143094 | validation: 0.18401931497158558]
	TIME [epoch: 5.7 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3317197104041104		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.3317197104041104 | validation: 0.17983049417752425]
	TIME [epoch: 5.7 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32897339544175663		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.32897339544175663 | validation: 0.1714132143345587]
	TIME [epoch: 5.71 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3289456778437154		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.3289456778437154 | validation: 0.17991497702433812]
	TIME [epoch: 5.73 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299749902696552		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.3299749902696552 | validation: 0.18107261268326497]
	TIME [epoch: 5.7 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299198039497311		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.3299198039497311 | validation: 0.18746479619608866]
	TIME [epoch: 5.7 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3315397077822946		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.3315397077822946 | validation: 0.1819524674710039]
	TIME [epoch: 5.7 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32830642448636904		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.32830642448636904 | validation: 0.18268246416845565]
	TIME [epoch: 5.7 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307474953967291		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.3307474953967291 | validation: 0.17992101869872895]
	TIME [epoch: 5.7 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33296494147781275		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.33296494147781275 | validation: 0.18123013770830806]
	TIME [epoch: 5.73 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33029495815364374		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.33029495815364374 | validation: 0.19309402450534535]
	TIME [epoch: 5.7 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3314275922925165		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.3314275922925165 | validation: 0.1883597228710339]
	TIME [epoch: 5.7 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33509438558896243		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.33509438558896243 | validation: 0.18999142372459063]
	TIME [epoch: 5.7 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3371936215643704		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.3371936215643704 | validation: 0.18611259108548436]
	TIME [epoch: 5.7 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336048053976315		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.3336048053976315 | validation: 0.18665167557501897]
	TIME [epoch: 5.7 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3377238087588477		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.3377238087588477 | validation: 0.20618929105644185]
	TIME [epoch: 5.71 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385889217456022		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.3385889217456022 | validation: 0.19962722069332997]
	TIME [epoch: 5.73 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33627228549398924		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.33627228549398924 | validation: 0.19659196951909985]
	TIME [epoch: 5.7 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331867880909109		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.331867880909109 | validation: 0.17070766125986317]
	TIME [epoch: 5.7 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3337471098408855		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.3337471098408855 | validation: 0.1805496159263782]
	TIME [epoch: 5.7 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33550415404082223		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.33550415404082223 | validation: 0.18820558171239715]
	TIME [epoch: 5.7 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3339329586784774		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.3339329586784774 | validation: 0.1902967262205655]
	TIME [epoch: 5.7 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.334468718326302		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.334468718326302 | validation: 0.1857066734892085]
	TIME [epoch: 5.73 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34046413013093		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.34046413013093 | validation: 0.19188201288972095]
	TIME [epoch: 5.7 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3349438455758913		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.3349438455758913 | validation: 0.19515450110214502]
	TIME [epoch: 5.7 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33338204790131265		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.33338204790131265 | validation: 0.18099551134292205]
	TIME [epoch: 5.7 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3317619578215585		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.3317619578215585 | validation: 0.1951221852791275]
	TIME [epoch: 5.7 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33251065769396304		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.33251065769396304 | validation: 0.18367252507812773]
	TIME [epoch: 5.7 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3331738787290964		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.3331738787290964 | validation: 0.1873564381602058]
	TIME [epoch: 5.71 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33702964520131046		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.33702964520131046 | validation: 0.18950569002792997]
	TIME [epoch: 5.73 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329239950293831		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.3329239950293831 | validation: 0.17856169426568677]
	TIME [epoch: 5.7 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3358788770371556		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.3358788770371556 | validation: 0.1780058275377699]
	TIME [epoch: 5.7 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3324181866326448		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.3324181866326448 | validation: 0.18698079948659213]
	TIME [epoch: 5.7 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33566104368253613		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.33566104368253613 | validation: 0.1752366646550316]
	TIME [epoch: 5.7 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32768991427462063		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.32768991427462063 | validation: 0.18565262025098755]
	TIME [epoch: 5.7 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336351072223773		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.3336351072223773 | validation: 0.18849155460862835]
	TIME [epoch: 5.73 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3296419874545167		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.3296419874545167 | validation: 0.1803874286868134]
	TIME [epoch: 5.7 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331270115575788		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.331270115575788 | validation: 0.17903765738826785]
	TIME [epoch: 5.7 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33046421074529475		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.33046421074529475 | validation: 0.18012385496072975]
	TIME [epoch: 5.7 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3323253160421329		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.3323253160421329 | validation: 0.18263275638790905]
	TIME [epoch: 5.7 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33049167068938967		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.33049167068938967 | validation: 0.1812521065581686]
	TIME [epoch: 5.7 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338447430124897		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.3338447430124897 | validation: 0.18265019332084154]
	TIME [epoch: 5.71 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.337118063649295		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.337118063649295 | validation: 0.1730736814811069]
	TIME [epoch: 5.73 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.335910809060595		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.335910809060595 | validation: 0.1752473643407603]
	TIME [epoch: 5.7 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3377292164846549		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.3377292164846549 | validation: 0.17246037474675033]
	TIME [epoch: 5.7 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3337869807823508		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.3337869807823508 | validation: 0.18001404086263187]
	TIME [epoch: 5.7 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33546604647259687		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.33546604647259687 | validation: 0.16980263384670666]
	TIME [epoch: 5.7 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3334663659734573		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.3334663659734573 | validation: 0.17967307346983594]
	TIME [epoch: 5.7 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3303659301206583		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.3303659301206583 | validation: 0.18051265986324258]
	TIME [epoch: 5.73 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301778443446456		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.3301778443446456 | validation: 0.17718927821207864]
	TIME [epoch: 5.71 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321728562042633		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.3321728562042633 | validation: 0.18808168105195236]
	TIME [epoch: 5.7 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32998855910005437		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.32998855910005437 | validation: 0.17601038314269943]
	TIME [epoch: 5.7 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33479557688006434		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.33479557688006434 | validation: 0.18843782355181135]
	TIME [epoch: 5.7 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33335472606322036		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.33335472606322036 | validation: 0.17774193761676038]
	TIME [epoch: 5.7 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3314568756276021		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.3314568756276021 | validation: 0.17362402672262955]
	TIME [epoch: 5.71 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333654473917627		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.333654473917627 | validation: 0.17975078196429775]
	TIME [epoch: 5.73 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331058378851546		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.331058378851546 | validation: 0.18400200802547687]
	TIME [epoch: 5.7 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33421860749701426		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.33421860749701426 | validation: 0.1735925770235265]
	TIME [epoch: 5.7 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326309371147948		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.3326309371147948 | validation: 0.1873347790495664]
	TIME [epoch: 5.7 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3313406036340908		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.3313406036340908 | validation: 0.17909931760127887]
	TIME [epoch: 5.7 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33056273860677354		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.33056273860677354 | validation: 0.17545377712122978]
	TIME [epoch: 5.7 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33098848402603176		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.33098848402603176 | validation: 0.17795417975037262]
	TIME [epoch: 5.73 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295914613048349		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.3295914613048349 | validation: 0.1795075315310917]
	TIME [epoch: 5.7 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33270185597883994		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.33270185597883994 | validation: 0.18967470064444847]
	TIME [epoch: 5.7 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326275571509021		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.3326275571509021 | validation: 0.18720509208254985]
	TIME [epoch: 5.7 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33521882091589617		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.33521882091589617 | validation: 0.18504217628961697]
	TIME [epoch: 5.7 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33279833232431905		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.33279833232431905 | validation: 0.19589726597864845]
	TIME [epoch: 5.7 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301294750644448		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.3301294750644448 | validation: 0.1791177805848294]
	TIME [epoch: 5.71 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3257488275425975		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.3257488275425975 | validation: 0.17587038710566197]
	TIME [epoch: 5.72 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32894320307059244		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.32894320307059244 | validation: 0.17426917222513594]
	TIME [epoch: 5.7 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33711024347200713		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.33711024347200713 | validation: 0.1661766732742801]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_1865.pth
	Model improved!!!
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3377350537384703		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.3377350537384703 | validation: 0.17638893773459408]
	TIME [epoch: 5.7 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33422585159004853		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.33422585159004853 | validation: 0.17758474986163778]
	TIME [epoch: 5.7 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33122239174552104		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.33122239174552104 | validation: 0.18919395216321128]
	TIME [epoch: 5.7 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3350033126836577		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.3350033126836577 | validation: 0.183362102665522]
	TIME [epoch: 5.73 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3290377794862819		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.3290377794862819 | validation: 0.1811691725442951]
	TIME [epoch: 5.7 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33472964291838303		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.33472964291838303 | validation: 0.1761741770970078]
	TIME [epoch: 5.7 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3315879779601052		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.3315879779601052 | validation: 0.1786609122382776]
	TIME [epoch: 5.7 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32899002134518246		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.32899002134518246 | validation: 0.1647960840776991]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r1_20240310_010406/states/model_tr_study201_1873.pth
	Model improved!!!
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33039028724272435		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.33039028724272435 | validation: 0.1777842761057996]
	TIME [epoch: 5.7 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3288153845854822		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.3288153845854822 | validation: 0.17388328928264823]
	TIME [epoch: 5.72 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.332046802723055		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.332046802723055 | validation: 0.17469002383615434]
	TIME [epoch: 5.71 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32987555761720483		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.32987555761720483 | validation: 0.17521229106102332]
	TIME [epoch: 5.7 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3304787011700999		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.3304787011700999 | validation: 0.17763562545183298]
	TIME [epoch: 5.7 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3302608865726643		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.3302608865726643 | validation: 0.18696809842863957]
	TIME [epoch: 5.7 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33030276142436893		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.33030276142436893 | validation: 0.18042377983667593]
	TIME [epoch: 5.7 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3282852164479474		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.3282852164479474 | validation: 0.1859251679689356]
	TIME [epoch: 5.7 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33217934645418606		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.33217934645418606 | validation: 0.20564678058716432]
	TIME [epoch: 5.74 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3339516552089152		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.3339516552089152 | validation: 0.18097080797538526]
	TIME [epoch: 5.7 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33221722740412657		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.33221722740412657 | validation: 0.17015670597817245]
	TIME [epoch: 5.7 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3320419422299846		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.3320419422299846 | validation: 0.1831962546443222]
	TIME [epoch: 5.7 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32873369982668327		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.32873369982668327 | validation: 0.18584435829245052]
	TIME [epoch: 5.7 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3284975201973206		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.3284975201973206 | validation: 0.17643442501580278]
	TIME [epoch: 5.7 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.326730637067436		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.326730637067436 | validation: 0.18081499847448804]
	TIME [epoch: 5.72 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318040880785197		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.3318040880785197 | validation: 0.18267765526598378]
	TIME [epoch: 5.71 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33242589412442214		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.33242589412442214 | validation: 0.19702314712975813]
	TIME [epoch: 5.7 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3290293043612803		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.3290293043612803 | validation: 0.1896009495780692]
	TIME [epoch: 5.7 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33268402274824355		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.33268402274824355 | validation: 0.17997363296879448]
	TIME [epoch: 5.7 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33116489223070467		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.33116489223070467 | validation: 0.19421086219724906]
	TIME [epoch: 5.7 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333727869622665		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.333727869622665 | validation: 0.19358877375493927]
	TIME [epoch: 5.7 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33418959235676016		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.33418959235676016 | validation: 0.1830658451296431]
	TIME [epoch: 5.73 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3292472296713496		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.3292472296713496 | validation: 0.1912759623187758]
	TIME [epoch: 5.7 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316271715581182		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.3316271715581182 | validation: 0.19167354997658578]
	TIME [epoch: 5.7 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3349592165861284		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.3349592165861284 | validation: 0.19201408498397088]
	TIME [epoch: 5.7 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3324475641788159		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.3324475641788159 | validation: 0.18212686779872875]
	TIME [epoch: 5.7 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3368537018303551		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.3368537018303551 | validation: 0.19316918833593433]
	TIME [epoch: 5.7 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33154649567865174		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.33154649567865174 | validation: 0.18086548945468445]
	TIME [epoch: 5.72 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3300305653479444		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.3300305653479444 | validation: 0.18724939360812193]
	TIME [epoch: 5.71 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3332447598010171		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.3332447598010171 | validation: 0.18718205499521323]
	TIME [epoch: 5.7 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.330203906709179		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.330203906709179 | validation: 0.18326531042953662]
	TIME [epoch: 5.7 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336352637381993		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.3336352637381993 | validation: 0.18632322487483677]
	TIME [epoch: 5.7 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3327441607673767		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.3327441607673767 | validation: 0.18665988410003087]
	TIME [epoch: 5.7 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.330681425306925		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.330681425306925 | validation: 0.17937828913043846]
	TIME [epoch: 5.7 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3302805130470265		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.3302805130470265 | validation: 0.1790898507952985]
	TIME [epoch: 5.74 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32679810588006186		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.32679810588006186 | validation: 0.1972535181198005]
	TIME [epoch: 5.7 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3345563184353106		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.3345563184353106 | validation: 0.19863970669031136]
	TIME [epoch: 5.7 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336135293206677		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.3336135293206677 | validation: 0.18677050102254109]
	TIME [epoch: 5.7 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3320645784142112		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.3320645784142112 | validation: 0.183772984252833]
	TIME [epoch: 5.7 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33286644877192106		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.33286644877192106 | validation: 0.18907124305642886]
	TIME [epoch: 5.7 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3339946599157117		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.3339946599157117 | validation: 0.18635340478954632]
	TIME [epoch: 5.73 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3312770919827839		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.3312770919827839 | validation: 0.17447335333363548]
	TIME [epoch: 5.71 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3300106913856801		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.3300106913856801 | validation: 0.18653982087116222]
	TIME [epoch: 5.7 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33020638315127954		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.33020638315127954 | validation: 0.18723640670549457]
	TIME [epoch: 5.7 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329797746628873		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.3329797746628873 | validation: 0.19172362069509652]
	TIME [epoch: 5.7 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3340480468479928		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.3340480468479928 | validation: 0.19049825664038816]
	TIME [epoch: 5.7 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32736701171145915		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.32736701171145915 | validation: 0.18710979395303404]
	TIME [epoch: 5.7 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32734473789209284		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.32734473789209284 | validation: 0.17394657515297127]
	TIME [epoch: 5.73 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3287834198987497		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.3287834198987497 | validation: 0.1770423034399142]
	TIME [epoch: 5.7 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32749831041273497		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.32749831041273497 | validation: 0.18413060256278654]
	TIME [epoch: 5.7 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33080306175010005		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.33080306175010005 | validation: 0.18137311097030404]
	TIME [epoch: 5.7 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33367083083323407		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.33367083083323407 | validation: 0.16759340532346656]
	TIME [epoch: 5.7 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3332591277057635		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.3332591277057635 | validation: 0.17978731381362767]
	TIME [epoch: 5.7 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.326509518990286		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.326509518990286 | validation: 0.1775605804077749]
	TIME [epoch: 5.72 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3330261753826208		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.3330261753826208 | validation: 0.186944859101446]
	TIME [epoch: 5.71 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295267475739394		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.3295267475739394 | validation: 0.17993064694947847]
	TIME [epoch: 5.7 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33008464120606096		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.33008464120606096 | validation: 0.191366470237193]
	TIME [epoch: 5.7 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3314688338380715		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.3314688338380715 | validation: 0.1832552856659929]
	TIME [epoch: 5.7 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3273831853309414		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.3273831853309414 | validation: 0.178190158425028]
	TIME [epoch: 5.7 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3252982763087372		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.3252982763087372 | validation: 0.17889055126461093]
	TIME [epoch: 5.7 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3374743961905442		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.3374743961905442 | validation: 0.1852783069044734]
	TIME [epoch: 5.73 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3311150575596853		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.3311150575596853 | validation: 0.18189496930431281]
	TIME [epoch: 5.7 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3327434309084036		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.3327434309084036 | validation: 0.18304070329405173]
	TIME [epoch: 5.7 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32788308591764515		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.32788308591764515 | validation: 0.17725032165971846]
	TIME [epoch: 5.7 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33414952168213363		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.33414952168213363 | validation: 0.1701356318008936]
	TIME [epoch: 5.7 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307854376731176		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.3307854376731176 | validation: 0.17622809365851616]
	TIME [epoch: 5.7 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3290127651384501		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.3290127651384501 | validation: 0.17884134186110331]
	TIME [epoch: 5.72 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3284094739215321		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.3284094739215321 | validation: 0.17998662152343592]
	TIME [epoch: 5.71 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3261289133729548		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.3261289133729548 | validation: 0.1768675237743291]
	TIME [epoch: 5.7 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3314198897397917		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.3314198897397917 | validation: 0.18104174665814823]
	TIME [epoch: 5.7 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.332470420386188		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.332470420386188 | validation: 0.18419848084406024]
	TIME [epoch: 5.7 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3317955791069413		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.3317955791069413 | validation: 0.1826445664143857]
	TIME [epoch: 5.7 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3324344364832578		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.3324344364832578 | validation: 0.17119898214980975]
	TIME [epoch: 5.7 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3308459888119063		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.3308459888119063 | validation: 0.1811166060624311]
	TIME [epoch: 5.73 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3325433596854526		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.3325433596854526 | validation: 0.19223928513815275]
	TIME [epoch: 5.7 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3344724383397393		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.3344724383397393 | validation: 0.1959063228000581]
	TIME [epoch: 5.7 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33448414783415004		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.33448414783415004 | validation: 0.197410326926966]
	TIME [epoch: 5.7 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3331401347256334		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.3331401347256334 | validation: 0.19847990147997088]
	TIME [epoch: 5.7 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33407334724466353		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.33407334724466353 | validation: 0.1903356748721623]
	TIME [epoch: 5.7 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33681437920230073		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.33681437920230073 | validation: 0.19814207032674955]
	TIME [epoch: 5.72 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3337680503913999		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.3337680503913999 | validation: 0.1759370331940388]
	TIME [epoch: 5.71 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3289557929956695		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.3289557929956695 | validation: 0.18630027400994933]
	TIME [epoch: 5.7 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338045367790996		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.3338045367790996 | validation: 0.17889481173875177]
	TIME [epoch: 5.7 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3290099074973982		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.3290099074973982 | validation: 0.17537953166187858]
	TIME [epoch: 5.7 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3308534283562249		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.3308534283562249 | validation: 0.18263103222032526]
	TIME [epoch: 5.7 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3334157819274707		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.3334157819274707 | validation: 0.1785528159286209]
	TIME [epoch: 5.7 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3288100099189025		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.3288100099189025 | validation: 0.183675421867868]
	TIME [epoch: 5.73 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3300058000238978		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.3300058000238978 | validation: 0.1821287438042382]
	TIME [epoch: 5.7 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33193434053158943		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.33193434053158943 | validation: 0.18387885465036452]
	TIME [epoch: 5.7 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33006800271125014		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.33006800271125014 | validation: 0.17258301079384322]
	TIME [epoch: 5.7 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33139452754867493		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.33139452754867493 | validation: 0.18515622501980145]
	TIME [epoch: 5.7 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32922658736147736		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.32922658736147736 | validation: 0.18269410793452187]
	TIME [epoch: 5.7 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301543891981359		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.3301543891981359 | validation: 0.1833129046609767]
	TIME [epoch: 5.72 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3304600962246259		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.3304600962246259 | validation: 0.18202335868552805]
	TIME [epoch: 5.71 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.330611138294642		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.330611138294642 | validation: 0.18742128404762765]
	TIME [epoch: 5.7 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3276382034154055		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.3276382034154055 | validation: 0.20270264058577261]
	TIME [epoch: 5.7 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321429362867551		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.3321429362867551 | validation: 0.18981802529035563]
	TIME [epoch: 5.7 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333199876068893		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.333199876068893 | validation: 0.18339700344592522]
	TIME [epoch: 5.7 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3289413522023629		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.3289413522023629 | validation: 0.1731614577043127]
	TIME [epoch: 5.7 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32862546902005935		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.32862546902005935 | validation: 0.17248062579629525]
	TIME [epoch: 5.73 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3298033924799702		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.3298033924799702 | validation: 0.17916296073915688]
	TIME [epoch: 5.7 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3387925362665011		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.3387925362665011 | validation: 0.1742365743470282]
	TIME [epoch: 5.7 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316345711368044		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.3316345711368044 | validation: 0.18338885546341963]
	TIME [epoch: 5.7 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343702304421459		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.3343702304421459 | validation: 0.18352429418225832]
	TIME [epoch: 5.7 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32934460479216426		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.32934460479216426 | validation: 0.17955142882060998]
	TIME [epoch: 5.7 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32373735270547843		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.32373735270547843 | validation: 0.1914917917899648]
	TIME [epoch: 5.72 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331848339185841		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.331848339185841 | validation: 0.1861383056807066]
	TIME [epoch: 5.71 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33126455749552847		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.33126455749552847 | validation: 0.19069249038342442]
	TIME [epoch: 5.7 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32934222161795734		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.32934222161795734 | validation: 0.18410149113620783]
	TIME [epoch: 5.7 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33409626091126504		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.33409626091126504 | validation: 0.19056161805511573]
	TIME [epoch: 5.7 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33098734442409083		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.33098734442409083 | validation: 0.18893141863457846]
	TIME [epoch: 5.7 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33098713883054875		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.33098713883054875 | validation: 0.18605008173897428]
	TIME [epoch: 5.7 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3342533331922256		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.3342533331922256 | validation: 0.1815936389123138]
	TIME [epoch: 5.73 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32818382863945833		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.32818382863945833 | validation: 0.18130017541092452]
	TIME [epoch: 5.7 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3317504853365528		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.3317504853365528 | validation: 0.1774407145152658]
	TIME [epoch: 5.7 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331091406410534		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.331091406410534 | validation: 0.1685559496444146]
	TIME [epoch: 5.7 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3358217164215823		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.3358217164215823 | validation: 0.17587911991020083]
	TIME [epoch: 5.7 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33249967981667533		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.33249967981667533 | validation: 0.18189394258983577]
	TIME [epoch: 5.7 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33334465118979145		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.33334465118979145 | validation: 0.1770601979605344]
	TIME [epoch: 5.72 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33245220067495057		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.33245220067495057 | validation: 0.18155134102312365]
	TIME [epoch: 5.71 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3312375384381284		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.3312375384381284 | validation: 0.18429624444966436]
	TIME [epoch: 5.7 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33543307272402273		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.33543307272402273 | validation: 0.17657993110970557]
	TIME [epoch: 5.7 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.328656743416839		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.328656743416839 | validation: 0.17854787065509947]
	TIME [epoch: 5.7 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3314752496251878		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.3314752496251878 | validation: 0.17827830104455208]
	TIME [epoch: 5.7 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318969675259029		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.3318969675259029 | validation: 0.18270161379688787]
	TIME [epoch: 5.7 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33304913630886684		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.33304913630886684 | validation: 0.18104117588969487]
	TIME [epoch: 5.73 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32603886559239836		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.32603886559239836 | validation: 0.18789509933728404]
	TIME [epoch: 5.7 sec]
Finished training in 11647.524 seconds.
