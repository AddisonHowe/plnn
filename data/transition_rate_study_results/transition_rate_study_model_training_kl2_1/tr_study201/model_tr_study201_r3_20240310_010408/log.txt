Args:
Namespace(name='model_tr_study201', outdir='out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3', training_data='data/transition_rate_studies/tr_study201/tr_study201_training/r3', validation_data='data/transition_rate_studies/tr_study201/tr_study201_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1055618808

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.839595920236501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.839595920236501 | validation: 12.709432168340545]
	TIME [epoch: 93.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.741758905894015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.741758905894015 | validation: 9.520033256651574]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.137294003568355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.137294003568355 | validation: 8.819733077641828]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.446487487907937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.446487487907937 | validation: 10.203322630087648]
	TIME [epoch: 5.74 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.819699982208567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.819699982208567 | validation: 10.140882280872816]
	TIME [epoch: 5.75 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.966163539320496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.966163539320496 | validation: 8.841407741643819]
	TIME [epoch: 5.74 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.327498341447273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.327498341447273 | validation: 6.524622610149061]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.14692995381622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.14692995381622 | validation: 7.836761055900062]
	TIME [epoch: 5.75 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.066554905579447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.066554905579447 | validation: 6.182054193205525]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.214436365558998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.214436365558998 | validation: 5.887069831842849]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.673696542346521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.673696542346521 | validation: 5.610886193865074]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.209786597777189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.209786597777189 | validation: 6.035670298961188]
	TIME [epoch: 5.75 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.81183872692773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.81183872692773 | validation: 5.577307737872296]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.944444153147755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.944444153147755 | validation: 5.6074457688288035]
	TIME [epoch: 5.74 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.670736573869714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.670736573869714 | validation: 5.729284047872263]
	TIME [epoch: 5.78 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.553780747505243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.553780747505243 | validation: 5.598294173868193]
	TIME [epoch: 5.74 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.003139600091873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.003139600091873 | validation: 5.360187107839438]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.789270040894852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.789270040894852 | validation: 5.526297207780831]
	TIME [epoch: 5.73 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4501655734916366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4501655734916366 | validation: 5.334000050074699]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.606662375944723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.606662375944723 | validation: 6.180766746042184]
	TIME [epoch: 5.73 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.466238118972524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.466238118972524 | validation: 5.7054521608926505]
	TIME [epoch: 5.75 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.373899958485811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.373899958485811 | validation: 5.1485877233713735]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.118037990622449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.118037990622449 | validation: 5.085406587639552]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.723958811576541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.723958811576541 | validation: 6.119085933516858]
	TIME [epoch: 5.73 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.273599010697307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.273599010697307 | validation: 5.116779018411195]
	TIME [epoch: 5.73 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.154147386643171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.154147386643171 | validation: 5.873207461339702]
	TIME [epoch: 5.73 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.15717169656325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.15717169656325 | validation: 5.03257424318463]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.149770902780983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.149770902780983 | validation: 4.892053142022523]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.950103357871383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.950103357871383 | validation: 4.9885847975499376]
	TIME [epoch: 5.74 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.909527352044579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.909527352044579 | validation: 5.926171298580211]
	TIME [epoch: 5.75 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.906887189880817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.906887189880817 | validation: 4.629530050864038]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0421748644678015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0421748644678015 | validation: 4.843700273926821]
	TIME [epoch: 5.73 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.06967974440572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.06967974440572 | validation: 5.994778314919396]
	TIME [epoch: 5.73 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.94882022013403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.94882022013403 | validation: 4.850937086835954]
	TIME [epoch: 5.74 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506267629866113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.506267629866113 | validation: 4.730050201172583]
	TIME [epoch: 5.78 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487863826183119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.487863826183119 | validation: 4.781322178823502]
	TIME [epoch: 5.73 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.036577503439445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.036577503439445 | validation: 4.438769424301755]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3268903329755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3268903329755 | validation: 4.725905432825909]
	TIME [epoch: 5.73 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9512857952135994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9512857952135994 | validation: 4.779598712282595]
	TIME [epoch: 5.73 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7642009123854843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7642009123854843 | validation: 5.0226825699330275]
	TIME [epoch: 5.73 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7681005815899518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7681005815899518 | validation: 4.427176961836631]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.072308406627637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.072308406627637 | validation: 4.34999815701994]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6259819483232123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6259819483232123 | validation: 4.880140866629156]
	TIME [epoch: 5.74 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.776395431414423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.776395431414423 | validation: 5.286056578282003]
	TIME [epoch: 5.75 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.943730106529782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.943730106529782 | validation: 4.7154348500947165]
	TIME [epoch: 5.73 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7048592164859007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7048592164859007 | validation: 4.4849058297873885]
	TIME [epoch: 5.74 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6963004850245156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6963004850245156 | validation: 4.465313621836317]
	TIME [epoch: 5.73 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.702864535377712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.702864535377712 | validation: 4.096763555591065]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6914850777087613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6914850777087613 | validation: 4.641277416680726]
	TIME [epoch: 5.75 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7025607249215793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7025607249215793 | validation: 4.862868060236439]
	TIME [epoch: 5.75 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5300874131901927		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.5300874131901927 | validation: 4.944925182562265]
	TIME [epoch: 5.75 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6440866114753474		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.6440866114753474 | validation: 4.564680241192636]
	TIME [epoch: 5.74 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4610352928171957		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.4610352928171957 | validation: 4.826521227947443]
	TIME [epoch: 5.74 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5215995664184936		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.5215995664184936 | validation: 4.340997010151479]
	TIME [epoch: 5.74 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5487421660712997		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.5487421660712997 | validation: 4.454665187461236]
	TIME [epoch: 5.79 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4825677485530506		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.4825677485530506 | validation: 4.680421515484686]
	TIME [epoch: 5.75 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.336749390182176		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.336749390182176 | validation: 4.603832406349012]
	TIME [epoch: 5.75 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.272511963048723		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.272511963048723 | validation: 4.738725389648769]
	TIME [epoch: 5.74 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6204406067175503		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.6204406067175503 | validation: 4.400623496123687]
	TIME [epoch: 5.75 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.381645514377765		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.381645514377765 | validation: 4.67220426575644]
	TIME [epoch: 5.74 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4352770983816705		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.4352770983816705 | validation: 3.974401047735642]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.19316132250417		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.19316132250417 | validation: 4.357857595053914]
	TIME [epoch: 5.78 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1973528338003545		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.1973528338003545 | validation: 5.297779711088975]
	TIME [epoch: 5.75 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5004872907924676		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.5004872907924676 | validation: 4.6288187626143085]
	TIME [epoch: 5.75 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122687908403997		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.2122687908403997 | validation: 4.214264090891179]
	TIME [epoch: 5.75 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.251270344152917		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.251270344152917 | validation: 4.546834128104625]
	TIME [epoch: 5.74 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2757591456580517		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.2757591456580517 | validation: 4.211263103285186]
	TIME [epoch: 5.74 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.353016080312864		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.353016080312864 | validation: 3.9072061734587624]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.923583073847384		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.923583073847384 | validation: 5.402245890010525]
	TIME [epoch: 5.75 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.289896478858733		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.289896478858733 | validation: 4.622242133451526]
	TIME [epoch: 5.74 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1471853474754217		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.1471853474754217 | validation: 5.5160239635393715]
	TIME [epoch: 5.74 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5376956173490877		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.5376956173490877 | validation: 4.291043089111603]
	TIME [epoch: 5.74 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.168987015523782		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.168987015523782 | validation: 3.917306698610892]
	TIME [epoch: 5.74 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1115021866571944		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.1115021866571944 | validation: 4.056536372780347]
	TIME [epoch: 5.77 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0571242880105505		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.0571242880105505 | validation: 4.021454990553357]
	TIME [epoch: 5.76 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1700553159450084		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.1700553159450084 | validation: 4.236535794785942]
	TIME [epoch: 5.74 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.079914900345063		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.079914900345063 | validation: 3.99655371478391]
	TIME [epoch: 5.74 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.821307923508967		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.821307923508967 | validation: 4.2274561732368205]
	TIME [epoch: 5.74 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.194885910519191		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.194885910519191 | validation: 4.1652061808221585]
	TIME [epoch: 5.74 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.001997839656883		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.001997839656883 | validation: 3.8569612656080956]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1691815703103883		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.1691815703103883 | validation: 3.926516135347704]
	TIME [epoch: 5.79 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.035031324126238		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.035031324126238 | validation: 4.153725585821859]
	TIME [epoch: 5.75 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9690308649860615		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.9690308649860615 | validation: 4.418761381116926]
	TIME [epoch: 5.74 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9671411997038533		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.9671411997038533 | validation: 3.5981103323759926]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0502880801087664		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.0502880801087664 | validation: 4.417529675403291]
	TIME [epoch: 5.74 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0073962040715903		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.0073962040715903 | validation: 4.2675275837734254]
	TIME [epoch: 5.75 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.823224324524361		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.823224324524361 | validation: 4.368441328097983]
	TIME [epoch: 5.76 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9921161653093082		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.9921161653093082 | validation: 4.242351927390331]
	TIME [epoch: 5.76 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0435763082625704		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.0435763082625704 | validation: 3.755158787694249]
	TIME [epoch: 5.74 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8345892054417603		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.8345892054417603 | validation: 3.679131270484337]
	TIME [epoch: 5.74 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.833387169313985		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.833387169313985 | validation: 3.5686860946618455]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8615079217691037		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.8615079217691037 | validation: 3.65663679361687]
	TIME [epoch: 5.74 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.758024332483118		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.758024332483118 | validation: 3.8381820141157204]
	TIME [epoch: 5.75 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7269547743905598		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.7269547743905598 | validation: 3.93868613452437]
	TIME [epoch: 5.78 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8670094683117564		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.8670094683117564 | validation: 3.3741846836490086]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7491715794417244		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.7491715794417244 | validation: 3.6631156837605623]
	TIME [epoch: 5.73 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7776710604439803		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.7776710604439803 | validation: 3.7617281388275026]
	TIME [epoch: 5.74 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.013769754801125		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.013769754801125 | validation: 3.842741388180678]
	TIME [epoch: 5.73 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0334374176692265		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.0334374176692265 | validation: 3.6073188173572706]
	TIME [epoch: 5.73 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.858076066035436		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.858076066035436 | validation: 3.4329556385959554]
	TIME [epoch: 5.79 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5467047236634164		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.5467047236634164 | validation: 4.2822813836422755]
	TIME [epoch: 5.74 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8007991541810324		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.8007991541810324 | validation: 3.687988557464811]
	TIME [epoch: 5.73 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7633148985190696		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.7633148985190696 | validation: 3.503574377602472]
	TIME [epoch: 5.75 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6196779023338195		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.6196779023338195 | validation: 3.5847228836819545]
	TIME [epoch: 5.73 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6518243405607786		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.6518243405607786 | validation: 3.84913988747104]
	TIME [epoch: 5.74 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.533128760289405		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.533128760289405 | validation: 3.305360705422264]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6728546594813287		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.6728546594813287 | validation: 3.4488427339141303]
	TIME [epoch: 5.78 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.698432336221491		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.698432336221491 | validation: 5.617814927947086]
	TIME [epoch: 5.75 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1376013990433513		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.1376013990433513 | validation: 4.069469617561359]
	TIME [epoch: 5.73 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6801334291080647		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.6801334291080647 | validation: 3.3464007603732706]
	TIME [epoch: 5.75 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.985892364467324		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.985892364467324 | validation: 3.7788526258593333]
	TIME [epoch: 5.73 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.123352170899654		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.123352170899654 | validation: 3.981121655648368]
	TIME [epoch: 5.73 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6552098178239314		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.6552098178239314 | validation: 3.326859164109603]
	TIME [epoch: 5.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6221183305963556		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.6221183305963556 | validation: 3.7197135403185126]
	TIME [epoch: 5.73 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5595031314229257		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.5595031314229257 | validation: 3.490178817781766]
	TIME [epoch: 5.74 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6299678957756223		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.6299678957756223 | validation: 3.6976081792727578]
	TIME [epoch: 5.75 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.440841765920438		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.440841765920438 | validation: 3.6566469699408777]
	TIME [epoch: 5.75 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.333616029337531		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.333616029337531 | validation: 3.3241592003612204]
	TIME [epoch: 5.74 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.737428348749236		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.737428348749236 | validation: 3.4427173115838583]
	TIME [epoch: 5.76 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.587059964497337		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.587059964497337 | validation: 3.2932540882285255]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5503091741599158		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.5503091741599158 | validation: 3.1507515318226496]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3914352634086806		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.3914352634086806 | validation: 3.369858500379468]
	TIME [epoch: 5.74 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4410268666765664		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.4410268666765664 | validation: 3.264126643961688]
	TIME [epoch: 5.73 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3998070457063543		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.3998070457063543 | validation: 4.592870714520767]
	TIME [epoch: 5.75 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0104244334826715		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.0104244334826715 | validation: 3.5901708925064257]
	TIME [epoch: 5.75 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.540309254982692		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.540309254982692 | validation: 3.175950693282993]
	TIME [epoch: 5.79 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3698258444817153		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.3698258444817153 | validation: 3.670721818935841]
	TIME [epoch: 5.75 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.480318845491388		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.480318845491388 | validation: 3.827101607922817]
	TIME [epoch: 5.74 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5897414555595866		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.5897414555595866 | validation: 3.4910659202118866]
	TIME [epoch: 5.75 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4020031428385455		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.4020031428385455 | validation: 3.3214815693025357]
	TIME [epoch: 5.72 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3695041722218515		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.3695041722218515 | validation: 3.5732231609376273]
	TIME [epoch: 5.75 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.539143964957698		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.539143964957698 | validation: 3.3283287453030597]
	TIME [epoch: 5.76 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2889913074536494		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.2889913074536494 | validation: 3.340592306449228]
	TIME [epoch: 5.76 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3757123702489458		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.3757123702489458 | validation: 3.2363236352658453]
	TIME [epoch: 5.74 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4136936759527265		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.4136936759527265 | validation: 3.272636355497697]
	TIME [epoch: 5.75 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290105786897093		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.290105786897093 | validation: 3.090859326163565]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.148936664186194		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.148936664186194 | validation: 3.576136664159351]
	TIME [epoch: 5.74 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.756133951035033		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.756133951035033 | validation: 3.151477323810496]
	TIME [epoch: 5.76 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.362016071135945		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.362016071135945 | validation: 3.1651532363373533]
	TIME [epoch: 5.78 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.485720308454079		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.485720308454079 | validation: 3.354149944252057]
	TIME [epoch: 5.75 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3907408611134713		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.3907408611134713 | validation: 3.1419798515412087]
	TIME [epoch: 5.74 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3619184495307435		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.3619184495307435 | validation: 3.252488755809076]
	TIME [epoch: 5.74 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1525556072398393		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.1525556072398393 | validation: 3.6214956187498943]
	TIME [epoch: 5.74 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.334624877214739		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.334624877214739 | validation: 3.087077339886889]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2862971683334923		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.2862971683334923 | validation: 3.3263959166062897]
	TIME [epoch: 5.78 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2681545469095816		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.2681545469095816 | validation: 3.348800585228105]
	TIME [epoch: 5.74 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.435967515708537		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.435967515708537 | validation: 3.443189741773492]
	TIME [epoch: 5.74 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296611166470214		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 2.296611166470214 | validation: 3.3087486199847795]
	TIME [epoch: 5.74 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2384861121237614		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.2384861121237614 | validation: 3.6017868254015215]
	TIME [epoch: 5.74 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273347557958152		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.273347557958152 | validation: 3.5200084791895847]
	TIME [epoch: 5.74 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4963779634946066		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.4963779634946066 | validation: 4.790437263499604]
	TIME [epoch: 5.75 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.432129866793816		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.432129866793816 | validation: 3.1555838300610692]
	TIME [epoch: 5.77 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.461062177629615		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.461062177629615 | validation: 3.6552641298379953]
	TIME [epoch: 5.74 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3063906782213723		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.3063906782213723 | validation: 3.2359152995046436]
	TIME [epoch: 5.74 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.592989780958814		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.592989780958814 | validation: 3.192794589858802]
	TIME [epoch: 5.74 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2612954263273704		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.2612954263273704 | validation: 3.3103785521198694]
	TIME [epoch: 5.73 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2047841038390503		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.2047841038390503 | validation: 3.4843074885931866]
	TIME [epoch: 5.74 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4094939974054297		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.4094939974054297 | validation: 3.1305094374234343]
	TIME [epoch: 5.78 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2709629008459684		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.2709629008459684 | validation: 3.133054724582329]
	TIME [epoch: 5.74 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1473943083533023		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.1473943083533023 | validation: 3.398649219541744]
	TIME [epoch: 5.74 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247024980718547		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.247024980718547 | validation: 3.07433723470434]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2821372140030496		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.2821372140030496 | validation: 4.149523684219934]
	TIME [epoch: 5.74 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3659327922743767		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.3659327922743767 | validation: 3.2349585900052196]
	TIME [epoch: 5.74 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2834479722850576		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.2834479722850576 | validation: 3.6642856241921264]
	TIME [epoch: 5.76 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3218354935106023		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.3218354935106023 | validation: 3.2559674655071538]
	TIME [epoch: 5.75 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1814619629063707		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.1814619629063707 | validation: 3.056986621287117]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3500410798110494		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.3500410798110494 | validation: 3.2553865974405016]
	TIME [epoch: 5.74 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.241924296551838		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.241924296551838 | validation: 3.4696234403379838]
	TIME [epoch: 5.73 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.097874158489396		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.097874158489396 | validation: 2.9874480135202077]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1211077785453343		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.1211077785453343 | validation: 3.290718279645271]
	TIME [epoch: 5.74 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2888093062447803		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.2888093062447803 | validation: 3.1184375358724994]
	TIME [epoch: 5.78 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.112686622442747		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.112686622442747 | validation: 3.103732202006944]
	TIME [epoch: 5.74 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9264453735024587		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.9264453735024587 | validation: 3.067564174902541]
	TIME [epoch: 5.73 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4465420339622623		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.4465420339622623 | validation: 2.9933140931412527]
	TIME [epoch: 5.73 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4392427904029765		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.4392427904029765 | validation: 3.999651505505139]
	TIME [epoch: 5.73 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3446729350159874		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.3446729350159874 | validation: 3.5696115205531957]
	TIME [epoch: 5.73 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1053850360457274		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.1053850360457274 | validation: 3.2071385810350397]
	TIME [epoch: 5.76 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0324861129198277		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.0324861129198277 | validation: 3.215874058740651]
	TIME [epoch: 5.75 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.169694729513412		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.169694729513412 | validation: 3.1288228153170796]
	TIME [epoch: 5.73 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1441461647589284		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.1441461647589284 | validation: 3.4647999980031834]
	TIME [epoch: 5.73 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2821628021523725		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.2821628021523725 | validation: 3.0921387307680153]
	TIME [epoch: 5.73 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9800382170754534		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.9800382170754534 | validation: 2.9982510514171925]
	TIME [epoch: 5.73 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4162394912813916		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.4162394912813916 | validation: 3.0111428069413044]
	TIME [epoch: 5.74 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.132426805726755		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.132426805726755 | validation: 3.2834090930213895]
	TIME [epoch: 5.78 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.096213952018952		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.096213952018952 | validation: 5.269851673629603]
	TIME [epoch: 5.73 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.761228519116625		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.761228519116625 | validation: 3.020832793090753]
	TIME [epoch: 5.73 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.234768756504826		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.234768756504826 | validation: 3.1034397835062784]
	TIME [epoch: 5.73 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0180025588771477		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.0180025588771477 | validation: 3.117735856996682]
	TIME [epoch: 5.73 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0881023678406034		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.0881023678406034 | validation: 3.0540032245833992]
	TIME [epoch: 5.73 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.03808554376757		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 2.03808554376757 | validation: 3.080630955031939]
	TIME [epoch: 5.76 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0034499941798187		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.0034499941798187 | validation: 3.078120379316398]
	TIME [epoch: 5.75 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245711430928301		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.245711430928301 | validation: 4.524063579924599]
	TIME [epoch: 5.73 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5264700095552404		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.5264700095552404 | validation: 3.079882079652149]
	TIME [epoch: 5.73 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9566672539338397		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.9566672539338397 | validation: 3.049403449404086]
	TIME [epoch: 5.73 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.004114450491747		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.004114450491747 | validation: 3.0748927331457243]
	TIME [epoch: 5.73 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8579671453108195		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.8579671453108195 | validation: 2.9259974996324196]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086383014262867		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.086383014262867 | validation: 2.9532836931318656]
	TIME [epoch: 5.78 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1016533758631506		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.1016533758631506 | validation: 3.3438233709922627]
	TIME [epoch: 5.73 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.101674842764669		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.101674842764669 | validation: 3.134885964796788]
	TIME [epoch: 5.73 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3620677664972547		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.3620677664972547 | validation: 3.241792875780508]
	TIME [epoch: 5.73 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1263767231949693		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.1263767231949693 | validation: 2.9513679169920097]
	TIME [epoch: 5.73 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9994510396775325		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.9994510396775325 | validation: 3.1019682543189324]
	TIME [epoch: 5.73 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0602661973751957		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.0602661973751957 | validation: 3.342090760062516]
	TIME [epoch: 5.77 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0670906748484055		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.0670906748484055 | validation: 3.128577074667227]
	TIME [epoch: 5.74 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054209296209992		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.054209296209992 | validation: 3.0300429318531896]
	TIME [epoch: 5.73 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.076556657520947		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.076556657520947 | validation: 3.245120321533292]
	TIME [epoch: 5.73 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8967561428006499		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.8967561428006499 | validation: 2.8945127517682456]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8604827759157119		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.8604827759157119 | validation: 4.094651764044461]
	TIME [epoch: 5.74 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061112721708656		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.061112721708656 | validation: 5.255564184732815]
	TIME [epoch: 5.75 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.682677937779038		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.682677937779038 | validation: 3.359799752967141]
	TIME [epoch: 5.77 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.148092274179111		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.148092274179111 | validation: 2.969967256255074]
	TIME [epoch: 5.74 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.096806871633459		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.096806871633459 | validation: 2.973408934341336]
	TIME [epoch: 5.73 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0980966311886733		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.0980966311886733 | validation: 2.9676858391661667]
	TIME [epoch: 5.73 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0361052774603947		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.0361052774603947 | validation: 3.05117513458178]
	TIME [epoch: 5.73 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.089246782594034		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.089246782594034 | validation: 2.90315492607403]
	TIME [epoch: 5.73 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9109805400680142		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.9109805400680142 | validation: 3.761652346451387]
	TIME [epoch: 5.77 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0445702606375007		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.0445702606375007 | validation: 2.9272888390384857]
	TIME [epoch: 5.74 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8672482343116181		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.8672482343116181 | validation: 4.452091812677907]
	TIME [epoch: 5.73 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.504983999932916		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.504983999932916 | validation: 3.8769588341500696]
	TIME [epoch: 5.73 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3581227396064186		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.3581227396064186 | validation: 3.4957639880250047]
	TIME [epoch: 5.73 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0005947605451615		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.0005947605451615 | validation: 2.942023338045914]
	TIME [epoch: 5.73 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8795081399622502		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.8795081399622502 | validation: 3.35480048257321]
	TIME [epoch: 5.75 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.110794667743791		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.110794667743791 | validation: 2.8922407341782925]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094237952927351		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.094237952927351 | validation: 3.2515664707822887]
	TIME [epoch: 5.74 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0455121690321274		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.0455121690321274 | validation: 2.908664450052145]
	TIME [epoch: 5.74 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.961079178629383		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.961079178629383 | validation: 2.909316906306284]
	TIME [epoch: 5.75 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8410116211000203		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.8410116211000203 | validation: 3.5131744424089937]
	TIME [epoch: 5.74 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1405676135159917		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.1405676135159917 | validation: 2.9886731208840502]
	TIME [epoch: 5.75 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9906413094597526		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.9906413094597526 | validation: 3.004613395154668]
	TIME [epoch: 5.78 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.194197168398369		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.194197168398369 | validation: 3.1675704814464187]
	TIME [epoch: 5.75 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1037177908704257		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.1037177908704257 | validation: 3.343834020109614]
	TIME [epoch: 5.74 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9681325169881674		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.9681325169881674 | validation: 2.9538916075933668]
	TIME [epoch: 5.73 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.79890356994148		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.79890356994148 | validation: 2.9659225257165236]
	TIME [epoch: 5.73 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9169542608319454		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.9169542608319454 | validation: 2.8574795488861198]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7356141187061542		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.7356141187061542 | validation: 3.0932569892177875]
	TIME [epoch: 5.77 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9766237474312351		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.9766237474312351 | validation: 2.9339749616741746]
	TIME [epoch: 5.75 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1270026911808104		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.1270026911808104 | validation: 2.9827253307810793]
	TIME [epoch: 5.73 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8585309752264045		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.8585309752264045 | validation: 3.1146751966749355]
	TIME [epoch: 5.73 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8474088431689664		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.8474088431689664 | validation: 3.203466727005741]
	TIME [epoch: 5.74 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0262594998386585		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.0262594998386585 | validation: 3.3457981108971535]
	TIME [epoch: 5.74 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9859278238145834		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.9859278238145834 | validation: 2.90548511512683]
	TIME [epoch: 5.75 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.026659525649935		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.026659525649935 | validation: 2.954124542664683]
	TIME [epoch: 5.79 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0914747046788156		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 2.0914747046788156 | validation: 3.0561577977665]
	TIME [epoch: 5.75 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.832712084653741		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.832712084653741 | validation: 3.669169179123397]
	TIME [epoch: 5.75 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.105430942991033		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.105430942991033 | validation: 3.1236789304876713]
	TIME [epoch: 5.75 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8959291029459424		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.8959291029459424 | validation: 3.156546893359059]
	TIME [epoch: 5.73 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8035031010995661		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.8035031010995661 | validation: 2.906426279063818]
	TIME [epoch: 5.74 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9112307027472353		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.9112307027472353 | validation: 2.89936362173566]
	TIME [epoch: 5.76 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.01174093920087		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 2.01174093920087 | validation: 2.9165886418539753]
	TIME [epoch: 5.77 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7957568160904185		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.7957568160904185 | validation: 2.8415655276778478]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8826836329952852		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.8826836329952852 | validation: 2.806783086229609]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9031004133050045		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.9031004133050045 | validation: 2.985767039902938]
	TIME [epoch: 5.75 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8936251763381562		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.8936251763381562 | validation: 4.06427167608983]
	TIME [epoch: 5.73 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2211656620553755		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.2211656620553755 | validation: 3.154912473568926]
	TIME [epoch: 5.73 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8402592313062196		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.8402592313062196 | validation: 2.837786865311519]
	TIME [epoch: 5.78 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7978791425237362		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.7978791425237362 | validation: 3.2454334358830805]
	TIME [epoch: 5.73 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8847849682437556		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.8847849682437556 | validation: 2.8453775662581102]
	TIME [epoch: 5.73 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.91684492395295		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.91684492395295 | validation: 3.1171146771689866]
	TIME [epoch: 5.73 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7723254250538794		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.7723254250538794 | validation: 2.806535935375314]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1677926715105897		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.1677926715105897 | validation: 2.900156971154781]
	TIME [epoch: 5.75 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9538782500341128		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.9538782500341128 | validation: 3.024353902022804]
	TIME [epoch: 5.79 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9389639881895193		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.9389639881895193 | validation: 3.0137399491897554]
	TIME [epoch: 5.75 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.943082370523718		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.943082370523718 | validation: 2.9183267568768154]
	TIME [epoch: 5.73 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9581385430418896		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.9581385430418896 | validation: 2.9044099749390466]
	TIME [epoch: 5.73 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1683367865955305		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.1683367865955305 | validation: 2.937463253438029]
	TIME [epoch: 5.73 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.771944161320945		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.771944161320945 | validation: 3.025010061993727]
	TIME [epoch: 5.73 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8590060681462286		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.8590060681462286 | validation: 3.2706637204522133]
	TIME [epoch: 5.74 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8623920544787675		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.8623920544787675 | validation: 2.920510062079004]
	TIME [epoch: 5.76 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7833520453909855		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.7833520453909855 | validation: 2.9844965905454455]
	TIME [epoch: 5.73 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.846309060269771		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.846309060269771 | validation: 3.1189014926899508]
	TIME [epoch: 5.73 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8626935315904085		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.8626935315904085 | validation: 2.9514857505527585]
	TIME [epoch: 5.74 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7572739844171572		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.7572739844171572 | validation: 3.1503975657867147]
	TIME [epoch: 5.74 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7867398087612396		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.7867398087612396 | validation: 2.8256324584882675]
	TIME [epoch: 5.75 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6658837891259557		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.6658837891259557 | validation: 2.889695909324262]
	TIME [epoch: 5.79 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7389833998823259		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.7389833998823259 | validation: 2.7744810087833343]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8907772094450834		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.8907772094450834 | validation: 3.464975636728858]
	TIME [epoch: 5.74 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8987442776802912		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.8987442776802912 | validation: 2.8384026879664455]
	TIME [epoch: 5.75 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8956434736271028		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.8956434736271028 | validation: 2.804563622355882]
	TIME [epoch: 5.75 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9452123149979954		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.9452123149979954 | validation: 3.154736571259968]
	TIME [epoch: 5.75 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8938376044662038		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.8938376044662038 | validation: 2.8875808826959837]
	TIME [epoch: 5.76 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4206374339126744		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 2.4206374339126744 | validation: 3.1613080275980616]
	TIME [epoch: 5.78 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9514103708100028		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.9514103708100028 | validation: 3.5892076907119224]
	TIME [epoch: 5.75 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.879790125932073		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.879790125932073 | validation: 3.072211369582137]
	TIME [epoch: 5.75 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9205462353776734		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.9205462353776734 | validation: 2.9176732451770517]
	TIME [epoch: 5.75 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.811130370783597		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.811130370783597 | validation: 2.8919848621015265]
	TIME [epoch: 5.75 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.95140176547662		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.95140176547662 | validation: 3.405633384945025]
	TIME [epoch: 5.75 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0331976601992876		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.0331976601992876 | validation: 2.8803327981692792]
	TIME [epoch: 5.79 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7601719830294107		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.7601719830294107 | validation: 3.0494253752867713]
	TIME [epoch: 5.76 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8521790320672462		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.8521790320672462 | validation: 3.4213181594016806]
	TIME [epoch: 5.75 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.014686877203596		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.014686877203596 | validation: 2.826132622142761]
	TIME [epoch: 5.75 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6815307392044043		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.6815307392044043 | validation: 2.7955839297161074]
	TIME [epoch: 5.75 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.080320173385615		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.080320173385615 | validation: 3.0834709208987867]
	TIME [epoch: 5.75 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.020550343151017		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.020550343151017 | validation: 2.9367061679118387]
	TIME [epoch: 5.77 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9879928285969375		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.9879928285969375 | validation: 2.7750851900061653]
	TIME [epoch: 5.78 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8422685263357361		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.8422685263357361 | validation: 2.8502907837964506]
	TIME [epoch: 5.75 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1685834408698637		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.1685834408698637 | validation: 2.9615185280178755]
	TIME [epoch: 5.75 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9759545788002701		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.9759545788002701 | validation: 2.9123321881712663]
	TIME [epoch: 5.75 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9621922985003488		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.9621922985003488 | validation: 2.8658190047845062]
	TIME [epoch: 5.75 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.931017523275176		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.931017523275176 | validation: 3.007796556264602]
	TIME [epoch: 5.75 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8927384036457677		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.8927384036457677 | validation: 3.044450127837777]
	TIME [epoch: 5.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8245184408340083		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.8245184408340083 | validation: 3.260910315956814]
	TIME [epoch: 5.75 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0252229191293574		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.0252229191293574 | validation: 2.8664900539268796]
	TIME [epoch: 5.75 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.466643241176532		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 2.466643241176532 | validation: 2.93184360369999]
	TIME [epoch: 5.75 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8499126522459457		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.8499126522459457 | validation: 3.0961330253650114]
	TIME [epoch: 5.75 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8953766492398811		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.8953766492398811 | validation: 2.8243182204762003]
	TIME [epoch: 5.75 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7685396943043072		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.7685396943043072 | validation: 3.266107477454532]
	TIME [epoch: 5.78 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8795727530635762		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.8795727530635762 | validation: 2.771702905653372]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.801988974710511		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.801988974710511 | validation: 2.8833903438171307]
	TIME [epoch: 5.75 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8076453356536435		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.8076453356536435 | validation: 3.301528040468935]
	TIME [epoch: 5.75 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.008913284567407		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.008913284567407 | validation: 2.952448246403626]
	TIME [epoch: 5.74 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7399218273007826		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.7399218273007826 | validation: 2.8408980111754443]
	TIME [epoch: 5.75 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7093744829894604		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.7093744829894604 | validation: 3.0683883289542138]
	TIME [epoch: 5.75 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.903608578088265		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.903608578088265 | validation: 2.7538908116384606]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.027153997762726		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 2.027153997762726 | validation: 2.8865737095828767]
	TIME [epoch: 5.75 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.819142748400252		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.819142748400252 | validation: 2.804452151261024]
	TIME [epoch: 5.75 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7479261602001515		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.7479261602001515 | validation: 2.7979240248964667]
	TIME [epoch: 5.75 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5347117569298536		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 2.5347117569298536 | validation: 3.2312690046436865]
	TIME [epoch: 5.75 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9461304194524616		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.9461304194524616 | validation: 2.885127712293545]
	TIME [epoch: 5.75 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7442824775720602		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.7442824775720602 | validation: 2.8442568046614207]
	TIME [epoch: 5.77 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6723074489135816		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.6723074489135816 | validation: 2.936780181535758]
	TIME [epoch: 5.76 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.699870048321011		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.699870048321011 | validation: 2.8216782224593873]
	TIME [epoch: 5.75 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7471245420590447		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.7471245420590447 | validation: 2.758956846250792]
	TIME [epoch: 5.75 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6261128663559334		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.6261128663559334 | validation: 2.775955509624589]
	TIME [epoch: 5.75 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.898373398085915		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.898373398085915 | validation: 2.7893633430879765]
	TIME [epoch: 5.75 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8639646477952383		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.8639646477952383 | validation: 2.8432112583196942]
	TIME [epoch: 5.75 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8657362499260606		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.8657362499260606 | validation: 2.8081472522460627]
	TIME [epoch: 5.79 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6540961713496933		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.6540961713496933 | validation: 2.8172990907447106]
	TIME [epoch: 5.75 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8354601374145578		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.8354601374145578 | validation: 2.903107952745184]
	TIME [epoch: 5.75 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8184202233728524		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.8184202233728524 | validation: 2.8025978798809468]
	TIME [epoch: 5.75 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8800144615805934		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.8800144615805934 | validation: 3.060372216580635]
	TIME [epoch: 5.74 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32150223405539		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 2.32150223405539 | validation: 3.0198273764835903]
	TIME [epoch: 5.74 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8777433585345384		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.8777433585345384 | validation: 3.2218484203762126]
	TIME [epoch: 5.78 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7215396351225216		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.7215396351225216 | validation: 2.9589847682425465]
	TIME [epoch: 5.75 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7263636140859664		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.7263636140859664 | validation: 2.871290866234822]
	TIME [epoch: 5.75 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8582307644709348		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.8582307644709348 | validation: 2.8461286583593814]
	TIME [epoch: 5.74 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8910427465504653		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.8910427465504653 | validation: 2.7928993588864226]
	TIME [epoch: 5.74 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6898871323411284		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.6898871323411284 | validation: 2.882734655474613]
	TIME [epoch: 5.75 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.716457757936908		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.716457757936908 | validation: 2.7568713700156833]
	TIME [epoch: 5.76 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7308000530388268		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.7308000530388268 | validation: 2.767256997076383]
	TIME [epoch: 5.78 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.759811618027461		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.759811618027461 | validation: 2.9934031641829733]
	TIME [epoch: 5.75 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7826617610151585		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.7826617610151585 | validation: 2.9699917264138516]
	TIME [epoch: 5.75 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7582460390286243		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.7582460390286243 | validation: 3.1892605468661475]
	TIME [epoch: 5.75 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6961396778534923		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.6961396778534923 | validation: 2.7958048663547044]
	TIME [epoch: 5.74 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6009565221683468		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.6009565221683468 | validation: 3.131881387396598]
	TIME [epoch: 5.74 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8929339324686134		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.8929339324686134 | validation: 2.834060962958527]
	TIME [epoch: 5.79 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6833819655805335		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.6833819655805335 | validation: 3.0171061080715926]
	TIME [epoch: 5.75 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7074154021850418		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.7074154021850418 | validation: 2.734417431577689]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6693285724396163		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.6693285724396163 | validation: 3.1547850622317766]
	TIME [epoch: 5.75 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8987220567767364		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.8987220567767364 | validation: 2.8326486509208815]
	TIME [epoch: 5.75 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6993918225101747		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.6993918225101747 | validation: 2.781201162400959]
	TIME [epoch: 5.73 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6257061655866745		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.6257061655866745 | validation: 3.0746933095955673]
	TIME [epoch: 5.76 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9030238923627385		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.9030238923627385 | validation: 2.8523042921213118]
	TIME [epoch: 5.77 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7836217551572386		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.7836217551572386 | validation: 2.838718002774616]
	TIME [epoch: 5.75 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6506251508704783		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.6506251508704783 | validation: 2.9410372324921377]
	TIME [epoch: 5.75 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7480202939787237		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.7480202939787237 | validation: 2.7950514377283087]
	TIME [epoch: 5.74 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.640082251331429		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.640082251331429 | validation: 2.74544365330814]
	TIME [epoch: 5.73 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.620377848772852		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.620377848772852 | validation: 2.8984117403992724]
	TIME [epoch: 5.73 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.699243254476528		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.699243254476528 | validation: 2.971266886441138]
	TIME [epoch: 5.78 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6527271583939709		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.6527271583939709 | validation: 2.7957918971179323]
	TIME [epoch: 5.73 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.721055618018335		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.721055618018335 | validation: 2.7771857485647193]
	TIME [epoch: 5.75 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7301895930038995		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.7301895930038995 | validation: 2.742421513832125]
	TIME [epoch: 5.74 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6455375681083337		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.6455375681083337 | validation: 2.938437235140989]
	TIME [epoch: 5.73 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.717145000461392		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.717145000461392 | validation: 3.516578807331853]
	TIME [epoch: 5.73 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8543806597988797		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.8543806597988797 | validation: 2.835571644686376]
	TIME [epoch: 5.75 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7619585202049723		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.7619585202049723 | validation: 2.88869654928037]
	TIME [epoch: 5.77 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7188096680861467		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.7188096680861467 | validation: 2.7819973607874067]
	TIME [epoch: 5.74 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6419176693394908		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.6419176693394908 | validation: 2.7512827982471526]
	TIME [epoch: 5.73 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.680885907193258		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.680885907193258 | validation: 2.8769629252523705]
	TIME [epoch: 5.73 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.821331197945577		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.821331197945577 | validation: 2.9717815951501767]
	TIME [epoch: 5.74 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.792026567519461		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.792026567519461 | validation: 3.248466905119169]
	TIME [epoch: 5.75 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7968184802162712		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.7968184802162712 | validation: 2.6827975541579008]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6629000996791554		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.6629000996791554 | validation: 2.7419199444520626]
	TIME [epoch: 5.74 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.618550165432085		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.618550165432085 | validation: 2.695791265227791]
	TIME [epoch: 5.73 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6940085858071317		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.6940085858071317 | validation: 2.7663085982251254]
	TIME [epoch: 5.72 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.711950651817671		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.711950651817671 | validation: 2.6973820991764756]
	TIME [epoch: 5.74 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6229516446823908		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.6229516446823908 | validation: 2.736502329371233]
	TIME [epoch: 5.73 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6695343066717219		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.6695343066717219 | validation: 2.747328701156425]
	TIME [epoch: 5.76 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6477518396402249		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.6477518396402249 | validation: 2.705847450480764]
	TIME [epoch: 5.77 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248098963145564		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 2.248098963145564 | validation: 3.244608073888285]
	TIME [epoch: 5.74 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7306221795132983		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.7306221795132983 | validation: 3.2761134555780758]
	TIME [epoch: 5.75 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9580702756077262		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.9580702756077262 | validation: 2.9959874251073404]
	TIME [epoch: 5.74 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.715561588004514		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.715561588004514 | validation: 2.804307944930106]
	TIME [epoch: 5.73 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6622894891721671		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.6622894891721671 | validation: 2.8553918714056756]
	TIME [epoch: 5.74 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.678623274982178		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.678623274982178 | validation: 2.8515699033622766]
	TIME [epoch: 5.78 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8071659830942364		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.8071659830942364 | validation: 2.893876314194332]
	TIME [epoch: 5.73 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6728144390788313		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.6728144390788313 | validation: 2.9371716386712046]
	TIME [epoch: 5.73 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7750168307714065		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.7750168307714065 | validation: 2.97144779621799]
	TIME [epoch: 5.73 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7210696605950893		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.7210696605950893 | validation: 3.404743053580558]
	TIME [epoch: 5.73 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9678573419058873		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.9678573419058873 | validation: 2.86607614917521]
	TIME [epoch: 5.73 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7647618674599066		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.7647618674599066 | validation: 2.7591670539581985]
	TIME [epoch: 5.76 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7148276505623037		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.7148276505623037 | validation: 2.7778061357183286]
	TIME [epoch: 5.75 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6483804070685506		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.6483804070685506 | validation: 2.7729260402218427]
	TIME [epoch: 5.73 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7520058769163924		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.7520058769163924 | validation: 2.792590404863886]
	TIME [epoch: 5.73 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6316001004284177		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.6316001004284177 | validation: 2.8335779981461666]
	TIME [epoch: 5.73 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6855875947939323		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.6855875947939323 | validation: 2.877178230895278]
	TIME [epoch: 5.73 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6788901923384962		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.6788901923384962 | validation: 2.8379724619267495]
	TIME [epoch: 5.74 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6839811453774338		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.6839811453774338 | validation: 2.7750918414501884]
	TIME [epoch: 5.78 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6153087651028024		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.6153087651028024 | validation: 2.8143675677482465]
	TIME [epoch: 5.74 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6229443162327417		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.6229443162327417 | validation: 2.8023351177967464]
	TIME [epoch: 5.73 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6837737753813984		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.6837737753813984 | validation: 2.7977589705579664]
	TIME [epoch: 5.73 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6420855895812816		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.6420855895812816 | validation: 2.720537934291176]
	TIME [epoch: 5.73 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6064260907433225		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.6064260907433225 | validation: 2.6760248365289634]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6942387557897047		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.6942387557897047 | validation: 2.6983965862831316]
	TIME [epoch: 5.76 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.597357624725255		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.597357624725255 | validation: 2.7052831920520193]
	TIME [epoch: 5.76 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6208987541305326		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.6208987541305326 | validation: 2.741844964939137]
	TIME [epoch: 5.73 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6440352418583348		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.6440352418583348 | validation: 2.7486437926443172]
	TIME [epoch: 5.75 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6153330277833873		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.6153330277833873 | validation: 2.685295836282451]
	TIME [epoch: 5.72 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6945160236844452		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.6945160236844452 | validation: 2.8032613670438424]
	TIME [epoch: 5.73 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.642044281189267		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.642044281189267 | validation: 2.812109650188812]
	TIME [epoch: 5.73 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6276263598765182		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.6276263598765182 | validation: 2.8561621494728344]
	TIME [epoch: 5.79 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.631260375912872		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.631260375912872 | validation: 2.7383635225158094]
	TIME [epoch: 5.75 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6556713744953024		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.6556713744953024 | validation: 2.8037078382629987]
	TIME [epoch: 5.75 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6244109351344156		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.6244109351344156 | validation: 2.695985097367061]
	TIME [epoch: 5.74 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5736976796816233		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.5736976796816233 | validation: 2.7123520854984013]
	TIME [epoch: 5.74 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6010848274493243		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.6010848274493243 | validation: 2.8533340298210943]
	TIME [epoch: 5.73 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5994175859020658		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.5994175859020658 | validation: 2.6653649540143363]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6736737491721119		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.6736737491721119 | validation: 2.835921071058802]
	TIME [epoch: 5.76 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7408105004077759		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.7408105004077759 | validation: 2.643139842536239]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_418.pth
	Model improved!!!
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6385961369728927		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.6385961369728927 | validation: 2.7095386543737976]
	TIME [epoch: 5.73 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5626354096088455		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.5626354096088455 | validation: 2.944710826418169]
	TIME [epoch: 5.74 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6667512168801355		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.6667512168801355 | validation: 2.6705504732436447]
	TIME [epoch: 5.74 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.759720045783883		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.759720045783883 | validation: 2.7846217879736264]
	TIME [epoch: 5.76 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7586376646310207		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.7586376646310207 | validation: 2.9393650744594164]
	TIME [epoch: 5.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5651839713578197		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.5651839713578197 | validation: 2.953597416634399]
	TIME [epoch: 5.75 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6282564241144408		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.6282564241144408 | validation: 3.2340106380654072]
	TIME [epoch: 5.74 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7903857522334383		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.7903857522334383 | validation: 2.665564137401257]
	TIME [epoch: 5.74 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8679547692733598		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.8679547692733598 | validation: 2.976903128562467]
	TIME [epoch: 5.73 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.695414952439831		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.695414952439831 | validation: 2.672766645346369]
	TIME [epoch: 5.75 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.586404355196318		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.586404355196318 | validation: 2.664188542258496]
	TIME [epoch: 5.79 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6749384108848266		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.6749384108848266 | validation: 2.6562695490892514]
	TIME [epoch: 5.75 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6328446355487733		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.6328446355487733 | validation: 2.6643278311147345]
	TIME [epoch: 5.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5745389106893122		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.5745389106893122 | validation: 2.856734841909004]
	TIME [epoch: 5.74 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6328053723188982		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.6328053723188982 | validation: 2.6902694933258577]
	TIME [epoch: 5.74 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5593959359483565		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.5593959359483565 | validation: 2.797268550657334]
	TIME [epoch: 5.74 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7119295731259812		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.7119295731259812 | validation: 2.7652578934898577]
	TIME [epoch: 5.76 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5587584297043442		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.5587584297043442 | validation: 2.6124875627181923]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5757633943889273		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.5757633943889273 | validation: 2.756528884361734]
	TIME [epoch: 5.74 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.547947721864245		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.547947721864245 | validation: 2.631772974352823]
	TIME [epoch: 5.74 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.579358423177805		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.579358423177805 | validation: 2.7370784706340614]
	TIME [epoch: 5.74 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.62190362086147		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.62190362086147 | validation: 2.687291961910304]
	TIME [epoch: 5.74 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5891784916874792		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.5891784916874792 | validation: 2.720216647302174]
	TIME [epoch: 5.75 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.833268151839904		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.833268151839904 | validation: 2.800648128954262]
	TIME [epoch: 5.78 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5843115350855115		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.5843115350855115 | validation: 2.7021162814972444]
	TIME [epoch: 5.73 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.537861160695885		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.537861160695885 | validation: 2.6274258131351336]
	TIME [epoch: 5.72 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5472312180603438		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.5472312180603438 | validation: 2.5718744739539625]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8311673387553309		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.8311673387553309 | validation: 2.765931362762501]
	TIME [epoch: 5.74 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5699990511930824		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.5699990511930824 | validation: 2.5856856735936407]
	TIME [epoch: 5.74 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5439236001501113		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.5439236001501113 | validation: 2.5738420201656824]
	TIME [epoch: 5.75 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.664990209280629		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.664990209280629 | validation: 2.6086212459630667]
	TIME [epoch: 5.74 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.517838369954485		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.517838369954485 | validation: 2.963483358066651]
	TIME [epoch: 5.73 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6163169587988395		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.6163169587988395 | validation: 2.5400551198852845]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_451.pth
	Model improved!!!
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5808678810918544		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.5808678810918544 | validation: 2.798900563878346]
	TIME [epoch: 6.01 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6771132955568573		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.6771132955568573 | validation: 2.7512211845024526]
	TIME [epoch: 5.74 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5718615859926452		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.5718615859926452 | validation: 2.5695083530773846]
	TIME [epoch: 5.75 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5593599738644333		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.5593599738644333 | validation: 2.6313244019705047]
	TIME [epoch: 5.79 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6647588742894275		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.6647588742894275 | validation: 2.5860850634272525]
	TIME [epoch: 5.75 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5765300528857142		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.5765300528857142 | validation: 2.6649083479376423]
	TIME [epoch: 5.75 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5472261471658633		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.5472261471658633 | validation: 2.4753480690193106]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4467740439635384		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.4467740439635384 | validation: 2.499402279340884]
	TIME [epoch: 5.75 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5717205533334595		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.5717205533334595 | validation: 2.56068603924052]
	TIME [epoch: 5.75 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.565412765476101		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.565412765476101 | validation: 2.9524878692288836]
	TIME [epoch: 5.78 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.65411684027502		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.65411684027502 | validation: 2.465988129746948]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5997931200991544		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.5997931200991544 | validation: 2.4992785986276944]
	TIME [epoch: 5.75 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.562052421412042		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.562052421412042 | validation: 2.53687782989828]
	TIME [epoch: 5.74 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5271520185677543		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.5271520185677543 | validation: 2.4315939343923136]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4691761231669576		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.4691761231669576 | validation: 2.3975650299644795]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4995053559542455		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.4995053559542455 | validation: 2.3080162086622598]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_467.pth
	Model improved!!!
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.365812094022536		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.365812094022536 | validation: 2.156257678139045]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4028770541355313		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.4028770541355313 | validation: 2.2334853395349743]
	TIME [epoch: 5.75 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.500192408560781		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.500192408560781 | validation: 2.449443954447433]
	TIME [epoch: 5.74 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4805310385729105		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.4805310385729105 | validation: 2.187760961263964]
	TIME [epoch: 5.73 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3557891067321		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.3557891067321 | validation: 2.1648298363634315]
	TIME [epoch: 5.74 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.483585284325586		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.483585284325586 | validation: 2.094310382172579]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_473.pth
	Model improved!!!
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.26352831264514		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.26352831264514 | validation: 2.072124833584941]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_474.pth
	Model improved!!!
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2389374587750872		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.2389374587750872 | validation: 2.1229423869525608]
	TIME [epoch: 5.75 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2085568250860783		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.2085568250860783 | validation: 2.0139976941700057]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_476.pth
	Model improved!!!
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3051624299061493		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.3051624299061493 | validation: 2.074578581721464]
	TIME [epoch: 5.74 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1981563222037273		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.1981563222037273 | validation: 2.0391524345519247]
	TIME [epoch: 5.73 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1656148223036478		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.1656148223036478 | validation: 1.906993123875457]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1271621097777123		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.1271621097777123 | validation: 1.971172365326668]
	TIME [epoch: 5.77 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2093803519506847		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 1.2093803519506847 | validation: 1.8615865234977378]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_481.pth
	Model improved!!!
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0783056466756253		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 1.0783056466756253 | validation: 1.9482536993535098]
	TIME [epoch: 5.73 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0793460913501822		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.0793460913501822 | validation: 1.9231568846140834]
	TIME [epoch: 6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2283998727832235		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.2283998727832235 | validation: 1.5968810446007178]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_484.pth
	Model improved!!!
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.125325356030079		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.125325356030079 | validation: 1.87379261184037]
	TIME [epoch: 5.75 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1042724768738266		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.1042724768738266 | validation: 1.8266244970111694]
	TIME [epoch: 5.79 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0746522259074769		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.0746522259074769 | validation: 1.865365049124997]
	TIME [epoch: 5.75 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0800070415079708		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.0800070415079708 | validation: 1.9007173633198882]
	TIME [epoch: 5.75 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1515756503794305		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.1515756503794305 | validation: 1.8522872350445476]
	TIME [epoch: 5.75 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1305287343117338		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.1305287343117338 | validation: 1.4652689968036332]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_490.pth
	Model improved!!!
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.128739319367108		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.128739319367108 | validation: 1.7444534801965494]
	TIME [epoch: 5.75 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1056203696743765		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.1056203696743765 | validation: 1.7144190725915442]
	TIME [epoch: 5.77 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0921864231843044		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.0921864231843044 | validation: 1.9054558914727966]
	TIME [epoch: 5.76 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0806806020985165		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.0806806020985165 | validation: 1.4324369297297228]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9925635137713154		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.9925635137713154 | validation: 1.8330745463666112]
	TIME [epoch: 5.75 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0312533562170365		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 1.0312533562170365 | validation: 1.790025703616472]
	TIME [epoch: 5.75 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9998895252397162		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.9998895252397162 | validation: 1.5456747352252012]
	TIME [epoch: 5.75 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0037290219849062		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.0037290219849062 | validation: 1.523511965063511]
	TIME [epoch: 5.74 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9677256803871698		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.9677256803871698 | validation: 2.0413274911029458]
	TIME [epoch: 5.79 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0691031166657663		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.0691031166657663 | validation: 1.5529691490740738]
	TIME [epoch: 5.75 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020940391953142		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.020940391953142 | validation: 1.649829151014802]
	TIME [epoch: 5.74 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0410278579416212		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.0410278579416212 | validation: 1.705514320924859]
	TIME [epoch: 5.74 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9121849785835888		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.9121849785835888 | validation: 1.6201793307235555]
	TIME [epoch: 5.75 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.939791141971933		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.939791141971933 | validation: 1.5812442725786204]
	TIME [epoch: 5.74 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9634615474874462		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.9634615474874462 | validation: 1.662532345846492]
	TIME [epoch: 5.77 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0767924530770836		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.0767924530770836 | validation: 1.6282175033160347]
	TIME [epoch: 5.76 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0721976136045355		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.0721976136045355 | validation: 1.3657429227364173]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_507.pth
	Model improved!!!
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.941463083264331		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.941463083264331 | validation: 1.4992229738082372]
	TIME [epoch: 5.75 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8878639027644282		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.8878639027644282 | validation: 1.3243406570009697]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_509.pth
	Model improved!!!
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9196923282363132		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.9196923282363132 | validation: 1.349816525295443]
	TIME [epoch: 5.75 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9469277167510691		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.9469277167510691 | validation: 1.5119015386917998]
	TIME [epoch: 5.75 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9154248623669372		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.9154248623669372 | validation: 1.4630961256106503]
	TIME [epoch: 5.78 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9067436968598647		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.9067436968598647 | validation: 1.4626803912269133]
	TIME [epoch: 5.74 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9241268931903993		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.9241268931903993 | validation: 1.146353441667462]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_514.pth
	Model improved!!!
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.853888156288578		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.853888156288578 | validation: 1.571179216366192]
	TIME [epoch: 5.74 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8903098887964156		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.8903098887964156 | validation: 1.3839369721962391]
	TIME [epoch: 5.74 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8551438162866994		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.8551438162866994 | validation: 1.3838373495316318]
	TIME [epoch: 5.73 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9300253155768738		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.9300253155768738 | validation: 1.5005018721511818]
	TIME [epoch: 5.77 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0010947038684204		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.0010947038684204 | validation: 1.4506069350815063]
	TIME [epoch: 5.74 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9030218405819296		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.9030218405819296 | validation: 1.376152697283896]
	TIME [epoch: 5.73 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9831266402857071		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.9831266402857071 | validation: 1.3696554856753893]
	TIME [epoch: 5.74 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.84941107610162		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.84941107610162 | validation: 1.3486840402059364]
	TIME [epoch: 5.74 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8434764390001253		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.8434764390001253 | validation: 1.3306841571950818]
	TIME [epoch: 5.73 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.841084569424073		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.841084569424073 | validation: 1.1265842067179976]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8313980436990422		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.8313980436990422 | validation: 1.5037975329652582]
	TIME [epoch: 5.77 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8324239827425806		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.8324239827425806 | validation: 1.0995762804666311]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_526.pth
	Model improved!!!
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7750080694776932		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.7750080694776932 | validation: 1.266205780848226]
	TIME [epoch: 5.73 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8060722709243852		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.8060722709243852 | validation: 1.2274172204414961]
	TIME [epoch: 5.73 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7995361897607931		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.7995361897607931 | validation: 1.4506325306272043]
	TIME [epoch: 5.73 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.783217325750623		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.783217325750623 | validation: 1.4591454814417513]
	TIME [epoch: 5.73 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7561562442612743		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.7561562442612743 | validation: 1.2626210985080197]
	TIME [epoch: 5.78 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7422658814185578		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.7422658814185578 | validation: 1.2587906579030421]
	TIME [epoch: 5.73 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8327350692351249		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.8327350692351249 | validation: 0.9356118814232529]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7681254953049359		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.7681254953049359 | validation: 1.3204079239517057]
	TIME [epoch: 5.73 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9694248844320719		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.9694248844320719 | validation: 1.084517273147741]
	TIME [epoch: 5.72 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6725388817831435		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.6725388817831435 | validation: 1.1677617408129404]
	TIME [epoch: 5.72 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207942481684071		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.7207942481684071 | validation: 1.4518909367586172]
	TIME [epoch: 5.77 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000830269644754		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.7000830269644754 | validation: 0.9889523830814776]
	TIME [epoch: 5.75 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6785987175681447		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.6785987175681447 | validation: 1.2997714138927199]
	TIME [epoch: 5.72 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7326556962712515		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.7326556962712515 | validation: 1.2548153803945679]
	TIME [epoch: 5.72 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.729555647760067		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.729555647760067 | validation: 0.9575260744540397]
	TIME [epoch: 5.72 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7291036374866239		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.7291036374866239 | validation: 1.0095376896869792]
	TIME [epoch: 5.73 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6473499767167159		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.6473499767167159 | validation: 1.2337419577930822]
	TIME [epoch: 5.74 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7985799799330483		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.7985799799330483 | validation: 1.1571253044551388]
	TIME [epoch: 5.76 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8396907557164631		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.8396907557164631 | validation: 0.8319290948284548]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_545.pth
	Model improved!!!
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6006076336270184		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.6006076336270184 | validation: 1.13407012873195]
	TIME [epoch: 5.75 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6776567472971355		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.6776567472971355 | validation: 0.729650215125759]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_547.pth
	Model improved!!!
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6796659986874201		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.6796659986874201 | validation: 0.7108383499249036]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.627732250004609		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.627732250004609 | validation: 0.7802309205711252]
	TIME [epoch: 5.74 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825617322417025		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.6825617322417025 | validation: 0.9922322411342452]
	TIME [epoch: 5.78 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5944607888505751		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.5944607888505751 | validation: 0.8515509079897338]
	TIME [epoch: 5.74 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6352810137318111		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.6352810137318111 | validation: 0.9836933083953534]
	TIME [epoch: 5.73 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6562140159219232		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.6562140159219232 | validation: 0.7505332726623862]
	TIME [epoch: 5.73 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6958138552823284		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.6958138552823284 | validation: 0.6486128375950714]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_554.pth
	Model improved!!!
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974862940211534		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.6974862940211534 | validation: 0.7227201777925635]
	TIME [epoch: 5.74 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6688575797573222		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.6688575797573222 | validation: 0.6860943582325731]
	TIME [epoch: 5.76 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6002573178819914		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.6002573178819914 | validation: 1.0088215186413259]
	TIME [epoch: 5.75 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.612667471912826		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.612667471912826 | validation: 1.0978360684795299]
	TIME [epoch: 5.74 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6424745249935682		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.6424745249935682 | validation: 0.8503397922571562]
	TIME [epoch: 5.74 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6754963752974291		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.6754963752974291 | validation: 0.6758622873889302]
	TIME [epoch: 5.73 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6090489745398988		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.6090489745398988 | validation: 0.8703538124524066]
	TIME [epoch: 5.74 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6094826582290892		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.6094826582290892 | validation: 0.5171467179455325]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6306068082704339		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.6306068082704339 | validation: 0.7169988315317124]
	TIME [epoch: 5.78 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5876431573073833		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.5876431573073833 | validation: 0.8030754921632353]
	TIME [epoch: 5.74 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5877905741676577		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.5877905741676577 | validation: 0.6614664685673443]
	TIME [epoch: 5.73 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6540295994133078		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.6540295994133078 | validation: 0.6534530698233411]
	TIME [epoch: 5.73 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6157953675478338		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.6157953675478338 | validation: 0.5453363095098327]
	TIME [epoch: 5.73 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5949423827744789		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.5949423827744789 | validation: 0.5738490248339565]
	TIME [epoch: 5.73 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5875793974138974		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.5875793974138974 | validation: 0.9105720931067456]
	TIME [epoch: 5.77 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6525969031578369		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.6525969031578369 | validation: 1.3503834422192953]
	TIME [epoch: 5.74 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7475857849365067		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.7475857849365067 | validation: 0.6068003472642167]
	TIME [epoch: 5.73 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5616034730338395		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.5616034730338395 | validation: 0.62896180983474]
	TIME [epoch: 5.74 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6279363822155544		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.6279363822155544 | validation: 0.5620215452266742]
	TIME [epoch: 5.74 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6929399056201672		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.6929399056201672 | validation: 0.4909948014721243]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_574.pth
	Model improved!!!
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5960630146116935		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.5960630146116935 | validation: 0.9084671100466565]
	TIME [epoch: 5.75 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5688069285908685		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.5688069285908685 | validation: 0.8028593617800069]
	TIME [epoch: 5.77 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5673655079652496		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.5673655079652496 | validation: 0.8454731469828507]
	TIME [epoch: 5.73 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5988200000717511		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.5988200000717511 | validation: 0.5308920633345714]
	TIME [epoch: 5.73 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6693875932353323		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.6693875932353323 | validation: 0.8520466527556266]
	TIME [epoch: 5.73 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831268206205177		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.6831268206205177 | validation: 0.6951871113167633]
	TIME [epoch: 5.72 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5680207192516908		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.5680207192516908 | validation: 0.9406761018816926]
	TIME [epoch: 5.73 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6279197116986738		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.6279197116986738 | validation: 0.9198869590244706]
	TIME [epoch: 5.76 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871935539731227		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.6871935539731227 | validation: 0.6413119957690481]
	TIME [epoch: 5.73 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5714920930790286		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.5714920930790286 | validation: 0.6956068876826745]
	TIME [epoch: 5.73 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5811759166836361		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.5811759166836361 | validation: 0.6693422290731218]
	TIME [epoch: 5.73 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5912203810615073		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.5912203810615073 | validation: 0.4858745067172832]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_586.pth
	Model improved!!!
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6111012713556102		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.6111012713556102 | validation: 0.5861361884634374]
	TIME [epoch: 5.75 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5902144522377473		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.5902144522377473 | validation: 0.5566527325786109]
	TIME [epoch: 5.77 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5261315565864364		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.5261315565864364 | validation: 0.4922534016517895]
	TIME [epoch: 5.76 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6039270530656227		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.6039270530656227 | validation: 0.5987837973312579]
	TIME [epoch: 5.75 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5693720141228152		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.5693720141228152 | validation: 0.6499386707233572]
	TIME [epoch: 5.74 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6367768183491073		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.6367768183491073 | validation: 0.7845069236257824]
	TIME [epoch: 5.74 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6497126264256108		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.6497126264256108 | validation: 0.6918666856989028]
	TIME [epoch: 5.74 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5965791713164721		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.5965791713164721 | validation: 0.5484741641225496]
	TIME [epoch: 5.74 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5992289183760109		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.5992289183760109 | validation: 0.5490420567736903]
	TIME [epoch: 5.79 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6074966937540176		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.6074966937540176 | validation: 0.6208361552507023]
	TIME [epoch: 5.75 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810448817871581		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.5810448817871581 | validation: 0.5930186707618895]
	TIME [epoch: 5.72 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5321043927823194		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.5321043927823194 | validation: 0.5964940308097896]
	TIME [epoch: 5.73 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5586692454546541		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.5586692454546541 | validation: 0.6116346586800662]
	TIME [epoch: 5.72 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6031989335426045		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.6031989335426045 | validation: 0.5694124058304287]
	TIME [epoch: 5.74 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6382175412858042		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.6382175412858042 | validation: 0.6534469323861418]
	TIME [epoch: 5.77 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5788433515407331		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.5788433515407331 | validation: 0.5912752598744447]
	TIME [epoch: 5.76 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5364805262143371		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.5364805262143371 | validation: 0.4922604838294406]
	TIME [epoch: 5.74 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5703678800647334		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.5703678800647334 | validation: 0.7144199764496575]
	TIME [epoch: 5.74 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5773906914787964		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.5773906914787964 | validation: 0.5840527044574809]
	TIME [epoch: 5.74 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5779731322447277		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.5779731322447277 | validation: 0.654138559328599]
	TIME [epoch: 5.74 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5873457908723766		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.5873457908723766 | validation: 0.8901598977996562]
	TIME [epoch: 5.74 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5608339811776006		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.5608339811776006 | validation: 0.8288885943521169]
	TIME [epoch: 5.79 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6061570103034651		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.6061570103034651 | validation: 0.6279208102139681]
	TIME [epoch: 5.75 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5615860958461701		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.5615860958461701 | validation: 0.5611528559526743]
	TIME [epoch: 5.74 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6160725450532885		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.6160725450532885 | validation: 0.5412097863259205]
	TIME [epoch: 5.74 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5526568117332639		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.5526568117332639 | validation: 0.5675405112598726]
	TIME [epoch: 5.74 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5513228071242052		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.5513228071242052 | validation: 0.6544565211326446]
	TIME [epoch: 5.74 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189213524480922		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.5189213524480922 | validation: 0.6364842813972134]
	TIME [epoch: 5.77 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572446085262019		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.572446085262019 | validation: 0.528826706693447]
	TIME [epoch: 5.76 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357544644628975		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5357544644628975 | validation: 0.449355046590496]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5476949701591082		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.5476949701591082 | validation: 0.6049096480251602]
	TIME [epoch: 5.73 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377666468496057		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.5377666468496057 | validation: 0.4321320359592847]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5335330049214257		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.5335330049214257 | validation: 0.9069024555180434]
	TIME [epoch: 5.74 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5921490882907035		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.5921490882907035 | validation: 0.7031023610776967]
	TIME [epoch: 5.74 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5350897761150857		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.5350897761150857 | validation: 0.6413029527324275]
	TIME [epoch: 5.78 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6547691811894714		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.6547691811894714 | validation: 0.5120133576144323]
	TIME [epoch: 5.72 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5465264539425267		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.5465264539425267 | validation: 0.9729556953534066]
	TIME [epoch: 5.74 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5879228023195227		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.5879228023195227 | validation: 0.6137420189699389]
	TIME [epoch: 5.73 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.541158203821179		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.541158203821179 | validation: 0.8279625933533641]
	TIME [epoch: 5.74 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5818009005272965		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.5818009005272965 | validation: 0.5681083956330195]
	TIME [epoch: 5.72 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5660449675597768		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5660449675597768 | validation: 0.5787606677305354]
	TIME [epoch: 5.79 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5241507827277619		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.5241507827277619 | validation: 0.6059954909855714]
	TIME [epoch: 5.75 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5688932746522114		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5688932746522114 | validation: 0.5277767541746252]
	TIME [epoch: 5.74 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5196935653233853		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.5196935653233853 | validation: 0.5028373785351233]
	TIME [epoch: 5.72 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5426391922205277		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.5426391922205277 | validation: 0.46917346144862415]
	TIME [epoch: 5.74 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8836380791712419		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.8836380791712419 | validation: 0.710222564485648]
	TIME [epoch: 5.74 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585511280324316		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.5585511280324316 | validation: 0.6380249287566883]
	TIME [epoch: 5.76 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5792420376191271		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.5792420376191271 | validation: 0.6099653937697628]
	TIME [epoch: 5.78 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5351937375884733		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.5351937375884733 | validation: 0.8036857335512412]
	TIME [epoch: 5.75 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5937743355536231		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.5937743355536231 | validation: 0.6053707815355204]
	TIME [epoch: 5.74 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.536429063615402		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.536429063615402 | validation: 0.6549739177464237]
	TIME [epoch: 5.74 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5517101809338494		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.5517101809338494 | validation: 0.5053501514494629]
	TIME [epoch: 5.74 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5590839654139663		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.5590839654139663 | validation: 0.6017521209265995]
	TIME [epoch: 5.73 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5594323243905768		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.5594323243905768 | validation: 0.5167742730995858]
	TIME [epoch: 5.77 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4966575571363673		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.4966575571363673 | validation: 0.5616259538581959]
	TIME [epoch: 5.73 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5048990641778449		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.5048990641778449 | validation: 0.6387789132814754]
	TIME [epoch: 5.73 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5874199140370642		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.5874199140370642 | validation: 0.48716017498893893]
	TIME [epoch: 5.74 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5549147519309572		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.5549147519309572 | validation: 0.4789406946003866]
	TIME [epoch: 5.73 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5225180009073737		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.5225180009073737 | validation: 0.47165817043473485]
	TIME [epoch: 5.72 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5536074343114458		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.5536074343114458 | validation: 0.6042039997858534]
	TIME [epoch: 5.74 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377111942867987		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.5377111942867987 | validation: 0.42522529775072065]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_647.pth
	Model improved!!!
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5756236369356347		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.5756236369356347 | validation: 0.511583932811469]
	TIME [epoch: 5.73 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5509769335931212		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.5509769335931212 | validation: 0.6168749982602795]
	TIME [epoch: 5.74 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5166665575701396		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.5166665575701396 | validation: 0.5107269692023431]
	TIME [epoch: 5.73 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5054445660022823		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.5054445660022823 | validation: 0.5068530220458397]
	TIME [epoch: 5.73 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5765044002762925		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5765044002762925 | validation: 0.5227801932524527]
	TIME [epoch: 5.73 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47919755526534186		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.47919755526534186 | validation: 0.6051211860718954]
	TIME [epoch: 5.79 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5070577933687048		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.5070577933687048 | validation: 0.6340713566242492]
	TIME [epoch: 5.75 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5012936065867215		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.5012936065867215 | validation: 0.5163914562161128]
	TIME [epoch: 5.74 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396667678682162		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.5396667678682162 | validation: 0.4859882586759853]
	TIME [epoch: 5.74 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.575224148054222		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.575224148054222 | validation: 0.5148195950873676]
	TIME [epoch: 5.74 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5190033262219774		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.5190033262219774 | validation: 0.49853450748316996]
	TIME [epoch: 5.74 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5139286210286742		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.5139286210286742 | validation: 0.4958888078626123]
	TIME [epoch: 5.76 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5128341583441661		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.5128341583441661 | validation: 0.5810782825189164]
	TIME [epoch: 5.78 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516576357531123		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.516576357531123 | validation: 0.5516622584646395]
	TIME [epoch: 5.75 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5122725270514564		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.5122725270514564 | validation: 0.5142805546941149]
	TIME [epoch: 5.73 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585175905847719		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.5585175905847719 | validation: 0.7603652383599218]
	TIME [epoch: 5.74 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5891921248979863		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.5891921248979863 | validation: 0.45450662128586666]
	TIME [epoch: 5.74 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5273020635954238		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.5273020635954238 | validation: 0.47637200743796515]
	TIME [epoch: 5.74 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5005898848878991		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.5005898848878991 | validation: 0.47827219818091055]
	TIME [epoch: 5.79 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5156128489045073		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.5156128489045073 | validation: 0.6070582274377643]
	TIME [epoch: 5.75 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5431081747410103		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.5431081747410103 | validation: 1.3487493723898252]
	TIME [epoch: 5.74 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6538787759311575		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.6538787759311575 | validation: 0.5096540738192169]
	TIME [epoch: 5.74 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.593320322216232		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.593320322216232 | validation: 0.46263265907214]
	TIME [epoch: 5.74 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5438248743058539		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.5438248743058539 | validation: 0.6569178996345041]
	TIME [epoch: 5.74 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5197295696926891		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.5197295696926891 | validation: 0.6945700156852564]
	TIME [epoch: 5.77 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.518421698109557		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.518421698109557 | validation: 0.536324487450391]
	TIME [epoch: 5.76 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141174024860885		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.5141174024860885 | validation: 0.5072088634606945]
	TIME [epoch: 5.75 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5515036342733831		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.5515036342733831 | validation: 0.5709845997812926]
	TIME [epoch: 5.74 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5252483464830957		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.5252483464830957 | validation: 0.5416359950976655]
	TIME [epoch: 5.74 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48781728438507316		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.48781728438507316 | validation: 0.486544846613194]
	TIME [epoch: 5.74 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522071234530678		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.522071234530678 | validation: 0.5591098819758886]
	TIME [epoch: 5.74 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4943813986534433		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.4943813986534433 | validation: 0.4949541576288279]
	TIME [epoch: 5.79 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5232969534597472		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.5232969534597472 | validation: 0.5459510282808853]
	TIME [epoch: 5.75 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5420962533230069		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.5420962533230069 | validation: 0.5130380011618658]
	TIME [epoch: 5.74 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49579581706301534		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.49579581706301534 | validation: 0.5212979677657624]
	TIME [epoch: 5.74 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5400437608113373		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.5400437608113373 | validation: 0.5148168532811361]
	TIME [epoch: 5.74 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5486328015941806		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.5486328015941806 | validation: 0.44172347189469097]
	TIME [epoch: 5.73 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.515315987040489		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.515315987040489 | validation: 0.4549483685802865]
	TIME [epoch: 5.77 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5791257977472074		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.5791257977472074 | validation: 0.5091483336162375]
	TIME [epoch: 5.75 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49340977760477855		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.49340977760477855 | validation: 0.46964300925602104]
	TIME [epoch: 5.75 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47680136129561274		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.47680136129561274 | validation: 0.5314405670451136]
	TIME [epoch: 5.74 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48657969868315676		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.48657969868315676 | validation: 0.5688981612435621]
	TIME [epoch: 5.75 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5225789452395972		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5225789452395972 | validation: 0.46779752699991994]
	TIME [epoch: 5.73 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5211631090740722		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.5211631090740722 | validation: 0.4651271375905801]
	TIME [epoch: 5.75 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.535255406039689		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.535255406039689 | validation: 0.4126089220030428]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_692.pth
	Model improved!!!
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48691307465838624		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.48691307465838624 | validation: 0.6057856281933663]
	TIME [epoch: 5.74 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5210990649537602		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.5210990649537602 | validation: 0.5765429687429636]
	TIME [epoch: 5.74 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.562872984168945		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.562872984168945 | validation: 0.4912368459898175]
	TIME [epoch: 5.74 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49885122524823344		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.49885122524823344 | validation: 0.45071978026834153]
	TIME [epoch: 5.74 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49470791344952614		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.49470791344952614 | validation: 0.6059210887993186]
	TIME [epoch: 5.74 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5475073696313136		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.5475073696313136 | validation: 0.5193191872066312]
	TIME [epoch: 5.77 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5464638453944359		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.5464638453944359 | validation: 0.6306466576630033]
	TIME [epoch: 5.76 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5315923250182462		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.5315923250182462 | validation: 0.4792689538555514]
	TIME [epoch: 5.73 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49837929586256435		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.49837929586256435 | validation: 0.4187459244249792]
	TIME [epoch: 5.73 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4897538682794972		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.4897538682794972 | validation: 0.6341344918482718]
	TIME [epoch: 5.74 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5620598183755864		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.5620598183755864 | validation: 0.45824618336408607]
	TIME [epoch: 5.74 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.511368390913757		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.511368390913757 | validation: 0.4109214080085236]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_704.pth
	Model improved!!!
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4740644413469534		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.4740644413469534 | validation: 0.4675106570749115]
	TIME [epoch: 5.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5318997276624896		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.5318997276624896 | validation: 0.494354111232107]
	TIME [epoch: 5.75 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49849251857974175		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.49849251857974175 | validation: 0.47566363620222535]
	TIME [epoch: 5.75 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5008192519179626		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.5008192519179626 | validation: 0.4820815307283125]
	TIME [epoch: 5.75 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49253016595324506		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.49253016595324506 | validation: 0.5999632347918638]
	TIME [epoch: 5.75 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5050983209848148		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.5050983209848148 | validation: 0.46426883701524374]
	TIME [epoch: 5.75 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4911747794539556		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.4911747794539556 | validation: 0.6547391172684663]
	TIME [epoch: 5.79 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5148620680448254		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.5148620680448254 | validation: 0.47683620777524305]
	TIME [epoch: 5.75 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5232069939823826		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.5232069939823826 | validation: 0.539148584615928]
	TIME [epoch: 5.75 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5381102166384314		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.5381102166384314 | validation: 0.5411627682347857]
	TIME [epoch: 5.75 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5573577984850383		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.5573577984850383 | validation: 0.42725234294137876]
	TIME [epoch: 5.75 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.479802326519862		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.479802326519862 | validation: 0.5620525945175165]
	TIME [epoch: 5.75 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.51877363138865		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.51877363138865 | validation: 0.45324721415609104]
	TIME [epoch: 5.76 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49243638216858254		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.49243638216858254 | validation: 0.7515264930512653]
	TIME [epoch: 5.78 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374818336697718		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.6374818336697718 | validation: 0.47870622645464067]
	TIME [epoch: 5.75 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4933198822720464		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.4933198822720464 | validation: 0.5771082383899061]
	TIME [epoch: 5.75 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5463870561042482		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.5463870561042482 | validation: 0.6159670181458217]
	TIME [epoch: 5.75 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5562138244223518		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.5562138244223518 | validation: 0.5668364454709546]
	TIME [epoch: 5.75 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5000333859743702		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.5000333859743702 | validation: 0.6143972850187426]
	TIME [epoch: 5.75 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5196344283731249		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.5196344283731249 | validation: 0.5081526847185052]
	TIME [epoch: 5.79 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4843152250086041		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.4843152250086041 | validation: 0.4428664404907765]
	TIME [epoch: 5.76 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47506099306657285		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.47506099306657285 | validation: 0.596125756826292]
	TIME [epoch: 5.75 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5274757580469648		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.5274757580469648 | validation: 0.4700532415692712]
	TIME [epoch: 5.75 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4772947653575462		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.4772947653575462 | validation: 0.4400632554648853]
	TIME [epoch: 5.75 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4763874705780313		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.4763874705780313 | validation: 0.46028954681175244]
	TIME [epoch: 5.75 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.507949384920512		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.507949384920512 | validation: 0.4370000344696404]
	TIME [epoch: 5.76 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49805573882878484		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.49805573882878484 | validation: 0.4263074974798136]
	TIME [epoch: 5.79 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44990272746612986		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.44990272746612986 | validation: 0.6412286115153838]
	TIME [epoch: 5.75 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5263045885962792		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.5263045885962792 | validation: 0.5426029240981504]
	TIME [epoch: 5.75 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4658817365540416		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.4658817365540416 | validation: 0.5106074290469259]
	TIME [epoch: 5.75 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199959081273234		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.5199959081273234 | validation: 0.47683132838927217]
	TIME [epoch: 5.75 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46795593436590854		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.46795593436590854 | validation: 0.4626978199624108]
	TIME [epoch: 5.75 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5127577938308707		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.5127577938308707 | validation: 0.5327262366122684]
	TIME [epoch: 5.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48485980239941673		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.48485980239941673 | validation: 0.5011384615756742]
	TIME [epoch: 5.76 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4781077488808692		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.4781077488808692 | validation: 0.48061248863416295]
	TIME [epoch: 5.75 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5057502169489261		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.5057502169489261 | validation: 0.4397866219133732]
	TIME [epoch: 5.75 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4892070548383013		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.4892070548383013 | validation: 0.4411891115109184]
	TIME [epoch: 5.75 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5591115779820149		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.5591115779820149 | validation: 0.5211310289033314]
	TIME [epoch: 5.75 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4739936100682427		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.4739936100682427 | validation: 0.442047578869462]
	TIME [epoch: 5.76 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4604071759467998		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.4604071759467998 | validation: 0.5239391298222165]
	TIME [epoch: 5.79 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46626660281082616		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.46626660281082616 | validation: 0.47738708087945114]
	TIME [epoch: 5.75 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4615072064711389		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.4615072064711389 | validation: 0.510407698671397]
	TIME [epoch: 5.75 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.471211160779879		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.471211160779879 | validation: 0.494911129547947]
	TIME [epoch: 5.75 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46856793283548653		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.46856793283548653 | validation: 0.5955923574336827]
	TIME [epoch: 5.75 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5142918568061845		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.5142918568061845 | validation: 0.539306958542189]
	TIME [epoch: 5.75 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5441436966813211		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.5441436966813211 | validation: 0.4406967166881142]
	TIME [epoch: 5.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45657793168826055		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.45657793168826055 | validation: 0.5838680505495608]
	TIME [epoch: 5.75 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4711693318396912		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.4711693318396912 | validation: 0.44201016634362755]
	TIME [epoch: 5.75 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4816128999299361		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.4816128999299361 | validation: 0.5191327312165097]
	TIME [epoch: 5.75 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49967441269857454		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.49967441269857454 | validation: 0.554985027593866]
	TIME [epoch: 5.75 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5168106690197198		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.5168106690197198 | validation: 0.5792036335315539]
	TIME [epoch: 5.75 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45778105059660223		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.45778105059660223 | validation: 0.5347509233511648]
	TIME [epoch: 5.78 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4467687642597903		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.4467687642597903 | validation: 0.6124958168895923]
	TIME [epoch: 5.77 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4628939330298336		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.4628939330298336 | validation: 0.4944686069243814]
	TIME [epoch: 5.75 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45945053008440184		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.45945053008440184 | validation: 0.4835332614793248]
	TIME [epoch: 5.75 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5007198966564331		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.5007198966564331 | validation: 0.5077312306778956]
	TIME [epoch: 5.75 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46616438994467574		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.46616438994467574 | validation: 0.6096229120620328]
	TIME [epoch: 5.75 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5532795533693452		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.5532795533693452 | validation: 0.5142482163114996]
	TIME [epoch: 5.75 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46185878787716517		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.46185878787716517 | validation: 0.4719483230059288]
	TIME [epoch: 5.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4556997671539279		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.4556997671539279 | validation: 0.424220687365788]
	TIME [epoch: 5.76 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47087244685492674		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.47087244685492674 | validation: 0.4802484140139724]
	TIME [epoch: 5.75 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5126587257321625		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.5126587257321625 | validation: 0.49175674751619197]
	TIME [epoch: 5.75 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4981504776329527		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.4981504776329527 | validation: 0.509066537328014]
	TIME [epoch: 5.75 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.480748377247714		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.480748377247714 | validation: 0.5127035438806999]
	TIME [epoch: 5.75 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4743014656596484		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.4743014656596484 | validation: 0.5366163926877363]
	TIME [epoch: 5.78 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5001163833476749		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.5001163833476749 | validation: 0.46867709697484106]
	TIME [epoch: 5.77 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.451490846429933		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.451490846429933 | validation: 0.43735504720037865]
	TIME [epoch: 5.75 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46546534567910997		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.46546534567910997 | validation: 0.4233187667464489]
	TIME [epoch: 5.75 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4971302783372069		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.4971302783372069 | validation: 0.4130401534134064]
	TIME [epoch: 5.75 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5042306228616098		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.5042306228616098 | validation: 0.5243824521017281]
	TIME [epoch: 5.75 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.492057163646967		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.492057163646967 | validation: 0.4473572870525191]
	TIME [epoch: 5.75 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48001372966682565		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.48001372966682565 | validation: 0.5015763859303575]
	TIME [epoch: 5.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49213281065267894		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.49213281065267894 | validation: 0.5366370773020445]
	TIME [epoch: 5.75 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5088576337000673		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.5088576337000673 | validation: 0.5109846371663415]
	TIME [epoch: 5.75 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4879969415356427		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.4879969415356427 | validation: 0.615129681197287]
	TIME [epoch: 5.75 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4799932766192476		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.4799932766192476 | validation: 0.6158244169934272]
	TIME [epoch: 5.75 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4980005289535922		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.4980005289535922 | validation: 0.460906641527613]
	TIME [epoch: 5.75 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48000269121459926		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.48000269121459926 | validation: 0.5593143671876661]
	TIME [epoch: 5.78 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45734690480804074		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.45734690480804074 | validation: 0.478450932166032]
	TIME [epoch: 5.77 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47604534583450364		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.47604534583450364 | validation: 0.40387633193542144]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_784.pth
	Model improved!!!
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4433180602488828		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.4433180602488828 | validation: 0.46519090933266427]
	TIME [epoch: 5.75 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4535859338307068		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.4535859338307068 | validation: 0.42844236325793655]
	TIME [epoch: 5.73 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4568925365410259		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.4568925365410259 | validation: 0.657504631250413]
	TIME [epoch: 5.74 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47181964146449334		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.47181964146449334 | validation: 0.45628258192208393]
	TIME [epoch: 5.76 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4379626980597183		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.4379626980597183 | validation: 0.47935368875896467]
	TIME [epoch: 5.78 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4657638736490407		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.4657638736490407 | validation: 0.40388585636111757]
	TIME [epoch: 5.74 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4562322937951879		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.4562322937951879 | validation: 0.38508186778587666]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_791.pth
	Model improved!!!
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4474066147889768		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.4474066147889768 | validation: 0.4626133507459136]
	TIME [epoch: 5.74 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44563034647432176		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.44563034647432176 | validation: 0.5135326731290495]
	TIME [epoch: 5.72 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4546690086164667		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.4546690086164667 | validation: 0.42278766353252223]
	TIME [epoch: 5.73 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5312912597432643		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.5312912597432643 | validation: 0.4328606897780851]
	TIME [epoch: 5.77 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4717690756417413		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.4717690756417413 | validation: 0.4184927284276816]
	TIME [epoch: 5.73 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4732361619663869		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.4732361619663869 | validation: 0.38804333572521044]
	TIME [epoch: 5.72 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4543039003387271		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.4543039003387271 | validation: 0.4788477143809269]
	TIME [epoch: 5.72 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46154343619485844		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.46154343619485844 | validation: 0.4136731071507839]
	TIME [epoch: 5.73 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5008080344755539		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.5008080344755539 | validation: 0.48652968612630804]
	TIME [epoch: 5.74 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4508080215209241		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.4508080215209241 | validation: 0.3935065539236952]
	TIME [epoch: 5.75 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45790170084340676		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.45790170084340676 | validation: 0.4437653613721799]
	TIME [epoch: 5.76 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4341025807342796		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.4341025807342796 | validation: 0.5397895664741104]
	TIME [epoch: 5.72 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4540907947249091		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.4540907947249091 | validation: 0.4980517193410809]
	TIME [epoch: 5.72 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46358266362544415		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.46358266362544415 | validation: 0.4410123998734225]
	TIME [epoch: 5.72 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4824599272595987		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.4824599272595987 | validation: 0.418652429969636]
	TIME [epoch: 5.72 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44599727294293057		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.44599727294293057 | validation: 0.5635467470782592]
	TIME [epoch: 5.72 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44849475622164375		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.44849475622164375 | validation: 0.5060442299616725]
	TIME [epoch: 5.77 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47469890850272967		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.47469890850272967 | validation: 0.5414010178150475]
	TIME [epoch: 5.73 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4549156947589947		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.4549156947589947 | validation: 0.5121903612665891]
	TIME [epoch: 5.73 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4861593153655681		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.4861593153655681 | validation: 0.5842509272787564]
	TIME [epoch: 5.74 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4517739254623797		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.4517739254623797 | validation: 0.49030231028302323]
	TIME [epoch: 5.75 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45446294831870204		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.45446294831870204 | validation: 0.5338665938246044]
	TIME [epoch: 5.74 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45295090460886756		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.45295090460886756 | validation: 0.47424968943252493]
	TIME [epoch: 5.76 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44762175760966655		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.44762175760966655 | validation: 0.4153228088671335]
	TIME [epoch: 5.78 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4536964232152074		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.4536964232152074 | validation: 0.466131766458138]
	TIME [epoch: 5.75 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44696213735739765		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.44696213735739765 | validation: 0.5275065127392636]
	TIME [epoch: 5.75 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4862077259644938		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.4862077259644938 | validation: 0.4236635025004424]
	TIME [epoch: 5.74 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46464482245118394		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.46464482245118394 | validation: 0.41112743008452013]
	TIME [epoch: 5.74 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43635882754997235		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.43635882754997235 | validation: 0.3904659603372583]
	TIME [epoch: 5.73 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4427016604172776		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.4427016604172776 | validation: 0.44795913380888086]
	TIME [epoch: 5.78 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45230027814341806		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.45230027814341806 | validation: 0.46946824808261434]
	TIME [epoch: 5.75 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46616894893977656		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.46616894893977656 | validation: 0.4468485187301316]
	TIME [epoch: 5.74 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45452484696529827		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.45452484696529827 | validation: 0.5729098300184119]
	TIME [epoch: 5.73 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5196854230527549		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.5196854230527549 | validation: 0.6777510378941528]
	TIME [epoch: 5.74 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4654214758055848		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.4654214758055848 | validation: 0.4296679519549693]
	TIME [epoch: 5.74 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4563738477318752		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.4563738477318752 | validation: 0.4656242921823916]
	TIME [epoch: 5.76 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47435635341612503		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.47435635341612503 | validation: 0.4874385311717586]
	TIME [epoch: 5.76 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45381105006414324		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.45381105006414324 | validation: 0.4534436666269688]
	TIME [epoch: 5.75 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45637985283576155		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.45637985283576155 | validation: 0.40803576734235364]
	TIME [epoch: 5.73 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42948322212322154		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.42948322212322154 | validation: 0.47893730208191915]
	TIME [epoch: 5.74 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.447290011508569		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.447290011508569 | validation: 0.4401163983147373]
	TIME [epoch: 5.75 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.468371600192784		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.468371600192784 | validation: 0.5204755270301421]
	TIME [epoch: 5.75 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4615009518479094		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.4615009518479094 | validation: 0.572327929247911]
	TIME [epoch: 5.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4305563081764776		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.4305563081764776 | validation: 0.5157288380137662]
	TIME [epoch: 5.75 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4407028794368718		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.4407028794368718 | validation: 0.43209518588554174]
	TIME [epoch: 5.75 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44838779175975446		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.44838779175975446 | validation: 0.4710200297071478]
	TIME [epoch: 5.75 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4378312516176137		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.4378312516176137 | validation: 0.41191401224187296]
	TIME [epoch: 5.75 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44163924732230575		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.44163924732230575 | validation: 0.38146143928073656]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_839.pth
	Model improved!!!
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4588660104639314		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.4588660104639314 | validation: 0.43956349057134025]
	TIME [epoch: 5.78 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4657006551080818		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.4657006551080818 | validation: 0.5642043947404937]
	TIME [epoch: 5.76 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4918011459166579		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.4918011459166579 | validation: 0.5146974823605112]
	TIME [epoch: 5.73 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44059691521939326		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.44059691521939326 | validation: 0.43095241265746126]
	TIME [epoch: 5.75 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4278753955407538		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.4278753955407538 | validation: 0.5042512451418237]
	TIME [epoch: 5.74 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4824133936974281		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.4824133936974281 | validation: 0.5226946686765767]
	TIME [epoch: 5.75 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4448527542024707		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.4448527542024707 | validation: 0.3951691337092663]
	TIME [epoch: 5.74 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4331402260791329		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.4331402260791329 | validation: 0.4060559440981814]
	TIME [epoch: 5.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4383439930186531		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.4383439930186531 | validation: 0.41305377620040307]
	TIME [epoch: 5.75 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.448608791572644		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.448608791572644 | validation: 0.45511761720312166]
	TIME [epoch: 5.75 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4642545692426808		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.4642545692426808 | validation: 0.47497116954316865]
	TIME [epoch: 5.73 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44923711693836593		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.44923711693836593 | validation: 0.4559991903960885]
	TIME [epoch: 5.73 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.429711490866818		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.429711490866818 | validation: 0.4979707151750533]
	TIME [epoch: 5.73 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4414946479601658		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.4414946479601658 | validation: 0.3935995181587414]
	TIME [epoch: 5.76 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46814736860777634		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.46814736860777634 | validation: 0.46370516075631324]
	TIME [epoch: 5.77 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4259909942921138		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.4259909942921138 | validation: 0.3963908729051628]
	TIME [epoch: 5.73 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44628443326090844		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.44628443326090844 | validation: 0.5264149342677105]
	TIME [epoch: 5.73 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4882781035314481		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.4882781035314481 | validation: 0.6178562991188754]
	TIME [epoch: 5.75 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46519058754749487		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.46519058754749487 | validation: 0.4148808218290415]
	TIME [epoch: 5.75 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43149907358435935		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.43149907358435935 | validation: 0.4240635096140467]
	TIME [epoch: 5.75 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44276727208887184		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.44276727208887184 | validation: 0.5889882750741924]
	TIME [epoch: 5.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4441610047456422		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.4441610047456422 | validation: 0.41486225473000077]
	TIME [epoch: 5.75 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45368946313857417		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.45368946313857417 | validation: 0.6441398263884951]
	TIME [epoch: 5.75 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4509844976631025		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.4509844976631025 | validation: 0.4745314287713219]
	TIME [epoch: 5.75 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44248408729332117		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.44248408729332117 | validation: 0.48241122892832766]
	TIME [epoch: 5.75 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4313536762179334		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.4313536762179334 | validation: 0.4446995469900871]
	TIME [epoch: 5.75 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.452263754126802		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.452263754126802 | validation: 0.5831322905054183]
	TIME [epoch: 5.78 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4453166384245383		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.4453166384245383 | validation: 0.3900257190409376]
	TIME [epoch: 5.77 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4099041610828196		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.4099041610828196 | validation: 0.41910406599172884]
	TIME [epoch: 5.75 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44420313727907945		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.44420313727907945 | validation: 0.5187539821976103]
	TIME [epoch: 5.73 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41664495029705617		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.41664495029705617 | validation: 0.4676271263465233]
	TIME [epoch: 5.75 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4356048183585342		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.4356048183585342 | validation: 0.40491439063212326]
	TIME [epoch: 5.73 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41571507918422534		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.41571507918422534 | validation: 0.42416729129159025]
	TIME [epoch: 5.75 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41377143808779004		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.41377143808779004 | validation: 0.44294389689360103]
	TIME [epoch: 5.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4196611601279302		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.4196611601279302 | validation: 0.38868861674459526]
	TIME [epoch: 5.75 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4649724277137197		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.4649724277137197 | validation: 0.426583596728022]
	TIME [epoch: 5.73 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46397283807798095		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.46397283807798095 | validation: 0.5881165963096893]
	TIME [epoch: 5.73 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45614570265576976		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.45614570265576976 | validation: 0.44812293145602483]
	TIME [epoch: 5.73 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41942342230490637		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.41942342230490637 | validation: 0.45040445908892496]
	TIME [epoch: 5.75 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44628074058518646		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.44628074058518646 | validation: 0.5108981058445767]
	TIME [epoch: 5.78 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4704221718032829		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.4704221718032829 | validation: 0.4438859041146302]
	TIME [epoch: 5.76 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44977626945693855		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.44977626945693855 | validation: 0.49330415867595817]
	TIME [epoch: 5.75 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45385202620124754		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.45385202620124754 | validation: 0.45828739941407337]
	TIME [epoch: 5.75 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4537474233549324		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.4537474233549324 | validation: 0.4202548716362085]
	TIME [epoch: 5.75 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41992932855485027		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.41992932855485027 | validation: 0.4736414172615986]
	TIME [epoch: 5.73 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4241107430104671		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.4241107430104671 | validation: 0.4243494744443524]
	TIME [epoch: 5.73 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44748682110805826		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.44748682110805826 | validation: 0.5520293737043409]
	TIME [epoch: 5.78 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4641878178508303		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.4641878178508303 | validation: 0.389040439974617]
	TIME [epoch: 5.75 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41439542304073684		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.41439542304073684 | validation: 0.42154230003051174]
	TIME [epoch: 5.73 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42901602458899424		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.42901602458899424 | validation: 0.44340921588149346]
	TIME [epoch: 5.73 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4282506068441122		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.4282506068441122 | validation: 0.3702988897892614]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_890.pth
	Model improved!!!
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4722017334662979		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.4722017334662979 | validation: 0.7343992227556072]
	TIME [epoch: 5.73 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5375887245997422		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.5375887245997422 | validation: 0.3934291710338648]
	TIME [epoch: 5.79 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42502602362106034		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.42502602362106034 | validation: 0.45925925885297003]
	TIME [epoch: 5.74 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46317770252000023		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.46317770252000023 | validation: 0.44466766067359553]
	TIME [epoch: 5.73 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43532223176453044		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.43532223176453044 | validation: 0.471196282391273]
	TIME [epoch: 5.74 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42253101440373597		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.42253101440373597 | validation: 0.4155555167927011]
	TIME [epoch: 5.72 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4444733087015994		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.4444733087015994 | validation: 0.5019880648159386]
	TIME [epoch: 5.73 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41819210798312034		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.41819210798312034 | validation: 0.39363618763332897]
	TIME [epoch: 5.76 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4258106400028029		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.4258106400028029 | validation: 0.4792722823332601]
	TIME [epoch: 5.76 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41941200988325733		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.41941200988325733 | validation: 0.4044975329440177]
	TIME [epoch: 5.74 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45539660644662966		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.45539660644662966 | validation: 0.5016918146707663]
	TIME [epoch: 5.76 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43696748296621146		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.43696748296621146 | validation: 0.5854089592405245]
	TIME [epoch: 5.72 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4566464984464099		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.4566464984464099 | validation: 0.4778197499644287]
	TIME [epoch: 5.72 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4995222691071193		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.4995222691071193 | validation: 0.3902463032192013]
	TIME [epoch: 5.73 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44939365426676375		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.44939365426676375 | validation: 0.604962973068142]
	TIME [epoch: 5.79 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44816606831921596		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.44816606831921596 | validation: 0.41453211422444003]
	TIME [epoch: 5.73 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4859493539910513		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.4859493539910513 | validation: 0.44356903543260745]
	TIME [epoch: 5.72 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44271959022870144		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.44271959022870144 | validation: 0.5492870477113769]
	TIME [epoch: 5.73 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4677747486375325		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.4677747486375325 | validation: 0.40800290789389354]
	TIME [epoch: 5.72 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4231095095958769		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.4231095095958769 | validation: 0.414100280449358]
	TIME [epoch: 5.72 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40964643059417		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.40964643059417 | validation: 0.3680987961801189]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_911.pth
	Model improved!!!
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40977329722204653		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.40977329722204653 | validation: 0.4605260247078657]
	TIME [epoch: 5.78 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42006218345081797		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.42006218345081797 | validation: 0.364608658277309]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_913.pth
	Model improved!!!
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41683488376240446		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.41683488376240446 | validation: 0.43713014529286126]
	TIME [epoch: 5.73 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4196982959955001		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.4196982959955001 | validation: 0.4327966277487106]
	TIME [epoch: 5.73 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4474955782337331		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.4474955782337331 | validation: 0.3979242396453333]
	TIME [epoch: 5.74 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.426572818875947		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.426572818875947 | validation: 0.45734094619905463]
	TIME [epoch: 5.73 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41572174993334576		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.41572174993334576 | validation: 0.4043330355859298]
	TIME [epoch: 5.79 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4111249253078587		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.4111249253078587 | validation: 0.394159004882121]
	TIME [epoch: 5.73 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42255889177969164		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.42255889177969164 | validation: 0.39120055249197466]
	TIME [epoch: 5.74 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.440605180241631		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.440605180241631 | validation: 0.4451679537742614]
	TIME [epoch: 5.73 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4220522261722781		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.4220522261722781 | validation: 0.42790068193170316]
	TIME [epoch: 5.74 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42735338363799025		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.42735338363799025 | validation: 0.38660561245327324]
	TIME [epoch: 5.73 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41782756650205255		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.41782756650205255 | validation: 0.47987654490682174]
	TIME [epoch: 5.77 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4272222304181864		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.4272222304181864 | validation: 0.4307765404750925]
	TIME [epoch: 5.75 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42424828428739725		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.42424828428739725 | validation: 0.4887438984913169]
	TIME [epoch: 5.73 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4113487566262642		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.4113487566262642 | validation: 0.40414654578454134]
	TIME [epoch: 5.74 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4309316900365945		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.4309316900365945 | validation: 0.5180518057764016]
	TIME [epoch: 5.74 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41769332501240297		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.41769332501240297 | validation: 0.460085101788364]
	TIME [epoch: 5.74 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42808058961119		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.42808058961119 | validation: 0.6296492447361597]
	TIME [epoch: 5.74 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44235720317858046		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.44235720317858046 | validation: 0.3904015981120755]
	TIME [epoch: 5.78 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4283392354107706		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.4283392354107706 | validation: 0.38925939005330784]
	TIME [epoch: 5.74 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44903516588848713		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.44903516588848713 | validation: 0.6524373890074862]
	TIME [epoch: 5.74 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4243943167797251		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.4243943167797251 | validation: 0.41557594830377254]
	TIME [epoch: 5.74 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41744353557420827		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.41744353557420827 | validation: 0.35829963705974677]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_935.pth
	Model improved!!!
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4198439365571419		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.4198439365571419 | validation: 0.5200544127694563]
	TIME [epoch: 5.74 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41061682487272644		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.41061682487272644 | validation: 0.3856307788472077]
	TIME [epoch: 5.78 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4306764181261341		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.4306764181261341 | validation: 0.5019997090848969]
	TIME [epoch: 5.74 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.437427087045807		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.437427087045807 | validation: 0.463789064598938]
	TIME [epoch: 5.74 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4387772115867625		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.4387772115867625 | validation: 0.4497564148920095]
	TIME [epoch: 5.74 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40522313576461644		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.40522313576461644 | validation: 0.3809548647411576]
	TIME [epoch: 5.73 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4219943268377322		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.4219943268377322 | validation: 0.4106086454186755]
	TIME [epoch: 5.74 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42521505688817274		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.42521505688817274 | validation: 0.4563226519806854]
	TIME [epoch: 5.76 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.437403392602685		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.437403392602685 | validation: 0.45133872874206576]
	TIME [epoch: 5.78 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4295251414597143		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.4295251414597143 | validation: 0.41934470030383564]
	TIME [epoch: 5.74 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4010941963698626		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.4010941963698626 | validation: 0.4732120972418369]
	TIME [epoch: 5.74 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42208321496324913		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.42208321496324913 | validation: 0.39157150105359656]
	TIME [epoch: 5.74 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4151497020036347		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.4151497020036347 | validation: 0.39004310763268507]
	TIME [epoch: 5.74 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42233700217330133		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.42233700217330133 | validation: 0.49161234568167844]
	TIME [epoch: 5.73 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.433333465507745		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.433333465507745 | validation: 0.4830269721402556]
	TIME [epoch: 5.77 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43110787316878585		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.43110787316878585 | validation: 0.3896661769643018]
	TIME [epoch: 5.74 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42886582779456817		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.42886582779456817 | validation: 0.4355304986063977]
	TIME [epoch: 5.73 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4241617984866633		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.4241617984866633 | validation: 0.5251507125168824]
	TIME [epoch: 5.72 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44869938792360875		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.44869938792360875 | validation: 0.40881184267638176]
	TIME [epoch: 5.74 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42556610340613565		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.42556610340613565 | validation: 0.41916978972535907]
	TIME [epoch: 5.73 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4300589871057675		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.4300589871057675 | validation: 0.38012457137079]
	TIME [epoch: 5.74 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4227886948619174		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.4227886948619174 | validation: 0.3616942742004786]
	TIME [epoch: 5.76 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42183582842664996		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.42183582842664996 | validation: 0.39142621686101114]
	TIME [epoch: 5.73 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3984001222323291		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.3984001222323291 | validation: 0.4093505954274073]
	TIME [epoch: 5.73 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41231256442489783		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.41231256442489783 | validation: 0.3747879798429539]
	TIME [epoch: 5.73 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.428513459300304		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.428513459300304 | validation: 0.41768484036949105]
	TIME [epoch: 5.74 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40574336372942515		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.40574336372942515 | validation: 0.38293377735456263]
	TIME [epoch: 5.74 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4045529068179427		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.4045529068179427 | validation: 0.38899594194511394]
	TIME [epoch: 5.77 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4080080945569034		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.4080080945569034 | validation: 0.3798384707413706]
	TIME [epoch: 5.73 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4172251113154783		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.4172251113154783 | validation: 0.39428723735369686]
	TIME [epoch: 5.74 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41193563185451765		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.41193563185451765 | validation: 0.3932922660361547]
	TIME [epoch: 5.74 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4148340363601325		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.4148340363601325 | validation: 0.3552132903364007]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_967.pth
	Model improved!!!
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4067428781541413		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.4067428781541413 | validation: 0.3789641045359302]
	TIME [epoch: 5.73 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4219201125548904		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.4219201125548904 | validation: 0.4127530472293534]
	TIME [epoch: 5.75 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4437807171469734		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.4437807171469734 | validation: 0.5518630366048036]
	TIME [epoch: 5.77 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4322365840817574		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.4322365840817574 | validation: 0.4789198038893482]
	TIME [epoch: 5.73 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40463616100619415		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.40463616100619415 | validation: 0.36468198451509376]
	TIME [epoch: 5.73 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39459922175129913		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.39459922175129913 | validation: 0.39419863033352387]
	TIME [epoch: 5.74 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4045948087985016		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.4045948087985016 | validation: 0.4361133152123917]
	TIME [epoch: 5.73 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4057576085979543		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.4057576085979543 | validation: 0.38424311454182436]
	TIME [epoch: 5.74 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4159542350998499		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.4159542350998499 | validation: 0.36772631789227606]
	TIME [epoch: 5.79 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4127951686579914		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.4127951686579914 | validation: 0.4905777295270519]
	TIME [epoch: 5.75 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44469287986769646		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.44469287986769646 | validation: 0.47790402441932855]
	TIME [epoch: 5.74 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40825279108829443		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.40825279108829443 | validation: 0.4540878268945793]
	TIME [epoch: 5.74 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4125315840999647		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.4125315840999647 | validation: 0.3912140251989283]
	TIME [epoch: 5.74 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4105987038157824		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.4105987038157824 | validation: 0.40183327993108126]
	TIME [epoch: 5.73 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40348349811773204		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.40348349811773204 | validation: 0.41712453828429297]
	TIME [epoch: 5.76 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4250644294534617		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.4250644294534617 | validation: 0.3623224040624987]
	TIME [epoch: 5.76 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4012140305588375		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.4012140305588375 | validation: 0.37322657587462715]
	TIME [epoch: 5.74 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4037025725463684		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.4037025725463684 | validation: 0.39001136516756274]
	TIME [epoch: 5.73 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41054749281842495		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.41054749281842495 | validation: 0.36228067929282076]
	TIME [epoch: 5.74 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3973175430577152		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.3973175430577152 | validation: 0.3964782371372863]
	TIME [epoch: 5.73 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933884806615935		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.3933884806615935 | validation: 0.36483557791470717]
	TIME [epoch: 5.74 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41545281235392384		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.41545281235392384 | validation: 0.49904083206118266]
	TIME [epoch: 5.79 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.476492371284522		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.476492371284522 | validation: 0.3634186976188586]
	TIME [epoch: 5.75 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4086761691796139		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.4086761691796139 | validation: 0.3535927653989303]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_991.pth
	Model improved!!!
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4220481645119378		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.4220481645119378 | validation: 0.45484547598683545]
	TIME [epoch: 5.73 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41003306971864933		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.41003306971864933 | validation: 0.3901685858915792]
	TIME [epoch: 5.74 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41347091666435026		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.41347091666435026 | validation: 0.4791360340510611]
	TIME [epoch: 5.74 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40135891440279237		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.40135891440279237 | validation: 0.42052939345780815]
	TIME [epoch: 5.77 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41386668225719475		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.41386668225719475 | validation: 0.42423345990825034]
	TIME [epoch: 5.76 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41354555858725495		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.41354555858725495 | validation: 0.37446445191938715]
	TIME [epoch: 5.72 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42291923042654256		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.42291923042654256 | validation: 0.4122541467791767]
	TIME [epoch: 5.74 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39868729022908955		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.39868729022908955 | validation: 0.4044854197647645]
	TIME [epoch: 5.73 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4032852577072601		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.4032852577072601 | validation: 0.4001349030538752]
	TIME [epoch: 5.73 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.395790623685741		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.395790623685741 | validation: 0.3720454598254074]
	TIME [epoch: 5.74 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3994136739891839		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.3994136739891839 | validation: 0.35611776973150727]
	TIME [epoch: 5.78 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4309124528207746		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.4309124528207746 | validation: 0.4154903235825118]
	TIME [epoch: 5.74 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.416504005176191		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.416504005176191 | validation: 0.3985106491127214]
	TIME [epoch: 5.73 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3979462998312072		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.3979462998312072 | validation: 0.4123349568422182]
	TIME [epoch: 5.74 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45895043138304426		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.45895043138304426 | validation: 0.38257178848546974]
	TIME [epoch: 5.74 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.403368178368174		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.403368178368174 | validation: 0.43654768323376575]
	TIME [epoch: 5.74 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43010116932990816		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.43010116932990816 | validation: 0.39958534095514275]
	TIME [epoch: 5.76 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40838955265884186		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.40838955265884186 | validation: 0.41702619865894625]
	TIME [epoch: 5.76 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4066557869872348		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.4066557869872348 | validation: 0.35609024617405427]
	TIME [epoch: 5.74 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3899891132885645		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.3899891132885645 | validation: 0.38127917308463866]
	TIME [epoch: 5.73 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992362496211772		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.3992362496211772 | validation: 0.3541996138618806]
	TIME [epoch: 5.74 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4015547264628626		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.4015547264628626 | validation: 0.3678185848364439]
	TIME [epoch: 5.73 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40540413823766724		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.40540413823766724 | validation: 0.4619004499535949]
	TIME [epoch: 5.74 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39658055800220027		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.39658055800220027 | validation: 0.4271674700058792]
	TIME [epoch: 5.77 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40998418738870496		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.40998418738870496 | validation: 0.44016143890625614]
	TIME [epoch: 5.75 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4000358880802389		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.4000358880802389 | validation: 0.3772012042855923]
	TIME [epoch: 5.73 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44305284116111177		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.44305284116111177 | validation: 0.3952768451232133]
	TIME [epoch: 5.73 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4131081292449866		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.4131081292449866 | validation: 0.36616343203472446]
	TIME [epoch: 5.74 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39625768433023945		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.39625768433023945 | validation: 0.5262863151663888]
	TIME [epoch: 5.74 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.413112624891668		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.413112624891668 | validation: 0.37565601272464116]
	TIME [epoch: 5.77 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40341195467623603		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.40341195467623603 | validation: 0.3851191750984086]
	TIME [epoch: 5.76 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4036109369871455		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.4036109369871455 | validation: 0.3914971376431143]
	TIME [epoch: 5.74 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39834568230027934		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.39834568230027934 | validation: 0.3925240052731169]
	TIME [epoch: 5.73 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3906892036898781		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.3906892036898781 | validation: 0.4753684285755223]
	TIME [epoch: 5.74 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4055370107096868		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.4055370107096868 | validation: 0.4218160426187005]
	TIME [epoch: 5.73 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3968208093022818		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.3968208093022818 | validation: 0.35934077786962576]
	TIME [epoch: 5.74 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39336347025759866		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.39336347025759866 | validation: 0.3829984241202108]
	TIME [epoch: 5.79 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39996968114169995		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.39996968114169995 | validation: 0.4030584931940686]
	TIME [epoch: 5.74 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.397182617552209		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.397182617552209 | validation: 0.38617158708492855]
	TIME [epoch: 5.74 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4056860024325052		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.4056860024325052 | validation: 0.4115647755829602]
	TIME [epoch: 5.74 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3927357265342833		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.3927357265342833 | validation: 0.3744803903645226]
	TIME [epoch: 5.74 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3994999827402075		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.3994999827402075 | validation: 0.35303883935465097]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1033.pth
	Model improved!!!
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4135303193164189		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.4135303193164189 | validation: 0.3621035173950146]
	TIME [epoch: 5.79 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3953404301655989		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.3953404301655989 | validation: 0.3502226484633564]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1035.pth
	Model improved!!!
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4032177796920257		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.4032177796920257 | validation: 0.3733235896328682]
	TIME [epoch: 5.75 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3971692210578768		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.3971692210578768 | validation: 0.35109245433422304]
	TIME [epoch: 5.75 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38144616155429145		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.38144616155429145 | validation: 0.40713091117303374]
	TIME [epoch: 5.75 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39871497910835196		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.39871497910835196 | validation: 0.35534052936915134]
	TIME [epoch: 5.75 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4000893854759069		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.4000893854759069 | validation: 0.45797048666022805]
	TIME [epoch: 5.77 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40710879381454834		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.40710879381454834 | validation: 0.3804049745263171]
	TIME [epoch: 5.77 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39667581224776644		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.39667581224776644 | validation: 0.3520721432386679]
	TIME [epoch: 5.75 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4033713782810861		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.4033713782810861 | validation: 0.36192375481702355]
	TIME [epoch: 5.75 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4041734022180635		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.4041734022180635 | validation: 0.43645812956715496]
	TIME [epoch: 5.75 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.401186236524427		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.401186236524427 | validation: 0.3594052564272748]
	TIME [epoch: 5.75 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39942057581560486		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.39942057581560486 | validation: 0.3807629656876097]
	TIME [epoch: 5.75 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918275737480015		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.3918275737480015 | validation: 0.37617108957621465]
	TIME [epoch: 5.79 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4012385845269498		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.4012385845269498 | validation: 0.5172584061628155]
	TIME [epoch: 5.75 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4253685054332127		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.4253685054332127 | validation: 0.39588822006618957]
	TIME [epoch: 5.75 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40010790981511807		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.40010790981511807 | validation: 0.3851521382189694]
	TIME [epoch: 5.75 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3954686047980716		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.3954686047980716 | validation: 0.3682685094632788]
	TIME [epoch: 5.75 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918573637874982		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.3918573637874982 | validation: 0.37246577743133297]
	TIME [epoch: 5.75 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3945181517444676		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.3945181517444676 | validation: 0.36639277917047625]
	TIME [epoch: 5.77 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41270722077184163		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.41270722077184163 | validation: 0.37359366790883825]
	TIME [epoch: 5.77 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3936852942604107		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.3936852942604107 | validation: 0.36820749715818113]
	TIME [epoch: 5.75 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3984655325834122		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.3984655325834122 | validation: 0.37517229407537395]
	TIME [epoch: 5.75 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40604244828511077		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.40604244828511077 | validation: 0.36443644538823466]
	TIME [epoch: 5.75 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39399321575319846		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.39399321575319846 | validation: 0.4026315574260495]
	TIME [epoch: 5.75 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3994663765729482		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.3994663765729482 | validation: 0.38984958262413516]
	TIME [epoch: 5.75 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39581330703374096		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.39581330703374096 | validation: 0.3710448902639124]
	TIME [epoch: 5.79 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39086329938540987		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.39086329938540987 | validation: 0.5053184932176447]
	TIME [epoch: 5.75 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39377162797868914		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.39377162797868914 | validation: 0.3565765478093978]
	TIME [epoch: 5.75 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3808548844226195		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.3808548844226195 | validation: 0.3816627479425941]
	TIME [epoch: 5.75 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4118634523580476		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.4118634523580476 | validation: 0.36801207772694855]
	TIME [epoch: 5.74 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4079257918371476		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.4079257918371476 | validation: 0.39912924530151744]
	TIME [epoch: 5.74 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.404391895567655		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.404391895567655 | validation: 0.34947875407407436]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1066.pth
	Model improved!!!
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3872974764847978		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.3872974764847978 | validation: 0.3663621848530839]
	TIME [epoch: 5.76 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3905636855205999		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.3905636855205999 | validation: 0.3871682918212761]
	TIME [epoch: 5.74 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3927369883800572		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.3927369883800572 | validation: 0.382099217124463]
	TIME [epoch: 5.74 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38489921126386245		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.38489921126386245 | validation: 0.3521261868547906]
	TIME [epoch: 5.74 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3819671383989868		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.3819671383989868 | validation: 0.35325756217048193]
	TIME [epoch: 5.74 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3927375971354773		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.3927375971354773 | validation: 0.3548294463090803]
	TIME [epoch: 5.75 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38795180946983693		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.38795180946983693 | validation: 0.35213103310279154]
	TIME [epoch: 5.78 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38279674134375374		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.38279674134375374 | validation: 0.3591993206803417]
	TIME [epoch: 5.74 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40794248637168795		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.40794248637168795 | validation: 0.34086179898362756]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1075.pth
	Model improved!!!
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3973407679659939		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.3973407679659939 | validation: 0.3540076621056899]
	TIME [epoch: 5.74 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389483012513255		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.389483012513255 | validation: 0.35988533300923037]
	TIME [epoch: 5.74 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38629114373375045		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.38629114373375045 | validation: 0.38792260634734066]
	TIME [epoch: 5.74 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38312939737956103		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.38312939737956103 | validation: 0.4077059623470092]
	TIME [epoch: 5.78 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39267470301961566		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.39267470301961566 | validation: 0.34825780416943536]
	TIME [epoch: 5.75 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3985343165190535		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.3985343165190535 | validation: 0.4644275825682984]
	TIME [epoch: 5.74 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3991978901532785		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.3991978901532785 | validation: 0.37716201317440096]
	TIME [epoch: 5.74 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4251520220405772		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.4251520220405772 | validation: 0.42002154687900706]
	TIME [epoch: 5.74 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38666132983955803		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.38666132983955803 | validation: 0.3367562562112461]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1084.pth
	Model improved!!!
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3773195163204414		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.3773195163204414 | validation: 0.40530156752232027]
	TIME [epoch: 5.75 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38307620624873884		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.38307620624873884 | validation: 0.3594415532477535]
	TIME [epoch: 5.74 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38811143537754433		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.38811143537754433 | validation: 0.35066044464274854]
	TIME [epoch: 5.74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3722577036461563		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.3722577036461563 | validation: 0.34976794802658867]
	TIME [epoch: 5.74 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3807429499836513		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.3807429499836513 | validation: 0.3562800471570822]
	TIME [epoch: 5.73 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40496282182137666		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.40496282182137666 | validation: 0.4243162543226358]
	TIME [epoch: 5.72 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3995293536290928		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.3995293536290928 | validation: 0.42193581606177816]
	TIME [epoch: 5.72 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3806474128809449		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.3806474128809449 | validation: 0.3520407300464206]
	TIME [epoch: 5.77 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39497872961851077		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.39497872961851077 | validation: 0.44941706963527134]
	TIME [epoch: 5.72 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3919397347981171		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.3919397347981171 | validation: 0.34706908474006376]
	TIME [epoch: 5.72 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4023459341953551		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.4023459341953551 | validation: 0.37555663721930693]
	TIME [epoch: 5.74 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3897708256523372		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.3897708256523372 | validation: 0.4099872658110224]
	TIME [epoch: 5.74 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39253432441431274		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.39253432441431274 | validation: 0.4243620770351626]
	TIME [epoch: 5.72 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40512885374442853		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.40512885374442853 | validation: 0.37070128431323623]
	TIME [epoch: 5.75 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38490638420200585		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.38490638420200585 | validation: 0.3752037568451982]
	TIME [epoch: 5.75 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3896035557935577		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.3896035557935577 | validation: 0.37042011654619283]
	TIME [epoch: 5.73 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3908965408294412		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.3908965408294412 | validation: 0.4131356300943628]
	TIME [epoch: 5.73 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4249999398766582		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.4249999398766582 | validation: 0.3413556069455919]
	TIME [epoch: 5.73 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3802159029887323		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.3802159029887323 | validation: 0.3842380675045725]
	TIME [epoch: 5.72 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4043035719052942		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.4043035719052942 | validation: 0.3544407389511211]
	TIME [epoch: 5.73 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3982414295111751		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.3982414295111751 | validation: 0.3601002756612654]
	TIME [epoch: 5.78 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.385393338705039		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.385393338705039 | validation: 0.3681191653941291]
	TIME [epoch: 5.73 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3900983325712656		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.3900983325712656 | validation: 0.3667932294699695]
	TIME [epoch: 5.73 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3729330666213649		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.3729330666213649 | validation: 0.3758666830899327]
	TIME [epoch: 5.73 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40505250837806334		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.40505250837806334 | validation: 0.3882146569210563]
	TIME [epoch: 5.74 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4013124884667117		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.4013124884667117 | validation: 0.4056351795235382]
	TIME [epoch: 5.72 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38214393835813687		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.38214393835813687 | validation: 0.38425173061263407]
	TIME [epoch: 5.75 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38159949103001944		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.38159949103001944 | validation: 0.3799521936702396]
	TIME [epoch: 5.76 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38138753592224417		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.38138753592224417 | validation: 0.37436892485817186]
	TIME [epoch: 5.72 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40186334591344103		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.40186334591344103 | validation: 0.35651593091087447]
	TIME [epoch: 5.73 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3854814588949607		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.3854814588949607 | validation: 0.3565745826626243]
	TIME [epoch: 5.72 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3887740873086865		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.3887740873086865 | validation: 0.38110448013844045]
	TIME [epoch: 5.73 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38149459644488537		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.38149459644488537 | validation: 0.4084861155295363]
	TIME [epoch: 5.73 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3831402230028451		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.3831402230028451 | validation: 0.35043701579529085]
	TIME [epoch: 5.78 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3863210410553356		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.3863210410553356 | validation: 0.41205725028965695]
	TIME [epoch: 5.73 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.404912914504255		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.404912914504255 | validation: 0.37961937722340106]
	TIME [epoch: 5.72 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38328853241989835		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.38328853241989835 | validation: 0.42410667792363826]
	TIME [epoch: 5.72 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39475032340345645		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.39475032340345645 | validation: 0.3601219171963438]
	TIME [epoch: 5.73 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39573186017259765		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.39573186017259765 | validation: 0.42145495130759786]
	TIME [epoch: 5.73 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4000018747180937		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.4000018747180937 | validation: 0.371424013318491]
	TIME [epoch: 5.75 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39557244567260974		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.39557244567260974 | validation: 0.370166660248822]
	TIME [epoch: 5.75 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38504252229832636		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.38504252229832636 | validation: 0.3521426541092064]
	TIME [epoch: 5.72 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736996309840942		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.3736996309840942 | validation: 0.3370369979085895]
	TIME [epoch: 5.73 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37392991131488096		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.37392991131488096 | validation: 0.3651320436736434]
	TIME [epoch: 5.72 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38152246291333913		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.38152246291333913 | validation: 0.38486877601741143]
	TIME [epoch: 5.72 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40711236645534876		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.40711236645534876 | validation: 0.381115230299992]
	TIME [epoch: 5.73 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3910510299939073		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.3910510299939073 | validation: 0.37145783164652346]
	TIME [epoch: 5.77 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38438318311746633		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.38438318311746633 | validation: 0.3813559837165187]
	TIME [epoch: 5.72 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4162800983654381		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.4162800983654381 | validation: 0.39368784322264716]
	TIME [epoch: 5.72 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38776747217471674		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.38776747217471674 | validation: 0.3980732001134726]
	TIME [epoch: 5.72 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3971489701349085		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.3971489701349085 | validation: 0.3820307686088206]
	TIME [epoch: 5.74 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3795009615409344		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.3795009615409344 | validation: 0.35732538946535863]
	TIME [epoch: 5.72 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37641893478285204		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.37641893478285204 | validation: 0.3487286792672086]
	TIME [epoch: 5.75 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757414027116336		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.3757414027116336 | validation: 0.34842187260403706]
	TIME [epoch: 5.74 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37488880470852776		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.37488880470852776 | validation: 0.3593820175811529]
	TIME [epoch: 5.72 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38823159094287824		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.38823159094287824 | validation: 0.42514107055242095]
	TIME [epoch: 5.73 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38136885991144454		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.38136885991144454 | validation: 0.3327809772380214]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1141.pth
	Model improved!!!
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37858722581708587		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.37858722581708587 | validation: 0.5231014994704444]
	TIME [epoch: 5.72 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.402519645267774		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.402519645267774 | validation: 0.3788038883304275]
	TIME [epoch: 5.73 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39934294662852615		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.39934294662852615 | validation: 0.3957940347953834]
	TIME [epoch: 5.76 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39463206018002955		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.39463206018002955 | validation: 0.35115498330410744]
	TIME [epoch: 5.74 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37314686973571326		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.37314686973571326 | validation: 0.3527807867018171]
	TIME [epoch: 5.74 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36709458132900785		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.36709458132900785 | validation: 0.3728255638637343]
	TIME [epoch: 5.74 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38554395857529944		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.38554395857529944 | validation: 0.37429209712100714]
	TIME [epoch: 5.74 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3842707713268676		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.3842707713268676 | validation: 0.3778169890770227]
	TIME [epoch: 5.74 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37610820911823106		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.37610820911823106 | validation: 0.3525625764233877]
	TIME [epoch: 5.79 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37691420209098736		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.37691420209098736 | validation: 0.367255735070013]
	TIME [epoch: 5.75 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.382710699200187		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.382710699200187 | validation: 0.4145743834458145]
	TIME [epoch: 5.74 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3691932311609286		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.3691932311609286 | validation: 0.37925669716164606]
	TIME [epoch: 5.74 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3638693695161674		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.3638693695161674 | validation: 0.3546833910626126]
	TIME [epoch: 5.74 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37143257109084415		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.37143257109084415 | validation: 0.36418796693205097]
	TIME [epoch: 5.74 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3816330344333845		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.3816330344333845 | validation: 0.3615294566675575]
	TIME [epoch: 5.75 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37833862384433653		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.37833862384433653 | validation: 0.34560135304368567]
	TIME [epoch: 5.78 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3800630089350643		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.3800630089350643 | validation: 0.37016465356005546]
	TIME [epoch: 5.74 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38455882903064154		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.38455882903064154 | validation: 0.3744044403159226]
	TIME [epoch: 5.74 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3838695859591823		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.3838695859591823 | validation: 0.3358623434735815]
	TIME [epoch: 5.72 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39030178959218126		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.39030178959218126 | validation: 0.37867611873046364]
	TIME [epoch: 5.74 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3769023328461223		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.3769023328461223 | validation: 0.3453135973546923]
	TIME [epoch: 5.74 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3678123944688597		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.3678123944688597 | validation: 0.340823053580523]
	TIME [epoch: 5.79 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3718063681625796		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.3718063681625796 | validation: 0.38734580451974465]
	TIME [epoch: 5.75 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3711021359475116		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.3711021359475116 | validation: 0.35838157152272976]
	TIME [epoch: 5.74 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38094289180870833		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.38094289180870833 | validation: 0.4673351303572042]
	TIME [epoch: 5.74 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37884761215810947		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.37884761215810947 | validation: 0.3477377258346583]
	TIME [epoch: 5.72 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3705028784974587		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.3705028784974587 | validation: 0.3921793271179131]
	TIME [epoch: 5.74 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37479371181045384		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.37479371181045384 | validation: 0.40155752498487235]
	TIME [epoch: 5.76 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3920915039592938		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.3920915039592938 | validation: 0.3459980240177153]
	TIME [epoch: 5.76 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3720289004066991		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.3720289004066991 | validation: 0.3550226790153581]
	TIME [epoch: 5.72 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39336314192123895		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.39336314192123895 | validation: 0.4972368105298854]
	TIME [epoch: 5.72 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3876377727209455		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.3876377727209455 | validation: 0.3590229472365482]
	TIME [epoch: 5.72 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.371179759427083		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.371179759427083 | validation: 0.3999177369630259]
	TIME [epoch: 5.74 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3735415428021284		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.3735415428021284 | validation: 0.36707682612429815]
	TIME [epoch: 5.74 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736795931968457		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.3736795931968457 | validation: 0.37360302435353765]
	TIME [epoch: 5.79 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3807979294527503		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.3807979294527503 | validation: 0.3486832847849705]
	TIME [epoch: 5.75 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38141467671480456		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.38141467671480456 | validation: 0.3717441742003716]
	TIME [epoch: 5.74 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37276873190407733		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.37276873190407733 | validation: 0.42507459031565875]
	TIME [epoch: 5.74 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3691421891110688		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.3691421891110688 | validation: 0.3474859490531806]
	TIME [epoch: 5.74 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37727384952655796		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.37727384952655796 | validation: 0.3997839784135577]
	TIME [epoch: 5.74 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.382778582060334		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.382778582060334 | validation: 0.4040037909699569]
	TIME [epoch: 5.75 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38781986051238054		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.38781986051238054 | validation: 0.4562012604632244]
	TIME [epoch: 5.78 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38430340936144314		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.38430340936144314 | validation: 0.3556420987028714]
	TIME [epoch: 5.74 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3754209931278748		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.3754209931278748 | validation: 0.3899609363534539]
	TIME [epoch: 5.74 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694114852214119		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.3694114852214119 | validation: 0.34974756330075657]
	TIME [epoch: 5.74 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36950507414544553		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.36950507414544553 | validation: 0.34368645533571324]
	TIME [epoch: 5.74 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3708271128722327		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.3708271128722327 | validation: 0.3752679605108783]
	TIME [epoch: 5.73 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37311884125413947		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.37311884125413947 | validation: 0.3776801757872359]
	TIME [epoch: 5.79 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3806440299495048		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.3806440299495048 | validation: 0.38253433491557204]
	TIME [epoch: 5.75 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37340971135561407		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.37340971135561407 | validation: 0.41263894619359665]
	TIME [epoch: 5.75 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38874411519879476		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.38874411519879476 | validation: 0.36846497252599425]
	TIME [epoch: 5.74 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3885091461231701		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.3885091461231701 | validation: 0.3596197089965548]
	TIME [epoch: 5.74 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38146162330010996		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.38146162330010996 | validation: 0.3859634304129908]
	TIME [epoch: 5.73 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3782940130072242		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.3782940130072242 | validation: 0.4116322594786012]
	TIME [epoch: 5.76 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3762707628826562		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.3762707628826562 | validation: 0.33585054750660975]
	TIME [epoch: 5.78 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38114737875636845		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.38114737875636845 | validation: 0.3702737275256091]
	TIME [epoch: 5.74 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36893743316362315		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.36893743316362315 | validation: 0.3666647601145216]
	TIME [epoch: 5.74 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3675517519656025		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.3675517519656025 | validation: 0.3835530095138657]
	TIME [epoch: 5.74 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3799359234472052		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.3799359234472052 | validation: 0.34068781347242655]
	TIME [epoch: 5.74 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38011803631621166		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.38011803631621166 | validation: 0.35034552902888216]
	TIME [epoch: 5.74 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36336675990678646		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.36336675990678646 | validation: 0.3848152207257913]
	TIME [epoch: 5.79 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37242574174835136		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.37242574174835136 | validation: 0.33278730659274286]
	TIME [epoch: 5.74 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38273363076480105		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.38273363076480105 | validation: 0.3694550381812192]
	TIME [epoch: 5.74 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3674127063415009		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.3674127063415009 | validation: 0.4112443485849779]
	TIME [epoch: 5.74 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765576134912195		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.3765576134912195 | validation: 0.3623149396533056]
	TIME [epoch: 5.73 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3721480964619799		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.3721480964619799 | validation: 0.3777911151418218]
	TIME [epoch: 5.74 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38014392584324047		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.38014392584324047 | validation: 0.3949316648470297]
	TIME [epoch: 5.76 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38877891339136245		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.38877891339136245 | validation: 0.3326778690101051]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1209.pth
	Model improved!!!
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39445610195485425		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.39445610195485425 | validation: 0.367721753878289]
	TIME [epoch: 5.74 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4129813060585564		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.4129813060585564 | validation: 0.3953670129045871]
	TIME [epoch: 5.74 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4276424186366543		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.4276424186366543 | validation: 0.387468919005873]
	TIME [epoch: 5.73 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39354091261933255		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.39354091261933255 | validation: 0.3854886180829867]
	TIME [epoch: 5.74 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3799137411789088		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.3799137411789088 | validation: 0.3454425205808734]
	TIME [epoch: 5.74 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3732372822389699		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.3732372822389699 | validation: 0.3389143101607259]
	TIME [epoch: 5.77 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3750663465634944		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.3750663465634944 | validation: 0.3991358837975729]
	TIME [epoch: 5.73 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4002065467345326		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.4002065467345326 | validation: 0.40859127385787103]
	TIME [epoch: 5.72 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37698702936710377		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.37698702936710377 | validation: 0.359801345606941]
	TIME [epoch: 5.74 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736548931713039		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.3736548931713039 | validation: 0.34016038335689713]
	TIME [epoch: 5.74 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36471406576654475		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.36471406576654475 | validation: 0.3792946180790591]
	TIME [epoch: 5.74 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37921731757992383		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.37921731757992383 | validation: 0.3347417341465094]
	TIME [epoch: 5.76 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3635245080200068		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.3635245080200068 | validation: 0.3386597750090711]
	TIME [epoch: 5.76 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3795553912268719		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.3795553912268719 | validation: 0.33695655650626033]
	TIME [epoch: 5.74 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652691911392298		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.3652691911392298 | validation: 0.31825934524661725]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1224.pth
	Model improved!!!
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3615834600462396		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.3615834600462396 | validation: 0.3102613775540507]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1225.pth
	Model improved!!!
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37790331348551165		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.37790331348551165 | validation: 0.34345396612748685]
	TIME [epoch: 5.73 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37194956170596843		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.37194956170596843 | validation: 0.33709361058378845]
	TIME [epoch: 5.74 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3666840197915157		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.3666840197915157 | validation: 0.3416101572425669]
	TIME [epoch: 5.77 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3650221369618314		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.3650221369618314 | validation: 0.3748920237604987]
	TIME [epoch: 5.74 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36614090626122864		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.36614090626122864 | validation: 0.34777112201974264]
	TIME [epoch: 5.74 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37468127942829355		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.37468127942829355 | validation: 0.3851140262417285]
	TIME [epoch: 5.74 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38375908043590906		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.38375908043590906 | validation: 0.42102618829100713]
	TIME [epoch: 5.74 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36946623617285257		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.36946623617285257 | validation: 0.3586297240177748]
	TIME [epoch: 5.74 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3595692430290899		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.3595692430290899 | validation: 0.3386149270013685]
	TIME [epoch: 5.77 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3610804980726754		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.3610804980726754 | validation: 0.3379723396826523]
	TIME [epoch: 5.73 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3619255422491546		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.3619255422491546 | validation: 0.335158317022923]
	TIME [epoch: 5.72 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37517045560830753		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.37517045560830753 | validation: 0.41241015352146926]
	TIME [epoch: 5.72 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37348842165013224		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.37348842165013224 | validation: 0.3408804784421011]
	TIME [epoch: 5.72 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36056156445858284		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.36056156445858284 | validation: 0.34982174061900567]
	TIME [epoch: 5.72 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3655325934008218		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.3655325934008218 | validation: 0.34186864314298077]
	TIME [epoch: 5.74 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3819858963910859		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.3819858963910859 | validation: 0.3565169972223651]
	TIME [epoch: 5.76 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37771403964505873		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.37771403964505873 | validation: 0.36821931786664225]
	TIME [epoch: 5.73 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36939388183775457		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.36939388183775457 | validation: 0.3345974175053049]
	TIME [epoch: 5.72 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736540097840318		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.3736540097840318 | validation: 0.370645057107328]
	TIME [epoch: 5.73 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36622829381775346		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.36622829381775346 | validation: 0.34840300069359414]
	TIME [epoch: 5.74 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3674417630343716		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.3674417630343716 | validation: 0.33594967823460836]
	TIME [epoch: 5.73 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37007241749105213		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.37007241749105213 | validation: 0.3230370495570877]
	TIME [epoch: 5.77 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37001903835317035		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.37001903835317035 | validation: 0.34539330473434277]
	TIME [epoch: 5.74 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3835515995535213		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.3835515995535213 | validation: 0.35971766402146393]
	TIME [epoch: 5.72 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3737770263428728		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.3737770263428728 | validation: 0.35011491147932716]
	TIME [epoch: 5.72 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38810592884492745		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.38810592884492745 | validation: 0.36129555556983567]
	TIME [epoch: 5.72 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706868289283889		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.3706868289283889 | validation: 0.35646772803649013]
	TIME [epoch: 5.74 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36792525525092323		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.36792525525092323 | validation: 0.3579248751810164]
	TIME [epoch: 5.74 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36590499600066095		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.36590499600066095 | validation: 0.3333738741394609]
	TIME [epoch: 5.77 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36954515119626213		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.36954515119626213 | validation: 0.343571090737889]
	TIME [epoch: 5.72 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362709572458389		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.362709572458389 | validation: 0.3401673816446204]
	TIME [epoch: 5.74 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36956635885961436		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.36956635885961436 | validation: 0.3258469304586131]
	TIME [epoch: 5.73 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.368433109371901		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.368433109371901 | validation: 0.3372667996763515]
	TIME [epoch: 5.73 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36483851418425434		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.36483851418425434 | validation: 0.3601921770901374]
	TIME [epoch: 5.74 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37071252614571343		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.37071252614571343 | validation: 0.3654813170892327]
	TIME [epoch: 5.77 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3657012409773289		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.3657012409773289 | validation: 0.38725295947226407]
	TIME [epoch: 5.74 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3644199271592198		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.3644199271592198 | validation: 0.3582250708190506]
	TIME [epoch: 5.74 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36880520412172235		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.36880520412172235 | validation: 0.42026887535016555]
	TIME [epoch: 5.74 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36590488722403486		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.36590488722403486 | validation: 0.37248459541054474]
	TIME [epoch: 5.73 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3599138600277085		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.3599138600277085 | validation: 0.3796523433066075]
	TIME [epoch: 5.74 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591555577018819		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.3591555577018819 | validation: 0.34898791258358813]
	TIME [epoch: 5.76 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36279319229618245		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.36279319229618245 | validation: 0.36659375556983975]
	TIME [epoch: 5.74 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37795818404543513		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.37795818404543513 | validation: 0.34426022418103414]
	TIME [epoch: 5.72 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3764036892582472		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.3764036892582472 | validation: 0.3804096078537386]
	TIME [epoch: 5.72 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673638393669901		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.3673638393669901 | validation: 0.33231542097416905]
	TIME [epoch: 5.74 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3649682861992057		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.3649682861992057 | validation: 0.34790012511929463]
	TIME [epoch: 5.74 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3660645448576369		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.3660645448576369 | validation: 0.34382842982282313]
	TIME [epoch: 5.74 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35865253173990447		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.35865253173990447 | validation: 0.34112216502985454]
	TIME [epoch: 5.77 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3624732763526872		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.3624732763526872 | validation: 0.34917065390188456]
	TIME [epoch: 5.74 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692260750976158		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.3692260750976158 | validation: 0.412542823276355]
	TIME [epoch: 5.73 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3700491680682614		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.3700491680682614 | validation: 0.3712884986124469]
	TIME [epoch: 5.72 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36758685802493907		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.36758685802493907 | validation: 0.3560018380519969]
	TIME [epoch: 5.72 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3625515492008753		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.3625515492008753 | validation: 0.3947853507458835]
	TIME [epoch: 5.73 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37006525196933093		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.37006525196933093 | validation: 0.35663542752499283]
	TIME [epoch: 5.75 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3625124147126457		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.3625124147126457 | validation: 0.36778957602301704]
	TIME [epoch: 5.74 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36356764328376046		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.36356764328376046 | validation: 0.34958786649082785]
	TIME [epoch: 5.72 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37719748376712003		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.37719748376712003 | validation: 0.4044067887818855]
	TIME [epoch: 5.72 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3836396414431461		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.3836396414431461 | validation: 0.327870828619634]
	TIME [epoch: 5.72 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3682756747343558		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.3682756747343558 | validation: 0.33277389622223874]
	TIME [epoch: 5.74 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623144228990839		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.3623144228990839 | validation: 0.3433176860138258]
	TIME [epoch: 5.72 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3668660095973122		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.3668660095973122 | validation: 0.3659804962312924]
	TIME [epoch: 5.77 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3727384500570922		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.3727384500570922 | validation: 0.3401442732019179]
	TIME [epoch: 5.73 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36992308905245364		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.36992308905245364 | validation: 0.3390453105455598]
	TIME [epoch: 5.73 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3650747836727064		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.3650747836727064 | validation: 0.35573677225019956]
	TIME [epoch: 5.72 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36958778140069615		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.36958778140069615 | validation: 0.37382211523920006]
	TIME [epoch: 5.73 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771076573457035		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.3771076573457035 | validation: 0.4149806575012342]
	TIME [epoch: 5.72 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3814511457373011		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.3814511457373011 | validation: 0.35956015917522266]
	TIME [epoch: 5.77 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3727387647541194		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.3727387647541194 | validation: 0.34352610567322034]
	TIME [epoch: 5.74 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36777939994213055		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.36777939994213055 | validation: 0.34828665531578934]
	TIME [epoch: 5.72 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3759051045668458		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.3759051045668458 | validation: 0.40404761178535337]
	TIME [epoch: 5.74 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3678197381593663		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.3678197381593663 | validation: 0.38078230345158715]
	TIME [epoch: 5.74 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3640949897208919		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.3640949897208919 | validation: 0.350317368627305]
	TIME [epoch: 5.74 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765902891770736		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.3765902891770736 | validation: 0.37168419862561763]
	TIME [epoch: 5.74 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36382554053698546		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.36382554053698546 | validation: 0.3644308023087632]
	TIME [epoch: 5.79 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.369724205883564		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.369724205883564 | validation: 0.35706063797934134]
	TIME [epoch: 5.74 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36317286132108406		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.36317286132108406 | validation: 0.3649676910144274]
	TIME [epoch: 5.73 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362562295671652		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.362562295671652 | validation: 0.35032117398767365]
	TIME [epoch: 5.74 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575611471595131		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.3575611471595131 | validation: 0.3362135892470447]
	TIME [epoch: 5.72 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37979766950564364		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.37979766950564364 | validation: 0.3481012894344977]
	TIME [epoch: 5.74 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37512062157926307		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.37512062157926307 | validation: 0.3554521252426482]
	TIME [epoch: 5.76 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3666018154333619		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.3666018154333619 | validation: 0.34587510123353243]
	TIME [epoch: 5.76 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36091414635785		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.36091414635785 | validation: 0.34709043123244215]
	TIME [epoch: 5.74 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3752013401436394		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.3752013401436394 | validation: 0.31841016432594693]
	TIME [epoch: 5.72 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37725678773376403		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.37725678773376403 | validation: 0.3631220090379658]
	TIME [epoch: 5.73 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36999972697085487		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.36999972697085487 | validation: 0.3301860402622145]
	TIME [epoch: 5.73 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364293085940843		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.364293085940843 | validation: 0.37830967362829526]
	TIME [epoch: 5.72 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3710856460097982		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.3710856460097982 | validation: 0.3341499253669784]
	TIME [epoch: 5.77 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361577692803601		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.361577692803601 | validation: 0.3719876333560606]
	TIME [epoch: 5.73 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3594881672566085		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.3594881672566085 | validation: 0.3600166150313231]
	TIME [epoch: 5.74 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36402127313113675		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.36402127313113675 | validation: 0.33290027803676553]
	TIME [epoch: 5.74 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365356364606237		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.365356364606237 | validation: 0.33887857543953914]
	TIME [epoch: 5.72 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36804880082210295		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.36804880082210295 | validation: 0.36424947756294734]
	TIME [epoch: 5.72 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3639507739691908		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.3639507739691908 | validation: 0.3500013435160318]
	TIME [epoch: 5.75 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695054447790775		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.3695054447790775 | validation: 0.34685183991078694]
	TIME [epoch: 5.74 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38193711711799233		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.38193711711799233 | validation: 0.32327188234754645]
	TIME [epoch: 5.72 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3616718722830259		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.3616718722830259 | validation: 0.3277794384795544]
	TIME [epoch: 5.72 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3624010710981179		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.3624010710981179 | validation: 0.34258533270582214]
	TIME [epoch: 5.74 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3589018453599878		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.3589018453599878 | validation: 0.3469452423991294]
	TIME [epoch: 5.73 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36012851354358455		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.36012851354358455 | validation: 0.35235369876866396]
	TIME [epoch: 5.72 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37091907437258487		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.37091907437258487 | validation: 0.3595984529950953]
	TIME [epoch: 5.77 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3622475769412565		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.3622475769412565 | validation: 0.3643124028424204]
	TIME [epoch: 5.73 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3703263955401334		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.3703263955401334 | validation: 0.38074711288775476]
	TIME [epoch: 5.74 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573195096497658		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.3573195096497658 | validation: 0.3714909322030961]
	TIME [epoch: 5.73 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36595230425881964		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.36595230425881964 | validation: 0.35395013605651926]
	TIME [epoch: 5.73 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3641119382139878		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.3641119382139878 | validation: 0.33753110867689345]
	TIME [epoch: 5.72 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3700617841241355		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.3700617841241355 | validation: 0.37767013030554053]
	TIME [epoch: 5.75 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35975079227257206		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.35975079227257206 | validation: 0.3931153790577818]
	TIME [epoch: 5.74 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3655287437778135		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.3655287437778135 | validation: 0.37214542713103266]
	TIME [epoch: 5.73 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3700270966660206		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.3700270966660206 | validation: 0.36571908196051156]
	TIME [epoch: 5.72 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36406612597877797		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.36406612597877797 | validation: 0.34607833350260125]
	TIME [epoch: 5.72 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3611462299378155		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.3611462299378155 | validation: 0.36957133744962084]
	TIME [epoch: 5.74 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36172702241997007		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.36172702241997007 | validation: 0.3361916588063671]
	TIME [epoch: 5.74 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36466269159449616		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.36466269159449616 | validation: 0.32911594550977685]
	TIME [epoch: 5.78 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35882243107775436		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.35882243107775436 | validation: 0.33044311362198975]
	TIME [epoch: 5.73 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35828979314309295		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.35828979314309295 | validation: 0.36036709562233826]
	TIME [epoch: 5.72 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702771207970477		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.3702771207970477 | validation: 0.3247621906306249]
	TIME [epoch: 5.74 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36141703239666945		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.36141703239666945 | validation: 0.332859050964733]
	TIME [epoch: 5.74 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35732177513022684		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.35732177513022684 | validation: 0.3628018555846242]
	TIME [epoch: 5.72 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36515230795400905		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.36515230795400905 | validation: 0.3390949829739113]
	TIME [epoch: 5.78 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601170483282551		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.3601170483282551 | validation: 0.3324247336361771]
	TIME [epoch: 5.73 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36256775860039814		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.36256775860039814 | validation: 0.3995248375129464]
	TIME [epoch: 5.72 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36830847368109093		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.36830847368109093 | validation: 0.35429371697042183]
	TIME [epoch: 5.73 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36358820924248797		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.36358820924248797 | validation: 0.36231345072305443]
	TIME [epoch: 5.72 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628407535174042		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.3628407535174042 | validation: 0.349209260428014]
	TIME [epoch: 5.73 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36207076568885727		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.36207076568885727 | validation: 0.3309969257735488]
	TIME [epoch: 5.75 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36137050255756387		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.36137050255756387 | validation: 0.3302388569126589]
	TIME [epoch: 5.76 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36105107548889737		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.36105107548889737 | validation: 0.3385057733091766]
	TIME [epoch: 5.72 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36303186882894894		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.36303186882894894 | validation: 0.31484304150730813]
	TIME [epoch: 5.73 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35883695503639357		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.35883695503639357 | validation: 0.32902689172083244]
	TIME [epoch: 5.74 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36517931874841775		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.36517931874841775 | validation: 0.36193387418776884]
	TIME [epoch: 5.73 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35960761524270457		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.35960761524270457 | validation: 0.38242060731008715]
	TIME [epoch: 5.72 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36034597357069775		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.36034597357069775 | validation: 0.3295716635698399]
	TIME [epoch: 5.78 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3671063285154412		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.3671063285154412 | validation: 0.34528982054843244]
	TIME [epoch: 5.74 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35685033305819325		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.35685033305819325 | validation: 0.3252965348894918]
	TIME [epoch: 5.74 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35669116538267315		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.35669116538267315 | validation: 0.3207731005223025]
	TIME [epoch: 5.73 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3704394955529788		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.3704394955529788 | validation: 0.3301859877912668]
	TIME [epoch: 5.73 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35876607458379367		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.35876607458379367 | validation: 0.3441712106528332]
	TIME [epoch: 5.74 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35255639276310785		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.35255639276310785 | validation: 0.32979034348170294]
	TIME [epoch: 5.75 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3659931899064531		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.3659931899064531 | validation: 0.3679760704504977]
	TIME [epoch: 5.77 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38670993837762313		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.38670993837762313 | validation: 0.3384433846580751]
	TIME [epoch: 5.74 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37712782760428387		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.37712782760428387 | validation: 0.3314837535150704]
	TIME [epoch: 5.74 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3634839318032089		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.3634839318032089 | validation: 0.3457012299570289]
	TIME [epoch: 5.74 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3603530535644702		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.3603530535644702 | validation: 0.31414792631607863]
	TIME [epoch: 5.74 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585422021443798		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.3585422021443798 | validation: 0.3250306083099983]
	TIME [epoch: 5.73 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36012035839319967		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.36012035839319967 | validation: 0.33936925158066844]
	TIME [epoch: 5.78 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35722101815842977		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.35722101815842977 | validation: 0.3174310934356528]
	TIME [epoch: 5.73 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3659110680780063		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.3659110680780063 | validation: 0.3343229980983159]
	TIME [epoch: 5.72 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3533891376716358		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.3533891376716358 | validation: 0.343658650695629]
	TIME [epoch: 5.72 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36200478268691044		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.36200478268691044 | validation: 0.35204659239490227]
	TIME [epoch: 5.73 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.366440729926971		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.366440729926971 | validation: 0.3400035069356899]
	TIME [epoch: 5.74 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35398093388859697		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.35398093388859697 | validation: 0.3395592976164788]
	TIME [epoch: 5.75 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35715918452889317		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.35715918452889317 | validation: 0.32171225746638377]
	TIME [epoch: 5.76 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35742577108654977		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.35742577108654977 | validation: 0.32537077345556087]
	TIME [epoch: 5.74 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3582959565005558		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.3582959565005558 | validation: 0.36585786372359863]
	TIME [epoch: 5.73 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35473074644030156		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.35473074644030156 | validation: 0.3334799126592469]
	TIME [epoch: 5.72 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538894436475909		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.3538894436475909 | validation: 0.3395660731131022]
	TIME [epoch: 5.72 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3583336959916758		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.3583336959916758 | validation: 0.3377179827849183]
	TIME [epoch: 5.72 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527132856233661		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.3527132856233661 | validation: 0.32044901063139714]
	TIME [epoch: 5.77 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362077986470627		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.362077986470627 | validation: 0.33696959408782995]
	TIME [epoch: 5.73 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35810292445555625		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.35810292445555625 | validation: 0.33727792879611174]
	TIME [epoch: 5.72 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35616347692205025		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.35616347692205025 | validation: 0.3359618662634617]
	TIME [epoch: 5.73 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35337325481626836		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.35337325481626836 | validation: 0.3261499019959241]
	TIME [epoch: 5.74 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35696423523391707		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.35696423523391707 | validation: 0.3198553492490194]
	TIME [epoch: 5.74 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3566957778583428		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.3566957778583428 | validation: 0.33310040756212184]
	TIME [epoch: 5.74 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3663163362676513		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.3663163362676513 | validation: 0.3431865437308392]
	TIME [epoch: 5.76 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3588442666865747		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.3588442666865747 | validation: 0.31058059876663946]
	TIME [epoch: 5.73 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3619943505131994		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.3619943505131994 | validation: 0.332471148808348]
	TIME [epoch: 5.72 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3565050859609413		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.3565050859609413 | validation: 0.3290718478136772]
	TIME [epoch: 5.73 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3595117265311925		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.3595117265311925 | validation: 0.3240761231825169]
	TIME [epoch: 5.72 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35626875535533603		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.35626875535533603 | validation: 0.32935783432704197]
	TIME [epoch: 5.73 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36024018268725055		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.36024018268725055 | validation: 0.32318135768694795]
	TIME [epoch: 5.78 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3595128904344424		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.3595128904344424 | validation: 0.345473375352218]
	TIME [epoch: 5.74 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35557382961254097		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.35557382961254097 | validation: 0.3599247290717839]
	TIME [epoch: 5.74 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3605124585794058		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.3605124585794058 | validation: 0.34693263308463834]
	TIME [epoch: 5.73 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3558649677495444		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.3558649677495444 | validation: 0.33696371447574075]
	TIME [epoch: 5.73 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36629435947401146		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.36629435947401146 | validation: 0.3296612309410894]
	TIME [epoch: 5.74 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609259486327373		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.3609259486327373 | validation: 0.33870505408313145]
	TIME [epoch: 5.76 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36192435333385176		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.36192435333385176 | validation: 0.34776523274325166]
	TIME [epoch: 5.76 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35325852715640293		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.35325852715640293 | validation: 0.34438691832818835]
	TIME [epoch: 5.74 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3549246397315703		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.3549246397315703 | validation: 0.32422582660715327]
	TIME [epoch: 5.74 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540177273512084		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.3540177273512084 | validation: 0.39078967738601067]
	TIME [epoch: 5.73 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3684228989123247		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.3684228989123247 | validation: 0.3532256136167959]
	TIME [epoch: 5.72 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3569805602904258		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.3569805602904258 | validation: 0.33191869262226986]
	TIME [epoch: 5.74 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3615948782678746		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.3615948782678746 | validation: 0.31917757960978577]
	TIME [epoch: 5.79 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3581997812552337		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.3581997812552337 | validation: 0.3403628755254006]
	TIME [epoch: 5.73 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574366378108724		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.3574366378108724 | validation: 0.36146285736836364]
	TIME [epoch: 5.74 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3665792879167708		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.3665792879167708 | validation: 0.3419891831956574]
	TIME [epoch: 5.73 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36007605329906645		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.36007605329906645 | validation: 0.32804229904870186]
	TIME [epoch: 5.74 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35845353287323806		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.35845353287323806 | validation: 0.31830237388627547]
	TIME [epoch: 5.74 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3646933737070636		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.3646933737070636 | validation: 0.328827004802207]
	TIME [epoch: 5.75 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36164716663193064		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.36164716663193064 | validation: 0.34859302979041673]
	TIME [epoch: 5.75 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36068144212933795		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.36068144212933795 | validation: 0.3357575373782109]
	TIME [epoch: 5.74 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35206814185267205		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.35206814185267205 | validation: 0.42574356737831226]
	TIME [epoch: 5.74 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771512785725152		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.3771512785725152 | validation: 0.3433530385577901]
	TIME [epoch: 5.73 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35397943169235		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.35397943169235 | validation: 0.3359536215474555]
	TIME [epoch: 5.72 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3629802537331562		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.3629802537331562 | validation: 0.3315109990327019]
	TIME [epoch: 5.73 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632590243544761		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.3632590243544761 | validation: 0.33844042170632094]
	TIME [epoch: 5.79 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3551849825412029		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.3551849825412029 | validation: 0.350758127502838]
	TIME [epoch: 5.73 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35435141380236107		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.35435141380236107 | validation: 0.33365371508377967]
	TIME [epoch: 5.74 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35678739824676575		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.35678739824676575 | validation: 0.3320825665850603]
	TIME [epoch: 5.74 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3535749187237956		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.3535749187237956 | validation: 0.3460379597616673]
	TIME [epoch: 5.74 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35691226318435854		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.35691226318435854 | validation: 0.33459949248482995]
	TIME [epoch: 5.72 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35641966734169706		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.35641966734169706 | validation: 0.315730285190787]
	TIME [epoch: 5.76 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575330072591299		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.3575330072591299 | validation: 0.3139926034428918]
	TIME [epoch: 5.75 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3625783914665409		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.3625783914665409 | validation: 0.33801343346806784]
	TIME [epoch: 5.74 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37184383650595454		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.37184383650595454 | validation: 0.35001068312253014]
	TIME [epoch: 5.74 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36947698743217877		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.36947698743217877 | validation: 0.31800190000141315]
	TIME [epoch: 5.74 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3586434816467747		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.3586434816467747 | validation: 0.32318773817074475]
	TIME [epoch: 5.72 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35524160520403775		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.35524160520403775 | validation: 0.3291919262047064]
	TIME [epoch: 5.73 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35599366441315816		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.35599366441315816 | validation: 0.31027539322663594]
	TIME [epoch: 5.77 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35878271365801884		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.35878271365801884 | validation: 0.31593115494001595]
	TIME [epoch: 5.73 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3588581538822967		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.3588581538822967 | validation: 0.3341639389502582]
	TIME [epoch: 5.74 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3602787128264287		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.3602787128264287 | validation: 0.34669366606435625]
	TIME [epoch: 5.73 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528691193781896		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.3528691193781896 | validation: 0.3572327386368026]
	TIME [epoch: 5.73 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36368442340889723		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.36368442340889723 | validation: 0.3268764742956875]
	TIME [epoch: 5.74 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35983161523835516		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.35983161523835516 | validation: 0.3511998838328148]
	TIME [epoch: 5.76 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3551964174294856		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.3551964174294856 | validation: 0.34872363833791115]
	TIME [epoch: 5.75 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36097682209388243		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.36097682209388243 | validation: 0.34205976753919515]
	TIME [epoch: 5.73 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36314427123342435		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.36314427123342435 | validation: 0.36558521990586473]
	TIME [epoch: 5.73 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35718721179234025		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.35718721179234025 | validation: 0.35254884583170154]
	TIME [epoch: 5.72 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540265475883489		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.3540265475883489 | validation: 0.3202481737254432]
	TIME [epoch: 5.73 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3555158648607527		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.3555158648607527 | validation: 0.33794827706193287]
	TIME [epoch: 5.73 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.354345867130167		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.354345867130167 | validation: 0.32393185163335986]
	TIME [epoch: 5.77 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.356061188695137		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.356061188695137 | validation: 0.34242248986725854]
	TIME [epoch: 5.73 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35471644894391774		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.35471644894391774 | validation: 0.3326096455028343]
	TIME [epoch: 5.72 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3588226590866219		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.3588226590866219 | validation: 0.33138777872325137]
	TIME [epoch: 5.73 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607551524631666		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.3607551524631666 | validation: 0.3343485565288647]
	TIME [epoch: 5.73 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3590108566525172		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.3590108566525172 | validation: 0.3323992418488392]
	TIME [epoch: 5.74 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573987187378017		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.3573987187378017 | validation: 0.3146584954637317]
	TIME [epoch: 5.76 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35146074440985453		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.35146074440985453 | validation: 0.3319373256693162]
	TIME [epoch: 5.76 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3503300626006848		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.3503300626006848 | validation: 0.32222003877111816]
	TIME [epoch: 5.74 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35740318560895146		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.35740318560895146 | validation: 0.32662025736906053]
	TIME [epoch: 5.73 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35562295579102476		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.35562295579102476 | validation: 0.3021483603274687]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1458.pth
	Model improved!!!
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364922210864537		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.364922210864537 | validation: 0.317239279410643]
	TIME [epoch: 5.73 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361237772997727		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.361237772997727 | validation: 0.318183777877783]
	TIME [epoch: 5.75 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3596903383210573		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.3596903383210573 | validation: 0.31899439677705155]
	TIME [epoch: 5.78 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3626061732049775		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.3626061732049775 | validation: 0.36044101694006003]
	TIME [epoch: 5.73 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3641014097153363		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.3641014097153363 | validation: 0.3295433495270659]
	TIME [epoch: 5.74 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35180558558160346		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.35180558558160346 | validation: 0.32786245087049054]
	TIME [epoch: 5.72 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35198542519363385		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.35198542519363385 | validation: 0.342779211709861]
	TIME [epoch: 5.73 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3589912749329347		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.3589912749329347 | validation: 0.32058085520320573]
	TIME [epoch: 5.72 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35728020760645507		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.35728020760645507 | validation: 0.3521461980410326]
	TIME [epoch: 5.78 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3511092068062099		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.3511092068062099 | validation: 0.35155184109470095]
	TIME [epoch: 5.73 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496896560214352		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.3496896560214352 | validation: 0.3334572651634837]
	TIME [epoch: 5.74 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34929811414740236		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.34929811414740236 | validation: 0.3292058035523348]
	TIME [epoch: 5.72 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3571300802476136		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.3571300802476136 | validation: 0.32447611317972175]
	TIME [epoch: 5.72 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35236083397139667		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.35236083397139667 | validation: 0.34256934412960677]
	TIME [epoch: 5.72 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34821989381070606		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.34821989381070606 | validation: 0.3522990191405722]
	TIME [epoch: 5.75 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527734061517907		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.3527734061517907 | validation: 0.33732029254784257]
	TIME [epoch: 5.76 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3522388301470676		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.3522388301470676 | validation: 0.3448196059512375]
	TIME [epoch: 5.72 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575503754784652		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.3575503754784652 | validation: 0.3084380317101509]
	TIME [epoch: 5.71 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35396133285948306		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.35396133285948306 | validation: 0.3260535675709825]
	TIME [epoch: 5.74 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3592532849047207		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.3592532849047207 | validation: 0.31443688808385434]
	TIME [epoch: 5.72 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3554899347522398		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.3554899347522398 | validation: 0.32914910127026753]
	TIME [epoch: 5.74 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35199971935339763		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.35199971935339763 | validation: 0.3270300201280067]
	TIME [epoch: 5.76 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36349867289455773		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.36349867289455773 | validation: 0.33986720766363854]
	TIME [epoch: 5.73 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36068929523810084		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.36068929523810084 | validation: 0.3444518568900046]
	TIME [epoch: 5.74 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3529651065554903		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.3529651065554903 | validation: 0.3468997336383881]
	TIME [epoch: 5.73 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36064068002679783		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.36064068002679783 | validation: 0.34478638953156576]
	TIME [epoch: 5.73 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3603242952074125		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.3603242952074125 | validation: 0.33244464280117036]
	TIME [epoch: 5.72 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570196061089608		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.3570196061089608 | validation: 0.3482744698488179]
	TIME [epoch: 5.75 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.355154858153905		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.355154858153905 | validation: 0.3368605411698509]
	TIME [epoch: 5.77 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35079655431795714		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.35079655431795714 | validation: 0.3260356341998093]
	TIME [epoch: 5.74 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35026074412102953		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.35026074412102953 | validation: 0.3736816988282663]
	TIME [epoch: 5.74 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524034760813813		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.3524034760813813 | validation: 0.3589075386997554]
	TIME [epoch: 5.73 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34918289201170016		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.34918289201170016 | validation: 0.33356597842324465]
	TIME [epoch: 5.72 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35261524771154984		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.35261524771154984 | validation: 0.3290081884094515]
	TIME [epoch: 5.73 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3564298174912113		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.3564298174912113 | validation: 0.33863423157773415]
	TIME [epoch: 5.77 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35547970074803675		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.35547970074803675 | validation: 0.33132300468256065]
	TIME [epoch: 5.74 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543665923449756		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.3543665923449756 | validation: 0.31284454257963684]
	TIME [epoch: 5.72 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35354846981519716		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.35354846981519716 | validation: 0.32632780165975706]
	TIME [epoch: 5.73 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35850276468043796		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.35850276468043796 | validation: 0.35163737101876874]
	TIME [epoch: 5.73 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3505521570999498		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.3505521570999498 | validation: 0.3479352374416456]
	TIME [epoch: 5.73 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35635606253022734		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.35635606253022734 | validation: 0.3490654312407753]
	TIME [epoch: 5.76 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527737908159693		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.3527737908159693 | validation: 0.35417704860646465]
	TIME [epoch: 5.74 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35590764471897884		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.35590764471897884 | validation: 0.3519520459453503]
	TIME [epoch: 5.73 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.357402456824135		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.357402456824135 | validation: 0.39578043731977863]
	TIME [epoch: 5.73 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36342205397512617		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.36342205397512617 | validation: 0.3565561070291484]
	TIME [epoch: 5.74 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3509673108409539		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.3509673108409539 | validation: 0.337392200545726]
	TIME [epoch: 5.74 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35852721196037834		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.35852721196037834 | validation: 0.332022773176397]
	TIME [epoch: 5.74 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35658481435135664		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.35658481435135664 | validation: 0.34049400327231966]
	TIME [epoch: 5.77 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3515035401792226		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.3515035401792226 | validation: 0.36294322130507256]
	TIME [epoch: 5.74 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3488808987685246		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.3488808987685246 | validation: 0.32781122828817644]
	TIME [epoch: 5.74 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3536349673392026		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.3536349673392026 | validation: 0.34341721185872587]
	TIME [epoch: 5.74 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3522729330864615		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.3522729330864615 | validation: 0.3800937671591264]
	TIME [epoch: 5.74 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3533539395927046		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.3533539395927046 | validation: 0.3596550605184061]
	TIME [epoch: 5.74 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351924951525645		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.351924951525645 | validation: 0.350212717306608]
	TIME [epoch: 5.77 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35136175909823814		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.35136175909823814 | validation: 0.33764363072996106]
	TIME [epoch: 5.78 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3512737809967598		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.3512737809967598 | validation: 0.3272750150304202]
	TIME [epoch: 5.74 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35132132252029985		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.35132132252029985 | validation: 0.3594336868162992]
	TIME [epoch: 5.72 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35383693234468316		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.35383693234468316 | validation: 0.3738500138001875]
	TIME [epoch: 5.74 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35296208950401603		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.35296208950401603 | validation: 0.3497412629497385]
	TIME [epoch: 5.74 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.350726807598322		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.350726807598322 | validation: 0.3420362467285175]
	TIME [epoch: 5.74 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3502840635449941		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.3502840635449941 | validation: 0.3176574448054781]
	TIME [epoch: 5.79 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35480945730239766		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.35480945730239766 | validation: 0.3481712817030013]
	TIME [epoch: 5.74 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35282823726347373		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.35282823726347373 | validation: 0.3568513638598729]
	TIME [epoch: 5.74 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527772441459039		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.3527772441459039 | validation: 0.35045269035601784]
	TIME [epoch: 5.74 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3554468702382998		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.3554468702382998 | validation: 0.3553339626006591]
	TIME [epoch: 5.74 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35781410168137523		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.35781410168137523 | validation: 0.3431603087214222]
	TIME [epoch: 5.74 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35171989200414966		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.35171989200414966 | validation: 0.33260315323339046]
	TIME [epoch: 5.77 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35370554302153023		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.35370554302153023 | validation: 0.3310560116565985]
	TIME [epoch: 5.76 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508369430956835		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.3508369430956835 | validation: 0.3311657724638979]
	TIME [epoch: 5.74 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35056820648439735		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.35056820648439735 | validation: 0.3320692743345876]
	TIME [epoch: 5.72 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35401052546659445		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.35401052546659445 | validation: 0.3455052013820155]
	TIME [epoch: 5.74 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.353255542877228		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.353255542877228 | validation: 0.32398663669811945]
	TIME [epoch: 5.73 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35202736916253485		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.35202736916253485 | validation: 0.33225410770930114]
	TIME [epoch: 5.74 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35772832077986066		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.35772832077986066 | validation: 0.3229407589199782]
	TIME [epoch: 5.78 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35182394608761014		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.35182394608761014 | validation: 0.32365632751453033]
	TIME [epoch: 5.74 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461466794650146		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.3461466794650146 | validation: 0.325959062661955]
	TIME [epoch: 5.73 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35198963820154505		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.35198963820154505 | validation: 0.33488008299084404]
	TIME [epoch: 5.74 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3505983187375272		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.3505983187375272 | validation: 0.31998328722492125]
	TIME [epoch: 5.72 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34865944144821026		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.34865944144821026 | validation: 0.3283511647848002]
	TIME [epoch: 5.72 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35437684038958167		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.35437684038958167 | validation: 0.32969450235464837]
	TIME [epoch: 5.76 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475357350152991		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.3475357350152991 | validation: 0.34108847011614857]
	TIME [epoch: 5.76 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35004122570401025		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.35004122570401025 | validation: 0.3273098147066177]
	TIME [epoch: 5.73 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35168951128457177		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.35168951128457177 | validation: 0.3117156642571959]
	TIME [epoch: 5.72 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35741955777942946		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.35741955777942946 | validation: 0.32526154297128407]
	TIME [epoch: 5.73 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34959477565559105		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.34959477565559105 | validation: 0.340185861031883]
	TIME [epoch: 5.72 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3580466102347765		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.3580466102347765 | validation: 0.3459135529699317]
	TIME [epoch: 5.75 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35305506552820753		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.35305506552820753 | validation: 0.3262116386427961]
	TIME [epoch: 5.76 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498573107583626		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.3498573107583626 | validation: 0.31736193152722497]
	TIME [epoch: 5.74 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35270638924879305		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.35270638924879305 | validation: 0.33496878385499274]
	TIME [epoch: 5.73 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35410620809799076		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.35410620809799076 | validation: 0.3369166507844827]
	TIME [epoch: 5.74 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3581633323261056		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.3581633323261056 | validation: 0.32663255064205987]
	TIME [epoch: 5.72 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3511474933136282		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.3511474933136282 | validation: 0.3230601527363718]
	TIME [epoch: 5.74 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35588318772170363		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.35588318772170363 | validation: 0.33129049348643025]
	TIME [epoch: 5.78 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3525752715686409		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.3525752715686409 | validation: 0.3315738979355288]
	TIME [epoch: 5.73 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34729132859036055		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.34729132859036055 | validation: 0.3228778542040786]
	TIME [epoch: 5.72 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3478688620857567		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.3478688620857567 | validation: 0.3333109566945811]
	TIME [epoch: 5.73 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.357581942167668		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.357581942167668 | validation: 0.32610026818193033]
	TIME [epoch: 5.74 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3616737728443895		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.3616737728443895 | validation: 0.3248528812683986]
	TIME [epoch: 5.72 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3544424333693614		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.3544424333693614 | validation: 0.347596335578197]
	TIME [epoch: 5.75 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35881348532220136		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.35881348532220136 | validation: 0.3293225564708849]
	TIME [epoch: 5.77 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35386279621098915		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.35386279621098915 | validation: 0.3229133413584488]
	TIME [epoch: 5.74 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3505546098276473		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.3505546098276473 | validation: 0.33576627332007236]
	TIME [epoch: 5.73 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538201097754372		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.3538201097754372 | validation: 0.3435596562145958]
	TIME [epoch: 5.72 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3557875196192671		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.3557875196192671 | validation: 0.3263878748380485]
	TIME [epoch: 5.73 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35861748413065275		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.35861748413065275 | validation: 0.30735272226297583]
	TIME [epoch: 5.74 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538663538480668		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.3538663538480668 | validation: 0.3235763971063462]
	TIME [epoch: 5.76 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3548183632179012		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.3548183632179012 | validation: 0.3207726538694435]
	TIME [epoch: 5.74 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35426609404729303		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.35426609404729303 | validation: 0.3246042679505034]
	TIME [epoch: 5.72 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468903139380688		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.3468903139380688 | validation: 0.3230023403166244]
	TIME [epoch: 5.73 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35123728101485696		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.35123728101485696 | validation: 0.3226147535029125]
	TIME [epoch: 5.73 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34837764240789815		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.34837764240789815 | validation: 0.3175652828608345]
	TIME [epoch: 5.72 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34715021238972016		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.34715021238972016 | validation: 0.3392171075432745]
	TIME [epoch: 5.75 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34979268813741704		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.34979268813741704 | validation: 0.30791444860573025]
	TIME [epoch: 5.77 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521652365120657		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.3521652365120657 | validation: 0.30963669152383827]
	TIME [epoch: 5.73 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34755033615605413		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.34755033615605413 | validation: 0.36019147691793635]
	TIME [epoch: 5.72 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574571866851545		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.3574571866851545 | validation: 0.3520478355087609]
	TIME [epoch: 5.73 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498071552696381		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.3498071552696381 | validation: 0.35896578878217716]
	TIME [epoch: 5.73 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34789421512123686		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.34789421512123686 | validation: 0.342876107574935]
	TIME [epoch: 5.73 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35456917796584814		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.35456917796584814 | validation: 0.3305592729763485]
	TIME [epoch: 5.77 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3532536185047841		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.3532536185047841 | validation: 0.3300839199893572]
	TIME [epoch: 5.73 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3465615384568272		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.3465615384568272 | validation: 0.33096635245102446]
	TIME [epoch: 5.73 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.349324390143015		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.349324390143015 | validation: 0.34491764406978276]
	TIME [epoch: 5.72 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498412202714327		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.3498412202714327 | validation: 0.37716719529902776]
	TIME [epoch: 5.74 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359796095259865		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.359796095259865 | validation: 0.3447522097750222]
	TIME [epoch: 5.72 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34585833892683		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.34585833892683 | validation: 0.3188736704967801]
	TIME [epoch: 5.74 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35585687018538814		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.35585687018538814 | validation: 0.32899862160597115]
	TIME [epoch: 5.77 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3506333076358272		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.3506333076358272 | validation: 0.34214431929175987]
	TIME [epoch: 5.73 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3459945984267545		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.3459945984267545 | validation: 0.3600572336754819]
	TIME [epoch: 5.72 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35373078295891497		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.35373078295891497 | validation: 0.3687459467242898]
	TIME [epoch: 5.73 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35486947475282293		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.35486947475282293 | validation: 0.34904849498502194]
	TIME [epoch: 5.73 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3530719957511984		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.3530719957511984 | validation: 0.33939511939696476]
	TIME [epoch: 5.74 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3530492961161367		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.3530492961161367 | validation: 0.35689574055426704]
	TIME [epoch: 5.77 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496018448231189		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.3496018448231189 | validation: 0.3308093090190053]
	TIME [epoch: 5.73 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3480521284800017		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.3480521284800017 | validation: 0.33545851514289565]
	TIME [epoch: 5.72 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528454206573072		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.3528454206573072 | validation: 0.3144511708548823]
	TIME [epoch: 5.72 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34863373913477086		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.34863373913477086 | validation: 0.3195191233648273]
	TIME [epoch: 5.73 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3477622131742629		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.3477622131742629 | validation: 0.33589354937529087]
	TIME [epoch: 5.72 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507673275333079		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.3507673275333079 | validation: 0.34380210631640984]
	TIME [epoch: 5.74 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453143040801135		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.3453143040801135 | validation: 0.3298477049385325]
	TIME [epoch: 5.77 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3486146578891739		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.3486146578891739 | validation: 0.3231018363562763]
	TIME [epoch: 5.74 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3465973493814328		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.3465973493814328 | validation: 0.31978636304788227]
	TIME [epoch: 5.72 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3432436375836764		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.3432436375836764 | validation: 0.3509305865641193]
	TIME [epoch: 5.72 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496210144209568		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.3496210144209568 | validation: 0.34169327102597935]
	TIME [epoch: 5.72 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501274688838795		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.3501274688838795 | validation: 0.3312794731270707]
	TIME [epoch: 5.73 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34305570458528634		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.34305570458528634 | validation: 0.329920745130665]
	TIME [epoch: 5.77 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34767159057244323		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.34767159057244323 | validation: 0.34554224711892845]
	TIME [epoch: 5.74 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34779678596787367		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.34779678596787367 | validation: 0.33374768939618693]
	TIME [epoch: 5.72 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35150196446874427		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.35150196446874427 | validation: 0.34419899413959326]
	TIME [epoch: 5.74 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501157878019853		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.3501157878019853 | validation: 0.32300715829900994]
	TIME [epoch: 5.72 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508938620583241		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.3508938620583241 | validation: 0.31291956282222894]
	TIME [epoch: 5.72 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496997875134428		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.3496997875134428 | validation: 0.3185903101856467]
	TIME [epoch: 5.77 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528364289517054		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.3528364289517054 | validation: 0.3248990912115532]
	TIME [epoch: 5.74 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35131165572875045		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.35131165572875045 | validation: 0.33653021141715783]
	TIME [epoch: 5.73 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3464581617592665		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.3464581617592665 | validation: 0.3117350018133581]
	TIME [epoch: 5.73 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3502080399439207		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.3502080399439207 | validation: 0.30801335213953474]
	TIME [epoch: 5.72 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34819058151343907		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.34819058151343907 | validation: 0.32805476275521533]
	TIME [epoch: 5.73 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35042844111147314		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.35042844111147314 | validation: 0.3146380719899874]
	TIME [epoch: 5.72 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3449250603259265		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.3449250603259265 | validation: 0.3202816575836313]
	TIME [epoch: 5.77 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3492106996496945		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.3492106996496945 | validation: 0.3200387363015852]
	TIME [epoch: 5.72 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440307167170522		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.3440307167170522 | validation: 0.3188352110915922]
	TIME [epoch: 5.72 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3471421492742427		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.3471421492742427 | validation: 0.3255963964802805]
	TIME [epoch: 5.72 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34633618515185277		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.34633618515185277 | validation: 0.29782955678525413]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r3_20240310_010408/states/model_tr_study201_1620.pth
	Model improved!!!
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3449238352551123		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.3449238352551123 | validation: 0.3159333283476355]
	TIME [epoch: 5.74 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468280890045475		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.3468280890045475 | validation: 0.3184312457496095]
	TIME [epoch: 5.77 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34725730207908956		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.34725730207908956 | validation: 0.3068792023560462]
	TIME [epoch: 5.76 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3506116160483669		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.3506116160483669 | validation: 0.3131492299590846]
	TIME [epoch: 5.74 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540668137295021		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.3540668137295021 | validation: 0.3172704143100238]
	TIME [epoch: 5.74 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528094266620756		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.3528094266620756 | validation: 0.3168372458560323]
	TIME [epoch: 5.74 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3530977435502023		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.3530977435502023 | validation: 0.31210564379645145]
	TIME [epoch: 5.74 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34872532322340427		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.34872532322340427 | validation: 0.3319268141760082]
	TIME [epoch: 5.75 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34696127593710974		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.34696127593710974 | validation: 0.32559777778196664]
	TIME [epoch: 5.78 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496772699706073		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.3496772699706073 | validation: 0.3125402144384258]
	TIME [epoch: 5.74 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3535808650874597		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.3535808650874597 | validation: 0.316680289696907]
	TIME [epoch: 5.74 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3505139630687514		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.3505139630687514 | validation: 0.319865387387205]
	TIME [epoch: 5.74 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34477461060101444		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.34477461060101444 | validation: 0.3092966810255832]
	TIME [epoch: 5.74 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.345100158613337		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.345100158613337 | validation: 0.31928166225842525]
	TIME [epoch: 5.74 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34811583317592587		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.34811583317592587 | validation: 0.32464065719947266]
	TIME [epoch: 5.78 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518891863897985		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.3518891863897985 | validation: 0.3204444795496336]
	TIME [epoch: 5.75 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34597477603986465		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.34597477603986465 | validation: 0.3104547389873601]
	TIME [epoch: 5.74 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34418909082624927		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.34418909082624927 | validation: 0.32951483001405296]
	TIME [epoch: 5.74 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3473341162610797		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.3473341162610797 | validation: 0.3158701877482518]
	TIME [epoch: 5.74 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34795331671456214		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.34795331671456214 | validation: 0.340579640452306]
	TIME [epoch: 5.74 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34530342389824314		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.34530342389824314 | validation: 0.30766355339139423]
	TIME [epoch: 5.75 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34440743424966014		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.34440743424966014 | validation: 0.3148584801884795]
	TIME [epoch: 5.78 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34314354773575584		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.34314354773575584 | validation: 0.3333076042667231]
	TIME [epoch: 5.75 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35004701160921126		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.35004701160921126 | validation: 0.34064444618507095]
	TIME [epoch: 5.74 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34444266949959446		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.34444266949959446 | validation: 0.3186311273899194]
	TIME [epoch: 5.74 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34217082048544606		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.34217082048544606 | validation: 0.3228632614222062]
	TIME [epoch: 5.74 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3456535709376144		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.3456535709376144 | validation: 0.31529151704952346]
	TIME [epoch: 5.75 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3481459619928309		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.3481459619928309 | validation: 0.3188230454484289]
	TIME [epoch: 5.79 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35421349716817807		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.35421349716817807 | validation: 0.33588787810301823]
	TIME [epoch: 5.75 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35450126013962857		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.35450126013962857 | validation: 0.31619524187797626]
	TIME [epoch: 5.75 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35097624817000944		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.35097624817000944 | validation: 0.313499711479449]
	TIME [epoch: 5.75 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3479660718278289		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.3479660718278289 | validation: 0.3131082658200339]
	TIME [epoch: 5.75 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34709020147442937		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.34709020147442937 | validation: 0.32084592143359336]
	TIME [epoch: 5.75 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34846157599932404		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.34846157599932404 | validation: 0.3219791511887775]
	TIME [epoch: 5.76 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3465218066457969		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.3465218066457969 | validation: 0.3274282704042766]
	TIME [epoch: 5.78 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518074073140315		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.3518074073140315 | validation: 0.3190908636328172]
	TIME [epoch: 5.75 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3488051340014281		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.3488051340014281 | validation: 0.33091218243467346]
	TIME [epoch: 5.75 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507332346584592		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.3507332346584592 | validation: 0.3296230409563462]
	TIME [epoch: 5.75 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34320707284203084		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.34320707284203084 | validation: 0.33395703295617274]
	TIME [epoch: 5.75 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3450660993003768		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.3450660993003768 | validation: 0.31887705524184434]
	TIME [epoch: 5.75 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453950188486117		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.3453950188486117 | validation: 0.3248205814003689]
	TIME [epoch: 5.8 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.345456770311411		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.345456770311411 | validation: 0.329814771685652]
	TIME [epoch: 5.75 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34890089753235054		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.34890089753235054 | validation: 0.31740917632639026]
	TIME [epoch: 5.75 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3503933016048908		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.3503933016048908 | validation: 0.3267699729419715]
	TIME [epoch: 5.75 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34347305050634314		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.34347305050634314 | validation: 0.32391037745865237]
	TIME [epoch: 5.75 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.348372519294632		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.348372519294632 | validation: 0.32778288550149187]
	TIME [epoch: 5.75 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34833147081319316		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.34833147081319316 | validation: 0.3498839321541624]
	TIME [epoch: 5.77 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3513255603052192		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.3513255603052192 | validation: 0.34872257051506045]
	TIME [epoch: 5.77 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507497281891765		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.3507497281891765 | validation: 0.3416151519736684]
	TIME [epoch: 5.75 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.350826597524295		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.350826597524295 | validation: 0.3152635446640174]
	TIME [epoch: 5.75 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35531763989704596		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.35531763989704596 | validation: 0.31379651238890305]
	TIME [epoch: 5.75 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35003561403313915		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.35003561403313915 | validation: 0.3272248536829767]
	TIME [epoch: 5.75 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3487568585351837		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.3487568585351837 | validation: 0.31545554132130793]
	TIME [epoch: 5.75 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527724087278323		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.3527724087278323 | validation: 0.32429994124400624]
	TIME [epoch: 5.79 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3515845964208786		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.3515845964208786 | validation: 0.32961398119844876]
	TIME [epoch: 5.75 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3562215190389527		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.3562215190389527 | validation: 0.33283852308994144]
	TIME [epoch: 5.75 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34895986502025567		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.34895986502025567 | validation: 0.32497515926229936]
	TIME [epoch: 5.75 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34981551922026755		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.34981551922026755 | validation: 0.32077904475562674]
	TIME [epoch: 5.75 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352298313544011		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.352298313544011 | validation: 0.3224693851340618]
	TIME [epoch: 5.75 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508189340559983		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.3508189340559983 | validation: 0.33500725322333624]
	TIME [epoch: 5.77 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35498835884413343		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.35498835884413343 | validation: 0.33128284787286644]
	TIME [epoch: 5.77 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3551000416605765		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.3551000416605765 | validation: 0.316132927632387]
	TIME [epoch: 5.75 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3604205157174051		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.3604205157174051 | validation: 0.32507540254188]
	TIME [epoch: 5.75 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36027736806344035		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.36027736806344035 | validation: 0.31917514104424627]
	TIME [epoch: 5.75 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3589257383387594		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.3589257383387594 | validation: 0.33760791915996224]
	TIME [epoch: 5.74 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36446674842301685		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.36446674842301685 | validation: 0.3346199253345567]
	TIME [epoch: 5.75 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3662806912390648		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.3662806912390648 | validation: 0.34682214330337086]
	TIME [epoch: 5.79 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36121663582227514		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.36121663582227514 | validation: 0.3446749694743121]
	TIME [epoch: 5.75 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3586912758221868		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.3586912758221868 | validation: 0.3501631465814218]
	TIME [epoch: 5.75 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496869725634696		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.3496869725634696 | validation: 0.3339696428255329]
	TIME [epoch: 5.75 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3512374026565419		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.3512374026565419 | validation: 0.3288622121512525]
	TIME [epoch: 5.74 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.354619997848764		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.354619997848764 | validation: 0.3384489079623606]
	TIME [epoch: 5.75 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496074653964695		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.3496074653964695 | validation: 0.3455474146154907]
	TIME [epoch: 5.77 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35391510673818677		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.35391510673818677 | validation: 0.3297936252960079]
	TIME [epoch: 5.76 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3520307560008638		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.3520307560008638 | validation: 0.326510330387574]
	TIME [epoch: 5.75 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3504652728412411		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.3504652728412411 | validation: 0.34495613438547723]
	TIME [epoch: 5.75 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35018756017105457		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.35018756017105457 | validation: 0.3468260462921923]
	TIME [epoch: 5.75 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34643585719179965		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.34643585719179965 | validation: 0.3491829540923862]
	TIME [epoch: 5.75 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34881072640603156		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.34881072640603156 | validation: 0.365985598655265]
	TIME [epoch: 5.76 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35235888186403336		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.35235888186403336 | validation: 0.3449429074083736]
	TIME [epoch: 5.78 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35180194776116597		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.35180194776116597 | validation: 0.33189645971407666]
	TIME [epoch: 5.75 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35180960653902504		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.35180960653902504 | validation: 0.3261937370301504]
	TIME [epoch: 5.75 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468606220016854		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.3468606220016854 | validation: 0.3353936783370334]
	TIME [epoch: 5.75 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34724461078252783		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.34724461078252783 | validation: 0.34369731870802384]
	TIME [epoch: 5.75 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3464954883736353		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.3464954883736353 | validation: 0.3341572416870551]
	TIME [epoch: 5.75 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34672676263830227		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.34672676263830227 | validation: 0.32637769154070273]
	TIME [epoch: 5.79 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491936747290955		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.3491936747290955 | validation: 0.3290664102778629]
	TIME [epoch: 5.75 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3462735771060599		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.3462735771060599 | validation: 0.34124143037822535]
	TIME [epoch: 5.75 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34798377105548267		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.34798377105548267 | validation: 0.3479011840931509]
	TIME [epoch: 5.75 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518654203899717		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.3518654203899717 | validation: 0.3396457263035649]
	TIME [epoch: 5.75 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3446153961076026		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.3446153961076026 | validation: 0.34030153676959685]
	TIME [epoch: 5.75 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34587950554497193		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.34587950554497193 | validation: 0.33162436765910863]
	TIME [epoch: 5.76 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34767658910312493		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.34767658910312493 | validation: 0.3356137595243359]
	TIME [epoch: 5.78 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3481288792903895		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.3481288792903895 | validation: 0.32966956693710886]
	TIME [epoch: 5.75 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3456762049478871		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.3456762049478871 | validation: 0.3428378256840698]
	TIME [epoch: 5.75 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34540091874553397		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.34540091874553397 | validation: 0.3328455635104065]
	TIME [epoch: 5.75 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34833213954431225		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.34833213954431225 | validation: 0.3296413433772119]
	TIME [epoch: 5.75 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34871277726210415		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.34871277726210415 | validation: 0.32740130304046816]
	TIME [epoch: 5.75 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3425697836512614		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.3425697836512614 | validation: 0.32931565725372525]
	TIME [epoch: 5.79 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34671753601896826		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.34671753601896826 | validation: 0.33590626331741513]
	TIME [epoch: 5.75 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34877854396177344		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.34877854396177344 | validation: 0.33747977817106434]
	TIME [epoch: 5.75 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34783662645932306		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.34783662645932306 | validation: 0.3310848843611777]
	TIME [epoch: 5.75 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34688095503648986		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.34688095503648986 | validation: 0.317611265768695]
	TIME [epoch: 5.75 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34488091200601395		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.34488091200601395 | validation: 0.3236376911920113]
	TIME [epoch: 5.75 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34587802698024356		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.34587802698024356 | validation: 0.3333736615054128]
	TIME [epoch: 5.77 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3495690580343081		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.3495690580343081 | validation: 0.3265856410595314]
	TIME [epoch: 5.77 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3462780487231357		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.3462780487231357 | validation: 0.32435651641210994]
	TIME [epoch: 5.75 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3495298895089575		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.3495298895089575 | validation: 0.32755034060787724]
	TIME [epoch: 5.75 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34442766344023246		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.34442766344023246 | validation: 0.3292389348448394]
	TIME [epoch: 5.75 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3409133357522594		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.3409133357522594 | validation: 0.3265459358117978]
	TIME [epoch: 5.75 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34816183975776804		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.34816183975776804 | validation: 0.33921667483681317]
	TIME [epoch: 5.75 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34365611828548714		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.34365611828548714 | validation: 0.31516058671208486]
	TIME [epoch: 5.79 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35296550039003816		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.35296550039003816 | validation: 0.322451309508758]
	TIME [epoch: 5.75 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34853618451685575		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.34853618451685575 | validation: 0.3286857331747837]
	TIME [epoch: 5.75 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347526870505663		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.347526870505663 | validation: 0.31934400132543345]
	TIME [epoch: 5.75 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3495981261575339		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.3495981261575339 | validation: 0.3269849853545222]
	TIME [epoch: 5.75 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472086138124358		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.3472086138124358 | validation: 0.327793462262955]
	TIME [epoch: 5.75 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498836103864333		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.3498836103864333 | validation: 0.3337028252008845]
	TIME [epoch: 5.77 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34384248334071077		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.34384248334071077 | validation: 0.33106968507294876]
	TIME [epoch: 5.77 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3506197107973629		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.3506197107973629 | validation: 0.3399639147933557]
	TIME [epoch: 5.75 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3456728295527998		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.3456728295527998 | validation: 0.34080965243233347]
	TIME [epoch: 5.75 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461330639661667		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.3461330639661667 | validation: 0.34274499100670425]
	TIME [epoch: 5.75 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34596636858362406		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.34596636858362406 | validation: 0.328462031325039]
	TIME [epoch: 5.75 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439365126826768		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.3439365126826768 | validation: 0.3261525939660655]
	TIME [epoch: 5.75 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34594536710065016		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.34594536710065016 | validation: 0.3172103795595628]
	TIME [epoch: 5.79 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34858133546475756		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.34858133546475756 | validation: 0.32260774950631105]
	TIME [epoch: 5.75 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439715306304919		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.3439715306304919 | validation: 0.3117808318671064]
	TIME [epoch: 5.75 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34483280770513247		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.34483280770513247 | validation: 0.3155620185581745]
	TIME [epoch: 5.75 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34572300291302316		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.34572300291302316 | validation: 0.3189574591440935]
	TIME [epoch: 5.75 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34280335124771466		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.34280335124771466 | validation: 0.31650333374485007]
	TIME [epoch: 5.75 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34420429846471273		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.34420429846471273 | validation: 0.32367423366893355]
	TIME [epoch: 5.78 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3407767392929322		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.3407767392929322 | validation: 0.3398698230633929]
	TIME [epoch: 5.76 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347272278971199		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.347272278971199 | validation: 0.3270390320723218]
	TIME [epoch: 5.75 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3467133998071134		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.3467133998071134 | validation: 0.3213807897855165]
	TIME [epoch: 5.75 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34247898184543685		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.34247898184543685 | validation: 0.3273286708652066]
	TIME [epoch: 5.75 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34734865758230493		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.34734865758230493 | validation: 0.32554174286950355]
	TIME [epoch: 5.75 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34380733608843184		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.34380733608843184 | validation: 0.3130419517423401]
	TIME [epoch: 5.76 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3483206577953499		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.3483206577953499 | validation: 0.31321904071235634]
	TIME [epoch: 5.78 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34755503294346984		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.34755503294346984 | validation: 0.31723507080053515]
	TIME [epoch: 5.75 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34929326185616527		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.34929326185616527 | validation: 0.3270801909979852]
	TIME [epoch: 5.75 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472822977729958		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.3472822977729958 | validation: 0.3201305930667559]
	TIME [epoch: 5.75 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447819405982201		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.3447819405982201 | validation: 0.33208265772054757]
	TIME [epoch: 5.75 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3467663661799538		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.3467663661799538 | validation: 0.3333566021573367]
	TIME [epoch: 5.74 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3463301193379022		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.3463301193379022 | validation: 0.3396643368385756]
	TIME [epoch: 5.79 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3470372634203931		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.3470372634203931 | validation: 0.3197283105498942]
	TIME [epoch: 5.75 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34617606378902105		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.34617606378902105 | validation: 0.3275752604873686]
	TIME [epoch: 5.75 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34614141477726634		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.34614141477726634 | validation: 0.3317472499919967]
	TIME [epoch: 5.74 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439598438581936		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.3439598438581936 | validation: 0.32664347778198677]
	TIME [epoch: 5.75 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461034107036023		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.3461034107036023 | validation: 0.31928574150622857]
	TIME [epoch: 5.75 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35060849589750204		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.35060849589750204 | validation: 0.3146101335692685]
	TIME [epoch: 5.76 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35082922715771786		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.35082922715771786 | validation: 0.324438559023898]
	TIME [epoch: 5.78 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3466011533172568		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.3466011533172568 | validation: 0.32653259060352324]
	TIME [epoch: 5.75 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34908119726855097		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.34908119726855097 | validation: 0.3373866423826621]
	TIME [epoch: 5.75 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34751502765732756		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.34751502765732756 | validation: 0.3310404942125592]
	TIME [epoch: 5.74 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34814833736235323		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.34814833736235323 | validation: 0.3342989768334478]
	TIME [epoch: 5.74 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34208773334338544		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.34208773334338544 | validation: 0.33227572316051374]
	TIME [epoch: 5.74 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3402775376879193		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.3402775376879193 | validation: 0.31280806194186966]
	TIME [epoch: 5.79 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34549181942989965		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.34549181942989965 | validation: 0.31097869527514915]
	TIME [epoch: 5.75 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34554629149048843		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.34554629149048843 | validation: 0.3169896206610426]
	TIME [epoch: 5.74 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34698139920745186		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.34698139920745186 | validation: 0.32606646205548645]
	TIME [epoch: 5.75 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3487687659154275		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.3487687659154275 | validation: 0.3226656823636675]
	TIME [epoch: 5.74 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35127707540130826		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.35127707540130826 | validation: 0.3272151601716267]
	TIME [epoch: 5.75 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521926981069236		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.3521926981069236 | validation: 0.3317717140321429]
	TIME [epoch: 5.76 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3459769377572434		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.3459769377572434 | validation: 0.3347908303671545]
	TIME [epoch: 5.78 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3497161235291839		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.3497161235291839 | validation: 0.3269750647541156]
	TIME [epoch: 5.75 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34439476048059137		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.34439476048059137 | validation: 0.32332678143195004]
	TIME [epoch: 5.74 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508398393935351		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.3508398393935351 | validation: 0.3300701045148179]
	TIME [epoch: 5.74 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35164394324161086		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.35164394324161086 | validation: 0.34343943289008044]
	TIME [epoch: 5.74 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34645680426093395		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.34645680426093395 | validation: 0.3405524594813052]
	TIME [epoch: 5.74 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.349014195648427		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.349014195648427 | validation: 0.35465877191050416]
	TIME [epoch: 5.79 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34572535351546096		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.34572535351546096 | validation: 0.33883035561045377]
	TIME [epoch: 5.75 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3532012561219888		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.3532012561219888 | validation: 0.347895238977262]
	TIME [epoch: 5.74 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3485970226556309		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.3485970226556309 | validation: 0.33931138717897796]
	TIME [epoch: 5.74 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454351416409634		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.3454351416409634 | validation: 0.33655982850983973]
	TIME [epoch: 5.74 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35063014073171606		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.35063014073171606 | validation: 0.3282468012121833]
	TIME [epoch: 5.74 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34902220076336155		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.34902220076336155 | validation: 0.33961274599642083]
	TIME [epoch: 5.77 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34456087732218377		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.34456087732218377 | validation: 0.35116866073559316]
	TIME [epoch: 5.76 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34685772425188416		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.34685772425188416 | validation: 0.33373970094914657]
	TIME [epoch: 5.75 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3452605551209881		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.3452605551209881 | validation: 0.3238173540184143]
	TIME [epoch: 5.73 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34267473125042125		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.34267473125042125 | validation: 0.3224160132089625]
	TIME [epoch: 5.75 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34218388171404945		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.34218388171404945 | validation: 0.32699210760177855]
	TIME [epoch: 5.74 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3434244371529485		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.3434244371529485 | validation: 0.324361650027558]
	TIME [epoch: 5.75 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34259191014794477		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.34259191014794477 | validation: 0.33267522135961175]
	TIME [epoch: 5.79 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34500354892813434		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.34500354892813434 | validation: 0.3288477692300559]
	TIME [epoch: 5.75 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34707200820584716		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.34707200820584716 | validation: 0.3426605296471361]
	TIME [epoch: 5.74 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34919269280205995		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.34919269280205995 | validation: 0.33547811521729115]
	TIME [epoch: 5.73 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436632343128731		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.3436632343128731 | validation: 0.329013987818966]
	TIME [epoch: 5.73 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3482281791406943		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.3482281791406943 | validation: 0.3428588979924193]
	TIME [epoch: 5.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34407849121436757		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.34407849121436757 | validation: 0.3560864789468035]
	TIME [epoch: 5.76 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.348811505638867		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.348811505638867 | validation: 0.33513148631038375]
	TIME [epoch: 5.76 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34360902810971455		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.34360902810971455 | validation: 0.33602283473701405]
	TIME [epoch: 5.74 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442615619527681		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.3442615619527681 | validation: 0.3287285653868138]
	TIME [epoch: 5.73 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461499404104764		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.3461499404104764 | validation: 0.320447868739833]
	TIME [epoch: 5.73 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34625742608597754		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.34625742608597754 | validation: 0.3204357600328936]
	TIME [epoch: 5.73 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3406061849871804		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.3406061849871804 | validation: 0.33608696992291137]
	TIME [epoch: 5.73 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3481600768631305		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.3481600768631305 | validation: 0.3352281808425734]
	TIME [epoch: 5.77 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3465422648608397		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.3465422648608397 | validation: 0.3291552388413889]
	TIME [epoch: 5.73 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3505265154834729		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.3505265154834729 | validation: 0.3196243558968565]
	TIME [epoch: 5.73 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3458653006948804		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.3458653006948804 | validation: 0.3129956154789174]
	TIME [epoch: 5.74 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35100287951315834		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.35100287951315834 | validation: 0.31685144051979847]
	TIME [epoch: 5.74 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35072008456033865		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.35072008456033865 | validation: 0.32403410714596687]
	TIME [epoch: 5.74 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3474048194858739		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.3474048194858739 | validation: 0.31996748702810696]
	TIME [epoch: 5.78 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3515116091652334		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.3515116091652334 | validation: 0.3186604301280855]
	TIME [epoch: 5.74 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35240215406207454		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.35240215406207454 | validation: 0.319558056819458]
	TIME [epoch: 5.73 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34511439006860317		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.34511439006860317 | validation: 0.31064691740053285]
	TIME [epoch: 5.73 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34695578652075837		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.34695578652075837 | validation: 0.3180193705567268]
	TIME [epoch: 5.73 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454278147340016		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.3454278147340016 | validation: 0.3301109700922349]
	TIME [epoch: 5.73 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34495541815855113		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.34495541815855113 | validation: 0.32340847133045103]
	TIME [epoch: 5.74 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34313864032994706		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.34313864032994706 | validation: 0.31981007261902245]
	TIME [epoch: 5.76 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3457937464269793		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.3457937464269793 | validation: 0.3156142548108275]
	TIME [epoch: 5.73 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3419609933601784		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.3419609933601784 | validation: 0.3108122104089882]
	TIME [epoch: 5.73 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34517210247270474		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.34517210247270474 | validation: 0.3281688168741754]
	TIME [epoch: 5.73 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447907303186353		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.3447907303186353 | validation: 0.320276683769699]
	TIME [epoch: 5.73 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3415884727537248		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.3415884727537248 | validation: 0.3211001184924677]
	TIME [epoch: 5.73 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454889046302907		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.3454889046302907 | validation: 0.3207840942660246]
	TIME [epoch: 5.77 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34918980308732656		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.34918980308732656 | validation: 0.32029515621248605]
	TIME [epoch: 5.73 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3470991358131986		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.3470991358131986 | validation: 0.312970447061254]
	TIME [epoch: 5.73 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34560096183857586		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.34560096183857586 | validation: 0.31818784272444683]
	TIME [epoch: 5.73 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34944542427799413		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.34944542427799413 | validation: 0.32694988193663704]
	TIME [epoch: 5.73 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3463182225663875		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.3463182225663875 | validation: 0.33461615792380656]
	TIME [epoch: 5.73 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.346936970186087		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.346936970186087 | validation: 0.34737232977679405]
	TIME [epoch: 5.74 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35056337686317085		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.35056337686317085 | validation: 0.34389312359873353]
	TIME [epoch: 5.76 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.345278817560901		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.345278817560901 | validation: 0.35085956716724875]
	TIME [epoch: 5.73 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34857578067605355		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.34857578067605355 | validation: 0.33919552588085083]
	TIME [epoch: 5.73 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34238661696554745		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.34238661696554745 | validation: 0.33685761794537955]
	TIME [epoch: 5.73 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35038179371807165		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.35038179371807165 | validation: 0.3443224949727848]
	TIME [epoch: 5.72 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3395005552301947		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.3395005552301947 | validation: 0.33390662814605093]
	TIME [epoch: 5.73 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.341985572988937		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.341985572988937 | validation: 0.323341264090147]
	TIME [epoch: 5.77 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3446709961065567		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.3446709961065567 | validation: 0.32743696299340463]
	TIME [epoch: 5.73 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461106257401096		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.3461106257401096 | validation: 0.3318738331753715]
	TIME [epoch: 5.73 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3424819936514464		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.3424819936514464 | validation: 0.32577412386279153]
	TIME [epoch: 5.73 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3428643714230496		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.3428643714230496 | validation: 0.3280565404383451]
	TIME [epoch: 5.73 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447786562248722		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.3447786562248722 | validation: 0.32542341044850154]
	TIME [epoch: 5.73 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3452418850497689		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.3452418850497689 | validation: 0.32850070093211003]
	TIME [epoch: 5.74 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3398696019280106		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.3398696019280106 | validation: 0.3338067280586688]
	TIME [epoch: 5.76 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3465989687052674		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.3465989687052674 | validation: 0.3295085247589422]
	TIME [epoch: 5.73 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3433510261262091		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.3433510261262091 | validation: 0.32731447842269445]
	TIME [epoch: 5.73 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.345318191274473		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.345318191274473 | validation: 0.3326282680938256]
	TIME [epoch: 5.72 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3499813553645602		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.3499813553645602 | validation: 0.3382784871137611]
	TIME [epoch: 5.72 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.349810656432069		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.349810656432069 | validation: 0.3401807873250586]
	TIME [epoch: 5.73 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34541513837828747		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.34541513837828747 | validation: 0.3221835276453022]
	TIME [epoch: 5.77 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3494291311446162		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.3494291311446162 | validation: 0.3263783443433203]
	TIME [epoch: 5.73 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34520646485998185		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.34520646485998185 | validation: 0.3162077957221957]
	TIME [epoch: 5.72 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3420469335851434		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.3420469335851434 | validation: 0.3229843627920346]
	TIME [epoch: 5.72 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3525851455412622		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.3525851455412622 | validation: 0.34110307355537767]
	TIME [epoch: 5.72 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34460344579689395		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.34460344579689395 | validation: 0.33664263240199516]
	TIME [epoch: 5.72 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34703663595460177		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.34703663595460177 | validation: 0.330459202574734]
	TIME [epoch: 5.75 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3437626341404953		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.3437626341404953 | validation: 0.3328602333858676]
	TIME [epoch: 5.75 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3470363759276857		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.3470363759276857 | validation: 0.3328747294953219]
	TIME [epoch: 5.73 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34647508170391744		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.34647508170391744 | validation: 0.3179592045987678]
	TIME [epoch: 5.73 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34659869241445607		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.34659869241445607 | validation: 0.32110586967926735]
	TIME [epoch: 5.72 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3438902607058635		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.3438902607058635 | validation: 0.31997763612421104]
	TIME [epoch: 5.73 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34543895023897564		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.34543895023897564 | validation: 0.31811123358885085]
	TIME [epoch: 5.73 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34619236123724595		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.34619236123724595 | validation: 0.31964291653384197]
	TIME [epoch: 5.77 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3470352776499983		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.3470352776499983 | validation: 0.3189107097911083]
	TIME [epoch: 5.73 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34445295806151843		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.34445295806151843 | validation: 0.32228616665115595]
	TIME [epoch: 5.73 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442384749558384		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.3442384749558384 | validation: 0.32186275617405563]
	TIME [epoch: 5.75 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34355811404937375		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.34355811404937375 | validation: 0.31836758873753934]
	TIME [epoch: 5.75 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3465344183312604		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.3465344183312604 | validation: 0.3369761458002215]
	TIME [epoch: 5.73 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34555226436391145		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.34555226436391145 | validation: 0.3352581483068745]
	TIME [epoch: 5.75 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34662537522830816		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.34662537522830816 | validation: 0.3233522271407877]
	TIME [epoch: 5.75 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3441360492270509		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.3441360492270509 | validation: 0.31894882955945625]
	TIME [epoch: 5.73 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468032101994677		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.3468032101994677 | validation: 0.3277651420402893]
	TIME [epoch: 5.73 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3460220809431899		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.3460220809431899 | validation: 0.32955560322871363]
	TIME [epoch: 5.73 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34175984053763514		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.34175984053763514 | validation: 0.3307158276226879]
	TIME [epoch: 5.72 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.344930191186555		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.344930191186555 | validation: 0.3142428175596201]
	TIME [epoch: 5.73 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34505136356021526		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.34505136356021526 | validation: 0.31959872000166195]
	TIME [epoch: 5.79 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3426296666245729		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.3426296666245729 | validation: 0.30920293153497447]
	TIME [epoch: 5.75 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447106720197301		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.3447106720197301 | validation: 0.3154379223088721]
	TIME [epoch: 5.75 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3429948438176912		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.3429948438176912 | validation: 0.3230396690512989]
	TIME [epoch: 5.73 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3441825871256654		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.3441825871256654 | validation: 0.32987884190734834]
	TIME [epoch: 5.73 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.342311327621192		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.342311327621192 | validation: 0.3156442677961942]
	TIME [epoch: 5.73 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3429689144127514		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.3429689144127514 | validation: 0.3110396196665947]
	TIME [epoch: 5.75 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468428291507948		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.3468428291507948 | validation: 0.3223670836795283]
	TIME [epoch: 5.74 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34458679835701533		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.34458679835701533 | validation: 0.32770412663964366]
	TIME [epoch: 5.73 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.344854681747617		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.344854681747617 | validation: 0.31253290367306974]
	TIME [epoch: 5.73 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34452245051074937		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.34452245051074937 | validation: 0.31555777211990044]
	TIME [epoch: 5.73 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34190260989227506		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.34190260989227506 | validation: 0.3274814438416596]
	TIME [epoch: 5.73 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461161405292335		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.3461161405292335 | validation: 0.32390891429551943]
	TIME [epoch: 5.74 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3430887508729044		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.3430887508729044 | validation: 0.31592529116701]
	TIME [epoch: 5.76 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3424135267191136		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.3424135267191136 | validation: 0.3250219367229459]
	TIME [epoch: 5.75 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3469873804216492		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.3469873804216492 | validation: 0.3152535763075603]
	TIME [epoch: 5.73 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442301066594979		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.3442301066594979 | validation: 0.31426713534635026]
	TIME [epoch: 5.75 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3455270241703703		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.3455270241703703 | validation: 0.3292903825552728]
	TIME [epoch: 5.73 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3434777253373593		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.3434777253373593 | validation: 0.3242044749518015]
	TIME [epoch: 5.75 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34468196064887624		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.34468196064887624 | validation: 0.31546492975350726]
	TIME [epoch: 5.79 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34304956635545747		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.34304956635545747 | validation: 0.33245497026485465]
	TIME [epoch: 5.75 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436121564095589		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.3436121564095589 | validation: 0.329673962782407]
	TIME [epoch: 5.75 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3441875796367527		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.3441875796367527 | validation: 0.337533863656179]
	TIME [epoch: 5.72 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3457936708750552		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.3457936708750552 | validation: 0.3457452162966195]
	TIME [epoch: 5.72 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34822780092178246		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.34822780092178246 | validation: 0.334426859075273]
	TIME [epoch: 5.73 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34413781710513647		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.34413781710513647 | validation: 0.33082835993264453]
	TIME [epoch: 5.74 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34576779925844714		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.34576779925844714 | validation: 0.33487685393205097]
	TIME [epoch: 5.76 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3410327974453609		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.3410327974453609 | validation: 0.32440787550467526]
	TIME [epoch: 5.73 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442219584384802		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.3442219584384802 | validation: 0.3259533767928351]
	TIME [epoch: 5.73 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442560190038675		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.3442560190038675 | validation: 0.33483589605429276]
	TIME [epoch: 5.73 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435676093034016		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.3435676093034016 | validation: 0.3320130844887551]
	TIME [epoch: 5.72 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34589141833991593		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.34589141833991593 | validation: 0.33528253200072294]
	TIME [epoch: 5.73 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3456406553774396		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.3456406553774396 | validation: 0.32321323877973046]
	TIME [epoch: 5.77 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3414505448083439		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.3414505448083439 | validation: 0.3339424047397029]
	TIME [epoch: 5.73 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3499244140933753		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.3499244140933753 | validation: 0.3137513297838614]
	TIME [epoch: 5.73 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468926343598346		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.3468926343598346 | validation: 0.3259160113999055]
	TIME [epoch: 5.73 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34438556505846935		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.34438556505846935 | validation: 0.31752933677490697]
	TIME [epoch: 5.73 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34690219351188345		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.34690219351188345 | validation: 0.32079185400289434]
	TIME [epoch: 5.73 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436319608312588		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.3436319608312588 | validation: 0.3230391606566982]
	TIME [epoch: 5.74 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34164389695051833		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.34164389695051833 | validation: 0.32209990479244455]
	TIME [epoch: 5.77 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34598933219986405		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.34598933219986405 | validation: 0.3292094612450474]
	TIME [epoch: 5.73 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435270462868111		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.3435270462868111 | validation: 0.33659114461276746]
	TIME [epoch: 5.73 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3415066054332819		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.3415066054332819 | validation: 0.3182873858103804]
	TIME [epoch: 5.73 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34699655499310433		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.34699655499310433 | validation: 0.3299130376341268]
	TIME [epoch: 5.73 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34136955784945616		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.34136955784945616 | validation: 0.3171799688119061]
	TIME [epoch: 5.73 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3403389734871054		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.3403389734871054 | validation: 0.30944458159484484]
	TIME [epoch: 5.77 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3438623708749765		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.3438623708749765 | validation: 0.320083144495929]
	TIME [epoch: 5.73 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3429267286434541		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.3429267286434541 | validation: 0.32759491745098507]
	TIME [epoch: 5.73 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439779094155611		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.3439779094155611 | validation: 0.32385257888957236]
	TIME [epoch: 5.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34198321263155584		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.34198321263155584 | validation: 0.31923312071298987]
	TIME [epoch: 5.73 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3413687184793246		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.3413687184793246 | validation: 0.3237762674219073]
	TIME [epoch: 5.72 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3402693699986752		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.3402693699986752 | validation: 0.32447001497570455]
	TIME [epoch: 5.75 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34089089538190037		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.34089089538190037 | validation: 0.3185546483157768]
	TIME [epoch: 5.74 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34289754587272275		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.34289754587272275 | validation: 0.33079080764493834]
	TIME [epoch: 5.73 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3419773865895034		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.3419773865895034 | validation: 0.32430358547351384]
	TIME [epoch: 5.73 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3477148052953744		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.3477148052953744 | validation: 0.3268926843460106]
	TIME [epoch: 5.74 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33947891533999486		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.33947891533999486 | validation: 0.3208713989236399]
	TIME [epoch: 5.75 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435194878206071		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.3435194878206071 | validation: 0.31874708828873155]
	TIME [epoch: 5.75 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439658301806372		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.3439658301806372 | validation: 0.328539469852191]
	TIME [epoch: 5.79 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34193699517670073		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.34193699517670073 | validation: 0.3196152205582288]
	TIME [epoch: 5.75 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34638597798807486		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.34638597798807486 | validation: 0.331710817343687]
	TIME [epoch: 5.75 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34468831666165267		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.34468831666165267 | validation: 0.3353082580484012]
	TIME [epoch: 5.75 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34226280790811886		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.34226280790811886 | validation: 0.32713508105620925]
	TIME [epoch: 5.75 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442333416739297		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.3442333416739297 | validation: 0.3171007848953964]
	TIME [epoch: 5.74 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3445789036971233		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.3445789036971233 | validation: 0.31838223351735734]
	TIME [epoch: 5.77 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3448785503238392		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.3448785503238392 | validation: 0.3214643147985096]
	TIME [epoch: 5.76 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34320548283185215		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.34320548283185215 | validation: 0.3182071708400622]
	TIME [epoch: 5.75 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3423425663404517		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.3423425663404517 | validation: 0.32015910496907696]
	TIME [epoch: 5.75 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34198714999356283		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.34198714999356283 | validation: 0.31965891732903756]
	TIME [epoch: 5.74 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3414148912334778		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.3414148912334778 | validation: 0.31787059786952127]
	TIME [epoch: 5.74 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440501206193157		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.3440501206193157 | validation: 0.3208587654770119]
	TIME [epoch: 5.75 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34727853722298385		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.34727853722298385 | validation: 0.315452057509764]
	TIME [epoch: 5.79 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.343218064195465		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.343218064195465 | validation: 0.32360664111720966]
	TIME [epoch: 5.75 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34326634075504375		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.34326634075504375 | validation: 0.31023902377339513]
	TIME [epoch: 5.75 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34472510546404733		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.34472510546404733 | validation: 0.30783277247313146]
	TIME [epoch: 5.75 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34056733984565374		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.34056733984565374 | validation: 0.3138881588142789]
	TIME [epoch: 5.74 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3446593702938961		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.3446593702938961 | validation: 0.31600059980443673]
	TIME [epoch: 5.75 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472588842385472		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.3472588842385472 | validation: 0.32965306165826513]
	TIME [epoch: 5.79 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34346957035037956		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.34346957035037956 | validation: 0.3263096075658839]
	TIME [epoch: 5.75 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475437591875702		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.3475437591875702 | validation: 0.32019813409610787]
	TIME [epoch: 5.75 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3474120750796001		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.3474120750796001 | validation: 0.33195440214543953]
	TIME [epoch: 5.74 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34372989564469253		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.34372989564469253 | validation: 0.32667630902566236]
	TIME [epoch: 5.75 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412838099215761		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.3412838099215761 | validation: 0.31962815827115443]
	TIME [epoch: 5.75 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34613466893735656		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.34613466893735656 | validation: 0.3236268015279983]
	TIME [epoch: 5.76 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439891660066144		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.3439891660066144 | validation: 0.3239509311069601]
	TIME [epoch: 5.78 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454214597216591		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.3454214597216591 | validation: 0.3382813046013506]
	TIME [epoch: 5.75 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34731111746795684		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.34731111746795684 | validation: 0.32197223014010573]
	TIME [epoch: 5.74 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34125462761611064		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.34125462761611064 | validation: 0.3165502322576001]
	TIME [epoch: 5.75 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3474946505032156		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.3474946505032156 | validation: 0.329064686010222]
	TIME [epoch: 5.75 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3408994048250085		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.3408994048250085 | validation: 0.3246396860044191]
	TIME [epoch: 5.73 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3452046637044194		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.3452046637044194 | validation: 0.3293641753249306]
	TIME [epoch: 5.79 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3466592846144474		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.3466592846144474 | validation: 0.3202123332753513]
	TIME [epoch: 5.75 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34217426952233937		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.34217426952233937 | validation: 0.32489024226159785]
	TIME [epoch: 5.74 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34141431952707685		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.34141431952707685 | validation: 0.32224195291978475]
	TIME [epoch: 5.73 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3427578745608042		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.3427578745608042 | validation: 0.31642860029350445]
	TIME [epoch: 5.72 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436517488932005		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.3436517488932005 | validation: 0.3171307949767702]
	TIME [epoch: 5.73 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3426374204670999		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.3426374204670999 | validation: 0.3195335639184615]
	TIME [epoch: 5.74 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3427101050735704		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.3427101050735704 | validation: 0.32562735334271153]
	TIME [epoch: 5.76 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442558524255718		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.3442558524255718 | validation: 0.3167305180726856]
	TIME [epoch: 5.73 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34393445466439915		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.34393445466439915 | validation: 0.3228607946700931]
	TIME [epoch: 5.73 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454186915810796		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.3454186915810796 | validation: 0.3248767628166209]
	TIME [epoch: 5.72 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34197997278584213		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.34197997278584213 | validation: 0.31535738294389754]
	TIME [epoch: 5.72 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33949208845452983		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.33949208845452983 | validation: 0.320695274373665]
	TIME [epoch: 5.72 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3426477342838518		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.3426477342838518 | validation: 0.3182588921997567]
	TIME [epoch: 5.76 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34329962039950507		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.34329962039950507 | validation: 0.3246310074070049]
	TIME [epoch: 5.73 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34535887782267116		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.34535887782267116 | validation: 0.31646316218420206]
	TIME [epoch: 5.72 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34321210467825236		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.34321210467825236 | validation: 0.3237459813608634]
	TIME [epoch: 5.73 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34361442805809267		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.34361442805809267 | validation: 0.32227010051182203]
	TIME [epoch: 5.72 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3422634933562134		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.3422634933562134 | validation: 0.3305635889992278]
	TIME [epoch: 5.72 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3430675511713368		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.3430675511713368 | validation: 0.32796704129321624]
	TIME [epoch: 5.74 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34228054971906063		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.34228054971906063 | validation: 0.3265823862144843]
	TIME [epoch: 5.73 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3492578765848925		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.3492578765848925 | validation: 0.3111266570702428]
	TIME [epoch: 5.71 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447215496354794		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.3447215496354794 | validation: 0.3164649402173105]
	TIME [epoch: 5.71 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34308133553711695		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.34308133553711695 | validation: 0.31887412426342343]
	TIME [epoch: 5.72 sec]
Finished training in 11706.896 seconds.
