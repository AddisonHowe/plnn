Args:
Namespace(name='model_tr_study202', outdir='out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3', training_data='data/transition_rate_studies/tr_study202/tr_study202_training/r3', validation_data='data/transition_rate_studies/tr_study202/tr_study202_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3110265083

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.015584337819279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.015584337819279 | validation: 12.727824831191159]
	TIME [epoch: 94.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.915354879215318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.915354879215318 | validation: 11.810858083062682]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.433031832331691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.433031832331691 | validation: 10.117708813180677]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.360957126880878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.360957126880878 | validation: 9.41681693256734]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.12182240204466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.12182240204466 | validation: 10.186493702468816]
	TIME [epoch: 5.76 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.272309664774564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.272309664774564 | validation: 7.026574642338919]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.935316032929545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.935316032929545 | validation: 7.799633853745379]
	TIME [epoch: 5.75 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.675257130444818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.675257130444818 | validation: 6.498025452812246]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.857731199286102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.857731199286102 | validation: 6.447101346232536]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.607226052429381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.607226052429381 | validation: 4.32875435237611]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.984696222031226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.984696222031226 | validation: 4.411010910171208]
	TIME [epoch: 5.79 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.842329229149389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.842329229149389 | validation: 4.63325658093882]
	TIME [epoch: 5.76 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.776159950159657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.776159950159657 | validation: 4.477145562941237]
	TIME [epoch: 5.74 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2452965986916364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2452965986916364 | validation: 4.128202320007907]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.803309756668128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.803309756668128 | validation: 4.175365900859941]
	TIME [epoch: 5.75 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.765695682083838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.765695682083838 | validation: 4.650241380669363]
	TIME [epoch: 5.75 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.78626986421057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.78626986421057 | validation: 4.1780553300241525]
	TIME [epoch: 5.78 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.286962527280819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.286962527280819 | validation: 4.915758958018647]
	TIME [epoch: 5.77 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.502192127678123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.502192127678123 | validation: 5.955363651253244]
	TIME [epoch: 5.76 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.78789981290546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.78789981290546 | validation: 4.204751578426996]
	TIME [epoch: 5.75 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2740271554911216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2740271554911216 | validation: 4.067548432530022]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.545788836546808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.545788836546808 | validation: 3.9521098245006567]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.782449197031312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.782449197031312 | validation: 4.394456744673002]
	TIME [epoch: 5.76 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.585769219945711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.585769219945711 | validation: 3.893800006905964]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.198934286865137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.198934286865137 | validation: 5.673166507854696]
	TIME [epoch: 5.74 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452916650479851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.452916650479851 | validation: 4.053159816981739]
	TIME [epoch: 5.75 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.211686218355955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.211686218355955 | validation: 4.046916855185772]
	TIME [epoch: 5.74 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.056819816633847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.056819816633847 | validation: 3.8557326704444246]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.994878469508256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.994878469508256 | validation: 4.570472166091028]
	TIME [epoch: 5.74 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8988705802049086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8988705802049086 | validation: 4.524044572669673]
	TIME [epoch: 5.75 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.267243779107579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.267243779107579 | validation: 4.186085954304097]
	TIME [epoch: 5.77 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7399359699941095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7399359699941095 | validation: 4.324138143158712]
	TIME [epoch: 5.76 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.985263650105485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.985263650105485 | validation: 3.3442017874562326]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8404263073205107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8404263073205107 | validation: 3.8337236585037493]
	TIME [epoch: 5.75 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7070488752647988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7070488752647988 | validation: 3.2084639048416115]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3887692646247976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3887692646247976 | validation: 4.227843002692183]
	TIME [epoch: 5.75 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39809783878139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.39809783878139 | validation: 3.7037885275935767]
	TIME [epoch: 5.79 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.574637190828945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.574637190828945 | validation: 3.5988937618176573]
	TIME [epoch: 5.75 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7546605071345973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7546605071345973 | validation: 3.5087596481028753]
	TIME [epoch: 5.75 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1462592660759245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1462592660759245 | validation: 3.398196924451057]
	TIME [epoch: 5.74 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2699754132731496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2699754132731496 | validation: 3.4289015329043413]
	TIME [epoch: 5.74 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.139453617753462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.139453617753462 | validation: 3.1735028497065727]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7352325974295155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7352325974295155 | validation: 4.34778846587464]
	TIME [epoch: 5.75 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4709978779255524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4709978779255524 | validation: 3.622082598725952]
	TIME [epoch: 5.78 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1931937178923033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1931937178923033 | validation: 3.0918865232576396]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0984237369213017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0984237369213017 | validation: 2.72525806958112]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6984987518253893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6984987518253893 | validation: 3.036771328896045]
	TIME [epoch: 5.75 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.945303843060509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.945303843060509 | validation: 3.5777845460345357]
	TIME [epoch: 5.76 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9691147669765425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9691147669765425 | validation: 2.773343561337796]
	TIME [epoch: 5.75 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8496842133276887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8496842133276887 | validation: 2.706511728669878]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.621046228171759		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.621046228171759 | validation: 2.8023616424639877]
	TIME [epoch: 5.79 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6209012361281303		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.6209012361281303 | validation: 3.285826827699126]
	TIME [epoch: 5.76 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.063942358703788		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.063942358703788 | validation: 2.922968564729844]
	TIME [epoch: 5.76 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9797280130519472		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.9797280130519472 | validation: 2.510998567065358]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.405749096489987		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.405749096489987 | validation: 2.6692987134096087]
	TIME [epoch: 5.76 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.556487559327118		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.556487559327118 | validation: 2.8656155429994072]
	TIME [epoch: 5.75 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.503858330786948		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.503858330786948 | validation: 2.6990487533752723]
	TIME [epoch: 5.79 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4093200765400695		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.4093200765400695 | validation: 2.8634031923179752]
	TIME [epoch: 5.77 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801741470542463		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.801741470542463 | validation: 3.4456937639757372]
	TIME [epoch: 5.76 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6401629855260023		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.6401629855260023 | validation: 2.1405095238269074]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1576175787322978		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.1576175787322978 | validation: 2.852683915669537]
	TIME [epoch: 5.76 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3909101962891843		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.3909101962891843 | validation: 2.1778998769690467]
	TIME [epoch: 5.75 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2547220007829307		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.2547220007829307 | validation: 2.419425628718828]
	TIME [epoch: 5.75 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3475874399909733		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.3475874399909733 | validation: 2.158548098838977]
	TIME [epoch: 5.78 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2584897062931457		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.2584897062931457 | validation: 2.4112192021389007]
	TIME [epoch: 5.75 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2371391411204153		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.2371391411204153 | validation: 2.4047494189421377]
	TIME [epoch: 5.75 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3642358660390848		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.3642358660390848 | validation: 2.7958310320302737]
	TIME [epoch: 5.75 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3519637925441055		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.3519637925441055 | validation: 2.0618996127217377]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.171296763767601		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.171296763767601 | validation: 2.04496760226186]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1181562126990343		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.1181562126990343 | validation: 2.0835098091124626]
	TIME [epoch: 5.79 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.177545220357435		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.177545220357435 | validation: 1.8246430258375619]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0309967535240387		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.0309967535240387 | validation: 1.9031465707143056]
	TIME [epoch: 5.75 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0470047349773846		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.0470047349773846 | validation: 2.1959386784463883]
	TIME [epoch: 5.75 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.121388075848931		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.121388075848931 | validation: 1.8821158280251917]
	TIME [epoch: 5.74 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9253907644055754		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.9253907644055754 | validation: 2.1305188001036512]
	TIME [epoch: 5.75 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1470941588521817		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.1470941588521817 | validation: 1.6614744410277877]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0883114669157683		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.0883114669157683 | validation: 1.9717838411696853]
	TIME [epoch: 5.76 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.901536530484031		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.901536530484031 | validation: 1.6831700340120392]
	TIME [epoch: 5.75 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8481959297992812		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.8481959297992812 | validation: 2.0796884945793788]
	TIME [epoch: 5.75 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057501044102967		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.057501044102967 | validation: 2.0011267528203205]
	TIME [epoch: 5.76 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8714098907496748		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.8714098907496748 | validation: 1.7611175012417426]
	TIME [epoch: 5.75 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.709495113686636		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.709495113686636 | validation: 1.7981708301609265]
	TIME [epoch: 5.76 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6909326970296632		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.6909326970296632 | validation: 2.100759618597144]
	TIME [epoch: 5.79 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8908436886863698		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.8908436886863698 | validation: 1.645984063056792]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7835905214013439		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.7835905214013439 | validation: 2.3042733664815422]
	TIME [epoch: 5.76 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0040354760295926		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.0040354760295926 | validation: 1.4799687482506736]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.587189906065482		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.587189906065482 | validation: 1.4513643016929216]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5728408667761393		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.5728408667761393 | validation: 1.9668536372161078]
	TIME [epoch: 5.75 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.731506427846394		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.731506427846394 | validation: 1.716411416330559]
	TIME [epoch: 5.79 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.691400396969935		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.691400396969935 | validation: 2.8656512438183075]
	TIME [epoch: 5.75 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.970110692034338		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.970110692034338 | validation: 1.5989863068947938]
	TIME [epoch: 5.76 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8177523517849237		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.8177523517849237 | validation: 2.2750196682415953]
	TIME [epoch: 5.76 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7495379584468123		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.7495379584468123 | validation: 1.3858067925162962]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5660746395702436		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.5660746395702436 | validation: 1.6646988261458306]
	TIME [epoch: 5.76 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6273467607481038		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.6273467607481038 | validation: 1.4614985820778106]
	TIME [epoch: 5.78 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.450254172477113		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.450254172477113 | validation: 1.210031135537819]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3879614378056147		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.3879614378056147 | validation: 1.3510390888630617]
	TIME [epoch: 5.77 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3743634734793277		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.3743634734793277 | validation: 1.4287652631333865]
	TIME [epoch: 5.76 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.375122953602756		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.375122953602756 | validation: 1.6159382254993329]
	TIME [epoch: 5.76 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5106643950491214		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.5106643950491214 | validation: 1.5068631454993422]
	TIME [epoch: 5.76 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4205046874711234		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.4205046874711234 | validation: 1.609740342712588]
	TIME [epoch: 5.76 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6273100436511		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.6273100436511 | validation: 1.8135832605473081]
	TIME [epoch: 5.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4077784657575818		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.4077784657575818 | validation: 1.6531259707315524]
	TIME [epoch: 5.76 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3906457624068285		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.3906457624068285 | validation: 1.3964160167558306]
	TIME [epoch: 5.76 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4366373255695677		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.4366373255695677 | validation: 1.1792953911289976]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3451823928190985		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.3451823928190985 | validation: 1.6718952029756975]
	TIME [epoch: 5.76 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3842018712753217		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.3842018712753217 | validation: 1.3295241091382832]
	TIME [epoch: 5.76 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.32863994579494		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.32863994579494 | validation: 1.2031867622577037]
	TIME [epoch: 5.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3786092148435622		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.3786092148435622 | validation: 1.298758668032134]
	TIME [epoch: 5.76 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4777238351238484		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.4777238351238484 | validation: 1.1704991572722592]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.157828343837361		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.157828343837361 | validation: 2.015451294128796]
	TIME [epoch: 5.76 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6118510266384203		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.6118510266384203 | validation: 1.203833075042806]
	TIME [epoch: 5.76 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2596255447089117		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.2596255447089117 | validation: 1.5291020078255764]
	TIME [epoch: 5.76 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2419388156272029		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.2419388156272029 | validation: 1.136201797493807]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3693037053963795		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.3693037053963795 | validation: 1.2201569274391633]
	TIME [epoch: 5.79 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1610926248890046		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.1610926248890046 | validation: 1.2127466531075854]
	TIME [epoch: 5.76 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.159280543205705		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.159280543205705 | validation: 1.1142346168546124]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2709728165871073		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.2709728165871073 | validation: 1.4621558765194962]
	TIME [epoch: 5.76 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2107933412421619		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.2107933412421619 | validation: 1.0148668249028228]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2528467024742735		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.2528467024742735 | validation: 1.0034365321124252]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0037521032457166		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.0037521032457166 | validation: 1.05395241536047]
	TIME [epoch: 5.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3401140859169636		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.3401140859169636 | validation: 1.0616812021584254]
	TIME [epoch: 5.76 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239269773261748		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.239269773261748 | validation: 0.8851146876119088]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.212774187743164		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.212774187743164 | validation: 1.0466297874266346]
	TIME [epoch: 5.76 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1289377151113602		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.1289377151113602 | validation: 1.961018089355037]
	TIME [epoch: 5.75 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4372857918847255		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.4372857918847255 | validation: 1.1867947493861268]
	TIME [epoch: 5.76 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1527654517855668		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.1527654517855668 | validation: 0.9466869182351624]
	TIME [epoch: 5.79 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9694786891152634		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.9694786891152634 | validation: 1.077859222212268]
	TIME [epoch: 5.76 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9229557759096402		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.9229557759096402 | validation: 0.8493799350296033]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9213203384732579		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.9213203384732579 | validation: 1.0310127881529234]
	TIME [epoch: 5.75 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1113977969769704		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.1113977969769704 | validation: 0.7711665903606482]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9661316581541205		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.9661316581541205 | validation: 1.0432211929187134]
	TIME [epoch: 5.75 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1847198301207718		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.1847198301207718 | validation: 1.7395194683620137]
	TIME [epoch: 5.78 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1779692420917984		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.1779692420917984 | validation: 1.483022403862733]
	TIME [epoch: 5.78 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0823204735182315		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.0823204735182315 | validation: 0.8940400936968703]
	TIME [epoch: 5.76 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9394880955897236		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.9394880955897236 | validation: 0.83311161253917]
	TIME [epoch: 5.76 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7935306100125826		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.7935306100125826 | validation: 1.308408576601747]
	TIME [epoch: 5.76 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9745656013416673		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.9745656013416673 | validation: 0.8887827149201478]
	TIME [epoch: 5.76 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7974579135789122		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.7974579135789122 | validation: 0.9548778960177958]
	TIME [epoch: 5.76 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9083958343170621		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.9083958343170621 | validation: 0.9068979087393099]
	TIME [epoch: 5.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9198542555463999		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.9198542555463999 | validation: 1.3602739922559182]
	TIME [epoch: 5.76 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9094902820996279		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.9094902820996279 | validation: 0.9033582782420757]
	TIME [epoch: 5.75 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9337959347684177		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.9337959347684177 | validation: 0.7503439157294952]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9005303709961131		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.9005303709961131 | validation: 0.9973157501136816]
	TIME [epoch: 5.75 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9248702011742806		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.9248702011742806 | validation: 0.6140751991775941]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9268082249886311		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.9268082249886311 | validation: 0.9334055731650164]
	TIME [epoch: 5.78 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9396113419203205		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.9396113419203205 | validation: 0.7893423104537922]
	TIME [epoch: 5.75 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8169107635461982		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.8169107635461982 | validation: 1.1426262001970502]
	TIME [epoch: 5.74 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9410615323778037		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.9410615323778037 | validation: 0.9192617834307687]
	TIME [epoch: 5.74 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7945492811088163		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.7945492811088163 | validation: 0.9010227280365676]
	TIME [epoch: 5.74 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.917975685134099		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.917975685134099 | validation: 0.7212840900349455]
	TIME [epoch: 5.74 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463387235885687		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.6463387235885687 | validation: 1.0003941308716835]
	TIME [epoch: 5.75 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.003021897926811		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.003021897926811 | validation: 0.6695163507091492]
	TIME [epoch: 5.77 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7581504551692273		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.7581504551692273 | validation: 0.8457473446056105]
	TIME [epoch: 5.74 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8620570649084746		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.8620570649084746 | validation: 0.7196204365469353]
	TIME [epoch: 5.74 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1796966691117308		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.1796966691117308 | validation: 0.7123094801413672]
	TIME [epoch: 5.74 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249530683779895		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.0249530683779895 | validation: 1.0405033143032951]
	TIME [epoch: 5.74 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8520630570177915		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.8520630570177915 | validation: 0.7250092492062546]
	TIME [epoch: 5.74 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.820761743396355		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.820761743396355 | validation: 1.5052869936660471]
	TIME [epoch: 5.78 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0908492640257923		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.0908492640257923 | validation: 0.8625339846139087]
	TIME [epoch: 5.74 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8523618519120164		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.8523618519120164 | validation: 0.6920913709548353]
	TIME [epoch: 5.74 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209467596247641		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.7209467596247641 | validation: 0.6605877764123125]
	TIME [epoch: 5.74 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8622177280162642		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.8622177280162642 | validation: 0.7914867648714821]
	TIME [epoch: 5.74 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8483280994330993		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.8483280994330993 | validation: 1.0305588913395354]
	TIME [epoch: 5.74 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8986077193154007		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.8986077193154007 | validation: 0.8959170053457094]
	TIME [epoch: 5.75 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719461192287771		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.719461192287771 | validation: 0.8145694120713105]
	TIME [epoch: 5.77 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7554066260825872		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.7554066260825872 | validation: 1.066969326199082]
	TIME [epoch: 5.74 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0697826702005182		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.0697826702005182 | validation: 0.7081120703439819]
	TIME [epoch: 5.74 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6681038704014206		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.6681038704014206 | validation: 1.4229045787135035]
	TIME [epoch: 5.74 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.899545699608884		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.899545699608884 | validation: 0.8294911326054796]
	TIME [epoch: 5.75 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7881778930628464		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.7881778930628464 | validation: 1.2220393492246033]
	TIME [epoch: 5.75 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9391981479371718		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.9391981479371718 | validation: 1.0170356824524065]
	TIME [epoch: 5.79 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8245932762315293		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.8245932762315293 | validation: 0.8148187761061156]
	TIME [epoch: 5.76 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.002286575665843		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.002286575665843 | validation: 1.2671317665647388]
	TIME [epoch: 5.75 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9185137032898217		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.9185137032898217 | validation: 0.7880221746477247]
	TIME [epoch: 5.75 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699785334457708		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.699785334457708 | validation: 0.792342064241218]
	TIME [epoch: 5.75 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7428356792106778		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.7428356792106778 | validation: 0.6733750661761753]
	TIME [epoch: 5.76 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7498774730920524		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.7498774730920524 | validation: 1.4818969404472415]
	TIME [epoch: 5.76 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9287100247934634		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.9287100247934634 | validation: 0.6842728308615641]
	TIME [epoch: 5.78 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6805330594148782		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.6805330594148782 | validation: 0.5514026373602358]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7011668344863791		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.7011668344863791 | validation: 0.7113605894513384]
	TIME [epoch: 5.75 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7530976481205414		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.7530976481205414 | validation: 0.5315791667756932]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086587124439576		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.086587124439576 | validation: 0.8190350371640446]
	TIME [epoch: 5.75 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9379457611974655		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9379457611974655 | validation: 1.0088627611709895]
	TIME [epoch: 5.75 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332531492581034		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.7332531492581034 | validation: 0.5762418700604915]
	TIME [epoch: 5.79 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.728094064262891		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.728094064262891 | validation: 0.7408064771764674]
	TIME [epoch: 5.75 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8072298064737117		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.8072298064737117 | validation: 0.5922214697111483]
	TIME [epoch: 5.75 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312512012371719		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.6312512012371719 | validation: 0.53792148653149]
	TIME [epoch: 5.75 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223431282283581		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.7223431282283581 | validation: 0.5767578507723552]
	TIME [epoch: 5.74 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8955858604598419		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.8955858604598419 | validation: 0.49523669201270176]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214143465397919		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.7214143465397919 | validation: 0.7937211999621943]
	TIME [epoch: 5.77 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6550714503068982		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.6550714503068982 | validation: 0.6284226591917077]
	TIME [epoch: 5.75 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870695052848219		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.6870695052848219 | validation: 0.6230789653807877]
	TIME [epoch: 5.74 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.75447201520158		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.75447201520158 | validation: 0.7338836446818587]
	TIME [epoch: 5.74 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6388714099938864		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.6388714099938864 | validation: 0.6939012464318529]
	TIME [epoch: 5.74 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830826642761105		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.6830826642761105 | validation: 0.9463598086122081]
	TIME [epoch: 5.74 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6376289676922817		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.6376289676922817 | validation: 0.4442001674878565]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5910347035911123		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.5910347035911123 | validation: 1.2778471684992547]
	TIME [epoch: 5.78 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6711732153076945		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.6711732153076945 | validation: 0.543848288701417]
	TIME [epoch: 5.74 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7394172370464579		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.7394172370464579 | validation: 0.5674435616796702]
	TIME [epoch: 5.74 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6716070992754476		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.6716070992754476 | validation: 1.176349911375787]
	TIME [epoch: 5.74 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236384080633911		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.7236384080633911 | validation: 0.8729610271533517]
	TIME [epoch: 5.73 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9596993876084238		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.9596993876084238 | validation: 1.0007204405495722]
	TIME [epoch: 5.74 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7483659537440687		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.7483659537440687 | validation: 0.4770263202699269]
	TIME [epoch: 5.77 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857539714132238		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.6857539714132238 | validation: 0.6195643923434662]
	TIME [epoch: 5.74 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6761521772169469		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.6761521772169469 | validation: 0.51189165101646]
	TIME [epoch: 5.74 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47164859879492793		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.47164859879492793 | validation: 0.7058862743848449]
	TIME [epoch: 5.74 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5856722359751484		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.5856722359751484 | validation: 0.4794286141422552]
	TIME [epoch: 5.74 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6447614155686543		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.6447614155686543 | validation: 0.7782232283037072]
	TIME [epoch: 5.74 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6751626863440304		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.6751626863440304 | validation: 0.4763734946773972]
	TIME [epoch: 5.75 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5904385186962328		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.5904385186962328 | validation: 0.48888255441761985]
	TIME [epoch: 5.77 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49131393976213444		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.49131393976213444 | validation: 0.5970324014587756]
	TIME [epoch: 5.74 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.554683470998647		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.554683470998647 | validation: 0.7778653120145299]
	TIME [epoch: 5.74 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6413978688797839		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.6413978688797839 | validation: 0.39827158166892523]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5476399342016556		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.5476399342016556 | validation: 0.6141048252641079]
	TIME [epoch: 5.74 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5612496997922538		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.5612496997922538 | validation: 0.942793958859869]
	TIME [epoch: 5.75 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.714854058996069		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.714854058996069 | validation: 0.45423622985083717]
	TIME [epoch: 5.78 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5691464551163141		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.5691464551163141 | validation: 0.787907603855043]
	TIME [epoch: 5.75 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5644168448387878		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.5644168448387878 | validation: 0.8089907716423054]
	TIME [epoch: 5.75 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6693758965172889		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.6693758965172889 | validation: 0.49813241105306405]
	TIME [epoch: 5.75 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48176339577261407		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.48176339577261407 | validation: 0.3683015939694261]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5338229145040068		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.5338229145040068 | validation: 0.37508587484344774]
	TIME [epoch: 5.75 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5751604530508002		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.5751604530508002 | validation: 0.7268012460988444]
	TIME [epoch: 5.75 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839085389335153		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.6839085389335153 | validation: 0.5779681318781461]
	TIME [epoch: 5.77 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6070327859577827		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.6070327859577827 | validation: 0.6672281509087901]
	TIME [epoch: 5.74 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5561973757770196		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.5561973757770196 | validation: 0.6259706753730371]
	TIME [epoch: 5.75 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5111713853139633		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.5111713853139633 | validation: 0.9775859866853095]
	TIME [epoch: 5.74 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228208295110257		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.7228208295110257 | validation: 0.33444243113782945]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4182045432838135		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.4182045432838135 | validation: 0.6744376480238714]
	TIME [epoch: 5.74 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5430019220493836		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.5430019220493836 | validation: 0.44773268608595046]
	TIME [epoch: 5.79 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4963413101249845		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.4963413101249845 | validation: 0.5941942960866584]
	TIME [epoch: 5.74 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5203817343267191		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.5203817343267191 | validation: 0.8377299239707864]
	TIME [epoch: 5.75 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6935357097198922		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.6935357097198922 | validation: 1.1189127412390647]
	TIME [epoch: 5.76 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217471007490663		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.7217471007490663 | validation: 0.37544540802240656]
	TIME [epoch: 5.75 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5752392677288874		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.5752392677288874 | validation: 0.40918903752608615]
	TIME [epoch: 5.76 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707899948036469		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.4707899948036469 | validation: 0.35020414378275805]
	TIME [epoch: 5.77 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230673731081771		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.7230673731081771 | validation: 0.45995239442069397]
	TIME [epoch: 5.78 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6768290247422843		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.6768290247422843 | validation: 0.5051461504340984]
	TIME [epoch: 5.75 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.517111675774915		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.517111675774915 | validation: 0.3998297165939614]
	TIME [epoch: 5.76 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5150210722321784		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.5150210722321784 | validation: 0.36702842136833996]
	TIME [epoch: 5.75 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4537052550621867		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.4537052550621867 | validation: 1.1214711017051964]
	TIME [epoch: 5.76 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7397682909705171		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.7397682909705171 | validation: 0.39997929167988594]
	TIME [epoch: 5.75 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5440148328780446		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.5440148328780446 | validation: 0.467922080533052]
	TIME [epoch: 5.78 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4461400946540811		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.4461400946540811 | validation: 0.5621948412810472]
	TIME [epoch: 5.74 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6158298897051513		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.6158298897051513 | validation: 0.4104133795138246]
	TIME [epoch: 5.74 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6193432835164736		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.6193432835164736 | validation: 0.3477475102142338]
	TIME [epoch: 5.75 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5096251508820622		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.5096251508820622 | validation: 0.48553267519571963]
	TIME [epoch: 5.74 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4905178076646016		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.4905178076646016 | validation: 0.592252277966816]
	TIME [epoch: 5.74 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5183914187473271		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.5183914187473271 | validation: 0.4305435164411715]
	TIME [epoch: 5.76 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.714963697253356		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.714963697253356 | validation: 0.35405407557390817]
	TIME [epoch: 5.75 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44888188433263054		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.44888188433263054 | validation: 0.31909426917353856]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35602539103851916		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.35602539103851916 | validation: 0.7589069003677423]
	TIME [epoch: 5.76 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5240080272577351		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.5240080272577351 | validation: 0.7039984962415022]
	TIME [epoch: 5.75 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5422405649469657		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.5422405649469657 | validation: 0.4546786636564552]
	TIME [epoch: 5.74 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40864499142385446		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.40864499142385446 | validation: 0.3761908353883841]
	TIME [epoch: 5.74 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47298899605034833		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.47298899605034833 | validation: 0.4294576341353141]
	TIME [epoch: 5.79 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293920927148482		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.5293920927148482 | validation: 0.5571258402760846]
	TIME [epoch: 5.75 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4927913375503331		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.4927913375503331 | validation: 0.5756973534046026]
	TIME [epoch: 5.75 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6470239997595791		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.6470239997595791 | validation: 0.3113908044173765]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.53011585624492		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.53011585624492 | validation: 0.3546742268752033]
	TIME [epoch: 5.75 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4081182006067315		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.4081182006067315 | validation: 0.43740453701209164]
	TIME [epoch: 5.74 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4853586748671682		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.4853586748671682 | validation: 0.5333788332588664]
	TIME [epoch: 5.78 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4476290214941939		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.4476290214941939 | validation: 0.7252249384365144]
	TIME [epoch: 5.74 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48216257406520757		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.48216257406520757 | validation: 0.43579312503358764]
	TIME [epoch: 5.74 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4667591916244049		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.4667591916244049 | validation: 0.4529922421525599]
	TIME [epoch: 5.75 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4357106798009058		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.4357106798009058 | validation: 0.2721634042881686]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3853644637692063		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.3853644637692063 | validation: 0.44998154590233924]
	TIME [epoch: 5.74 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5148472735035201		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.5148472735035201 | validation: 0.3095992174379014]
	TIME [epoch: 5.76 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4002943403173749		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.4002943403173749 | validation: 0.31958498222564824]
	TIME [epoch: 5.78 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4124596224742092		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.4124596224742092 | validation: 0.3199421489752272]
	TIME [epoch: 5.75 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45427147317473643		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.45427147317473643 | validation: 0.5011701398118136]
	TIME [epoch: 5.75 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44877168146756946		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.44877168146756946 | validation: 0.2972800874591219]
	TIME [epoch: 5.75 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35736343259103154		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.35736343259103154 | validation: 0.3594463620905478]
	TIME [epoch: 5.76 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5064649010959202		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.5064649010959202 | validation: 0.34512609834062896]
	TIME [epoch: 5.75 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3697774891702987		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.3697774891702987 | validation: 0.3267569937451823]
	TIME [epoch: 5.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41518914791088235		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.41518914791088235 | validation: 0.25871113317984895]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_276.pth
	Model improved!!!
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3777144085256602		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.3777144085256602 | validation: 0.27491747382702175]
	TIME [epoch: 5.76 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.554268733530633		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.554268733530633 | validation: 0.8806618187438943]
	TIME [epoch: 5.75 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6590925837103851		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6590925837103851 | validation: 0.6253642301965056]
	TIME [epoch: 5.74 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45021726409609064		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.45021726409609064 | validation: 0.3868995065276837]
	TIME [epoch: 5.75 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37620789848911856		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.37620789848911856 | validation: 0.31531915677927047]
	TIME [epoch: 5.78 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42712931167035684		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.42712931167035684 | validation: 0.3980288040491962]
	TIME [epoch: 5.76 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4173376044504101		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.4173376044504101 | validation: 0.2907168652228325]
	TIME [epoch: 5.74 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5864444308190182		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.5864444308190182 | validation: 0.2948034026949315]
	TIME [epoch: 5.76 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.547871804138528		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.547871804138528 | validation: 0.324193422947334]
	TIME [epoch: 5.75 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39291734338378587		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.39291734338378587 | validation: 0.33731557572608967]
	TIME [epoch: 5.75 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574561905324523		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.3574561905324523 | validation: 0.3283662645772933]
	TIME [epoch: 5.74 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316485532188577		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.3316485532188577 | validation: 0.3810284785468905]
	TIME [epoch: 5.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41124365623307224		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.41124365623307224 | validation: 0.6567581069101612]
	TIME [epoch: 5.76 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7631332579435506		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.7631332579435506 | validation: 0.49277970220276957]
	TIME [epoch: 5.76 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3980533403204401		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.3980533403204401 | validation: 0.5454883727953801]
	TIME [epoch: 5.76 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5134953147234774		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.5134953147234774 | validation: 0.3197177176565099]
	TIME [epoch: 5.76 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3174485165979566		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.3174485165979566 | validation: 0.37528600572565857]
	TIME [epoch: 5.76 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44038822143474166		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.44038822143474166 | validation: 0.5764386171610143]
	TIME [epoch: 5.79 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5131111623361532		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.5131111623361532 | validation: 0.736364121376976]
	TIME [epoch: 5.77 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5456016526537724		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.5456016526537724 | validation: 0.44910943574094403]
	TIME [epoch: 5.76 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4607601266868512		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.4607601266868512 | validation: 0.8195178835611739]
	TIME [epoch: 5.75 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.626212431570045		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.626212431570045 | validation: 0.34028063471018527]
	TIME [epoch: 5.76 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36717643707608516		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.36717643707608516 | validation: 0.31715794308151196]
	TIME [epoch: 5.76 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3717543546772325		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.3717543546772325 | validation: 0.3370954690269113]
	TIME [epoch: 5.76 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33540540755183834		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.33540540755183834 | validation: 0.27891990273962813]
	TIME [epoch: 5.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3034318257506091		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.3034318257506091 | validation: 0.31258062432141676]
	TIME [epoch: 5.76 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998704688019471		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.2998704688019471 | validation: 0.29724412788631527]
	TIME [epoch: 5.76 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570021284086757		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.3570021284086757 | validation: 0.23959166019966446]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26563183157863823		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.26563183157863823 | validation: 0.9307254503785507]
	TIME [epoch: 5.76 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42524688339801486		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.42524688339801486 | validation: 0.35429800660787786]
	TIME [epoch: 5.74 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31387227018702296		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.31387227018702296 | validation: 0.38686784345570646]
	TIME [epoch: 5.78 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4190124570527204		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.4190124570527204 | validation: 0.3077519116927621]
	TIME [epoch: 5.74 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4667207874794752		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.4667207874794752 | validation: 0.3091430714625933]
	TIME [epoch: 5.74 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3817261594566992		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.3817261594566992 | validation: 0.22250535989492526]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2929641672618642		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.2929641672618642 | validation: 0.4235887478907933]
	TIME [epoch: 5.74 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4019825758634092		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.4019825758634092 | validation: 0.27466561884361484]
	TIME [epoch: 5.74 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34786150625964907		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.34786150625964907 | validation: 0.47534489448854933]
	TIME [epoch: 5.77 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30546571100598796		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.30546571100598796 | validation: 0.1754623513134737]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6180701300860217		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.6180701300860217 | validation: 0.35424348684217466]
	TIME [epoch: 5.75 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299916953016173		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.3299916953016173 | validation: 0.2002766019541609]
	TIME [epoch: 5.75 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3135915382342174		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.3135915382342174 | validation: 0.19795290985283076]
	TIME [epoch: 5.74 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2912868517614951		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.2912868517614951 | validation: 0.9472930741746096]
	TIME [epoch: 5.74 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5270505586309537		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.5270505586309537 | validation: 0.49841878574228277]
	TIME [epoch: 5.74 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38435604856078964		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.38435604856078964 | validation: 0.43029424968329594]
	TIME [epoch: 5.78 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31130002207058666		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.31130002207058666 | validation: 0.3965291527813318]
	TIME [epoch: 5.75 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34319941342366056		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.34319941342366056 | validation: 0.22016535212189106]
	TIME [epoch: 5.75 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3178557382862824		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.3178557382862824 | validation: 0.5190915835830194]
	TIME [epoch: 5.74 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472565207994381		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.3472565207994381 | validation: 0.22826051174118359]
	TIME [epoch: 5.74 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3555594245945827		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.3555594245945827 | validation: 0.3201070722206991]
	TIME [epoch: 5.74 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3966544500001961		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.3966544500001961 | validation: 0.16446261673368853]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_326.pth
	Model improved!!!
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435338182501869		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.3435338182501869 | validation: 0.19059161961577079]
	TIME [epoch: 5.78 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23557394062400022		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.23557394062400022 | validation: 0.6432899576020299]
	TIME [epoch: 5.76 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39563274792340625		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.39563274792340625 | validation: 0.6972096644788884]
	TIME [epoch: 5.74 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45939948156734045		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.45939948156734045 | validation: 0.6170195326128435]
	TIME [epoch: 5.74 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39347336711921577		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.39347336711921577 | validation: 0.39129704780091695]
	TIME [epoch: 5.74 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3137401238618771		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.3137401238618771 | validation: 0.5408275953803233]
	TIME [epoch: 5.74 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3823172232080122		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.3823172232080122 | validation: 0.32227187567051974]
	TIME [epoch: 5.78 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27425440475195284		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.27425440475195284 | validation: 0.4562517972576837]
	TIME [epoch: 5.75 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28621045124469546		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.28621045124469546 | validation: 0.2972122037097383]
	TIME [epoch: 5.74 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27362614215716624		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.27362614215716624 | validation: 0.15574941060756683]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996793653455171		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.2996793653455171 | validation: 0.3151559531590429]
	TIME [epoch: 5.74 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3144566876402477		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.3144566876402477 | validation: 0.15994344953188624]
	TIME [epoch: 5.76 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22851426236863884		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.22851426236863884 | validation: 0.335419001160652]
	TIME [epoch: 5.78 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34229040638371594		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.34229040638371594 | validation: 0.5735752131573344]
	TIME [epoch: 5.77 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4159696610689468		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.4159696610689468 | validation: 0.15140108754622922]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32574427793189953		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.32574427793189953 | validation: 0.31429308571683884]
	TIME [epoch: 5.74 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29302722313250984		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.29302722313250984 | validation: 0.27167696804517555]
	TIME [epoch: 5.76 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5762112031231533		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5762112031231533 | validation: 0.46754095775014626]
	TIME [epoch: 5.75 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4007911406133578		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.4007911406133578 | validation: 0.18906737099942814]
	TIME [epoch: 5.77 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2113995552668711		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.2113995552668711 | validation: 0.23194791631793835]
	TIME [epoch: 5.77 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839488625271763		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.2839488625271763 | validation: 0.2354988274359604]
	TIME [epoch: 5.74 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2621431096370441		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.2621431096370441 | validation: 0.5226424637418527]
	TIME [epoch: 5.75 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33532639594020563		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.33532639594020563 | validation: 0.34242319933390536]
	TIME [epoch: 5.75 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3153429756234176		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.3153429756234176 | validation: 0.6154131103497308]
	TIME [epoch: 5.74 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36913141281951123		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.36913141281951123 | validation: 0.42248644660007456]
	TIME [epoch: 5.75 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939937991841191		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.2939937991841191 | validation: 0.26082763771030165]
	TIME [epoch: 5.78 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22134368637184199		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.22134368637184199 | validation: 0.36836058149549333]
	TIME [epoch: 5.76 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46233378818662596		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.46233378818662596 | validation: 0.39864037504415023]
	TIME [epoch: 5.75 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2862837528046045		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.2862837528046045 | validation: 0.32128405742634913]
	TIME [epoch: 5.74 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34332358574527205		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.34332358574527205 | validation: 0.36798727962554156]
	TIME [epoch: 5.75 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3657556068339658		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.3657556068339658 | validation: 0.2798958460015554]
	TIME [epoch: 5.74 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31175031277565507		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.31175031277565507 | validation: 0.414463338491443]
	TIME [epoch: 5.77 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3053519876000842		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.3053519876000842 | validation: 0.2849495824059927]
	TIME [epoch: 5.76 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584633214954523		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.2584633214954523 | validation: 0.33153682716710087]
	TIME [epoch: 5.75 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26818544545194967		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.26818544545194967 | validation: 0.6473307289525297]
	TIME [epoch: 5.75 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4352205068420237		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.4352205068420237 | validation: 0.14081726968827293]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28673089053278444		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.28673089053278444 | validation: 0.20607307391617155]
	TIME [epoch: 5.76 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1911644647213974		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.1911644647213974 | validation: 0.13924666456206436]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4290567943231146		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.4290567943231146 | validation: 0.6224717542787641]
	TIME [epoch: 5.79 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35128130290052817		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.35128130290052817 | validation: 0.28930488532074045]
	TIME [epoch: 5.76 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26971763540764937		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.26971763540764937 | validation: 0.16621123419381117]
	TIME [epoch: 5.74 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2830070165954569		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.2830070165954569 | validation: 0.20704449962090907]
	TIME [epoch: 5.76 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24455050732196437		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.24455050732196437 | validation: 0.18677333222062154]
	TIME [epoch: 5.75 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36040844347740464		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.36040844347740464 | validation: 0.24078871300423454]
	TIME [epoch: 5.75 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307513580984863		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.3307513580984863 | validation: 0.7214947282387228]
	TIME [epoch: 5.78 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35799739599839153		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.35799739599839153 | validation: 0.31639914306690137]
	TIME [epoch: 5.77 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29344984900109633		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.29344984900109633 | validation: 0.22575684928786616]
	TIME [epoch: 5.76 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27154832438932786		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.27154832438932786 | validation: 0.3427589623391841]
	TIME [epoch: 5.74 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28788891707268893		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.28788891707268893 | validation: 0.14830560701320322]
	TIME [epoch: 5.74 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4459180209655263		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.4459180209655263 | validation: 0.19387019111653309]
	TIME [epoch: 5.74 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29962263890621466		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.29962263890621466 | validation: 0.3346263426409665]
	TIME [epoch: 5.74 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331286305016416		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.331286305016416 | validation: 0.17860956568667505]
	TIME [epoch: 5.78 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38277110525430114		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.38277110525430114 | validation: 0.3410442543722824]
	TIME [epoch: 5.75 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2600470913852888		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.2600470913852888 | validation: 0.25574259501035956]
	TIME [epoch: 5.74 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789260490119302		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.2789260490119302 | validation: 0.22102490395858163]
	TIME [epoch: 5.75 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26092612686016725		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.26092612686016725 | validation: 0.2228651118577376]
	TIME [epoch: 5.74 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3018348435579571		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.3018348435579571 | validation: 0.2885534646316224]
	TIME [epoch: 5.74 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21335321010895614		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.21335321010895614 | validation: 0.14470443125417684]
	TIME [epoch: 5.77 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23416386306501813		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.23416386306501813 | validation: 0.363286287601176]
	TIME [epoch: 5.76 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28584573568314364		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.28584573568314364 | validation: 0.41216047586883564]
	TIME [epoch: 5.74 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27654806133804527		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.27654806133804527 | validation: 0.4438165938268421]
	TIME [epoch: 5.74 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2955831954671502		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.2955831954671502 | validation: 0.5345559863937409]
	TIME [epoch: 5.74 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3217471117159841		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.3217471117159841 | validation: 0.1816352595426076]
	TIME [epoch: 5.75 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34265653622456416		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.34265653622456416 | validation: 0.21585303976252473]
	TIME [epoch: 5.74 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2336874984224771		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.2336874984224771 | validation: 0.41821477874419927]
	TIME [epoch: 5.79 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31602032180921646		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.31602032180921646 | validation: 0.2181312639378374]
	TIME [epoch: 5.74 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802183784056412		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.2802183784056412 | validation: 0.1889710435666334]
	TIME [epoch: 5.75 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29937728241701556		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.29937728241701556 | validation: 0.15096019542645714]
	TIME [epoch: 5.74 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2786401518304945		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.2786401518304945 | validation: 0.18990481256307434]
	TIME [epoch: 5.74 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21987396468245665		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.21987396468245665 | validation: 0.4015869197904176]
	TIME [epoch: 5.74 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20873868926564704		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.20873868926564704 | validation: 0.10762886031956143]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18596503843979797		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.18596503843979797 | validation: 0.32119133476551115]
	TIME [epoch: 5.78 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3145753767321636		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.3145753767321636 | validation: 0.13644063786516314]
	TIME [epoch: 5.74 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32833426564893986		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.32833426564893986 | validation: 0.46371334929590113]
	TIME [epoch: 5.74 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31324966618558137		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.31324966618558137 | validation: 0.6574127764666688]
	TIME [epoch: 5.74 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32280931788096606		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.32280931788096606 | validation: 0.17675887259257322]
	TIME [epoch: 5.74 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22033008642643623		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.22033008642643623 | validation: 0.21276842473091243]
	TIME [epoch: 5.74 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19838986555441138		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.19838986555441138 | validation: 0.1933502057768709]
	TIME [epoch: 5.78 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21836357915189547		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.21836357915189547 | validation: 0.66841697452756]
	TIME [epoch: 5.74 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33491409031501657		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.33491409031501657 | validation: 0.19317064748002463]
	TIME [epoch: 5.74 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2616657026070436		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.2616657026070436 | validation: 0.3373081408349368]
	TIME [epoch: 5.74 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26609840223998804		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.26609840223998804 | validation: 0.4307402546927165]
	TIME [epoch: 5.74 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2657422022326151		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.2657422022326151 | validation: 0.2111117763389462]
	TIME [epoch: 5.74 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19731918214705169		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.19731918214705169 | validation: 0.16074852515800836]
	TIME [epoch: 5.77 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17942058911635062		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.17942058911635062 | validation: 0.19055929855349354]
	TIME [epoch: 5.75 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22412118661284575		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.22412118661284575 | validation: 0.2071526949870557]
	TIME [epoch: 5.74 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24537122408165474		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.24537122408165474 | validation: 0.361084856667186]
	TIME [epoch: 5.74 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878568813144846		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.2878568813144846 | validation: 0.21987689856478512]
	TIME [epoch: 5.74 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.323810013032623		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.323810013032623 | validation: 0.1367114041774385]
	TIME [epoch: 5.74 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21370373372908236		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.21370373372908236 | validation: 0.12763079237100353]
	TIME [epoch: 5.74 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1980048243905452		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.1980048243905452 | validation: 0.1623584091588212]
	TIME [epoch: 5.78 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2963326998530294		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.2963326998530294 | validation: 0.4964034071898668]
	TIME [epoch: 5.75 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29265633242789074		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.29265633242789074 | validation: 0.15888685949231246]
	TIME [epoch: 5.74 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16420063000014515		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.16420063000014515 | validation: 0.24948728465711256]
	TIME [epoch: 5.74 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19210288404537237		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.19210288404537237 | validation: 0.16691930382671857]
	TIME [epoch: 5.74 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19657640783092872		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.19657640783092872 | validation: 0.19208211686516258]
	TIME [epoch: 5.74 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21763967181333438		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.21763967181333438 | validation: 0.6862457975812507]
	TIME [epoch: 5.77 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35951748345401513		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.35951748345401513 | validation: 0.22830908033766784]
	TIME [epoch: 5.76 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23445384053849994		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.23445384053849994 | validation: 0.16609584746443304]
	TIME [epoch: 5.75 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2098025987845188		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.2098025987845188 | validation: 0.17320649771212915]
	TIME [epoch: 5.74 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23918516254392386		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.23918516254392386 | validation: 0.23072107410008846]
	TIME [epoch: 5.74 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2173091014776998		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.2173091014776998 | validation: 0.3097246361312795]
	TIME [epoch: 5.74 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17534216262884575		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.17534216262884575 | validation: 0.16438789910152085]
	TIME [epoch: 5.74 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21269225079492954		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.21269225079492954 | validation: 0.36083210088433626]
	TIME [epoch: 5.78 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2824138745145832		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.2824138745145832 | validation: 0.24690883868957575]
	TIME [epoch: 5.74 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2157376812340373		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.2157376812340373 | validation: 0.16623851010658464]
	TIME [epoch: 5.74 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2960258392363575		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.2960258392363575 | validation: 0.2943078970685934]
	TIME [epoch: 5.74 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3112991817481137		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.3112991817481137 | validation: 0.23285158924733776]
	TIME [epoch: 5.74 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18348018913109646		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.18348018913109646 | validation: 0.35154899546343926]
	TIME [epoch: 5.74 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686986916634408		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.2686986916634408 | validation: 0.47653774122769393]
	TIME [epoch: 5.77 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27344034742420054		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.27344034742420054 | validation: 0.332514226794329]
	TIME [epoch: 5.76 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2556447212687877		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.2556447212687877 | validation: 0.485668380613059]
	TIME [epoch: 5.75 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27878090864084193		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.27878090864084193 | validation: 0.1386223491792339]
	TIME [epoch: 5.74 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23796761845989003		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.23796761845989003 | validation: 0.09109548501169566]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2444736034191014		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.2444736034191014 | validation: 0.24115092461683663]
	TIME [epoch: 5.74 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21011369316400733		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.21011369316400733 | validation: 0.4745001918764844]
	TIME [epoch: 5.76 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2604985973825065		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.2604985973825065 | validation: 0.21624551298443095]
	TIME [epoch: 5.77 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918891003526338		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.3918891003526338 | validation: 0.18246690356155235]
	TIME [epoch: 5.73 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2636201502089383		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.2636201502089383 | validation: 0.14971197156182306]
	TIME [epoch: 5.75 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854907967012169		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.1854907967012169 | validation: 0.18265713320521293]
	TIME [epoch: 5.75 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21305881186648953		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.21305881186648953 | validation: 0.19952533673800368]
	TIME [epoch: 5.75 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31033042146328227		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.31033042146328227 | validation: 0.28499239331094167]
	TIME [epoch: 5.75 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.244621102820277		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.244621102820277 | validation: 0.18460698597999453]
	TIME [epoch: 5.78 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1609995392447266		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.1609995392447266 | validation: 0.15525523886456274]
	TIME [epoch: 5.75 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16174566394794085		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.16174566394794085 | validation: 0.24413095112427663]
	TIME [epoch: 5.75 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24892486910251904		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.24892486910251904 | validation: 0.13297245807665178]
	TIME [epoch: 5.75 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26645968169707834		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.26645968169707834 | validation: 0.22239745890901508]
	TIME [epoch: 5.75 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23095014561725516		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.23095014561725516 | validation: 0.34920518790296906]
	TIME [epoch: 5.75 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2549906134301128		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.2549906134301128 | validation: 0.25768235696684005]
	TIME [epoch: 5.76 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2043067899269331		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.2043067899269331 | validation: 0.13475111643908305]
	TIME [epoch: 5.77 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19334236488064124		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.19334236488064124 | validation: 0.23975529938655382]
	TIME [epoch: 5.74 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2630420919109214		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.2630420919109214 | validation: 0.38001338692251113]
	TIME [epoch: 5.75 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295842742303422		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.3295842742303422 | validation: 0.1981569720109055]
	TIME [epoch: 5.74 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26558441187087517		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.26558441187087517 | validation: 0.14740761639971756]
	TIME [epoch: 5.74 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22290828880295488		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.22290828880295488 | validation: 0.13644035299302565]
	TIME [epoch: 5.75 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1823115476578968		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.1823115476578968 | validation: 0.1589162530114643]
	TIME [epoch: 5.77 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1977410780719212		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.1977410780719212 | validation: 0.1469325485833415]
	TIME [epoch: 5.74 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17007166628946624		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.17007166628946624 | validation: 0.11032120296646422]
	TIME [epoch: 5.74 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2230538685491605		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.2230538685491605 | validation: 0.18632750029721656]
	TIME [epoch: 5.74 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23449864408424426		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.23449864408424426 | validation: 0.18680856696562034]
	TIME [epoch: 5.74 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17146836757515901		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.17146836757515901 | validation: 0.19623186933401238]
	TIME [epoch: 5.75 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17385594406775326		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.17385594406775326 | validation: 0.23131054514092783]
	TIME [epoch: 5.75 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30866515845322123		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.30866515845322123 | validation: 0.11995321495794688]
	TIME [epoch: 5.77 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18612386711808554		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.18612386711808554 | validation: 0.2922054814865951]
	TIME [epoch: 5.74 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2410939459096713		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.2410939459096713 | validation: 0.17541836534308117]
	TIME [epoch: 5.74 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15974457931967292		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.15974457931967292 | validation: 0.2019047911753109]
	TIME [epoch: 5.74 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17489845805738094		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.17489845805738094 | validation: 0.13332042414604023]
	TIME [epoch: 5.74 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16174117098421653		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.16174117098421653 | validation: 0.11335172789994392]
	TIME [epoch: 5.73 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21601912693220154		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.21601912693220154 | validation: 0.20193616399232853]
	TIME [epoch: 5.77 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19254391492623105		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.19254391492623105 | validation: 0.2444750857312937]
	TIME [epoch: 5.74 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2921412926967124		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.2921412926967124 | validation: 0.12617857066383484]
	TIME [epoch: 5.73 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22834941670478537		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.22834941670478537 | validation: 0.2611397163858965]
	TIME [epoch: 5.74 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19231210060443402		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.19231210060443402 | validation: 0.3123643033810341]
	TIME [epoch: 5.73 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16997344825225857		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.16997344825225857 | validation: 0.1373811496399631]
	TIME [epoch: 5.74 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506911131872115		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.1506911131872115 | validation: 0.3022263670528739]
	TIME [epoch: 5.74 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15986326699605521		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.15986326699605521 | validation: 0.3183459415459862]
	TIME [epoch: 5.77 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17390902640335873		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.17390902640335873 | validation: 0.12163941233324528]
	TIME [epoch: 5.74 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13361248922847735		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.13361248922847735 | validation: 0.16985758929681932]
	TIME [epoch: 5.74 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11525530447948887		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.11525530447948887 | validation: 0.09862973661999756]
	TIME [epoch: 5.73 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479628251515841		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.1479628251515841 | validation: 0.38960770775356196]
	TIME [epoch: 5.74 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25901364121673476		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.25901364121673476 | validation: 0.09847294083983467]
	TIME [epoch: 5.73 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14815066776925925		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.14815066776925925 | validation: 0.2141555821432283]
	TIME [epoch: 5.77 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13212923359037468		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.13212923359037468 | validation: 0.15099361942403794]
	TIME [epoch: 5.75 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17522249023730757		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.17522249023730757 | validation: 0.15384524080507053]
	TIME [epoch: 5.74 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567043372099966		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.1567043372099966 | validation: 0.07688919958652829]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_491.pth
	Model improved!!!
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13650203517237972		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.13650203517237972 | validation: 0.2325458831096907]
	TIME [epoch: 5.75 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.329591612717956		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.329591612717956 | validation: 0.2816002400212884]
	TIME [epoch: 5.75 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1812255136718099		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.1812255136718099 | validation: 0.09254884795591999]
	TIME [epoch: 5.78 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1738774056378786		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.1738774056378786 | validation: 0.24456502278597622]
	TIME [epoch: 5.79 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23091902604400236		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.23091902604400236 | validation: 0.2402742062260365]
	TIME [epoch: 5.74 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497277258148254		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.1497277258148254 | validation: 0.1487247185122022]
	TIME [epoch: 5.75 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1345382483119754		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.1345382483119754 | validation: 0.2611084744657212]
	TIME [epoch: 5.76 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2107661356945622		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.2107661356945622 | validation: 0.3281885882851398]
	TIME [epoch: 5.75 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19146586038757454		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.19146586038757454 | validation: 0.21295531415650634]
	TIME [epoch: 5.75 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22882722559508506		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.22882722559508506 | validation: 0.11970469928811323]
	TIME [epoch: 5.78 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17052516513411525		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.17052516513411525 | validation: 0.20822186258787015]
	TIME [epoch: 5.75 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20458223996631084		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.20458223996631084 | validation: 0.17299351513481326]
	TIME [epoch: 5.75 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14252399253471523		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.14252399253471523 | validation: 0.29323981770018137]
	TIME [epoch: 5.75 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35171288614065327		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.35171288614065327 | validation: 0.0688965086606428]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442672069167326		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.1442672069167326 | validation: 0.24569142448467218]
	TIME [epoch: 5.75 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2507131235519434		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.2507131235519434 | validation: 0.22509632112606498]
	TIME [epoch: 5.78 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15986378922198421		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.15986378922198421 | validation: 0.2107161128705522]
	TIME [epoch: 5.76 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19769080184304946		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.19769080184304946 | validation: 0.08167058325333319]
	TIME [epoch: 5.74 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15923962636824388		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.15923962636824388 | validation: 0.14456562270621282]
	TIME [epoch: 5.74 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12110701056199388		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.12110701056199388 | validation: 0.143929371558762]
	TIME [epoch: 5.74 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10965583304655896		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.10965583304655896 | validation: 0.1432854844682618]
	TIME [epoch: 5.75 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16916023142297731		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.16916023142297731 | validation: 0.1418772384336727]
	TIME [epoch: 5.75 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22402739145276968		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.22402739145276968 | validation: 0.25687945755643676]
	TIME [epoch: 5.78 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17687458505688725		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.17687458505688725 | validation: 0.17414333184817257]
	TIME [epoch: 5.75 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17096963499594528		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.17096963499594528 | validation: 0.19795358012374928]
	TIME [epoch: 5.74 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17707459780595775		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.17707459780595775 | validation: 0.12597971208730396]
	TIME [epoch: 5.75 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1404862697869183		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.1404862697869183 | validation: 0.14048779556542879]
	TIME [epoch: 5.76 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1844953038241628		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.1844953038241628 | validation: 0.2768696476319036]
	TIME [epoch: 5.74 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17354642665949804		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.17354642665949804 | validation: 0.16983525065046973]
	TIME [epoch: 5.79 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13986676091080136		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.13986676091080136 | validation: 0.1479097521666136]
	TIME [epoch: 5.75 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17577898807997258		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.17577898807997258 | validation: 0.12821224246958085]
	TIME [epoch: 5.74 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14233749050273392		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.14233749050273392 | validation: 0.10995494246735205]
	TIME [epoch: 5.76 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14487107267258453		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.14487107267258453 | validation: 0.19359846214091947]
	TIME [epoch: 5.74 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25034039382793183		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.25034039382793183 | validation: 0.11612916363521793]
	TIME [epoch: 5.75 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484655287097264		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.1484655287097264 | validation: 0.15871401968852483]
	TIME [epoch: 5.74 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16790536874347345		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.16790536874347345 | validation: 0.376925974159738]
	TIME [epoch: 5.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19835370723527238		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.19835370723527238 | validation: 0.08994674419765543]
	TIME [epoch: 5.76 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19697753172628776		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.19697753172628776 | validation: 0.8476295232785427]
	TIME [epoch: 5.75 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4479678379644292		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.4479678379644292 | validation: 0.2009435038873684]
	TIME [epoch: 5.73 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29848464087575244		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.29848464087575244 | validation: 0.14571620766634968]
	TIME [epoch: 5.74 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20128890966507912		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.20128890966507912 | validation: 0.10592771262352184]
	TIME [epoch: 5.74 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17915226702286052		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.17915226702286052 | validation: 0.3114107779775677]
	TIME [epoch: 5.76 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1710040895522077		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.1710040895522077 | validation: 0.21778355259767754]
	TIME [epoch: 5.75 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1608079687852319		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1608079687852319 | validation: 0.2513509091785236]
	TIME [epoch: 5.74 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17593640132936295		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.17593640132936295 | validation: 0.16924074965004388]
	TIME [epoch: 5.74 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14561556170852544		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.14561556170852544 | validation: 0.137573835610001]
	TIME [epoch: 5.74 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15903038223949856		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.15903038223949856 | validation: 0.16180094353208663]
	TIME [epoch: 5.74 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24217394102589634		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.24217394102589634 | validation: 0.21364818806486072]
	TIME [epoch: 5.74 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20944902017221723		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.20944902017221723 | validation: 0.15633745379520236]
	TIME [epoch: 5.78 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17548705407599058		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.17548705407599058 | validation: 0.24812986431064005]
	TIME [epoch: 5.74 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15685417194038376		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.15685417194038376 | validation: 0.18181465480554898]
	TIME [epoch: 5.74 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2617497167535914		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.2617497167535914 | validation: 0.5150916935741334]
	TIME [epoch: 5.74 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3428805653849689		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.3428805653849689 | validation: 0.07441322233020005]
	TIME [epoch: 5.74 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16616566025988164		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.16616566025988164 | validation: 0.16901175019401848]
	TIME [epoch: 5.74 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18775568391162786		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.18775568391162786 | validation: 0.20279456673238677]
	TIME [epoch: 5.77 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14619008779482076		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.14619008779482076 | validation: 0.15201668388393835]
	TIME [epoch: 5.75 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1604559328497872		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.1604559328497872 | validation: 0.1270348354404116]
	TIME [epoch: 5.74 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16653908084105212		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.16653908084105212 | validation: 0.29168179154645374]
	TIME [epoch: 5.75 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1716425334951416		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.1716425334951416 | validation: 0.11160893395031829]
	TIME [epoch: 5.74 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12795095226627748		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.12795095226627748 | validation: 0.1830137416016428]
	TIME [epoch: 5.74 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15981610036066332		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.15981610036066332 | validation: 0.17228728517259653]
	TIME [epoch: 5.74 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11575900185598043		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.11575900185598043 | validation: 0.24107951166578973]
	TIME [epoch: 5.78 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17266828331105064		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.17266828331105064 | validation: 0.07350830638170973]
	TIME [epoch: 5.74 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12135949838646096		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.12135949838646096 | validation: 0.1388641872511499]
	TIME [epoch: 5.75 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16125859267140005		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.16125859267140005 | validation: 0.10314672773482225]
	TIME [epoch: 5.74 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13762456501977283		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.13762456501977283 | validation: 0.1943074926744221]
	TIME [epoch: 5.75 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2072545420054722		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.2072545420054722 | validation: 0.15784872929767294]
	TIME [epoch: 5.74 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14939229303246862		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.14939229303246862 | validation: 0.17487471763117302]
	TIME [epoch: 5.78 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1791167327171452		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1791167327171452 | validation: 0.1426523309360086]
	TIME [epoch: 5.77 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346322880294015		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.1346322880294015 | validation: 0.20245641374629444]
	TIME [epoch: 5.76 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1414124731064089		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.1414124731064089 | validation: 0.1016207267541191]
	TIME [epoch: 5.76 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14712587542819144		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.14712587542819144 | validation: 0.16930770607379497]
	TIME [epoch: 5.76 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15706863058654238		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.15706863058654238 | validation: 0.1434024352084897]
	TIME [epoch: 5.76 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15435821299093028		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.15435821299093028 | validation: 0.1581147424207704]
	TIME [epoch: 5.74 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13114677381320777		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.13114677381320777 | validation: 0.08880389030910832]
	TIME [epoch: 5.78 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14025340136621375		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.14025340136621375 | validation: 0.13185020622370858]
	TIME [epoch: 5.74 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13367714255957822		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.13367714255957822 | validation: 0.14441412785524332]
	TIME [epoch: 5.74 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16126812617103048		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.16126812617103048 | validation: 0.07697602914593295]
	TIME [epoch: 5.74 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27905358406234		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.27905358406234 | validation: 0.09278949425907453]
	TIME [epoch: 5.74 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1826525101071201		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.1826525101071201 | validation: 0.29357293254745764]
	TIME [epoch: 5.74 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17391512901086026		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.17391512901086026 | validation: 0.14779842240283841]
	TIME [epoch: 5.77 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14105998895243504		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.14105998895243504 | validation: 0.19330238491332957]
	TIME [epoch: 5.75 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17174671219343984		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.17174671219343984 | validation: 0.3246165620187354]
	TIME [epoch: 5.74 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23636179951499375		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.23636179951499375 | validation: 0.18077534540690288]
	TIME [epoch: 5.74 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13496521325326333		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.13496521325326333 | validation: 0.23001666515022923]
	TIME [epoch: 5.74 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19084088587817424		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.19084088587817424 | validation: 0.10836495610215341]
	TIME [epoch: 5.74 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14420388568840897		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.14420388568840897 | validation: 0.17947025641290418]
	TIME [epoch: 5.74 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12575504890461678		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.12575504890461678 | validation: 0.1735947576712503]
	TIME [epoch: 5.78 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16980789456637047		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.16980789456637047 | validation: 0.18089217511164635]
	TIME [epoch: 5.74 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1436190098365658		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.1436190098365658 | validation: 0.21184817176234724]
	TIME [epoch: 5.75 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12651200995443698		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.12651200995443698 | validation: 0.07969576705932953]
	TIME [epoch: 5.74 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11631429091188869		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.11631429091188869 | validation: 0.19742425409007383]
	TIME [epoch: 5.74 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16722308677162148		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.16722308677162148 | validation: 0.20510005288151675]
	TIME [epoch: 5.74 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17495021450575363		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.17495021450575363 | validation: 0.24169484941874309]
	TIME [epoch: 5.77 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13354267069662437		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.13354267069662437 | validation: 0.14483436976871264]
	TIME [epoch: 5.75 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10614085946503861		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.10614085946503861 | validation: 0.11019976734420714]
	TIME [epoch: 5.74 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13793246547798463		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.13793246547798463 | validation: 0.13769651254117427]
	TIME [epoch: 5.74 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11944917764402986		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.11944917764402986 | validation: 0.27076453693353364]
	TIME [epoch: 5.74 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24474381810930373		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.24474381810930373 | validation: 0.08829793931400462]
	TIME [epoch: 5.74 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11131208328235438		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.11131208328235438 | validation: 0.09812525538796138]
	TIME [epoch: 5.74 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13690635656719352		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.13690635656719352 | validation: 0.08514150722295157]
	TIME [epoch: 5.78 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12331184675341214		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.12331184675341214 | validation: 0.18221804797091817]
	TIME [epoch: 5.74 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28836710875172233		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.28836710875172233 | validation: 0.12850596625436808]
	TIME [epoch: 5.74 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17228845649296043		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.17228845649296043 | validation: 0.12024001442744417]
	TIME [epoch: 5.75 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350081512860034		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.1350081512860034 | validation: 0.1722688603006977]
	TIME [epoch: 5.76 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14159470937152993		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.14159470937152993 | validation: 0.15239553153449623]
	TIME [epoch: 5.76 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10365367446138017		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.10365367446138017 | validation: 0.20202082695047588]
	TIME [epoch: 5.79 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15782300642545752		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.15782300642545752 | validation: 0.14591568629270513]
	TIME [epoch: 5.77 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339610347596895		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.1339610347596895 | validation: 0.11727338600816346]
	TIME [epoch: 5.76 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17162123509248628		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.17162123509248628 | validation: 0.22481242633944526]
	TIME [epoch: 5.75 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1955269930243958		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.1955269930243958 | validation: 0.28509812186017414]
	TIME [epoch: 5.76 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15429693035774822		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.15429693035774822 | validation: 0.14262061206091547]
	TIME [epoch: 5.76 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12536473479833277		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.12536473479833277 | validation: 0.12560084699340476]
	TIME [epoch: 5.76 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14693350478202444		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.14693350478202444 | validation: 0.10968790920000716]
	TIME [epoch: 5.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17874947296464327		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.17874947296464327 | validation: 0.11206773539005045]
	TIME [epoch: 5.76 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12718833003882848		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.12718833003882848 | validation: 0.16695614344575255]
	TIME [epoch: 5.76 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20370211094031868		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.20370211094031868 | validation: 0.1109144309879656]
	TIME [epoch: 5.76 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12285943228458121		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.12285943228458121 | validation: 0.3281109464868564]
	TIME [epoch: 5.74 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17323177998408287		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.17323177998408287 | validation: 0.2820930273131226]
	TIME [epoch: 5.76 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21406041028862116		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.21406041028862116 | validation: 0.2439006779252361]
	TIME [epoch: 5.79 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522513661743315		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.1522513661743315 | validation: 0.21739600157721775]
	TIME [epoch: 5.77 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16564536053573126		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.16564536053573126 | validation: 0.06999645112430235]
	TIME [epoch: 5.74 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12312483705972038		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.12312483705972038 | validation: 0.17769967034042572]
	TIME [epoch: 5.74 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1225897450254899		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.1225897450254899 | validation: 0.1790512484888288]
	TIME [epoch: 5.75 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19852621804366227		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.19852621804366227 | validation: 0.11322139420799161]
	TIME [epoch: 5.76 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11069529405108766		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.11069529405108766 | validation: 0.18541173546844736]
	TIME [epoch: 5.76 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1125228936887016		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.1125228936887016 | validation: 0.15868836365068295]
	TIME [epoch: 5.79 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12883076857337752		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.12883076857337752 | validation: 0.12228386277912773]
	TIME [epoch: 5.76 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0996351860790651		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.0996351860790651 | validation: 0.19949032456674765]
	TIME [epoch: 5.76 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12741065860656406		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.12741065860656406 | validation: 0.1337714593030393]
	TIME [epoch: 5.75 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15026367216211894		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.15026367216211894 | validation: 0.11867861127062469]
	TIME [epoch: 5.74 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10532325364779696		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.10532325364779696 | validation: 0.18319909103375046]
	TIME [epoch: 5.74 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11621088691003698		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.11621088691003698 | validation: 0.12266397614923952]
	TIME [epoch: 5.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11646174378111243		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.11646174378111243 | validation: 0.2217003409767018]
	TIME [epoch: 5.77 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15972221751027393		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.15972221751027393 | validation: 0.09156173693491333]
	TIME [epoch: 5.75 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11255219974643856		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.11255219974643856 | validation: 0.1835519584864479]
	TIME [epoch: 5.74 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13277353141628548		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.13277353141628548 | validation: 0.12833371777227742]
	TIME [epoch: 5.75 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11927196210987133		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.11927196210987133 | validation: 0.16313385406349631]
	TIME [epoch: 5.76 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12680025812079193		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.12680025812079193 | validation: 0.07485752926751857]
	TIME [epoch: 5.76 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10364007512280221		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.10364007512280221 | validation: 0.14958246302361175]
	TIME [epoch: 5.79 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13228074981342894		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.13228074981342894 | validation: 0.07931318128891722]
	TIME [epoch: 5.76 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11831625340219712		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.11831625340219712 | validation: 0.17632369624818167]
	TIME [epoch: 5.76 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13665528309570846		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.13665528309570846 | validation: 0.10810564952977217]
	TIME [epoch: 5.75 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12079032807404		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.12079032807404 | validation: 0.07314754175990949]
	TIME [epoch: 5.76 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740717088124749		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.07740717088124749 | validation: 0.1567823797954639]
	TIME [epoch: 5.75 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11198952049479177		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.11198952049479177 | validation: 0.06550497304934476]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15266166746539728		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.15266166746539728 | validation: 0.08090302234121653]
	TIME [epoch: 5.75 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09301000293130045		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.09301000293130045 | validation: 0.1506298227037115]
	TIME [epoch: 5.75 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11597926907613842		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.11597926907613842 | validation: 0.14908300367384966]
	TIME [epoch: 5.76 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1671672687342285		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.1671672687342285 | validation: 0.22378085550863894]
	TIME [epoch: 5.75 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12346569148743823		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.12346569148743823 | validation: 0.2835542305573511]
	TIME [epoch: 5.75 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15655486168397512		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.15655486168397512 | validation: 0.10452585657512393]
	TIME [epoch: 5.75 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13649989461997175		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.13649989461997175 | validation: 0.10870991796885596]
	TIME [epoch: 5.78 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733735914132873		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.1733735914132873 | validation: 0.11748187533052214]
	TIME [epoch: 5.74 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11063246893412058		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.11063246893412058 | validation: 0.10475050823133895]
	TIME [epoch: 5.76 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15015433441254936		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.15015433441254936 | validation: 0.08350300199637435]
	TIME [epoch: 5.73 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1007581992224827		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.1007581992224827 | validation: 0.09132711120339877]
	TIME [epoch: 5.74 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09844429685005202		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.09844429685005202 | validation: 0.06806786510846786]
	TIME [epoch: 5.74 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13541858450664684		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.13541858450664684 | validation: 0.14112216007199244]
	TIME [epoch: 5.78 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13701395508111996		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.13701395508111996 | validation: 0.1426110745591153]
	TIME [epoch: 5.74 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12290497193047918		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.12290497193047918 | validation: 0.1253013198294982]
	TIME [epoch: 5.74 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09859805717345739		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.09859805717345739 | validation: 0.13082502393102616]
	TIME [epoch: 5.74 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10091729178539505		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.10091729178539505 | validation: 0.10862218230032218]
	TIME [epoch: 5.74 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0949959278262179		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.0949959278262179 | validation: 0.08434016793661663]
	TIME [epoch: 5.75 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1170545480043211		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.1170545480043211 | validation: 0.058929567584626245]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_656.pth
	Model improved!!!
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11162660988138104		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.11162660988138104 | validation: 0.20583957287360335]
	TIME [epoch: 5.77 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15922213548612887		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.15922213548612887 | validation: 0.19254160870999998]
	TIME [epoch: 5.74 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13491410754055666		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.13491410754055666 | validation: 0.22094444863687937]
	TIME [epoch: 5.76 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1581904784137489		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.1581904784137489 | validation: 0.06610043224674501]
	TIME [epoch: 5.74 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10866754799552586		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.10866754799552586 | validation: 0.12386010612144216]
	TIME [epoch: 5.75 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10595901863108685		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.10595901863108685 | validation: 0.19174071990024805]
	TIME [epoch: 5.74 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11117435495075684		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.11117435495075684 | validation: 0.10944818571285536]
	TIME [epoch: 5.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422949360835758		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.1422949360835758 | validation: 0.073378034942151]
	TIME [epoch: 5.75 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09371008308895845		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.09371008308895845 | validation: 0.06414861353415352]
	TIME [epoch: 5.75 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15916124881442967		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.15916124881442967 | validation: 0.1717761554107229]
	TIME [epoch: 5.75 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13358945658721574		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.13358945658721574 | validation: 0.0540290304846145]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_667.pth
	Model improved!!!
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17020132419267223		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.17020132419267223 | validation: 0.16940761525647471]
	TIME [epoch: 5.74 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11665731976183998		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.11665731976183998 | validation: 0.091385871796118]
	TIME [epoch: 5.78 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12308993221260878		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.12308993221260878 | validation: 0.14853740683208702]
	TIME [epoch: 5.74 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.123656258228721		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.123656258228721 | validation: 0.07698437234127926]
	TIME [epoch: 5.75 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09308258992433645		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.09308258992433645 | validation: 0.12126295321915255]
	TIME [epoch: 5.73 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09414748271174454		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.09414748271174454 | validation: 0.10124114566174726]
	TIME [epoch: 5.74 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14376804495884438		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.14376804495884438 | validation: 0.1771713122164077]
	TIME [epoch: 5.74 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12017102937972428		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.12017102937972428 | validation: 0.15142818187489826]
	TIME [epoch: 5.75 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10003200433526113		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.10003200433526113 | validation: 0.07037543771574647]
	TIME [epoch: 5.78 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07889162707333998		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.07889162707333998 | validation: 0.1364102996592416]
	TIME [epoch: 5.75 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10599997887244011		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.10599997887244011 | validation: 0.0573962299499893]
	TIME [epoch: 5.74 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06862752824347902		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.06862752824347902 | validation: 0.12107853089018088]
	TIME [epoch: 5.75 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12194611767609972		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.12194611767609972 | validation: 0.07747506853101915]
	TIME [epoch: 5.75 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07926036240181539		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.07926036240181539 | validation: 0.1286235663252836]
	TIME [epoch: 5.74 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07727177802951693		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.07727177802951693 | validation: 0.07442656033901986]
	TIME [epoch: 5.79 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290396775616983		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.1290396775616983 | validation: 0.12413961824298408]
	TIME [epoch: 5.74 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326085102790851		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.1326085102790851 | validation: 0.08056325055654077]
	TIME [epoch: 5.75 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09246601493734448		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.09246601493734448 | validation: 0.07383451403398007]
	TIME [epoch: 5.74 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07705746006039672		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.07705746006039672 | validation: 0.25053127432880573]
	TIME [epoch: 5.74 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15613607273956231		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.15613607273956231 | validation: 0.1566691829532687]
	TIME [epoch: 5.74 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1491176972313181		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.1491176972313181 | validation: 0.15886893566386498]
	TIME [epoch: 5.75 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15537557558420506		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.15537557558420506 | validation: 0.10470955083196999]
	TIME [epoch: 5.77 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11757633881078197		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.11757633881078197 | validation: 0.09936081814185937]
	TIME [epoch: 5.74 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16391353698306382		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.16391353698306382 | validation: 0.10300172669843319]
	TIME [epoch: 5.73 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13990168785006127		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.13990168785006127 | validation: 0.17931704562098127]
	TIME [epoch: 5.74 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10861646789576412		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.10861646789576412 | validation: 0.09694478073756717]
	TIME [epoch: 5.74 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0955390063221215		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.0955390063221215 | validation: 0.077987490360508]
	TIME [epoch: 5.74 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10720999757891515		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.10720999757891515 | validation: 0.14368365472710623]
	TIME [epoch: 5.78 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10814376381279546		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.10814376381279546 | validation: 0.10213159870893568]
	TIME [epoch: 5.74 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08850241623390727		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.08850241623390727 | validation: 0.09009233812358701]
	TIME [epoch: 5.74 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10102075933499004		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.10102075933499004 | validation: 0.09462296776786505]
	TIME [epoch: 5.74 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13003263754165603		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.13003263754165603 | validation: 0.11775655322280836]
	TIME [epoch: 5.74 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08753271496762936		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.08753271496762936 | validation: 0.07923787106231707]
	TIME [epoch: 5.74 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2893794028169446		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.2893794028169446 | validation: 0.21851186137180542]
	TIME [epoch: 5.75 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13036737385389796		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.13036737385389796 | validation: 0.07870100694822442]
	TIME [epoch: 5.77 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0708552945207997		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.0708552945207997 | validation: 0.06249110603447674]
	TIME [epoch: 5.74 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09738180085499805		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.09738180085499805 | validation: 0.05672575858644278]
	TIME [epoch: 5.74 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06962821638887727		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.06962821638887727 | validation: 0.17618316998140607]
	TIME [epoch: 5.74 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10358728272057952		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.10358728272057952 | validation: 0.11960737551211409]
	TIME [epoch: 5.75 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12095389815353112		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.12095389815353112 | validation: 0.1555272314166516]
	TIME [epoch: 5.74 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11775338414454826		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.11775338414454826 | validation: 0.07321631786472028]
	TIME [epoch: 5.79 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09047378642886408		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.09047378642886408 | validation: 0.06855031466685967]
	TIME [epoch: 5.75 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14082118647210162		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.14082118647210162 | validation: 0.0785839629926282]
	TIME [epoch: 5.74 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08615403927446233		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.08615403927446233 | validation: 0.11519948417133474]
	TIME [epoch: 5.74 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11370617026089769		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.11370617026089769 | validation: 0.07258535765750629]
	TIME [epoch: 5.75 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09040460526393009		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.09040460526393009 | validation: 0.1001333496699298]
	TIME [epoch: 5.74 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09128508546654589		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.09128508546654589 | validation: 0.11451246369683298]
	TIME [epoch: 5.75 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08205238597700076		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.08205238597700076 | validation: 0.07859425430343006]
	TIME [epoch: 5.77 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07373871904079032		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.07373871904079032 | validation: 0.0737573797133149]
	TIME [epoch: 5.74 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08988419382130385		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.08988419382130385 | validation: 0.09765344921533237]
	TIME [epoch: 5.75 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11251759461681199		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.11251759461681199 | validation: 0.1101756219544733]
	TIME [epoch: 5.74 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07385272124167544		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.07385272124167544 | validation: 0.1444167017886038]
	TIME [epoch: 5.74 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10061675996685004		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.10061675996685004 | validation: 0.03601442389156553]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_720.pth
	Model improved!!!
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07782349148088868		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.07782349148088868 | validation: 0.08877481359572674]
	TIME [epoch: 5.79 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12576892020768576		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.12576892020768576 | validation: 0.1598203619968324]
	TIME [epoch: 5.74 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11006818923996713		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.11006818923996713 | validation: 0.0717718442774924]
	TIME [epoch: 5.74 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0884114440834266		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.0884114440834266 | validation: 0.0713357021967684]
	TIME [epoch: 5.74 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15439667385043643		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.15439667385043643 | validation: 0.0604085676043815]
	TIME [epoch: 5.74 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09190195467797213		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.09190195467797213 | validation: 0.1649848984582631]
	TIME [epoch: 5.75 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11762986162154748		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.11762986162154748 | validation: 0.11064493894854374]
	TIME [epoch: 5.77 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09944926471306001		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.09944926471306001 | validation: 0.10380512657213126]
	TIME [epoch: 5.78 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08846689800667382		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.08846689800667382 | validation: 0.09188713102508392]
	TIME [epoch: 5.75 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0863061501549707		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.0863061501549707 | validation: 0.09019905353068243]
	TIME [epoch: 5.75 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09646737012668877		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.09646737012668877 | validation: 0.0807592544849395]
	TIME [epoch: 5.75 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0761076043367464		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.0761076043367464 | validation: 0.08978951588879859]
	TIME [epoch: 5.75 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274826236664614		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.1274826236664614 | validation: 0.09544045451970007]
	TIME [epoch: 5.75 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07520820073483109		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.07520820073483109 | validation: 0.0736204453358996]
	TIME [epoch: 5.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07564709734473182		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.07564709734473182 | validation: 0.08737370777101941]
	TIME [epoch: 5.76 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.070895975935865		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.070895975935865 | validation: 0.06368551121094095]
	TIME [epoch: 5.75 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10068719901810694		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.10068719901810694 | validation: 0.12003862192914046]
	TIME [epoch: 5.75 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10825457938480672		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.10825457938480672 | validation: 0.1078336698753819]
	TIME [epoch: 5.75 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09027573881178792		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.09027573881178792 | validation: 0.10581293948649975]
	TIME [epoch: 5.75 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350810353960957		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.1350810353960957 | validation: 0.13185790310765869]
	TIME [epoch: 5.78 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10758712191301395		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.10758712191301395 | validation: 0.09332510899426932]
	TIME [epoch: 5.77 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0794430964799769		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.0794430964799769 | validation: 0.0901743570838514]
	TIME [epoch: 5.76 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1092249846603719		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.1092249846603719 | validation: 0.12720202957898788]
	TIME [epoch: 5.75 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10290000776521464		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.10290000776521464 | validation: 0.06749751971823409]
	TIME [epoch: 5.75 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07727887258615246		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.07727887258615246 | validation: 0.13797896797633097]
	TIME [epoch: 5.75 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15919905538835308		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.15919905538835308 | validation: 0.2522165266432518]
	TIME [epoch: 5.75 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11239566129042938		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.11239566129042938 | validation: 0.08676356115047146]
	TIME [epoch: 5.79 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11664943666182356		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.11664943666182356 | validation: 0.08014194376591036]
	TIME [epoch: 5.76 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06281016939770077		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.06281016939770077 | validation: 0.1273051467844415]
	TIME [epoch: 5.76 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08301333319918044		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.08301333319918044 | validation: 0.14045001172252072]
	TIME [epoch: 5.75 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11321187790574783		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.11321187790574783 | validation: 0.12903980460478578]
	TIME [epoch: 5.75 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09507292271952614		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.09507292271952614 | validation: 0.14005800467757573]
	TIME [epoch: 5.75 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09662049884545537		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.09662049884545537 | validation: 0.07642453575142696]
	TIME [epoch: 5.77 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07894461758796673		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.07894461758796673 | validation: 0.06097756996709573]
	TIME [epoch: 5.76 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0631338015003853		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.0631338015003853 | validation: 0.06085762763155764]
	TIME [epoch: 5.75 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16236475678360537		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.16236475678360537 | validation: 0.09390492841745221]
	TIME [epoch: 5.75 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06961543683554784		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.06961543683554784 | validation: 0.08267391462562912]
	TIME [epoch: 5.75 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06484467692852462		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.06484467692852462 | validation: 0.060007295587751454]
	TIME [epoch: 5.75 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08175573673971082		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.08175573673971082 | validation: 0.12149658581742163]
	TIME [epoch: 5.76 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10017476711851693		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.10017476711851693 | validation: 0.11281450080531069]
	TIME [epoch: 5.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07753014544571346		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.07753014544571346 | validation: 0.08339387889618415]
	TIME [epoch: 5.76 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0758149378997238		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.0758149378997238 | validation: 0.09377184040582512]
	TIME [epoch: 5.75 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08368410874720414		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.08368410874720414 | validation: 0.0760672975947719]
	TIME [epoch: 5.75 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08415978148237933		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.08415978148237933 | validation: 0.07017612320351566]
	TIME [epoch: 5.75 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0817106607151914		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.0817106607151914 | validation: 0.13102948589847968]
	TIME [epoch: 5.74 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06850221527145353		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.06850221527145353 | validation: 0.07433795279030526]
	TIME [epoch: 5.77 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11160250445560492		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.11160250445560492 | validation: 0.1435492892052044]
	TIME [epoch: 5.76 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10747192438834674		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.10747192438834674 | validation: 0.07057956976205138]
	TIME [epoch: 5.74 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07771828915407576		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.07771828915407576 | validation: 0.07974568513659683]
	TIME [epoch: 5.75 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08754946117367322		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.08754946117367322 | validation: 0.16593992076145916]
	TIME [epoch: 5.76 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10380468413477442		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.10380468413477442 | validation: 0.09145300113264973]
	TIME [epoch: 5.78 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10194759082796362		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.10194759082796362 | validation: 0.0993195290918922]
	TIME [epoch: 5.74 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08788736819954024		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.08788736819954024 | validation: 0.053270064434734685]
	TIME [epoch: 5.79 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07616063355404729		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.07616063355404729 | validation: 0.09196991696824082]
	TIME [epoch: 5.75 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08222840179140412		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.08222840179140412 | validation: 0.14565787026844643]
	TIME [epoch: 5.75 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12019778783303026		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.12019778783303026 | validation: 0.08429865146595841]
	TIME [epoch: 5.74 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12377904278367588		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.12377904278367588 | validation: 0.09511010390248767]
	TIME [epoch: 5.74 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0794890190510127		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.0794890190510127 | validation: 0.13562776032816498]
	TIME [epoch: 5.75 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09828166965705955		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.09828166965705955 | validation: 0.11275533552563345]
	TIME [epoch: 5.78 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08312050445521385		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.08312050445521385 | validation: 0.0982230490431613]
	TIME [epoch: 5.76 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821137379258824		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.06821137379258824 | validation: 0.06321881075113887]
	TIME [epoch: 5.76 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07273377861414797		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.07273377861414797 | validation: 0.06330417139098175]
	TIME [epoch: 5.75 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0797446507265637		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.0797446507265637 | validation: 0.0978565446563032]
	TIME [epoch: 5.74 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08282795101984856		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.08282795101984856 | validation: 0.10626559820667968]
	TIME [epoch: 5.75 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06078547950263979		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.06078547950263979 | validation: 0.06738198187844781]
	TIME [epoch: 5.74 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06747618699500545		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.06747618699500545 | validation: 0.062069342228744856]
	TIME [epoch: 5.79 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061217540202182216		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.061217540202182216 | validation: 0.07012302818089404]
	TIME [epoch: 5.75 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08019535562296592		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.08019535562296592 | validation: 0.08216131354097264]
	TIME [epoch: 5.75 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0924539797379066		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.0924539797379066 | validation: 0.11737928024537812]
	TIME [epoch: 5.75 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09416080099529442		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.09416080099529442 | validation: 0.10526730105267952]
	TIME [epoch: 5.75 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08814303419167094		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.08814303419167094 | validation: 0.051165524367449054]
	TIME [epoch: 5.76 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07334165555742761		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.07334165555742761 | validation: 0.0682855036233255]
	TIME [epoch: 5.78 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06909307299921726		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.06909307299921726 | validation: 0.06157141410571876]
	TIME [epoch: 5.77 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08412769417262377		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.08412769417262377 | validation: 0.07339376095974985]
	TIME [epoch: 5.75 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11148846417265511		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.11148846417265511 | validation: 0.05255271004312819]
	TIME [epoch: 5.75 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09480105157618604		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.09480105157618604 | validation: 0.13468378452485336]
	TIME [epoch: 5.75 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07699255123212906		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.07699255123212906 | validation: 0.07228434842198697]
	TIME [epoch: 5.75 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051521956418488946		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.051521956418488946 | validation: 0.10572459571710999]
	TIME [epoch: 5.74 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0880577660232798		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.0880577660232798 | validation: 0.08917758388144112]
	TIME [epoch: 5.79 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10113587273266383		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.10113587273266383 | validation: 0.06735842284846087]
	TIME [epoch: 5.75 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06756379191440096		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.06756379191440096 | validation: 0.039730711555525836]
	TIME [epoch: 5.76 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06780149116703527		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.06780149116703527 | validation: 0.08675890154034858]
	TIME [epoch: 5.76 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127803715930873		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.08127803715930873 | validation: 0.09688715184841068]
	TIME [epoch: 5.75 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0931204483525663		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.0931204483525663 | validation: 0.11323302575280546]
	TIME [epoch: 5.75 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07434499842074663		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.07434499842074663 | validation: 0.08682952927847529]
	TIME [epoch: 5.78 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05891525316069274		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.05891525316069274 | validation: 0.07389941919990588]
	TIME [epoch: 5.75 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07186542584359741		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.07186542584359741 | validation: 0.08049817263471151]
	TIME [epoch: 5.76 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09279555317272602		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.09279555317272602 | validation: 0.07814882778162517]
	TIME [epoch: 5.75 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07163849835617628		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.07163849835617628 | validation: 0.09285238261670323]
	TIME [epoch: 5.75 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08633086934449954		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.08633086934449954 | validation: 0.0870263041297049]
	TIME [epoch: 5.74 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08523894188023713		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.08523894188023713 | validation: 0.12673361418420365]
	TIME [epoch: 5.75 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12194445534284054		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.12194445534284054 | validation: 0.11343911558966976]
	TIME [epoch: 5.78 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756526238053598		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.0756526238053598 | validation: 0.1256226945403508]
	TIME [epoch: 5.76 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06873038069162049		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.06873038069162049 | validation: 0.0859142475986929]
	TIME [epoch: 5.74 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06509944231305792		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.06509944231305792 | validation: 0.0919190515174298]
	TIME [epoch: 5.73 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07334030011942647		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.07334030011942647 | validation: 0.0838214730646367]
	TIME [epoch: 5.73 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09444990301447659		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.09444990301447659 | validation: 0.1042554588011346]
	TIME [epoch: 5.74 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11854788110745874		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.11854788110745874 | validation: 0.15865756274802542]
	TIME [epoch: 5.78 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07331360277184153		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.07331360277184153 | validation: 0.07236373367358093]
	TIME [epoch: 5.75 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0634824978238829		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.0634824978238829 | validation: 0.07998977371052803]
	TIME [epoch: 5.75 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07818583165673437		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.07818583165673437 | validation: 0.13744402070913872]
	TIME [epoch: 5.75 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09288343917757223		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.09288343917757223 | validation: 0.12640398693007268]
	TIME [epoch: 5.74 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0701788090669477		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.0701788090669477 | validation: 0.05417796566762346]
	TIME [epoch: 5.74 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06845799851754378		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.06845799851754378 | validation: 0.046384904447175364]
	TIME [epoch: 5.76 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.097971698186064		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.097971698186064 | validation: 0.08328440072637364]
	TIME [epoch: 5.77 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08290758988620953		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.08290758988620953 | validation: 0.1386850482944554]
	TIME [epoch: 5.75 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09378367710481608		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.09378367710481608 | validation: 0.07930066997651243]
	TIME [epoch: 5.75 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07486466904280276		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.07486466904280276 | validation: 0.06082578390088143]
	TIME [epoch: 5.75 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05907130555907886		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.05907130555907886 | validation: 0.07520363617875159]
	TIME [epoch: 5.75 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06129764588508231		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.06129764588508231 | validation: 0.0886660161386705]
	TIME [epoch: 5.75 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08011394198789303		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.08011394198789303 | validation: 0.06646594784832027]
	TIME [epoch: 5.79 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057010182661813645		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.057010182661813645 | validation: 0.10174448480921883]
	TIME [epoch: 5.76 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06690648202527363		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.06690648202527363 | validation: 0.10580211819105972]
	TIME [epoch: 5.75 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07644781705940272		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.07644781705940272 | validation: 0.07585701292934721]
	TIME [epoch: 5.75 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07832331722114425		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.07832331722114425 | validation: 0.11769298248850624]
	TIME [epoch: 5.75 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07759945661303551		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.07759945661303551 | validation: 0.0836334468328758]
	TIME [epoch: 5.74 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0640381713431836		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.0640381713431836 | validation: 0.1086289543506787]
	TIME [epoch: 5.76 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07064921485277373		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.07064921485277373 | validation: 0.08012056235293245]
	TIME [epoch: 5.76 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05299627705895102		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.05299627705895102 | validation: 0.07876006688173211]
	TIME [epoch: 5.74 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702957297793269		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.06702957297793269 | validation: 0.09547958146357222]
	TIME [epoch: 5.74 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08130984074008371		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.08130984074008371 | validation: 0.11749450838815888]
	TIME [epoch: 5.74 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06607189008024383		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.06607189008024383 | validation: 0.10830026138084808]
	TIME [epoch: 5.74 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0670065797237048		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.0670065797237048 | validation: 0.0536279086075989]
	TIME [epoch: 5.74 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08676119105615887		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.08676119105615887 | validation: 0.05596077636465885]
	TIME [epoch: 5.79 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05890218657241851		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.05890218657241851 | validation: 0.0527399702214808]
	TIME [epoch: 5.74 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10616659472086604		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.10616659472086604 | validation: 0.0636869375428279]
	TIME [epoch: 5.74 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09438485987164236		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.09438485987164236 | validation: 0.08020514914678596]
	TIME [epoch: 5.75 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07495914401452072		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.07495914401452072 | validation: 0.08593908265358198]
	TIME [epoch: 5.74 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06652662103404379		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.06652662103404379 | validation: 0.05730492241578259]
	TIME [epoch: 5.74 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08895069877507919		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.08895069877507919 | validation: 0.07412175831134488]
	TIME [epoch: 5.75 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07730542516076258		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.07730542516076258 | validation: 0.055876149930234265]
	TIME [epoch: 5.77 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08415395800891476		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.08415395800891476 | validation: 0.07285452474549174]
	TIME [epoch: 5.74 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06215066348196789		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.06215066348196789 | validation: 0.062362199128708176]
	TIME [epoch: 5.75 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09009425237345708		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.09009425237345708 | validation: 0.055774898809994713]
	TIME [epoch: 5.74 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05737112976051533		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.05737112976051533 | validation: 0.1384944901919311]
	TIME [epoch: 5.75 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0860363433847644		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.0860363433847644 | validation: 0.05948311888010251]
	TIME [epoch: 5.74 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0493686496854496		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.0493686496854496 | validation: 0.052907336508673776]
	TIME [epoch: 5.78 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07502741911511078		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.07502741911511078 | validation: 0.06496566036758483]
	TIME [epoch: 5.75 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07276226813934832		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.07276226813934832 | validation: 0.06708450145170583]
	TIME [epoch: 5.74 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06554248732042135		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.06554248732042135 | validation: 0.09066206612896209]
	TIME [epoch: 5.74 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0895891593209982		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.0895891593209982 | validation: 0.07073002365606697]
	TIME [epoch: 5.74 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056304521028049836		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.056304521028049836 | validation: 0.08189500625266215]
	TIME [epoch: 5.75 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08165324562561317		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.08165324562561317 | validation: 0.11475276409010692]
	TIME [epoch: 5.75 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05921615195144139		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.05921615195144139 | validation: 0.057964882734377436]
	TIME [epoch: 5.76 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05073962117994502		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.05073962117994502 | validation: 0.1274332664903388]
	TIME [epoch: 5.74 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05596526714485864		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.05596526714485864 | validation: 0.05683830411364195]
	TIME [epoch: 5.76 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05703570325227193		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.05703570325227193 | validation: 0.0773444122438711]
	TIME [epoch: 5.75 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0757074111800434		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.0757074111800434 | validation: 0.059654652179622535]
	TIME [epoch: 5.75 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051745313437488116		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.051745313437488116 | validation: 0.07165018655766553]
	TIME [epoch: 5.75 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05009436289083948		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.05009436289083948 | validation: 0.08526310621070594]
	TIME [epoch: 5.79 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0734182198063216		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.0734182198063216 | validation: 0.10850870642123366]
	TIME [epoch: 5.76 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08114284964837803		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.08114284964837803 | validation: 0.06596169324215655]
	TIME [epoch: 5.74 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09624485781668074		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.09624485781668074 | validation: 0.06481977425691013]
	TIME [epoch: 5.75 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060104343696702096		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.060104343696702096 | validation: 0.10210611400757462]
	TIME [epoch: 5.74 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07225968757132538		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.07225968757132538 | validation: 0.07315369242166936]
	TIME [epoch: 5.75 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06494231670711409		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.06494231670711409 | validation: 0.04143683515270144]
	TIME [epoch: 5.75 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07092467800448508		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.07092467800448508 | validation: 0.05017487948921207]
	TIME [epoch: 5.77 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07627470090864438		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.07627470090864438 | validation: 0.09334434645653954]
	TIME [epoch: 5.75 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07003168497945252		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.07003168497945252 | validation: 0.07412520055938754]
	TIME [epoch: 5.75 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06137458568727659		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.06137458568727659 | validation: 0.07061237264375393]
	TIME [epoch: 5.75 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05746830680168655		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.05746830680168655 | validation: 0.04822797098949977]
	TIME [epoch: 5.75 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05794780201655495		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.05794780201655495 | validation: 0.07097587472930694]
	TIME [epoch: 5.75 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11168737952262242		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.11168737952262242 | validation: 0.08431634468371325]
	TIME [epoch: 5.79 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06550808346406227		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.06550808346406227 | validation: 0.06802289885352508]
	TIME [epoch: 5.76 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06158625697440959		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.06158625697440959 | validation: 0.09099072954936233]
	TIME [epoch: 5.75 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07815308835591003		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.07815308835591003 | validation: 0.07602115743699214]
	TIME [epoch: 5.73 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0729864171005137		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.0729864171005137 | validation: 0.09593986623589369]
	TIME [epoch: 5.74 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06111495163367008		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.06111495163367008 | validation: 0.05738351382914617]
	TIME [epoch: 5.73 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05591238683376972		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.05591238683376972 | validation: 0.08687546539747469]
	TIME [epoch: 5.76 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055306105796750216		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.055306105796750216 | validation: 0.07926622549326673]
	TIME [epoch: 5.75 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06748806050758156		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.06748806050758156 | validation: 0.12925801517588492]
	TIME [epoch: 5.74 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07587999849168528		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.07587999849168528 | validation: 0.06269408548960495]
	TIME [epoch: 5.74 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053662602302208956		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.053662602302208956 | validation: 0.0606054852352399]
	TIME [epoch: 5.74 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0734866528454983		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.0734866528454983 | validation: 0.09256043230836818]
	TIME [epoch: 5.75 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0708272911342129		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.0708272911342129 | validation: 0.06646890719190818]
	TIME [epoch: 5.74 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04881197784762863		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.04881197784762863 | validation: 0.0760383669631293]
	TIME [epoch: 5.8 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06085442766177134		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.06085442766177134 | validation: 0.08283969211665007]
	TIME [epoch: 5.74 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06665125736592316		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.06665125736592316 | validation: 0.11138356728658387]
	TIME [epoch: 5.74 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06085934103771547		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.06085934103771547 | validation: 0.07463942091410124]
	TIME [epoch: 5.74 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10462758121239248		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.10462758121239248 | validation: 0.058395472629091234]
	TIME [epoch: 5.73 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04901636634726078		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.04901636634726078 | validation: 0.06566555413200469]
	TIME [epoch: 5.75 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07111730963192128		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.07111730963192128 | validation: 0.12449529804354356]
	TIME [epoch: 5.76 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07413289307536033		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.07413289307536033 | validation: 0.08169736406183219]
	TIME [epoch: 5.77 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05768699643158917		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.05768699643158917 | validation: 0.03615738161064082]
	TIME [epoch: 5.75 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0784044164918548		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.0784044164918548 | validation: 0.04929228666909974]
	TIME [epoch: 5.75 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05117912145906632		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.05117912145906632 | validation: 0.07717001686421393]
	TIME [epoch: 5.75 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06965718033512974		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.06965718033512974 | validation: 0.0965292141891634]
	TIME [epoch: 5.75 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08617465652482859		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.08617465652482859 | validation: 0.04036376517330413]
	TIME [epoch: 5.75 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058914886411396264		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.058914886411396264 | validation: 0.08856382099598807]
	TIME [epoch: 5.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07991027090386044		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.07991027090386044 | validation: 0.11260524652178776]
	TIME [epoch: 5.76 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07051634617193756		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.07051634617193756 | validation: 0.1172075746538492]
	TIME [epoch: 5.75 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08050698243669005		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.08050698243669005 | validation: 0.04683265007942544]
	TIME [epoch: 5.75 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04939334321825338		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.04939334321825338 | validation: 0.045270914158269886]
	TIME [epoch: 5.75 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07485529263229804		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.07485529263229804 | validation: 0.07255507949137767]
	TIME [epoch: 5.75 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06213648693737469		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.06213648693737469 | validation: 0.08721507606860213]
	TIME [epoch: 5.78 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07529645519530477		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.07529645519530477 | validation: 0.05318907604066486]
	TIME [epoch: 5.77 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06450211740253019		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.06450211740253019 | validation: 0.047815175993048735]
	TIME [epoch: 5.76 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04975328429241816		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.04975328429241816 | validation: 0.06019474960597176]
	TIME [epoch: 5.75 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565063564095912		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.05565063564095912 | validation: 0.10858135704867639]
	TIME [epoch: 5.74 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08547986857525852		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.08547986857525852 | validation: 0.040299691797287526]
	TIME [epoch: 5.74 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05952138031391295		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.05952138031391295 | validation: 0.06238914066994759]
	TIME [epoch: 5.74 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06756363955398746		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.06756363955398746 | validation: 0.06454825229861813]
	TIME [epoch: 5.78 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049508635412762333		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.049508635412762333 | validation: 0.053090357436886164]
	TIME [epoch: 5.75 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05605178952032927		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.05605178952032927 | validation: 0.0652091836376054]
	TIME [epoch: 5.74 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05371171570061348		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.05371171570061348 | validation: 0.0547429017048743]
	TIME [epoch: 5.73 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06830436676738673		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.06830436676738673 | validation: 0.0806808817533147]
	TIME [epoch: 5.75 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0762605979399122		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.0762605979399122 | validation: 0.09105502070410065]
	TIME [epoch: 5.74 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06275750083827719		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.06275750083827719 | validation: 0.09596995484627556]
	TIME [epoch: 5.77 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06579084824913331		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.06579084824913331 | validation: 0.11014655539719023]
	TIME [epoch: 5.76 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11203551358893288		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.11203551358893288 | validation: 0.04332577351016825]
	TIME [epoch: 5.74 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07998556370768772		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.07998556370768772 | validation: 0.07983119947162544]
	TIME [epoch: 5.74 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06269795920498655		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.06269795920498655 | validation: 0.10826246354118244]
	TIME [epoch: 5.74 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07500946556144844		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.07500946556144844 | validation: 0.057817259739364975]
	TIME [epoch: 5.74 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07886505285885473		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.07886505285885473 | validation: 0.12428406936069779]
	TIME [epoch: 5.74 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06931967742305369		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.06931967742305369 | validation: 0.06687193103092341]
	TIME [epoch: 5.78 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04226708123664839		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.04226708123664839 | validation: 0.05710661387171477]
	TIME [epoch: 5.74 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05516149298686057		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.05516149298686057 | validation: 0.05762381775387972]
	TIME [epoch: 5.74 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04479607499671702		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.04479607499671702 | validation: 0.04916246754215234]
	TIME [epoch: 5.74 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05178659467710299		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.05178659467710299 | validation: 0.13050085631351427]
	TIME [epoch: 5.73 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888186899975045		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.0888186899975045 | validation: 0.11217656825634782]
	TIME [epoch: 5.74 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06883493496239447		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.06883493496239447 | validation: 0.07886162924184437]
	TIME [epoch: 5.77 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06151537546449457		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.06151537546449457 | validation: 0.07303638007017528]
	TIME [epoch: 5.75 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05083459459330897		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.05083459459330897 | validation: 0.0727173416848828]
	TIME [epoch: 5.74 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05465957252236677		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.05465957252236677 | validation: 0.06908699040012951]
	TIME [epoch: 5.74 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04382823878134484		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.04382823878134484 | validation: 0.0448467577135966]
	TIME [epoch: 5.74 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07737922206296877		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.07737922206296877 | validation: 0.06378626853905822]
	TIME [epoch: 5.74 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06890074718490422		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.06890074718490422 | validation: 0.09338568866681535]
	TIME [epoch: 5.74 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06949623639472331		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.06949623639472331 | validation: 0.058352021334459395]
	TIME [epoch: 5.78 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09384067244040198		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.09384067244040198 | validation: 0.055867673567531376]
	TIME [epoch: 5.74 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052446081383404744		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.052446081383404744 | validation: 0.1072493382155247]
	TIME [epoch: 5.75 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08230893926472277		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.08230893926472277 | validation: 0.15228399503109902]
	TIME [epoch: 5.74 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07537664828795645		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.07537664828795645 | validation: 0.08242064019895703]
	TIME [epoch: 5.74 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07471113169201168		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.07471113169201168 | validation: 0.09750222302847414]
	TIME [epoch: 5.74 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09486677816572765		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.09486677816572765 | validation: 0.05410492931731613]
	TIME [epoch: 5.78 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06342793623127535		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.06342793623127535 | validation: 0.04350933529544264]
	TIME [epoch: 5.75 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06325537265162982		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.06325537265162982 | validation: 0.0713155195967868]
	TIME [epoch: 5.74 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07091218959807777		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.07091218959807777 | validation: 0.055229147103621694]
	TIME [epoch: 5.74 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048892331018000466		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.048892331018000466 | validation: 0.05825919517169873]
	TIME [epoch: 5.74 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07257214291722354		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.07257214291722354 | validation: 0.06242160096378686]
	TIME [epoch: 5.74 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06107907644639064		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.06107907644639064 | validation: 0.09529350854868522]
	TIME [epoch: 5.75 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056600069398690014		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.056600069398690014 | validation: 0.044925287521802255]
	TIME [epoch: 5.78 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04579957346430551		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.04579957346430551 | validation: 0.05476471896328294]
	TIME [epoch: 5.74 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07025135064106298		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.07025135064106298 | validation: 0.03916326351636898]
	TIME [epoch: 5.74 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04751056829950725		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.04751056829950725 | validation: 0.0425094847291064]
	TIME [epoch: 5.74 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05490034453237719		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.05490034453237719 | validation: 0.05218712718578562]
	TIME [epoch: 5.74 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05625836807901705		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.05625836807901705 | validation: 0.044026007954629486]
	TIME [epoch: 5.75 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05400486542076203		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.05400486542076203 | validation: 0.04425941063334042]
	TIME [epoch: 5.77 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05563408528580127		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.05563408528580127 | validation: 0.06838266848246442]
	TIME [epoch: 5.76 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05664633919600484		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.05664633919600484 | validation: 0.08993326810187181]
	TIME [epoch: 5.74 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07024578771554346		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.07024578771554346 | validation: 0.07091154590318137]
	TIME [epoch: 5.75 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044963535753721376		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.044963535753721376 | validation: 0.0580869033924577]
	TIME [epoch: 5.75 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062399971949292136		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.062399971949292136 | validation: 0.0429816632750663]
	TIME [epoch: 5.75 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05039963764613875		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.05039963764613875 | validation: 0.04354368698875209]
	TIME [epoch: 5.77 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048639335638812876		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.048639335638812876 | validation: 0.08833721508886878]
	TIME [epoch: 5.76 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061581366795508685		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.061581366795508685 | validation: 0.13394754927634175]
	TIME [epoch: 5.74 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.074010441448683		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.074010441448683 | validation: 0.07566684634221167]
	TIME [epoch: 5.74 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054624881882024634		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.054624881882024634 | validation: 0.035300614137460475]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_977.pth
	Model improved!!!
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053336606320872185		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.053336606320872185 | validation: 0.04115873886572793]
	TIME [epoch: 5.75 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08890906266424599		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.08890906266424599 | validation: 0.09354714047448426]
	TIME [epoch: 5.74 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15217670359732693		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.15217670359732693 | validation: 0.06971961366684497]
	TIME [epoch: 5.78 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06714670127500022		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.06714670127500022 | validation: 0.05104812109930306]
	TIME [epoch: 5.74 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06297436075391538		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.06297436075391538 | validation: 0.05517278752223321]
	TIME [epoch: 5.74 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04511638003715128		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.04511638003715128 | validation: 0.07739793241573296]
	TIME [epoch: 5.75 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05624723001962564		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.05624723001962564 | validation: 0.05794972016165653]
	TIME [epoch: 5.75 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053647471702953434		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.053647471702953434 | validation: 0.06878818480302083]
	TIME [epoch: 5.74 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05439221624979168		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.05439221624979168 | validation: 0.062482839263699026]
	TIME [epoch: 5.75 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07528923642051343		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.07528923642051343 | validation: 0.07007433778065246]
	TIME [epoch: 5.78 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04515626697339703		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.04515626697339703 | validation: 0.055122028919318014]
	TIME [epoch: 5.76 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06128078101031647		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.06128078101031647 | validation: 0.043490026864899244]
	TIME [epoch: 5.75 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05934915482390551		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.05934915482390551 | validation: 0.056919399146684646]
	TIME [epoch: 5.74 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05581502170115481		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.05581502170115481 | validation: 0.07713501611637837]
	TIME [epoch: 5.73 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06295321187221567		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.06295321187221567 | validation: 0.05723982026021235]
	TIME [epoch: 5.74 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06586467811025731		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.06586467811025731 | validation: 0.10291712576028043]
	TIME [epoch: 5.78 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07545154856297095		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.07545154856297095 | validation: 0.11218480161284539]
	TIME [epoch: 5.75 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06159768120583708		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.06159768120583708 | validation: 0.06237610306501533]
	TIME [epoch: 5.74 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058642170382052244		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.058642170382052244 | validation: 0.05615008655950771]
	TIME [epoch: 5.75 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04433773982774599		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.04433773982774599 | validation: 0.06024897353815634]
	TIME [epoch: 5.75 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04757712153606986		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.04757712153606986 | validation: 0.07512004374820698]
	TIME [epoch: 5.73 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05777262842551137		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.05777262842551137 | validation: 0.03453663464303263]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_999.pth
	Model improved!!!
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04423875659759792		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.04423875659759792 | validation: 0.06637343099920498]
	TIME [epoch: 5.77 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056709387414726246		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.056709387414726246 | validation: 0.05553609248744773]
	TIME [epoch: 5.74 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05452595666624853		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.05452595666624853 | validation: 0.07274559953064695]
	TIME [epoch: 5.74 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053950899846387665		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.053950899846387665 | validation: 0.1134793087295698]
	TIME [epoch: 5.74 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07315295040295462		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.07315295040295462 | validation: 0.08385026939656502]
	TIME [epoch: 5.74 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05955183294075446		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.05955183294075446 | validation: 0.06341499996439603]
	TIME [epoch: 5.74 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0702275331503728		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.0702275331503728 | validation: 0.0647532649719456]
	TIME [epoch: 5.78 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05107190019045173		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.05107190019045173 | validation: 0.044916812299136105]
	TIME [epoch: 5.74 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05474660671074503		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.05474660671074503 | validation: 0.04884104108299061]
	TIME [epoch: 5.74 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05495746783326152		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.05495746783326152 | validation: 0.05481440610296323]
	TIME [epoch: 5.74 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08491161198378341		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.08491161198378341 | validation: 0.05775236999265404]
	TIME [epoch: 5.74 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05160547103955494		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.05160547103955494 | validation: 0.05434627949301793]
	TIME [epoch: 5.74 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051757047679976464		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.051757047679976464 | validation: 0.05189962348040931]
	TIME [epoch: 5.76 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0419723014305865		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.0419723014305865 | validation: 0.06267299485356988]
	TIME [epoch: 5.75 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05123933045113516		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.05123933045113516 | validation: 0.06637804387161877]
	TIME [epoch: 5.74 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046722390889701905		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.046722390889701905 | validation: 0.048658072359803906]
	TIME [epoch: 5.74 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04884986060308155		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.04884986060308155 | validation: 0.07284868514756633]
	TIME [epoch: 5.74 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06330161888796992		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.06330161888796992 | validation: 0.08912052253586618]
	TIME [epoch: 5.74 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055711693886118345		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.055711693886118345 | validation: 0.0573006165668445]
	TIME [epoch: 5.74 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04575737526898264		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.04575737526898264 | validation: 0.07154287921534894]
	TIME [epoch: 5.78 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05229983222220693		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.05229983222220693 | validation: 0.06336819180400688]
	TIME [epoch: 5.74 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059533473880566345		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.059533473880566345 | validation: 0.055749719263762244]
	TIME [epoch: 5.74 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04499361394371215		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.04499361394371215 | validation: 0.030915578216075712]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_1022.pth
	Model improved!!!
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06063802606673285		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.06063802606673285 | validation: 0.04200310452067262]
	TIME [epoch: 5.74 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04446895818958671		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.04446895818958671 | validation: 0.039103796897739476]
	TIME [epoch: 5.74 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07014798778431408		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.07014798778431408 | validation: 0.10136605072312904]
	TIME [epoch: 5.77 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06954353879038033		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.06954353879038033 | validation: 0.06976419978151512]
	TIME [epoch: 5.74 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06800025490808763		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.06800025490808763 | validation: 0.058511822808317134]
	TIME [epoch: 5.74 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05133184593443787		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.05133184593443787 | validation: 0.04543761103424511]
	TIME [epoch: 5.74 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04676282434796486		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.04676282434796486 | validation: 0.05314158036205777]
	TIME [epoch: 5.74 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04665314613523998		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.04665314613523998 | validation: 0.05219124759653633]
	TIME [epoch: 5.74 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04947083482830955		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.04947083482830955 | validation: 0.04609199169035753]
	TIME [epoch: 5.75 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053640914146319885		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.053640914146319885 | validation: 0.06419463132282034]
	TIME [epoch: 5.77 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09710016059874324		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.09710016059874324 | validation: 0.06293838009731532]
	TIME [epoch: 5.74 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06139521133201291		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.06139521133201291 | validation: 0.04910194906881595]
	TIME [epoch: 5.74 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04944524538121615		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.04944524538121615 | validation: 0.06324025165668697]
	TIME [epoch: 5.74 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05282387098312131		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.05282387098312131 | validation: 0.05678978755145904]
	TIME [epoch: 5.74 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05337152808175001		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.05337152808175001 | validation: 0.05900816273989234]
	TIME [epoch: 5.74 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647036924569127		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.0647036924569127 | validation: 0.06007690071275994]
	TIME [epoch: 5.77 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0684587755257866		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.0684587755257866 | validation: 0.053530519489846266]
	TIME [epoch: 5.74 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047154407039401894		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.047154407039401894 | validation: 0.07497124953631389]
	TIME [epoch: 5.74 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07759371563256737		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.07759371563256737 | validation: 0.08513262457855071]
	TIME [epoch: 5.74 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06301996099921052		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.06301996099921052 | validation: 0.062012801157987865]
	TIME [epoch: 5.74 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04826001371036742		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.04826001371036742 | validation: 0.0808383233648399]
	TIME [epoch: 5.74 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06252588389148925		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.06252588389148925 | validation: 0.07199289440866384]
	TIME [epoch: 5.75 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05636579096346714		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.05636579096346714 | validation: 0.058177830015636166]
	TIME [epoch: 5.77 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05476060290637148		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.05476060290637148 | validation: 0.05527732725880941]
	TIME [epoch: 5.74 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054600325670014556		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.054600325670014556 | validation: 0.051370834929929464]
	TIME [epoch: 5.74 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05664365634668437		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.05664365634668437 | validation: 0.05148246679984142]
	TIME [epoch: 5.74 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06120427309789263		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.06120427309789263 | validation: 0.059054285923355126]
	TIME [epoch: 5.74 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058228281597117286		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.058228281597117286 | validation: 0.061418653974898575]
	TIME [epoch: 5.74 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057715441438968895		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.057715441438968895 | validation: 0.04621580539558266]
	TIME [epoch: 5.77 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062396411045651023		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.062396411045651023 | validation: 0.06399400252810399]
	TIME [epoch: 5.74 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467190264442679		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.04467190264442679 | validation: 0.052205634247565746]
	TIME [epoch: 5.74 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06550135838923932		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.06550135838923932 | validation: 0.04881287911127338]
	TIME [epoch: 5.74 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043656114096327435		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.043656114096327435 | validation: 0.06318716334315827]
	TIME [epoch: 5.74 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054424349948104564		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.054424349948104564 | validation: 0.06067845685451279]
	TIME [epoch: 5.74 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042691634808337944		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.042691634808337944 | validation: 0.04882132675150373]
	TIME [epoch: 5.75 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0602974378430362		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.0602974378430362 | validation: 0.07965636813542398]
	TIME [epoch: 5.77 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05687180393129597		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.05687180393129597 | validation: 0.03733577853176938]
	TIME [epoch: 5.74 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047471913415234726		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.047471913415234726 | validation: 0.048271420589486275]
	TIME [epoch: 5.74 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043201526370333185		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.043201526370333185 | validation: 0.054386827786265676]
	TIME [epoch: 5.74 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04826498970165852		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.04826498970165852 | validation: 0.07137661376609028]
	TIME [epoch: 5.74 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05178340662298471		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.05178340662298471 | validation: 0.06455869889470908]
	TIME [epoch: 5.73 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047470746366742866		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.047470746366742866 | validation: 0.06617238500266318]
	TIME [epoch: 5.77 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08336351618663947		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.08336351618663947 | validation: 0.12047033082944097]
	TIME [epoch: 5.75 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08095914988870573		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.08095914988870573 | validation: 0.06264508007217395]
	TIME [epoch: 5.74 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054102871086406414		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.054102871086406414 | validation: 0.05199884633728814]
	TIME [epoch: 5.74 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04229366394883157		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.04229366394883157 | validation: 0.059188221870068836]
	TIME [epoch: 5.74 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04974100921346203		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.04974100921346203 | validation: 0.04841275633405959]
	TIME [epoch: 5.73 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04369802701336132		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.04369802701336132 | validation: 0.07642439260199471]
	TIME [epoch: 5.75 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051442468979802466		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.051442468979802466 | validation: 0.09149600195080687]
	TIME [epoch: 5.76 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04923925144778946		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.04923925144778946 | validation: 0.055251143967197325]
	TIME [epoch: 5.76 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04092876496260349		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.04092876496260349 | validation: 0.041862976709091615]
	TIME [epoch: 5.74 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05425146683317608		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.05425146683317608 | validation: 0.056477724264086204]
	TIME [epoch: 5.74 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04885512785387335		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.04885512785387335 | validation: 0.04188041547541294]
	TIME [epoch: 5.73 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036763757153231005		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.036763757153231005 | validation: 0.04305043766749762]
	TIME [epoch: 5.74 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03964410588717529		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.03964410588717529 | validation: 0.03873298496141074]
	TIME [epoch: 5.78 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040722090541623346		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.040722090541623346 | validation: 0.057685951189017856]
	TIME [epoch: 5.75 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05259075459250842		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.05259075459250842 | validation: 0.05656425906903651]
	TIME [epoch: 5.74 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05013506974764852		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.05013506974764852 | validation: 0.03829125330976299]
	TIME [epoch: 5.74 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04886940576766773		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.04886940576766773 | validation: 0.03928539702555574]
	TIME [epoch: 5.74 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059561593737191304		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.059561593737191304 | validation: 0.03892776077462704]
	TIME [epoch: 5.73 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052998079839443636		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.052998079839443636 | validation: 0.07007062750043291]
	TIME [epoch: 5.75 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05964880289760601		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.05964880289760601 | validation: 0.048139812788164225]
	TIME [epoch: 5.77 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04214824620260966		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.04214824620260966 | validation: 0.0559645431313805]
	TIME [epoch: 5.74 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044269290958572974		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.044269290958572974 | validation: 0.04175186008577745]
	TIME [epoch: 5.74 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03843197503925305		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.03843197503925305 | validation: 0.049601389901115185]
	TIME [epoch: 5.74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04680441400706239		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.04680441400706239 | validation: 0.03890662564695467]
	TIME [epoch: 5.74 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04651195961568166		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.04651195961568166 | validation: 0.05819689701860057]
	TIME [epoch: 5.74 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05678039699271967		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.05678039699271967 | validation: 0.12791684307942883]
	TIME [epoch: 5.78 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10509240046067747		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.10509240046067747 | validation: 0.07862622170502145]
	TIME [epoch: 5.75 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05310735611382779		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.05310735611382779 | validation: 0.07157137056016766]
	TIME [epoch: 5.74 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0520822378942896		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.0520822378942896 | validation: 0.05093551867963756]
	TIME [epoch: 5.74 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05770883078041016		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.05770883078041016 | validation: 0.06064003014679387]
	TIME [epoch: 5.74 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045734935045597516		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.045734935045597516 | validation: 0.04675057085023609]
	TIME [epoch: 5.75 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04640824893728539		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.04640824893728539 | validation: 0.07038594077956002]
	TIME [epoch: 5.77 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05234230610604507		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.05234230610604507 | validation: 0.0680382068025563]
	TIME [epoch: 5.78 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05772381703512475		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.05772381703512475 | validation: 0.0530406450180347]
	TIME [epoch: 5.74 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04028088166120769		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.04028088166120769 | validation: 0.03926260347034382]
	TIME [epoch: 5.75 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048236930313682466		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.048236930313682466 | validation: 0.06726760579969848]
	TIME [epoch: 5.74 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590801977924685		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.04590801977924685 | validation: 0.0564992190590066]
	TIME [epoch: 5.74 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05699733545602073		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.05699733545602073 | validation: 0.06904309546089142]
	TIME [epoch: 5.74 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07082158864877397		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.07082158864877397 | validation: 0.058988343529766056]
	TIME [epoch: 5.78 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07177622087152315		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.07177622087152315 | validation: 0.05628205928828436]
	TIME [epoch: 5.76 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04981378156221736		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.04981378156221736 | validation: 0.05732150487108964]
	TIME [epoch: 5.75 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048003281274738976		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.048003281274738976 | validation: 0.05033334171077693]
	TIME [epoch: 5.75 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03920019060989545		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.03920019060989545 | validation: 0.05411425930139707]
	TIME [epoch: 5.74 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0433884721182269		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.0433884721182269 | validation: 0.0510982130818158]
	TIME [epoch: 5.75 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04935892072424613		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.04935892072424613 | validation: 0.054355818792924955]
	TIME [epoch: 5.77 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04958744732523306		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.04958744732523306 | validation: 0.08221010824894923]
	TIME [epoch: 5.75 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06560772975041243		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.06560772975041243 | validation: 0.049377595209976664]
	TIME [epoch: 5.74 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04420849140384808		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.04420849140384808 | validation: 0.05167488834197521]
	TIME [epoch: 5.74 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04413343593229053		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.04413343593229053 | validation: 0.060460307657536794]
	TIME [epoch: 5.74 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04457204454790882		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.04457204454790882 | validation: 0.060135542779082146]
	TIME [epoch: 5.74 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03908103018643427		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.03908103018643427 | validation: 0.07252929723765715]
	TIME [epoch: 5.74 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05007692980048735		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.05007692980048735 | validation: 0.05293886308059178]
	TIME [epoch: 5.78 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04424094763496045		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.04424094763496045 | validation: 0.0593498497771291]
	TIME [epoch: 5.74 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046387478056618026		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.046387478056618026 | validation: 0.05056493690445035]
	TIME [epoch: 5.75 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044851592068665465		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.044851592068665465 | validation: 0.05595660532823497]
	TIME [epoch: 5.75 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04365034640769451		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.04365034640769451 | validation: 0.055573374828934985]
	TIME [epoch: 5.75 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04235755728001167		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.04235755728001167 | validation: 0.06554124138940556]
	TIME [epoch: 5.75 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054133615336775534		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.054133615336775534 | validation: 0.07215319858183976]
	TIME [epoch: 5.77 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049612753289270964		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.049612753289270964 | validation: 0.06890993084138859]
	TIME [epoch: 5.77 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05141599018862678		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.05141599018862678 | validation: 0.07152242340580037]
	TIME [epoch: 5.74 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054784463908848724		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.054784463908848724 | validation: 0.05166465803315788]
	TIME [epoch: 5.75 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04679243650426766		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.04679243650426766 | validation: 0.06082143046136159]
	TIME [epoch: 5.75 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04508006939560322		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.04508006939560322 | validation: 0.05571998703246681]
	TIME [epoch: 5.76 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05131038993327271		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.05131038993327271 | validation: 0.0523507836592991]
	TIME [epoch: 5.74 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042915799787542924		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.042915799787542924 | validation: 0.04486010465221718]
	TIME [epoch: 5.78 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05185444218087723		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.05185444218087723 | validation: 0.03554457085772017]
	TIME [epoch: 5.76 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041191362441448075		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.041191362441448075 | validation: 0.05171030334649119]
	TIME [epoch: 5.75 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045557783752483955		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.045557783752483955 | validation: 0.0580908551332722]
	TIME [epoch: 5.75 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05592525758519427		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.05592525758519427 | validation: 0.05446819347668717]
	TIME [epoch: 5.75 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04424428207179885		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.04424428207179885 | validation: 0.044709990195516344]
	TIME [epoch: 5.75 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04355289171282581		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.04355289171282581 | validation: 0.043385074796162756]
	TIME [epoch: 5.78 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04383374037479252		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.04383374037479252 | validation: 0.05833906052891466]
	TIME [epoch: 5.77 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06608348122837941		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.06608348122837941 | validation: 0.04819176771482668]
	TIME [epoch: 5.76 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04626979511721787		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.04626979511721787 | validation: 0.04939559736329505]
	TIME [epoch: 5.76 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044254982095829565		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.044254982095829565 | validation: 0.06693515140272527]
	TIME [epoch: 5.75 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045581165075414085		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.045581165075414085 | validation: 0.06208851771605121]
	TIME [epoch: 5.76 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05195777659614411		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.05195777659614411 | validation: 0.039074936061679694]
	TIME [epoch: 5.76 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834174007685819		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.03834174007685819 | validation: 0.054212156410684643]
	TIME [epoch: 5.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048709876098401036		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.048709876098401036 | validation: 0.044768167881279367]
	TIME [epoch: 5.76 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04583787290499847		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.04583787290499847 | validation: 0.054813435667763324]
	TIME [epoch: 5.76 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04623060107312607		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.04623060107312607 | validation: 0.054052585833340355]
	TIME [epoch: 5.76 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04418234383594589		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.04418234383594589 | validation: 0.05849109129251416]
	TIME [epoch: 5.76 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05498879171532055		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.05498879171532055 | validation: 0.05408428010616646]
	TIME [epoch: 5.76 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04559867478933481		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.04559867478933481 | validation: 0.06153011007182206]
	TIME [epoch: 5.79 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046838681229354306		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.046838681229354306 | validation: 0.036335943124639974]
	TIME [epoch: 5.77 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05910470184503661		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.05910470184503661 | validation: 0.04406412986307689]
	TIME [epoch: 5.76 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044366884168284486		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.044366884168284486 | validation: 0.041619932802505394]
	TIME [epoch: 5.76 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042683087735046754		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.042683087735046754 | validation: 0.049563275081915714]
	TIME [epoch: 5.76 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03885593332597689		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.03885593332597689 | validation: 0.05955464893366912]
	TIME [epoch: 5.76 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04538871812723333		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.04538871812723333 | validation: 0.03724165261486622]
	TIME [epoch: 5.78 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04851448131186975		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.04851448131186975 | validation: 0.05270072058470011]
	TIME [epoch: 5.78 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05975304493160592		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.05975304493160592 | validation: 0.038087125403779]
	TIME [epoch: 5.76 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04502719014639676		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.04502719014639676 | validation: 0.04835622614139599]
	TIME [epoch: 5.75 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04423823007936938		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.04423823007936938 | validation: 0.05444666413717164]
	TIME [epoch: 5.73 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04995613464607489		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.04995613464607489 | validation: 0.04162322969252198]
	TIME [epoch: 5.75 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045389737275768394		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.045389737275768394 | validation: 0.03914381567437604]
	TIME [epoch: 5.75 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04926310306243199		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.04926310306243199 | validation: 0.05263964319897306]
	TIME [epoch: 5.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04095617209555305		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.04095617209555305 | validation: 0.057564524240044296]
	TIME [epoch: 5.76 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047340988420435305		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.047340988420435305 | validation: 0.03894481485364156]
	TIME [epoch: 5.75 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04777290905096589		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.04777290905096589 | validation: 0.06824333323045698]
	TIME [epoch: 5.75 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05352254671025324		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.05352254671025324 | validation: 0.045177893305475544]
	TIME [epoch: 5.75 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046232664782868436		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.046232664782868436 | validation: 0.04413765767676638]
	TIME [epoch: 5.75 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0466538563256262		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.0466538563256262 | validation: 0.05655072658390867]
	TIME [epoch: 5.77 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04843808651943293		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.04843808651943293 | validation: 0.05061078140563675]
	TIME [epoch: 5.77 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040474370389664366		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.040474370389664366 | validation: 0.057619061075513116]
	TIME [epoch: 5.76 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049153909240580114		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.049153909240580114 | validation: 0.0605456417766006]
	TIME [epoch: 5.74 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03791453826418807		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.03791453826418807 | validation: 0.04025501363453352]
	TIME [epoch: 5.73 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04259288701692183		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.04259288701692183 | validation: 0.06641531292439452]
	TIME [epoch: 5.73 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05056072519135123		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.05056072519135123 | validation: 0.06566404803823611]
	TIME [epoch: 5.73 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0458064940556493		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.0458064940556493 | validation: 0.043086288115161624]
	TIME [epoch: 5.78 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04220057980050853		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.04220057980050853 | validation: 0.04900209442279194]
	TIME [epoch: 5.74 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03814500904824493		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.03814500904824493 | validation: 0.05221817789776648]
	TIME [epoch: 5.73 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04065318583054567		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.04065318583054567 | validation: 0.047153017987668466]
	TIME [epoch: 5.73 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042603673861178276		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.042603673861178276 | validation: 0.04175652750278235]
	TIME [epoch: 5.73 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04239782900344309		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.04239782900344309 | validation: 0.054156623730419046]
	TIME [epoch: 5.73 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0731744152875729		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.0731744152875729 | validation: 0.04746271040609242]
	TIME [epoch: 5.75 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04919826784769502		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.04919826784769502 | validation: 0.03740184984358219]
	TIME [epoch: 5.76 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04327382636331386		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.04327382636331386 | validation: 0.02984004456655348]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_1182.pth
	Model improved!!!
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046568666663367966		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.046568666663367966 | validation: 0.03659948517291456]
	TIME [epoch: 5.73 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04023892089629139		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.04023892089629139 | validation: 0.02660192133328181]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r3_20240310_015135/states/model_tr_study202_1184.pth
	Model improved!!!
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044119409755010414		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.044119409755010414 | validation: 0.04854559598418115]
	TIME [epoch: 5.74 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06684683630277412		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.06684683630277412 | validation: 0.06271007450432475]
	TIME [epoch: 5.74 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07247155837775257		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.07247155837775257 | validation: 0.05484728116759208]
	TIME [epoch: 5.79 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04401383360959528		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.04401383360959528 | validation: 0.03158787224754523]
	TIME [epoch: 5.75 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03961252571205395		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.03961252571205395 | validation: 0.036286713533844946]
	TIME [epoch: 5.75 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041495312752090834		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.041495312752090834 | validation: 0.05156205557479645]
	TIME [epoch: 5.73 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040434962820708235		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.040434962820708235 | validation: 0.04948865388830461]
	TIME [epoch: 5.73 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06058385349714844		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.06058385349714844 | validation: 0.04865575842496314]
	TIME [epoch: 5.73 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051106775814385635		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.051106775814385635 | validation: 0.05007055331926601]
	TIME [epoch: 5.76 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046859058306328416		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.046859058306328416 | validation: 0.04747493282040096]
	TIME [epoch: 5.75 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05107853878894198		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.05107853878894198 | validation: 0.05128945036832831]
	TIME [epoch: 5.73 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0408573504800052		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.0408573504800052 | validation: 0.03951786339895921]
	TIME [epoch: 5.74 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049903705172699986		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.049903705172699986 | validation: 0.05524335475986554]
	TIME [epoch: 5.73 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04310180512859944		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.04310180512859944 | validation: 0.06962955379611596]
	TIME [epoch: 5.73 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05756843305175337		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.05756843305175337 | validation: 0.056099009899475694]
	TIME [epoch: 5.74 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0395918994273815		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.0395918994273815 | validation: 0.03814446805660149]
	TIME [epoch: 5.78 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049201390239468665		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.049201390239468665 | validation: 0.07618431178547208]
	TIME [epoch: 5.73 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04734084555463696		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.04734084555463696 | validation: 0.03881138688649407]
	TIME [epoch: 5.73 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04835619039726273		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.04835619039726273 | validation: 0.04671855450115722]
	TIME [epoch: 5.73 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04986909535834695		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.04986909535834695 | validation: 0.049459115943932444]
	TIME [epoch: 5.73 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046522442305303065		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.046522442305303065 | validation: 0.04109069297497059]
	TIME [epoch: 5.73 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048935884706268806		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.048935884706268806 | validation: 0.05131174243314389]
	TIME [epoch: 5.76 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05301810873326511		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.05301810873326511 | validation: 0.040715478833908136]
	TIME [epoch: 5.75 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04009884431010535		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.04009884431010535 | validation: 0.03425911968625568]
	TIME [epoch: 5.74 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03868480628533341		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.03868480628533341 | validation: 0.039511849801918394]
	TIME [epoch: 5.73 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033836862512134684		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.033836862512134684 | validation: 0.046765672093419454]
	TIME [epoch: 5.73 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04220581764800809		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.04220581764800809 | validation: 0.03970141733255894]
	TIME [epoch: 5.73 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046658880857486235		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.046658880857486235 | validation: 0.03788251643250959]
	TIME [epoch: 5.73 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040512462965541944		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.040512462965541944 | validation: 0.0548143767730986]
	TIME [epoch: 5.79 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04960690730433674		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.04960690730433674 | validation: 0.045379122340667565]
	TIME [epoch: 5.74 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03871071851391568		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.03871071851391568 | validation: 0.05700808016360772]
	TIME [epoch: 5.73 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05589480923351485		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.05589480923351485 | validation: 0.05617071018179751]
	TIME [epoch: 5.73 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04428640280531143		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.04428640280531143 | validation: 0.043976617478495204]
	TIME [epoch: 5.73 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04452090147209456		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.04452090147209456 | validation: 0.04609583902570703]
	TIME [epoch: 5.73 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04364164719820641		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.04364164719820641 | validation: 0.04793273753155025]
	TIME [epoch: 5.76 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0373266010657819		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.0373266010657819 | validation: 0.050352333304113206]
	TIME [epoch: 5.75 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04583877639997504		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.04583877639997504 | validation: 0.06087609948090483]
	TIME [epoch: 5.74 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04478057760447738		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.04478057760447738 | validation: 0.04443253531571312]
	TIME [epoch: 5.74 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05023921100579867		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.05023921100579867 | validation: 0.05411564970735182]
	TIME [epoch: 5.74 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04242332557499542		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.04242332557499542 | validation: 0.04314536982871056]
	TIME [epoch: 5.74 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040539104845955985		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.040539104845955985 | validation: 0.04202839145385017]
	TIME [epoch: 5.74 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036030351819853396		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.036030351819853396 | validation: 0.048822018137564406]
	TIME [epoch: 5.78 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04717744398649989		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.04717744398649989 | validation: 0.07512152025591977]
	TIME [epoch: 5.74 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05730421313050454		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.05730421313050454 | validation: 0.045522091674015275]
	TIME [epoch: 5.74 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03573205290130995		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.03573205290130995 | validation: 0.055229479216784956]
	TIME [epoch: 5.74 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04061981624395536		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.04061981624395536 | validation: 0.0459743862492705]
	TIME [epoch: 5.74 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0341497928074389		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.0341497928074389 | validation: 0.06313607944161198]
	TIME [epoch: 5.76 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04557983513753311		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.04557983513753311 | validation: 0.07181708109031405]
	TIME [epoch: 5.8 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06158619110844629		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.06158619110844629 | validation: 0.07177150123250357]
	TIME [epoch: 5.76 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050228873043101405		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.050228873043101405 | validation: 0.05082933905743735]
	TIME [epoch: 5.74 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04002627577445532		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.04002627577445532 | validation: 0.04674241936061371]
	TIME [epoch: 5.74 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042325518945114826		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.042325518945114826 | validation: 0.04326431672695739]
	TIME [epoch: 5.74 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047668185433532656		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.047668185433532656 | validation: 0.044025659283999034]
	TIME [epoch: 5.74 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04155388826140073		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.04155388826140073 | validation: 0.050747814514120256]
	TIME [epoch: 5.75 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590207795404636		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.04590207795404636 | validation: 0.04457665152994098]
	TIME [epoch: 5.77 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044519731634968064		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.044519731634968064 | validation: 0.03981360116423618]
	TIME [epoch: 5.74 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042077849156749766		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.042077849156749766 | validation: 0.05949051053978554]
	TIME [epoch: 5.74 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0452309754614339		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.0452309754614339 | validation: 0.06387486224413871]
	TIME [epoch: 5.74 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05271199800416469		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.05271199800416469 | validation: 0.05391176235037403]
	TIME [epoch: 5.74 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04323121661022928		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.04323121661022928 | validation: 0.06585827690233739]
	TIME [epoch: 5.74 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04051186352042703		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.04051186352042703 | validation: 0.05706892719510702]
	TIME [epoch: 5.8 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038625702758098554		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.038625702758098554 | validation: 0.05718546161616972]
	TIME [epoch: 5.76 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04439537168893291		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.04439537168893291 | validation: 0.053568898047004564]
	TIME [epoch: 5.76 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045475256150406526		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.045475256150406526 | validation: 0.04968112519731013]
	TIME [epoch: 5.76 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04712678780281692		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.04712678780281692 | validation: 0.05924264974163927]
	TIME [epoch: 5.76 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04282148646238301		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.04282148646238301 | validation: 0.05283404771619487]
	TIME [epoch: 5.76 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04574310113586209		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.04574310113586209 | validation: 0.03121148078228189]
	TIME [epoch: 5.77 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041495301162296855		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.041495301162296855 | validation: 0.04901057205196262]
	TIME [epoch: 5.79 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04498995574491449		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.04498995574491449 | validation: 0.03992768785506976]
	TIME [epoch: 5.76 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04119446671585922		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.04119446671585922 | validation: 0.03445001087061958]
	TIME [epoch: 5.76 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04178975327414866		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.04178975327414866 | validation: 0.034742979053160136]
	TIME [epoch: 5.76 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03888440665341368		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.03888440665341368 | validation: 0.04336137609701445]
	TIME [epoch: 5.76 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0517179091069144		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.0517179091069144 | validation: 0.0504646914559976]
	TIME [epoch: 5.76 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045759928319721935		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.045759928319721935 | validation: 0.051858224547571066]
	TIME [epoch: 5.8 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04601666276424757		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.04601666276424757 | validation: 0.045595643058697906]
	TIME [epoch: 5.77 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04210873647422369		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.04210873647422369 | validation: 0.05050673564054502]
	TIME [epoch: 5.77 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03956562885403378		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.03956562885403378 | validation: 0.05465722288095414]
	TIME [epoch: 5.76 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04802875280343331		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.04802875280343331 | validation: 0.05389013737292633]
	TIME [epoch: 5.77 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041526274629657536		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.041526274629657536 | validation: 0.059563170330992427]
	TIME [epoch: 5.77 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0405430390822369		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.0405430390822369 | validation: 0.066709945088201]
	TIME [epoch: 5.78 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0485539617512956		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.0485539617512956 | validation: 0.0553328485117631]
	TIME [epoch: 5.79 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04002396095197596		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.04002396095197596 | validation: 0.04835922885261608]
	TIME [epoch: 5.77 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04042473686925271		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.04042473686925271 | validation: 0.05262322051102965]
	TIME [epoch: 5.76 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044622842475768816		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.044622842475768816 | validation: 0.059066604779200296]
	TIME [epoch: 5.76 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061640919274006445		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.061640919274006445 | validation: 0.07172948447528377]
	TIME [epoch: 5.76 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05141608356765115		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.05141608356765115 | validation: 0.04965810429174029]
	TIME [epoch: 5.76 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04220449478323076		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.04220449478323076 | validation: 0.04714248585670352]
	TIME [epoch: 5.8 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040138855142842336		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.040138855142842336 | validation: 0.04563154874183224]
	TIME [epoch: 5.77 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04719006935797083		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.04719006935797083 | validation: 0.049114495339945344]
	TIME [epoch: 5.77 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04622702086084905		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.04622702086084905 | validation: 0.044243888331316365]
	TIME [epoch: 5.76 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040490649713926324		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.040490649713926324 | validation: 0.04677680242778944]
	TIME [epoch: 5.75 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037489571429188365		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.037489571429188365 | validation: 0.041749222703273504]
	TIME [epoch: 5.76 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042027216193378535		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.042027216193378535 | validation: 0.06804369017017335]
	TIME [epoch: 5.79 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0569351894274019		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.0569351894274019 | validation: 0.056407888993923995]
	TIME [epoch: 5.77 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040513980005041486		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.040513980005041486 | validation: 0.058466688591687195]
	TIME [epoch: 5.77 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0461765030778382		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.0461765030778382 | validation: 0.07821402787409511]
	TIME [epoch: 5.76 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05530727807238014		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.05530727807238014 | validation: 0.08963671779821035]
	TIME [epoch: 5.76 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04847099049515852		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.04847099049515852 | validation: 0.06378620816844713]
	TIME [epoch: 5.76 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036921196459043945		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.036921196459043945 | validation: 0.056113539364432814]
	TIME [epoch: 5.76 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04636385649183959		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.04636385649183959 | validation: 0.07033252690205317]
	TIME [epoch: 5.8 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049026743033283145		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.049026743033283145 | validation: 0.05677927420696413]
	TIME [epoch: 5.76 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038779147501692354		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.038779147501692354 | validation: 0.03738009146994542]
	TIME [epoch: 5.76 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03733528675211717		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.03733528675211717 | validation: 0.032935383204886495]
	TIME [epoch: 5.76 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041933250572777254		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.041933250572777254 | validation: 0.06181065331926604]
	TIME [epoch: 5.76 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04675961967940456		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.04675961967940456 | validation: 0.05306346973555774]
	TIME [epoch: 5.76 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04149766211678329		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.04149766211678329 | validation: 0.04703827689693329]
	TIME [epoch: 5.78 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032235022613696825		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.032235022613696825 | validation: 0.04352024795227852]
	TIME [epoch: 5.78 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03881250239708814		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.03881250239708814 | validation: 0.05316893601906319]
	TIME [epoch: 5.76 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03524007967571371		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.03524007967571371 | validation: 0.043495122644623394]
	TIME [epoch: 5.76 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038418031168157965		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.038418031168157965 | validation: 0.04665220999265979]
	TIME [epoch: 5.75 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036968858697129306		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.036968858697129306 | validation: 0.04240278347396277]
	TIME [epoch: 5.75 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04602785257611255		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.04602785257611255 | validation: 0.06229935556690717]
	TIME [epoch: 5.76 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04643904892759446		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.04643904892759446 | validation: 0.05169465221558785]
	TIME [epoch: 5.78 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044563562670604795		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.044563562670604795 | validation: 0.0465884573240083]
	TIME [epoch: 5.76 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04098006339272871		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.04098006339272871 | validation: 0.05115436149129831]
	TIME [epoch: 5.74 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04501445861025227		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.04501445861025227 | validation: 0.04438266819414434]
	TIME [epoch: 5.75 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04258019506071849		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.04258019506071849 | validation: 0.05456494433196169]
	TIME [epoch: 5.75 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04545327663216532		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.04545327663216532 | validation: 0.056857608465140645]
	TIME [epoch: 5.75 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05310068585682252		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.05310068585682252 | validation: 0.05960687123382948]
	TIME [epoch: 5.78 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04718495695971662		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.04718495695971662 | validation: 0.05819592163413625]
	TIME [epoch: 5.76 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041174245252556814		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.041174245252556814 | validation: 0.05229750060417537]
	TIME [epoch: 5.75 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04035228714011642		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.04035228714011642 | validation: 0.05482121397754411]
	TIME [epoch: 5.75 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042993007165695124		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.042993007165695124 | validation: 0.05149686652324647]
	TIME [epoch: 5.75 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04135355825575899		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.04135355825575899 | validation: 0.05174976529519171]
	TIME [epoch: 5.74 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039846566459504865		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.039846566459504865 | validation: 0.049030820597204886]
	TIME [epoch: 5.77 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038375854275924715		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.038375854275924715 | validation: 0.05553705695577842]
	TIME [epoch: 5.76 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04296314430263667		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.04296314430263667 | validation: 0.05387879479619084]
	TIME [epoch: 5.75 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03872644018914633		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.03872644018914633 | validation: 0.051784879750027456]
	TIME [epoch: 5.75 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04067969614434775		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.04067969614434775 | validation: 0.06830957829563093]
	TIME [epoch: 5.75 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04633947708428823		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.04633947708428823 | validation: 0.07107311422307229]
	TIME [epoch: 5.75 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05080819426533202		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.05080819426533202 | validation: 0.06869033919304196]
	TIME [epoch: 5.74 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04233729500590046		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.04233729500590046 | validation: 0.0544270929451751]
	TIME [epoch: 5.79 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040037412420989855		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.040037412420989855 | validation: 0.047455990228244475]
	TIME [epoch: 5.74 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037089302992803504		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.037089302992803504 | validation: 0.04320640826656866]
	TIME [epoch: 5.73 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039319510252692765		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.039319510252692765 | validation: 0.047412112189338516]
	TIME [epoch: 5.73 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039461979126328754		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.039461979126328754 | validation: 0.05464542470205385]
	TIME [epoch: 5.75 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04340977703335845		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.04340977703335845 | validation: 0.038574254990142935]
	TIME [epoch: 5.75 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04846646421617365		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.04846646421617365 | validation: 0.035523861135917566]
	TIME [epoch: 5.77 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04164374747735874		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.04164374747735874 | validation: 0.03888357536890233]
	TIME [epoch: 5.78 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0423514295650756		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.0423514295650756 | validation: 0.03965335346890349]
	TIME [epoch: 5.76 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037410016570361054		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.037410016570361054 | validation: 0.04010652064577313]
	TIME [epoch: 5.75 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037117666594748966		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.037117666594748966 | validation: 0.059434346786129]
	TIME [epoch: 5.75 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04624732734689352		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.04624732734689352 | validation: 0.05657524166758932]
	TIME [epoch: 5.76 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048305980275572126		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.048305980275572126 | validation: 0.059009120902985636]
	TIME [epoch: 5.75 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04808134519781335		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.04808134519781335 | validation: 0.053893285971537315]
	TIME [epoch: 5.8 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041708399511066904		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.041708399511066904 | validation: 0.04955911595086738]
	TIME [epoch: 5.76 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03794567267598531		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.03794567267598531 | validation: 0.03863898810415807]
	TIME [epoch: 5.76 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04260701853473738		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.04260701853473738 | validation: 0.04229214490455067]
	TIME [epoch: 5.76 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035369846097509504		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.035369846097509504 | validation: 0.04863566514553519]
	TIME [epoch: 5.76 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04539213486075849		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.04539213486075849 | validation: 0.04471273977957514]
	TIME [epoch: 5.75 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03917497088995263		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.03917497088995263 | validation: 0.041766009122384616]
	TIME [epoch: 5.77 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036587866008709426		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.036587866008709426 | validation: 0.04258727029211274]
	TIME [epoch: 5.76 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03619475960952624		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.03619475960952624 | validation: 0.05014998754369399]
	TIME [epoch: 5.76 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037668421614940634		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.037668421614940634 | validation: 0.04319283233923276]
	TIME [epoch: 5.76 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03902865330890051		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.03902865330890051 | validation: 0.03883390621492336]
	TIME [epoch: 5.76 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03942153349935606		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.03942153349935606 | validation: 0.0423311459140096]
	TIME [epoch: 5.75 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04235455712167471		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.04235455712167471 | validation: 0.049065069996501356]
	TIME [epoch: 5.76 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03576086319268071		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.03576086319268071 | validation: 0.044395091386224106]
	TIME [epoch: 5.79 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03586777164405755		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.03586777164405755 | validation: 0.049522501238295734]
	TIME [epoch: 5.75 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04347472795938472		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.04347472795938472 | validation: 0.059136598433758854]
	TIME [epoch: 5.76 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04850929169268389		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.04850929169268389 | validation: 0.05634126334100183]
	TIME [epoch: 5.75 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042834614916836315		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.042834614916836315 | validation: 0.05553588335810172]
	TIME [epoch: 5.73 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041160811607271336		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.041160811607271336 | validation: 0.06053903130251993]
	TIME [epoch: 5.76 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04010472495773054		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.04010472495773054 | validation: 0.06495789838863378]
	TIME [epoch: 5.78 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03923273031496331		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.03923273031496331 | validation: 0.06049163731171239]
	TIME [epoch: 5.77 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0405392552880861		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.0405392552880861 | validation: 0.05265880648006409]
	TIME [epoch: 5.75 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03635955014013923		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.03635955014013923 | validation: 0.05399027859020868]
	TIME [epoch: 5.76 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036766175970416655		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.036766175970416655 | validation: 0.0501547899417307]
	TIME [epoch: 5.75 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03662012755201678		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.03662012755201678 | validation: 0.05182981206681451]
	TIME [epoch: 5.73 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032715097141935094		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.032715097141935094 | validation: 0.044051500287801255]
	TIME [epoch: 5.75 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834349408503251		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.03834349408503251 | validation: 0.048556556495757346]
	TIME [epoch: 5.8 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04048761089246273		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.04048761089246273 | validation: 0.054805762332907244]
	TIME [epoch: 5.74 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03837988323051532		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.03837988323051532 | validation: 0.05428942116940855]
	TIME [epoch: 5.75 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03370409402372351		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.03370409402372351 | validation: 0.043221656803356885]
	TIME [epoch: 5.74 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03647065661435725		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.03647065661435725 | validation: 0.04765188486631562]
	TIME [epoch: 5.74 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03414495369972316		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.03414495369972316 | validation: 0.05277352190545098]
	TIME [epoch: 5.73 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03939382492053026		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.03939382492053026 | validation: 0.04625975573699535]
	TIME [epoch: 5.77 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03296678959488309		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.03296678959488309 | validation: 0.04490482088250114]
	TIME [epoch: 5.75 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03742212814911252		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.03742212814911252 | validation: 0.045868369185386344]
	TIME [epoch: 5.74 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03505377984453112		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.03505377984453112 | validation: 0.04658567329090378]
	TIME [epoch: 5.74 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044938935157929655		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.044938935157929655 | validation: 0.057503002390265935]
	TIME [epoch: 5.73 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04177066057543852		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.04177066057543852 | validation: 0.04637568059645686]
	TIME [epoch: 5.75 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04593609026484048		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.04593609026484048 | validation: 0.059388779687049906]
	TIME [epoch: 5.73 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03900845327217932		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.03900845327217932 | validation: 0.03376823337419437]
	TIME [epoch: 5.79 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04049261481902375		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.04049261481902375 | validation: 0.034387359223932254]
	TIME [epoch: 5.73 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036318105117914334		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.036318105117914334 | validation: 0.04161065182064149]
	TIME [epoch: 5.73 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04368811259898408		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.04368811259898408 | validation: 0.046444935214596854]
	TIME [epoch: 5.73 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03888579721600106		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.03888579721600106 | validation: 0.050697561001447136]
	TIME [epoch: 5.73 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0392600878583224		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.0392600878583224 | validation: 0.05135153147793682]
	TIME [epoch: 5.73 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03426889684959718		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.03426889684959718 | validation: 0.0470558985700019]
	TIME [epoch: 5.76 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03985009837370844		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.03985009837370844 | validation: 0.03125288557698619]
	TIME [epoch: 5.75 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037430726374114126		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.037430726374114126 | validation: 0.0421567166654064]
	TIME [epoch: 5.73 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034916243157743235		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.034916243157743235 | validation: 0.045720324722734226]
	TIME [epoch: 5.73 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035401439799181034		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.035401439799181034 | validation: 0.04618338113648417]
	TIME [epoch: 5.73 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03774668628941608		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.03774668628941608 | validation: 0.051716219837995986]
	TIME [epoch: 5.73 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038846834460017174		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.038846834460017174 | validation: 0.044035841031073754]
	TIME [epoch: 5.73 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036710729166459594		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.036710729166459594 | validation: 0.04337650182757719]
	TIME [epoch: 5.78 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03637921910944588		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.03637921910944588 | validation: 0.04388359195385453]
	TIME [epoch: 5.73 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038926413433005236		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.038926413433005236 | validation: 0.05120128884712734]
	TIME [epoch: 5.74 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03803980603105532		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.03803980603105532 | validation: 0.056994253424106536]
	TIME [epoch: 5.75 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035750538304976376		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.035750538304976376 | validation: 0.051671868308720593]
	TIME [epoch: 5.73 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037262593498992636		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.037262593498992636 | validation: 0.045997829944018916]
	TIME [epoch: 5.73 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03996375651079228		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.03996375651079228 | validation: 0.07003300063087867]
	TIME [epoch: 5.76 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041325801424155234		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.041325801424155234 | validation: 0.053127227281080415]
	TIME [epoch: 5.75 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044944251754148526		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.044944251754148526 | validation: 0.04364279089388005]
	TIME [epoch: 5.73 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03565249689988101		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.03565249689988101 | validation: 0.04426230166808552]
	TIME [epoch: 5.73 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03978427232709002		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.03978427232709002 | validation: 0.0527228232364833]
	TIME [epoch: 5.73 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03198925192971595		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.03198925192971595 | validation: 0.04839285786316391]
	TIME [epoch: 5.73 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04381582641917257		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.04381582641917257 | validation: 0.042048010724364156]
	TIME [epoch: 5.73 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041720485079275796		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.041720485079275796 | validation: 0.036625337377180975]
	TIME [epoch: 5.77 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04293278318230023		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.04293278318230023 | validation: 0.045986885961085716]
	TIME [epoch: 5.74 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04602323227049361		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.04602323227049361 | validation: 0.04416167347266071]
	TIME [epoch: 5.73 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034449375857291534		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.034449375857291534 | validation: 0.03293320143666297]
	TIME [epoch: 5.73 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04008282750935798		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.04008282750935798 | validation: 0.03324328747402469]
	TIME [epoch: 5.74 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035206747152931796		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.035206747152931796 | validation: 0.04038487902282616]
	TIME [epoch: 5.75 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045998692867455164		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.045998692867455164 | validation: 0.04949649056671327]
	TIME [epoch: 5.76 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0451314048318206		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.0451314048318206 | validation: 0.03336234937456459]
	TIME [epoch: 5.77 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03627123729861253		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.03627123729861253 | validation: 0.04063381316031988]
	TIME [epoch: 5.74 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03252982176402241		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.03252982176402241 | validation: 0.04568799859432193]
	TIME [epoch: 5.75 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03706310927294726		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.03706310927294726 | validation: 0.047989983275815135]
	TIME [epoch: 5.74 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04239223750965271		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.04239223750965271 | validation: 0.053249149881171284]
	TIME [epoch: 5.73 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050035692782188404		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.050035692782188404 | validation: 0.056077547896311745]
	TIME [epoch: 5.75 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04640904387869519		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.04640904387869519 | validation: 0.051932599013940844]
	TIME [epoch: 5.79 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04662292683429896		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.04662292683429896 | validation: 0.05943144230270242]
	TIME [epoch: 5.75 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043137974252428796		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.043137974252428796 | validation: 0.04803210647083569]
	TIME [epoch: 5.73 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04118645045851896		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.04118645045851896 | validation: 0.0485134715139848]
	TIME [epoch: 5.75 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035159767220413404		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.035159767220413404 | validation: 0.05266050377292853]
	TIME [epoch: 5.73 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04256517420992552		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.04256517420992552 | validation: 0.05897249150061733]
	TIME [epoch: 5.73 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047599666552553155		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.047599666552553155 | validation: 0.052933140933870776]
	TIME [epoch: 5.77 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042857204389306375		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.042857204389306375 | validation: 0.05884692057870115]
	TIME [epoch: 5.74 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044426188488540796		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.044426188488540796 | validation: 0.05577508329591021]
	TIME [epoch: 5.75 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03976461061745256		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.03976461061745256 | validation: 0.06178350117844266]
	TIME [epoch: 5.75 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041139326196465355		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.041139326196465355 | validation: 0.06964857397458403]
	TIME [epoch: 5.73 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04672233351147266		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.04672233351147266 | validation: 0.06790090455006405]
	TIME [epoch: 5.73 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04813427260369867		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.04813427260369867 | validation: 0.05930341779032399]
	TIME [epoch: 5.75 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037291503076266025		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.037291503076266025 | validation: 0.05319951786483102]
	TIME [epoch: 5.76 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04052843914414307		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.04052843914414307 | validation: 0.04695566579143533]
	TIME [epoch: 5.75 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03639769598688174		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.03639769598688174 | validation: 0.04366987770863515]
	TIME [epoch: 5.75 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030982122368096075		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.030982122368096075 | validation: 0.04062936899965955]
	TIME [epoch: 5.73 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040711021996100334		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.040711021996100334 | validation: 0.05307896176871528]
	TIME [epoch: 5.73 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03826852952545427		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.03826852952545427 | validation: 0.04697961159287327]
	TIME [epoch: 5.73 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03627995195731761		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.03627995195731761 | validation: 0.052851065413792815]
	TIME [epoch: 5.79 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04063661629601611		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.04063661629601611 | validation: 0.05243386617791718]
	TIME [epoch: 5.74 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04481364608842876		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.04481364608842876 | validation: 0.056180484606907485]
	TIME [epoch: 5.75 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04052001159803077		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.04052001159803077 | validation: 0.054993729703672944]
	TIME [epoch: 5.73 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040474375868887094		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.040474375868887094 | validation: 0.04566834598557524]
	TIME [epoch: 5.73 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035645285110471985		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.035645285110471985 | validation: 0.058669450536936466]
	TIME [epoch: 5.73 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035754594992953144		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.035754594992953144 | validation: 0.06332918009286694]
	TIME [epoch: 5.77 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041330738607309056		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.041330738607309056 | validation: 0.04970999980744023]
	TIME [epoch: 5.76 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0366390343439911		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.0366390343439911 | validation: 0.049307707290891366]
	TIME [epoch: 5.73 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0386470027004699		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.0386470027004699 | validation: 0.04719638874396297]
	TIME [epoch: 5.75 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036491592938178885		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.036491592938178885 | validation: 0.03348795978858788]
	TIME [epoch: 5.75 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03381085853138816		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.03381085853138816 | validation: 0.047614705740511194]
	TIME [epoch: 5.73 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037591272965572436		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.037591272965572436 | validation: 0.046838286222516436]
	TIME [epoch: 5.73 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037920046102874146		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.037920046102874146 | validation: 0.054448523177353894]
	TIME [epoch: 5.77 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037187376732485955		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.037187376732485955 | validation: 0.04184599380985087]
	TIME [epoch: 5.76 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03383092364118093		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.03383092364118093 | validation: 0.03594041278622772]
	TIME [epoch: 5.75 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03909342503975088		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.03909342503975088 | validation: 0.04825772581728683]
	TIME [epoch: 5.75 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04391742115290247		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.04391742115290247 | validation: 0.04372834589589287]
	TIME [epoch: 5.75 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04045432230285726		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.04045432230285726 | validation: 0.03703592757394595]
	TIME [epoch: 5.75 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03885472175490764		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.03885472175490764 | validation: 0.04414926827864967]
	TIME [epoch: 5.76 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035217025013449456		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.035217025013449456 | validation: 0.044857939377950275]
	TIME [epoch: 5.76 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03570868156247504		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.03570868156247504 | validation: 0.03417629622586236]
	TIME [epoch: 5.73 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034204026130843244		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.034204026130843244 | validation: 0.03714288025070686]
	TIME [epoch: 5.73 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03678430883930832		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.03678430883930832 | validation: 0.04514683726978015]
	TIME [epoch: 5.73 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033051908185061374		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.033051908185061374 | validation: 0.029354037234988143]
	TIME [epoch: 5.74 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621465055716168		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.03621465055716168 | validation: 0.040730261309695724]
	TIME [epoch: 5.73 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03366916959871845		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.03366916959871845 | validation: 0.04668461404718919]
	TIME [epoch: 5.79 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03623666538061481		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.03623666538061481 | validation: 0.03446744638352192]
	TIME [epoch: 5.75 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036259675229413056		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.036259675229413056 | validation: 0.04610086783783392]
	TIME [epoch: 5.75 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03527731381315275		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.03527731381315275 | validation: 0.04590539651408088]
	TIME [epoch: 5.75 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03223119930598775		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.03223119930598775 | validation: 0.048724502169777535]
	TIME [epoch: 5.75 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03202301161335798		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.03202301161335798 | validation: 0.04248052081599494]
	TIME [epoch: 5.75 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03520132416188492		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.03520132416188492 | validation: 0.043602751188222086]
	TIME [epoch: 5.78 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042744803595886796		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.042744803595886796 | validation: 0.05528408178943803]
	TIME [epoch: 5.74 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039378990205315406		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.039378990205315406 | validation: 0.04524437093087376]
	TIME [epoch: 5.74 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0428578228405987		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.0428578228405987 | validation: 0.03843971706436296]
	TIME [epoch: 5.73 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037011701604496704		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.037011701604496704 | validation: 0.04243986653357947]
	TIME [epoch: 5.75 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03302434035720267		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.03302434035720267 | validation: 0.03771642296042759]
	TIME [epoch: 5.73 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03638763154198557		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.03638763154198557 | validation: 0.0468712032550184]
	TIME [epoch: 5.73 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03328918972826333		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.03328918972826333 | validation: 0.046491988136807424]
	TIME [epoch: 5.77 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03626106964323818		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.03626106964323818 | validation: 0.033678667528863275]
	TIME [epoch: 5.75 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035579156498748904		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.035579156498748904 | validation: 0.043737487852534854]
	TIME [epoch: 5.74 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03770916907040894		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.03770916907040894 | validation: 0.041994992216925466]
	TIME [epoch: 5.73 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033350228251196816		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.033350228251196816 | validation: 0.037659920083255194]
	TIME [epoch: 5.74 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03243508900057202		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.03243508900057202 | validation: 0.041027810984999816]
	TIME [epoch: 5.73 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033135340308419414		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.033135340308419414 | validation: 0.03808306812924672]
	TIME [epoch: 5.78 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03557942203642531		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.03557942203642531 | validation: 0.04238007648602265]
	TIME [epoch: 5.76 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04101629921734629		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.04101629921734629 | validation: 0.04478276424366817]
	TIME [epoch: 5.73 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03479585423624322		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.03479585423624322 | validation: 0.04374056923773896]
	TIME [epoch: 5.74 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03744998669667729		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.03744998669667729 | validation: 0.043106903566790956]
	TIME [epoch: 5.73 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034760784043084185		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.034760784043084185 | validation: 0.044757203331531534]
	TIME [epoch: 5.73 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03532327126299169		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.03532327126299169 | validation: 0.0449251633103245]
	TIME [epoch: 5.73 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03941581042560653		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.03941581042560653 | validation: 0.05418709681087653]
	TIME [epoch: 5.77 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043753199739659535		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.043753199739659535 | validation: 0.04315435989019823]
	TIME [epoch: 5.73 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037651708429593825		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.037651708429593825 | validation: 0.039388360836744775]
	TIME [epoch: 5.73 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036976773545379454		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.036976773545379454 | validation: 0.04676416041532759]
	TIME [epoch: 5.73 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04628376474526748		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.04628376474526748 | validation: 0.05065539326538092]
	TIME [epoch: 5.75 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03585885923727829		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.03585885923727829 | validation: 0.048356253507134836]
	TIME [epoch: 5.75 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03762485629894504		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.03762485629894504 | validation: 0.054242912619155474]
	TIME [epoch: 5.78 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038342925343754504		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.038342925343754504 | validation: 0.03950237001379477]
	TIME [epoch: 5.76 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03818244633975015		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.03818244633975015 | validation: 0.03688525015192923]
	TIME [epoch: 5.75 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03961945412061387		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.03961945412061387 | validation: 0.04419345333041896]
	TIME [epoch: 5.75 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03913941638480608		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.03913941638480608 | validation: 0.05001305163923722]
	TIME [epoch: 5.75 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03795249764183922		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.03795249764183922 | validation: 0.04130639190598428]
	TIME [epoch: 5.73 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03462744218658397		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.03462744218658397 | validation: 0.04440889133128513]
	TIME [epoch: 5.73 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035958390607084334		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.035958390607084334 | validation: 0.0506714995801417]
	TIME [epoch: 5.77 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03900262861031363		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.03900262861031363 | validation: 0.0416540874390871]
	TIME [epoch: 5.73 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04058103510792381		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.04058103510792381 | validation: 0.046547662123425225]
	TIME [epoch: 5.73 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034888793380694214		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.034888793380694214 | validation: 0.04653827695373143]
	TIME [epoch: 5.73 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0340621912541263		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.0340621912541263 | validation: 0.03420318867750034]
	TIME [epoch: 5.73 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032278138548293166		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.032278138548293166 | validation: 0.04370799009380379]
	TIME [epoch: 5.73 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621630723788003		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.03621630723788003 | validation: 0.046908716703926226]
	TIME [epoch: 5.76 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039751201008528206		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.039751201008528206 | validation: 0.04919367483280846]
	TIME [epoch: 5.74 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039220503263883294		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.039220503263883294 | validation: 0.04391693241035524]
	TIME [epoch: 5.73 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03119014678446854		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.03119014678446854 | validation: 0.0405618846711352]
	TIME [epoch: 5.73 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03387921076055289		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.03387921076055289 | validation: 0.04898199377132786]
	TIME [epoch: 5.73 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03410172669035299		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.03410172669035299 | validation: 0.04418160122032582]
	TIME [epoch: 5.74 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03528841931108686		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.03528841931108686 | validation: 0.04781661356926031]
	TIME [epoch: 5.75 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03642862595900066		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.03642862595900066 | validation: 0.04686600667205299]
	TIME [epoch: 5.77 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032686122545041774		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.032686122545041774 | validation: 0.03700128563849261]
	TIME [epoch: 5.73 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03477049581648802		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.03477049581648802 | validation: 0.04313463760084885]
	TIME [epoch: 5.73 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03334381359246496		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.03334381359246496 | validation: 0.03761527218497888]
	TIME [epoch: 5.73 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03622570271077978		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.03622570271077978 | validation: 0.03434791737078793]
	TIME [epoch: 5.73 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03857252857258871		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.03857252857258871 | validation: 0.035314398794120086]
	TIME [epoch: 5.73 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03724932908224113		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.03724932908224113 | validation: 0.044541738124745316]
	TIME [epoch: 5.76 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03331267554135339		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.03331267554135339 | validation: 0.04453895950543013]
	TIME [epoch: 5.74 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03378508033925798		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.03378508033925798 | validation: 0.04028775083417133]
	TIME [epoch: 5.74 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03826704184613166		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.03826704184613166 | validation: 0.041814391723334045]
	TIME [epoch: 5.73 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03277138658485187		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.03277138658485187 | validation: 0.04248965937499456]
	TIME [epoch: 5.75 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037818122605328144		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.037818122605328144 | validation: 0.052044065175463575]
	TIME [epoch: 5.75 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04056223525246576		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.04056223525246576 | validation: 0.041731447613749]
	TIME [epoch: 5.75 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04001233838571634		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.04001233838571634 | validation: 0.04554246297226593]
	TIME [epoch: 5.76 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033105391528486204		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.033105391528486204 | validation: 0.054090223009026134]
	TIME [epoch: 5.73 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03401433591343908		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.03401433591343908 | validation: 0.041610604501050766]
	TIME [epoch: 5.73 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038293977708016826		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.038293977708016826 | validation: 0.037230464279136156]
	TIME [epoch: 5.73 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03615920774757567		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.03615920774757567 | validation: 0.044544162553331657]
	TIME [epoch: 5.75 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03659802648303225		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.03659802648303225 | validation: 0.03749663820647339]
	TIME [epoch: 5.75 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03943371642279504		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.03943371642279504 | validation: 0.04140989893676868]
	TIME [epoch: 5.79 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036974430009351515		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.036974430009351515 | validation: 0.040501376649038925]
	TIME [epoch: 5.75 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036056090237357286		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.036056090237357286 | validation: 0.03505278827663107]
	TIME [epoch: 5.75 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03581975830670526		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.03581975830670526 | validation: 0.04512002167689056]
	TIME [epoch: 5.75 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0340190408530895		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.0340190408530895 | validation: 0.0370661784800707]
	TIME [epoch: 5.75 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034858553824416556		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.034858553824416556 | validation: 0.03995642528406839]
	TIME [epoch: 5.75 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03312899452459374		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.03312899452459374 | validation: 0.05030684937038849]
	TIME [epoch: 5.76 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03394718817117107		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.03394718817117107 | validation: 0.043307450717613175]
	TIME [epoch: 5.77 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030836258235135583		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.030836258235135583 | validation: 0.04109131662455081]
	TIME [epoch: 5.75 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313856616291383		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.03313856616291383 | validation: 0.04286437966926712]
	TIME [epoch: 5.75 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036051594336451935		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.036051594336451935 | validation: 0.037247924009233276]
	TIME [epoch: 5.75 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034270065602389474		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.034270065602389474 | validation: 0.0406339477843568]
	TIME [epoch: 5.75 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04021481874487222		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.04021481874487222 | validation: 0.036388937572339256]
	TIME [epoch: 5.75 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04063474754210435		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.04063474754210435 | validation: 0.04544239243547511]
	TIME [epoch: 5.78 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042013395932880865		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.042013395932880865 | validation: 0.05184904735967146]
	TIME [epoch: 5.75 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039932264410221005		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.039932264410221005 | validation: 0.05203380779862522]
	TIME [epoch: 5.75 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030433221282958806		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.030433221282958806 | validation: 0.04526406229107849]
	TIME [epoch: 5.75 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03710826098974058		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.03710826098974058 | validation: 0.048444042863446966]
	TIME [epoch: 5.75 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03701736821339778		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.03701736821339778 | validation: 0.04042281695940522]
	TIME [epoch: 5.75 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03678011040238096		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.03678011040238096 | validation: 0.03978883059664845]
	TIME [epoch: 5.74 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03207391201896198		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.03207391201896198 | validation: 0.03631385542712572]
	TIME [epoch: 5.76 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03527567247809587		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.03527567247809587 | validation: 0.03040725261647081]
	TIME [epoch: 5.73 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03718250094534257		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.03718250094534257 | validation: 0.05044626655780766]
	TIME [epoch: 5.73 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03774523090445729		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.03774523090445729 | validation: 0.037705587293730976]
	TIME [epoch: 5.73 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03185728932060922		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.03185728932060922 | validation: 0.038015460638305944]
	TIME [epoch: 5.73 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03168358780515825		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.03168358780515825 | validation: 0.036649021731440135]
	TIME [epoch: 5.74 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03456726636144433		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.03456726636144433 | validation: 0.03589181684645057]
	TIME [epoch: 5.79 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03319768135968011		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.03319768135968011 | validation: 0.04141133898792404]
	TIME [epoch: 5.75 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03583566992617647		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.03583566992617647 | validation: 0.036728880206123866]
	TIME [epoch: 5.75 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037015385147220414		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.037015385147220414 | validation: 0.04899506174776898]
	TIME [epoch: 5.73 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03551000028498147		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.03551000028498147 | validation: 0.039308886732434774]
	TIME [epoch: 5.75 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03863447000999096		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.03863447000999096 | validation: 0.039366852918746933]
	TIME [epoch: 5.75 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0355674809861036		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.0355674809861036 | validation: 0.04269907011610145]
	TIME [epoch: 5.76 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03454508914318671		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.03454508914318671 | validation: 0.04886539229839343]
	TIME [epoch: 5.77 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033367922590223247		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.033367922590223247 | validation: 0.04139715299424509]
	TIME [epoch: 5.75 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304096629326578		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.03304096629326578 | validation: 0.045429056755068274]
	TIME [epoch: 5.75 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03497193848468645		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.03497193848468645 | validation: 0.044053040521999993]
	TIME [epoch: 5.75 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03698883601729301		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.03698883601729301 | validation: 0.04573573657665449]
	TIME [epoch: 5.74 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03585234555897101		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.03585234555897101 | validation: 0.04597962246602887]
	TIME [epoch: 5.75 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03986186293042384		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.03986186293042384 | validation: 0.046704443090357234]
	TIME [epoch: 5.79 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03539924444574333		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.03539924444574333 | validation: 0.04973662015670838]
	TIME [epoch: 5.75 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034610391851352895		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.034610391851352895 | validation: 0.049128029870490864]
	TIME [epoch: 5.75 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03581040724088237		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.03581040724088237 | validation: 0.05349221139202873]
	TIME [epoch: 5.75 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03717806192173685		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.03717806192173685 | validation: 0.061713742849172075]
	TIME [epoch: 5.73 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03952721897950149		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.03952721897950149 | validation: 0.04914269192130458]
	TIME [epoch: 5.75 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04050092004396871		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.04050092004396871 | validation: 0.05138528312942595]
	TIME [epoch: 5.78 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03700966060139202		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.03700966060139202 | validation: 0.058255963121904404]
	TIME [epoch: 5.76 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035536499017034734		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.035536499017034734 | validation: 0.04806999292851634]
	TIME [epoch: 5.75 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03263599886945656		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.03263599886945656 | validation: 0.04248283983638471]
	TIME [epoch: 5.73 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0333238075977508		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.0333238075977508 | validation: 0.052322231825730155]
	TIME [epoch: 5.74 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03964532124087462		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.03964532124087462 | validation: 0.057127261597486774]
	TIME [epoch: 5.73 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03613212073676218		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.03613212073676218 | validation: 0.050474812188426914]
	TIME [epoch: 5.73 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03715034226782049		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.03715034226782049 | validation: 0.04196204114478798]
	TIME [epoch: 5.78 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0365572643926796		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.0365572643926796 | validation: 0.04187485915285578]
	TIME [epoch: 5.75 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038462709547067805		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.038462709547067805 | validation: 0.04703371845622645]
	TIME [epoch: 5.75 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03337670390255585		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.03337670390255585 | validation: 0.052074378584237455]
	TIME [epoch: 5.74 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034987191516044375		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.034987191516044375 | validation: 0.05792004748017208]
	TIME [epoch: 5.73 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03725333651566365		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.03725333651566365 | validation: 0.044878188173054154]
	TIME [epoch: 5.75 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03400412049088779		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.03400412049088779 | validation: 0.0410123131987512]
	TIME [epoch: 5.77 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0313637874063686		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.0313637874063686 | validation: 0.035442922168986805]
	TIME [epoch: 5.75 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03682390832797378		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.03682390832797378 | validation: 0.038477640026988]
	TIME [epoch: 5.74 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03214438577319295		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.03214438577319295 | validation: 0.033256618915285155]
	TIME [epoch: 5.75 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03736261949923286		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.03736261949923286 | validation: 0.04163905439757135]
	TIME [epoch: 5.73 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03308834848622477		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.03308834848622477 | validation: 0.041436446541706674]
	TIME [epoch: 5.73 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03616284491352087		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.03616284491352087 | validation: 0.038378070966123536]
	TIME [epoch: 5.73 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035202175834843606		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.035202175834843606 | validation: 0.035407782701680025]
	TIME [epoch: 5.77 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03481780762421327		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.03481780762421327 | validation: 0.03922488019809188]
	TIME [epoch: 5.75 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03531030578135024		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.03531030578135024 | validation: 0.035603773527244094]
	TIME [epoch: 5.73 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03607948823022733		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.03607948823022733 | validation: 0.040557365157135886]
	TIME [epoch: 5.73 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03415344324473951		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.03415344324473951 | validation: 0.037577905324797066]
	TIME [epoch: 5.75 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03770191064753584		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.03770191064753584 | validation: 0.03908878387860639]
	TIME [epoch: 5.73 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037460643653111005		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.037460643653111005 | validation: 0.04611994612248628]
	TIME [epoch: 5.76 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03265114060041531		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.03265114060041531 | validation: 0.0387382301559862]
	TIME [epoch: 5.75 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02887892119397871		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.02887892119397871 | validation: 0.042362146131250535]
	TIME [epoch: 5.75 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03244271545163039		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.03244271545163039 | validation: 0.04400994265798684]
	TIME [epoch: 5.73 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03183634875724948		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.03183634875724948 | validation: 0.032529061970130266]
	TIME [epoch: 5.73 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03007030501825618		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.03007030501825618 | validation: 0.03830701062984153]
	TIME [epoch: 5.73 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033898870801448225		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.033898870801448225 | validation: 0.04479640598387673]
	TIME [epoch: 5.73 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0360864999746172		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.0360864999746172 | validation: 0.05772576146781286]
	TIME [epoch: 5.77 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037479239657933705		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.037479239657933705 | validation: 0.042575017660308634]
	TIME [epoch: 5.75 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037124760534592474		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.037124760534592474 | validation: 0.04438495988715932]
	TIME [epoch: 5.74 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03800897747314366		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.03800897747314366 | validation: 0.04497986920762724]
	TIME [epoch: 5.75 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03596453944290651		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.03596453944290651 | validation: 0.033950837838717475]
	TIME [epoch: 5.75 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03084343427409114		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.03084343427409114 | validation: 0.03825113605261384]
	TIME [epoch: 5.74 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035302656708652916		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.035302656708652916 | validation: 0.043424444026987676]
	TIME [epoch: 5.77 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02753507308436804		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.02753507308436804 | validation: 0.04079668334189186]
	TIME [epoch: 5.75 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034809492882597916		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.034809492882597916 | validation: 0.03546036945862877]
	TIME [epoch: 5.73 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034852692998199		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.034852692998199 | validation: 0.037948640577645826]
	TIME [epoch: 5.73 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03447121181253511		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.03447121181253511 | validation: 0.04085745932678979]
	TIME [epoch: 5.74 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031307339991568636		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.031307339991568636 | validation: 0.0408528152012221]
	TIME [epoch: 5.74 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03123113090149461		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.03123113090149461 | validation: 0.03784322380022875]
	TIME [epoch: 5.75 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036022332424228865		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.036022332424228865 | validation: 0.05104256572332909]
	TIME [epoch: 5.76 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03489319119858395		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.03489319119858395 | validation: 0.04141911784028002]
	TIME [epoch: 5.73 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037024914045746496		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.037024914045746496 | validation: 0.0361466079820478]
	TIME [epoch: 5.75 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035326132337052514		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.035326132337052514 | validation: 0.04119255228346616]
	TIME [epoch: 5.73 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03984283821627258		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.03984283821627258 | validation: 0.048103967749692556]
	TIME [epoch: 5.75 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03699374874931753		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.03699374874931753 | validation: 0.04774264250474244]
	TIME [epoch: 5.75 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034795972141450235		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.034795972141450235 | validation: 0.05298548411369345]
	TIME [epoch: 5.78 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03488841887850439		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.03488841887850439 | validation: 0.05148462535707779]
	TIME [epoch: 5.75 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03384385037063531		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.03384385037063531 | validation: 0.045900754833875956]
	TIME [epoch: 5.74 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029920950845475996		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.029920950845475996 | validation: 0.045857511556554494]
	TIME [epoch: 5.74 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03050069172549056		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.03050069172549056 | validation: 0.041791119142502144]
	TIME [epoch: 5.75 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03383364865859959		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.03383364865859959 | validation: 0.048793620064633315]
	TIME [epoch: 5.74 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03385785898279806		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.03385785898279806 | validation: 0.04917500994784349]
	TIME [epoch: 5.75 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03075298717453607		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.03075298717453607 | validation: 0.04762052338960853]
	TIME [epoch: 5.77 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03356787786211953		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.03356787786211953 | validation: 0.03622151302290298]
	TIME [epoch: 5.74 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030249652128079018		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.030249652128079018 | validation: 0.0435724072267101]
	TIME [epoch: 5.74 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03317973094287902		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.03317973094287902 | validation: 0.0428078916346341]
	TIME [epoch: 5.73 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03644959805061479		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.03644959805061479 | validation: 0.04798098988737262]
	TIME [epoch: 5.75 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03628398025600052		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.03628398025600052 | validation: 0.04229408052832924]
	TIME [epoch: 5.74 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034052338092309065		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.034052338092309065 | validation: 0.04203595999101634]
	TIME [epoch: 5.77 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03489561576107865		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.03489561576107865 | validation: 0.045374550000613446]
	TIME [epoch: 5.74 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03486587830320666		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.03486587830320666 | validation: 0.0457299094433568]
	TIME [epoch: 5.73 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035303815460395536		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.035303815460395536 | validation: 0.03529132591176765]
	TIME [epoch: 5.73 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03461985553675237		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.03461985553675237 | validation: 0.03716782618644313]
	TIME [epoch: 5.75 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034735663106227846		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.034735663106227846 | validation: 0.03847121073014911]
	TIME [epoch: 5.74 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03280649181796143		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.03280649181796143 | validation: 0.04683093001761786]
	TIME [epoch: 5.76 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03551193288649421		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.03551193288649421 | validation: 0.04940770779067291]
	TIME [epoch: 5.77 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037545460689250035		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.037545460689250035 | validation: 0.049284886687943084]
	TIME [epoch: 5.75 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033683854861946305		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.033683854861946305 | validation: 0.05159772884845896]
	TIME [epoch: 5.74 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03907727951728858		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.03907727951728858 | validation: 0.049960745179991044]
	TIME [epoch: 5.73 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03694533674747392		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.03694533674747392 | validation: 0.04220919943883246]
	TIME [epoch: 5.73 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03181275893307052		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.03181275893307052 | validation: 0.04382971782549504]
	TIME [epoch: 5.74 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031040643412864014		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.031040643412864014 | validation: 0.04806000165753114]
	TIME [epoch: 5.77 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03419930489975399		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.03419930489975399 | validation: 0.05807986205144368]
	TIME [epoch: 5.75 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0339454793118851		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.0339454793118851 | validation: 0.054883706742692766]
	TIME [epoch: 5.74 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030583149475582272		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.030583149475582272 | validation: 0.048383848710095725]
	TIME [epoch: 5.74 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0351919019293108		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.0351919019293108 | validation: 0.041735754012599484]
	TIME [epoch: 5.73 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030574998732893936		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.030574998732893936 | validation: 0.049918428136862085]
	TIME [epoch: 5.73 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032091854993019905		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.032091854993019905 | validation: 0.033250918914215236]
	TIME [epoch: 5.76 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03582211499795361		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.03582211499795361 | validation: 0.04088649931903009]
	TIME [epoch: 5.75 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03230215614602705		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.03230215614602705 | validation: 0.045085575438512]
	TIME [epoch: 5.75 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03978775275430786		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.03978775275430786 | validation: 0.04780166991031641]
	TIME [epoch: 5.73 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03665876122435824		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.03665876122435824 | validation: 0.0504950052763148]
	TIME [epoch: 5.73 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0345356148204741		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.0345356148204741 | validation: 0.04650042790070739]
	TIME [epoch: 5.75 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03889929581078041		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.03889929581078041 | validation: 0.044398621748222115]
	TIME [epoch: 5.74 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03543471590574832		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.03543471590574832 | validation: 0.03793404007432833]
	TIME [epoch: 5.78 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031115133591930938		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.031115133591930938 | validation: 0.042945170215908275]
	TIME [epoch: 5.74 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331624283702449		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.0331624283702449 | validation: 0.04730186248099852]
	TIME [epoch: 5.74 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036635145417521886		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.036635145417521886 | validation: 0.03529727808738516]
	TIME [epoch: 5.75 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03375305578987933		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.03375305578987933 | validation: 0.04128698610755231]
	TIME [epoch: 5.74 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035233149260205515		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.035233149260205515 | validation: 0.046060355873952144]
	TIME [epoch: 5.73 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032954035462858224		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.032954035462858224 | validation: 0.04568608711513957]
	TIME [epoch: 5.76 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03062746056650749		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.03062746056650749 | validation: 0.03909428473863618]
	TIME [epoch: 5.75 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032860882408379574		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.032860882408379574 | validation: 0.03259384456289339]
	TIME [epoch: 5.74 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033843659179712236		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.033843659179712236 | validation: 0.045008185030367284]
	TIME [epoch: 5.74 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03527083098910237		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.03527083098910237 | validation: 0.047493195059986296]
	TIME [epoch: 5.75 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331164392120168		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.0331164392120168 | validation: 0.044022965454485787]
	TIME [epoch: 5.73 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03901093352864584		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.03901093352864584 | validation: 0.038144795014059873]
	TIME [epoch: 5.75 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037396115057703114		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.037396115057703114 | validation: 0.03754713527927268]
	TIME [epoch: 5.78 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03364839887639834		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.03364839887639834 | validation: 0.0362691672189576]
	TIME [epoch: 5.74 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032167100219462536		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.032167100219462536 | validation: 0.04238575127823717]
	TIME [epoch: 5.73 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430967286073338		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.03430967286073338 | validation: 0.04909236574905183]
	TIME [epoch: 5.73 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03731414653834072		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.03731414653834072 | validation: 0.046097952250375815]
	TIME [epoch: 5.74 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035490444987169044		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.035490444987169044 | validation: 0.042172132262104485]
	TIME [epoch: 5.74 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03563410643933759		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.03563410643933759 | validation: 0.03334899357664346]
	TIME [epoch: 5.77 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029167195097291335		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.029167195097291335 | validation: 0.042331994164339054]
	TIME [epoch: 5.75 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03630394644357302		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.03630394644357302 | validation: 0.04764559448327432]
	TIME [epoch: 5.73 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03789232042849922		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.03789232042849922 | validation: 0.044368129189228396]
	TIME [epoch: 5.74 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036847158810852584		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.036847158810852584 | validation: 0.042014812919151934]
	TIME [epoch: 5.75 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03441464856056134		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.03441464856056134 | validation: 0.02805502852540586]
	TIME [epoch: 5.74 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03290217758821078		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.03290217758821078 | validation: 0.038928316069744895]
	TIME [epoch: 5.73 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03692981059424726		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.03692981059424726 | validation: 0.03907446335481485]
	TIME [epoch: 5.78 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03095819196652019		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.03095819196652019 | validation: 0.04421571737013281]
	TIME [epoch: 5.73 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033205830389258374		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.033205830389258374 | validation: 0.03216922844450567]
	TIME [epoch: 5.74 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03268628545180914		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.03268628545180914 | validation: 0.044894757904592665]
	TIME [epoch: 5.74 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035411257956164816		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.035411257956164816 | validation: 0.04003130074500558]
	TIME [epoch: 5.74 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038297259916923385		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.038297259916923385 | validation: 0.039133678777171464]
	TIME [epoch: 5.75 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030438806321153908		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.030438806321153908 | validation: 0.042471496673761884]
	TIME [epoch: 5.77 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03263641583210321		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.03263641583210321 | validation: 0.02850669425644295]
	TIME [epoch: 5.75 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03792347947110315		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.03792347947110315 | validation: 0.03981464870373134]
	TIME [epoch: 5.74 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034133858400124		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.034133858400124 | validation: 0.03611950802248201]
	TIME [epoch: 5.74 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031656564621590104		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.031656564621590104 | validation: 0.039960570757607276]
	TIME [epoch: 5.74 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02951154466396494		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.02951154466396494 | validation: 0.038219732552506235]
	TIME [epoch: 5.74 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03409344319156865		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.03409344319156865 | validation: 0.038497513277556725]
	TIME [epoch: 5.75 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03476403256793975		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.03476403256793975 | validation: 0.04076603252659295]
	TIME [epoch: 5.78 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02947049087673006		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.02947049087673006 | validation: 0.03722663432709827]
	TIME [epoch: 5.75 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03373486230796582		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.03373486230796582 | validation: 0.04719721948260345]
	TIME [epoch: 5.74 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034928980917919177		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.034928980917919177 | validation: 0.03652051524650273]
	TIME [epoch: 5.74 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033341195689995565		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.033341195689995565 | validation: 0.04050976192231464]
	TIME [epoch: 5.74 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03209200966250731		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.03209200966250731 | validation: 0.041839101227675285]
	TIME [epoch: 5.75 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03600980141677429		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.03600980141677429 | validation: 0.03018904200180523]
	TIME [epoch: 5.77 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03699185869481118		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.03699185869481118 | validation: 0.031749529368354734]
	TIME [epoch: 5.74 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03843086298939613		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.03843086298939613 | validation: 0.0405735382423031]
	TIME [epoch: 5.74 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03628714168506531		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.03628714168506531 | validation: 0.039891768088357156]
	TIME [epoch: 5.74 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0378888993342633		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.0378888993342633 | validation: 0.03566824468547732]
	TIME [epoch: 5.75 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039803957134376206		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.039803957134376206 | validation: 0.035913238299674105]
	TIME [epoch: 5.73 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040706062761767664		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.040706062761767664 | validation: 0.03727098205269989]
	TIME [epoch: 5.75 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03717387452944672		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.03717387452944672 | validation: 0.032486937974114435]
	TIME [epoch: 5.76 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0399330533636964		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.0399330533636964 | validation: 0.04111238874534418]
	TIME [epoch: 5.75 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034517125328978014		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.034517125328978014 | validation: 0.04767434522149558]
	TIME [epoch: 5.73 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03228408325028904		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.03228408325028904 | validation: 0.03506682020298798]
	TIME [epoch: 5.74 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0360738949822901		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.0360738949822901 | validation: 0.03520064145865272]
	TIME [epoch: 5.74 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03846285619135341		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.03846285619135341 | validation: 0.03816444427208113]
	TIME [epoch: 5.73 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03824052615911305		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.03824052615911305 | validation: 0.03541396038893856]
	TIME [epoch: 5.76 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335948995984402		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.0335948995984402 | validation: 0.03589167148604862]
	TIME [epoch: 5.73 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03821705332617934		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.03821705332617934 | validation: 0.033717801544307355]
	TIME [epoch: 5.75 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034313582613302966		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.034313582613302966 | validation: 0.04677595815356435]
	TIME [epoch: 5.73 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03742367460574083		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.03742367460574083 | validation: 0.044211383386402625]
	TIME [epoch: 5.73 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03442154984718816		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.03442154984718816 | validation: 0.04819169620504508]
	TIME [epoch: 5.74 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03626109320639247		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.03626109320639247 | validation: 0.047356641304593605]
	TIME [epoch: 5.75 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034557350936529604		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.034557350936529604 | validation: 0.05326203157981068]
	TIME [epoch: 5.77 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0338812708027924		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.0338812708027924 | validation: 0.0502791327105933]
	TIME [epoch: 5.74 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03322161545224832		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.03322161545224832 | validation: 0.04850837882429713]
	TIME [epoch: 5.74 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038905813736951934		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.038905813736951934 | validation: 0.04223803096359953]
	TIME [epoch: 5.73 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03725466468658731		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.03725466468658731 | validation: 0.04463864905132428]
	TIME [epoch: 5.74 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038646677913141504		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.038646677913141504 | validation: 0.05069492530288862]
	TIME [epoch: 5.74 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03769305026223649		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.03769305026223649 | validation: 0.0438908379174234]
	TIME [epoch: 5.77 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834894128425297		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.03834894128425297 | validation: 0.056029186424245564]
	TIME [epoch: 5.74 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038690774593178386		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.038690774593178386 | validation: 0.04346300342227567]
	TIME [epoch: 5.74 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036438815105711855		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.036438815105711855 | validation: 0.04532308587108208]
	TIME [epoch: 5.75 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03281728957628391		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.03281728957628391 | validation: 0.04134936702411112]
	TIME [epoch: 5.74 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033670818339090254		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.033670818339090254 | validation: 0.04843751304962865]
	TIME [epoch: 5.74 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03288495625605972		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.03288495625605972 | validation: 0.041976547220428755]
	TIME [epoch: 5.75 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03411020277352105		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.03411020277352105 | validation: 0.05073205210942027]
	TIME [epoch: 5.78 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035334289038150404		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.035334289038150404 | validation: 0.0377253134747919]
	TIME [epoch: 5.74 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032510036819870754		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.032510036819870754 | validation: 0.04476869537748093]
	TIME [epoch: 5.74 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030729714481269883		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.030729714481269883 | validation: 0.03819761735804455]
	TIME [epoch: 5.74 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0317546520281827		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.0317546520281827 | validation: 0.042806000978946206]
	TIME [epoch: 5.74 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033143999351690066		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.033143999351690066 | validation: 0.03923784555315399]
	TIME [epoch: 5.74 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02839451624868545		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.02839451624868545 | validation: 0.04110341330407108]
	TIME [epoch: 5.78 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031025183150405346		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.031025183150405346 | validation: 0.04203280105864798]
	TIME [epoch: 5.74 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028946339001810224		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.028946339001810224 | validation: 0.038637609120129285]
	TIME [epoch: 5.74 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034706331783770486		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.034706331783770486 | validation: 0.03241661709394411]
	TIME [epoch: 5.74 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03370971179246299		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.03370971179246299 | validation: 0.04167834202093316]
	TIME [epoch: 5.74 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029806032258457855		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.029806032258457855 | validation: 0.04495509269719466]
	TIME [epoch: 5.73 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026575890172719056		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.026575890172719056 | validation: 0.04508409129423343]
	TIME [epoch: 5.77 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036507486431600414		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.036507486431600414 | validation: 0.03009772424625007]
	TIME [epoch: 5.74 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03374945886475674		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.03374945886475674 | validation: 0.039060003667497185]
	TIME [epoch: 5.73 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034075838096207345		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.034075838096207345 | validation: 0.04665595492591618]
	TIME [epoch: 5.73 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032557497618798635		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.032557497618798635 | validation: 0.046571769943771255]
	TIME [epoch: 5.73 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03722436966520868		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.03722436966520868 | validation: 0.04409021334271067]
	TIME [epoch: 5.75 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154220645167979		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.03154220645167979 | validation: 0.035720788358057684]
	TIME [epoch: 5.74 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335868346609835		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.0335868346609835 | validation: 0.044633652463613824]
	TIME [epoch: 5.78 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03377929188325426		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.03377929188325426 | validation: 0.04066203825150227]
	TIME [epoch: 5.75 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03784900062746677		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.03784900062746677 | validation: 0.03966896431226572]
	TIME [epoch: 5.75 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03123418729811655		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.03123418729811655 | validation: 0.0434332786726159]
	TIME [epoch: 5.75 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03142145961015468		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.03142145961015468 | validation: 0.04298179055046832]
	TIME [epoch: 5.73 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027669231511086127		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.027669231511086127 | validation: 0.04209733833116263]
	TIME [epoch: 5.74 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027841807849000474		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.027841807849000474 | validation: 0.04589409480127492]
	TIME [epoch: 5.76 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03664983700005705		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.03664983700005705 | validation: 0.037881994900859736]
	TIME [epoch: 5.76 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03065442810283826		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.03065442810283826 | validation: 0.048319227721374494]
	TIME [epoch: 5.73 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0316467101935801		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.0316467101935801 | validation: 0.03891585288314502]
	TIME [epoch: 5.75 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030668165723055404		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.030668165723055404 | validation: 0.04126047216075405]
	TIME [epoch: 5.75 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033960458683489195		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.033960458683489195 | validation: 0.04150046889192883]
	TIME [epoch: 5.74 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03307660576402852		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.03307660576402852 | validation: 0.04005692615483669]
	TIME [epoch: 5.75 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03417477178508592		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.03417477178508592 | validation: 0.04180367788788227]
	TIME [epoch: 5.79 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03113272313204328		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.03113272313204328 | validation: 0.029457459780080804]
	TIME [epoch: 5.75 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03804248705566133		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.03804248705566133 | validation: 0.03113739421226266]
	TIME [epoch: 5.74 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03382127603320743		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.03382127603320743 | validation: 0.04145116084625707]
	TIME [epoch: 5.75 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03168723911748864		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.03168723911748864 | validation: 0.0330994517856381]
	TIME [epoch: 5.75 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034687901149952634		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.034687901149952634 | validation: 0.04124034682979554]
	TIME [epoch: 5.73 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034873577102173516		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.034873577102173516 | validation: 0.04059685591263179]
	TIME [epoch: 5.78 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03133549073629111		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.03133549073629111 | validation: 0.04559325585360852]
	TIME [epoch: 5.74 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03372300148185269		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.03372300148185269 | validation: 0.03896186916506627]
	TIME [epoch: 5.75 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03189781943959466		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.03189781943959466 | validation: 0.04566627348059605]
	TIME [epoch: 5.75 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03352158222619474		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.03352158222619474 | validation: 0.04399921662382902]
	TIME [epoch: 5.75 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03499873640400279		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.03499873640400279 | validation: 0.032054910605395864]
	TIME [epoch: 5.73 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032558226315122535		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.032558226315122535 | validation: 0.0394794094786313]
	TIME [epoch: 5.76 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034397249816728155		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.034397249816728155 | validation: 0.04724592623681332]
	TIME [epoch: 5.76 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03337407169282954		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.03337407169282954 | validation: 0.03385577444875414]
	TIME [epoch: 5.75 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0340599450839284		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.0340599450839284 | validation: 0.047921467710170945]
	TIME [epoch: 5.73 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036428827351347226		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.036428827351347226 | validation: 0.036091972487842336]
	TIME [epoch: 5.74 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03705469519217727		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.03705469519217727 | validation: 0.04900116381175224]
	TIME [epoch: 5.73 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03706899698846184		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.03706899698846184 | validation: 0.036218679763625625]
	TIME [epoch: 5.74 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030657013323369606		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.030657013323369606 | validation: 0.036378407778094736]
	TIME [epoch: 5.77 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03552916393600046		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.03552916393600046 | validation: 0.038644149523024945]
	TIME [epoch: 5.74 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0320498850366182		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.0320498850366182 | validation: 0.040539065986061947]
	TIME [epoch: 5.74 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03356790887486196		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.03356790887486196 | validation: 0.041805710832972784]
	TIME [epoch: 5.75 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03846148315097216		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.03846148315097216 | validation: 0.04116998656762238]
	TIME [epoch: 5.74 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03384455348079926		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.03384455348079926 | validation: 0.034096583959770416]
	TIME [epoch: 5.73 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0361198222712797		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.0361198222712797 | validation: 0.037029572234180345]
	TIME [epoch: 5.74 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03227792992773453		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.03227792992773453 | validation: 0.034168370005560854]
	TIME [epoch: 5.76 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03549064982229718		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.03549064982229718 | validation: 0.03523187572556917]
	TIME [epoch: 5.73 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03443148354265977		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.03443148354265977 | validation: 0.04033882545895114]
	TIME [epoch: 5.73 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03176712434876842		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.03176712434876842 | validation: 0.04292727261886903]
	TIME [epoch: 5.73 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03288975317044897		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.03288975317044897 | validation: 0.037643612948681494]
	TIME [epoch: 5.73 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03565951168962049		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.03565951168962049 | validation: 0.038711821231278525]
	TIME [epoch: 5.73 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03176154680248537		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.03176154680248537 | validation: 0.03685263454158582]
	TIME [epoch: 5.77 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03221738167705562		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.03221738167705562 | validation: 0.033270814701382066]
	TIME [epoch: 5.74 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03336137582302026		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.03336137582302026 | validation: 0.04145136651915816]
	TIME [epoch: 5.73 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031033339006762528		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.031033339006762528 | validation: 0.03944532508839192]
	TIME [epoch: 5.73 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030554474391831093		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.030554474391831093 | validation: 0.038190272171152666]
	TIME [epoch: 5.73 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031066039394150972		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.031066039394150972 | validation: 0.029846055426435054]
	TIME [epoch: 5.73 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232174887016722		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.03232174887016722 | validation: 0.044070886478661635]
	TIME [epoch: 5.75 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03339536060006309		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.03339536060006309 | validation: 0.03945086729983763]
	TIME [epoch: 5.76 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02640095897381474		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.02640095897381474 | validation: 0.036808210621252384]
	TIME [epoch: 5.73 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031742500941117066		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.031742500941117066 | validation: 0.0469636824940077]
	TIME [epoch: 5.73 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030558179092661328		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.030558179092661328 | validation: 0.03887698589619144]
	TIME [epoch: 5.73 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0326587543898384		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.0326587543898384 | validation: 0.029524630557371163]
	TIME [epoch: 5.75 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328843756627818		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.0328843756627818 | validation: 0.04263515576604455]
	TIME [epoch: 5.75 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02762297619620304		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.02762297619620304 | validation: 0.03700509218022365]
	TIME [epoch: 5.79 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03159604167441773		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.03159604167441773 | validation: 0.03520624175028471]
	TIME [epoch: 5.74 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034801185056686564		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.034801185056686564 | validation: 0.037948718637646185]
	TIME [epoch: 5.73 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03436502568600769		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.03436502568600769 | validation: 0.043551356121510176]
	TIME [epoch: 5.73 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03248170588168647		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.03248170588168647 | validation: 0.04519985166180367]
	TIME [epoch: 5.75 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03171146994085542		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.03171146994085542 | validation: 0.03910767852651852]
	TIME [epoch: 5.75 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0344790521472005		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.0344790521472005 | validation: 0.0350163500804131]
	TIME [epoch: 5.74 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034588121466312766		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.034588121466312766 | validation: 0.03693200797169653]
	TIME [epoch: 5.76 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032185437988894686		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.032185437988894686 | validation: 0.03628646118310702]
	TIME [epoch: 5.75 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033268956116047785		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.033268956116047785 | validation: 0.035876492257694945]
	TIME [epoch: 5.75 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03224279587290177		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.03224279587290177 | validation: 0.038544262073763796]
	TIME [epoch: 5.75 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034680209939014744		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.034680209939014744 | validation: 0.04250481474959348]
	TIME [epoch: 5.75 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03628568783346371		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.03628568783346371 | validation: 0.037320312232460184]
	TIME [epoch: 5.75 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034754934013821105		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.034754934013821105 | validation: 0.044685884672199076]
	TIME [epoch: 5.78 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030785642305191097		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.030785642305191097 | validation: 0.041897442737009134]
	TIME [epoch: 5.75 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03348911454126758		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.03348911454126758 | validation: 0.03869452621715629]
	TIME [epoch: 5.75 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03463227248350355		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.03463227248350355 | validation: 0.043482972822842976]
	TIME [epoch: 5.73 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033015021997713674		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.033015021997713674 | validation: 0.04940941706698408]
	TIME [epoch: 5.75 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558789325329186		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.03558789325329186 | validation: 0.039607881223104255]
	TIME [epoch: 5.75 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031158232074388427		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.031158232074388427 | validation: 0.035496999683984204]
	TIME [epoch: 5.77 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03242623179629076		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.03242623179629076 | validation: 0.04128014022334341]
	TIME [epoch: 5.74 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030777865701789052		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.030777865701789052 | validation: 0.043746578242722975]
	TIME [epoch: 5.74 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031326972862902244		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.031326972862902244 | validation: 0.035004193520819155]
	TIME [epoch: 5.73 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037474327706569506		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.037474327706569506 | validation: 0.046922095871053976]
	TIME [epoch: 5.74 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03689356514530105		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.03689356514530105 | validation: 0.03493230696999978]
	TIME [epoch: 5.74 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032190486873494066		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.032190486873494066 | validation: 0.04431757003569331]
	TIME [epoch: 5.73 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03497405024851538		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.03497405024851538 | validation: 0.04275669343996654]
	TIME [epoch: 5.77 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030614487904661057		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.030614487904661057 | validation: 0.03958249937662687]
	TIME [epoch: 5.74 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03354524753659047		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.03354524753659047 | validation: 0.0443892648797296]
	TIME [epoch: 5.74 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031684857586529315		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.031684857586529315 | validation: 0.044833964780376656]
	TIME [epoch: 5.74 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03358636853961583		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.03358636853961583 | validation: 0.03997158019401653]
	TIME [epoch: 5.73 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03140517334961392		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.03140517334961392 | validation: 0.042028509909252075]
	TIME [epoch: 5.73 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03425416188146209		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.03425416188146209 | validation: 0.03720229882655269]
	TIME [epoch: 5.76 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03386935069894634		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.03386935069894634 | validation: 0.042757457635932895]
	TIME [epoch: 5.75 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032717787940610324		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.032717787940610324 | validation: 0.04505363522721212]
	TIME [epoch: 5.73 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03341039434159289		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.03341039434159289 | validation: 0.0433472254927459]
	TIME [epoch: 5.73 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03327989022097095		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.03327989022097095 | validation: 0.039898558091265815]
	TIME [epoch: 5.73 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032634444185341144		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.032634444185341144 | validation: 0.045933407856677974]
	TIME [epoch: 5.73 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033737626913161275		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.033737626913161275 | validation: 0.046167992099049066]
	TIME [epoch: 5.74 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035333429197547624		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.035333429197547624 | validation: 0.05026773192832623]
	TIME [epoch: 5.79 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036586147501905406		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.036586147501905406 | validation: 0.05102103584289596]
	TIME [epoch: 5.75 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036083345065354704		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.036083345065354704 | validation: 0.04754335601078591]
	TIME [epoch: 5.75 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03876552571494413		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.03876552571494413 | validation: 0.04137882427855853]
	TIME [epoch: 5.74 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034664231244243615		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.034664231244243615 | validation: 0.04400220757847507]
	TIME [epoch: 5.75 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03242138215721732		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.03242138215721732 | validation: 0.0363993191765529]
	TIME [epoch: 5.75 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032641422267789336		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.032641422267789336 | validation: 0.036682020716901124]
	TIME [epoch: 5.78 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03139820727265065		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.03139820727265065 | validation: 0.03860642121610844]
	TIME [epoch: 5.76 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03431376764711304		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.03431376764711304 | validation: 0.04066390274949926]
	TIME [epoch: 5.75 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030858456163643452		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.030858456163643452 | validation: 0.032987603819423436]
	TIME [epoch: 5.75 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032141367773384236		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.032141367773384236 | validation: 0.04940735826215486]
	TIME [epoch: 5.74 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03408971337621731		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.03408971337621731 | validation: 0.03451844087363943]
	TIME [epoch: 5.75 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03336462042845991		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.03336462042845991 | validation: 0.04412090607284124]
	TIME [epoch: 5.76 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030077116090945575		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.030077116090945575 | validation: 0.03264938455069236]
	TIME [epoch: 5.78 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02954575381717827		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.02954575381717827 | validation: 0.03602634878616914]
	TIME [epoch: 5.73 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03216695948330756		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.03216695948330756 | validation: 0.03559673849158108]
	TIME [epoch: 5.74 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03082027079762034		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.03082027079762034 | validation: 0.04115931923080707]
	TIME [epoch: 5.73 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035582054493196145		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.035582054493196145 | validation: 0.036708492293334206]
	TIME [epoch: 5.73 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031105048997989798		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.031105048997989798 | validation: 0.04467038218876412]
	TIME [epoch: 5.73 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03099760800072571		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.03099760800072571 | validation: 0.03162903179847123]
	TIME [epoch: 5.79 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028957421779131104		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.028957421779131104 | validation: 0.043498746641924914]
	TIME [epoch: 5.75 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03195099619845031		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.03195099619845031 | validation: 0.039944717870353995]
	TIME [epoch: 5.75 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030636859322541267		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.030636859322541267 | validation: 0.037912143323336756]
	TIME [epoch: 5.73 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031454191287214786		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.031454191287214786 | validation: 0.035251138761226736]
	TIME [epoch: 5.75 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03286177890192825		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.03286177890192825 | validation: 0.04590626781247198]
	TIME [epoch: 5.75 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034105392720297154		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.034105392720297154 | validation: 0.04216760795290685]
	TIME [epoch: 5.76 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03088551412809295		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.03088551412809295 | validation: 0.038870324857468413]
	TIME [epoch: 5.78 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03543285871936577		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.03543285871936577 | validation: 0.0450167036400594]
	TIME [epoch: 5.75 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03437274866727313		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.03437274866727313 | validation: 0.03382228322970491]
	TIME [epoch: 5.75 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03404159601913286		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.03404159601913286 | validation: 0.0382883435240216]
	TIME [epoch: 5.75 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034698228601094006		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.034698228601094006 | validation: 0.04739125191118562]
	TIME [epoch: 5.73 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03801148385282907		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.03801148385282907 | validation: 0.03399471886595669]
	TIME [epoch: 5.75 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035950273119795574		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.035950273119795574 | validation: 0.049111808601878394]
	TIME [epoch: 5.78 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035106480013690766		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.035106480013690766 | validation: 0.03668901287671417]
	TIME [epoch: 5.76 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03564760843176075		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.03564760843176075 | validation: 0.0387838157325809]
	TIME [epoch: 5.74 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485811800919717		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.03485811800919717 | validation: 0.03814752219264589]
	TIME [epoch: 5.74 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034511445769135674		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.034511445769135674 | validation: 0.032345148513196725]
	TIME [epoch: 5.75 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03224822725839807		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.03224822725839807 | validation: 0.04673662486741087]
	TIME [epoch: 5.75 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033058526756292596		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.033058526756292596 | validation: 0.036835606399202594]
	TIME [epoch: 5.76 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03418588873102832		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.03418588873102832 | validation: 0.03912282503425123]
	TIME [epoch: 5.78 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03218438950107704		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.03218438950107704 | validation: 0.03842479353705325]
	TIME [epoch: 5.75 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031249587505222845		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.031249587505222845 | validation: 0.0331891211318793]
	TIME [epoch: 5.75 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03452784949135646		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.03452784949135646 | validation: 0.03588371866858545]
	TIME [epoch: 5.75 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030703752636686815		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.030703752636686815 | validation: 0.04319354234277244]
	TIME [epoch: 5.74 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03250333245655826		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.03250333245655826 | validation: 0.03767827274722373]
	TIME [epoch: 5.75 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032771348290801784		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.032771348290801784 | validation: 0.03640897823063196]
	TIME [epoch: 5.79 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03406880145931359		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.03406880145931359 | validation: 0.046490604332518476]
	TIME [epoch: 5.75 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038054830144349704		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.038054830144349704 | validation: 0.043196107408709356]
	TIME [epoch: 5.75 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304540165184025		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.03304540165184025 | validation: 0.03341421630624461]
	TIME [epoch: 5.75 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032141841028026086		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.032141841028026086 | validation: 0.043609571055819085]
	TIME [epoch: 5.75 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028652554187539207		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.028652554187539207 | validation: 0.0374402548839581]
	TIME [epoch: 5.74 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031119807674408667		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.031119807674408667 | validation: 0.03839166696115387]
	TIME [epoch: 5.78 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03411852110379414		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.03411852110379414 | validation: 0.034988231080059266]
	TIME [epoch: 5.76 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03477149025268972		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.03477149025268972 | validation: 0.0423580653693903]
	TIME [epoch: 5.74 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03242665316856945		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.03242665316856945 | validation: 0.048789572174098676]
	TIME [epoch: 5.74 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031789134790048273		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.031789134790048273 | validation: 0.035558482521119796]
	TIME [epoch: 5.74 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03347499799193764		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.03347499799193764 | validation: 0.04331277672692282]
	TIME [epoch: 5.74 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03269557541080022		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.03269557541080022 | validation: 0.03860039685512756]
	TIME [epoch: 5.75 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03238497447676706		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.03238497447676706 | validation: 0.04314821366564822]
	TIME [epoch: 5.77 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03215817363008795		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.03215817363008795 | validation: 0.04236435320321534]
	TIME [epoch: 5.75 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03270628399521148		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.03270628399521148 | validation: 0.04174010610308027]
	TIME [epoch: 5.74 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03186276525737089		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.03186276525737089 | validation: 0.040438155584845877]
	TIME [epoch: 5.75 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037575376007669595		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.037575376007669595 | validation: 0.040223486323882555]
	TIME [epoch: 5.75 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03156010363957905		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.03156010363957905 | validation: 0.04373917847375159]
	TIME [epoch: 5.73 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03252468092181081		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.03252468092181081 | validation: 0.040089601837141886]
	TIME [epoch: 5.75 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320331760589943		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.03320331760589943 | validation: 0.04400924037630031]
	TIME [epoch: 5.75 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03259907288612121		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.03259907288612121 | validation: 0.04494322476118383]
	TIME [epoch: 5.74 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0370730023822638		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.0370730023822638 | validation: 0.04260798311629959]
	TIME [epoch: 5.75 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03674389769757819		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.03674389769757819 | validation: 0.04173065124567226]
	TIME [epoch: 5.74 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03455401137993748		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.03455401137993748 | validation: 0.04142750221917028]
	TIME [epoch: 5.75 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03237608619122963		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.03237608619122963 | validation: 0.03921033508302412]
	TIME [epoch: 5.75 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0347768305183193		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.0347768305183193 | validation: 0.03752890540564162]
	TIME [epoch: 5.77 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03495554374503753		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.03495554374503753 | validation: 0.03537236017404785]
	TIME [epoch: 5.73 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03626752344662615		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.03626752344662615 | validation: 0.04102815818827115]
	TIME [epoch: 5.73 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03262460170565942		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.03262460170565942 | validation: 0.04130616822270285]
	TIME [epoch: 5.73 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030796413207792753		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.030796413207792753 | validation: 0.046411178933896055]
	TIME [epoch: 5.73 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03407861474168271		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.03407861474168271 | validation: 0.03958506711657004]
	TIME [epoch: 5.74 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029990249724982126		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.029990249724982126 | validation: 0.05048550822634446]
	TIME [epoch: 5.79 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030692813703437134		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.030692813703437134 | validation: 0.04560284751665563]
	TIME [epoch: 5.75 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03420404097006237		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.03420404097006237 | validation: 0.04326941381697825]
	TIME [epoch: 5.75 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03199241329614695		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.03199241329614695 | validation: 0.037348130943946886]
	TIME [epoch: 5.73 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032037859796928414		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.032037859796928414 | validation: 0.03809113970783401]
	TIME [epoch: 5.73 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033862362185970586		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.033862362185970586 | validation: 0.04082016565061366]
	TIME [epoch: 5.74 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027779205811473917		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.027779205811473917 | validation: 0.04560454033284917]
	TIME [epoch: 5.76 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031928928319103156		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.031928928319103156 | validation: 0.038190545316637195]
	TIME [epoch: 5.76 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03267152988808326		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.03267152988808326 | validation: 0.03476805184111954]
	TIME [epoch: 5.73 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02891444721254689		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.02891444721254689 | validation: 0.05053275585464457]
	TIME [epoch: 5.74 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03114752497763107		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.03114752497763107 | validation: 0.04282469829817763]
	TIME [epoch: 5.74 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03031975807769901		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.03031975807769901 | validation: 0.04001106924010037]
	TIME [epoch: 5.73 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595147602239844		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.03595147602239844 | validation: 0.04510874103311137]
	TIME [epoch: 5.73 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034545832873183954		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.034545832873183954 | validation: 0.036673389910969696]
	TIME [epoch: 5.77 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032747655778366795		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.032747655778366795 | validation: 0.04080288187509588]
	TIME [epoch: 5.74 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03678006968699337		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.03678006968699337 | validation: 0.0342934546968028]
	TIME [epoch: 5.74 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035818432213410564		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.035818432213410564 | validation: 0.0525230015417479]
	TIME [epoch: 5.74 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03269288363079913		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.03269288363079913 | validation: 0.04051276768344974]
	TIME [epoch: 5.75 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03308848270229498		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.03308848270229498 | validation: 0.04014994740745202]
	TIME [epoch: 5.74 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033409619380120194		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.033409619380120194 | validation: 0.049229013649118844]
	TIME [epoch: 5.76 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03221236742477396		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.03221236742477396 | validation: 0.035292942793678964]
	TIME [epoch: 5.78 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03218466104772395		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.03218466104772395 | validation: 0.04107687523627039]
	TIME [epoch: 5.74 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030769597286510183		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.030769597286510183 | validation: 0.040313613768220444]
	TIME [epoch: 5.74 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03378481896818169		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.03378481896818169 | validation: 0.041420180173581116]
	TIME [epoch: 5.75 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03317855661665341		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.03317855661665341 | validation: 0.04114014539758735]
	TIME [epoch: 5.75 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03308172988992934		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.03308172988992934 | validation: 0.03933809319887667]
	TIME [epoch: 5.73 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033307270806474436		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.033307270806474436 | validation: 0.034545810746138106]
	TIME [epoch: 5.77 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033690580468796444		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.033690580468796444 | validation: 0.03379062122012402]
	TIME [epoch: 5.74 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030376072915080567		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.030376072915080567 | validation: 0.034946810273761966]
	TIME [epoch: 5.75 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0333670090973823		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.0333670090973823 | validation: 0.04472889466276996]
	TIME [epoch: 5.75 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029511372247332884		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.029511372247332884 | validation: 0.03417047150548746]
	TIME [epoch: 5.75 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033412297391337595		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.033412297391337595 | validation: 0.02938082247553348]
	TIME [epoch: 5.74 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03622287754716623		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.03622287754716623 | validation: 0.033744762933723554]
	TIME [epoch: 5.76 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03116749889622374		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.03116749889622374 | validation: 0.030983478687111612]
	TIME [epoch: 5.76 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03273056890248348		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.03273056890248348 | validation: 0.0362873307141446]
	TIME [epoch: 5.73 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0310231335511002		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.0310231335511002 | validation: 0.03895216653682849]
	TIME [epoch: 5.74 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03125100867834177		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.03125100867834177 | validation: 0.04128583130976932]
	TIME [epoch: 5.75 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03543053461095982		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.03543053461095982 | validation: 0.034310999184351924]
	TIME [epoch: 5.75 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02984577088072798		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.02984577088072798 | validation: 0.03489700137408222]
	TIME [epoch: 5.75 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558628787832268		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.03558628787832268 | validation: 0.040571047569053664]
	TIME [epoch: 5.79 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031926976914417995		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.031926976914417995 | validation: 0.035111276464918934]
	TIME [epoch: 5.75 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034682668541217564		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.034682668541217564 | validation: 0.039320615178438316]
	TIME [epoch: 5.75 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03338913373403016		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.03338913373403016 | validation: 0.045430100373769204]
	TIME [epoch: 5.75 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03629137499756384		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.03629137499756384 | validation: 0.04430637378979504]
	TIME [epoch: 5.75 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03238715647293925		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.03238715647293925 | validation: 0.03187057166951433]
	TIME [epoch: 5.75 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032653775873878896		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.032653775873878896 | validation: 0.04088630806494133]
	TIME [epoch: 5.78 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154007193231285		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.03154007193231285 | validation: 0.035439812376275824]
	TIME [epoch: 5.76 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030562718397950658		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.030562718397950658 | validation: 0.04241261691191836]
	TIME [epoch: 5.75 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030243343409271		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.030243343409271 | validation: 0.039128302859234125]
	TIME [epoch: 5.75 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03169077256172387		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.03169077256172387 | validation: 0.050157632271568435]
	TIME [epoch: 5.73 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03302282894166734		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.03302282894166734 | validation: 0.02680715335896912]
	TIME [epoch: 5.73 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03059294335974856		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.03059294335974856 | validation: 0.032200831234966615]
	TIME [epoch: 5.75 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036129876392211976		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.036129876392211976 | validation: 0.031404468335395154]
	TIME [epoch: 5.79 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03306327340557383		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.03306327340557383 | validation: 0.04024846393926578]
	TIME [epoch: 5.75 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03024288606228944		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.03024288606228944 | validation: 0.044438820503716]
	TIME [epoch: 5.73 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032673930010630486		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.032673930010630486 | validation: 0.03333709011531371]
	TIME [epoch: 5.75 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029285960274752276		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.029285960274752276 | validation: 0.04323528737101995]
	TIME [epoch: 5.75 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03425136603272651		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.03425136603272651 | validation: 0.03207850025674081]
	TIME [epoch: 5.75 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032218681899889495		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.032218681899889495 | validation: 0.0383661420881243]
	TIME [epoch: 5.76 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03438001546366365		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.03438001546366365 | validation: 0.03029640290637679]
	TIME [epoch: 5.74 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034303548289352385		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.034303548289352385 | validation: 0.04245105880643891]
	TIME [epoch: 5.74 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030629673508546444		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.030629673508546444 | validation: 0.03845532893007939]
	TIME [epoch: 5.74 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033957841815934774		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.033957841815934774 | validation: 0.037908083267151414]
	TIME [epoch: 5.73 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335246325943436		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.0335246325943436 | validation: 0.044585513395174206]
	TIME [epoch: 5.73 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03110116598777532		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.03110116598777532 | validation: 0.03869464769084303]
	TIME [epoch: 5.75 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03340346041235309		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.03340346041235309 | validation: 0.03886203605433365]
	TIME [epoch: 5.78 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313254236418371		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.03313254236418371 | validation: 0.04242381192930239]
	TIME [epoch: 5.75 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0327520152969495		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.0327520152969495 | validation: 0.0345738020554464]
	TIME [epoch: 5.75 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031080792442140383		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.031080792442140383 | validation: 0.0359813961315402]
	TIME [epoch: 5.75 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03331213923742928		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.03331213923742928 | validation: 0.044137415867032834]
	TIME [epoch: 5.75 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03350847257429162		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.03350847257429162 | validation: 0.03766810354536906]
	TIME [epoch: 5.73 sec]
Finished training in 11711.640 seconds.
