Args:
Namespace(name='model_tr_study202', outdir='out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2', training_data='data/transition_rate_studies/tr_study202/tr_study202_training/r2', validation_data='data/transition_rate_studies/tr_study202/tr_study202_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1994163076

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.605711721083717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.605711721083717 | validation: 11.57421967940675]
	TIME [epoch: 94.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.247138062793649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.247138062793649 | validation: 11.029808928140092]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.543533107745468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.543533107745468 | validation: 11.298413868523118]
	TIME [epoch: 5.75 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.381787279962126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.381787279962126 | validation: 11.163507641758532]
	TIME [epoch: 5.78 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.202974597438336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.202974597438336 | validation: 10.584422729387589]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.483660955875507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.483660955875507 | validation: 9.320499911340315]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.645855280840243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.645855280840243 | validation: 8.22878994937052]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.672352236186744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.672352236186744 | validation: 7.2902014636563495]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.418663766291849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.418663766291849 | validation: 7.8599233358353215]
	TIME [epoch: 5.75 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.618422924139411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.618422924139411 | validation: 7.076288736070877]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.098367751886201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.098367751886201 | validation: 6.5448804525914674]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1645657043269795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1645657043269795 | validation: 6.524153852929929]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.940332989812981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.940332989812981 | validation: 6.915747558341575]
	TIME [epoch: 5.76 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.919862640143309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.919862640143309 | validation: 6.841097318212422]
	TIME [epoch: 5.75 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.012452817031565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.012452817031565 | validation: 6.5454549415820145]
	TIME [epoch: 5.76 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.80459639505169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.80459639505169 | validation: 6.3660355049429915]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.669874272308613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.669874272308613 | validation: 6.572483328948882]
	TIME [epoch: 5.79 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.032364719550909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.032364719550909 | validation: 8.303895941021244]
	TIME [epoch: 5.76 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.59565250153847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.59565250153847 | validation: 6.4235943753938285]
	TIME [epoch: 5.75 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.817900351561381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.817900351561381 | validation: 6.711827633925789]
	TIME [epoch: 5.75 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.759084676916317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.759084676916317 | validation: 6.518225953609065]
	TIME [epoch: 5.76 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.78330012787289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.78330012787289 | validation: 6.3663579264158585]
	TIME [epoch: 5.75 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.713363272056639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.713363272056639 | validation: 6.63504638392381]
	TIME [epoch: 5.75 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.754823778422166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.754823778422166 | validation: 7.068830197985393]
	TIME [epoch: 5.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.71326235493329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.71326235493329 | validation: 6.2272443507364414]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485197542940347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.485197542940347 | validation: 6.277594829051423]
	TIME [epoch: 5.75 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459213212957459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.459213212957459 | validation: 6.0566101978558935]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.323973480581664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.323973480581664 | validation: 6.5575394150695105]
	TIME [epoch: 5.74 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.739710509685166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.739710509685166 | validation: 5.773513089009916]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.291848170816936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.291848170816936 | validation: 5.982176853304249]
	TIME [epoch: 5.77 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.248891937780359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.248891937780359 | validation: 5.751041550718772]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.193105758713031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.193105758713031 | validation: 5.84165809042277]
	TIME [epoch: 5.74 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2060719959242086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2060719959242086 | validation: 5.620332435878563]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.05380440659713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.05380440659713 | validation: 5.644036281315011]
	TIME [epoch: 5.76 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.077446969727894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.077446969727894 | validation: 5.532234428175015]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.003605627573482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.003605627573482 | validation: 5.593015934762887]
	TIME [epoch: 5.74 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.956731311745349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.956731311745349 | validation: 5.379622456837248]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7753098256926534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7753098256926534 | validation: 6.1287626037038745]
	TIME [epoch: 5.76 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8686379536265214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8686379536265214 | validation: 5.250981721862427]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.616953046733876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.616953046733876 | validation: 4.98825819048501]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.406208559689539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.406208559689539 | validation: 5.60236147478222]
	TIME [epoch: 5.74 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1623872796095402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1623872796095402 | validation: 5.340076813261033]
	TIME [epoch: 5.74 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0563471379513327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0563471379513327 | validation: 4.330901645073296]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9031748708077947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9031748708077947 | validation: 4.2818425663781845]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7978604915258236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7978604915258236 | validation: 4.157506081298723]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.052384897027203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.052384897027203 | validation: 4.374171093142622]
	TIME [epoch: 5.76 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.678203767615189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.678203767615189 | validation: 4.796924377086783]
	TIME [epoch: 5.75 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8402723488175647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8402723488175647 | validation: 4.424910059252613]
	TIME [epoch: 5.75 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.821582598691424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.821582598691424 | validation: 4.048670943207169]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6752810381283387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6752810381283387 | validation: 4.648606147464026]
	TIME [epoch: 5.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7302532187149007		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.7302532187149007 | validation: 5.367970608314671]
	TIME [epoch: 5.76 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1333277296555275		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.1333277296555275 | validation: 4.124986557099956]
	TIME [epoch: 5.75 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4278814793729957		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.4278814793729957 | validation: 4.750328573862078]
	TIME [epoch: 5.75 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.670680465499673		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.670680465499673 | validation: 4.350552489175053]
	TIME [epoch: 5.75 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6125739942796247		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.6125739942796247 | validation: 4.53966083792703]
	TIME [epoch: 5.75 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4445918935034143		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.4445918935034143 | validation: 3.967076201640161]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4248385483869184		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.4248385483869184 | validation: 4.287250327511457]
	TIME [epoch: 5.76 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5519412046840553		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.5519412046840553 | validation: 4.376233798835921]
	TIME [epoch: 5.75 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4518904313766012		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.4518904313766012 | validation: 3.968216922911629]
	TIME [epoch: 5.75 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.509622768802484		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.509622768802484 | validation: 4.238210995237141]
	TIME [epoch: 5.75 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.405819990753503		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.405819990753503 | validation: 3.8200302191472857]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2302300974103964		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.2302300974103964 | validation: 4.3151677858662]
	TIME [epoch: 5.79 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5357306005446		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.5357306005446 | validation: 4.018840653553682]
	TIME [epoch: 5.76 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4563867921293907		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.4563867921293907 | validation: 3.898355863258868]
	TIME [epoch: 5.75 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3039794241364433		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.3039794241364433 | validation: 4.010106701743245]
	TIME [epoch: 5.75 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4103751206704915		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.4103751206704915 | validation: 3.8009232179518455]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288754840756144		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.288754840756144 | validation: 3.9261486923001714]
	TIME [epoch: 5.76 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27584732889707		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.27584732889707 | validation: 4.180308721080189]
	TIME [epoch: 5.79 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.283267759976319		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.283267759976319 | validation: 3.697515807568813]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2338297578496826		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.2338297578496826 | validation: 3.9439589387019143]
	TIME [epoch: 5.75 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1452046154629816		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.1452046154629816 | validation: 4.3393754158678055]
	TIME [epoch: 5.75 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3646155560787774		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.3646155560787774 | validation: 4.009841215808058]
	TIME [epoch: 5.74 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.179781298486211		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.179781298486211 | validation: 3.7864286894943247]
	TIME [epoch: 5.75 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4537410942999998		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.4537410942999998 | validation: 4.38717682604701]
	TIME [epoch: 5.77 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3697042820934193		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.3697042820934193 | validation: 3.7636046731279573]
	TIME [epoch: 5.77 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9703000280837935		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.9703000280837935 | validation: 3.720247496027093]
	TIME [epoch: 5.74 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.990656201814552		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.990656201814552 | validation: 4.6850365051854785]
	TIME [epoch: 5.75 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3208071219405757		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.3208071219405757 | validation: 3.9657743751297607]
	TIME [epoch: 5.75 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1223060013837047		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.1223060013837047 | validation: 3.714029892251483]
	TIME [epoch: 5.74 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0749779611024652		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.0749779611024652 | validation: 3.813018472861146]
	TIME [epoch: 5.77 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.118126209328482		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.118126209328482 | validation: 3.98005162282371]
	TIME [epoch: 5.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071310659637315		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.071310659637315 | validation: 3.739004439790499]
	TIME [epoch: 5.74 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.134131678686006		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.134131678686006 | validation: 3.598561422388244]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9371817685746748		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.9371817685746748 | validation: 3.700209545729823]
	TIME [epoch: 5.75 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286835150987461		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.286835150987461 | validation: 3.6536887344793127]
	TIME [epoch: 5.74 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.042650137120128		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.042650137120128 | validation: 3.74847474906728]
	TIME [epoch: 5.76 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9052743419589246		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.9052743419589246 | validation: 4.482631694351236]
	TIME [epoch: 5.76 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.795576017565921		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.795576017565921 | validation: 4.291511660359823]
	TIME [epoch: 5.74 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2185228319005663		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.2185228319005663 | validation: 3.6007260486996495]
	TIME [epoch: 5.74 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071729094081483		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.071729094081483 | validation: 3.9708856952137364]
	TIME [epoch: 5.73 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4214825359296444		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.4214825359296444 | validation: 3.8427969014534673]
	TIME [epoch: 5.74 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1616677704951757		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.1616677704951757 | validation: 3.724798949159391]
	TIME [epoch: 5.77 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9584044721463045		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.9584044721463045 | validation: 3.7090379779919793]
	TIME [epoch: 5.76 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069129522538104		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.069129522538104 | validation: 3.62022217093891]
	TIME [epoch: 5.74 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.829433560164019		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.829433560164019 | validation: 3.6025049324491687]
	TIME [epoch: 5.74 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0218487237198097		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.0218487237198097 | validation: 3.4524476957897194]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.214274879955288		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.214274879955288 | validation: 3.527523799307934]
	TIME [epoch: 5.76 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8479493534225786		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.8479493534225786 | validation: 3.6265171500818028]
	TIME [epoch: 5.79 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.84189744485627		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.84189744485627 | validation: 3.813511489426607]
	TIME [epoch: 5.76 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9404010069849207		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.9404010069849207 | validation: 3.4216368485452624]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.036882864400223		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.036882864400223 | validation: 3.8409985949168255]
	TIME [epoch: 5.74 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1072222641890654		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.1072222641890654 | validation: 3.437345780351693]
	TIME [epoch: 5.74 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1078510310752074		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.1078510310752074 | validation: 3.9500651380160416]
	TIME [epoch: 5.74 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.921591690498126		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.921591690498126 | validation: 3.7365512392807396]
	TIME [epoch: 5.77 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.932168574311135		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.932168574311135 | validation: 3.753774329605194]
	TIME [epoch: 5.75 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8487242378624835		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.8487242378624835 | validation: 3.598517389049314]
	TIME [epoch: 5.74 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9879115309264388		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.9879115309264388 | validation: 3.439710774713923]
	TIME [epoch: 5.74 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9086519819785654		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.9086519819785654 | validation: 3.603638812848378]
	TIME [epoch: 5.74 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9167061235036968		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.9167061235036968 | validation: 3.784649536025501]
	TIME [epoch: 5.74 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.168008994792859		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.168008994792859 | validation: 3.5249122361026135]
	TIME [epoch: 5.74 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.183762843077311		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.183762843077311 | validation: 4.746748037911188]
	TIME [epoch: 5.78 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.165101966761304		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.165101966761304 | validation: 3.6406513753885212]
	TIME [epoch: 5.74 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.993866114369404		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.993866114369404 | validation: 3.7608441864891904]
	TIME [epoch: 5.74 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.906437615543602		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.906437615543602 | validation: 3.7385193038501248]
	TIME [epoch: 5.74 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8886686981919212		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.8886686981919212 | validation: 4.62191988431394]
	TIME [epoch: 5.74 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2104487376270483		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.2104487376270483 | validation: 3.5437445485030596]
	TIME [epoch: 5.74 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7557731437073403		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.7557731437073403 | validation: 3.856926951992747]
	TIME [epoch: 5.77 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8986578096644153		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.8986578096644153 | validation: 3.4705393790619277]
	TIME [epoch: 5.76 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.769270601768969		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.769270601768969 | validation: 3.594043908691383]
	TIME [epoch: 5.75 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7237550330462625		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.7237550330462625 | validation: 3.4091782242137096]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7978915853156516		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.7978915853156516 | validation: 3.549902325101341]
	TIME [epoch: 5.74 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8083567874469961		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.8083567874469961 | validation: 3.5213714755140657]
	TIME [epoch: 5.75 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8904612456688341		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.8904612456688341 | validation: 3.5721708265385392]
	TIME [epoch: 5.75 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7717456097844766		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.7717456097844766 | validation: 3.39896809460346]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7816913184692011		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.7816913184692011 | validation: 3.4258797985321685]
	TIME [epoch: 5.76 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8293005448524784		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.8293005448524784 | validation: 4.015858745491753]
	TIME [epoch: 5.76 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0281267830262015		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.0281267830262015 | validation: 3.3856692394248147]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.740818072485561		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.740818072485561 | validation: 3.647009488495604]
	TIME [epoch: 5.74 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8128232378527902		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.8128232378527902 | validation: 3.685852588284157]
	TIME [epoch: 5.74 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8121435660269019		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.8121435660269019 | validation: 3.706479275553179]
	TIME [epoch: 5.78 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8064854495295066		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.8064854495295066 | validation: 3.824792811963136]
	TIME [epoch: 5.74 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8164711681934815		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.8164711681934815 | validation: 3.581551153020965]
	TIME [epoch: 5.74 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8267367142002284		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.8267367142002284 | validation: 3.576572425990538]
	TIME [epoch: 5.73 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8220060748555142		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.8220060748555142 | validation: 3.4281542622273626]
	TIME [epoch: 5.74 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.735547233098138		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.735547233098138 | validation: 3.6942583406712766]
	TIME [epoch: 5.76 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7846343995274068		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.7846343995274068 | validation: 3.572148429249611]
	TIME [epoch: 5.75 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.983234345682401		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.983234345682401 | validation: 3.5037040727264497]
	TIME [epoch: 5.78 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8044588899536618		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.8044588899536618 | validation: 3.3713953136156034]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.824417100833563		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.824417100833563 | validation: 3.450076991275689]
	TIME [epoch: 5.75 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7426271028645741		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.7426271028645741 | validation: 3.394765393429219]
	TIME [epoch: 5.74 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.098596140584925		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.098596140584925 | validation: 3.331272055058718]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.711463160441253		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.711463160441253 | validation: 3.486407236757484]
	TIME [epoch: 5.75 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7783160762899601		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.7783160762899601 | validation: 3.355384509460796]
	TIME [epoch: 5.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7354708459816919		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.7354708459816919 | validation: 3.406823538601007]
	TIME [epoch: 5.76 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7232454931629368		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.7232454931629368 | validation: 3.3251688030167963]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7345884803783447		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.7345884803783447 | validation: 3.385060274552692]
	TIME [epoch: 5.75 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7265527489306989		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.7265527489306989 | validation: 3.4602387215799832]
	TIME [epoch: 5.74 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7465242882550196		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.7465242882550196 | validation: 3.377830668576932]
	TIME [epoch: 5.75 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7601090653745082		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.7601090653745082 | validation: 3.5439088173851876]
	TIME [epoch: 5.77 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7847762997885421		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.7847762997885421 | validation: 3.3953956504946237]
	TIME [epoch: 5.77 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6579873778400578		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.6579873778400578 | validation: 3.557120496016674]
	TIME [epoch: 5.74 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.737953826286873		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.737953826286873 | validation: 3.3922954321605348]
	TIME [epoch: 5.74 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5957236702041617		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.5957236702041617 | validation: 3.405927445558201]
	TIME [epoch: 5.76 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.670439786389532		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.670439786389532 | validation: 3.8401419321341157]
	TIME [epoch: 5.74 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7528091412962017		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.7528091412962017 | validation: 3.502956065195798]
	TIME [epoch: 5.74 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.822495560004218		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.822495560004218 | validation: 3.5819973666897376]
	TIME [epoch: 5.78 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9793381347214076		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.9793381347214076 | validation: 3.840372355223306]
	TIME [epoch: 5.75 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9044949564514777		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.9044949564514777 | validation: 3.6151304893318854]
	TIME [epoch: 5.75 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.723923652648006		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.723923652648006 | validation: 3.431519333498231]
	TIME [epoch: 5.75 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7036588961553252		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.7036588961553252 | validation: 3.3961366199750067]
	TIME [epoch: 5.75 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6677325870048285		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.6677325870048285 | validation: 3.489855409006923]
	TIME [epoch: 5.75 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7553285726012091		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.7553285726012091 | validation: 3.2623195125689337]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7223588661274896		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.7223588661274896 | validation: 3.737613617520137]
	TIME [epoch: 5.77 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8276338309420763		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.8276338309420763 | validation: 3.437132317566991]
	TIME [epoch: 5.74 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6404831499461328		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.6404831499461328 | validation: 3.562938033417068]
	TIME [epoch: 5.74 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8197360127697966		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.8197360127697966 | validation: 3.32749737466704]
	TIME [epoch: 5.74 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6879706676035953		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.6879706676035953 | validation: 3.566823860639328]
	TIME [epoch: 5.74 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7195684658290151		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.7195684658290151 | validation: 3.4310075024595874]
	TIME [epoch: 5.76 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5833167167943978		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.5833167167943978 | validation: 3.381689856155926]
	TIME [epoch: 5.79 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6752257188093647		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.6752257188093647 | validation: 3.3477824563144583]
	TIME [epoch: 5.77 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6749492125824141		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.6749492125824141 | validation: 3.2581762792274187]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6374920123493455		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.6374920123493455 | validation: 3.7362207739564623]
	TIME [epoch: 5.75 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7406536076156873		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.7406536076156873 | validation: 3.333361115257885]
	TIME [epoch: 5.77 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6581802256523348		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.6581802256523348 | validation: 3.392597248488576]
	TIME [epoch: 5.75 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6531058493475355		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.6531058493475355 | validation: 3.366417134117711]
	TIME [epoch: 5.79 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7100699108485975		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.7100699108485975 | validation: 3.397635337228092]
	TIME [epoch: 5.76 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7188394651893426		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.7188394651893426 | validation: 3.373210326502132]
	TIME [epoch: 5.77 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7860251516172103		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.7860251516172103 | validation: 3.241651719842539]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5442098594312594		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.5442098594312594 | validation: 3.801296737378]
	TIME [epoch: 5.76 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6753825030511837		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.6753825030511837 | validation: 3.573256183375841]
	TIME [epoch: 5.77 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6950732918989324		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.6950732918989324 | validation: 3.2964343533715703]
	TIME [epoch: 5.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6139331139097324		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.6139331139097324 | validation: 3.3126908929475714]
	TIME [epoch: 5.78 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6500524478778933		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.6500524478778933 | validation: 3.2470435090471668]
	TIME [epoch: 5.76 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7947934783626343		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.7947934783626343 | validation: 3.4885514613981288]
	TIME [epoch: 5.75 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7441828190985178		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.7441828190985178 | validation: 3.2504227709754305]
	TIME [epoch: 5.76 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6607963804570853		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.6607963804570853 | validation: 3.496218094587504]
	TIME [epoch: 5.76 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6451478893925586		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.6451478893925586 | validation: 3.242716475374399]
	TIME [epoch: 5.77 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6121359176170258		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.6121359176170258 | validation: 3.518223466506594]
	TIME [epoch: 5.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7882332017618976		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.7882332017618976 | validation: 3.6260154247493586]
	TIME [epoch: 5.76 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7733211388488355		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.7733211388488355 | validation: 3.68013723680357]
	TIME [epoch: 5.75 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7667695895407096		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.7667695895407096 | validation: 3.3670764106035223]
	TIME [epoch: 5.75 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.596197911462873		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.596197911462873 | validation: 3.472674623099006]
	TIME [epoch: 5.76 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.665361250300033		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.665361250300033 | validation: 3.4604005010313768]
	TIME [epoch: 5.75 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6319196733410573		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.6319196733410573 | validation: 3.275170052808807]
	TIME [epoch: 5.79 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5738685152020824		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.5738685152020824 | validation: 3.3301437874441024]
	TIME [epoch: 5.76 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5689155242706656		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.5689155242706656 | validation: 3.3413506450634363]
	TIME [epoch: 5.76 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6082506018208707		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.6082506018208707 | validation: 3.1910426602579514]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5459260618119957		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.5459260618119957 | validation: 3.3507848352252623]
	TIME [epoch: 5.75 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6121372569147057		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.6121372569147057 | validation: 3.4850296696092258]
	TIME [epoch: 5.75 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6171689605707684		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.6171689605707684 | validation: 3.272748726556125]
	TIME [epoch: 5.75 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.606408972336071		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.606408972336071 | validation: 3.3237152733868043]
	TIME [epoch: 5.79 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6111772803059248		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.6111772803059248 | validation: 3.3320694696889515]
	TIME [epoch: 5.75 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5975129509654955		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.5975129509654955 | validation: 3.3246704250560106]
	TIME [epoch: 5.75 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5971753686152985		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.5971753686152985 | validation: 3.221081767799693]
	TIME [epoch: 5.75 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6055733737162239		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.6055733737162239 | validation: 3.4494682757516433]
	TIME [epoch: 5.75 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6628412052849275		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.6628412052849275 | validation: 3.2377566979112773]
	TIME [epoch: 5.75 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.859303194571325		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.859303194571325 | validation: 3.2959692335037984]
	TIME [epoch: 5.77 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.579332169074889		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.579332169074889 | validation: 3.309827809031474]
	TIME [epoch: 5.76 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6262933924529066		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.6262933924529066 | validation: 3.2203507581770587]
	TIME [epoch: 5.75 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5819357566876637		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.5819357566876637 | validation: 3.4009074085518587]
	TIME [epoch: 5.75 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6498938541772123		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.6498938541772123 | validation: 3.2895052512976704]
	TIME [epoch: 5.75 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6370942586806454		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.6370942586806454 | validation: 3.4067474290265474]
	TIME [epoch: 5.75 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6527561991365012		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.6527561991365012 | validation: 3.202847395003604]
	TIME [epoch: 5.75 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5899273876077744		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.5899273876077744 | validation: 3.261505635368179]
	TIME [epoch: 5.79 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6761107168855505		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.6761107168855505 | validation: 3.1960729541806585]
	TIME [epoch: 5.75 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5737435175016958		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.5737435175016958 | validation: 3.230014944791824]
	TIME [epoch: 5.75 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5310913745810517		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.5310913745810517 | validation: 3.2448170723634377]
	TIME [epoch: 5.75 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6670180081063393		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.6670180081063393 | validation: 3.518509613918455]
	TIME [epoch: 5.75 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6988597081587447		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.6988597081587447 | validation: 3.1752124995830595]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7897089612906243		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.7897089612906243 | validation: 3.222578194184776]
	TIME [epoch: 5.78 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.653269040127376		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.653269040127376 | validation: 3.2192207821285583]
	TIME [epoch: 5.75 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5592967885416615		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.5592967885416615 | validation: 3.276166568926891]
	TIME [epoch: 5.75 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6449067487191087		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.6449067487191087 | validation: 3.356282652380007]
	TIME [epoch: 5.75 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.618876480396042		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.618876480396042 | validation: 3.2193286945850703]
	TIME [epoch: 5.74 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5654938124802817		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.5654938124802817 | validation: 3.2950684920675655]
	TIME [epoch: 5.74 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5823591017895675		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.5823591017895675 | validation: 3.1997186119611927]
	TIME [epoch: 5.76 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.666540188094469		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.666540188094469 | validation: 3.2797356752578253]
	TIME [epoch: 5.77 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5756901084039239		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.5756901084039239 | validation: 3.2693608996692745]
	TIME [epoch: 5.75 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7607347244374565		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.7607347244374565 | validation: 3.516581794531315]
	TIME [epoch: 5.75 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.623776062661207		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.623776062661207 | validation: 3.4206047665251424]
	TIME [epoch: 5.75 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5637720066887084		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.5637720066887084 | validation: 3.203869248885269]
	TIME [epoch: 5.74 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.631525598376093		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.631525598376093 | validation: 3.261880048882878]
	TIME [epoch: 5.75 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5632020726770337		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.5632020726770337 | validation: 3.1979235027258057]
	TIME [epoch: 5.78 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5515874805731809		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.5515874805731809 | validation: 3.3221721376471827]
	TIME [epoch: 5.75 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6033885594737947		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.6033885594737947 | validation: 3.166062100799976]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6108679403495851		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.6108679403495851 | validation: 3.624242717229762]
	TIME [epoch: 5.75 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.714750036714971		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.714750036714971 | validation: 3.2192977414931825]
	TIME [epoch: 5.74 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5981876436626694		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.5981876436626694 | validation: 3.273651500413818]
	TIME [epoch: 5.74 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6970136316339708		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.6970136316339708 | validation: 3.1675673713497026]
	TIME [epoch: 5.77 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6707481625753184		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.6707481625753184 | validation: 3.4672526339298124]
	TIME [epoch: 5.77 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.770307537740793		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.770307537740793 | validation: 3.231248561128575]
	TIME [epoch: 5.75 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5758963978392613		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.5758963978392613 | validation: 3.425024265241004]
	TIME [epoch: 5.75 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5886577564637774		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.5886577564637774 | validation: 3.3928257579628527]
	TIME [epoch: 5.75 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.856715751935841		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.856715751935841 | validation: 3.3071570957369056]
	TIME [epoch: 5.74 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6045623725341076		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.6045623725341076 | validation: 3.2089639532609295]
	TIME [epoch: 5.75 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5808353268671915		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.5808353268671915 | validation: 3.3440113707114474]
	TIME [epoch: 5.78 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5863656360303844		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.5863656360303844 | validation: 3.317306738321511]
	TIME [epoch: 5.75 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6023089328121827		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.6023089328121827 | validation: 3.4192869760385167]
	TIME [epoch: 5.75 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6683767300161148		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.6683767300161148 | validation: 3.2383817118923037]
	TIME [epoch: 5.74 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5360326185121689		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.5360326185121689 | validation: 3.3320384303140487]
	TIME [epoch: 5.74 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4942771161011335		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.4942771161011335 | validation: 3.1681796456076183]
	TIME [epoch: 5.74 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5396994737331866		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.5396994737331866 | validation: 3.252446666411298]
	TIME [epoch: 5.76 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5391123569581429		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.5391123569581429 | validation: 3.1665708104955392]
	TIME [epoch: 5.77 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5759571866486737		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.5759571866486737 | validation: 3.157945982199176]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7233719147874564		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.7233719147874564 | validation: 3.289958058242037]
	TIME [epoch: 5.75 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5726147560619745		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.5726147560619745 | validation: 3.2082797778311294]
	TIME [epoch: 5.76 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.564954301974436		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.564954301974436 | validation: 3.1870454406205146]
	TIME [epoch: 5.74 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4715652146992582		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.4715652146992582 | validation: 3.1760236607353263]
	TIME [epoch: 5.75 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5398502570258945		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.5398502570258945 | validation: 3.295050988560362]
	TIME [epoch: 5.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.534810353135105		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.534810353135105 | validation: 3.2132448962918545]
	TIME [epoch: 5.76 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5090771845244741		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.5090771845244741 | validation: 3.161791670387347]
	TIME [epoch: 5.75 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.506326621736588		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.506326621736588 | validation: 3.2394261578504553]
	TIME [epoch: 5.76 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5386406231946619		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.5386406231946619 | validation: 3.2121080408350036]
	TIME [epoch: 5.76 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5215232606872482		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.5215232606872482 | validation: 3.211155696402051]
	TIME [epoch: 5.74 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4790519674621716		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.4790519674621716 | validation: 3.1814870268912374]
	TIME [epoch: 5.79 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.462743204969461		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.462743204969461 | validation: 3.164760495739953]
	TIME [epoch: 5.77 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.598592704401974		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.598592704401974 | validation: 3.188577291827362]
	TIME [epoch: 5.75 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5307719155046773		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.5307719155046773 | validation: 3.249608108488652]
	TIME [epoch: 5.75 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4882187633999906		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.4882187633999906 | validation: 3.2024432028273613]
	TIME [epoch: 5.75 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.505150624289023		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.505150624289023 | validation: 3.18791663650734]
	TIME [epoch: 5.75 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.556711529999749		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.556711529999749 | validation: 3.1409662468049557]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4936626245947378		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.4936626245947378 | validation: 3.2076512497453997]
	TIME [epoch: 5.79 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4920987960941137		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.4920987960941137 | validation: 3.38316693080097]
	TIME [epoch: 5.75 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5496585048460876		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.5496585048460876 | validation: 3.1569001158387153]
	TIME [epoch: 5.75 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5092442569727098		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.5092442569727098 | validation: 3.221316033242085]
	TIME [epoch: 5.75 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4651873952243197		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.4651873952243197 | validation: 3.230153889440995]
	TIME [epoch: 5.75 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5370583248619307		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.5370583248619307 | validation: 3.5643202602494473]
	TIME [epoch: 5.75 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6043760710886117		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.6043760710886117 | validation: 3.182624935419863]
	TIME [epoch: 5.77 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4916579427890286		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.4916579427890286 | validation: 3.182807484355351]
	TIME [epoch: 5.77 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.562783737899038		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.562783737899038 | validation: 3.2339187229785704]
	TIME [epoch: 5.75 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4390492902610506		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.4390492902610506 | validation: 3.1605451250966623]
	TIME [epoch: 5.76 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4630058640034869		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.4630058640034869 | validation: 3.217849817477819]
	TIME [epoch: 5.75 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5551129875097682		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.5551129875097682 | validation: 3.1550810343321802]
	TIME [epoch: 5.74 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4722253811363577		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.4722253811363577 | validation: 3.1102305860554327]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.521398516083972		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.521398516083972 | validation: 3.182540646987127]
	TIME [epoch: 5.79 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.47210571507899		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.47210571507899 | validation: 3.1469104344791616]
	TIME [epoch: 5.74 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5586639065558985		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.5586639065558985 | validation: 3.184438102534256]
	TIME [epoch: 5.74 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.503149203465733		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.503149203465733 | validation: 3.362744649269972]
	TIME [epoch: 5.76 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5397994517233617		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.5397994517233617 | validation: 3.1388174796999904]
	TIME [epoch: 5.76 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5150525049016594		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.5150525049016594 | validation: 3.1660935647090755]
	TIME [epoch: 5.76 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.458836517522255		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.458836517522255 | validation: 3.3346136384071885]
	TIME [epoch: 5.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4801973349715292		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.4801973349715292 | validation: 3.1651039238566927]
	TIME [epoch: 5.76 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.452658422034214		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.452658422034214 | validation: 3.3401214040634666]
	TIME [epoch: 5.74 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.591722645200966		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.591722645200966 | validation: 3.605349448460687]
	TIME [epoch: 5.76 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6096998747620213		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.6096998747620213 | validation: 3.134582915894601]
	TIME [epoch: 5.75 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5397923356712524		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.5397923356712524 | validation: 3.184990952324503]
	TIME [epoch: 5.76 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5093661515560663		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.5093661515560663 | validation: 3.2274426538573233]
	TIME [epoch: 5.75 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4946123851668691		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.4946123851668691 | validation: 3.1934858452671895]
	TIME [epoch: 5.78 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5031655540441435		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.5031655540441435 | validation: 3.147285896713683]
	TIME [epoch: 5.74 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5337309526027938		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.5337309526027938 | validation: 3.1754185348330264]
	TIME [epoch: 5.76 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5906260603785154		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.5906260603785154 | validation: 3.814427491245325]
	TIME [epoch: 5.75 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6506917956208746		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.6506917956208746 | validation: 3.3872684732101046]
	TIME [epoch: 5.76 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5821862777224935		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.5821862777224935 | validation: 3.1445822727608084]
	TIME [epoch: 5.76 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4565079861434658		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.4565079861434658 | validation: 3.1351768529333093]
	TIME [epoch: 5.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6334522968876108		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.6334522968876108 | validation: 3.207240147709772]
	TIME [epoch: 5.76 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5075412486681936		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.5075412486681936 | validation: 3.5462562368953194]
	TIME [epoch: 5.76 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.651250615509928		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.651250615509928 | validation: 3.3302821796835365]
	TIME [epoch: 5.76 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5679198208156169		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.5679198208156169 | validation: 3.403041446541516]
	TIME [epoch: 5.76 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5638636739442402		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.5638636739442402 | validation: 3.1136567956482204]
	TIME [epoch: 5.76 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4489380634023419		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.4489380634023419 | validation: 3.337273087364493]
	TIME [epoch: 5.77 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5330858655092192		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.5330858655092192 | validation: 3.134343183803087]
	TIME [epoch: 5.79 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6047688492597416		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.6047688492597416 | validation: 3.3220046024118703]
	TIME [epoch: 5.76 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4617805746419612		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.4617805746419612 | validation: 3.1317135796712536]
	TIME [epoch: 5.76 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4993809597379277		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.4993809597379277 | validation: 3.149482801004207]
	TIME [epoch: 5.76 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4399263265091164		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.4399263265091164 | validation: 3.236418958847419]
	TIME [epoch: 5.76 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4724739680685999		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.4724739680685999 | validation: 3.367032863153655]
	TIME [epoch: 5.76 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.480683592083037		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.480683592083037 | validation: 3.1059823560529525]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5596566968074375		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.5596566968074375 | validation: 3.1523133755400945]
	TIME [epoch: 5.76 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.459427151627491		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.459427151627491 | validation: 3.11677273827857]
	TIME [epoch: 5.76 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4843061007093112		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.4843061007093112 | validation: 3.2166366173940864]
	TIME [epoch: 5.76 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4919189335594631		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.4919189335594631 | validation: 3.102710773642105]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.425955952314389		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.425955952314389 | validation: 3.1893988345740083]
	TIME [epoch: 5.74 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.529171682266316		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.529171682266316 | validation: 3.539663240698492]
	TIME [epoch: 5.77 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5736278808226611		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.5736278808226611 | validation: 3.1958536100760155]
	TIME [epoch: 5.76 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.476017437515237		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.476017437515237 | validation: 3.259988808791551]
	TIME [epoch: 5.74 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4868308575734006		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.4868308575734006 | validation: 3.1358848405333903]
	TIME [epoch: 5.74 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.472032378766172		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.472032378766172 | validation: 3.212760905033113]
	TIME [epoch: 5.74 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4679782118145845		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.4679782118145845 | validation: 3.1063437904020432]
	TIME [epoch: 5.74 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4216433858529078		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.4216433858529078 | validation: 3.203856889387758]
	TIME [epoch: 5.76 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4505175068936595		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.4505175068936595 | validation: 3.2258821344823043]
	TIME [epoch: 5.79 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.431771865185476		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.431771865185476 | validation: 3.124774169439055]
	TIME [epoch: 5.74 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4087272905645416		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.4087272905645416 | validation: 3.1944201495596043]
	TIME [epoch: 5.74 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.461166762695469		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.461166762695469 | validation: 3.159036412168792]
	TIME [epoch: 5.74 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4674635858978262		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.4674635858978262 | validation: 3.2471771750032397]
	TIME [epoch: 5.74 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4854887517041093		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.4854887517041093 | validation: 3.1849982060200204]
	TIME [epoch: 5.74 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4411307283257249		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.4411307283257249 | validation: 3.1862446301388516]
	TIME [epoch: 5.77 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4446458420876573		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.4446458420876573 | validation: 3.14603208739777]
	TIME [epoch: 5.75 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4518989994035485		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.4518989994035485 | validation: 3.2875552788658515]
	TIME [epoch: 5.74 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5054177926115693		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.5054177926115693 | validation: 3.2290920255797686]
	TIME [epoch: 5.74 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4583857680255108		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.4583857680255108 | validation: 3.0761899801207067]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4214847884607698		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.4214847884607698 | validation: 3.091937810116401]
	TIME [epoch: 5.74 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5175965977976789		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.5175965977976789 | validation: 3.164849426433897]
	TIME [epoch: 5.74 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5494626737675787		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.5494626737675787 | validation: 3.1910354977727633]
	TIME [epoch: 5.78 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.428720643896094		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.428720643896094 | validation: 3.306012590275403]
	TIME [epoch: 5.74 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5094221892569504		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.5094221892569504 | validation: 3.0804307257268437]
	TIME [epoch: 5.74 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3881821822256484		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.3881821822256484 | validation: 3.1404088392931406]
	TIME [epoch: 5.74 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4130829688699098		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.4130829688699098 | validation: 3.2019243714240737]
	TIME [epoch: 5.75 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4172622631805367		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.4172622631805367 | validation: 3.2654344275562575]
	TIME [epoch: 5.76 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4871633684758303		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.4871633684758303 | validation: 3.112826778664587]
	TIME [epoch: 5.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4276548373214921		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.4276548373214921 | validation: 3.341358058016343]
	TIME [epoch: 5.76 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5862032694745212		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.5862032694745212 | validation: 3.1229931834001325]
	TIME [epoch: 5.76 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.398453539695854		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.398453539695854 | validation: 3.0961316371108007]
	TIME [epoch: 5.76 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.531554951329532		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.531554951329532 | validation: 3.1523751118944565]
	TIME [epoch: 5.73 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3905420511497875		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.3905420511497875 | validation: 3.1043521146025617]
	TIME [epoch: 5.76 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4490818798753367		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.4490818798753367 | validation: 3.159465466378778]
	TIME [epoch: 5.77 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.469322473107868		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.469322473107868 | validation: 3.14203781508092]
	TIME [epoch: 5.78 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.443621208858691		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.443621208858691 | validation: 3.0801168281053855]
	TIME [epoch: 5.76 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4235090543248787		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.4235090543248787 | validation: 3.9941881778213175]
	TIME [epoch: 5.75 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7825062947472932		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.7825062947472932 | validation: 3.152332660683147]
	TIME [epoch: 5.75 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4059085492332855		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.4059085492332855 | validation: 3.121037568164485]
	TIME [epoch: 5.75 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4291019405585925		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.4291019405585925 | validation: 3.236722869204211]
	TIME [epoch: 5.75 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4055979140918324		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.4055979140918324 | validation: 3.080794444368613]
	TIME [epoch: 5.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4468914823968633		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.4468914823968633 | validation: 3.0952989704397584]
	TIME [epoch: 5.75 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3965204333889492		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.3965204333889492 | validation: 3.134507178396967]
	TIME [epoch: 5.76 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.426848824827896		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.426848824827896 | validation: 3.3322139197015628]
	TIME [epoch: 5.75 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5071297456337478		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.5071297456337478 | validation: 3.062594201109498]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.46553269508368		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.46553269508368 | validation: 3.1503943111885575]
	TIME [epoch: 5.76 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4128821474446087		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.4128821474446087 | validation: 3.107277953794678]
	TIME [epoch: 5.77 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3768824237953727		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.3768824237953727 | validation: 3.4546225578065526]
	TIME [epoch: 5.79 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5477920468373005		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.5477920468373005 | validation: 3.1958058151848823]
	TIME [epoch: 5.76 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4325163791816724		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.4325163791816724 | validation: 3.118610388400395]
	TIME [epoch: 5.75 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4692600246579532		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.4692600246579532 | validation: 3.2547707487283755]
	TIME [epoch: 5.75 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5560235081269254		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.5560235081269254 | validation: 3.109464768582395]
	TIME [epoch: 5.75 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4176037284828042		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.4176037284828042 | validation: 3.155191519883266]
	TIME [epoch: 5.75 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4522864289509902		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.4522864289509902 | validation: 3.135919926657461]
	TIME [epoch: 5.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.424869621941824		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.424869621941824 | validation: 3.1441150470439854]
	TIME [epoch: 5.76 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4002949328794594		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.4002949328794594 | validation: 3.2097739128776848]
	TIME [epoch: 5.76 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.48292951862762		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.48292951862762 | validation: 3.1259664800396623]
	TIME [epoch: 5.75 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.406973851798349		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.406973851798349 | validation: 3.2384581168474877]
	TIME [epoch: 5.74 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4236255783924086		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.4236255783924086 | validation: 3.097442139261653]
	TIME [epoch: 5.76 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3930072940578695		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.3930072940578695 | validation: 3.269895479816987]
	TIME [epoch: 5.76 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4266730443855598		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.4266730443855598 | validation: 3.316955360524478]
	TIME [epoch: 5.79 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5480503894897455		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.5480503894897455 | validation: 3.0583102819506873]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.483197807990168		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.483197807990168 | validation: 3.286653186119114]
	TIME [epoch: 5.76 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4850533608199483		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.4850533608199483 | validation: 3.160626719475485]
	TIME [epoch: 5.75 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4085040469358519		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.4085040469358519 | validation: 3.2111617537388746]
	TIME [epoch: 5.75 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5013046672151753		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.5013046672151753 | validation: 3.226506678770565]
	TIME [epoch: 5.75 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4465635990716568		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.4465635990716568 | validation: 3.059716936940972]
	TIME [epoch: 5.79 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3611941281768414		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.3611941281768414 | validation: 3.121577027778709]
	TIME [epoch: 5.76 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4328757148440943		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.4328757148440943 | validation: 3.1171527652013737]
	TIME [epoch: 5.76 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3844592898562682		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.3844592898562682 | validation: 3.0769198863125893]
	TIME [epoch: 5.74 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.381660367270861		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.381660367270861 | validation: 3.0889606432595778]
	TIME [epoch: 6.02 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3820574046967473		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.3820574046967473 | validation: 3.1472388652204883]
	TIME [epoch: 5.76 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.394612690241086		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.394612690241086 | validation: 3.0643993657528745]
	TIME [epoch: 5.79 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5491022935893664		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.5491022935893664 | validation: 3.1041006423521367]
	TIME [epoch: 5.77 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.409542739362735		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.409542739362735 | validation: 3.168514345324795]
	TIME [epoch: 5.76 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.39363121385051		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.39363121385051 | validation: 3.053257562163492]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3542186084017995		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.3542186084017995 | validation: 3.150001932739241]
	TIME [epoch: 5.76 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4284706361978623		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.4284706361978623 | validation: 3.103934253442133]
	TIME [epoch: 5.76 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4068351264500083		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.4068351264500083 | validation: 3.026544193951431]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3562422243062446		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.3562422243062446 | validation: 3.1785236551411593]
	TIME [epoch: 5.79 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3911328404429693		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.3911328404429693 | validation: 3.0517712069244904]
	TIME [epoch: 5.76 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.378247357586227		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.378247357586227 | validation: 3.1594702691105794]
	TIME [epoch: 5.76 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4102452432373453		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.4102452432373453 | validation: 3.1606166258039456]
	TIME [epoch: 5.76 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4300594350208033		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.4300594350208033 | validation: 3.207754740390297]
	TIME [epoch: 5.76 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4341306779824348		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.4341306779824348 | validation: 3.056805119084541]
	TIME [epoch: 5.76 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3710278210592972		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.3710278210592972 | validation: 3.094239038303897]
	TIME [epoch: 5.79 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3837029992151493		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.3837029992151493 | validation: 3.1461621259046932]
	TIME [epoch: 5.76 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3982699855423917		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.3982699855423917 | validation: 3.0858398013285173]
	TIME [epoch: 5.76 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.363132874719629		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.363132874719629 | validation: 3.1498123837679612]
	TIME [epoch: 5.76 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.35653367604689		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.35653367604689 | validation: 3.297544184524858]
	TIME [epoch: 5.76 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4106667807819948		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.4106667807819948 | validation: 3.0674049077521044]
	TIME [epoch: 5.76 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3978884149713677		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.3978884149713677 | validation: 3.0287928106504545]
	TIME [epoch: 5.77 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.410377154660668		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.410377154660668 | validation: 3.0790174463933524]
	TIME [epoch: 5.78 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3633847415146385		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.3633847415146385 | validation: 3.1154101588780225]
	TIME [epoch: 5.76 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.391851182924207		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.391851182924207 | validation: 3.172968190090742]
	TIME [epoch: 5.76 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4215813568343263		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.4215813568343263 | validation: 3.2056364760145026]
	TIME [epoch: 5.76 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4326352735279353		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.4326352735279353 | validation: 3.1989613783229105]
	TIME [epoch: 5.76 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4396496829622545		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.4396496829622545 | validation: 3.111041272634941]
	TIME [epoch: 5.76 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5540435610350984		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.5540435610350984 | validation: 3.3107721048392453]
	TIME [epoch: 5.79 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.484276027309178		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.484276027309178 | validation: 3.16355491196478]
	TIME [epoch: 5.76 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3980726311825356		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.3980726311825356 | validation: 3.121509093339816]
	TIME [epoch: 5.76 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3773048377234882		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.3773048377234882 | validation: 3.13783124242358]
	TIME [epoch: 5.76 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3594989369083343		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.3594989369083343 | validation: 3.1480656143773618]
	TIME [epoch: 5.76 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3865563934820448		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.3865563934820448 | validation: 3.2432602133377646]
	TIME [epoch: 5.76 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4467891529512555		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.4467891529512555 | validation: 3.1858440738201876]
	TIME [epoch: 5.77 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.367401331981052		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.367401331981052 | validation: 3.1197167921616598]
	TIME [epoch: 5.78 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3941564056502125		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.3941564056502125 | validation: 3.0943847908635718]
	TIME [epoch: 5.76 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5571287834805305		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.5571287834805305 | validation: 3.0861100907979586]
	TIME [epoch: 5.76 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3806347986927068		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.3806347986927068 | validation: 3.050719686277798]
	TIME [epoch: 5.76 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3852726627105292		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.3852726627105292 | validation: 3.0834648929981068]
	TIME [epoch: 5.76 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3462807943157322		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.3462807943157322 | validation: 3.050595492325002]
	TIME [epoch: 5.76 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.363489152435362		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.363489152435362 | validation: 3.0582788630430593]
	TIME [epoch: 5.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3523569972168037		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.3523569972168037 | validation: 3.04839468264146]
	TIME [epoch: 5.77 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3653558592890915		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.3653558592890915 | validation: 3.0711852180750316]
	TIME [epoch: 5.76 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3652522796845352		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.3652522796845352 | validation: 3.0865309912266516]
	TIME [epoch: 5.76 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4024396144273144		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.4024396144273144 | validation: 3.1265763703795573]
	TIME [epoch: 5.76 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3697699546910524		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.3697699546910524 | validation: 3.1259015225419917]
	TIME [epoch: 5.76 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4655996394765467		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.4655996394765467 | validation: 3.0794582433848934]
	TIME [epoch: 5.79 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3548320994243614		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.3548320994243614 | validation: 3.038231360719734]
	TIME [epoch: 5.75 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.35469191070229		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.35469191070229 | validation: 3.1079750597558853]
	TIME [epoch: 5.74 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.35930447129895		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.35930447129895 | validation: 3.0541426212498664]
	TIME [epoch: 5.76 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3360745955537956		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.3360745955537956 | validation: 3.0802172752604084]
	TIME [epoch: 5.76 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3502822958161707		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.3502822958161707 | validation: 3.166597090693564]
	TIME [epoch: 5.76 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4158713565281742		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.4158713565281742 | validation: 3.095704606810489]
	TIME [epoch: 5.76 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3507266107125369		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.3507266107125369 | validation: 3.1220228152138567]
	TIME [epoch: 5.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4478438917957874		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.4478438917957874 | validation: 3.1935667037822153]
	TIME [epoch: 5.76 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4478286051934184		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.4478286051934184 | validation: 3.065492971409201]
	TIME [epoch: 5.76 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3637076808483382		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.3637076808483382 | validation: 3.0835150682655765]
	TIME [epoch: 5.76 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3542731911408867		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.3542731911408867 | validation: 3.10457401676482]
	TIME [epoch: 5.76 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3813151314629568		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.3813151314629568 | validation: 3.0555085427284014]
	TIME [epoch: 5.76 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4063752505449534		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.4063752505449534 | validation: 3.0484417523492913]
	TIME [epoch: 5.78 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3533188489089645		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.3533188489089645 | validation: 3.130208656836871]
	TIME [epoch: 5.77 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4351576993847188		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.4351576993847188 | validation: 3.0243814300412617]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.423466120720545		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.423466120720545 | validation: 3.060784719648243]
	TIME [epoch: 5.76 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3677210558995188		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.3677210558995188 | validation: 3.036526984685996]
	TIME [epoch: 5.76 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.351796567335263		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.351796567335263 | validation: 3.064252290819131]
	TIME [epoch: 5.76 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.532806375803811		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.532806375803811 | validation: 3.1234423487585397]
	TIME [epoch: 5.76 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3604092103196312		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.3604092103196312 | validation: 3.0424750152210653]
	TIME [epoch: 5.78 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3608927701728706		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.3608927701728706 | validation: 3.136339974052987]
	TIME [epoch: 5.76 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3807685315474651		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.3807685315474651 | validation: 3.053288625502522]
	TIME [epoch: 5.76 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3329270273314575		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.3329270273314575 | validation: 3.093171861222196]
	TIME [epoch: 5.76 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3821889725904113		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.3821889725904113 | validation: 3.073374897572557]
	TIME [epoch: 5.74 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3354081837607157		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.3354081837607157 | validation: 3.0606475242461095]
	TIME [epoch: 5.75 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3648637402232158		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.3648637402232158 | validation: 3.035096191691189]
	TIME [epoch: 5.76 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3407874895348835		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.3407874895348835 | validation: 3.077661891729231]
	TIME [epoch: 5.76 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.391084160353527		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.391084160353527 | validation: 3.0993885356138056]
	TIME [epoch: 5.74 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3816770166693972		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.3816770166693972 | validation: 3.206503572082236]
	TIME [epoch: 5.74 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3984299413584282		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.3984299413584282 | validation: 3.0866165252186146]
	TIME [epoch: 5.74 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3901721607303263		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.3901721607303263 | validation: 3.0458293772888987]
	TIME [epoch: 5.74 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3530513863232276		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.3530513863232276 | validation: 3.0923464500668105]
	TIME [epoch: 5.74 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3866812549076701		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.3866812549076701 | validation: 3.041515470539157]
	TIME [epoch: 5.77 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3455482111586599		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.3455482111586599 | validation: 3.1735296939933764]
	TIME [epoch: 5.74 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3927287055721007		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.3927287055721007 | validation: 3.066099007440254]
	TIME [epoch: 5.74 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3316956992030615		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.3316956992030615 | validation: 3.0411058785879677]
	TIME [epoch: 5.74 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.352430284873237		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.352430284873237 | validation: 3.084675163578089]
	TIME [epoch: 5.76 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.324943830142854		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.324943830142854 | validation: 3.0375080073965672]
	TIME [epoch: 5.74 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3213189373908623		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.3213189373908623 | validation: 3.06649103170821]
	TIME [epoch: 5.77 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3338652628935206		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.3338652628935206 | validation: 3.082730050181158]
	TIME [epoch: 5.75 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3617020503277317		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.3617020503277317 | validation: 3.148619670925589]
	TIME [epoch: 5.74 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.473021967367473		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 1.473021967367473 | validation: 3.1285372219731644]
	TIME [epoch: 5.74 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3972678343214735		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 1.3972678343214735 | validation: 3.1854589676692644]
	TIME [epoch: 5.74 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.375982867612377		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.375982867612377 | validation: 3.054481022607382]
	TIME [epoch: 5.74 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3328816715605303		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.3328816715605303 | validation: 3.047867173865]
	TIME [epoch: 5.74 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3482368580906037		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.3482368580906037 | validation: 3.034802867573985]
	TIME [epoch: 5.78 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3741585297067191		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.3741585297067191 | validation: 3.045070497800752]
	TIME [epoch: 5.74 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3373244146226901		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.3373244146226901 | validation: 3.06169286216131]
	TIME [epoch: 5.74 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4094711002389957		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.4094711002389957 | validation: 3.143306803068959]
	TIME [epoch: 5.74 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3480361338503615		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.3480361338503615 | validation: 3.0419200413929874]
	TIME [epoch: 5.74 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.341606326881808		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.341606326881808 | validation: 3.100373478651179]
	TIME [epoch: 5.74 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3545510066728235		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.3545510066728235 | validation: 3.077175750459078]
	TIME [epoch: 5.77 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3800854561331755		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.3800854561331755 | validation: 3.0924099566104446]
	TIME [epoch: 5.75 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3833857422904003		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.3833857422904003 | validation: 3.1033659805450124]
	TIME [epoch: 5.74 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4016329065126107		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.4016329065126107 | validation: 3.160420080923694]
	TIME [epoch: 5.74 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.423141756946658		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.423141756946658 | validation: 3.2189142433053797]
	TIME [epoch: 5.74 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.397442449565999		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 1.397442449565999 | validation: 3.018279007932674]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3345422814958625		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.3345422814958625 | validation: 3.075126322402629]
	TIME [epoch: 5.76 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3521520583561115		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.3521520583561115 | validation: 3.0175465010232108]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3446991009416918		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.3446991009416918 | validation: 3.038513892385505]
	TIME [epoch: 5.74 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3191067138717611		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.3191067138717611 | validation: 3.0419980503049566]
	TIME [epoch: 5.74 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3077754487258964		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.3077754487258964 | validation: 3.064757405175318]
	TIME [epoch: 5.74 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3812000393871597		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.3812000393871597 | validation: 3.1192213008903664]
	TIME [epoch: 5.75 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4016926877301874		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.4016926877301874 | validation: 3.0441553263460834]
	TIME [epoch: 5.74 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3267674463759676		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 1.3267674463759676 | validation: 3.097827546428504]
	TIME [epoch: 5.78 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4134496629063809		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.4134496629063809 | validation: 3.0323572191192]
	TIME [epoch: 5.75 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3161281067864867		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.3161281067864867 | validation: 3.0547457932809365]
	TIME [epoch: 5.74 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3091420594731447		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.3091420594731447 | validation: 3.0894638822843867]
	TIME [epoch: 5.74 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3703746978430054		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.3703746978430054 | validation: 3.331955022845523]
	TIME [epoch: 5.74 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.41350236452638		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.41350236452638 | validation: 3.0318553959343477]
	TIME [epoch: 5.74 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.35994216086833		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.35994216086833 | validation: 3.0470899518024654]
	TIME [epoch: 5.75 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3413538917380934		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.3413538917380934 | validation: 3.1703137990535617]
	TIME [epoch: 5.79 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.360738711146059		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.360738711146059 | validation: 3.0578766738169207]
	TIME [epoch: 5.76 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.313113368805766		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.313113368805766 | validation: 3.013591071962234]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_513.pth
	Model improved!!!
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3135636099369778		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.3135636099369778 | validation: 3.137189776645605]
	TIME [epoch: 5.76 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3585266551150825		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.3585266551150825 | validation: 3.0196085064097553]
	TIME [epoch: 5.74 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.307173752505473		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 1.307173752505473 | validation: 3.070095289874993]
	TIME [epoch: 5.74 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3205391032540732		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.3205391032540732 | validation: 3.0344541544542585]
	TIME [epoch: 5.78 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.367374606633962		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.367374606633962 | validation: 3.0881530124429197]
	TIME [epoch: 5.74 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3896516677636892		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.3896516677636892 | validation: 3.043957054953086]
	TIME [epoch: 5.74 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3522046515154775		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.3522046515154775 | validation: 3.108662291232255]
	TIME [epoch: 5.74 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3493727658419739		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 1.3493727658419739 | validation: 3.032245218770264]
	TIME [epoch: 5.74 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3165390998766922		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.3165390998766922 | validation: 3.1312424262954948]
	TIME [epoch: 5.74 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4075095221401854		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.4075095221401854 | validation: 3.107436701762338]
	TIME [epoch: 5.76 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.336396308463557		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.336396308463557 | validation: 3.0985921298023915]
	TIME [epoch: 5.76 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3698099922171827		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 1.3698099922171827 | validation: 3.0333262902549416]
	TIME [epoch: 5.74 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3743350389401532		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.3743350389401532 | validation: 3.0397027127640577]
	TIME [epoch: 5.74 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3154588966494583		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.3154588966494583 | validation: 3.0317145275615918]
	TIME [epoch: 5.74 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3440860552808425		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.3440860552808425 | validation: 3.07592165220782]
	TIME [epoch: 5.74 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3474437061764166		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.3474437061764166 | validation: 3.044535810520839]
	TIME [epoch: 5.74 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3423896289212411		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 1.3423896289212411 | validation: 3.09143086870314]
	TIME [epoch: 5.78 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3470861842221664		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.3470861842221664 | validation: 3.011788581234482]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_531.pth
	Model improved!!!
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.338159378955307		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.338159378955307 | validation: 3.121337601120441]
	TIME [epoch: 5.76 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3841707482253234		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.3841707482253234 | validation: 3.0480903037845635]
	TIME [epoch: 5.76 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3401558124393882		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.3401558124393882 | validation: 3.0219372019771864]
	TIME [epoch: 5.74 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.303731758158718		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 1.303731758158718 | validation: 3.0323867385053838]
	TIME [epoch: 5.74 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3311217654959726		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 1.3311217654959726 | validation: 3.164144438942204]
	TIME [epoch: 5.77 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3355236968044564		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 1.3355236968044564 | validation: 3.072551137668256]
	TIME [epoch: 5.75 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3286721831963626		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 1.3286721831963626 | validation: 3.0384502574975163]
	TIME [epoch: 5.76 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3484505485895517		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 1.3484505485895517 | validation: 3.0274620813469677]
	TIME [epoch: 5.75 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3449954377134825		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.3449954377134825 | validation: 3.0897733344005944]
	TIME [epoch: 5.76 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3636800039602375		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.3636800039602375 | validation: 3.1201762833667748]
	TIME [epoch: 5.76 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.339330773573194		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 1.339330773573194 | validation: 3.051380838892173]
	TIME [epoch: 5.76 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3921690962388764		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 1.3921690962388764 | validation: 3.025893475101824]
	TIME [epoch: 5.78 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3397837101289038		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 1.3397837101289038 | validation: 3.0241120258644116]
	TIME [epoch: 5.76 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3039880194620241		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 1.3039880194620241 | validation: 3.038867511585072]
	TIME [epoch: 5.76 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.352881228777134		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 1.352881228777134 | validation: 3.0917944825957853]
	TIME [epoch: 5.76 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.343979212999245		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 1.343979212999245 | validation: 3.0833023077270947]
	TIME [epoch: 5.76 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3261391418931219		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 1.3261391418931219 | validation: 3.0489683781146892]
	TIME [epoch: 5.76 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3070925156236477		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 1.3070925156236477 | validation: 3.050206642760807]
	TIME [epoch: 5.79 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3367924810361187		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 1.3367924810361187 | validation: 3.048925012119327]
	TIME [epoch: 5.77 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2987309295066263		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 1.2987309295066263 | validation: 3.0707072976121506]
	TIME [epoch: 5.75 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3377274030151673		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 1.3377274030151673 | validation: 3.162328629272133]
	TIME [epoch: 5.76 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4207315889061234		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 1.4207315889061234 | validation: 3.04594645257573]
	TIME [epoch: 5.74 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3238417363816344		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 1.3238417363816344 | validation: 3.015762827067919]
	TIME [epoch: 5.74 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3008263614027327		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 1.3008263614027327 | validation: 3.0311207598844465]
	TIME [epoch: 5.77 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.316515165073059		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 1.316515165073059 | validation: 3.073530875676949]
	TIME [epoch: 5.79 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3081815549800204		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 1.3081815549800204 | validation: 3.0257190730202]
	TIME [epoch: 5.76 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3457782092526855		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 1.3457782092526855 | validation: 3.1262811973822027]
	TIME [epoch: 5.76 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.375539129172855		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.375539129172855 | validation: 3.0545743503182736]
	TIME [epoch: 5.76 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.330607372229966		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 1.330607372229966 | validation: 3.0221336309778084]
	TIME [epoch: 5.76 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3257524263571194		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 1.3257524263571194 | validation: 3.1100545024404505]
	TIME [epoch: 5.76 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4646810856578174		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 1.4646810856578174 | validation: 2.9998815762391065]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3271144405058222		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 1.3271144405058222 | validation: 3.0647370540942904]
	TIME [epoch: 5.77 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3105819534311258		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 1.3105819534311258 | validation: 3.001221028997518]
	TIME [epoch: 5.76 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3492439449804916		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 1.3492439449804916 | validation: 3.0484122967340346]
	TIME [epoch: 5.75 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3070909268771482		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 1.3070909268771482 | validation: 3.0324693918534087]
	TIME [epoch: 5.75 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3052582578470338		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.3052582578470338 | validation: 3.0170004117632154]
	TIME [epoch: 5.75 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3631143705005713		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 1.3631143705005713 | validation: 3.0305420706073205]
	TIME [epoch: 5.77 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3057129454285898		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 1.3057129454285898 | validation: 3.0255595364370915]
	TIME [epoch: 5.78 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3029249688007056		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.3029249688007056 | validation: 3.0427876221283485]
	TIME [epoch: 5.76 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3214116927241224		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 1.3214116927241224 | validation: 3.0171064817465374]
	TIME [epoch: 5.76 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3048152378729516		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 1.3048152378729516 | validation: 3.008718508171836]
	TIME [epoch: 5.75 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3264381446735212		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 1.3264381446735212 | validation: 3.2610148516237127]
	TIME [epoch: 5.75 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4451210664349174		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 1.4451210664349174 | validation: 3.023185802791009]
	TIME [epoch: 5.75 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3153942926159412		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 1.3153942926159412 | validation: 3.1327996792882518]
	TIME [epoch: 5.79 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3593370964198206		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 1.3593370964198206 | validation: 3.067819754802716]
	TIME [epoch: 5.76 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3093650638250547		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 1.3093650638250547 | validation: 3.004823925977306]
	TIME [epoch: 5.75 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4036828949072535		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 1.4036828949072535 | validation: 3.024466632308542]
	TIME [epoch: 5.73 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3309489069405347		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 1.3309489069405347 | validation: 3.01162216393315]
	TIME [epoch: 5.75 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3018389427666488		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 1.3018389427666488 | validation: 3.029072896435711]
	TIME [epoch: 5.75 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3347381952401727		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 1.3347381952401727 | validation: 3.1012636628329853]
	TIME [epoch: 5.77 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3354560787355716		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 1.3354560787355716 | validation: 3.0017548820192195]
	TIME [epoch: 5.79 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3206998228919962		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 1.3206998228919962 | validation: 3.107773048342774]
	TIME [epoch: 5.76 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3421295105399953		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 1.3421295105399953 | validation: 3.0429655267321993]
	TIME [epoch: 5.76 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2971744982355637		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 1.2971744982355637 | validation: 3.016467157717941]
	TIME [epoch: 5.75 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3709818625503365		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 1.3709818625503365 | validation: 3.0291465098920907]
	TIME [epoch: 5.75 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3583905168092132		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 1.3583905168092132 | validation: 3.0675106807214525]
	TIME [epoch: 5.75 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.309280490499672		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 1.309280490499672 | validation: 3.051286375219521]
	TIME [epoch: 5.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.321825224744861		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 1.321825224744861 | validation: 3.016336152961269]
	TIME [epoch: 5.76 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3155078411698735		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 1.3155078411698735 | validation: 3.0042749421971466]
	TIME [epoch: 5.75 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4826235660567186		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.4826235660567186 | validation: 3.0189421931821223]
	TIME [epoch: 5.75 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3729324038768334		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 1.3729324038768334 | validation: 3.037920889940385]
	TIME [epoch: 5.76 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3422357369540574		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 1.3422357369540574 | validation: 3.104363008293089]
	TIME [epoch: 5.75 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3310954452622643		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 1.3310954452622643 | validation: 3.044864696830726]
	TIME [epoch: 5.79 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.305353833929852		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 1.305353833929852 | validation: 3.040098796630829]
	TIME [epoch: 5.76 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2941082115081874		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 1.2941082115081874 | validation: 3.0173597153035803]
	TIME [epoch: 5.76 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3241260822728926		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 1.3241260822728926 | validation: 3.0577527851340656]
	TIME [epoch: 5.76 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3107084446591948		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 1.3107084446591948 | validation: 3.0319671715912775]
	TIME [epoch: 5.75 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2983812065391185		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 1.2983812065391185 | validation: 3.0137931049173483]
	TIME [epoch: 5.75 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3034556170057336		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 1.3034556170057336 | validation: 3.0436191319352623]
	TIME [epoch: 5.75 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.354910408024426		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 1.354910408024426 | validation: 2.9972509696779186]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_601.pth
	Model improved!!!
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3116039868785587		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 1.3116039868785587 | validation: 3.0204461030024983]
	TIME [epoch: 5.76 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2968912941327972		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 1.2968912941327972 | validation: 3.0059374619109467]
	TIME [epoch: 5.75 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3285191813671213		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 1.3285191813671213 | validation: 3.014894522362913]
	TIME [epoch: 5.74 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3008630111071606		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 1.3008630111071606 | validation: 3.0601996139859375]
	TIME [epoch: 5.75 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3041555145660084		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.3041555145660084 | validation: 3.063466992063166]
	TIME [epoch: 5.75 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.298107123113267		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 1.298107123113267 | validation: 3.009651984038697]
	TIME [epoch: 5.78 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3108408400891651		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 1.3108408400891651 | validation: 3.003663317496432]
	TIME [epoch: 5.76 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.304482989239363		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 1.304482989239363 | validation: 3.020548219234346]
	TIME [epoch: 5.75 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3106049840208416		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 1.3106049840208416 | validation: 3.0801342038031465]
	TIME [epoch: 5.76 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3199301324779389		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 1.3199301324779389 | validation: 3.0369029581929348]
	TIME [epoch: 5.75 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2973258590785384		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 1.2973258590785384 | validation: 3.1332596321401427]
	TIME [epoch: 5.76 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3214093591860272		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 1.3214093591860272 | validation: 3.005993943163479]
	TIME [epoch: 5.76 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3240690557431123		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 1.3240690557431123 | validation: 3.180129426302542]
	TIME [epoch: 5.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3529226751762038		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 1.3529226751762038 | validation: 3.1192837191685863]
	TIME [epoch: 5.76 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3321501215455023		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 1.3321501215455023 | validation: 3.049627675997188]
	TIME [epoch: 5.74 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.30570822411819		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 1.30570822411819 | validation: 3.074701806283199]
	TIME [epoch: 5.75 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2938326964530755		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 1.2938326964530755 | validation: 2.9945620576362098]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2941506953092405		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 1.2941506953092405 | validation: 3.0880991788293524]
	TIME [epoch: 5.75 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3120085218982007		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 1.3120085218982007 | validation: 3.0118925044301545]
	TIME [epoch: 5.79 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3167345173874674		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 1.3167345173874674 | validation: 3.053693809573543]
	TIME [epoch: 5.76 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3372726439921168		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 1.3372726439921168 | validation: 3.142029281805343]
	TIME [epoch: 5.75 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3719065573720568		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 1.3719065573720568 | validation: 2.9993238261394617]
	TIME [epoch: 5.74 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3209228512537183		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 1.3209228512537183 | validation: 3.056558810669344]
	TIME [epoch: 5.74 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.371212878245648		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 1.371212878245648 | validation: 3.0541435314445513]
	TIME [epoch: 5.74 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3002982710816084		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 1.3002982710816084 | validation: 3.0368274257807855]
	TIME [epoch: 5.75 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2947843092736777		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 1.2947843092736777 | validation: 2.9908010512945955]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_627.pth
	Model improved!!!
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.287709042610588		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 1.287709042610588 | validation: 3.0341594110299446]
	TIME [epoch: 5.76 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.311568617976568		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 1.311568617976568 | validation: 3.025681337791865]
	TIME [epoch: 5.76 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3068712002529252		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 1.3068712002529252 | validation: 3.0243067560231136]
	TIME [epoch: 5.76 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.304085275646896		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 1.304085275646896 | validation: 3.034531824800952]
	TIME [epoch: 5.77 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3355222588583002		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 1.3355222588583002 | validation: 3.0771482633370915]
	TIME [epoch: 5.76 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3275048145554793		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 1.3275048145554793 | validation: 3.0095259492419384]
	TIME [epoch: 5.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.30108861654284		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 1.30108861654284 | validation: 2.998072600931142]
	TIME [epoch: 5.76 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2963582592657532		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 1.2963582592657532 | validation: 3.024210061713294]
	TIME [epoch: 5.76 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2949846661641442		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 1.2949846661641442 | validation: 3.0709818205973707]
	TIME [epoch: 5.76 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3288710962983177		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 1.3288710962983177 | validation: 3.205948667699256]
	TIME [epoch: 5.76 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3961537963784507		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 1.3961537963784507 | validation: 3.094681733991161]
	TIME [epoch: 5.76 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3096229595248277		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 1.3096229595248277 | validation: 3.028279530964186]
	TIME [epoch: 5.79 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2936678868391707		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 1.2936678868391707 | validation: 3.0496413486489264]
	TIME [epoch: 5.77 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2966627396037138		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 1.2966627396037138 | validation: 3.038183807805026]
	TIME [epoch: 5.77 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3144343394174538		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 1.3144343394174538 | validation: 3.0009576412298307]
	TIME [epoch: 5.76 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2877974747694554		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 1.2877974747694554 | validation: 3.0992512012886584]
	TIME [epoch: 5.76 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3241672221238088		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 1.3241672221238088 | validation: 3.045808544341711]
	TIME [epoch: 5.76 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3203584684702014		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.3203584684702014 | validation: 3.0134511418198784]
	TIME [epoch: 5.76 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3005891525371167		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 1.3005891525371167 | validation: 3.0116284655590024]
	TIME [epoch: 5.81 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3125715739708868		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 1.3125715739708868 | validation: 3.014256965842755]
	TIME [epoch: 5.77 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.312028497290261		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 1.312028497290261 | validation: 3.088278232209619]
	TIME [epoch: 5.76 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3048159880248258		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 1.3048159880248258 | validation: 3.013370215048842]
	TIME [epoch: 5.76 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2838781446573289		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 1.2838781446573289 | validation: 3.023789778156078]
	TIME [epoch: 5.76 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2801073516102934		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 1.2801073516102934 | validation: 3.04060987061906]
	TIME [epoch: 5.76 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2806412231832762		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 1.2806412231832762 | validation: 3.0787922843660356]
	TIME [epoch: 5.79 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3353421610889615		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 1.3353421610889615 | validation: 3.044956496081903]
	TIME [epoch: 5.78 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3291721550344586		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 1.3291721550344586 | validation: 3.013470109155507]
	TIME [epoch: 5.77 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2789622925229156		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 1.2789622925229156 | validation: 3.0133163384554145]
	TIME [epoch: 5.76 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2808599150982927		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 1.2808599150982927 | validation: 3.008764725524628]
	TIME [epoch: 5.76 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.268180300847746		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 1.268180300847746 | validation: 2.9996080387137]
	TIME [epoch: 5.76 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.277851802533081		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 1.277851802533081 | validation: 3.0001105217983097]
	TIME [epoch: 5.76 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3067218387163253		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 1.3067218387163253 | validation: 3.012239600240049]
	TIME [epoch: 5.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.287964455010782		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 1.287964455010782 | validation: 3.0335837391979568]
	TIME [epoch: 5.77 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2850560016191643		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 1.2850560016191643 | validation: 3.011750794094593]
	TIME [epoch: 5.76 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.34099309896707		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 1.34099309896707 | validation: 3.002507654071517]
	TIME [epoch: 5.76 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2739245194951945		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 1.2739245194951945 | validation: 2.99517186349609]
	TIME [epoch: 5.76 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2808668903004563		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 1.2808668903004563 | validation: 3.116051665250001]
	TIME [epoch: 5.76 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2980338025599254		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 1.2980338025599254 | validation: 3.0004622394777702]
	TIME [epoch: 5.79 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2920845808187171		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 1.2920845808187171 | validation: 2.9992300986423643]
	TIME [epoch: 5.78 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3045662933798394		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 1.3045662933798394 | validation: 3.03226875126846]
	TIME [epoch: 5.76 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2843862810777025		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 1.2843862810777025 | validation: 2.99993507306977]
	TIME [epoch: 5.76 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3121907701782511		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 1.3121907701782511 | validation: 3.049262229098415]
	TIME [epoch: 5.76 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2914280261197906		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 1.2914280261197906 | validation: 3.0509606645702125]
	TIME [epoch: 5.76 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.298299363323394		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 1.298299363323394 | validation: 3.0255520837673586]
	TIME [epoch: 5.77 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2891154890743117		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 1.2891154890743117 | validation: 3.0025640351414795]
	TIME [epoch: 5.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2696002606241632		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 1.2696002606241632 | validation: 3.0340390601694494]
	TIME [epoch: 5.76 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3334160320969342		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 1.3334160320969342 | validation: 2.9895690312723833]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_674.pth
	Model improved!!!
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2733924342912695		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 1.2733924342912695 | validation: 3.0070571639928265]
	TIME [epoch: 5.76 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2665092769869408		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 1.2665092769869408 | validation: 3.0728019623971465]
	TIME [epoch: 5.76 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3098035859053674		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 1.3098035859053674 | validation: 3.0481731208153158]
	TIME [epoch: 5.76 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3333399154475216		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 1.3333399154475216 | validation: 2.996868142049553]
	TIME [epoch: 5.79 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2869462745493023		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 1.2869462745493023 | validation: 2.987060538870228]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_679.pth
	Model improved!!!
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3027220680434244		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 1.3027220680434244 | validation: 3.068183012779747]
	TIME [epoch: 5.76 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2912953121262727		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 1.2912953121262727 | validation: 3.029713076830507]
	TIME [epoch: 5.76 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3112307116211819		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 1.3112307116211819 | validation: 3.0029379947825663]
	TIME [epoch: 5.76 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2865678902428144		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 1.2865678902428144 | validation: 3.002904703843417]
	TIME [epoch: 5.76 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.292188550072694		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 1.292188550072694 | validation: 2.999726525289712]
	TIME [epoch: 5.78 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3262160990528673		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 1.3262160990528673 | validation: 3.0731009726773504]
	TIME [epoch: 5.77 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2882917934766638		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 1.2882917934766638 | validation: 3.023239038522412]
	TIME [epoch: 5.76 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2905912271682956		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 1.2905912271682956 | validation: 3.023972189468592]
	TIME [epoch: 5.74 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3063728510580503		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 1.3063728510580503 | validation: 3.0404865660519387]
	TIME [epoch: 5.76 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2972194718089507		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 1.2972194718089507 | validation: 3.050066951272938]
	TIME [epoch: 5.74 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2948283203477415		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 1.2948283203477415 | validation: 3.0188667803909857]
	TIME [epoch: 5.75 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2883567556145308		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 1.2883567556145308 | validation: 3.048296597817865]
	TIME [epoch: 5.79 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2985026390938774		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 1.2985026390938774 | validation: 3.004563768294507]
	TIME [epoch: 5.76 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2656528105195575		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 1.2656528105195575 | validation: 2.993326215519934]
	TIME [epoch: 5.76 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2825519649629533		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 1.2825519649629533 | validation: 3.0004678525755804]
	TIME [epoch: 5.75 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2780089374126264		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 1.2780089374126264 | validation: 3.0292571045350076]
	TIME [epoch: 5.76 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2866420611631415		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 1.2866420611631415 | validation: 2.978510199691232]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.272595964902861		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 1.272595964902861 | validation: 2.9943825486266995]
	TIME [epoch: 5.79 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.276161256005475		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 1.276161256005475 | validation: 3.0071819907043675]
	TIME [epoch: 5.77 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2950553912290248		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 1.2950553912290248 | validation: 3.029596926018677]
	TIME [epoch: 5.74 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3267457403950602		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 1.3267457403950602 | validation: 2.9931701767549863]
	TIME [epoch: 5.74 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2791499143568776		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 1.2791499143568776 | validation: 2.990704102503635]
	TIME [epoch: 5.75 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2911543993383305		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 1.2911543993383305 | validation: 3.0514885796819686]
	TIME [epoch: 5.75 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3077114061392896		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 1.3077114061392896 | validation: 3.035325888714313]
	TIME [epoch: 5.74 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3122860304130701		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 1.3122860304130701 | validation: 3.0702515561230896]
	TIME [epoch: 5.78 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3028108215813887		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 1.3028108215813887 | validation: 3.12057263766411]
	TIME [epoch: 5.74 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3224040807425537		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 1.3224040807425537 | validation: 3.046144636289904]
	TIME [epoch: 5.74 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3126205047753414		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 1.3126205047753414 | validation: 3.022703871306461]
	TIME [epoch: 5.74 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2800338478340971		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 1.2800338478340971 | validation: 3.012677088459241]
	TIME [epoch: 5.74 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2691396239086192		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 1.2691396239086192 | validation: 3.015599149985161]
	TIME [epoch: 5.73 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3379482842878987		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 1.3379482842878987 | validation: 3.001605755229755]
	TIME [epoch: 5.76 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2814997403047401		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 1.2814997403047401 | validation: 3.0010466423208575]
	TIME [epoch: 5.75 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.281680061269801		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 1.281680061269801 | validation: 3.0027899543576972]
	TIME [epoch: 5.74 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.284219306546853		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 1.284219306546853 | validation: 2.9963968688937395]
	TIME [epoch: 5.75 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.289697135092621		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 1.289697135092621 | validation: 2.9738020527581366]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_714.pth
	Model improved!!!
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2825817142813754		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 1.2825817142813754 | validation: 2.9760302212562837]
	TIME [epoch: 5.75 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2768170283066298		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 1.2768170283066298 | validation: 3.0002372859278243]
	TIME [epoch: 5.77 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2699682639059238		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 1.2699682639059238 | validation: 3.0100546769393532]
	TIME [epoch: 5.78 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3075264755822487		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 1.3075264755822487 | validation: 3.00172313691964]
	TIME [epoch: 5.74 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2802252912083194		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 1.2802252912083194 | validation: 2.989937568683465]
	TIME [epoch: 5.74 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.279237741051987		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 1.279237741051987 | validation: 2.994811276209423]
	TIME [epoch: 5.74 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2626896379146433		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 1.2626896379146433 | validation: 3.0311046000764224]
	TIME [epoch: 5.74 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2858073280446072		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 1.2858073280446072 | validation: 2.9929138190453797]
	TIME [epoch: 5.73 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2835561381697551		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 1.2835561381697551 | validation: 3.1372043159524385]
	TIME [epoch: 5.77 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4394993102592475		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 1.4394993102592475 | validation: 3.0626491234995474]
	TIME [epoch: 5.74 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3123215551713254		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 1.3123215551713254 | validation: 3.011034055740907]
	TIME [epoch: 5.74 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.272860079448632		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 1.272860079448632 | validation: 3.0292257717115683]
	TIME [epoch: 5.73 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2846515953587603		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 1.2846515953587603 | validation: 3.0414643039509213]
	TIME [epoch: 5.74 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2810283999189942		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 1.2810283999189942 | validation: 2.994631352675932]
	TIME [epoch: 5.74 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2892908119976685		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 1.2892908119976685 | validation: 3.018868088838772]
	TIME [epoch: 5.75 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2921705754079265		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 1.2921705754079265 | validation: 2.9921222592882804]
	TIME [epoch: 5.78 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2669861568142258		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 1.2669861568142258 | validation: 2.990973386978477]
	TIME [epoch: 5.74 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2702940929472084		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 1.2702940929472084 | validation: 3.1100040086533047]
	TIME [epoch: 5.75 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3140762089762013		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 1.3140762089762013 | validation: 3.0183178042727197]
	TIME [epoch: 5.74 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2730375266387113		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 1.2730375266387113 | validation: 2.984264421993438]
	TIME [epoch: 5.74 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.266691666699369		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 1.266691666699369 | validation: 3.0095943436099617]
	TIME [epoch: 5.74 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.28687505500171		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 1.28687505500171 | validation: 3.006111837480317]
	TIME [epoch: 5.78 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2792198494107896		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 1.2792198494107896 | validation: 2.98655626777499]
	TIME [epoch: 5.74 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.268902805471633		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 1.268902805471633 | validation: 2.9837224397920057]
	TIME [epoch: 5.74 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2551069949923634		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 1.2551069949923634 | validation: 3.0483251480243765]
	TIME [epoch: 5.76 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3189657838364504		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 1.3189657838364504 | validation: 3.0312906923221785]
	TIME [epoch: 5.74 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.274502506290056		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 1.274502506290056 | validation: 2.9867223528745344]
	TIME [epoch: 5.73 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2773554948031083		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 1.2773554948031083 | validation: 3.03157000032876]
	TIME [epoch: 5.75 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2768199926417507		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 1.2768199926417507 | validation: 3.0034934862896567]
	TIME [epoch: 5.77 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.27031743170539		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 1.27031743170539 | validation: 3.030190836345243]
	TIME [epoch: 5.74 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2950125306385147		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 1.2950125306385147 | validation: 3.010423348340118]
	TIME [epoch: 5.74 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.297262633982644		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 1.297262633982644 | validation: 2.993253999894486]
	TIME [epoch: 5.74 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2691579989427115		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 1.2691579989427115 | validation: 2.984151926720932]
	TIME [epoch: 5.74 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2886077114390393		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 1.2886077114390393 | validation: 2.9850842028596816]
	TIME [epoch: 5.75 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.259104521070339		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 1.259104521070339 | validation: 3.001459571367301]
	TIME [epoch: 5.79 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2828487345727821		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 1.2828487345727821 | validation: 3.0001042744377697]
	TIME [epoch: 5.74 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2722453104360065		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 1.2722453104360065 | validation: 3.0155127062348503]
	TIME [epoch: 5.75 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2783244847028719		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 1.2783244847028719 | validation: 3.006116263926727]
	TIME [epoch: 5.74 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2826620738884795		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 1.2826620738884795 | validation: 2.997848190517484]
	TIME [epoch: 5.74 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2624385561533291		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 1.2624385561533291 | validation: 2.9965948130150646]
	TIME [epoch: 5.74 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2627630615065366		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 1.2627630615065366 | validation: 3.009447842672644]
	TIME [epoch: 5.75 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2830243064255011		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 1.2830243064255011 | validation: 3.0516219459876464]
	TIME [epoch: 5.76 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.277968346183565		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 1.277968346183565 | validation: 3.004869871529412]
	TIME [epoch: 5.74 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2682242360549338		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 1.2682242360549338 | validation: 2.988629489640264]
	TIME [epoch: 5.73 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.261015283180335		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 1.261015283180335 | validation: 3.0071855306084756]
	TIME [epoch: 5.73 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2639563788709451		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 1.2639563788709451 | validation: 3.025882531418997]
	TIME [epoch: 5.73 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2733261490950054		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 1.2733261490950054 | validation: 2.9857110571205023]
	TIME [epoch: 5.73 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.277542306918523		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 1.277542306918523 | validation: 3.00032216582778]
	TIME [epoch: 5.77 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.282294990479635		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 1.282294990479635 | validation: 2.9929592352876218]
	TIME [epoch: 5.74 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3037177285111756		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 1.3037177285111756 | validation: 2.9931187437350624]
	TIME [epoch: 5.74 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2884382079632015		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 1.2884382079632015 | validation: 3.0250061429238757]
	TIME [epoch: 5.74 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.268798388218514		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 1.268798388218514 | validation: 2.98889177018015]
	TIME [epoch: 5.73 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2730076549224079		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 1.2730076549224079 | validation: 3.0283615004123674]
	TIME [epoch: 5.73 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2760693125725031		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 1.2760693125725031 | validation: 2.9934927333933854]
	TIME [epoch: 5.75 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2679878634129005		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 1.2679878634129005 | validation: 3.015642744443244]
	TIME [epoch: 5.78 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2696136064020371		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 1.2696136064020371 | validation: 2.9830660836143172]
	TIME [epoch: 5.74 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2866996959215669		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 1.2866996959215669 | validation: 3.003665080506082]
	TIME [epoch: 5.74 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2637082425421393		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 1.2637082425421393 | validation: 2.992456794948964]
	TIME [epoch: 5.74 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.288156732391665		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 1.288156732391665 | validation: 3.0209049191255373]
	TIME [epoch: 5.74 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2848767834535155		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 1.2848767834535155 | validation: 3.010635475882707]
	TIME [epoch: 5.74 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2782641251387825		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 1.2782641251387825 | validation: 3.0376968299704177]
	TIME [epoch: 5.78 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2978027710579036		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 1.2978027710579036 | validation: 3.010886426597766]
	TIME [epoch: 5.74 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2862438467718331		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 1.2862438467718331 | validation: 3.0241500854149956]
	TIME [epoch: 5.74 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.278178879111437		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 1.278178879111437 | validation: 2.990351427009806]
	TIME [epoch: 5.74 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2678676663091002		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 1.2678676663091002 | validation: 3.0195812380995095]
	TIME [epoch: 5.74 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2659900037373957		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 1.2659900037373957 | validation: 2.9835153166104926]
	TIME [epoch: 5.75 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2603389835451746		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 1.2603389835451746 | validation: 2.9913869660840042]
	TIME [epoch: 5.75 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.252113275331269		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 1.252113275331269 | validation: 2.999910316574775]
	TIME [epoch: 5.76 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2945129473891739		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 1.2945129473891739 | validation: 2.9865819914805547]
	TIME [epoch: 5.74 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2700698343746053		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 1.2700698343746053 | validation: 2.990020778569569]
	TIME [epoch: 5.74 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2590768921465751		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 1.2590768921465751 | validation: 3.0312715288715344]
	TIME [epoch: 5.74 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2657891852995626		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 1.2657891852995626 | validation: 3.002924763950872]
	TIME [epoch: 5.74 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2618152921234245		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 1.2618152921234245 | validation: 3.0659047437090625]
	TIME [epoch: 5.74 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3464772288249658		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 1.3464772288249658 | validation: 2.992522071362181]
	TIME [epoch: 5.78 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2710948358312084		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 1.2710948358312084 | validation: 3.0078764735701053]
	TIME [epoch: 5.76 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.261033177299578		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 1.261033177299578 | validation: 3.014931479631224]
	TIME [epoch: 5.74 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2743343656085648		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 1.2743343656085648 | validation: 3.065740066006077]
	TIME [epoch: 5.74 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3215897477900815		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 1.3215897477900815 | validation: 2.998847256574277]
	TIME [epoch: 5.74 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2740298783609314		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 1.2740298783609314 | validation: 3.0132851889726693]
	TIME [epoch: 5.74 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.263908679996523		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 1.263908679996523 | validation: 2.983242853282813]
	TIME [epoch: 5.75 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2684087265130972		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 1.2684087265130972 | validation: 2.989591798374919]
	TIME [epoch: 5.78 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2650074795169104		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 1.2650074795169104 | validation: 3.001049752364344]
	TIME [epoch: 5.76 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2619690569923683		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 1.2619690569923683 | validation: 2.986901738745104]
	TIME [epoch: 5.74 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.259867059958537		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 1.259867059958537 | validation: 2.983082023537178]
	TIME [epoch: 5.74 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2558637738421345		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 1.2558637738421345 | validation: 2.974501410257291]
	TIME [epoch: 5.74 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.286551252673676		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 1.286551252673676 | validation: 3.039830757676832]
	TIME [epoch: 5.73 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2694821438107418		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 1.2694821438107418 | validation: 3.0089709226334165]
	TIME [epoch: 5.79 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3024902144309118		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 1.3024902144309118 | validation: 3.020077919287211]
	TIME [epoch: 5.74 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.275662688654552		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 1.275662688654552 | validation: 2.9905540213568247]
	TIME [epoch: 5.74 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.276598929989551		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 1.276598929989551 | validation: 2.9918789081260093]
	TIME [epoch: 5.74 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2607063254249116		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 1.2607063254249116 | validation: 2.9929349621622756]
	TIME [epoch: 5.73 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2712595611286845		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 1.2712595611286845 | validation: 2.980971033934843]
	TIME [epoch: 5.74 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.281622918089748		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 1.281622918089748 | validation: 3.0592930437857935]
	TIME [epoch: 5.76 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2766865737738193		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 1.2766865737738193 | validation: 3.005214234015531]
	TIME [epoch: 5.76 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2616295180709547		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 1.2616295180709547 | validation: 2.97455729290416]
	TIME [epoch: 5.74 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2788630139812538		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 1.2788630139812538 | validation: 2.989640893764291]
	TIME [epoch: 5.73 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2710447064439265		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 1.2710447064439265 | validation: 3.012572060768812]
	TIME [epoch: 5.75 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2688430220444447		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 1.2688430220444447 | validation: 3.009792399766395]
	TIME [epoch: 5.74 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2934825406677732		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 1.2934825406677732 | validation: 3.060146484844853]
	TIME [epoch: 5.74 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2821695312282084		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 1.2821695312282084 | validation: 2.9801091074105934]
	TIME [epoch: 5.78 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.269006050004367		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 1.269006050004367 | validation: 3.0758801980058736]
	TIME [epoch: 5.74 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2846634577119365		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 1.2846634577119365 | validation: 3.005235068446222]
	TIME [epoch: 5.73 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2810295266246516		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 1.2810295266246516 | validation: 3.0664130433153014]
	TIME [epoch: 5.74 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.317461330360063		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 1.317461330360063 | validation: 3.0330149435509974]
	TIME [epoch: 5.73 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2681839606115028		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 1.2681839606115028 | validation: 3.0102719208680497]
	TIME [epoch: 5.74 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2889610879655586		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 1.2889610879655586 | validation: 2.9955071835009868]
	TIME [epoch: 5.77 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.268799837806143		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 1.268799837806143 | validation: 3.001880705478247]
	TIME [epoch: 5.76 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2650121940124188		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 1.2650121940124188 | validation: 2.9909495138962154]
	TIME [epoch: 5.74 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.254903295036614		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 1.254903295036614 | validation: 2.9867913244154556]
	TIME [epoch: 5.74 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2607225250237883		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 1.2607225250237883 | validation: 2.9786696466894376]
	TIME [epoch: 5.74 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.263277912606695		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 1.263277912606695 | validation: 2.979605984178726]
	TIME [epoch: 5.76 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2805577591468051		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 1.2805577591468051 | validation: 3.0112917040968843]
	TIME [epoch: 5.74 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257677808823888		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 1.257677808823888 | validation: 2.9795736876736023]
	TIME [epoch: 5.78 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2557586071861278		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 1.2557586071861278 | validation: 3.002340068044008]
	TIME [epoch: 5.74 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2495864118939075		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 1.2495864118939075 | validation: 2.97644186828972]
	TIME [epoch: 5.73 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2734881043536603		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 1.2734881043536603 | validation: 2.9952872990650348]
	TIME [epoch: 5.74 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2598909296307064		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 1.2598909296307064 | validation: 2.9880905818387213]
	TIME [epoch: 5.73 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2656439568702675		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 1.2656439568702675 | validation: 2.978052228617968]
	TIME [epoch: 5.75 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2762004602755346		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 1.2762004602755346 | validation: 2.9927607793041737]
	TIME [epoch: 5.78 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2532505282127813		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 1.2532505282127813 | validation: 2.9733381676467787]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_834.pth
	Model improved!!!
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2523519000492769		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 1.2523519000492769 | validation: 2.9949699744843894]
	TIME [epoch: 5.76 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2631556301381996		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 1.2631556301381996 | validation: 3.0137263181907343]
	TIME [epoch: 5.75 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2903229927024045		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 1.2903229927024045 | validation: 2.9986354127348274]
	TIME [epoch: 5.75 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2675822539334116		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 1.2675822539334116 | validation: 2.9980689234302393]
	TIME [epoch: 5.75 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2774870943620527		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 1.2774870943620527 | validation: 2.991319225952425]
	TIME [epoch: 5.75 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2561198570251866		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 1.2561198570251866 | validation: 2.98510776820195]
	TIME [epoch: 5.79 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.256310954589601		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 1.256310954589601 | validation: 3.0056133617783587]
	TIME [epoch: 5.76 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2775258436950276		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 1.2775258436950276 | validation: 3.032189116096579]
	TIME [epoch: 5.76 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2782269641844854		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 1.2782269641844854 | validation: 3.0229593967601494]
	TIME [epoch: 5.75 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2725839739829827		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 1.2725839739829827 | validation: 2.9902695037565388]
	TIME [epoch: 5.75 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2585272756496098		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 1.2585272756496098 | validation: 2.9844311334338887]
	TIME [epoch: 5.76 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2548203230476793		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 1.2548203230476793 | validation: 2.9760801678688766]
	TIME [epoch: 5.79 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2730148965611334		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 1.2730148965611334 | validation: 2.982704733724064]
	TIME [epoch: 5.76 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2543082601744555		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 1.2543082601744555 | validation: 2.978914433904449]
	TIME [epoch: 5.74 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.301366133286039		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 1.301366133286039 | validation: 2.9745535347804544]
	TIME [epoch: 5.74 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2706153058318406		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 1.2706153058318406 | validation: 2.9988048285402304]
	TIME [epoch: 5.75 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2611919469997006		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 1.2611919469997006 | validation: 3.000114349587647]
	TIME [epoch: 5.74 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2551728830178603		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 1.2551728830178603 | validation: 2.995148980125874]
	TIME [epoch: 5.77 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.267086972212787		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 1.267086972212787 | validation: 2.995384670031042]
	TIME [epoch: 5.77 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2681197427742572		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 1.2681197427742572 | validation: 2.9917700580088615]
	TIME [epoch: 5.74 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.258047972295327		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 1.258047972295327 | validation: 3.0063836021106334]
	TIME [epoch: 5.75 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2616681191960468		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 1.2616681191960468 | validation: 3.024676506581354]
	TIME [epoch: 5.74 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.270307777717802		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 1.270307777717802 | validation: 3.005525112825643]
	TIME [epoch: 5.75 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2886960783526942		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 1.2886960783526942 | validation: 3.0193846309798436]
	TIME [epoch: 5.74 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2605994283287232		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 1.2605994283287232 | validation: 2.983022922007172]
	TIME [epoch: 5.78 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.268159189776237		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 1.268159189776237 | validation: 3.005506529502595]
	TIME [epoch: 5.74 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2616033510374882		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 1.2616033510374882 | validation: 2.9829569560172993]
	TIME [epoch: 5.74 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2732860032778865		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 1.2732860032778865 | validation: 2.988989093064852]
	TIME [epoch: 5.75 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.259345482781618		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 1.259345482781618 | validation: 2.9757962253188364]
	TIME [epoch: 5.76 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2668830242334428		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 1.2668830242334428 | validation: 2.994259272030961]
	TIME [epoch: 5.75 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2748869032390975		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 1.2748869032390975 | validation: 3.0464932437869385]
	TIME [epoch: 5.75 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.276829048142528		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 1.276829048142528 | validation: 2.997451496670883]
	TIME [epoch: 5.78 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.26679216921413		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 1.26679216921413 | validation: 2.9951216655132233]
	TIME [epoch: 5.76 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2515805230533887		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 1.2515805230533887 | validation: 2.9852327878992333]
	TIME [epoch: 5.76 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2547530407711909		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 1.2547530407711909 | validation: 2.9842374875117366]
	TIME [epoch: 5.76 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2532833620444623		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 1.2532833620444623 | validation: 2.974680902257085]
	TIME [epoch: 5.75 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2603848516951777		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 1.2603848516951777 | validation: 3.029342149478921]
	TIME [epoch: 5.75 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2668975318896782		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 1.2668975318896782 | validation: 2.979371304082945]
	TIME [epoch: 5.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2667885190823163		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 1.2667885190823163 | validation: 2.9861138947061123]
	TIME [epoch: 5.75 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2538769889003274		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 1.2538769889003274 | validation: 2.9925760215595076]
	TIME [epoch: 5.74 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2718800106158858		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 1.2718800106158858 | validation: 2.9930785942810507]
	TIME [epoch: 5.75 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2824273389718845		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 1.2824273389718845 | validation: 2.9820275383218506]
	TIME [epoch: 5.76 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2665464706301932		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 1.2665464706301932 | validation: 3.015715561791346]
	TIME [epoch: 5.75 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2940657470888703		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 1.2940657470888703 | validation: 2.9836996193881067]
	TIME [epoch: 5.77 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2630994888243576		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 1.2630994888243576 | validation: 3.0007441681206006]
	TIME [epoch: 5.78 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2547092517366425		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 1.2547092517366425 | validation: 3.012745997181528]
	TIME [epoch: 5.76 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2583284388448281		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 1.2583284388448281 | validation: 2.979369792022177]
	TIME [epoch: 5.75 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2547068833567714		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 1.2547068833567714 | validation: 2.99898093598725]
	TIME [epoch: 5.75 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2712075838528079		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 1.2712075838528079 | validation: 3.008204119128368]
	TIME [epoch: 5.75 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2564117134603965		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 1.2564117134603965 | validation: 2.987490732843554]
	TIME [epoch: 5.76 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2547495534381654		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 1.2547495534381654 | validation: 2.9807624653351974]
	TIME [epoch: 5.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.253383692548132		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 1.253383692548132 | validation: 2.9752169056493183]
	TIME [epoch: 5.76 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2599135424794494		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 1.2599135424794494 | validation: 2.9771492177718666]
	TIME [epoch: 5.76 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2481874915533324		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 1.2481874915533324 | validation: 2.9824039529824926]
	TIME [epoch: 5.76 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2649415373708783		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 1.2649415373708783 | validation: 2.981334974806434]
	TIME [epoch: 5.75 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2595216797418156		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 1.2595216797418156 | validation: 2.9932656194954563]
	TIME [epoch: 5.75 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2708431825324864		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 1.2708431825324864 | validation: 2.9852759394681945]
	TIME [epoch: 5.77 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2645038274939293		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 1.2645038274939293 | validation: 3.008747248444867]
	TIME [epoch: 5.78 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2832207542844567		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 1.2832207542844567 | validation: 2.9906386883960567]
	TIME [epoch: 5.76 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2604337464342734		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 1.2604337464342734 | validation: 3.0042199728812338]
	TIME [epoch: 5.75 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2674160768639535		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 1.2674160768639535 | validation: 3.002302876582214]
	TIME [epoch: 5.75 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2620901118546588		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 1.2620901118546588 | validation: 3.0371983831567064]
	TIME [epoch: 5.75 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3288248944123036		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 1.3288248944123036 | validation: 3.0015920498949904]
	TIME [epoch: 5.75 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.275918077417244		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 1.275918077417244 | validation: 2.990800121787739]
	TIME [epoch: 5.79 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2537240098036477		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 1.2537240098036477 | validation: 3.0047555984585164]
	TIME [epoch: 5.76 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.252105573456906		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 1.252105573456906 | validation: 2.988228664982244]
	TIME [epoch: 5.76 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2587750417155539		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 1.2587750417155539 | validation: 3.006960983709216]
	TIME [epoch: 5.75 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2504652708009076		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 1.2504652708009076 | validation: 2.9839534228553135]
	TIME [epoch: 5.76 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2510357524670965		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 1.2510357524670965 | validation: 2.9993364800717486]
	TIME [epoch: 5.75 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.258820670353709		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 1.258820670353709 | validation: 3.000524706212608]
	TIME [epoch: 5.78 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.262471081643416		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 1.262471081643416 | validation: 2.995110184401147]
	TIME [epoch: 5.77 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2554370616145023		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 1.2554370616145023 | validation: 2.983267493547428]
	TIME [epoch: 5.74 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2514968981985986		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 1.2514968981985986 | validation: 2.9967824317748386]
	TIME [epoch: 5.75 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2582737045169958		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 1.2582737045169958 | validation: 3.0070846332928114]
	TIME [epoch: 5.75 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2799920529489293		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 1.2799920529489293 | validation: 3.0290328596222595]
	TIME [epoch: 5.75 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3074274402501984		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 1.3074274402501984 | validation: 2.9987068648100452]
	TIME [epoch: 5.76 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2627444860165082		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 1.2627444860165082 | validation: 2.996888620916892]
	TIME [epoch: 5.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.264544146087365		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 1.264544146087365 | validation: 3.0005840358935068]
	TIME [epoch: 5.74 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2570904574358814		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 1.2570904574358814 | validation: 2.98635371515369]
	TIME [epoch: 5.74 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2507112345853482		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 1.2507112345853482 | validation: 2.9815156072929234]
	TIME [epoch: 5.74 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2507339085934488		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 1.2507339085934488 | validation: 2.9771480030454156]
	TIME [epoch: 5.75 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.256109411143964		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 1.256109411143964 | validation: 2.996839393577999]
	TIME [epoch: 5.73 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2550460666204		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 1.2550460666204 | validation: 2.9769231835446988]
	TIME [epoch: 5.78 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2639194475424973		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 1.2639194475424973 | validation: 2.989576481296142]
	TIME [epoch: 5.77 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2593164739482972		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 1.2593164739482972 | validation: 2.986404613552147]
	TIME [epoch: 5.76 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.251201825814949		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 1.251201825814949 | validation: 2.97953722601556]
	TIME [epoch: 5.75 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2597791726617347		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 1.2597791726617347 | validation: 3.020232524128262]
	TIME [epoch: 5.75 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2618117993004614		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 1.2618117993004614 | validation: 2.9753943363150506]
	TIME [epoch: 5.73 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2443896460057724		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 1.2443896460057724 | validation: 2.970250055948662]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_923.pth
	Model improved!!!
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2518354962782856		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 1.2518354962782856 | validation: 2.9825060149350087]
	TIME [epoch: 5.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2887379971930824		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 1.2887379971930824 | validation: 2.972340734892455]
	TIME [epoch: 5.76 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2466712193654095		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 1.2466712193654095 | validation: 2.9823448559669385]
	TIME [epoch: 5.75 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2669127286155757		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 1.2669127286155757 | validation: 2.9939637415296394]
	TIME [epoch: 5.75 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2518404176182218		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 1.2518404176182218 | validation: 2.971406398175004]
	TIME [epoch: 5.75 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.247984758319808		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 1.247984758319808 | validation: 2.9897184203686793]
	TIME [epoch: 5.75 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2505076201756888		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 1.2505076201756888 | validation: 3.0057964610636345]
	TIME [epoch: 5.79 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2588878265147885		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 1.2588878265147885 | validation: 2.9716053152408572]
	TIME [epoch: 5.76 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2639137165507142		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 1.2639137165507142 | validation: 2.989897262596953]
	TIME [epoch: 5.75 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2556110040533373		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 1.2556110040533373 | validation: 2.9964310555226428]
	TIME [epoch: 5.75 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2565838461042667		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 1.2565838461042667 | validation: 2.9742238786186874]
	TIME [epoch: 5.75 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2485450244676488		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 1.2485450244676488 | validation: 2.97912908526063]
	TIME [epoch: 5.75 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.256384454130124		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 1.256384454130124 | validation: 2.9930433626435327]
	TIME [epoch: 5.77 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2556027871913458		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 1.2556027871913458 | validation: 2.9775514969635686]
	TIME [epoch: 5.78 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2470994260719759		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 1.2470994260719759 | validation: 2.9861018601995037]
	TIME [epoch: 5.76 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2467798348691064		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 1.2467798348691064 | validation: 2.98547884239386]
	TIME [epoch: 5.75 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2491435769101695		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 1.2491435769101695 | validation: 2.9759872881068765]
	TIME [epoch: 5.75 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2669655562072537		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 1.2669655562072537 | validation: 2.9962880174032165]
	TIME [epoch: 5.74 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2536553671754453		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 1.2536553671754453 | validation: 3.014801377921939]
	TIME [epoch: 5.75 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2801328445434819		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 1.2801328445434819 | validation: 2.997987714331848]
	TIME [epoch: 5.79 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.254288549672372		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 1.254288549672372 | validation: 2.98825150971592]
	TIME [epoch: 5.74 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.243430357257635		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 1.243430357257635 | validation: 2.984903700950864]
	TIME [epoch: 5.75 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244751027810092		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 1.244751027810092 | validation: 2.9846200993715586]
	TIME [epoch: 5.74 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2652000078355905		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 1.2652000078355905 | validation: 3.02553592119342]
	TIME [epoch: 5.75 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2517477032509439		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 1.2517477032509439 | validation: 2.9667588438277295]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_948.pth
	Model improved!!!
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2533126700139143		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 1.2533126700139143 | validation: 3.0084408390897237]
	TIME [epoch: 5.77 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.261665073255375		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 1.261665073255375 | validation: 2.987493674162574]
	TIME [epoch: 5.78 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2643637975256468		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 1.2643637975256468 | validation: 2.9835936846519235]
	TIME [epoch: 5.76 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2464947182368042		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 1.2464947182368042 | validation: 2.9825308767338345]
	TIME [epoch: 5.76 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2483026330839155		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 1.2483026330839155 | validation: 2.992146717094054]
	TIME [epoch: 5.75 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2491278614557355		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 1.2491278614557355 | validation: 2.980362158104824]
	TIME [epoch: 5.75 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2443751425286462		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 1.2443751425286462 | validation: 2.9798224683148287]
	TIME [epoch: 5.76 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2539228660913067		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 1.2539228660913067 | validation: 3.0264938909168464]
	TIME [epoch: 5.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2645076704084377		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 1.2645076704084377 | validation: 2.9710769381970965]
	TIME [epoch: 5.75 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2445418528178762		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 1.2445418528178762 | validation: 2.9786053919051527]
	TIME [epoch: 5.75 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2647677709447684		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 1.2647677709447684 | validation: 3.0092439076918245]
	TIME [epoch: 5.74 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.268136323362972		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 1.268136323362972 | validation: 2.991030803762823]
	TIME [epoch: 5.75 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2508374030873788		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 1.2508374030873788 | validation: 2.983146892432291]
	TIME [epoch: 5.75 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2507379497995008		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 1.2507379497995008 | validation: 3.0163860296614873]
	TIME [epoch: 5.78 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.266543041478069		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 1.266543041478069 | validation: 2.9878862825901913]
	TIME [epoch: 5.77 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2632932110360293		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 1.2632932110360293 | validation: 3.0060507355198856]
	TIME [epoch: 5.76 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2546447582441413		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 1.2546447582441413 | validation: 3.007563327941175]
	TIME [epoch: 5.75 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2640137728485015		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 1.2640137728485015 | validation: 2.9821651076641666]
	TIME [epoch: 5.75 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.24580490742782		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 1.24580490742782 | validation: 2.9758173498123552]
	TIME [epoch: 5.75 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2629077800663353		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 1.2629077800663353 | validation: 2.9896243142635344]
	TIME [epoch: 5.74 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2513498130552643		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 1.2513498130552643 | validation: 2.971584062438493]
	TIME [epoch: 5.78 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.24518065119568		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 1.24518065119568 | validation: 2.9698613343442815]
	TIME [epoch: 5.74 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.25115618655198		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 1.25115618655198 | validation: 2.99004618693723]
	TIME [epoch: 5.74 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2433077946005398		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 1.2433077946005398 | validation: 2.974055220100157]
	TIME [epoch: 5.73 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2472007697794651		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 1.2472007697794651 | validation: 3.0096297181493017]
	TIME [epoch: 5.73 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2646303998783572		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 1.2646303998783572 | validation: 2.976535417284193]
	TIME [epoch: 5.74 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2388858482356044		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 1.2388858482356044 | validation: 2.9961603622708566]
	TIME [epoch: 5.76 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2440147593112754		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 1.2440147593112754 | validation: 2.9796347022157907]
	TIME [epoch: 5.77 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.251102176407636		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 1.251102176407636 | validation: 2.9978306460307578]
	TIME [epoch: 5.76 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257126155228676		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 1.257126155228676 | validation: 2.9958907754905617]
	TIME [epoch: 5.74 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2601439686113205		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 1.2601439686113205 | validation: 3.0549232637487695]
	TIME [epoch: 5.75 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2839282240387688		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 1.2839282240387688 | validation: 2.9915221978082696]
	TIME [epoch: 5.75 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2446344248554864		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 1.2446344248554864 | validation: 2.9612261233465564]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_981.pth
	Model improved!!!
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2613681591598929		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 1.2613681591598929 | validation: 3.0077250368204154]
	TIME [epoch: 5.79 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2657767596738783		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 1.2657767596738783 | validation: 2.9744436076938054]
	TIME [epoch: 5.75 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2497777122380143		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 1.2497777122380143 | validation: 2.989702958660989]
	TIME [epoch: 5.75 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2556488633125744		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 1.2556488633125744 | validation: 2.9934090335565786]
	TIME [epoch: 5.76 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2453696232807618		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 1.2453696232807618 | validation: 2.9843516762790103]
	TIME [epoch: 5.75 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2463669990918145		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 1.2463669990918145 | validation: 2.988743718046461]
	TIME [epoch: 5.75 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2614297668542236		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 1.2614297668542236 | validation: 3.026086294750038]
	TIME [epoch: 5.79 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2802063642392527		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 1.2802063642392527 | validation: 2.994476908507473]
	TIME [epoch: 5.76 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2479459016228227		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 1.2479459016228227 | validation: 2.9780297248308707]
	TIME [epoch: 5.74 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2434296431354979		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 1.2434296431354979 | validation: 2.977986823015632]
	TIME [epoch: 5.73 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2482335661107078		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 1.2482335661107078 | validation: 3.000260754186769]
	TIME [epoch: 5.73 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2480386953043414		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 1.2480386953043414 | validation: 2.9844312769547914]
	TIME [epoch: 5.73 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.245508321249582		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 1.245508321249582 | validation: 2.9870967846448635]
	TIME [epoch: 5.75 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2464519458370993		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 1.2464519458370993 | validation: 2.975657991103409]
	TIME [epoch: 5.77 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2476364619862879		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 1.2476364619862879 | validation: 2.972656711554316]
	TIME [epoch: 5.74 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2426638235301066		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 1.2426638235301066 | validation: 2.9749055762875436]
	TIME [epoch: 5.75 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2523600892524875		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 1.2523600892524875 | validation: 2.9944011234436188]
	TIME [epoch: 5.75 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2707222503177278		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 1.2707222503177278 | validation: 2.99591222616903]
	TIME [epoch: 5.75 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2711772539704933		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 1.2711772539704933 | validation: 3.001508827828666]
	TIME [epoch: 5.74 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2563993558135433		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 1.2563993558135433 | validation: 2.9776430966879035]
	TIME [epoch: 5.79 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2407483831441812		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 1.2407483831441812 | validation: 2.9739788525237647]
	TIME [epoch: 5.74 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2534466354599365		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 1.2534466354599365 | validation: 2.9870206555343635]
	TIME [epoch: 5.75 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2448688353791901		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 1.2448688353791901 | validation: 2.992761972418656]
	TIME [epoch: 5.75 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2596533917649446		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 1.2596533917649446 | validation: 2.9868350737978204]
	TIME [epoch: 5.73 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2442119647391934		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 1.2442119647391934 | validation: 2.9751564538531987]
	TIME [epoch: 5.73 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.242105884490229		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 1.242105884490229 | validation: 2.988576013392491]
	TIME [epoch: 5.76 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2485761519390377		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 1.2485761519390377 | validation: 2.978759904264814]
	TIME [epoch: 5.77 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2401924053747178		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 1.2401924053747178 | validation: 2.984469357289953]
	TIME [epoch: 5.74 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2651787060656494		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 1.2651787060656494 | validation: 2.998108316627872]
	TIME [epoch: 5.74 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2518428493084228		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 1.2518428493084228 | validation: 2.978651734496897]
	TIME [epoch: 5.75 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2646407395998787		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 1.2646407395998787 | validation: 2.974367625508751]
	TIME [epoch: 5.75 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2466431208368185		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 1.2466431208368185 | validation: 2.9949167386855144]
	TIME [epoch: 5.75 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2475231508744857		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 1.2475231508744857 | validation: 2.9750534921623943]
	TIME [epoch: 5.79 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2478226540107504		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 1.2478226540107504 | validation: 2.992996302822019]
	TIME [epoch: 5.76 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2489487617813486		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 1.2489487617813486 | validation: 2.9826100812387257]
	TIME [epoch: 5.75 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257759605933224		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 1.257759605933224 | validation: 3.0006753868828553]
	TIME [epoch: 5.75 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.24664594383519		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 1.24664594383519 | validation: 2.976092385572075]
	TIME [epoch: 5.75 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.249463500589105		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 1.249463500589105 | validation: 2.986552617287811]
	TIME [epoch: 5.73 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2469719759093334		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 1.2469719759093334 | validation: 2.9806440730674204]
	TIME [epoch: 5.76 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.275826562239959		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 1.275826562239959 | validation: 3.004962913822349]
	TIME [epoch: 5.76 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2604661230102063		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 1.2604661230102063 | validation: 2.985706525222653]
	TIME [epoch: 5.75 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2635597207527673		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 1.2635597207527673 | validation: 2.984645527083462]
	TIME [epoch: 5.74 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2469450212787225		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 1.2469450212787225 | validation: 2.9758748836387054]
	TIME [epoch: 5.75 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239817384420755		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 1.239817384420755 | validation: 2.9694950191785314]
	TIME [epoch: 5.73 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2377674434571637		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 1.2377674434571637 | validation: 2.971916670954848]
	TIME [epoch: 5.75 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2348511772511233		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 1.2348511772511233 | validation: 2.994711836293235]
	TIME [epoch: 5.78 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2485908931253038		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 1.2485908931253038 | validation: 2.9800880729756103]
	TIME [epoch: 5.75 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2573200464598102		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 1.2573200464598102 | validation: 3.003353843936411]
	TIME [epoch: 5.74 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2653636639175407		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 1.2653636639175407 | validation: 2.968759405606917]
	TIME [epoch: 5.75 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2421069196876597		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 1.2421069196876597 | validation: 2.9812282509554358]
	TIME [epoch: 5.73 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2446961500596148		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 1.2446961500596148 | validation: 2.9721831693474434]
	TIME [epoch: 5.74 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2374902835717447		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 1.2374902835717447 | validation: 2.986962094772033]
	TIME [epoch: 5.77 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2400654675012188		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 1.2400654675012188 | validation: 2.981681725548291]
	TIME [epoch: 5.76 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2462156961285964		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 1.2462156961285964 | validation: 2.9936378623932867]
	TIME [epoch: 5.74 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2486707853751167		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 1.2486707853751167 | validation: 2.9991609653519227]
	TIME [epoch: 5.74 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2705825676725844		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 1.2705825676725844 | validation: 2.9751998140802005]
	TIME [epoch: 5.75 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2495028732288014		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 1.2495028732288014 | validation: 2.982102470291253]
	TIME [epoch: 5.75 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.241452335829703		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 1.241452335829703 | validation: 2.9875846201492107]
	TIME [epoch: 5.75 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.245293598002629		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 1.245293598002629 | validation: 2.9689179708502826]
	TIME [epoch: 5.79 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244355262168596		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 1.244355262168596 | validation: 2.9796230342747707]
	TIME [epoch: 5.75 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2433859531483666		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 1.2433859531483666 | validation: 2.9740802685738523]
	TIME [epoch: 5.74 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2424007370865255		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 1.2424007370865255 | validation: 2.9975390417919345]
	TIME [epoch: 5.75 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2665878408850522		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 1.2665878408850522 | validation: 3.0159233814009325]
	TIME [epoch: 5.74 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.26514276160823		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 1.26514276160823 | validation: 2.9831673615838543]
	TIME [epoch: 5.75 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2622204147011944		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 1.2622204147011944 | validation: 3.0308900452760548]
	TIME [epoch: 5.77 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2691535009261634		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 1.2691535009261634 | validation: 2.990686079422433]
	TIME [epoch: 5.77 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.249106661103828		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 1.249106661103828 | validation: 3.0133869382931766]
	TIME [epoch: 5.75 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2626505401747887		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 1.2626505401747887 | validation: 2.9830168299250612]
	TIME [epoch: 5.73 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2438674715571687		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 1.2438674715571687 | validation: 2.972160600955239]
	TIME [epoch: 5.75 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.238294204536914		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 1.238294204536914 | validation: 2.977884835282]
	TIME [epoch: 5.74 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.242704932380901		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 1.242704932380901 | validation: 2.971204380843525]
	TIME [epoch: 5.74 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.248216603115992		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 1.248216603115992 | validation: 2.977258927650112]
	TIME [epoch: 5.79 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2457248206101765		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 1.2457248206101765 | validation: 2.9687324300604825]
	TIME [epoch: 5.74 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2470541437149		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 1.2470541437149 | validation: 2.980489263400768]
	TIME [epoch: 5.73 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2547371072859757		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 1.2547371072859757 | validation: 2.985193434398681]
	TIME [epoch: 5.73 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2419201392212997		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 1.2419201392212997 | validation: 2.9807806146515805]
	TIME [epoch: 5.75 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2442522179394793		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 1.2442522179394793 | validation: 2.9706050151043235]
	TIME [epoch: 5.73 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23898676617927		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 1.23898676617927 | validation: 2.9767736026671408]
	TIME [epoch: 5.77 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.243996394015213		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 1.243996394015213 | validation: 2.972832508317206]
	TIME [epoch: 5.75 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2515960992249517		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 1.2515960992249517 | validation: 3.0096446686026117]
	TIME [epoch: 5.75 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2657840523099004		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 1.2657840523099004 | validation: 2.970209714047276]
	TIME [epoch: 5.73 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2406718953875087		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 1.2406718953875087 | validation: 2.968399158017868]
	TIME [epoch: 5.75 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2425500475656746		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 1.2425500475656746 | validation: 2.9764718665534637]
	TIME [epoch: 5.73 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.243572381856403		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 1.243572381856403 | validation: 2.9850598051505814]
	TIME [epoch: 5.73 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.243556249046444		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 1.243556249046444 | validation: 2.974880610086012]
	TIME [epoch: 5.78 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2441169918441084		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 1.2441169918441084 | validation: 2.982822806635582]
	TIME [epoch: 5.74 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2514293787600472		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 1.2514293787600472 | validation: 2.989828611714112]
	TIME [epoch: 5.75 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.250888457717247		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 1.250888457717247 | validation: 2.986254650377611]
	TIME [epoch: 5.75 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244073576691383		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 1.244073576691383 | validation: 2.9719185630179408]
	TIME [epoch: 5.75 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2409919554802256		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 1.2409919554802256 | validation: 2.9772225248938526]
	TIME [epoch: 5.75 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2430356342401268		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 1.2430356342401268 | validation: 2.9749404641254977]
	TIME [epoch: 5.76 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2534654009913084		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 1.2534654009913084 | validation: 2.97138893443539]
	TIME [epoch: 5.77 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2390316629424305		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 1.2390316629424305 | validation: 2.975742036893388]
	TIME [epoch: 5.74 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2469426317740342		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 1.2469426317740342 | validation: 2.974598729904826]
	TIME [epoch: 5.74 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.245324808605846		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 1.245324808605846 | validation: 2.9952069902731684]
	TIME [epoch: 5.73 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2463414375412665		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 1.2463414375412665 | validation: 2.9732267534389734]
	TIME [epoch: 5.74 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2429239143633655		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 1.2429239143633655 | validation: 2.981448659782361]
	TIME [epoch: 5.75 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257306564256137		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 1.257306564256137 | validation: 2.979835745275019]
	TIME [epoch: 5.78 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240446433929872		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 1.240446433929872 | validation: 2.966849428511614]
	TIME [epoch: 5.75 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2405772608332903		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 1.2405772608332903 | validation: 2.96766824570963]
	TIME [epoch: 5.73 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2528872030125933		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 1.2528872030125933 | validation: 2.994610057800987]
	TIME [epoch: 5.73 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.276919411946893		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 1.276919411946893 | validation: 3.0451532380790063]
	TIME [epoch: 5.74 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2810929366361496		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 1.2810929366361496 | validation: 2.9914366825945877]
	TIME [epoch: 5.74 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2894670508623278		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 1.2894670508623278 | validation: 3.011152198958239]
	TIME [epoch: 5.77 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.267025497107284		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 1.267025497107284 | validation: 2.9731185997190437]
	TIME [epoch: 5.75 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240163971908591		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 1.240163971908591 | validation: 2.996857750218916]
	TIME [epoch: 5.74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2659005790811442		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 1.2659005790811442 | validation: 2.9821758671741443]
	TIME [epoch: 5.74 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2431997972069433		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 1.2431997972069433 | validation: 2.9838259168601597]
	TIME [epoch: 5.74 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2547163764597482		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 1.2547163764597482 | validation: 2.9886682369975213]
	TIME [epoch: 5.74 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2466810120572136		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 1.2466810120572136 | validation: 2.9848196513443384]
	TIME [epoch: 5.74 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.254227134101559		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 1.254227134101559 | validation: 2.9714015508452736]
	TIME [epoch: 5.78 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2373912954394581		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 1.2373912954394581 | validation: 2.969196748915898]
	TIME [epoch: 5.74 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2433255105125696		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 1.2433255105125696 | validation: 2.966209710662439]
	TIME [epoch: 5.74 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2460120716843943		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 1.2460120716843943 | validation: 2.965334036786256]
	TIME [epoch: 5.74 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2539107144122403		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 1.2539107144122403 | validation: 2.9770453158281316]
	TIME [epoch: 5.74 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2472053273768602		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 1.2472053273768602 | validation: 2.979445758225936]
	TIME [epoch: 5.74 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2481537958112983		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 1.2481537958112983 | validation: 2.972874222957437]
	TIME [epoch: 5.77 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2392463830961316		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 1.2392463830961316 | validation: 2.9754032666329557]
	TIME [epoch: 5.75 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2401163193200337		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 1.2401163193200337 | validation: 2.9814964133485478]
	TIME [epoch: 5.74 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2495605253551654		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 1.2495605253551654 | validation: 2.9832932064750577]
	TIME [epoch: 5.74 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2561165785252184		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 1.2561165785252184 | validation: 2.9861019906488457]
	TIME [epoch: 5.75 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2439933893268438		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 1.2439933893268438 | validation: 2.985930140484738]
	TIME [epoch: 5.74 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2451853772965884		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 1.2451853772965884 | validation: 3.0027624120871033]
	TIME [epoch: 5.77 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.246909590643154		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 1.246909590643154 | validation: 2.98925632080701]
	TIME [epoch: 5.77 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2421763821324578		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 1.2421763821324578 | validation: 2.9869775988005918]
	TIME [epoch: 5.74 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2640891282433309		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 1.2640891282433309 | validation: 3.032187782245288]
	TIME [epoch: 5.74 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2769230279648287		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 1.2769230279648287 | validation: 3.00714783518009]
	TIME [epoch: 5.74 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2518328147797648		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 1.2518328147797648 | validation: 2.9766830183771003]
	TIME [epoch: 5.74 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233769564816876		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 1.233769564816876 | validation: 2.9823598361646693]
	TIME [epoch: 5.75 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2477123927853033		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 1.2477123927853033 | validation: 2.9890373220662867]
	TIME [epoch: 5.78 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2507228506076737		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 1.2507228506076737 | validation: 2.982349189531459]
	TIME [epoch: 5.74 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2619386178268752		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 1.2619386178268752 | validation: 3.0138524345631947]
	TIME [epoch: 5.74 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2740102153998583		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 1.2740102153998583 | validation: 2.9792710917128336]
	TIME [epoch: 5.74 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2411706706427181		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 1.2411706706427181 | validation: 2.9974629108917403]
	TIME [epoch: 5.75 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2464978727370104		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 1.2464978727370104 | validation: 2.996507035243643]
	TIME [epoch: 5.75 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.250954807363243		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 1.250954807363243 | validation: 2.9681904314358127]
	TIME [epoch: 5.77 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2381112676135195		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 1.2381112676135195 | validation: 2.989682007695591]
	TIME [epoch: 5.77 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2526260562630889		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 1.2526260562630889 | validation: 2.97678025216013]
	TIME [epoch: 5.75 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2380323417460861		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 1.2380323417460861 | validation: 2.9794912014260486]
	TIME [epoch: 5.74 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2371643015223732		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 1.2371643015223732 | validation: 2.975061941785573]
	TIME [epoch: 5.74 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2369413265376206		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 1.2369413265376206 | validation: 2.97247707496908]
	TIME [epoch: 5.74 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2421162489223034		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 1.2421162489223034 | validation: 3.00657393727156]
	TIME [epoch: 5.74 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2491327491541617		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 1.2491327491541617 | validation: 2.9666233362871974]
	TIME [epoch: 5.78 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236575167334499		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 1.236575167334499 | validation: 2.974940631695702]
	TIME [epoch: 5.75 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2442815463413872		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 1.2442815463413872 | validation: 2.9746537506760173]
	TIME [epoch: 5.74 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2400716800876888		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 1.2400716800876888 | validation: 2.9793148911050937]
	TIME [epoch: 5.74 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.248736912166731		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 1.248736912166731 | validation: 2.9763900264453573]
	TIME [epoch: 5.74 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2606404678202763		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 1.2606404678202763 | validation: 3.011022261029857]
	TIME [epoch: 5.74 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2452689672398884		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 1.2452689672398884 | validation: 2.9744281830557755]
	TIME [epoch: 5.77 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2435699258093431		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 1.2435699258093431 | validation: 2.9963254211510564]
	TIME [epoch: 5.76 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2428377538389606		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 1.2428377538389606 | validation: 2.9667300042301945]
	TIME [epoch: 5.74 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2320220003064646		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 1.2320220003064646 | validation: 2.977965099623907]
	TIME [epoch: 5.75 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2490625860903402		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 1.2490625860903402 | validation: 2.9934959433140307]
	TIME [epoch: 5.74 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2498163018867916		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 1.2498163018867916 | validation: 2.97575190564938]
	TIME [epoch: 5.75 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2361536657436019		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 1.2361536657436019 | validation: 2.971919249647509]
	TIME [epoch: 5.74 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2394278619177999		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 1.2394278619177999 | validation: 2.9821079979634497]
	TIME [epoch: 5.78 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2418398219930533		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 1.2418398219930533 | validation: 2.977639514951394]
	TIME [epoch: 5.75 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.238892757079186		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 1.238892757079186 | validation: 2.980973557979877]
	TIME [epoch: 5.75 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244184610140154		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 1.244184610140154 | validation: 2.968783776204265]
	TIME [epoch: 5.75 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240114548749378		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 1.240114548749378 | validation: 2.97425225677668]
	TIME [epoch: 5.75 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236811909376696		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 1.236811909376696 | validation: 2.9741475924740377]
	TIME [epoch: 5.73 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2390626897258914		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 1.2390626897258914 | validation: 2.972931982287627]
	TIME [epoch: 5.75 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2406209136169637		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 1.2406209136169637 | validation: 2.97735120899142]
	TIME [epoch: 5.77 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239463674225598		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 1.239463674225598 | validation: 2.992450002521796]
	TIME [epoch: 5.74 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2675161829612778		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 1.2675161829612778 | validation: 2.9762233838958725]
	TIME [epoch: 5.74 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235207162524686		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 1.235207162524686 | validation: 2.972132105785406]
	TIME [epoch: 5.73 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2388914737609429		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 1.2388914737609429 | validation: 2.9703278444901855]
	TIME [epoch: 5.74 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2360320539638		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 1.2360320539638 | validation: 2.9790078129999236]
	TIME [epoch: 5.74 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235113574811105		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 1.235113574811105 | validation: 2.9779304090288865]
	TIME [epoch: 5.79 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2371063588218818		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 1.2371063588218818 | validation: 2.971258718277142]
	TIME [epoch: 5.75 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2353705203873138		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 1.2353705203873138 | validation: 2.9722897650682176]
	TIME [epoch: 5.74 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2509008115795184		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 1.2509008115795184 | validation: 2.967749162237766]
	TIME [epoch: 5.74 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2391207306470586		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 1.2391207306470586 | validation: 2.9902076151315886]
	TIME [epoch: 5.74 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2483964643496923		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 1.2483964643496923 | validation: 2.9743070185209013]
	TIME [epoch: 5.74 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.245672799576082		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 1.245672799576082 | validation: 2.9873150094260406]
	TIME [epoch: 5.76 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.250442082321185		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 1.250442082321185 | validation: 2.9704237490482384]
	TIME [epoch: 5.75 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2423754393412776		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 1.2423754393412776 | validation: 2.9700535630824847]
	TIME [epoch: 5.74 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2374038385725872		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 1.2374038385725872 | validation: 2.9632117728284864]
	TIME [epoch: 5.74 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2383728796135391		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 1.2383728796135391 | validation: 2.981498086979729]
	TIME [epoch: 5.73 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2485686171687		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 1.2485686171687 | validation: 2.9674424572952787]
	TIME [epoch: 5.74 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2374574298482068		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 1.2374574298482068 | validation: 2.977740306524826]
	TIME [epoch: 5.73 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2435012790646576		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 1.2435012790646576 | validation: 2.9856102314615836]
	TIME [epoch: 5.78 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244769576721022		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 1.244769576721022 | validation: 2.9778462557206087]
	TIME [epoch: 5.74 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2333216218159173		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 1.2333216218159173 | validation: 2.9775817082097458]
	TIME [epoch: 5.74 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2396198580892333		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 1.2396198580892333 | validation: 2.9664832786886426]
	TIME [epoch: 5.74 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2445940753868576		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 1.2445940753868576 | validation: 2.9766041897265985]
	TIME [epoch: 5.74 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239940072355886		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 1.239940072355886 | validation: 2.9826663992041444]
	TIME [epoch: 5.74 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239780430606575		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 1.239780430606575 | validation: 2.9648989413034905]
	TIME [epoch: 5.78 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2425850885951153		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 1.2425850885951153 | validation: 2.9768222683866497]
	TIME [epoch: 5.75 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2430144455872076		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 1.2430144455872076 | validation: 3.004067879154376]
	TIME [epoch: 5.74 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257122835050303		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 1.257122835050303 | validation: 2.9784551099068053]
	TIME [epoch: 5.73 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2423027561096829		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 1.2423027561096829 | validation: 2.966552517045288]
	TIME [epoch: 5.73 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2411427425571337		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 1.2411427425571337 | validation: 2.979777370180266]
	TIME [epoch: 5.74 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.24428793353891		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 1.24428793353891 | validation: 2.972318428930464]
	TIME [epoch: 5.74 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2381035484763245		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 1.2381035484763245 | validation: 2.9654678523381177]
	TIME [epoch: 5.78 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2412559802168908		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 1.2412559802168908 | validation: 2.9843318734753206]
	TIME [epoch: 5.74 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2502249961000633		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 1.2502249961000633 | validation: 2.974502204670166]
	TIME [epoch: 5.74 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2494319068679456		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 1.2494319068679456 | validation: 2.974634839927901]
	TIME [epoch: 5.74 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.247981335501069		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 1.247981335501069 | validation: 2.9765129512221473]
	TIME [epoch: 5.74 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2405340806128977		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 1.2405340806128977 | validation: 2.9753921735917546]
	TIME [epoch: 5.73 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2358195391313085		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 1.2358195391313085 | validation: 2.9724355074924724]
	TIME [epoch: 5.77 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2422843624641235		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 1.2422843624641235 | validation: 2.9814432997336726]
	TIME [epoch: 5.76 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2415514208752698		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 1.2415514208752698 | validation: 2.9776563863037357]
	TIME [epoch: 5.75 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.241718433629456		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 1.241718433629456 | validation: 2.972116214750157]
	TIME [epoch: 5.74 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2425876288542637		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 1.2425876288542637 | validation: 2.976659488574977]
	TIME [epoch: 5.74 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2414101309855816		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 1.2414101309855816 | validation: 2.984477561248172]
	TIME [epoch: 5.74 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2378132144330447		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 1.2378132144330447 | validation: 2.9745131413814363]
	TIME [epoch: 5.75 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2350635242294201		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 1.2350635242294201 | validation: 2.9713244005870343]
	TIME [epoch: 5.78 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2391196454890883		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 1.2391196454890883 | validation: 2.9648911457765803]
	TIME [epoch: 5.75 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2477403804823726		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 1.2477403804823726 | validation: 2.9736968179302132]
	TIME [epoch: 5.74 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2453333117770482		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 1.2453333117770482 | validation: 2.9795219221231224]
	TIME [epoch: 5.74 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2393438148673688		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 1.2393438148673688 | validation: 2.9625025470052413]
	TIME [epoch: 5.74 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234737288380337		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 1.234737288380337 | validation: 2.96972779452479]
	TIME [epoch: 5.75 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2351142862850482		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 1.2351142862850482 | validation: 2.972386911180698]
	TIME [epoch: 5.77 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2382488666123217		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 1.2382488666123217 | validation: 2.9721997745630575]
	TIME [epoch: 5.77 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239277662668941		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 1.239277662668941 | validation: 2.9773163549842865]
	TIME [epoch: 5.74 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2373228074123346		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 1.2373228074123346 | validation: 2.968518725489236]
	TIME [epoch: 5.74 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2369171353469497		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 1.2369171353469497 | validation: 2.9848586646539172]
	TIME [epoch: 5.74 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2374260083882893		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 1.2374260083882893 | validation: 2.977002768883356]
	TIME [epoch: 5.74 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2375694968367534		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 1.2375694968367534 | validation: 2.9724157902957873]
	TIME [epoch: 5.74 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2387244996790356		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 1.2387244996790356 | validation: 2.972127688487455]
	TIME [epoch: 5.79 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2326922471570092		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 1.2326922471570092 | validation: 2.969288577903628]
	TIME [epoch: 5.74 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2338530170922901		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 1.2338530170922901 | validation: 2.984961616923069]
	TIME [epoch: 5.74 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2467442201125323		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 1.2467442201125323 | validation: 2.9769470191452307]
	TIME [epoch: 5.74 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2437527910649115		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 1.2437527910649115 | validation: 2.976508054532865]
	TIME [epoch: 5.75 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.246036352831266		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 1.246036352831266 | validation: 2.976512227408587]
	TIME [epoch: 5.74 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2459892234285315		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 1.2459892234285315 | validation: 2.9723858128440623]
	TIME [epoch: 5.77 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2390577088111843		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 1.2390577088111843 | validation: 2.9776619002380604]
	TIME [epoch: 5.75 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23757543373475		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 1.23757543373475 | validation: 2.9679593806457825]
	TIME [epoch: 5.74 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2413150537155628		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 1.2413150537155628 | validation: 2.975651532596888]
	TIME [epoch: 5.74 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2350538446755164		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 1.2350538446755164 | validation: 2.9739405672325065]
	TIME [epoch: 5.74 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23426184376821		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 1.23426184376821 | validation: 2.975688884077225]
	TIME [epoch: 5.75 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2358596174785466		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 1.2358596174785466 | validation: 2.9783667525299053]
	TIME [epoch: 5.75 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2554719289097709		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 1.2554719289097709 | validation: 2.98230170387158]
	TIME [epoch: 5.78 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.246389897354414		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 1.246389897354414 | validation: 2.983333197902136]
	TIME [epoch: 5.74 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2383148807478153		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 1.2383148807478153 | validation: 2.9801290884836464]
	TIME [epoch: 5.74 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2353757362886348		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 1.2353757362886348 | validation: 2.967064622591764]
	TIME [epoch: 5.74 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2327346438419227		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 1.2327346438419227 | validation: 2.9629699409955426]
	TIME [epoch: 5.74 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2382116962201486		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 1.2382116962201486 | validation: 2.9770810393889984]
	TIME [epoch: 5.75 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2367943231581973		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 1.2367943231581973 | validation: 2.9648326031987664]
	TIME [epoch: 5.78 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2351586002741024		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 1.2351586002741024 | validation: 2.9775040331080636]
	TIME [epoch: 5.76 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2347249970227812		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 1.2347249970227812 | validation: 2.9762543956424814]
	TIME [epoch: 5.74 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234560477649402		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 1.234560477649402 | validation: 2.9845117129409893]
	TIME [epoch: 5.74 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23833794262343		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 1.23833794262343 | validation: 2.978469877306911]
	TIME [epoch: 5.75 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2430284272813057		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 1.2430284272813057 | validation: 2.978138444402207]
	TIME [epoch: 5.75 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244748272756199		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 1.244748272756199 | validation: 3.0014009553587675]
	TIME [epoch: 5.76 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2523387202982892		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 1.2523387202982892 | validation: 2.972223678412097]
	TIME [epoch: 5.78 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.237717036298578		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 1.237717036298578 | validation: 2.9810889891295007]
	TIME [epoch: 5.74 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2428765536996904		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 1.2428765536996904 | validation: 2.972635982930904]
	TIME [epoch: 5.75 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2398793968032182		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 1.2398793968032182 | validation: 2.971864562982081]
	TIME [epoch: 5.74 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.238372983127717		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 1.238372983127717 | validation: 2.9770315317144638]
	TIME [epoch: 5.75 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2443300390997716		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 1.2443300390997716 | validation: 2.965217225395786]
	TIME [epoch: 5.74 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2368776907800325		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 1.2368776907800325 | validation: 2.9874446471616403]
	TIME [epoch: 5.79 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2399111195153114		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 1.2399111195153114 | validation: 2.978375733398845]
	TIME [epoch: 5.75 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2358616639193134		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 1.2358616639193134 | validation: 2.9655073680090664]
	TIME [epoch: 5.75 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2389801680581791		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 1.2389801680581791 | validation: 2.968750311481661]
	TIME [epoch: 5.74 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2346167188366115		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 1.2346167188366115 | validation: 2.9781685188038014]
	TIME [epoch: 5.75 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2376790204069767		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 1.2376790204069767 | validation: 2.9664120606927016]
	TIME [epoch: 5.74 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2364473259112734		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 1.2364473259112734 | validation: 2.971841484385734]
	TIME [epoch: 5.77 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2328228324292343		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 1.2328228324292343 | validation: 2.9667358811953055]
	TIME [epoch: 5.78 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2415364873079708		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 1.2415364873079708 | validation: 2.9815139711169762]
	TIME [epoch: 5.75 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2359044317278907		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 1.2359044317278907 | validation: 2.974160074134459]
	TIME [epoch: 5.75 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2423158810181947		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 1.2423158810181947 | validation: 2.9718897013508405]
	TIME [epoch: 5.74 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2338560950486746		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 1.2338560950486746 | validation: 2.9741643749755187]
	TIME [epoch: 5.75 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235830219633419		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 1.235830219633419 | validation: 2.9692398132335365]
	TIME [epoch: 5.74 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2345004124828873		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 1.2345004124828873 | validation: 2.977947155308468]
	TIME [epoch: 5.78 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234339460046849		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 1.234339460046849 | validation: 2.9806191251753154]
	TIME [epoch: 5.74 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2416780666349887		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 1.2416780666349887 | validation: 2.9795698157332673]
	TIME [epoch: 5.75 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2356335673137966		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 1.2356335673137966 | validation: 2.9880304138090152]
	TIME [epoch: 5.74 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2394388914415124		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 1.2394388914415124 | validation: 2.970455427754264]
	TIME [epoch: 5.75 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2364526381579373		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 1.2364526381579373 | validation: 2.970937123022361]
	TIME [epoch: 5.74 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2376931431545386		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 1.2376931431545386 | validation: 2.9663012728944658]
	TIME [epoch: 5.77 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2372703561062888		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 1.2372703561062888 | validation: 2.977140757042383]
	TIME [epoch: 5.77 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2358412281471494		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 1.2358412281471494 | validation: 2.973883423071263]
	TIME [epoch: 5.75 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233244976690766		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 1.233244976690766 | validation: 2.9758548088313463]
	TIME [epoch: 5.74 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2356992639045883		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 1.2356992639045883 | validation: 2.982297294287446]
	TIME [epoch: 5.74 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2404681898524303		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 1.2404681898524303 | validation: 2.9908731903270307]
	TIME [epoch: 5.74 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2530836418531297		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 1.2530836418531297 | validation: 2.998002888902017]
	TIME [epoch: 5.74 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.255027091399199		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 1.255027091399199 | validation: 2.9785215321325222]
	TIME [epoch: 5.81 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.242382553196745		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 1.242382553196745 | validation: 2.983887919543264]
	TIME [epoch: 5.75 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2405828478359255		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 1.2405828478359255 | validation: 2.9787301107950532]
	TIME [epoch: 5.75 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2406343857729767		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 1.2406343857729767 | validation: 2.965065055064193]
	TIME [epoch: 5.75 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2399067057100934		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 1.2399067057100934 | validation: 2.982423789935496]
	TIME [epoch: 5.73 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2365045667541934		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 1.2365045667541934 | validation: 2.9682714004872297]
	TIME [epoch: 5.74 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324187248177796		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 1.2324187248177796 | validation: 2.9726288443491238]
	TIME [epoch: 5.76 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2353775666210933		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 1.2353775666210933 | validation: 2.96732043229962]
	TIME [epoch: 5.76 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2334978049768586		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 1.2334978049768586 | validation: 2.966487644765495]
	TIME [epoch: 5.74 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235301802545742		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 1.235301802545742 | validation: 2.9873478274826306]
	TIME [epoch: 5.74 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2401136665149772		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 1.2401136665149772 | validation: 2.97811526471014]
	TIME [epoch: 5.74 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2356092706588715		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 1.2356092706588715 | validation: 2.9643213321528283]
	TIME [epoch: 5.74 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2374182379463714		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 1.2374182379463714 | validation: 2.972170842444888]
	TIME [epoch: 5.75 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2406656123027013		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 1.2406656123027013 | validation: 2.9801507744824995]
	TIME [epoch: 5.79 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2453034310202478		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 1.2453034310202478 | validation: 2.973210117108663]
	TIME [epoch: 5.74 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2534394106438724		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 1.2534394106438724 | validation: 2.9679890967739304]
	TIME [epoch: 5.74 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2430390984061865		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 1.2430390984061865 | validation: 2.9716692476813074]
	TIME [epoch: 5.74 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2415539568673515		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 1.2415539568673515 | validation: 2.966820507682952]
	TIME [epoch: 5.75 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2353803280289313		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 1.2353803280289313 | validation: 2.9743358499001626]
	TIME [epoch: 5.73 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2412512246995033		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 1.2412512246995033 | validation: 2.9750072339086673]
	TIME [epoch: 5.78 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2414191055740869		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 1.2414191055740869 | validation: 2.975941860425052]
	TIME [epoch: 5.77 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23321564782204		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 1.23321564782204 | validation: 2.9711720036501963]
	TIME [epoch: 5.74 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2354593666424205		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 1.2354593666424205 | validation: 2.983988120953725]
	TIME [epoch: 5.76 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2334647710750029		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 1.2334647710750029 | validation: 2.977413256988125]
	TIME [epoch: 5.74 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324539042991178		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 1.2324539042991178 | validation: 2.9736368470381773]
	TIME [epoch: 5.74 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232877981998168		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 1.232877981998168 | validation: 2.9754135064801552]
	TIME [epoch: 5.74 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233472200829041		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 1.233472200829041 | validation: 2.9852335006812303]
	TIME [epoch: 5.79 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2362003297601163		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 1.2362003297601163 | validation: 2.9801932129518285]
	TIME [epoch: 5.74 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2336595484851196		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 1.2336595484851196 | validation: 2.978881438964048]
	TIME [epoch: 5.75 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236176913966689		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 1.236176913966689 | validation: 2.9645560269082525]
	TIME [epoch: 5.74 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235074647288243		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 1.235074647288243 | validation: 2.9751793300497082]
	TIME [epoch: 5.73 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2329324466601914		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 1.2329324466601914 | validation: 2.969846673786664]
	TIME [epoch: 5.74 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2368276156754887		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 1.2368276156754887 | validation: 2.9678346597509426]
	TIME [epoch: 5.79 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2345425489359216		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 1.2345425489359216 | validation: 2.964622221792705]
	TIME [epoch: 5.75 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2334680480472477		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 1.2334680480472477 | validation: 2.9738927872758176]
	TIME [epoch: 5.75 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2331292310444428		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 1.2331292310444428 | validation: 2.973516126326203]
	TIME [epoch: 5.74 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2409688931482399		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 1.2409688931482399 | validation: 2.985708990398815]
	TIME [epoch: 5.75 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2389710435822723		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 1.2389710435822723 | validation: 2.9658110035935032]
	TIME [epoch: 5.75 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2352143651766996		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 1.2352143651766996 | validation: 2.976188953506975]
	TIME [epoch: 5.75 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2378681250754864		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 1.2378681250754864 | validation: 2.9724152495235576]
	TIME [epoch: 5.79 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.245907948116666		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 1.245907948116666 | validation: 2.9687256530572608]
	TIME [epoch: 5.74 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2394488614803847		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 1.2394488614803847 | validation: 2.966406511558455]
	TIME [epoch: 5.74 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312157483482338		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 1.2312157483482338 | validation: 2.966337858228131]
	TIME [epoch: 5.75 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.246364871454135		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 1.246364871454135 | validation: 2.9784453244397175]
	TIME [epoch: 5.75 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2424885795075955		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 1.2424885795075955 | validation: 2.9881152434940588]
	TIME [epoch: 5.75 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2465710216845567		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 1.2465710216845567 | validation: 2.9874671471352032]
	TIME [epoch: 5.78 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2439828362659267		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 1.2439828362659267 | validation: 2.9753783638469384]
	TIME [epoch: 5.75 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236067833311552		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 1.236067833311552 | validation: 2.97675902221057]
	TIME [epoch: 5.74 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2399449394931192		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 1.2399449394931192 | validation: 2.975876444872554]
	TIME [epoch: 5.74 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2401249782842036		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 1.2401249782842036 | validation: 2.9647100990323443]
	TIME [epoch: 5.75 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234584077471946		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 1.234584077471946 | validation: 2.967700284692899]
	TIME [epoch: 5.74 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235551187255102		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 1.235551187255102 | validation: 2.972596960106179]
	TIME [epoch: 5.76 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2356273967915004		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 1.2356273967915004 | validation: 2.969811329697103]
	TIME [epoch: 5.77 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2299967850467048		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 1.2299967850467048 | validation: 2.9634668905458192]
	TIME [epoch: 5.75 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2404724309395763		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 1.2404724309395763 | validation: 2.985198986444636]
	TIME [epoch: 5.75 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233620954549483		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 1.233620954549483 | validation: 2.966715622111733]
	TIME [epoch: 5.75 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2406039360130043		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 1.2406039360130043 | validation: 2.970805503896926]
	TIME [epoch: 5.74 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2364322497845022		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 1.2364322497845022 | validation: 2.9677716872966515]
	TIME [epoch: 5.75 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2354414526256823		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 1.2354414526256823 | validation: 2.9711330226450388]
	TIME [epoch: 5.78 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2352443559161266		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 1.2352443559161266 | validation: 2.966963982605482]
	TIME [epoch: 5.75 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2363383453498806		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 1.2363383453498806 | validation: 2.97036685152042]
	TIME [epoch: 5.74 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2375031668919183		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 1.2375031668919183 | validation: 2.98390165303335]
	TIME [epoch: 5.74 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2394544866219777		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 1.2394544866219777 | validation: 2.9803847413410507]
	TIME [epoch: 5.74 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2363419404459504		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 1.2363419404459504 | validation: 2.9740559064514525]
	TIME [epoch: 5.73 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2353990877364045		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 1.2353990877364045 | validation: 2.9819141383549086]
	TIME [epoch: 5.76 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2416788323233554		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 1.2416788323233554 | validation: 2.983996140979522]
	TIME [epoch: 5.76 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.238093257798122		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 1.238093257798122 | validation: 2.9746701302703182]
	TIME [epoch: 5.74 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307433545946025		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 1.2307433545946025 | validation: 2.979223225539073]
	TIME [epoch: 5.73 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2368266603879692		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 1.2368266603879692 | validation: 2.9793830567579143]
	TIME [epoch: 5.74 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2402268076991156		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 1.2402268076991156 | validation: 2.9829824762841044]
	TIME [epoch: 5.74 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2358842084716577		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 1.2358842084716577 | validation: 2.967595530768016]
	TIME [epoch: 5.75 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2362673995953382		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 1.2362673995953382 | validation: 2.9791881855588414]
	TIME [epoch: 5.78 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2373433685378115		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 1.2373433685378115 | validation: 2.9740677609262502]
	TIME [epoch: 5.75 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2384222721682765		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 1.2384222721682765 | validation: 2.9744335291478996]
	TIME [epoch: 5.75 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2323661765130165		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 1.2323661765130165 | validation: 2.975617547107644]
	TIME [epoch: 5.74 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2328108444268848		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 1.2328108444268848 | validation: 2.966686220056098]
	TIME [epoch: 5.74 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324572436193357		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 1.2324572436193357 | validation: 2.9765507878533275]
	TIME [epoch: 5.73 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.251653652459681		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 1.251653652459681 | validation: 2.9897393486307546]
	TIME [epoch: 5.76 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2579465331247333		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 1.2579465331247333 | validation: 2.9917538588105255]
	TIME [epoch: 5.77 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2430132598778845		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 1.2430132598778845 | validation: 2.973053283800929]
	TIME [epoch: 5.75 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2330468648533774		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 1.2330468648533774 | validation: 2.970222660479926]
	TIME [epoch: 5.74 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2363007766862486		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 1.2363007766862486 | validation: 2.970873094447128]
	TIME [epoch: 5.75 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235027013415168		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 1.235027013415168 | validation: 2.9835945237503343]
	TIME [epoch: 5.73 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2330915404688922		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 1.2330915404688922 | validation: 2.9758705626072586]
	TIME [epoch: 5.74 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2321478979704654		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 1.2321478979704654 | validation: 2.9765454470392894]
	TIME [epoch: 5.78 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2339666396676023		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 1.2339666396676023 | validation: 2.976248655148783]
	TIME [epoch: 5.74 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2352238795601682		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 1.2352238795601682 | validation: 2.970109200600463]
	TIME [epoch: 5.73 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2364226213020775		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 1.2364226213020775 | validation: 2.970865885276711]
	TIME [epoch: 5.73 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2393315127799158		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 1.2393315127799158 | validation: 2.9735190577627892]
	TIME [epoch: 5.73 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235877776944424		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 1.235877776944424 | validation: 2.9741203243843497]
	TIME [epoch: 5.73 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2442617164382614		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 1.2442617164382614 | validation: 2.968884739616614]
	TIME [epoch: 5.77 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2404860555335233		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 1.2404860555335233 | validation: 2.9711631466915858]
	TIME [epoch: 5.76 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2350704778742043		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 1.2350704778742043 | validation: 2.9655740568068087]
	TIME [epoch: 5.74 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2326614183677458		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 1.2326614183677458 | validation: 2.9703803880866633]
	TIME [epoch: 5.74 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2337635174337422		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 1.2337635174337422 | validation: 2.9765147720454395]
	TIME [epoch: 5.74 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232360304084335		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 1.232360304084335 | validation: 2.9833455231813497]
	TIME [epoch: 5.75 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2386768203964726		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 1.2386768203964726 | validation: 2.9738984801633057]
	TIME [epoch: 5.75 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2334174306627514		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 1.2334174306627514 | validation: 2.9800794450341836]
	TIME [epoch: 5.79 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2372515102972366		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 1.2372515102972366 | validation: 2.9739398457178834]
	TIME [epoch: 5.75 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2350172965852177		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 1.2350172965852177 | validation: 2.9664262675617574]
	TIME [epoch: 5.75 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2317160884678282		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 1.2317160884678282 | validation: 2.970022550761273]
	TIME [epoch: 5.73 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2394386326155178		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 1.2394386326155178 | validation: 2.96828997323825]
	TIME [epoch: 5.73 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2452145566371873		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 1.2452145566371873 | validation: 2.9734966473036435]
	TIME [epoch: 5.73 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2382687665913172		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 1.2382687665913172 | validation: 2.972545288478135]
	TIME [epoch: 5.77 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2365079119724707		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 1.2365079119724707 | validation: 2.971626187152392]
	TIME [epoch: 5.76 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.237408382291675		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 1.237408382291675 | validation: 2.9863243390374485]
	TIME [epoch: 5.74 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2395977550781658		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 1.2395977550781658 | validation: 2.972059043670671]
	TIME [epoch: 5.75 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2393552767485896		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 1.2393552767485896 | validation: 2.9738308740022603]
	TIME [epoch: 5.75 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2344138248863137		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 1.2344138248863137 | validation: 2.9736905907762288]
	TIME [epoch: 5.74 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2338876883442707		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 1.2338876883442707 | validation: 2.966739208062541]
	TIME [epoch: 5.75 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236404112552043		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 1.236404112552043 | validation: 2.9723360160623953]
	TIME [epoch: 5.78 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2377521548036587		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 1.2377521548036587 | validation: 2.9663915843480653]
	TIME [epoch: 5.74 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2382944688214081		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 1.2382944688214081 | validation: 2.9769625345841972]
	TIME [epoch: 5.73 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.238518282866866		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 1.238518282866866 | validation: 2.9741105670876267]
	TIME [epoch: 5.74 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2408472228196175		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 1.2408472228196175 | validation: 2.9685638571193396]
	TIME [epoch: 5.74 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2308179717897885		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 1.2308179717897885 | validation: 2.973240762158705]
	TIME [epoch: 5.74 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234388965756864		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 1.234388965756864 | validation: 2.9711451526852786]
	TIME [epoch: 5.76 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232465772971441		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 1.232465772971441 | validation: 2.9718255733145615]
	TIME [epoch: 5.75 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230811888047168		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 1.230811888047168 | validation: 2.974268926933602]
	TIME [epoch: 5.73 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2373617875455096		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 1.2373617875455096 | validation: 2.979420038764023]
	TIME [epoch: 5.74 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2340665950608807		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 1.2340665950608807 | validation: 2.972308276559185]
	TIME [epoch: 5.73 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2373508118052343		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 1.2373508118052343 | validation: 2.9806877379883314]
	TIME [epoch: 5.74 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2354179422702234		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 1.2354179422702234 | validation: 2.9771262847617685]
	TIME [epoch: 5.74 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306335010036213		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 1.2306335010036213 | validation: 2.9703528445556335]
	TIME [epoch: 5.78 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2325720448837816		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 1.2325720448837816 | validation: 2.968489693071084]
	TIME [epoch: 5.74 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2328838889492888		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 1.2328838889492888 | validation: 2.96646455374741]
	TIME [epoch: 5.73 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2317102071675325		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 1.2317102071675325 | validation: 2.981980946362234]
	TIME [epoch: 5.74 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2412753742726763		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 1.2412753742726763 | validation: 2.9822954802687933]
	TIME [epoch: 5.73 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240614391942362		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 1.240614391942362 | validation: 2.989821549597511]
	TIME [epoch: 5.74 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2418453765051973		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 1.2418453765051973 | validation: 2.975787559449293]
	TIME [epoch: 5.76 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2364608608413983		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 1.2364608608413983 | validation: 2.9745417106090777]
	TIME [epoch: 5.75 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2382272815573319		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 1.2382272815573319 | validation: 2.984605272541191]
	TIME [epoch: 5.73 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2381552406648848		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 1.2381552406648848 | validation: 2.970883516358997]
	TIME [epoch: 5.75 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2366987050438254		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 1.2366987050438254 | validation: 2.9715429108754234]
	TIME [epoch: 5.73 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234990418850491		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 1.234990418850491 | validation: 2.9732255724477485]
	TIME [epoch: 5.75 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2362914991058578		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 1.2362914991058578 | validation: 2.972739463987849]
	TIME [epoch: 5.75 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2360917294495273		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 1.2360917294495273 | validation: 2.970885709683628]
	TIME [epoch: 5.78 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2349483857637835		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 1.2349483857637835 | validation: 2.971374980945885]
	TIME [epoch: 5.75 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2322662725344808		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 1.2322662725344808 | validation: 2.975768162433801]
	TIME [epoch: 5.75 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233938238394245		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 1.233938238394245 | validation: 2.9726520664273766]
	TIME [epoch: 5.75 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2354241682777964		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 1.2354241682777964 | validation: 2.974677422088528]
	TIME [epoch: 5.75 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2370208514151932		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 1.2370208514151932 | validation: 2.9769001463530422]
	TIME [epoch: 5.75 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2372511804989834		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 1.2372511804989834 | validation: 2.977555940964412]
	TIME [epoch: 5.79 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234097802852208		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 1.234097802852208 | validation: 2.971720563047436]
	TIME [epoch: 5.74 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2337243451060598		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 1.2337243451060598 | validation: 2.9747379287700135]
	TIME [epoch: 5.75 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2353726247015033		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 1.2353726247015033 | validation: 2.9851653480357214]
	TIME [epoch: 5.75 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2389590363471357		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 1.2389590363471357 | validation: 2.9717409995137234]
	TIME [epoch: 5.73 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236105791444046		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 1.236105791444046 | validation: 2.9836225849697224]
	TIME [epoch: 5.75 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2411324729448139		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 1.2411324729448139 | validation: 2.9777028154777816]
	TIME [epoch: 5.77 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2378722800755235		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 1.2378722800755235 | validation: 2.9676403709735406]
	TIME [epoch: 5.78 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319746617347695		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 1.2319746617347695 | validation: 2.97685498903976]
	TIME [epoch: 5.76 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2375523252943106		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 1.2375523252943106 | validation: 2.976215718302938]
	TIME [epoch: 5.75 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2382898254350203		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 1.2382898254350203 | validation: 2.976782707230722]
	TIME [epoch: 5.75 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236740788581325		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 1.236740788581325 | validation: 2.9706353319792607]
	TIME [epoch: 5.75 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2308932834103605		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 1.2308932834103605 | validation: 2.970243882264778]
	TIME [epoch: 5.75 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2354337472127719		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 1.2354337472127719 | validation: 2.9694644580526415]
	TIME [epoch: 5.79 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2304698658777347		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 1.2304698658777347 | validation: 2.977335488480546]
	TIME [epoch: 5.76 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2321850882215821		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 1.2321850882215821 | validation: 2.9725392661598806]
	TIME [epoch: 5.75 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319092890155194		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 1.2319092890155194 | validation: 2.9788285565324664]
	TIME [epoch: 5.75 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2429035334076963		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 1.2429035334076963 | validation: 2.982018987439339]
	TIME [epoch: 5.75 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2404701318558828		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 1.2404701318558828 | validation: 2.9791466872655668]
	TIME [epoch: 5.75 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2323258402660742		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 1.2323258402660742 | validation: 2.9717677016016046]
	TIME [epoch: 5.76 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2327205041740523		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 1.2327205041740523 | validation: 2.9760757307454373]
	TIME [epoch: 5.76 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2321548254490886		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 1.2321548254490886 | validation: 2.967214302370521]
	TIME [epoch: 5.75 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2332668052567288		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 1.2332668052567288 | validation: 2.9662502046187846]
	TIME [epoch: 5.75 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2332976332590233		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 1.2332976332590233 | validation: 2.9741471093673644]
	TIME [epoch: 5.73 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2346119601648562		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 1.2346119601648562 | validation: 2.9726408016644963]
	TIME [epoch: 5.75 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2314241341080558		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 1.2314241341080558 | validation: 2.979483135605665]
	TIME [epoch: 5.75 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2320230905094989		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 1.2320230905094989 | validation: 2.970358578551618]
	TIME [epoch: 5.79 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2362256524518633		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 1.2362256524518633 | validation: 2.9728872424032597]
	TIME [epoch: 5.75 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230691748985138		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 1.230691748985138 | validation: 2.97625770393802]
	TIME [epoch: 5.75 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2338110947216532		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 1.2338110947216532 | validation: 2.98555249940781]
	TIME [epoch: 5.75 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2350414308155753		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 1.2350414308155753 | validation: 2.9795773013182316]
	TIME [epoch: 5.75 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2385862542924846		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 1.2385862542924846 | validation: 2.988242882424519]
	TIME [epoch: 5.74 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2352631316879545		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 1.2352631316879545 | validation: 2.988033199966642]
	TIME [epoch: 5.78 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2420507637905422		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 1.2420507637905422 | validation: 2.979365634384083]
	TIME [epoch: 5.77 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2458242027998552		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 1.2458242027998552 | validation: 2.978714059309375]
	TIME [epoch: 5.75 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2386403265640304		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 1.2386403265640304 | validation: 2.9765613157286306]
	TIME [epoch: 5.75 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2365967891896767		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 1.2365967891896767 | validation: 2.982920007047137]
	TIME [epoch: 5.75 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2406162974654027		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 1.2406162974654027 | validation: 2.977211732383026]
	TIME [epoch: 5.75 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.243417256937493		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 1.243417256937493 | validation: 2.98428471892933]
	TIME [epoch: 5.73 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239293911057886		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 1.239293911057886 | validation: 2.977974643166925]
	TIME [epoch: 5.78 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239536946463011		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 1.239536946463011 | validation: 2.9731999892844967]
	TIME [epoch: 5.74 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2352731930213512		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 1.2352731930213512 | validation: 2.9754865958926366]
	TIME [epoch: 5.73 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2304490027162374		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 1.2304490027162374 | validation: 2.9721708353212324]
	TIME [epoch: 5.75 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2376249371987527		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 1.2376249371987527 | validation: 2.9749739166573703]
	TIME [epoch: 5.74 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230207327229308		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 1.230207327229308 | validation: 2.9721334433142066]
	TIME [epoch: 5.73 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2354107289354053		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 1.2354107289354053 | validation: 2.971557912948149]
	TIME [epoch: 5.77 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2299616294837363		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 1.2299616294837363 | validation: 2.9639649146484706]
	TIME [epoch: 5.76 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229467401886272		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 1.229467401886272 | validation: 2.9738859102906225]
	TIME [epoch: 5.74 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324179930109191		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 1.2324179930109191 | validation: 2.966254235587903]
	TIME [epoch: 5.75 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2343781481654312		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 1.2343781481654312 | validation: 2.9691318185119746]
	TIME [epoch: 5.75 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2339174348066602		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 1.2339174348066602 | validation: 2.9752330783674847]
	TIME [epoch: 5.75 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306500724939684		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 1.2306500724939684 | validation: 2.970221143999637]
	TIME [epoch: 5.74 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2283798855671493		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 1.2283798855671493 | validation: 2.9765335733804164]
	TIME [epoch: 5.8 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2344976889271797		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 1.2344976889271797 | validation: 2.974274292821346]
	TIME [epoch: 5.75 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2283998977928692		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 1.2283998977928692 | validation: 2.969523336614758]
	TIME [epoch: 5.75 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2347133313484804		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 1.2347133313484804 | validation: 2.9698023753927907]
	TIME [epoch: 5.74 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231338940436466		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 1.231338940436466 | validation: 2.9701928518878384]
	TIME [epoch: 5.75 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2340973290061215		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 1.2340973290061215 | validation: 2.970525958444394]
	TIME [epoch: 5.73 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2380005545518793		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 1.2380005545518793 | validation: 2.97000741949136]
	TIME [epoch: 5.76 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2333029183013087		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 1.2333029183013087 | validation: 2.9762198434758433]
	TIME [epoch: 5.75 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233525650742796		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 1.233525650742796 | validation: 2.9590571202279734]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_1462.pth
	Model improved!!!
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234380743484356		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 1.234380743484356 | validation: 2.974424265929688]
	TIME [epoch: 5.73 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2355615743008515		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 1.2355615743008515 | validation: 2.9736389357330415]
	TIME [epoch: 5.73 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2316624047551699		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 1.2316624047551699 | validation: 2.9662597633752683]
	TIME [epoch: 5.74 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232431680284247		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 1.232431680284247 | validation: 2.962013644112458]
	TIME [epoch: 5.75 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2341461782065455		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 1.2341461782065455 | validation: 2.9673227500597408]
	TIME [epoch: 5.77 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324349665350005		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 1.2324349665350005 | validation: 2.9682209533303547]
	TIME [epoch: 5.74 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233228932073327		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 1.233228932073327 | validation: 2.965960781843579]
	TIME [epoch: 5.74 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233231697656615		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 1.233231697656615 | validation: 2.962382615373256]
	TIME [epoch: 5.73 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2348211289928073		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 1.2348211289928073 | validation: 2.9681435514038026]
	TIME [epoch: 5.73 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2326339880178234		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 1.2326339880178234 | validation: 2.966438032763889]
	TIME [epoch: 5.73 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2336655133786716		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 1.2336655133786716 | validation: 2.9694606611279037]
	TIME [epoch: 5.77 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233826936343691		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 1.233826936343691 | validation: 2.9669080296907557]
	TIME [epoch: 5.75 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232883521271448		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 1.232883521271448 | validation: 2.964406071720408]
	TIME [epoch: 5.73 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234222704031582		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 1.234222704031582 | validation: 2.964567745845951]
	TIME [epoch: 5.75 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2346577642982173		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 1.2346577642982173 | validation: 2.9694982883400733]
	TIME [epoch: 5.74 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2361573884260864		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 1.2361573884260864 | validation: 2.9702034448527246]
	TIME [epoch: 5.74 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2305392556522403		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 1.2305392556522403 | validation: 2.969018413451418]
	TIME [epoch: 5.76 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2304172875679915		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 1.2304172875679915 | validation: 2.9771999090157464]
	TIME [epoch: 5.77 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235890148294139		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 1.235890148294139 | validation: 2.972739711353536]
	TIME [epoch: 5.75 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234481428008114		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 1.234481428008114 | validation: 2.973675867575342]
	TIME [epoch: 5.73 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2323294783046348		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 1.2323294783046348 | validation: 2.972455165901339]
	TIME [epoch: 5.73 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232963212131219		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 1.232963212131219 | validation: 2.9759319968267075]
	TIME [epoch: 5.73 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233394581377587		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 1.233394581377587 | validation: 2.979988387131392]
	TIME [epoch: 5.73 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235960167608678		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 1.235960167608678 | validation: 2.96837740988013]
	TIME [epoch: 5.79 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2304861092061508		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 1.2304861092061508 | validation: 2.9802825791014995]
	TIME [epoch: 5.75 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2339776869384336		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 1.2339776869384336 | validation: 2.980511754653907]
	TIME [epoch: 5.75 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2345352587673277		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 1.2345352587673277 | validation: 2.9819602069542044]
	TIME [epoch: 5.75 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23411740847777		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 1.23411740847777 | validation: 2.967785170207392]
	TIME [epoch: 5.74 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324972430155143		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 1.2324972430155143 | validation: 2.96980694795902]
	TIME [epoch: 5.73 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2271493984513722		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 1.2271493984513722 | validation: 2.9740796435117045]
	TIME [epoch: 5.76 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2331563860865302		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 1.2331563860865302 | validation: 2.966933088023398]
	TIME [epoch: 5.76 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2363835272579808		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 1.2363835272579808 | validation: 2.9688046559366374]
	TIME [epoch: 5.74 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2346317464974343		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 1.2346317464974343 | validation: 2.9720985334974706]
	TIME [epoch: 5.73 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2343042204820218		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 1.2343042204820218 | validation: 2.967834433339232]
	TIME [epoch: 5.74 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2353033563927336		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 1.2353033563927336 | validation: 2.9634013344663264]
	TIME [epoch: 5.73 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230819965156459		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 1.230819965156459 | validation: 2.970274016209929]
	TIME [epoch: 5.74 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2370286275942952		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 1.2370286275942952 | validation: 2.979349572105208]
	TIME [epoch: 5.78 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235382502789712		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 1.235382502789712 | validation: 2.9723862686963276]
	TIME [epoch: 5.74 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2362458069535218		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 1.2362458069535218 | validation: 2.972121039211473]
	TIME [epoch: 5.73 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233723132368119		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 1.233723132368119 | validation: 2.977539582132898]
	TIME [epoch: 5.75 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2334849258381508		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 1.2334849258381508 | validation: 2.9738771710278002]
	TIME [epoch: 5.74 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2322673654962184		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 1.2322673654962184 | validation: 2.977515960217936]
	TIME [epoch: 5.75 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319584884871464		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 1.2319584884871464 | validation: 2.964243660144953]
	TIME [epoch: 5.77 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2300596871095517		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 1.2300596871095517 | validation: 2.971052980664159]
	TIME [epoch: 5.77 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2355866226249588		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 1.2355866226249588 | validation: 2.9688301717855756]
	TIME [epoch: 5.75 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2314600623696077		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 1.2314600623696077 | validation: 2.976841163119043]
	TIME [epoch: 5.75 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236052859352653		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 1.236052859352653 | validation: 2.979379899864465]
	TIME [epoch: 5.75 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2363785168189942		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 1.2363785168189942 | validation: 2.975937203351632]
	TIME [epoch: 5.75 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2344791497709091		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 1.2344791497709091 | validation: 2.981389163224392]
	TIME [epoch: 5.75 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2301095035123901		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 1.2301095035123901 | validation: 2.9631891082384563]
	TIME [epoch: 5.78 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230559410455696		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 1.230559410455696 | validation: 2.969906150836629]
	TIME [epoch: 5.75 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228446506672652		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 1.228446506672652 | validation: 2.968385728895796]
	TIME [epoch: 5.75 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235591195093717		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 1.235591195093717 | validation: 2.976371721554221]
	TIME [epoch: 5.75 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2330034752179118		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 1.2330034752179118 | validation: 2.9708554881006597]
	TIME [epoch: 5.75 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2336577678440679		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 1.2336577678440679 | validation: 2.970909149740736]
	TIME [epoch: 5.74 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2358965102411597		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 1.2358965102411597 | validation: 2.9711621590095896]
	TIME [epoch: 5.77 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2403417956123013		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 1.2403417956123013 | validation: 2.967517468511232]
	TIME [epoch: 5.75 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2363890202522865		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 1.2363890202522865 | validation: 2.9738869745244965]
	TIME [epoch: 5.74 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2366919847215074		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 1.2366919847215074 | validation: 2.9677336848368046]
	TIME [epoch: 5.74 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235956780238356		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 1.235956780238356 | validation: 2.964418909205526]
	TIME [epoch: 5.75 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2325103265674608		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 1.2325103265674608 | validation: 2.968234768767965]
	TIME [epoch: 5.75 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319637795339458		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 1.2319637795339458 | validation: 2.9686139622560246]
	TIME [epoch: 5.73 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319250530260943		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 1.2319250530260943 | validation: 2.9682442635032227]
	TIME [epoch: 5.78 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2344051542752663		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 1.2344051542752663 | validation: 2.9724553294797955]
	TIME [epoch: 5.75 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2296363602221214		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 1.2296363602221214 | validation: 2.971997804319086]
	TIME [epoch: 5.74 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2359525002993277		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 1.2359525002993277 | validation: 2.970918477464328]
	TIME [epoch: 5.74 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324777462350132		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 1.2324777462350132 | validation: 2.9720702015524982]
	TIME [epoch: 5.75 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232726175918316		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 1.232726175918316 | validation: 2.974391167223435]
	TIME [epoch: 5.74 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232650612326661		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 1.232650612326661 | validation: 2.9725547538078274]
	TIME [epoch: 5.78 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2385204273368304		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 1.2385204273368304 | validation: 2.973702326185669]
	TIME [epoch: 5.76 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231857299739769		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 1.231857299739769 | validation: 2.968773722547013]
	TIME [epoch: 5.75 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2328098153043576		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 1.2328098153043576 | validation: 2.9741675982873867]
	TIME [epoch: 5.74 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229602579114185		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 1.229602579114185 | validation: 2.970624948454839]
	TIME [epoch: 5.74 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.22958464491478		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 1.22958464491478 | validation: 2.966781417503791]
	TIME [epoch: 5.74 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285414965193635		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 1.2285414965193635 | validation: 2.969725021910873]
	TIME [epoch: 5.75 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2292426406632548		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 1.2292426406632548 | validation: 2.971407823058736]
	TIME [epoch: 5.77 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2310359278848837		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 1.2310359278848837 | validation: 2.9771639934843996]
	TIME [epoch: 5.74 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2349949024223101		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 1.2349949024223101 | validation: 2.9831277523484907]
	TIME [epoch: 5.74 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2358504093810598		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 1.2358504093810598 | validation: 2.9735168362946434]
	TIME [epoch: 5.74 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2297776646128733		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 1.2297776646128733 | validation: 2.9846062045425357]
	TIME [epoch: 5.74 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2340278889069103		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 1.2340278889069103 | validation: 2.9730682893180074]
	TIME [epoch: 5.74 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2321925685657753		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 1.2321925685657753 | validation: 2.9741030941809186]
	TIME [epoch: 5.78 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307011784422852		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 1.2307011784422852 | validation: 2.976408758008054]
	TIME [epoch: 5.75 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2351935756199695		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 1.2351935756199695 | validation: 2.971066394281148]
	TIME [epoch: 5.74 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285722003807504		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 1.2285722003807504 | validation: 2.9861617293839027]
	TIME [epoch: 5.74 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2314746285534022		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 1.2314746285534022 | validation: 2.9737527984609073]
	TIME [epoch: 5.74 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234209512640878		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 1.234209512640878 | validation: 2.970574704831057]
	TIME [epoch: 5.73 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23486330497034		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 1.23486330497034 | validation: 2.9731697068470715]
	TIME [epoch: 5.75 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2328726594441648		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 1.2328726594441648 | validation: 2.970483260952849]
	TIME [epoch: 5.77 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2323558755601243		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 1.2323558755601243 | validation: 2.9735046244487955]
	TIME [epoch: 5.73 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23011970588939		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 1.23011970588939 | validation: 2.975900889231592]
	TIME [epoch: 5.74 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2329870146973327		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 1.2329870146973327 | validation: 2.9657472870381896]
	TIME [epoch: 5.74 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.226920593949643		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 1.226920593949643 | validation: 2.9627806538851393]
	TIME [epoch: 5.73 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2329798759149484		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 1.2329798759149484 | validation: 2.9680857512213588]
	TIME [epoch: 5.73 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307613465361222		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 1.2307613465361222 | validation: 2.973068291642547]
	TIME [epoch: 5.77 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231073826936042		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 1.231073826936042 | validation: 2.9660132709683182]
	TIME [epoch: 5.75 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312684238377285		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 1.2312684238377285 | validation: 2.9651667441204257]
	TIME [epoch: 5.74 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2342251363059276		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 1.2342251363059276 | validation: 2.9687911666548246]
	TIME [epoch: 5.74 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2284186113250462		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 1.2284186113250462 | validation: 2.9706803287990717]
	TIME [epoch: 5.73 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2310949144404337		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 1.2310949144404337 | validation: 2.975039411760498]
	TIME [epoch: 5.73 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236875031927982		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 1.236875031927982 | validation: 2.976840345621787]
	TIME [epoch: 5.75 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324264114779089		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 1.2324264114779089 | validation: 2.9762841353347493]
	TIME [epoch: 5.76 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233500843958539		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 1.233500843958539 | validation: 2.975331431595442]
	TIME [epoch: 5.74 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2351985802227787		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 1.2351985802227787 | validation: 2.979180518204627]
	TIME [epoch: 5.73 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2315341188777018		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 1.2315341188777018 | validation: 2.967423051044867]
	TIME [epoch: 5.74 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2327177584604003		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 1.2327177584604003 | validation: 2.9733460362011805]
	TIME [epoch: 5.73 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2337433981886679		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 1.2337433981886679 | validation: 2.9692649854142847]
	TIME [epoch: 5.74 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2351083247607564		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 1.2351083247607564 | validation: 2.9818298341854863]
	TIME [epoch: 5.77 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2344617538979101		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 1.2344617538979101 | validation: 2.9700030523614815]
	TIME [epoch: 5.75 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230623296666693		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 1.230623296666693 | validation: 2.977918621951659]
	TIME [epoch: 5.75 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233205399478049		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 1.233205399478049 | validation: 2.976797169270837]
	TIME [epoch: 5.74 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2360986412349226		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 1.2360986412349226 | validation: 2.972611367234922]
	TIME [epoch: 5.73 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2342966552565615		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 1.2342966552565615 | validation: 2.9727332831932776]
	TIME [epoch: 5.74 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2328478233585527		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 1.2328478233585527 | validation: 2.968483737741029]
	TIME [epoch: 5.76 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2326084830809565		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 1.2326084830809565 | validation: 2.9675008577557844]
	TIME [epoch: 5.76 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2313756296184906		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 1.2313756296184906 | validation: 2.968706650291004]
	TIME [epoch: 5.74 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230743615753339		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 1.230743615753339 | validation: 2.966270077226213]
	TIME [epoch: 5.74 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2314098812403307		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 1.2314098812403307 | validation: 2.967194168509802]
	TIME [epoch: 5.73 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234663257994254		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 1.234663257994254 | validation: 2.960738775494824]
	TIME [epoch: 5.74 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2342992684479062		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 1.2342992684479062 | validation: 2.9686439292612854]
	TIME [epoch: 5.75 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324211232080233		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 1.2324211232080233 | validation: 2.968507624735046]
	TIME [epoch: 5.78 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2320611775709658		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 1.2320611775709658 | validation: 2.9704469714691744]
	TIME [epoch: 5.74 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2335041492705296		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 1.2335041492705296 | validation: 2.9676154979248617]
	TIME [epoch: 5.74 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2322380092794922		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 1.2322380092794922 | validation: 2.9642507152072444]
	TIME [epoch: 5.74 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231222141755691		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 1.231222141755691 | validation: 2.9649255059285498]
	TIME [epoch: 5.74 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234749508080034		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 1.234749508080034 | validation: 2.962431023964341]
	TIME [epoch: 5.74 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2340922731764863		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 1.2340922731764863 | validation: 2.9675690203346847]
	TIME [epoch: 5.77 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231667811189345		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 1.231667811189345 | validation: 2.9705630731422925]
	TIME [epoch: 5.75 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2333961368500685		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 1.2333961368500685 | validation: 2.968784735969872]
	TIME [epoch: 5.74 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2282415294265223		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 1.2282415294265223 | validation: 2.960497982537694]
	TIME [epoch: 5.74 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2314004275485493		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 1.2314004275485493 | validation: 2.9732333945098257]
	TIME [epoch: 5.74 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2342409595191466		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 1.2342409595191466 | validation: 2.9739689291307605]
	TIME [epoch: 5.74 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319948406396928		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 1.2319948406396928 | validation: 2.9799368364720995]
	TIME [epoch: 5.75 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2359149422257365		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 1.2359149422257365 | validation: 2.970266447722803]
	TIME [epoch: 5.79 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2316657488261011		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 1.2316657488261011 | validation: 2.9680272158422714]
	TIME [epoch: 5.74 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229368319591018		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 1.229368319591018 | validation: 2.968663505431148]
	TIME [epoch: 5.74 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2293375302420824		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 1.2293375302420824 | validation: 2.9749898222645834]
	TIME [epoch: 5.73 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2296291814772946		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 1.2296291814772946 | validation: 2.971274745254855]
	TIME [epoch: 5.74 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2357317068758649		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 1.2357317068758649 | validation: 2.9612567437848485]
	TIME [epoch: 5.75 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2309093435165075		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 1.2309093435165075 | validation: 2.9657442049794724]
	TIME [epoch: 5.77 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233360880225029		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 1.233360880225029 | validation: 2.972986105756742]
	TIME [epoch: 5.75 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235254581304436		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 1.235254581304436 | validation: 2.9766958451728622]
	TIME [epoch: 5.74 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235051662874894		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 1.235051662874894 | validation: 2.97150832794703]
	TIME [epoch: 5.74 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312331743912666		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 1.2312331743912666 | validation: 2.975462983267105]
	TIME [epoch: 5.75 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233633476457331		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 1.233633476457331 | validation: 2.960235152400657]
	TIME [epoch: 5.73 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230691500025514		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 1.230691500025514 | validation: 2.9703194673817337]
	TIME [epoch: 5.74 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2299022063074987		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 1.2299022063074987 | validation: 2.9679143418230196]
	TIME [epoch: 5.78 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2340311278010938		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 1.2340311278010938 | validation: 2.971882519803366]
	TIME [epoch: 5.75 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2323419322674651		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 1.2323419322674651 | validation: 2.963177570099191]
	TIME [epoch: 5.74 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306229226674772		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 1.2306229226674772 | validation: 2.969019216826183]
	TIME [epoch: 5.75 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2315061270613237		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 1.2315061270613237 | validation: 2.9762409364325992]
	TIME [epoch: 5.74 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2343725252959812		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 1.2343725252959812 | validation: 2.967395469923512]
	TIME [epoch: 5.74 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2264223706633177		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 1.2264223706633177 | validation: 2.972365467847404]
	TIME [epoch: 5.77 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230831385622003		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 1.230831385622003 | validation: 2.974656719070359]
	TIME [epoch: 5.74 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230367685608447		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 1.230367685608447 | validation: 2.97323855158503]
	TIME [epoch: 5.73 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2333218601100338		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 1.2333218601100338 | validation: 2.966219392775721]
	TIME [epoch: 5.75 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2316211418062062		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 1.2316211418062062 | validation: 2.9629339805298662]
	TIME [epoch: 5.74 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232320692670184		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 1.232320692670184 | validation: 2.972070711592087]
	TIME [epoch: 5.73 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2291250667508968		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 1.2291250667508968 | validation: 2.972206855472155]
	TIME [epoch: 5.76 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285306135883365		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 1.2285306135883365 | validation: 2.974396468565423]
	TIME [epoch: 5.76 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2311804946306084		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 1.2311804946306084 | validation: 2.964205142801774]
	TIME [epoch: 5.75 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2359991764228484		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 1.2359991764228484 | validation: 2.9674876142938813]
	TIME [epoch: 5.74 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234442271836762		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 1.234442271836762 | validation: 2.9666283638854862]
	TIME [epoch: 5.74 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2311432588786477		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 1.2311432588786477 | validation: 2.966018448527036]
	TIME [epoch: 5.75 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235349761308402		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 1.235349761308402 | validation: 2.9699946797020447]
	TIME [epoch: 5.75 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2297538741335583		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 1.2297538741335583 | validation: 2.9566988873023132]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r2_20240310_015135/states/model_tr_study202_1628.pth
	Model improved!!!
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312414442873458		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 1.2312414442873458 | validation: 2.9701141490204948]
	TIME [epoch: 5.74 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2317106820637027		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 1.2317106820637027 | validation: 2.9698755571444653]
	TIME [epoch: 5.73 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2311988188480143		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 1.2311988188480143 | validation: 2.9702977749411024]
	TIME [epoch: 5.73 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231376326154135		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 1.231376326154135 | validation: 2.962183725412631]
	TIME [epoch: 5.74 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306805653843647		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 1.2306805653843647 | validation: 2.970582700295637]
	TIME [epoch: 5.73 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234725156429914		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 1.234725156429914 | validation: 2.9667470464201937]
	TIME [epoch: 5.76 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2276847494194938		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 1.2276847494194938 | validation: 2.9663970550856136]
	TIME [epoch: 5.75 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2344394436084432		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 1.2344394436084432 | validation: 2.968108254081018]
	TIME [epoch: 5.74 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2338943308527257		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 1.2338943308527257 | validation: 2.97104212107227]
	TIME [epoch: 5.74 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230816532243399		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 1.230816532243399 | validation: 2.970900345995201]
	TIME [epoch: 5.74 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2322175143306628		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 1.2322175143306628 | validation: 2.976818877356589]
	TIME [epoch: 5.74 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2327972142497927		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 1.2327972142497927 | validation: 2.9766844791873392]
	TIME [epoch: 5.74 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2298525310376178		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 1.2298525310376178 | validation: 2.9720793363498097]
	TIME [epoch: 5.78 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23028053566261		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 1.23028053566261 | validation: 2.9720393939137213]
	TIME [epoch: 5.74 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2314678681630704		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 1.2314678681630704 | validation: 2.977079040532617]
	TIME [epoch: 5.74 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231353667368811		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 1.231353667368811 | validation: 2.9646073789863854]
	TIME [epoch: 5.74 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2297121800546997		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 1.2297121800546997 | validation: 2.973028794039353]
	TIME [epoch: 5.74 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2317614440190168		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 1.2317614440190168 | validation: 2.9682052652365725]
	TIME [epoch: 5.74 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2351057628256548		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 1.2351057628256548 | validation: 2.9603869860798286]
	TIME [epoch: 5.77 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231365805736834		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 1.231365805736834 | validation: 2.9719951750630513]
	TIME [epoch: 5.75 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319593463517902		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 1.2319593463517902 | validation: 2.9729416638635247]
	TIME [epoch: 5.74 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312786819505772		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 1.2312786819505772 | validation: 2.967288360201974]
	TIME [epoch: 5.74 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229522713805022		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 1.229522713805022 | validation: 2.9739378186043344]
	TIME [epoch: 5.74 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2300164963641629		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 1.2300164963641629 | validation: 2.970762915666627]
	TIME [epoch: 5.74 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2274479704848777		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 1.2274479704848777 | validation: 2.9622740136881105]
	TIME [epoch: 5.74 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228298705956837		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 1.228298705956837 | validation: 2.9724785794673982]
	TIME [epoch: 5.78 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2304547688329117		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 1.2304547688329117 | validation: 2.9647184747603137]
	TIME [epoch: 5.74 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230497556885985		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 1.230497556885985 | validation: 2.9676046080217864]
	TIME [epoch: 5.74 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2293983821900187		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 1.2293983821900187 | validation: 2.972899829984952]
	TIME [epoch: 5.74 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2305330106192813		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 1.2305330106192813 | validation: 2.970760729620285]
	TIME [epoch: 5.74 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2339478964136898		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 1.2339478964136898 | validation: 2.979975795712978]
	TIME [epoch: 5.74 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2340834065515045		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 1.2340834065515045 | validation: 2.9676107725389773]
	TIME [epoch: 5.77 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2322986367282942		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 1.2322986367282942 | validation: 2.977906642862056]
	TIME [epoch: 5.75 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2302441378551265		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 1.2302441378551265 | validation: 2.9774276897701397]
	TIME [epoch: 5.74 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232512159083001		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 1.232512159083001 | validation: 2.9780718417097183]
	TIME [epoch: 5.74 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306375764101198		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 1.2306375764101198 | validation: 2.9705906005618012]
	TIME [epoch: 5.74 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2318658701548744		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 1.2318658701548744 | validation: 2.974082622236206]
	TIME [epoch: 5.74 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306545613062152		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 1.2306545613062152 | validation: 2.968891382017239]
	TIME [epoch: 5.74 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2287345992646208		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 1.2287345992646208 | validation: 2.970567037414586]
	TIME [epoch: 5.77 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312655709269293		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 1.2312655709269293 | validation: 2.974946836457624]
	TIME [epoch: 5.74 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234369730518336		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 1.234369730518336 | validation: 2.97375208728927]
	TIME [epoch: 5.74 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23403455432141		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 1.23403455432141 | validation: 2.977201360341332]
	TIME [epoch: 5.74 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236376460620088		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 1.236376460620088 | validation: 2.97370723645815]
	TIME [epoch: 5.74 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2320926093995122		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 1.2320926093995122 | validation: 2.9760573652553375]
	TIME [epoch: 5.74 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2345565974486523		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 1.2345565974486523 | validation: 2.9739108601845308]
	TIME [epoch: 5.77 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2303825144389975		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 1.2303825144389975 | validation: 2.9764650412023164]
	TIME [epoch: 5.74 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230199901966369		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 1.230199901966369 | validation: 2.9656566195487493]
	TIME [epoch: 5.74 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2338774341299317		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 1.2338774341299317 | validation: 2.970781906805562]
	TIME [epoch: 5.74 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2315991557656125		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 1.2315991557656125 | validation: 2.9783914110506973]
	TIME [epoch: 5.74 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2291909797114884		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 1.2291909797114884 | validation: 2.9802050729282747]
	TIME [epoch: 5.74 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2342177497624705		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 1.2342177497624705 | validation: 2.9713974843961704]
	TIME [epoch: 5.75 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2348713962734392		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 1.2348713962734392 | validation: 2.967798229869455]
	TIME [epoch: 5.77 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2292069449934238		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 1.2292069449934238 | validation: 2.9747625883557296]
	TIME [epoch: 5.74 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2283431922269388		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 1.2283431922269388 | validation: 2.970328380987587]
	TIME [epoch: 5.74 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2339740769462877		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 1.2339740769462877 | validation: 2.9749493822929858]
	TIME [epoch: 5.74 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2328244160165724		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 1.2328244160165724 | validation: 2.967811421683671]
	TIME [epoch: 5.74 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324590042293544		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 1.2324590042293544 | validation: 2.973446310114639]
	TIME [epoch: 5.74 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230688470949493		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 1.230688470949493 | validation: 2.9746755340731177]
	TIME [epoch: 5.78 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2329734369747916		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 1.2329734369747916 | validation: 2.9770462128404422]
	TIME [epoch: 5.74 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2309535567746521		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 1.2309535567746521 | validation: 2.9732009364873297]
	TIME [epoch: 5.74 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306409981223447		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 1.2306409981223447 | validation: 2.9693209811769568]
	TIME [epoch: 5.74 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2322467861286799		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 1.2322467861286799 | validation: 2.9733187991152654]
	TIME [epoch: 5.74 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2332285537135563		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 1.2332285537135563 | validation: 2.977520605034408]
	TIME [epoch: 5.74 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231090538826889		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 1.231090538826889 | validation: 2.973737237078443]
	TIME [epoch: 5.75 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2333670570896913		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 1.2333670570896913 | validation: 2.968701412123944]
	TIME [epoch: 5.77 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2295698534115096		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 1.2295698534115096 | validation: 2.9752214946876188]
	TIME [epoch: 5.74 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2337597980583817		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 1.2337597980583817 | validation: 2.97900802734267]
	TIME [epoch: 5.74 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2293766290195143		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 1.2293766290195143 | validation: 2.97198602466984]
	TIME [epoch: 5.74 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2326195175989338		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 1.2326195175989338 | validation: 2.9705422450225547]
	TIME [epoch: 5.74 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2335907433513005		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 1.2335907433513005 | validation: 2.9727102126886336]
	TIME [epoch: 5.74 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324619343751577		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 1.2324619343751577 | validation: 2.9730965470607527]
	TIME [epoch: 5.78 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2303577088879316		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 1.2303577088879316 | validation: 2.9677472215720493]
	TIME [epoch: 5.74 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228832838045439		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 1.228832838045439 | validation: 2.9717655915466237]
	TIME [epoch: 5.74 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2350099004726567		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 1.2350099004726567 | validation: 2.977738210340348]
	TIME [epoch: 5.74 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231638525582574		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 1.231638525582574 | validation: 2.980146890310434]
	TIME [epoch: 5.74 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.227817680109088		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 1.227817680109088 | validation: 2.972587077492861]
	TIME [epoch: 5.74 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231466452987582		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 1.231466452987582 | validation: 2.971748817383428]
	TIME [epoch: 5.75 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2318027728184153		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 1.2318027728184153 | validation: 2.96785999616873]
	TIME [epoch: 5.76 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2316906306062485		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 1.2316906306062485 | validation: 2.961823846961362]
	TIME [epoch: 5.74 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2320380978919108		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 1.2320380978919108 | validation: 2.972331399590891]
	TIME [epoch: 5.74 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2299031088331895		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 1.2299031088331895 | validation: 2.967444415010675]
	TIME [epoch: 5.74 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2301135028060999		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 1.2301135028060999 | validation: 2.965449448805621]
	TIME [epoch: 5.74 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2342434028920188		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 1.2342434028920188 | validation: 2.9628011510000647]
	TIME [epoch: 5.74 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228028590629521		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 1.228028590629521 | validation: 2.969988953388679]
	TIME [epoch: 5.78 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2304169875123883		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 1.2304169875123883 | validation: 2.9672486774662086]
	TIME [epoch: 5.74 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2287369665050536		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 1.2287369665050536 | validation: 2.9712489885492706]
	TIME [epoch: 5.74 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2299386617740249		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 1.2299386617740249 | validation: 2.962221931203498]
	TIME [epoch: 5.74 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2339917176323953		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 1.2339917176323953 | validation: 2.966167911972492]
	TIME [epoch: 5.74 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2297546282281309		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 1.2297546282281309 | validation: 2.975472049047927]
	TIME [epoch: 5.74 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2322888924567221		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 1.2322888924567221 | validation: 2.9619346256314962]
	TIME [epoch: 5.76 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2340533725693075		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 1.2340533725693075 | validation: 2.966716988030547]
	TIME [epoch: 5.75 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2329624101925287		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 1.2329624101925287 | validation: 2.964912575091588]
	TIME [epoch: 5.74 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2337141413233472		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 1.2337141413233472 | validation: 2.9687585023471175]
	TIME [epoch: 5.74 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324588179560596		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 1.2324588179560596 | validation: 2.9686163912910537]
	TIME [epoch: 5.74 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231552541361064		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 1.231552541361064 | validation: 2.9673600597599408]
	TIME [epoch: 5.74 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2268827978515948		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 1.2268827978515948 | validation: 2.9653751996267568]
	TIME [epoch: 5.74 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2353586413982405		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 1.2353586413982405 | validation: 2.971618810912388]
	TIME [epoch: 5.78 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228652892776564		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 1.228652892776564 | validation: 2.977247363831276]
	TIME [epoch: 5.74 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312838193051567		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 1.2312838193051567 | validation: 2.967805615682064]
	TIME [epoch: 5.74 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2263071258885145		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 1.2263071258885145 | validation: 2.969021685348049]
	TIME [epoch: 5.74 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2303467290154457		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 1.2303467290154457 | validation: 2.9705362720178936]
	TIME [epoch: 5.74 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233783765821826		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 1.233783765821826 | validation: 2.966665775511358]
	TIME [epoch: 5.74 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2329832952979494		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 1.2329832952979494 | validation: 2.9639323351144715]
	TIME [epoch: 5.76 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228121160253346		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 1.228121160253346 | validation: 2.9705574800769785]
	TIME [epoch: 5.75 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2313827663140782		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 1.2313827663140782 | validation: 2.9709599880309003]
	TIME [epoch: 5.74 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307667810832172		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 1.2307667810832172 | validation: 2.9682357266443775]
	TIME [epoch: 5.74 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2340954102483184		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 1.2340954102483184 | validation: 2.966526112331412]
	TIME [epoch: 5.74 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2297738792106752		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 1.2297738792106752 | validation: 2.971702732536944]
	TIME [epoch: 5.74 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230506898540737		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 1.230506898540737 | validation: 2.969599593400992]
	TIME [epoch: 5.74 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2290618156763689		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 1.2290618156763689 | validation: 2.9741062360660613]
	TIME [epoch: 5.78 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2333735213604506		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 1.2333735213604506 | validation: 2.9725509696054355]
	TIME [epoch: 5.74 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2345869358973285		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 1.2345869358973285 | validation: 2.9663193457761783]
	TIME [epoch: 5.74 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2354621976403122		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 1.2354621976403122 | validation: 2.973994029274855]
	TIME [epoch: 5.74 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2330691399742288		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 1.2330691399742288 | validation: 2.968963837499481]
	TIME [epoch: 5.74 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228746762854028		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 1.228746762854028 | validation: 2.9723780212111035]
	TIME [epoch: 5.74 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231405939444641		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 1.231405939444641 | validation: 2.976657856787723]
	TIME [epoch: 5.77 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230493656700664		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 1.230493656700664 | validation: 2.973489289800341]
	TIME [epoch: 5.75 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233391600551145		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 1.233391600551145 | validation: 2.977161220712128]
	TIME [epoch: 5.74 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2282621063005927		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 1.2282621063005927 | validation: 2.963861219886675]
	TIME [epoch: 5.74 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2303990239205382		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 1.2303990239205382 | validation: 2.969647921685449]
	TIME [epoch: 5.74 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2287953775942104		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 1.2287953775942104 | validation: 2.970437507511673]
	TIME [epoch: 5.74 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230067384714827		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 1.230067384714827 | validation: 2.9701381057683385]
	TIME [epoch: 5.75 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232791507087252		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 1.232791507087252 | validation: 2.9691372760709744]
	TIME [epoch: 5.77 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2308592942128653		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 1.2308592942128653 | validation: 2.971632272917182]
	TIME [epoch: 5.74 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2291924707421868		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 1.2291924707421868 | validation: 2.971706987500231]
	TIME [epoch: 5.74 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2310241414646088		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 1.2310241414646088 | validation: 2.9621719891879548]
	TIME [epoch: 5.74 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231812407055075		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 1.231812407055075 | validation: 2.9774575809055444]
	TIME [epoch: 5.74 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2325797225905144		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 1.2325797225905144 | validation: 2.9700871123921293]
	TIME [epoch: 5.74 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2331015823452856		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 1.2331015823452856 | validation: 2.9770300563952]
	TIME [epoch: 5.78 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2326822596988047		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 1.2326822596988047 | validation: 2.97754821791508]
	TIME [epoch: 5.74 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2314023134759005		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 1.2314023134759005 | validation: 2.969166921065979]
	TIME [epoch: 5.74 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2332377769091905		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 1.2332377769091905 | validation: 2.960518552888639]
	TIME [epoch: 5.74 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233911262321607		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 1.233911262321607 | validation: 2.970221871897178]
	TIME [epoch: 5.74 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2309887769179806		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 1.2309887769179806 | validation: 2.974468940888678]
	TIME [epoch: 5.74 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228820332442791		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 1.228820332442791 | validation: 2.9733207046399026]
	TIME [epoch: 5.75 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2342742348608333		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 1.2342742348608333 | validation: 2.9744685925331713]
	TIME [epoch: 5.77 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23049422438256		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 1.23049422438256 | validation: 2.972370376590423]
	TIME [epoch: 5.74 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2291034931038862		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 1.2291034931038862 | validation: 2.974569917025357]
	TIME [epoch: 5.74 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2280096667088476		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 1.2280096667088476 | validation: 2.9699581928341905]
	TIME [epoch: 5.74 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2322040942283157		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 1.2322040942283157 | validation: 2.963759558632312]
	TIME [epoch: 5.74 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230655887165407		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 1.230655887165407 | validation: 2.9780606846188222]
	TIME [epoch: 5.74 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324028909266602		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 1.2324028909266602 | validation: 2.9644254252500684]
	TIME [epoch: 5.77 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319277303087872		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 1.2319277303087872 | validation: 2.9754532009534467]
	TIME [epoch: 5.74 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2298990203013256		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 1.2298990203013256 | validation: 2.9695610437008684]
	TIME [epoch: 5.74 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2314428102604664		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 1.2314428102604664 | validation: 2.967704213181231]
	TIME [epoch: 5.74 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2322884716071898		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 1.2322884716071898 | validation: 2.969419933927534]
	TIME [epoch: 5.74 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2309234453016078		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 1.2309234453016078 | validation: 2.975823720657908]
	TIME [epoch: 5.74 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2289145354087232		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 1.2289145354087232 | validation: 2.9651181146276095]
	TIME [epoch: 5.75 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229921120009238		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 1.229921120009238 | validation: 2.9671787664599494]
	TIME [epoch: 5.77 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2308551465174626		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 1.2308551465174626 | validation: 2.9603598864820215]
	TIME [epoch: 5.74 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2286049367254792		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 1.2286049367254792 | validation: 2.964935309430042]
	TIME [epoch: 5.74 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231572110220129		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 1.231572110220129 | validation: 2.9766698691434033]
	TIME [epoch: 5.74 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2314547931072506		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 1.2314547931072506 | validation: 2.9684877159777794]
	TIME [epoch: 5.74 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324920605844558		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 1.2324920605844558 | validation: 2.96520312397692]
	TIME [epoch: 5.74 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2325993922958596		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 1.2325993922958596 | validation: 2.9708598760866143]
	TIME [epoch: 5.78 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231624635536945		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 1.231624635536945 | validation: 2.967713760178047]
	TIME [epoch: 5.74 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2350513100531573		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 1.2350513100531573 | validation: 2.9715183061520367]
	TIME [epoch: 5.74 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2288510178317202		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 1.2288510178317202 | validation: 2.9667767054772276]
	TIME [epoch: 5.74 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285259197827574		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 1.2285259197827574 | validation: 2.9698553757401736]
	TIME [epoch: 5.74 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2318914026337833		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 1.2318914026337833 | validation: 2.9673655211211556]
	TIME [epoch: 5.74 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228884025511412		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 1.228884025511412 | validation: 2.968500500315366]
	TIME [epoch: 5.77 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229982957097202		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 1.229982957097202 | validation: 2.9685835693754057]
	TIME [epoch: 5.75 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2316345006517493		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 1.2316345006517493 | validation: 2.972221537561882]
	TIME [epoch: 5.74 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2289574828634127		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 1.2289574828634127 | validation: 2.9679210271896177]
	TIME [epoch: 5.74 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2310652468749728		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 1.2310652468749728 | validation: 2.976861040828461]
	TIME [epoch: 5.74 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2335215271331386		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 1.2335215271331386 | validation: 2.9738177551826674]
	TIME [epoch: 5.74 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229945458288649		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 1.229945458288649 | validation: 2.9775763352688704]
	TIME [epoch: 5.74 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232642743475229		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 1.232642743475229 | validation: 2.9729019498550433]
	TIME [epoch: 5.78 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2317299243867295		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 1.2317299243867295 | validation: 2.9727303079490595]
	TIME [epoch: 5.74 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2328822917272504		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 1.2328822917272504 | validation: 2.9694346844508197]
	TIME [epoch: 5.74 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2318024288437013		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 1.2318024288437013 | validation: 2.9641441562912427]
	TIME [epoch: 5.74 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2272647602633788		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 1.2272647602633788 | validation: 2.9700156978999304]
	TIME [epoch: 5.74 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2268276073571291		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 1.2268276073571291 | validation: 2.967860399821656]
	TIME [epoch: 5.74 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2314619705463739		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 1.2314619705463739 | validation: 2.9729531411405175]
	TIME [epoch: 5.76 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2320364684707856		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 1.2320364684707856 | validation: 2.9755084402886256]
	TIME [epoch: 5.75 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2297541373602043		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 1.2297541373602043 | validation: 2.9724274057414726]
	TIME [epoch: 5.74 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2301489994723203		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 1.2301489994723203 | validation: 2.9746417096403253]
	TIME [epoch: 5.74 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2299548297794942		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 1.2299548297794942 | validation: 2.9742228923515177]
	TIME [epoch: 5.74 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2295719892969201		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 1.2295719892969201 | validation: 2.9705574117362175]
	TIME [epoch: 5.74 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307782225107178		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 1.2307782225107178 | validation: 2.96458978729317]
	TIME [epoch: 5.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230623402736728		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 1.230623402736728 | validation: 2.9672676475120694]
	TIME [epoch: 5.78 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2277770750224248		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 1.2277770750224248 | validation: 2.973979426811594]
	TIME [epoch: 5.74 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23070047613542		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 1.23070047613542 | validation: 2.97082547134754]
	TIME [epoch: 5.74 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228956998204829		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 1.228956998204829 | validation: 2.9717722748861526]
	TIME [epoch: 5.74 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231428258833847		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 1.231428258833847 | validation: 2.974215269934548]
	TIME [epoch: 5.75 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2299929858998226		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 1.2299929858998226 | validation: 2.9692959733236317]
	TIME [epoch: 5.74 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285205082956836		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 1.2285205082956836 | validation: 2.9659916491099536]
	TIME [epoch: 5.77 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2271878071186775		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 1.2271878071186775 | validation: 2.9739460646713485]
	TIME [epoch: 5.75 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285764716469882		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 1.2285764716469882 | validation: 2.9719609982366406]
	TIME [epoch: 5.74 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2292526982652727		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 1.2292526982652727 | validation: 2.969139796064064]
	TIME [epoch: 5.74 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.227210120922225		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 1.227210120922225 | validation: 2.9649910994061743]
	TIME [epoch: 5.74 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2289631272665644		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 1.2289631272665644 | validation: 2.972787310210647]
	TIME [epoch: 5.74 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307916802955363		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 1.2307916802955363 | validation: 2.970258865377308]
	TIME [epoch: 5.76 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228710068273368		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 1.228710068273368 | validation: 2.977406971399447]
	TIME [epoch: 5.77 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2270163309595543		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 1.2270163309595543 | validation: 2.974838791918844]
	TIME [epoch: 5.74 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2326437095997995		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 1.2326437095997995 | validation: 2.9723851807675556]
	TIME [epoch: 5.74 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319039952201316		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 1.2319039952201316 | validation: 2.971310473773692]
	TIME [epoch: 5.74 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306942408238162		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 1.2306942408238162 | validation: 2.971761575197317]
	TIME [epoch: 5.74 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230881891044023		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 1.230881891044023 | validation: 2.96996062135202]
	TIME [epoch: 5.74 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229572426419143		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 1.229572426419143 | validation: 2.9639228431577194]
	TIME [epoch: 5.78 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2329926539097498		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 1.2329926539097498 | validation: 2.9714848616046177]
	TIME [epoch: 5.74 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.227901185683559		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 1.227901185683559 | validation: 2.969557724988259]
	TIME [epoch: 5.74 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2287648303365113		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 1.2287648303365113 | validation: 2.9714632964655427]
	TIME [epoch: 5.74 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2289572444589238		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 1.2289572444589238 | validation: 2.973632942848112]
	TIME [epoch: 5.74 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2305068375457964		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 1.2305068375457964 | validation: 2.9763147843016475]
	TIME [epoch: 5.74 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233035070010526		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 1.233035070010526 | validation: 2.972293423437451]
	TIME [epoch: 5.75 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2292797382197835		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 1.2292797382197835 | validation: 2.9692257829817033]
	TIME [epoch: 5.77 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2287916345117078		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 1.2287916345117078 | validation: 2.9705271702201412]
	TIME [epoch: 5.75 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2323684770740293		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 1.2323684770740293 | validation: 2.9745014380739074]
	TIME [epoch: 5.74 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233983937255201		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 1.233983937255201 | validation: 2.9799964265678778]
	TIME [epoch: 5.74 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2305322788630202		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 1.2305322788630202 | validation: 2.977396262383503]
	TIME [epoch: 5.74 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2317312330931358		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 1.2317312330931358 | validation: 2.972782939595387]
	TIME [epoch: 5.75 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307570032496984		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 1.2307570032496984 | validation: 2.969526225785102]
	TIME [epoch: 5.78 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2325414525423863		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 1.2325414525423863 | validation: 2.9721563626255296]
	TIME [epoch: 5.75 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2300252411756578		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 1.2300252411756578 | validation: 2.9687355345516027]
	TIME [epoch: 5.75 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228367630212203		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 1.228367630212203 | validation: 2.9719547494018044]
	TIME [epoch: 5.75 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2293370632815903		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 1.2293370632815903 | validation: 2.969625796362185]
	TIME [epoch: 5.75 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231929031718256		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 1.231929031718256 | validation: 2.975533467243325]
	TIME [epoch: 5.75 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231160208856347		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 1.231160208856347 | validation: 2.9764096612679056]
	TIME [epoch: 5.76 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2331538520906993		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 1.2331538520906993 | validation: 2.9757070834814217]
	TIME [epoch: 5.76 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2302149203594255		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 1.2302149203594255 | validation: 2.967733540813564]
	TIME [epoch: 5.75 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2298137419300617		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 1.2298137419300617 | validation: 2.9764906726223037]
	TIME [epoch: 5.75 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.227641453793097		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 1.227641453793097 | validation: 2.976031472074279]
	TIME [epoch: 5.75 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23095692534017		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 1.23095692534017 | validation: 2.9786776991249533]
	TIME [epoch: 5.75 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2334065214030878		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 1.2334065214030878 | validation: 2.972481516990185]
	TIME [epoch: 5.74 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2330038429753818		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 1.2330038429753818 | validation: 2.9749343203969034]
	TIME [epoch: 5.78 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2370170728591614		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 1.2370170728591614 | validation: 2.9785550844463207]
	TIME [epoch: 5.75 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2316192138981437		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 1.2316192138981437 | validation: 2.9772548673830763]
	TIME [epoch: 5.75 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232091130592927		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 1.232091130592927 | validation: 2.9735709728198634]
	TIME [epoch: 5.74 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23099256481027		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 1.23099256481027 | validation: 2.967859796259891]
	TIME [epoch: 5.75 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2327158055661687		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 1.2327158055661687 | validation: 2.9719286104733578]
	TIME [epoch: 5.74 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2279415447559483		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 1.2279415447559483 | validation: 2.972036815293463]
	TIME [epoch: 5.78 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2305354346733282		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 1.2305354346733282 | validation: 2.9692055461590177]
	TIME [epoch: 5.77 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2280242570655784		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 1.2280242570655784 | validation: 2.9659842664364873]
	TIME [epoch: 5.74 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324339326831948		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 1.2324339326831948 | validation: 2.970618688656083]
	TIME [epoch: 5.75 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230089838239536		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 1.230089838239536 | validation: 2.9764897031708397]
	TIME [epoch: 5.75 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231915322196265		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 1.231915322196265 | validation: 2.9697393765696907]
	TIME [epoch: 5.74 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2295863279376358		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 1.2295863279376358 | validation: 2.9657406770924424]
	TIME [epoch: 5.75 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229807504398217		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 1.229807504398217 | validation: 2.9629811681520852]
	TIME [epoch: 5.78 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319168019786135		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 1.2319168019786135 | validation: 2.9587855104205665]
	TIME [epoch: 5.75 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312210166649988		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 1.2312210166649988 | validation: 2.973280494908203]
	TIME [epoch: 5.74 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307480770488122		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 1.2307480770488122 | validation: 2.9720351233888858]
	TIME [epoch: 5.74 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2327985233018321		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 1.2327985233018321 | validation: 2.968739690812953]
	TIME [epoch: 5.75 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2316704976655357		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 1.2316704976655357 | validation: 2.970176576347142]
	TIME [epoch: 5.74 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232043067095689		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 1.232043067095689 | validation: 2.9738000970762117]
	TIME [epoch: 5.77 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2298234843547022		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 1.2298234843547022 | validation: 2.9691596216625737]
	TIME [epoch: 5.76 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2301250329568618		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 1.2301250329568618 | validation: 2.9681724278111448]
	TIME [epoch: 5.75 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312403298121708		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 1.2312403298121708 | validation: 2.9654360136340814]
	TIME [epoch: 5.74 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306514138762967		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 1.2306514138762967 | validation: 2.9797520447931816]
	TIME [epoch: 5.74 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2317606307428262		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 1.2317606307428262 | validation: 2.970162744199029]
	TIME [epoch: 5.74 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2299900452641053		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 1.2299900452641053 | validation: 2.9727757196985274]
	TIME [epoch: 5.74 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2317048951030936		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 1.2317048951030936 | validation: 2.979968730415093]
	TIME [epoch: 5.78 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228118819522641		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 1.228118819522641 | validation: 2.972677885912907]
	TIME [epoch: 5.74 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2303438810747795		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 1.2303438810747795 | validation: 2.978659078758262]
	TIME [epoch: 5.75 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232309567834411		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 1.232309567834411 | validation: 2.968160490328313]
	TIME [epoch: 5.74 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319607435287645		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 1.2319607435287645 | validation: 2.9647744436547265]
	TIME [epoch: 5.75 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2286812423454851		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 1.2286812423454851 | validation: 2.9667595377872074]
	TIME [epoch: 5.74 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229265568454152		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 1.229265568454152 | validation: 2.9741086852930083]
	TIME [epoch: 5.78 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234211574924532		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 1.234211574924532 | validation: 2.9739019983835884]
	TIME [epoch: 5.75 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2286733737272602		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 1.2286733737272602 | validation: 2.9755644492366127]
	TIME [epoch: 5.74 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285902299259597		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 1.2285902299259597 | validation: 2.9736793541360944]
	TIME [epoch: 5.74 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2323749024639872		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 1.2323749024639872 | validation: 2.96829747401358]
	TIME [epoch: 5.74 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319015724797804		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 1.2319015724797804 | validation: 2.9684743069394757]
	TIME [epoch: 5.74 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228971489284902		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 1.228971489284902 | validation: 2.973184191383766]
	TIME [epoch: 5.75 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2286466911962852		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 1.2286466911962852 | validation: 2.967462331482376]
	TIME [epoch: 5.78 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229641067225354		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 1.229641067225354 | validation: 2.9690407774969128]
	TIME [epoch: 5.74 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.226849160934889		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 1.226849160934889 | validation: 2.976528452428876]
	TIME [epoch: 5.76 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319314070281076		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 1.2319314070281076 | validation: 2.9677735674210486]
	TIME [epoch: 5.74 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2284235379027415		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 1.2284235379027415 | validation: 2.9750120193101566]
	TIME [epoch: 5.76 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2287846593381424		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 1.2287846593381424 | validation: 2.9700419221860614]
	TIME [epoch: 5.74 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2295562616342288		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 1.2295562616342288 | validation: 2.9746301019803254]
	TIME [epoch: 5.78 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229022401488053		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 1.229022401488053 | validation: 2.9760736723666357]
	TIME [epoch: 5.74 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285376455829282		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 1.2285376455829282 | validation: 2.972082777203833]
	TIME [epoch: 5.74 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229536880010119		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 1.229536880010119 | validation: 2.977004859562021]
	TIME [epoch: 5.74 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312692264891247		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 1.2312692264891247 | validation: 2.972948059424683]
	TIME [epoch: 5.74 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230648755720964		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 1.230648755720964 | validation: 2.972054784724103]
	TIME [epoch: 5.74 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2298980404865085		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 1.2298980404865085 | validation: 2.967777107618265]
	TIME [epoch: 5.75 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229039128656887		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 1.229039128656887 | validation: 2.9710022535375336]
	TIME [epoch: 5.77 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233174665219956		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 1.233174665219956 | validation: 2.9701779336648158]
	TIME [epoch: 5.74 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2286654040318934		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 1.2286654040318934 | validation: 2.970697490299001]
	TIME [epoch: 5.74 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2291650346775223		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 1.2291650346775223 | validation: 2.970264618944035]
	TIME [epoch: 5.74 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307392255919338		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 1.2307392255919338 | validation: 2.965588230730641]
	TIME [epoch: 5.74 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2272612360176767		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 1.2272612360176767 | validation: 2.9632594480978356]
	TIME [epoch: 5.74 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230472951635172		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 1.230472951635172 | validation: 2.9679447591942334]
	TIME [epoch: 5.78 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2301772767989283		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 1.2301772767989283 | validation: 2.970552422644139]
	TIME [epoch: 5.74 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229804041014093		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 1.229804041014093 | validation: 2.9745753937657953]
	TIME [epoch: 5.74 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285674629792276		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 1.2285674629792276 | validation: 2.970969264398185]
	TIME [epoch: 5.75 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2332907217108218		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 1.2332907217108218 | validation: 2.9723909645710624]
	TIME [epoch: 5.74 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2287552062912739		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 1.2287552062912739 | validation: 2.9780005096007107]
	TIME [epoch: 5.74 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2305780241797444		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 1.2305780241797444 | validation: 2.965995169859576]
	TIME [epoch: 5.76 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2283796295212346		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 1.2283796295212346 | validation: 2.9726996440628626]
	TIME [epoch: 5.75 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228715092139022		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 1.228715092139022 | validation: 2.966504368103122]
	TIME [epoch: 5.74 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2310089552446248		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 1.2310089552446248 | validation: 2.967796227154784]
	TIME [epoch: 5.74 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.224866444357827		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 1.224866444357827 | validation: 2.970448172092203]
	TIME [epoch: 5.74 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234028591350955		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 1.234028591350955 | validation: 2.9773498109572585]
	TIME [epoch: 5.74 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2325817934901844		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 1.2325817934901844 | validation: 2.9700056052107318]
	TIME [epoch: 5.74 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2257546250290194		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 1.2257546250290194 | validation: 2.9628209722601833]
	TIME [epoch: 5.78 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306614046620932		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 1.2306614046620932 | validation: 2.9698638426840342]
	TIME [epoch: 5.74 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2287350987124352		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 1.2287350987124352 | validation: 2.967814154861701]
	TIME [epoch: 5.74 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229274392955987		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 1.229274392955987 | validation: 2.968510831639794]
	TIME [epoch: 5.74 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231300342655626		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 1.231300342655626 | validation: 2.969140181675615]
	TIME [epoch: 5.74 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2318635088144807		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 1.2318635088144807 | validation: 2.969066664058817]
	TIME [epoch: 5.73 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2350588462226015		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 1.2350588462226015 | validation: 2.965363571965627]
	TIME [epoch: 5.76 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2298732175642262		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 1.2298732175642262 | validation: 2.9694686335128564]
	TIME [epoch: 5.75 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312375405655467		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 1.2312375405655467 | validation: 2.9710220309323394]
	TIME [epoch: 5.74 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231005512623243		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 1.231005512623243 | validation: 2.977656439633217]
	TIME [epoch: 5.73 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2318210563871417		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 1.2318210563871417 | validation: 2.9684459566527237]
	TIME [epoch: 5.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229198156257063		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 1.229198156257063 | validation: 2.9677493304590716]
	TIME [epoch: 5.75 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307234941552667		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 1.2307234941552667 | validation: 2.9744760323441217]
	TIME [epoch: 5.76 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2275071511476345		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 1.2275071511476345 | validation: 2.969138852291455]
	TIME [epoch: 5.79 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2300526551990338		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 1.2300526551990338 | validation: 2.9755324502734584]
	TIME [epoch: 5.74 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2283127222247407		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 1.2283127222247407 | validation: 2.9666823181600943]
	TIME [epoch: 5.74 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2299872379355332		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 1.2299872379355332 | validation: 2.9697728860236405]
	TIME [epoch: 5.74 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2316772734299561		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 1.2316772734299561 | validation: 2.976317227578554]
	TIME [epoch: 5.76 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2297611671967372		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 1.2297611671967372 | validation: 2.9704863897907208]
	TIME [epoch: 5.73 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2308592760187171		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 1.2308592760187171 | validation: 2.968323437383035]
	TIME [epoch: 5.78 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231253644905599		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 1.231253644905599 | validation: 2.9752695519633403]
	TIME [epoch: 5.74 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2300828752738597		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 1.2300828752738597 | validation: 2.9719814609263757]
	TIME [epoch: 5.74 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2295314590518613		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 1.2295314590518613 | validation: 2.9666519800499622]
	TIME [epoch: 5.74 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312506282733904		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 1.2312506282733904 | validation: 2.9684612525163265]
	TIME [epoch: 5.73 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2330003803342244		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 1.2330003803342244 | validation: 2.973708021400649]
	TIME [epoch: 5.73 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2316569148689167		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 1.2316569148689167 | validation: 2.9714928388739814]
	TIME [epoch: 5.75 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2318576181262795		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 1.2318576181262795 | validation: 2.9719448017478123]
	TIME [epoch: 5.76 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2356949002090827		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 1.2356949002090827 | validation: 2.9758138559739984]
	TIME [epoch: 5.74 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2297056096351884		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 1.2297056096351884 | validation: 2.9683804635149]
	TIME [epoch: 5.74 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2324221026376894		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 1.2324221026376894 | validation: 2.9733172621713515]
	TIME [epoch: 5.74 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2310034702884147		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 1.2310034702884147 | validation: 2.9755377759764543]
	TIME [epoch: 5.74 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2337206192515908		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 1.2337206192515908 | validation: 2.9718689110474408]
	TIME [epoch: 5.74 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231300789131121		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 1.231300789131121 | validation: 2.9654054822805636]
	TIME [epoch: 5.77 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2326319376411194		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 1.2326319376411194 | validation: 2.9666912358616115]
	TIME [epoch: 5.74 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229890640861837		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 1.229890640861837 | validation: 2.969367406717527]
	TIME [epoch: 5.74 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2267505494742936		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 1.2267505494742936 | validation: 2.9794261882563307]
	TIME [epoch: 5.73 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2302689890922422		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 1.2302689890922422 | validation: 2.971302812855646]
	TIME [epoch: 5.74 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229749159432172		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 1.229749159432172 | validation: 2.9694835227381113]
	TIME [epoch: 5.73 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231059286087574		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 1.231059286087574 | validation: 2.972385338195419]
	TIME [epoch: 5.75 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231113058323142		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 1.231113058323142 | validation: 2.962182376108954]
	TIME [epoch: 5.76 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2288664558270568		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 1.2288664558270568 | validation: 2.9669955358452276]
	TIME [epoch: 5.74 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2321059003351484		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 1.2321059003351484 | validation: 2.9694653118087424]
	TIME [epoch: 5.74 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2278516148689298		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 1.2278516148689298 | validation: 2.9720727739933896]
	TIME [epoch: 5.73 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307964848360813		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 1.2307964848360813 | validation: 2.971675349605954]
	TIME [epoch: 5.74 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2330247589405117		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 1.2330247589405117 | validation: 2.969764496182545]
	TIME [epoch: 5.74 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2317314993715378		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 1.2317314993715378 | validation: 2.9700548192774647]
	TIME [epoch: 5.78 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.227969889950036		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 1.227969889950036 | validation: 2.9706997423890282]
	TIME [epoch: 5.74 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2294779567092782		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 1.2294779567092782 | validation: 2.974164972381302]
	TIME [epoch: 5.74 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23015472592322		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 1.23015472592322 | validation: 2.9711267233277874]
	TIME [epoch: 5.74 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2289676328300436		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 1.2289676328300436 | validation: 2.9693389219180073]
	TIME [epoch: 5.74 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2308518375605384		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 1.2308518375605384 | validation: 2.960325788856121]
	TIME [epoch: 5.74 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233282929495433		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 1.233282929495433 | validation: 2.970831041842274]
	TIME [epoch: 5.75 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230680288984563		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 1.230680288984563 | validation: 2.9693152388904394]
	TIME [epoch: 5.76 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306022282433522		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 1.2306022282433522 | validation: 2.9679220775460293]
	TIME [epoch: 5.74 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2310590140208504		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 1.2310590140208504 | validation: 2.971620519160021]
	TIME [epoch: 5.74 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2278423815001873		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 1.2278423815001873 | validation: 2.970661202566411]
	TIME [epoch: 5.75 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2301225978084376		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 1.2301225978084376 | validation: 2.9567325933966804]
	TIME [epoch: 5.74 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2295008127952383		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 1.2295008127952383 | validation: 2.969893061385427]
	TIME [epoch: 5.74 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2311912846423774		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 1.2311912846423774 | validation: 2.961875413672758]
	TIME [epoch: 5.78 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2296258219906953		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 1.2296258219906953 | validation: 2.9743322209649428]
	TIME [epoch: 5.74 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2273113389825168		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 1.2273113389825168 | validation: 2.9648392024262358]
	TIME [epoch: 5.74 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285414206291847		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 1.2285414206291847 | validation: 2.971436076075355]
	TIME [epoch: 5.74 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233431119791222		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 1.233431119791222 | validation: 2.970436514041561]
	TIME [epoch: 5.73 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.226148627904146		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 1.226148627904146 | validation: 2.975367010219781]
	TIME [epoch: 5.74 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229788422903993		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 1.229788422903993 | validation: 2.972325978894287]
	TIME [epoch: 5.77 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306609003565887		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 1.2306609003565887 | validation: 2.970890715637235]
	TIME [epoch: 5.76 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2303342485634305		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 1.2303342485634305 | validation: 2.9693697990937653]
	TIME [epoch: 5.74 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2284207991072633		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 1.2284207991072633 | validation: 2.9687754191886313]
	TIME [epoch: 5.74 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231814320262635		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 1.231814320262635 | validation: 2.9668729759944474]
	TIME [epoch: 5.75 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2286748060514678		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 1.2286748060514678 | validation: 2.968590974659311]
	TIME [epoch: 5.74 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228051276889648		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 1.228051276889648 | validation: 2.9689047472949404]
	TIME [epoch: 5.73 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2323725994347265		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 1.2323725994347265 | validation: 2.970427739420135]
	TIME [epoch: 5.78 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2328384294322103		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 1.2328384294322103 | validation: 2.971775246387409]
	TIME [epoch: 5.73 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2278189303930196		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 1.2278189303930196 | validation: 2.9663278968574778]
	TIME [epoch: 5.75 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2303382945882404		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 1.2303382945882404 | validation: 2.968710913784164]
	TIME [epoch: 5.74 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2286580357305978		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 1.2286580357305978 | validation: 2.969794844123918]
	TIME [epoch: 5.74 sec]
Finished training in 11707.819 seconds.
