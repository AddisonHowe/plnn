Args:
Namespace(name='model_tr_study203', outdir='out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1', training_data='data/transition_rate_studies/tr_study203/tr_study203_training/r1', validation_data='data/transition_rate_studies/tr_study203/tr_study203_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3015305408

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.585429272284289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.585429272284289 | validation: 13.038056884009032]
	TIME [epoch: 99.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.660305461880734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.660305461880734 | validation: 11.821099141169446]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.176450887162432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.176450887162432 | validation: 11.796320097236427]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.304875779573486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.304875779573486 | validation: 9.077255245262897]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.52542070924553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.52542070924553 | validation: 8.622950365771176]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.380993347715395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.380993347715395 | validation: 6.391703671786989]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.212519037960032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.212519037960032 | validation: 5.853678890321049]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.390178901250108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.390178901250108 | validation: 8.19296188892056]
	TIME [epoch: 11.5 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.397533313715112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.397533313715112 | validation: 5.686975905414614]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.921853705841059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.921853705841059 | validation: 5.39338023996786]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7873563114714255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7873563114714255 | validation: 5.701758545771759]
	TIME [epoch: 11.5 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6067277636096815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6067277636096815 | validation: 5.634791006259596]
	TIME [epoch: 11.5 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.22480798352184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.22480798352184 | validation: 5.8959721483626755]
	TIME [epoch: 11.5 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.71858562918435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.71858562918435 | validation: 5.9509723271901995]
	TIME [epoch: 11.5 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.329968852481883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.329968852481883 | validation: 5.961697065275189]
	TIME [epoch: 11.5 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3269587356568895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3269587356568895 | validation: 5.544964967059075]
	TIME [epoch: 11.5 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.322403114624495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.322403114624495 | validation: 5.452769997078758]
	TIME [epoch: 11.5 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1530840137794005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1530840137794005 | validation: 7.6565890497290185]
	TIME [epoch: 11.5 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.881668032505036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.881668032505036 | validation: 5.853273463081324]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.19384324953691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.19384324953691 | validation: 6.361810786707377]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.523978774344634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.523978774344634 | validation: 5.0369838768502175]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.256576366154182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.256576366154182 | validation: 5.16335654457839]
	TIME [epoch: 11.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.143923178839326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.143923178839326 | validation: 4.913000875017302]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7344623593045214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7344623593045214 | validation: 5.811986767938031]
	TIME [epoch: 11.5 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.168921549373541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.168921549373541 | validation: 5.141946169460782]
	TIME [epoch: 11.5 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.182184136489412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.182184136489412 | validation: 5.2187710113304]
	TIME [epoch: 11.5 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.80731022023119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.80731022023119 | validation: 5.8954232094886345]
	TIME [epoch: 11.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.190469040502161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.190469040502161 | validation: 4.954460445114847]
	TIME [epoch: 11.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8524833678574932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8524833678574932 | validation: 4.84398854190309]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.871895278873095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.871895278873095 | validation: 5.3278092284153855]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.97803808130677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.97803808130677 | validation: 4.777965637038245]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.934791097863028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.934791097863028 | validation: 4.598469327615333]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.026992004294179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.026992004294179 | validation: 5.036319257473465]
	TIME [epoch: 11.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9236496285755527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9236496285755527 | validation: 4.9812898833879]
	TIME [epoch: 11.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6838145275400422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6838145275400422 | validation: 4.64266955595467]
	TIME [epoch: 11.5 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.615644079057407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.615644079057407 | validation: 6.024815549629969]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.729996558840215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.729996558840215 | validation: 4.942763596790989]
	TIME [epoch: 11.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.047990530437408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.047990530437408 | validation: 5.251522457354831]
	TIME [epoch: 11.5 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6491823875531697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6491823875531697 | validation: 4.80114652592051]
	TIME [epoch: 11.5 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6762386591176606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6762386591176606 | validation: 4.978626226492751]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.672668338940337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.672668338940337 | validation: 4.655863108849508]
	TIME [epoch: 11.5 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39013108670405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.39013108670405 | validation: 5.77523786830403]
	TIME [epoch: 11.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7062639719205404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7062639719205404 | validation: 4.729375354365441]
	TIME [epoch: 11.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.676605431677868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.676605431677868 | validation: 4.8269471757485]
	TIME [epoch: 11.5 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.557485445937141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.557485445937141 | validation: 4.719753922598577]
	TIME [epoch: 11.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5545135239461123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5545135239461123 | validation: 5.087386157034605]
	TIME [epoch: 11.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.488199715142643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.488199715142643 | validation: 5.090037204493475]
	TIME [epoch: 11.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6747925974079703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6747925974079703 | validation: 4.886332678403127]
	TIME [epoch: 11.5 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5699023643119148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5699023643119148 | validation: 4.811594800585413]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.622426157019846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.622426157019846 | validation: 4.6777869621618855]
	TIME [epoch: 11.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.537466934379018		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.537466934379018 | validation: 4.539094900969032]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.496747435985621		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.496747435985621 | validation: 4.606649606550651]
	TIME [epoch: 11.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.081401602726572		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.081401602726572 | validation: 4.325869551403326]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3625514335453213		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.3625514335453213 | validation: 4.492011213944785]
	TIME [epoch: 11.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.398936916838562		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.398936916838562 | validation: 4.876304793495725]
	TIME [epoch: 11.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4404521640854817		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.4404521640854817 | validation: 4.708617878164629]
	TIME [epoch: 11.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3390228937739694		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.3390228937739694 | validation: 4.804625617983574]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1934734723227405		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.1934734723227405 | validation: 5.160527873912253]
	TIME [epoch: 11.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.617975793112393		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.617975793112393 | validation: 4.319988347361778]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3228919081674473		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.3228919081674473 | validation: 4.348803283428201]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.248658851175367		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.248658851175367 | validation: 5.869721517116943]
	TIME [epoch: 11.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4460858458699843		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.4460858458699843 | validation: 5.269545177759324]
	TIME [epoch: 11.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2577420796664667		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.2577420796664667 | validation: 5.3076341460969365]
	TIME [epoch: 11.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.973528586192558		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.973528586192558 | validation: 4.74035781344586]
	TIME [epoch: 11.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.244635226859714		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.244635226859714 | validation: 5.921695818981041]
	TIME [epoch: 11.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.457022001075032		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.457022001075032 | validation: 5.243991523255688]
	TIME [epoch: 11.5 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3799966644301014		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.3799966644301014 | validation: 5.330956418321068]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.610141496149897		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.610141496149897 | validation: 4.419411511457602]
	TIME [epoch: 11.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.138963984610518		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.138963984610518 | validation: 10.044102704042594]
	TIME [epoch: 11.5 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.758700059204466		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.758700059204466 | validation: 4.48968820618772]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.901253588681432		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.901253588681432 | validation: 4.150373898653768]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.340106839780208		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.340106839780208 | validation: 4.585102521696126]
	TIME [epoch: 11.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3069823271558887		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.3069823271558887 | validation: 4.574998200060217]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1727498795987215		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.1727498795987215 | validation: 4.530761626786783]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.165157040835428		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.165157040835428 | validation: 4.52445498952194]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0735035379044358		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.0735035379044358 | validation: 4.657301426522653]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.157860668004933		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.157860668004933 | validation: 4.716807684148921]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1434091292150526		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.1434091292150526 | validation: 4.111170652274893]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.452189137183465		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.452189137183465 | validation: 4.048401415230042]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9741381104312348		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.9741381104312348 | validation: 4.300323504611197]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.944580812383184		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.944580812383184 | validation: 4.573620002699737]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.075357661924307		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.075357661924307 | validation: 4.028806417203845]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8429586922427275		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.8429586922427275 | validation: 4.000018716949425]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9331901594134338		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.9331901594134338 | validation: 4.2992697218988445]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7916235524270605		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.7916235524270605 | validation: 3.992050117247535]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.126097834935992		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.126097834935992 | validation: 4.143755509627126]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8634279383554504		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.8634279383554504 | validation: 4.586205144440107]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9551780025094545		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.9551780025094545 | validation: 4.806504078634015]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8972089305805646		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.8972089305805646 | validation: 5.025315427448406]
	TIME [epoch: 11.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0030989055022097		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.0030989055022097 | validation: 4.337777601525001]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8067401167381556		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.8067401167381556 | validation: 4.820628296479576]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.89947590132262		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.89947590132262 | validation: 5.461633109482323]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7933907538220915		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.7933907538220915 | validation: 4.764983473978394]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.776974622554632		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.776974622554632 | validation: 4.550485826047637]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0651323049336527		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.0651323049336527 | validation: 4.3095996672166335]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.828924844060996		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.828924844060996 | validation: 4.4644610590258385]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7899910325046777		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.7899910325046777 | validation: 4.520606520760024]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6876238980058167		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.6876238980058167 | validation: 3.963590641015117]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8899147434416306		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.8899147434416306 | validation: 4.572467875647426]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.870686460267472		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.870686460267472 | validation: 4.237809493433101]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6193894831116644		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.6193894831116644 | validation: 4.0398643232214315]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.867884437747465		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.867884437747465 | validation: 3.8719992818107665]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6456184196433474		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.6456184196433474 | validation: 4.379842513179983]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6098300469778044		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.6098300469778044 | validation: 4.019674279936595]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.634520008783387		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.634520008783387 | validation: 4.155711654411782]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.578390277575168		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.578390277575168 | validation: 4.448026155516493]
	TIME [epoch: 11.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8193140969134283		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.8193140969134283 | validation: 3.6529078994236226]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.549661537250147		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.549661537250147 | validation: 4.047745187407804]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.495354946959007		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.495354946959007 | validation: 4.039397693362514]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5851823968710486		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.5851823968710486 | validation: 3.9181189888890446]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4435234975535245		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.4435234975535245 | validation: 3.671150759998681]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.48221808600241		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.48221808600241 | validation: 4.326365445734707]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5654747756815923		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.5654747756815923 | validation: 4.350071471803328]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5490183402081374		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.5490183402081374 | validation: 3.936495084915872]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4161422294250037		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.4161422294250037 | validation: 3.550168958228239]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6941978657907457		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.6941978657907457 | validation: 3.825311075859693]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5348771701197754		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.5348771701197754 | validation: 3.8990930717818397]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.362817234867612		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.362817234867612 | validation: 3.867546848793076]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4861609692166344		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.4861609692166344 | validation: 3.669698802088119]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.443333896885484		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.443333896885484 | validation: 4.029521268752334]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3786028533512003		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.3786028533512003 | validation: 3.75819665905975]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299288671452883		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.299288671452883 | validation: 3.678742152005965]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2474702889865004		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.2474702889865004 | validation: 5.1438102639869845]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7851161446430877		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.7851161446430877 | validation: 3.7649817357529374]
	TIME [epoch: 11.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3479284658640482		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.3479284658640482 | validation: 4.71460437761392]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.639728292756195		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.639728292756195 | validation: 3.673424947186334]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1612702579505463		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.1612702579505463 | validation: 3.625422859538223]
	TIME [epoch: 11.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.178959395514829		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.178959395514829 | validation: 3.893364264585882]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7048734055829535		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.7048734055829535 | validation: 3.633443206672753]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450911685410712		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.450911685410712 | validation: 4.171480139145023]
	TIME [epoch: 11.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4459223038375		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.4459223038375 | validation: 3.8833388113705607]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2328029112874015		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.2328029112874015 | validation: 4.078149723589959]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.39875742862104		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.39875742862104 | validation: 3.880104528644198]
	TIME [epoch: 11.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3352832896971387		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.3352832896971387 | validation: 3.7807913648056677]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2539122534579175		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.2539122534579175 | validation: 4.008465538125286]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3946628247099504		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.3946628247099504 | validation: 3.5396991854745354]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1231073603051787		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.1231073603051787 | validation: 3.5967819853092]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.380841044474603		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.380841044474603 | validation: 4.662643039764363]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.529778961579826		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.529778961579826 | validation: 3.6961360485973693]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1864030428028483		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.1864030428028483 | validation: 3.859452558315195]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328453947618668		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.328453947618668 | validation: 4.457772945408717]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3777284842805795		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.3777284842805795 | validation: 3.663710366755904]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3026872896370634		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.3026872896370634 | validation: 4.493529094616863]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325665671615028		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.325665671615028 | validation: 8.743877880585515]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.607238368738983		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 5.607238368738983 | validation: 5.279173192022354]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.757170915003015		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.757170915003015 | validation: 3.419124795965044]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2177929316631895		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.2177929316631895 | validation: 3.632734892835297]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0346738640588624		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 2.0346738640588624 | validation: 3.521734639348569]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.070794865033478		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.070794865033478 | validation: 3.7739778538608055]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3313275300024374		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.3313275300024374 | validation: 3.4756374935183936]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3248714903046266		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.3248714903046266 | validation: 3.543029420702708]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9657201512944278		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.9657201512944278 | validation: 3.5997936618930475]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.940330989461147		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.940330989461147 | validation: 4.77146438692819]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.416314263952552		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.416314263952552 | validation: 3.485077132294991]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.035801153029748		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.035801153029748 | validation: 3.481764001650337]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1786204823772284		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.1786204823772284 | validation: 4.092730285433119]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3541597038755926		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.3541597038755926 | validation: 3.3115004041336142]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9165823038532999		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.9165823038532999 | validation: 3.4455681030507606]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1478029170731774		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.1478029170731774 | validation: 4.346498707957892]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2300288452842985		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.2300288452842985 | validation: 3.49727848886042]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9680660802996774		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.9680660802996774 | validation: 3.5815524484344614]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.874714815514756		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.874714815514756 | validation: 3.454786388519929]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7998141371240113		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.7998141371240113 | validation: 5.3669279722785]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5246828228203695		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.5246828228203695 | validation: 3.33572169320423]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.832855639292163		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.832855639292163 | validation: 3.7707335665878325]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.027426088629621		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.027426088629621 | validation: 3.2175235041279233]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1784919132130485		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.1784919132130485 | validation: 3.4844996919675144]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.142882490482481		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.142882490482481 | validation: 3.5602572466992104]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9546516466388202		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.9546516466388202 | validation: 5.534602739246156]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8251154830132426		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.8251154830132426 | validation: 3.3953637957293603]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0323417648683666		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.0323417648683666 | validation: 6.050309656027236]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.976217399390773		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.976217399390773 | validation: 3.6206264145820994]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.128914167253959		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.128914167253959 | validation: 3.726609696058875]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8860174213512841		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.8860174213512841 | validation: 3.452524570150416]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057532155996079		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.057532155996079 | validation: 3.2592101132546545]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9186979354831442		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.9186979354831442 | validation: 3.7528053129036745]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8953894792190986		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.8953894792190986 | validation: 3.250920571667956]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.134763582009687		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.134763582009687 | validation: 3.2292581444014785]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8807710331304803		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.8807710331304803 | validation: 3.52323132801359]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.598340561720777		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.598340561720777 | validation: 3.5321820246551296]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6939162766713944		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.6939162766713944 | validation: 3.8282772396988776]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2619058779793284		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.2619058779793284 | validation: 3.2139002843898026]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.669666370074932		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.669666370074932 | validation: 3.525872320764352]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.187752044130386		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.187752044130386 | validation: 3.835643817354172]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9925015765670722		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.9925015765670722 | validation: 3.4201815668733047]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9447903714397263		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.9447903714397263 | validation: 3.4382202450109767]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9567849667254968		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.9567849667254968 | validation: 3.921637253540008]
	TIME [epoch: 11.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9500588624946105		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.9500588624946105 | validation: 3.872144827358034]
	TIME [epoch: 11.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8822642450170364		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.8822642450170364 | validation: 3.3472766537977163]
	TIME [epoch: 11.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9229824705591239		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.9229824705591239 | validation: 3.4637002717398717]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269139300631839		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.269139300631839 | validation: 3.1222884216664077]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.029640620316044		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 3.029640620316044 | validation: 3.431354529000826]
	TIME [epoch: 11.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.455013126217488		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.455013126217488 | validation: 3.7759922715684935]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273870799029317		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.273870799029317 | validation: 3.2905967267055236]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.008394925726079		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.008394925726079 | validation: 3.20152277833197]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0043408831439113		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.0043408831439113 | validation: 3.3099487062702737]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3759816291005937		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.3759816291005937 | validation: 3.3291351031128227]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086039405991122		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.086039405991122 | validation: 3.2154408043718186]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9996769886924264		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.9996769886924264 | validation: 3.32174838695251]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8605192427033372		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.8605192427033372 | validation: 3.601499092802518]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.908138703523064		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.908138703523064 | validation: 3.5219489884346604]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7884033408746145		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.7884033408746145 | validation: 3.4339179831005104]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7933462360972594		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.7933462360972594 | validation: 3.196798784759485]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.905209492084059		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.905209492084059 | validation: 3.5735467068239166]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8702245166499818		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.8702245166499818 | validation: 3.4882591075824645]
	TIME [epoch: 11.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7811240510377226		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.7811240510377226 | validation: 3.523646552683748]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9263574789176652		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.9263574789176652 | validation: 3.3213660907859834]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9130625807124018		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.9130625807124018 | validation: 4.2294881646591005]
	TIME [epoch: 11.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.21545636958226		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.21545636958226 | validation: 4.422576658818531]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3802615362263366		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.3802615362263366 | validation: 4.5923609724892005]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1610537779569445		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.1610537779569445 | validation: 4.7284143221987796]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.452338713529171		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.452338713529171 | validation: 4.394305533534201]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0566380411499554		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.0566380411499554 | validation: 4.162287725925273]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0942492719431485		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.0942492719431485 | validation: 3.326058731927611]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8727625221748165		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.8727625221748165 | validation: 3.362203689113295]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7984176175329512		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.7984176175329512 | validation: 3.3227945423567324]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7856090947285215		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.7856090947285215 | validation: 3.2028904252461317]
	TIME [epoch: 11.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7742838878646991		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.7742838878646991 | validation: 3.5959134348453228]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8403808956382726		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.8403808956382726 | validation: 3.788193711481698]
	TIME [epoch: 11.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.786342953458332		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.786342953458332 | validation: 3.354708499384342]
	TIME [epoch: 11.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.840465569296513		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.840465569296513 | validation: 3.36367117747444]
	TIME [epoch: 11.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8167600816412368		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.8167600816412368 | validation: 3.7359392031102527]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.867250711861839		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.867250711861839 | validation: 3.7529202738994263]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8343695846641137		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.8343695846641137 | validation: 3.543681038467588]
	TIME [epoch: 11.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7543484552913076		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.7543484552913076 | validation: 3.1025905398881446]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.752558572648406		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.752558572648406 | validation: 4.009375650322965]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.203451915885511		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.203451915885511 | validation: 4.538300909100099]
	TIME [epoch: 11.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1343194458272654		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.1343194458272654 | validation: 4.282882941913505]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1774340340363514		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.1774340340363514 | validation: 3.1582706050748364]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9979741558506507		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.9979741558506507 | validation: 3.185912270725788]
	TIME [epoch: 11.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.755096131221083		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.755096131221083 | validation: 3.5970039574447226]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.918746630501378		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.918746630501378 | validation: 3.6290569715746255]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7889836929381788		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.7889836929381788 | validation: 3.339788888821832]
	TIME [epoch: 11.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7192979134266249		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.7192979134266249 | validation: 3.381674191801334]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6517416648535308		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.6517416648535308 | validation: 3.3241200618131166]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.169243776824326		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 2.169243776824326 | validation: 4.5098409401097]
	TIME [epoch: 11.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.156457709742582		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.156457709742582 | validation: 4.024611090294355]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.87101240795171		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.87101240795171 | validation: 3.7962532085371072]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.749346747027988		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.749346747027988 | validation: 3.2750338322787322]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.815497208593774		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.815497208593774 | validation: 3.1833522680774218]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6461339026967285		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.6461339026967285 | validation: 3.205564589828232]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6572150619267365		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.6572150619267365 | validation: 4.013890229430401]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9969881915686527		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.9969881915686527 | validation: 3.7824173719706677]
	TIME [epoch: 11.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8709861774542609		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.8709861774542609 | validation: 3.38971748809632]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6745662072271879		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.6745662072271879 | validation: 3.376118633826896]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7682261098045924		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.7682261098045924 | validation: 3.2510605926917955]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6956312892344303		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.6956312892344303 | validation: 3.2605862651677135]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7254797540762281		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.7254797540762281 | validation: 3.222498048060409]
	TIME [epoch: 11.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7055280046114312		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.7055280046114312 | validation: 3.3471442482910225]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.771102507747058		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.771102507747058 | validation: 3.313152013563561]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8289661641047656		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.8289661641047656 | validation: 3.2533508824391975]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8782442883176271		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.8782442883176271 | validation: 4.330188013465068]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0962240500220934		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 2.0962240500220934 | validation: 4.131634171484331]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0339693860956753		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.0339693860956753 | validation: 4.064369723673921]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0019648717764778		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.0019648717764778 | validation: 3.8357196441267822]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8711666581308837		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.8711666581308837 | validation: 3.5855944325716953]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.773097986070486		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.773097986070486 | validation: 3.427297413474925]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.81729264956548		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.81729264956548 | validation: 3.2000657102305357]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6661865997531835		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.6661865997531835 | validation: 3.352321245917367]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6794215821980747		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.6794215821980747 | validation: 3.74511818726089]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3113936961906725		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.3113936961906725 | validation: 4.319095647295141]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0577266274924093		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 2.0577266274924093 | validation: 3.373713050881321]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6606712197633078		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.6606712197633078 | validation: 3.073548721967528]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6175135825691442		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.6175135825691442 | validation: 3.3381427350678496]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6566096479811443		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.6566096479811443 | validation: 3.728929536243464]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7908684977508362		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.7908684977508362 | validation: 3.372569759797997]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5766639063734784		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.5766639063734784 | validation: 3.2746390126542515]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6050451075579686		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.6050451075579686 | validation: 3.4592556999536885]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6683596549172384		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.6683596549172384 | validation: 3.5310990344352464]
	TIME [epoch: 11.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.646158219522205		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.646158219522205 | validation: 3.1305182043856674]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5554587471138264		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.5554587471138264 | validation: 3.1559862404115058]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.724728000762584		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.724728000762584 | validation: 3.039029572716732]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_272.pth
	Model improved!!!
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4970572291235271		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.4970572291235271 | validation: 3.2209196233491366]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5053890377890087		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.5053890377890087 | validation: 3.1348282751612135]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4834381537071866		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.4834381537071866 | validation: 3.559432078829871]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.744284376541937		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.744284376541937 | validation: 3.3617104635185853]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5401222161860988		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.5401222161860988 | validation: 3.5224813215836552]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7033648687659761		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.7033648687659761 | validation: 3.4076435708107176]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6579228213210362		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.6579228213210362 | validation: 3.288085936796638]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5785601919501424		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.5785601919501424 | validation: 3.072533245513032]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5627967237698672		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.5627967237698672 | validation: 3.1987207493100596]
	TIME [epoch: 11.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7898280832678835		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.7898280832678835 | validation: 3.455151493133248]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.709280414299673		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.709280414299673 | validation: 3.3013544566470547]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.630789226240342		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.630789226240342 | validation: 3.5950312842074084]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.750614428312134		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.750614428312134 | validation: 3.0443900096591756]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6117361602109783		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.6117361602109783 | validation: 3.02304071046643]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4746067508984726		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.4746067508984726 | validation: 3.113862679041071]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.686952123432698		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.686952123432698 | validation: 3.053744503730444]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4919533970274212		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.4919533970274212 | validation: 3.420516657710568]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5861989327434565		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.5861989327434565 | validation: 3.284133300957718]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6564581327299792		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.6564581327299792 | validation: 3.2938943610239155]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6222553682194407		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.6222553682194407 | validation: 3.2008922615870405]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.573451628401979		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.573451628401979 | validation: 3.079089058891799]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5323720685610225		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.5323720685610225 | validation: 3.0843718425225872]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5120857936502055		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.5120857936502055 | validation: 3.820445144724115]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8584080704759098		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.8584080704759098 | validation: 3.711605067347908]
	TIME [epoch: 11.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.681467900120008		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.681467900120008 | validation: 3.1039165472117]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.549022016838943		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.549022016838943 | validation: 3.1481776520458293]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5117176620359507		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.5117176620359507 | validation: 4.7636733051717455]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242547101084395		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 2.242547101084395 | validation: 3.68523920159367]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.711090682721887		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.711090682721887 | validation: 3.045224070736472]
	TIME [epoch: 11.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6262770964941728		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.6262770964941728 | validation: 3.08626686368989]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4563458775758922		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.4563458775758922 | validation: 3.934441280311485]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8058419401533223		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.8058419401533223 | validation: 3.0364498958797412]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7563702587734604		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.7563702587734604 | validation: 3.23562817262925]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9503295299388506		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.9503295299388506 | validation: 3.3782393072028256]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5318906095796185		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.5318906095796185 | validation: 3.2338625054323926]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.54369687906028		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.54369687906028 | validation: 3.370271928235807]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5404617189437129		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.5404617189437129 | validation: 3.0066128001815504]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_309.pth
	Model improved!!!
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5360673326782286		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.5360673326782286 | validation: 3.2187406306425066]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5394958316224003		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.5394958316224003 | validation: 3.170324805997834]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.584995413619462		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.584995413619462 | validation: 3.08811357377645]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7575486695376394		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.7575486695376394 | validation: 3.7203932288501074]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.869091138721767		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.869091138721767 | validation: 3.758597604244782]
	TIME [epoch: 11.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9146590895591191		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.9146590895591191 | validation: 3.06255739475855]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8035778354452214		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.8035778354452214 | validation: 3.094972311044304]
	TIME [epoch: 11.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8852724143676691		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.8852724143676691 | validation: 3.542554598409931]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.767404498600096		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.767404498600096 | validation: 3.471354908359263]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6834539502003758		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.6834539502003758 | validation: 3.012937855715496]
	TIME [epoch: 11.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7736990762457705		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.7736990762457705 | validation: 3.1589623408894134]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.745314493711961		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.745314493711961 | validation: 3.0377178479551006]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5181379120497265		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.5181379120497265 | validation: 3.5562955537718564]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.609774982859029		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.609774982859029 | validation: 3.0116337470221666]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.571944391660978		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.571944391660978 | validation: 3.0072190607837705]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6079739181497135		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.6079739181497135 | validation: 3.1834971010550652]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9868578667451078		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.9868578667451078 | validation: 3.2233752161609277]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6667292698962852		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.6667292698962852 | validation: 3.0038728832344255]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4482003623609137		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.4482003623609137 | validation: 3.394676619180881]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6863122790837926		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.6863122790837926 | validation: 3.845267639048024]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6736550272914772		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.6736550272914772 | validation: 3.7024005864609784]
	TIME [epoch: 11.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8511918240955445		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.8511918240955445 | validation: 3.6590360563869844]
	TIME [epoch: 11.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.763547960497988		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.763547960497988 | validation: 3.293700296277797]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.635362851425144		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.635362851425144 | validation: 3.4955763106676567]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6895980597043823		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.6895980597043823 | validation: 3.329752640273227]
	TIME [epoch: 11.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5807200249619944		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.5807200249619944 | validation: 3.2351046811854616]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5721791269906116		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.5721791269906116 | validation: 3.35433909823284]
	TIME [epoch: 11.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7417273854740007		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.7417273854740007 | validation: 3.1511005918213186]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5115717915775637		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.5115717915775637 | validation: 3.0529535217819324]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4269154845182754		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.4269154845182754 | validation: 3.2014206205491904]
	TIME [epoch: 11.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.786360945221668		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.786360945221668 | validation: 3.1273678912339236]
	TIME [epoch: 11.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.869113528521097		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.869113528521097 | validation: 3.045874413164504]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4750889024814948		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.4750889024814948 | validation: 3.0791001331950874]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5113810058084758		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.5113810058084758 | validation: 3.0142942317706094]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4546708166930384		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.4546708166930384 | validation: 3.152602481039919]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7065408216644073		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.7065408216644073 | validation: 3.177067876567838]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9616353492217549		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.9616353492217549 | validation: 3.257455585882783]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6435097983234472		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.6435097983234472 | validation: 3.1561561317878772]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.489978751637837		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.489978751637837 | validation: 3.676077900615125]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6986617094890133		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.6986617094890133 | validation: 3.7936711220218133]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.76309903680584		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.76309903680584 | validation: 3.3545782360278986]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.608060512932011		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.608060512932011 | validation: 3.117321488273511]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4821018454926174		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.4821018454926174 | validation: 3.215874585005979]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5096988454116664		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.5096988454116664 | validation: 3.112925438127669]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5111333353558203		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.5111333353558203 | validation: 3.1458357189382076]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.430510205358397		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.430510205358397 | validation: 3.3504203035185083]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4940721193098527		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.4940721193098527 | validation: 3.184335684878631]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4719367200926725		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.4719367200926725 | validation: 3.160081018397417]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4469946178136586		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.4469946178136586 | validation: 3.0234048765509978]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4103013767581596		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.4103013767581596 | validation: 2.978638935493627]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_359.pth
	Model improved!!!
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4380357357148155		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.4380357357148155 | validation: 3.071561035594291]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5049124949285853		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.5049124949285853 | validation: 3.2384852995058724]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4938111126438884		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.4938111126438884 | validation: 3.0258193129667066]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5108365512350972		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.5108365512350972 | validation: 3.1150980983333216]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4493469747427015		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.4493469747427015 | validation: 3.0288039802141213]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.382928536279346		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.382928536279346 | validation: 3.0822627419171424]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4598955481528075		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.4598955481528075 | validation: 3.3300052735600083]
	TIME [epoch: 11.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.445733882308402		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.445733882308402 | validation: 3.071151156963765]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4991005049834925		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.4991005049834925 | validation: 2.9804882902706904]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3610106936555983		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.3610106936555983 | validation: 3.1057055185470688]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4601638684507177		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.4601638684507177 | validation: 2.9942874956405428]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.555923343544767		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.555923343544767 | validation: 3.0089634012678035]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.460672040352436		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.460672040352436 | validation: 3.1427402713741506]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.609575460135765		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.609575460135765 | validation: 2.947464644677366]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9678770030916364		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.9678770030916364 | validation: 4.031993929312463]
	TIME [epoch: 11.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.680229149223791		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.680229149223791 | validation: 3.0207330432404933]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4122733193453187		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.4122733193453187 | validation: 3.2595053664598415]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.43923311590286		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.43923311590286 | validation: 3.0615377390585468]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3790031931737583		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.3790031931737583 | validation: 3.3745909763285806]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5234694103546973		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.5234694103546973 | validation: 3.0152241338693835]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.459603455868066		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.459603455868066 | validation: 2.988421030179661]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3668300634011		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.3668300634011 | validation: 3.053877284459326]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3799438861940843		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.3799438861940843 | validation: 2.9929851422944354]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4538142845767008		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.4538142845767008 | validation: 3.426472397632255]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5157749365449735		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.5157749365449735 | validation: 3.344142416164534]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.433921368108459		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.433921368108459 | validation: 3.1997835185298955]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4629247294700551		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.4629247294700551 | validation: 3.22547051737342]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.44174867402523		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.44174867402523 | validation: 3.301567520801431]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.520775061219138		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.520775061219138 | validation: 2.9558346759170497]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4449903542043199		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.4449903542043199 | validation: 3.0183138711826087]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3719847821265327		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.3719847821265327 | validation: 3.272762243127861]
	TIME [epoch: 11.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4495166674022686		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.4495166674022686 | validation: 3.0856520160664407]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3717978052971789		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.3717978052971789 | validation: 2.9951462918870413]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4570672935733437		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.4570672935733437 | validation: 3.076237523956535]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5212737831848908		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.5212737831848908 | validation: 3.0160946352732756]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4122122333558838		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.4122122333558838 | validation: 3.0822927485206697]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5627253783829733		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.5627253783829733 | validation: 2.9367242346600357]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.384692584050389		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.384692584050389 | validation: 3.0252750468381806]
	TIME [epoch: 11.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3699783083107713		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.3699783083107713 | validation: 3.201765355842758]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4001807989166122		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.4001807989166122 | validation: 3.2831259467986356]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.364692042033583		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.364692042033583 | validation: 3.3147802139325018]
	TIME [epoch: 11.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.457350785054044		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.457350785054044 | validation: 3.324958364996472]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8223636880016576		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.8223636880016576 | validation: 3.5255982687464225]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5556522316362102		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.5556522316362102 | validation: 3.0645630891090376]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3703607077660873		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.3703607077660873 | validation: 3.4013081731853685]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6182360519187133		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.6182360519187133 | validation: 3.82954284059236]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7562445977575454		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.7562445977575454 | validation: 3.091314279187539]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4177960247042314		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.4177960247042314 | validation: 2.9496613768636974]
	TIME [epoch: 11.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.433944581894216		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.433944581894216 | validation: 3.1096386116511874]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3716245184422284		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.3716245184422284 | validation: 3.08773192668753]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.362061869444518		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.362061869444518 | validation: 3.2127661313218887]
	TIME [epoch: 11.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3441723048957135		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.3441723048957135 | validation: 3.263220236792441]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5607265420093575		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.5607265420093575 | validation: 2.9416445730480656]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2850783483219164		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.2850783483219164 | validation: 3.15721491959066]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3617392872186294		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.3617392872186294 | validation: 3.1382762587326005]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.484605410099631		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.484605410099631 | validation: 3.442260196359283]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9230215476400585		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.9230215476400585 | validation: 3.009645638443125]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7839332827078813		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.7839332827078813 | validation: 3.0279499384019553]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4706969294390995		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.4706969294390995 | validation: 3.1096282484838573]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.325815371359141		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.325815371359141 | validation: 2.9225303244209218]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4144941662753834		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.4144941662753834 | validation: 3.118557203698604]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.381476895448339		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.381476895448339 | validation: 3.1996852803933553]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4121374087570722		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.4121374087570722 | validation: 2.931792144561681]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3884446729634008		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.3884446729634008 | validation: 2.95070040333797]
	TIME [epoch: 11.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3350269013118503		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.3350269013118503 | validation: 2.935679434336421]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5648314917339121		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.5648314917339121 | validation: 3.027077736562074]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3774132228977936		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.3774132228977936 | validation: 2.9121605176453587]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4355059721330887		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.4355059721330887 | validation: 3.2020200749607133]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4140910496808474		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.4140910496808474 | validation: 3.003661994341399]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4141795754839996		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.4141795754839996 | validation: 2.955989260120482]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3755600813349462		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.3755600813349462 | validation: 3.9871823908951614]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8249420975362587		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.8249420975362587 | validation: 3.0350462031059404]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3774787747774977		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.3774787747774977 | validation: 2.9998967997096533]
	TIME [epoch: 11.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3304279624823878		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.3304279624823878 | validation: 3.247677759779818]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5082431131512544		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.5082431131512544 | validation: 3.026553255904046]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2854985914811996		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.2854985914811996 | validation: 2.976176159431257]
	TIME [epoch: 11.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2438788004625319		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.2438788004625319 | validation: 2.970424026632004]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4173025920583637		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.4173025920583637 | validation: 3.036187023416477]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3133130618214903		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.3133130618214903 | validation: 3.254252442066157]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4768016868438214		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.4768016868438214 | validation: 2.9116755432570893]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5084690273839625		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.5084690273839625 | validation: 3.0009788033168254]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3490564394792686		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.3490564394792686 | validation: 3.019124496839856]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.386481770139216		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.386481770139216 | validation: 3.0698298972584115]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3683714551697648		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.3683714551697648 | validation: 3.2044721794354203]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3890317900599236		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.3890317900599236 | validation: 2.9306514856561625]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4198965968256412		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.4198965968256412 | validation: 2.977487265764068]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3520807659594771		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.3520807659594771 | validation: 2.913233147506643]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2979850503066972		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.2979850503066972 | validation: 2.999015206580021]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.383856494461658		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.383856494461658 | validation: 3.0799951139052086]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4002013782024563		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.4002013782024563 | validation: 2.916239575110404]
	TIME [epoch: 11.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4027567969121573		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.4027567969121573 | validation: 3.0124304728487146]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.476017938537335		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.476017938537335 | validation: 2.8944624669098453]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_451.pth
	Model improved!!!
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.359315011309218		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.359315011309218 | validation: 3.1475997664171054]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3056642704520318		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.3056642704520318 | validation: 2.9251641483420734]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3485578789559096		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.3485578789559096 | validation: 2.905486947575765]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5288567259161967		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.5288567259161967 | validation: 3.0558540712525555]
	TIME [epoch: 11.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.444374954135084		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.444374954135084 | validation: 2.955961978467201]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4528220852865374		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.4528220852865374 | validation: 2.9551189384653993]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3614514137009406		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.3614514137009406 | validation: 2.9274872997807986]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.288767862945106		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.288767862945106 | validation: 3.1719160646959597]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3134347373957738		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.3134347373957738 | validation: 3.0449889942352137]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3204973134013354		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.3204973134013354 | validation: 2.906233102903679]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.283882074663346		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.283882074663346 | validation: 2.9163097247590897]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3066872928165199		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.3066872928165199 | validation: 2.9118841007329856]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3239918454469728		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.3239918454469728 | validation: 2.93526304333587]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4350940925248343		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.4350940925248343 | validation: 2.9404518112132463]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3824881312306005		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.3824881312306005 | validation: 2.9381245836728853]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3601418915048105		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.3601418915048105 | validation: 2.971166788115368]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2837733962410738		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.2837733962410738 | validation: 3.0136217114940838]
	TIME [epoch: 11.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3396434851229237		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.3396434851229237 | validation: 2.960839553469851]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3659821100954395		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.3659821100954395 | validation: 2.9504215177232767]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5166631504769437		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.5166631504769437 | validation: 3.08522861222567]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5251332722469364		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.5251332722469364 | validation: 2.9587679417559754]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4202761706394138		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.4202761706394138 | validation: 2.8931312456238287]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_473.pth
	Model improved!!!
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.351335030879575		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.351335030879575 | validation: 2.8936797655473487]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2833280938946179		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.2833280938946179 | validation: 3.1149674154390192]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3534549713612294		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.3534549713612294 | validation: 2.950978575437683]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3269940625312873		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.3269940625312873 | validation: 2.8777188464302017]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_477.pth
	Model improved!!!
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3247156602503805		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.3247156602503805 | validation: 3.3269345034289017]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5306536308656298		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.5306536308656298 | validation: 3.214578682014012]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3432110920230675		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.3432110920230675 | validation: 3.0254715017547973]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3368145368190527		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 1.3368145368190527 | validation: 2.9926163249359297]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3798935056638593		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 1.3798935056638593 | validation: 2.89105551146902]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4844495263792936		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.4844495263792936 | validation: 2.929471003634142]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.444509476256237		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.444509476256237 | validation: 2.979399745418998]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4408847932620945		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.4408847932620945 | validation: 2.9057408818155954]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2770528415127544		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.2770528415127544 | validation: 3.1163024127519714]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3636496817619044		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.3636496817619044 | validation: 2.9391903594130624]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3647840450782747		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.3647840450782747 | validation: 2.9344459804490772]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4644145420924963		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.4644145420924963 | validation: 3.192429273176943]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4491900326689244		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.4491900326689244 | validation: 2.9304341424384437]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.308870106306445		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.308870106306445 | validation: 2.908113378216859]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.324066169335266		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.324066169335266 | validation: 2.989968497247594]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3342672494899617		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.3342672494899617 | validation: 3.07841811549764]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2895872052692219		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.2895872052692219 | validation: 2.960164538862155]
	TIME [epoch: 11.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2994255516576616		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.2994255516576616 | validation: 2.9540208475618592]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3176745430666272		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 1.3176745430666272 | validation: 3.1548605804042857]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3252321221560708		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.3252321221560708 | validation: 2.953082706681856]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3823448955008382		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.3823448955008382 | validation: 2.8892512323903015]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3324516028085291		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.3324516028085291 | validation: 2.9141273979248297]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.250824999810832		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.250824999810832 | validation: 2.973372898947033]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3521985395297362		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.3521985395297362 | validation: 3.03899033116583]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2896173173081862		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.2896173173081862 | validation: 2.90427722920713]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.293902407835561		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.293902407835561 | validation: 3.0738955638168823]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3034303748764593		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 1.3034303748764593 | validation: 3.1172746400222597]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.304462109159184		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.304462109159184 | validation: 3.0343229601018145]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4123369341252006		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.4123369341252006 | validation: 2.9156707166182425]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.251576475632952		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.251576475632952 | validation: 2.921291916856045]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3030786196326445		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.3030786196326445 | validation: 3.2065513829663788]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3132264979886363		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.3132264979886363 | validation: 3.3007351548286943]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.379077262459041		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.379077262459041 | validation: 3.0813289596111906]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2659755318944437		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.2659755318944437 | validation: 3.0087873974147725]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.341648133491659		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.341648133491659 | validation: 2.923449131848658]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2427878230252785		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.2427878230252785 | validation: 2.887727986947011]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4746819346859605		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.4746819346859605 | validation: 2.922497501362272]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3795209472746233		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.3795209472746233 | validation: 3.3383086139157]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5009654293028454		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 1.5009654293028454 | validation: 2.9221408680852985]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2748511040166572		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.2748511040166572 | validation: 2.926723947577405]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.319922192747641		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.319922192747641 | validation: 2.8898130684826207]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3112433901774652		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.3112433901774652 | validation: 3.386073515639391]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4890512107876241		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.4890512107876241 | validation: 3.2098835835753836]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4093894413036883		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 1.4093894413036883 | validation: 3.2688688083806965]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4044646121762394		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.4044646121762394 | validation: 3.01438058194526]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3511910564682905		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.3511910564682905 | validation: 2.897410447679628]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.394033397364934		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.394033397364934 | validation: 2.9679493316622803]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4046859006169594		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 1.4046859006169594 | validation: 2.921407945025379]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2920307121577252		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.2920307121577252 | validation: 2.9229314919669767]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.341184524140197		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.341184524140197 | validation: 2.9171532035178593]
	TIME [epoch: 11.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.374708266369754		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.374708266369754 | validation: 2.8933528386414094]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.275021533590505		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.275021533590505 | validation: 3.0062641173066242]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2679651748404628		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 1.2679651748404628 | validation: 2.9733244722993173]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5057203129910726		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.5057203129910726 | validation: 3.108023601639759]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3094361338618938		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.3094361338618938 | validation: 2.968468433092653]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2801522631844957		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.2801522631844957 | validation: 2.935773208206563]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2778555721625444		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.2778555721625444 | validation: 2.9089252444431124]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.359444445828629		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 1.359444445828629 | validation: 2.8868128837662814]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4220908041648328		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 1.4220908041648328 | validation: 2.924126809049074]
	TIME [epoch: 11.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2992795718560148		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 1.2992795718560148 | validation: 2.936311589806367]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2676206265716188		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 1.2676206265716188 | validation: 2.9885718320853125]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.262564932021602		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 1.262564932021602 | validation: 2.975612415737211]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.301873028581625		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.301873028581625 | validation: 2.9281259852259347]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2663073871611141		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.2663073871611141 | validation: 3.026359354407461]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3292841314032606		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 1.3292841314032606 | validation: 3.102349745803419]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.274686021403514		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 1.274686021403514 | validation: 3.061794875630676]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.29758139768266		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 1.29758139768266 | validation: 2.966572672664757]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2375090334150685		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 1.2375090334150685 | validation: 2.939922502462532]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.263711364831139		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 1.263711364831139 | validation: 3.227280553243006]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.483617201887514		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 1.483617201887514 | validation: 3.0492704049548616]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3302154797176295		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 1.3302154797176295 | validation: 3.131068542616298]
	TIME [epoch: 11.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.305478624775126		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 1.305478624775126 | validation: 3.0130834293248525]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3172010838761408		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 1.3172010838761408 | validation: 3.178377909739518]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3130633550766608		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 1.3130633550766608 | validation: 3.0163118359678793]
	TIME [epoch: 11.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2759076428443135		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 1.2759076428443135 | validation: 2.885358353922243]
	TIME [epoch: 11.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.256146637254839		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 1.256146637254839 | validation: 2.932654246107006]
	TIME [epoch: 11.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3057542995611677		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 1.3057542995611677 | validation: 2.9004983440147747]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2742665116607688		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 1.2742665116607688 | validation: 2.88416370032003]
	TIME [epoch: 11.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.285191323814904		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 1.285191323814904 | validation: 3.001072092693832]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3125238378322825		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 1.3125238378322825 | validation: 3.007503884989542]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2803968349906993		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 1.2803968349906993 | validation: 3.0372174560609175]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3013410156373095		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.3013410156373095 | validation: 2.875596504130146]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3022950317128463		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 1.3022950317128463 | validation: 3.06705344384518]
	TIME [epoch: 11.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3901857019333783		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 1.3901857019333783 | validation: 2.9905347659033765]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2457513689831998		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 1.2457513689831998 | validation: 3.115972908406446]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4319431131481415		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 1.4319431131481415 | validation: 3.031177779507026]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2859515896346978		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 1.2859515896346978 | validation: 2.942797323307044]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2605723219377134		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 1.2605723219377134 | validation: 2.883113294799184]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3117171980643114		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 1.3117171980643114 | validation: 2.902580412246063]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2229633609349875		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.2229633609349875 | validation: 3.0828985626228103]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3419033574832022		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 1.3419033574832022 | validation: 2.992016307164771]
	TIME [epoch: 11.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2444479060589702		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 1.2444479060589702 | validation: 2.9245656193823963]
	TIME [epoch: 11.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2988278992819289		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.2988278992819289 | validation: 3.005440821506836]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2556487021652722		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 1.2556487021652722 | validation: 2.8733909805529994]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_571.pth
	Model improved!!!
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2388366547165377		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 1.2388366547165377 | validation: 2.983733556270191]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2711342655433597		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 1.2711342655433597 | validation: 2.9658784336720396]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3998175943249334		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 1.3998175943249334 | validation: 3.209760049861324]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.33579932370488		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 1.33579932370488 | validation: 3.0523612171878285]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3221017045026922		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 1.3221017045026922 | validation: 2.890007694599307]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3030249895533852		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 1.3030249895533852 | validation: 2.970928040225686]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2855718134947862		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 1.2855718134947862 | validation: 3.136079643944737]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2817879699316101		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 1.2817879699316101 | validation: 2.9654015483884644]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3279004152029832		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 1.3279004152029832 | validation: 2.897026394863734]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.325058445680806		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 1.325058445680806 | validation: 2.9529617954357814]
	TIME [epoch: 11.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2831692443216751		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 1.2831692443216751 | validation: 2.9355732575231084]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.341237343924229		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 1.341237343924229 | validation: 2.9631927590485496]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2833710168432293		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 1.2833710168432293 | validation: 2.873096469187583]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_584.pth
	Model improved!!!
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2731268117503554		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 1.2731268117503554 | validation: 2.8808669805421574]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.237108373475953		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 1.237108373475953 | validation: 3.018211792748516]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2994661732058734		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 1.2994661732058734 | validation: 2.894935622631107]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2477638412424465		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 1.2477638412424465 | validation: 2.888468763597298]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2085259775472117		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 1.2085259775472117 | validation: 2.9154936556358497]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2852231593352268		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 1.2852231593352268 | validation: 3.007762055405856]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2572289974948672		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.2572289974948672 | validation: 2.88139249899839]
	TIME [epoch: 11.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.316669385974084		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 1.316669385974084 | validation: 2.877768051993446]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2518818312688516		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 1.2518818312688516 | validation: 3.0457482722065676]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2533059769868655		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 1.2533059769868655 | validation: 2.888547458381857]
	TIME [epoch: 11.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.411074783108327		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 1.411074783108327 | validation: 3.0048525645146267]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2667893265396317		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 1.2667893265396317 | validation: 2.872781677022394]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2332632463412763		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 1.2332632463412763 | validation: 2.891963534587081]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2216558795924375		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 1.2216558795924375 | validation: 2.878571073060907]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2372813456712246		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 1.2372813456712246 | validation: 2.925872269631258]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2338241772844638		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 1.2338241772844638 | validation: 2.9443768938473966]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.245638197873179		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 1.245638197873179 | validation: 2.9506016179456047]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2439709329003774		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 1.2439709329003774 | validation: 3.324216974493473]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3319423464396802		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 1.3319423464396802 | validation: 3.109108045962894]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5223171788923917		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 1.5223171788923917 | validation: 3.4025578467843323]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3607676488802505		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 1.3607676488802505 | validation: 2.876564863195124]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2208871258108829		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.2208871258108829 | validation: 2.9831586809108535]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2475515178565653		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 1.2475515178565653 | validation: 3.084922460912477]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232741661531958		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 1.232741661531958 | validation: 2.8979268088953267]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2936840981277649		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 1.2936840981277649 | validation: 3.0738363894407237]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3382558612707622		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 1.3382558612707622 | validation: 3.0625815653396784]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2604506142191796		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 1.2604506142191796 | validation: 2.943764980425069]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2111741499952204		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 1.2111741499952204 | validation: 2.8893583708554513]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235320830608761		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 1.235320830608761 | validation: 3.0783659076655083]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.319672307908855		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 1.319672307908855 | validation: 2.912424082132753]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2225409901475153		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 1.2225409901475153 | validation: 2.887351113537401]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2084478585496279		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 1.2084478585496279 | validation: 2.924315085464741]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2239804377403254		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 1.2239804377403254 | validation: 2.8977121266681967]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244277907915895		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 1.244277907915895 | validation: 3.125365822758553]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3172846194968457		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 1.3172846194968457 | validation: 3.0914618967293643]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3246700466799024		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 1.3246700466799024 | validation: 2.8629602809370898]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_620.pth
	Model improved!!!
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1985537680177012		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 1.1985537680177012 | validation: 2.8878096923543524]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2092837517183457		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 1.2092837517183457 | validation: 2.93616009192676]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2980631680876453		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 1.2980631680876453 | validation: 2.8670363768206837]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2695856837914294		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 1.2695856837914294 | validation: 3.2874894876912135]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3144234714796226		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 1.3144234714796226 | validation: 2.8785902967344397]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2108570578025513		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 1.2108570578025513 | validation: 2.884197459878144]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2053170869968302		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 1.2053170869968302 | validation: 3.036271791728858]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2737783987193871		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 1.2737783987193871 | validation: 2.8777124366385114]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3807574791206887		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 1.3807574791206887 | validation: 2.996696099120361]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2686593674403546		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 1.2686593674403546 | validation: 3.0693615357063937]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2346977657775047		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 1.2346977657775047 | validation: 2.920049432887664]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.225994394858105		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 1.225994394858105 | validation: 2.982773344586741]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2815690850689174		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 1.2815690850689174 | validation: 2.9380912676242423]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2076660923937432		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 1.2076660923937432 | validation: 2.9306466858642266]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2811205268367352		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 1.2811205268367352 | validation: 2.878816078163305]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2900247410843317		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 1.2900247410843317 | validation: 2.8680122293899353]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2207024137329645		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 1.2207024137329645 | validation: 2.9930243448464164]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3309145893995997		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 1.3309145893995997 | validation: 2.9157449667315314]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2108209872526163		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 1.2108209872526163 | validation: 2.8595302120513684]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2263891563430311		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 1.2263891563430311 | validation: 2.909165544737862]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2873087461157908		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 1.2873087461157908 | validation: 2.8750516251518032]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2873962892891953		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 1.2873962892891953 | validation: 3.074270517842529]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3174388237630643		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 1.3174388237630643 | validation: 2.9202037384275847]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2517880641435142		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 1.2517880641435142 | validation: 2.8654105376981445]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2436444533621986		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.2436444533621986 | validation: 2.95209329038087]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2951285164861643		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 1.2951285164861643 | validation: 2.8784727643082455]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2089781396801187		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 1.2089781396801187 | validation: 2.8875462649523334]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.186388512707065		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 1.186388512707065 | validation: 2.9754153281035407]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2217660416769727		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 1.2217660416769727 | validation: 2.892122702170017]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2191579383415114		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 1.2191579383415114 | validation: 2.863103735476333]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1955193693809232		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 1.1955193693809232 | validation: 2.8874994036864017]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.311400607641303		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 1.311400607641303 | validation: 2.894177835846957]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3295431730828375		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 1.3295431730828375 | validation: 2.9148002263341484]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2249606566504103		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 1.2249606566504103 | validation: 2.933704618875997]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2100523246614951		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 1.2100523246614951 | validation: 2.8860358405081725]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2247307122069084		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 1.2247307122069084 | validation: 2.8921526557140114]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2122212663952538		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 1.2122212663952538 | validation: 2.9703687209382816]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.247665301002558		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 1.247665301002558 | validation: 2.8932631949596788]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2049853649717486		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 1.2049853649717486 | validation: 2.9987857833231444]
	TIME [epoch: 11.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2208414369903786		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 1.2208414369903786 | validation: 2.8698212480056657]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2229553452721147		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 1.2229553452721147 | validation: 3.003683807479882]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2449476909338721		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 1.2449476909338721 | validation: 3.2500293289703506]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3373242546455597		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 1.3373242546455597 | validation: 2.9656038260640414]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2870897630157396		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 1.2870897630157396 | validation: 2.882680615423159]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2210148019151332		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 1.2210148019151332 | validation: 2.871252901273857]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2146744763469897		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 1.2146744763469897 | validation: 2.923182620596123]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2237635022106308		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 1.2237635022106308 | validation: 3.0023876530728875]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.248672930717278		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 1.248672930717278 | validation: 3.10920569495367]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.292599627048082		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 1.292599627048082 | validation: 2.8823751776879964]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2080309398865454		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 1.2080309398865454 | validation: 2.9859558229930245]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2103490084041728		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 1.2103490084041728 | validation: 2.8820368415900997]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2658367319486796		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 1.2658367319486796 | validation: 2.909242635304581]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2196513460420815		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 1.2196513460420815 | validation: 2.981013787589499]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2614141099323366		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 1.2614141099323366 | validation: 2.8727028101788403]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.190361498194262		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 1.190361498194262 | validation: 3.09017425828816]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2271403805375947		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 1.2271403805375947 | validation: 2.9037360076208314]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2420051322262482		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 1.2420051322262482 | validation: 3.040315170442965]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.208099173862339		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 1.208099173862339 | validation: 3.000438034646608]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2527275953380719		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 1.2527275953380719 | validation: 2.9155515625171597]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2035868429296481		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 1.2035868429296481 | validation: 2.8933879990864195]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2040687227259232		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 1.2040687227259232 | validation: 2.8681917825539736]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2225343579418877		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 1.2225343579418877 | validation: 2.8920350347048327]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2241557390732833		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 1.2241557390732833 | validation: 2.997266957858623]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3078900494168166		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 1.3078900494168166 | validation: 3.006388703880657]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2193921313195213		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 1.2193921313195213 | validation: 2.899426465038549]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1832541128606617		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 1.1832541128606617 | validation: 2.8633849624407266]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2186949277963843		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 1.2186949277963843 | validation: 2.9287832585034153]
	TIME [epoch: 11.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2235743080806158		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 1.2235743080806158 | validation: 2.9835709081942845]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2219718476540544		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 1.2219718476540544 | validation: 2.977456658274017]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2079937146077204		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 1.2079937146077204 | validation: 3.0611958167219733]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.261664525052065		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 1.261664525052065 | validation: 2.875158207874956]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3105487935425773		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 1.3105487935425773 | validation: 2.8997234135544976]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2648506756509064		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 1.2648506756509064 | validation: 2.9126647076046153]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2187729231217816		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 1.2187729231217816 | validation: 2.990798400974947]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2559489854997223		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 1.2559489854997223 | validation: 2.98888596579996]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2207946605378934		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 1.2207946605378934 | validation: 3.2104109804060346]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3899415195026934		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 1.3899415195026934 | validation: 2.8818668049952003]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.189938051058736		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 1.189938051058736 | validation: 2.8815394448666574]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1989370026350745		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 1.1989370026350745 | validation: 2.8945933445823915]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2157933300244066		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 1.2157933300244066 | validation: 2.8838693612179718]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.188517756280818		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 1.188517756280818 | validation: 2.88409989265842]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1784465532918524		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 1.1784465532918524 | validation: 3.0089245765185604]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2294295158622741		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 1.2294295158622741 | validation: 2.8663552877826546]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1968650665209934		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 1.1968650665209934 | validation: 2.877437666430799]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2120695748874133		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 1.2120695748874133 | validation: 2.8749883269695746]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2171853332877975		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 1.2171853332877975 | validation: 2.9662820305450395]
	TIME [epoch: 11.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2463804656265205		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 1.2463804656265205 | validation: 2.864599947965445]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1904429550986757		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 1.1904429550986757 | validation: 2.8623362011078792]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.197454933023442		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 1.197454933023442 | validation: 2.8882498356746455]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2388063742279498		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 1.2388063742279498 | validation: 2.861931219976272]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.242707205916899		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 1.242707205916899 | validation: 3.0427597710356156]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2596202518753143		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 1.2596202518753143 | validation: 2.895281384957574]
	TIME [epoch: 11.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.201276637811986		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 1.201276637811986 | validation: 2.8702343769024616]
	TIME [epoch: 11.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1958681474930501		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 1.1958681474930501 | validation: 2.89717296658785]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1939949921375772		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 1.1939949921375772 | validation: 2.8652549953160786]
	TIME [epoch: 11.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1976446556760512		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 1.1976446556760512 | validation: 2.912990144187909]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2280363346992322		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 1.2280363346992322 | validation: 2.9273509023438526]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2474271286063197		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 1.2474271286063197 | validation: 2.9353945512808868]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2576360535897921		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 1.2576360535897921 | validation: 2.966296248695394]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2151258778717628		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 1.2151258778717628 | validation: 2.943054113811095]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2153644576720073		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 1.2153644576720073 | validation: 2.9068861007542997]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.214406193147108		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 1.214406193147108 | validation: 2.8937793505403087]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2097362482492475		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 1.2097362482492475 | validation: 2.855797176881658]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_723.pth
	Model improved!!!
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.173539808285256		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 1.173539808285256 | validation: 2.9345612821684326]
	TIME [epoch: 11.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1844367069573787		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 1.1844367069573787 | validation: 2.9174504717287095]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1906238817253696		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 1.1906238817253696 | validation: 2.852621587875168]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2227646706381212		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 1.2227646706381212 | validation: 3.0057662976547967]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306885226952917		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 1.2306885226952917 | validation: 2.87090919259664]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2212620520551163		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 1.2212620520551163 | validation: 2.8703556293365478]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2083189841265662		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 1.2083189841265662 | validation: 2.9356622842905944]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2283456768090961		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 1.2283456768090961 | validation: 2.8883043718166004]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.213071127477488		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 1.213071127477488 | validation: 2.8610817547412135]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1764354707719455		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 1.1764354707719455 | validation: 3.0081838951917805]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2063794953071816		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 1.2063794953071816 | validation: 2.886347364552673]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.238736718133628		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 1.238736718133628 | validation: 2.902052811148827]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.200080147891552		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 1.200080147891552 | validation: 2.8790198339205277]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2498382206748793		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 1.2498382206748793 | validation: 2.8719752091484736]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2109430000383572		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 1.2109430000383572 | validation: 2.9421584912752134]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2482279301335673		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 1.2482279301335673 | validation: 3.072079190745092]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3755639870709349		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 1.3755639870709349 | validation: 2.970760613466275]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.247517649789304		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 1.247517649789304 | validation: 2.8562623225929666]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2079329087887698		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 1.2079329087887698 | validation: 2.859487804883447]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1823818004652882		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 1.1823818004652882 | validation: 3.0399877793842927]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2597183129027982		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 1.2597183129027982 | validation: 2.9582946354461863]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1948888622353204		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 1.1948888622353204 | validation: 2.892255240451941]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2016361496138648		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 1.2016361496138648 | validation: 2.861720625534992]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2067779485402503		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 1.2067779485402503 | validation: 2.8481604307543154]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_747.pth
	Model improved!!!
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.182134252244632		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 1.182134252244632 | validation: 2.887111219733024]
	TIME [epoch: 11.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1974375968885616		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 1.1974375968885616 | validation: 2.9131389448930225]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2271921961302996		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 1.2271921961302996 | validation: 3.0116802531062716]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2267775817597255		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 1.2267775817597255 | validation: 2.858146427406503]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.196458350805561		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 1.196458350805561 | validation: 2.847106417555434]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_752.pth
	Model improved!!!
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1767491455409196		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 1.1767491455409196 | validation: 2.864755114310717]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1790169236552819		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 1.1790169236552819 | validation: 3.0671995869287896]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2268493916952217		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 1.2268493916952217 | validation: 2.8838012784427893]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2073929164864552		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 1.2073929164864552 | validation: 3.019280531612175]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.217731848802262		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 1.217731848802262 | validation: 2.87693938847768]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174351805193446		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 1.174351805193446 | validation: 2.878708692155235]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1981117682505797		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 1.1981117682505797 | validation: 2.9509201014695505]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.208080093244457		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 1.208080093244457 | validation: 2.854766167867722]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2012812696384652		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 1.2012812696384652 | validation: 2.926768277560876]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2554481309548284		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 1.2554481309548284 | validation: 2.9474935270750295]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2482685521528052		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 1.2482685521528052 | validation: 2.857704935115505]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2197378179667986		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 1.2197378179667986 | validation: 2.941116224420948]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2149059751393358		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 1.2149059751393358 | validation: 2.8893291193482344]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1925822644771167		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 1.1925822644771167 | validation: 2.9896461916541326]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1934339412942403		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 1.1934339412942403 | validation: 2.9609590940669928]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2003744787585258		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 1.2003744787585258 | validation: 2.927114315844594]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1941703267088346		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 1.1941703267088346 | validation: 2.866598034832259]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.178252750741611		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 1.178252750741611 | validation: 2.892909714098299]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2291389215940243		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 1.2291389215940243 | validation: 2.876033481429081]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2451559813769664		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 1.2451559813769664 | validation: 2.85276173656648]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2069222753102384		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 1.2069222753102384 | validation: 2.8742259637765777]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.207428394367745		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 1.207428394367745 | validation: 2.870792815884341]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1608003327174925		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 1.1608003327174925 | validation: 2.887911916700883]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2018670621219225		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 1.2018670621219225 | validation: 2.849887487142049]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.179754983224291		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 1.179754983224291 | validation: 3.002068925617606]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2550369724920842		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 1.2550369724920842 | validation: 2.9026555336615854]
	TIME [epoch: 11.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1773001207130807		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 1.1773001207130807 | validation: 2.9815803667123366]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2154540893942878		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 1.2154540893942878 | validation: 2.9056931016289105]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1895949300342117		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 1.1895949300342117 | validation: 2.9180207653758545]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.227840505783961		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 1.227840505783961 | validation: 2.867908488866143]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1904733481457197		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 1.1904733481457197 | validation: 2.8976958596176368]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.203151765629099		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 1.203151765629099 | validation: 2.8927315128167987]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2092216702916843		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 1.2092216702916843 | validation: 2.9058375900875606]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2111716732859845		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 1.2111716732859845 | validation: 2.857091281664615]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1795637398547736		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 1.1795637398547736 | validation: 2.844443126253096]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_787.pth
	Model improved!!!
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2362578319648732		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 1.2362578319648732 | validation: 2.8903623293924863]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.222437064378042		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 1.222437064378042 | validation: 2.842408782447984]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_789.pth
	Model improved!!!
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2302352285114582		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 1.2302352285114582 | validation: 3.0230839644743788]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2401396267293925		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 1.2401396267293925 | validation: 2.9930850650976373]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2501122183609505		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 1.2501122183609505 | validation: 2.9199775125738734]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.188306164767907		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 1.188306164767907 | validation: 2.877226492006987]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.21458160287774		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 1.21458160287774 | validation: 2.8685449602922244]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.215881239093711		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 1.215881239093711 | validation: 2.9450095470625004]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2081533065622319		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 1.2081533065622319 | validation: 2.891235653060951]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2113451217419804		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 1.2113451217419804 | validation: 2.849981336228682]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.206940489653723		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 1.206940489653723 | validation: 2.9893590346065197]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2091599871043754		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 1.2091599871043754 | validation: 2.8747121895110634]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.214644206014217		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 1.214644206014217 | validation: 2.9325105223910293]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.189924209984794		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 1.189924209984794 | validation: 2.8969897809742498]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2204199190831697		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 1.2204199190831697 | validation: 2.87562353967419]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1815746169454895		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 1.1815746169454895 | validation: 2.8440140123591515]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232479789694405		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 1.232479789694405 | validation: 2.9889611195490695]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2318573919592113		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 1.2318573919592113 | validation: 2.8729990272637287]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2008093357309282		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 1.2008093357309282 | validation: 2.870322239765884]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1816336207368503		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 1.1816336207368503 | validation: 2.9786505784521924]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1998352992102517		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 1.1998352992102517 | validation: 2.87737326251847]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.212439040488617		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 1.212439040488617 | validation: 2.8655827287130626]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1942141483883633		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 1.1942141483883633 | validation: 2.9662943531337826]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2652649924796509		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 1.2652649924796509 | validation: 2.991518632315063]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2660514856006484		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 1.2660514856006484 | validation: 2.868911883746215]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1672906290255614		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 1.1672906290255614 | validation: 2.8630933847105906]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1801885546183244		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 1.1801885546183244 | validation: 2.8775105476608855]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174964920496527		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 1.174964920496527 | validation: 2.8589654368125714]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1927567799966097		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 1.1927567799966097 | validation: 2.8578178776063874]
	TIME [epoch: 11.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1701314611069829		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 1.1701314611069829 | validation: 2.9239485001132697]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.210195374653518		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 1.210195374653518 | validation: 2.90897211177224]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2212106596450805		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 1.2212106596450805 | validation: 2.881231826485896]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2204818114742413		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 1.2204818114742413 | validation: 2.875768905468102]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1649618465297331		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 1.1649618465297331 | validation: 2.8487632129094203]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1702240199344995		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 1.1702240199344995 | validation: 3.0831173633120468]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.246969175919948		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 1.246969175919948 | validation: 2.9665933539409606]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.187059705216788		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 1.187059705216788 | validation: 2.844300972810155]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1726666976949294		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 1.1726666976949294 | validation: 2.93509596386381]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1789067529216568		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 1.1789067529216568 | validation: 2.8700118538592885]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1899733058170143		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 1.1899733058170143 | validation: 2.879636853758693]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1901739097624362		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 1.1901739097624362 | validation: 3.0010263930469647]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2142893305448064		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 1.2142893305448064 | validation: 2.869022764869229]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1987930950409122		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 1.1987930950409122 | validation: 2.933769413177151]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1855028089307533		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 1.1855028089307533 | validation: 3.019617749667442]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2142933463579872		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 1.2142933463579872 | validation: 2.890239377120714]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2047702807958858		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 1.2047702807958858 | validation: 2.865740497830605]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1822331472319914		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 1.1822331472319914 | validation: 2.9316834997789636]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1886366181184207		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 1.1886366181184207 | validation: 2.922746365230331]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2402736654615092		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 1.2402736654615092 | validation: 2.868243690529241]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.165196469657099		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 1.165196469657099 | validation: 2.8859431388671157]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.169201321341077		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 1.169201321341077 | validation: 2.8918255638845474]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.176528910595822		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 1.176528910595822 | validation: 2.849913525494925]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1899602815758854		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 1.1899602815758854 | validation: 2.8998631034985296]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1707945101336656		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 1.1707945101336656 | validation: 2.8428958797106993]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1828094400367757		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 1.1828094400367757 | validation: 2.9435574105204503]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1880515910946827		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 1.1880515910946827 | validation: 2.8908668403033198]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.242546881490045		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 1.242546881490045 | validation: 2.864670601943576]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.183892755005836		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 1.183892755005836 | validation: 2.946190255699729]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1951667836598818		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 1.1951667836598818 | validation: 2.8487861804164396]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1656365544991314		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 1.1656365544991314 | validation: 2.84497283876968]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1958778984358247		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 1.1958778984358247 | validation: 2.911487246720012]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.187769516831368		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 1.187769516831368 | validation: 2.8958917501045303]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2180192117825919		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 1.2180192117825919 | validation: 2.8816289545358225]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1806120880131725		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 1.1806120880131725 | validation: 2.896138657084033]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1909998744438286		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 1.1909998744438286 | validation: 2.850130165991461]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1804080520567568		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 1.1804080520567568 | validation: 2.848639597611678]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1972939444639805		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 1.1972939444639805 | validation: 2.9773560372826102]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.202674433815151		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 1.202674433815151 | validation: 2.8515368214939305]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231025480282017		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 1.231025480282017 | validation: 2.8891507671737022]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2241286925556372		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 1.2241286925556372 | validation: 2.867437944564427]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1708043719303178		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 1.1708043719303178 | validation: 2.9071107902646687]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1913036327520294		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 1.1913036327520294 | validation: 2.8617158710393955]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1961175668667916		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 1.1961175668667916 | validation: 2.8673916031491693]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2000628631511765		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 1.2000628631511765 | validation: 2.880357246298877]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.167989853114391		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 1.167989853114391 | validation: 2.9156776989001076]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1858991368371976		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 1.1858991368371976 | validation: 2.9019862231268774]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2039359617955585		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 1.2039359617955585 | validation: 2.910005104116442]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2399997661636415		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 1.2399997661636415 | validation: 2.848003381116015]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1895223470990137		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 1.1895223470990137 | validation: 2.895552010940532]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1962576239148026		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 1.1962576239148026 | validation: 2.9533665463157286]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1917707153212322		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 1.1917707153212322 | validation: 2.873806260326499]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1721752836596184		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 1.1721752836596184 | validation: 2.9131211074296846]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2464817970398359		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 1.2464817970398359 | validation: 2.8434384560191224]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1780377478399278		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 1.1780377478399278 | validation: 2.8420492623594296]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_871.pth
	Model improved!!!
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.159259655323742		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 1.159259655323742 | validation: 2.8587336308797764]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1546165635840333		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 1.1546165635840333 | validation: 2.8466468542679717]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1758649471832765		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 1.1758649471832765 | validation: 2.875453923398036]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1720649144972453		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 1.1720649144972453 | validation: 2.8534449762190217]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1766823757757918		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 1.1766823757757918 | validation: 2.878472425577881]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1875749632746473		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 1.1875749632746473 | validation: 2.894505890620875]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2836793735819543		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 1.2836793735819543 | validation: 2.9848248166217606]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1896316138678282		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 1.1896316138678282 | validation: 2.858901307825255]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1813919689709134		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 1.1813919689709134 | validation: 2.8637171701317037]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.181659700635936		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 1.181659700635936 | validation: 2.8635395316919214]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1587877722925486		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 1.1587877722925486 | validation: 2.929133141970614]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1809222161159378		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 1.1809222161159378 | validation: 2.860011063078586]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1689543776669407		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 1.1689543776669407 | validation: 2.9226380871492426]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1894384522770378		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 1.1894384522770378 | validation: 2.9000264956913315]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1683879251241662		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 1.1683879251241662 | validation: 2.894355660272505]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1639025956894067		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 1.1639025956894067 | validation: 2.8630256363000695]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1698378747337712		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 1.1698378747337712 | validation: 2.8714877277436437]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.188506552709053		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 1.188506552709053 | validation: 2.8757426929852614]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1888486953649866		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 1.1888486953649866 | validation: 2.8723841157927543]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1939735406486764		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 1.1939735406486764 | validation: 2.961278769052895]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3112186803272807		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 1.3112186803272807 | validation: 2.9715178085762877]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2058488815084143		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 1.2058488815084143 | validation: 2.865694464972736]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1879503704446777		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 1.1879503704446777 | validation: 2.8601900414008186]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.164446307675373		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 1.164446307675373 | validation: 2.882181449760957]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1778395617306492		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 1.1778395617306492 | validation: 2.880034463747685]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1659410539453812		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 1.1659410539453812 | validation: 2.8644449988739114]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1738848248348925		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 1.1738848248348925 | validation: 2.8876631444701775]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.160883439064524		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 1.160883439064524 | validation: 2.86650913065949]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.203818576368975		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 1.203818576368975 | validation: 2.9922014490651585]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2211597609385354		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 1.2211597609385354 | validation: 2.859970678452055]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.193096902801876		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 1.193096902801876 | validation: 2.904156848049348]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1734391293505624		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 1.1734391293505624 | validation: 2.882116761359855]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1805928287530087		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 1.1805928287530087 | validation: 2.8544201431659078]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1499429479213754		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 1.1499429479213754 | validation: 2.8781585405464107]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1846052293898042		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 1.1846052293898042 | validation: 2.9010604460316336]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2065223730092276		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 1.2065223730092276 | validation: 2.9030583967447154]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1785333325944474		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 1.1785333325944474 | validation: 2.8741749691190353]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1803254423248544		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 1.1803254423248544 | validation: 2.8521771685214174]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2009475687516058		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 1.2009475687516058 | validation: 2.8535322202366245]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1867890895563402		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 1.1867890895563402 | validation: 2.8541570991907568]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1633711382283023		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 1.1633711382283023 | validation: 2.8735472091692076]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.161222255941317		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 1.161222255941317 | validation: 2.9124033010556736]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.181046372351763		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 1.181046372351763 | validation: 2.9577316838710166]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1837814002619542		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 1.1837814002619542 | validation: 2.8986773709507885]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1633642930102368		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 1.1633642930102368 | validation: 2.912980285307706]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2187329945509549		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 1.2187329945509549 | validation: 2.900006699232804]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1741154590984082		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 1.1741154590984082 | validation: 2.8525072765548236]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1710104975935387		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 1.1710104975935387 | validation: 2.935975915998506]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1708849865964512		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 1.1708849865964512 | validation: 2.874412905977966]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1776551155462849		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 1.1776551155462849 | validation: 2.8525554186973205]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2376250191589626		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 1.2376250191589626 | validation: 2.90705145391332]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2031584313820483		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 1.2031584313820483 | validation: 2.881333598162579]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1687180081741781		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 1.1687180081741781 | validation: 2.9035677695270308]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2162393776277927		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 1.2162393776277927 | validation: 2.8535462605876587]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1569594376992027		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 1.1569594376992027 | validation: 2.8732924229529107]
	TIME [epoch: 11.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.181364083514683		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 1.181364083514683 | validation: 2.8663451207694317]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.178231256934142		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 1.178231256934142 | validation: 2.9884645994268992]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2189737859709988		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 1.2189737859709988 | validation: 2.856815824456757]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1855357400578468		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 1.1855357400578468 | validation: 2.855061778036695]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1571890041493473		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 1.1571890041493473 | validation: 2.8658450391789283]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.168876882450561		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 1.168876882450561 | validation: 2.8366286301336525]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_932.pth
	Model improved!!!
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1653828539476283		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 1.1653828539476283 | validation: 2.882286940614031]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.192411807212151		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 1.192411807212151 | validation: 2.855265599608757]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1598768735902683		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 1.1598768735902683 | validation: 2.8631307305204747]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1708071213152624		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 1.1708071213152624 | validation: 2.870555965041587]
	TIME [epoch: 11.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1921742474852495		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 1.1921742474852495 | validation: 2.9425344241446103]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2580605852376285		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 1.2580605852376285 | validation: 3.078829418179268]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229639427311866		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 1.229639427311866 | validation: 2.8464665742014312]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1794300739988253		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 1.1794300739988253 | validation: 2.847973822773884]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1712517647787875		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 1.1712517647787875 | validation: 2.912452792335197]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1665891423678927		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 1.1665891423678927 | validation: 2.8466596197831837]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1774003397477568		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 1.1774003397477568 | validation: 2.8624247939237724]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1890319114377357		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 1.1890319114377357 | validation: 2.8996261104886365]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1652691760233127		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 1.1652691760233127 | validation: 2.865138020960007]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1571954277357277		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 1.1571954277357277 | validation: 2.886552885877634]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1691451397148105		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 1.1691451397148105 | validation: 2.9130208189223925]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1742708199418281		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 1.1742708199418281 | validation: 2.856398800855934]
	TIME [epoch: 11.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1621620679314566		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 1.1621620679314566 | validation: 2.951816874707904]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2587863897382743		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 1.2587863897382743 | validation: 2.8974123026884064]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.169010250351755		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 1.169010250351755 | validation: 2.9082000972816173]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1533383876589378		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 1.1533383876589378 | validation: 2.897075088633664]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1690400257345648		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 1.1690400257345648 | validation: 2.858237617748106]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1710353953307835		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 1.1710353953307835 | validation: 2.9484878791430322]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1700008839528941		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 1.1700008839528941 | validation: 2.895414039483942]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1669559879163993		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 1.1669559879163993 | validation: 2.884669104455373]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1929712905122964		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 1.1929712905122964 | validation: 2.8596206660774124]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1723564888195013		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 1.1723564888195013 | validation: 2.8676701154051303]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2013817200526886		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 1.2013817200526886 | validation: 2.8372440103276064]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1666818400915069		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 1.1666818400915069 | validation: 2.862768367361108]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.187340757242719		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 1.187340757242719 | validation: 2.8882084063802558]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.192360036693983		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 1.192360036693983 | validation: 2.889729274905641]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.158879894717452		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 1.158879894717452 | validation: 2.8600080858247545]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1485033238492055		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 1.1485033238492055 | validation: 2.8595069621365115]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1742745936789152		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 1.1742745936789152 | validation: 2.887344352069314]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.166984005293101		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 1.166984005293101 | validation: 2.8572455395925345]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1767193143162356		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 1.1767193143162356 | validation: 2.8663977172643245]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1595478680662268		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 1.1595478680662268 | validation: 2.86425553136999]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1596595736193533		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 1.1596595736193533 | validation: 2.8515717266157923]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1558267358855654		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 1.1558267358855654 | validation: 2.9016789671613576]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1514606678166701		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 1.1514606678166701 | validation: 2.9190161840416047]
	TIME [epoch: 11.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1750584922353586		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 1.1750584922353586 | validation: 2.877255997488457]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2128496354375065		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 1.2128496354375065 | validation: 2.844372503512726]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1723782997619403		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 1.1723782997619403 | validation: 2.862767740036779]
	TIME [epoch: 11.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1991577795497674		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 1.1991577795497674 | validation: 2.845228833568506]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1756648712598627		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 1.1756648712598627 | validation: 2.85006504106619]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1943960416529469		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 1.1943960416529469 | validation: 2.851939238661464]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1541764904125011		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 1.1541764904125011 | validation: 2.858335826326985]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1713109984886887		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 1.1713109984886887 | validation: 2.9004048501912694]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2125591392619683		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 1.2125591392619683 | validation: 2.861965692901316]
	TIME [epoch: 11.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1571409259359466		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 1.1571409259359466 | validation: 2.8886827034582008]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1650202854311775		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 1.1650202854311775 | validation: 2.845118163041758]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1716039541804968		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 1.1716039541804968 | validation: 2.880090330159072]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174900225131435		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 1.174900225131435 | validation: 2.9104801010450854]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1860753635091663		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 1.1860753635091663 | validation: 2.8685658942240275]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.156747989532189		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 1.156747989532189 | validation: 2.874151453754696]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1548505550124748		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 1.1548505550124748 | validation: 2.903420682350631]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.159643694341883		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 1.159643694341883 | validation: 2.8623149262576426]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1724095079109251		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 1.1724095079109251 | validation: 2.866803375184877]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1636872620294576		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 1.1636872620294576 | validation: 2.928008021634145]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1617416977741435		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 1.1617416977741435 | validation: 2.8625235766585244]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1647413159417213		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 1.1647413159417213 | validation: 2.863904944691671]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.160601068479227		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 1.160601068479227 | validation: 2.8794319342800363]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1863538730237912		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 1.1863538730237912 | validation: 2.879734646027198]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1677290672810992		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 1.1677290672810992 | validation: 2.85492264808919]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1810543977552803		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 1.1810543977552803 | validation: 2.848258969293786]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1862139632374245		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 1.1862139632374245 | validation: 2.891570998036847]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1639903967056986		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 1.1639903967056986 | validation: 2.8808876991546883]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1773634415711025		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 1.1773634415711025 | validation: 2.8438331600086175]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1704680364751539		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 1.1704680364751539 | validation: 2.871029275690588]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150243578730267		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 1.150243578730267 | validation: 2.876516832484664]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1582812495410102		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 1.1582812495410102 | validation: 2.8577201524496343]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1760107386578549		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 1.1760107386578549 | validation: 2.8788610519248197]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1683092707439322		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 1.1683092707439322 | validation: 2.8996804490438617]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1587461339641902		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 1.1587461339641902 | validation: 2.9079219801334455]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1984995015090185		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 1.1984995015090185 | validation: 2.934878510331356]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1616954232104015		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 1.1616954232104015 | validation: 2.8645999146550465]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1635206419679527		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 1.1635206419679527 | validation: 2.8677782695136007]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1840334561575183		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 1.1840334561575183 | validation: 2.848708904698645]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1473297795149544		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 1.1473297795149544 | validation: 2.8461948063534788]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1615652265760719		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 1.1615652265760719 | validation: 2.875103558556734]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.157940349070768		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 1.157940349070768 | validation: 2.8852507218644536]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.159690814464528		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 1.159690814464528 | validation: 2.8629392848472377]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1585736215863256		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 1.1585736215863256 | validation: 2.8547528192079317]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1574116954007592		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 1.1574116954007592 | validation: 2.8426290404238213]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154271224105325		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 1.154271224105325 | validation: 2.863734380283857]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1574087393764876		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 1.1574087393764876 | validation: 2.8514044343988303]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.162845411494803		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 1.162845411494803 | validation: 2.9348805786918417]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1641242619795151		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 1.1641242619795151 | validation: 2.856099958644244]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1704724690863444		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 1.1704724690863444 | validation: 2.859400432174682]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1601276289405549		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 1.1601276289405549 | validation: 2.8949865431148463]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1557631554054577		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 1.1557631554054577 | validation: 2.8593847422811236]
	TIME [epoch: 11.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.158048821409729		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 1.158048821409729 | validation: 2.845659533339615]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1511327767818853		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 1.1511327767818853 | validation: 2.846458404261058]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1472106706373326		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 1.1472106706373326 | validation: 2.870472705530452]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.160166458785088		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 1.160166458785088 | validation: 2.8493391347686234]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.175447182827085		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 1.175447182827085 | validation: 2.9497115997797367]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1823202778134432		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 1.1823202778134432 | validation: 2.847311949909113]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153304256879423		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 1.153304256879423 | validation: 2.8429562339478163]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1986719746624441		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 1.1986719746624441 | validation: 2.84468718538291]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1655423611172724		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 1.1655423611172724 | validation: 2.8562375493191205]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.162058460400945		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 1.162058460400945 | validation: 2.850339951636296]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1532032423472807		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 1.1532032423472807 | validation: 2.8778240103333927]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.161902450211799		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 1.161902450211799 | validation: 2.835278947733524]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_1034.pth
	Model improved!!!
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.167304444798713		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 1.167304444798713 | validation: 2.883883670433741]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1555637687952625		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 1.1555637687952625 | validation: 2.861257991553921]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.175946053829219		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 1.175946053829219 | validation: 2.8570311570570937]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1582349324062795		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 1.1582349324062795 | validation: 2.895728801726386]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1625621256192953		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 1.1625621256192953 | validation: 2.841895786576961]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1414075422088996		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 1.1414075422088996 | validation: 2.8594225797789465]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1569646969000447		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 1.1569646969000447 | validation: 2.88607641098028]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1523523070351394		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 1.1523523070351394 | validation: 2.8590500362987665]
	TIME [epoch: 11.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1508825801204372		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 1.1508825801204372 | validation: 2.8642987994113147]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1645466769191095		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 1.1645466769191095 | validation: 2.914363247519]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1568243456893081		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 1.1568243456893081 | validation: 2.859357886011102]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1561811755770812		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 1.1561811755770812 | validation: 2.8469325762777316]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1566130238046068		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 1.1566130238046068 | validation: 2.8675882745879857]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1683537427037805		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 1.1683537427037805 | validation: 2.834772690762003]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_1048.pth
	Model improved!!!
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1548664560352457		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 1.1548664560352457 | validation: 2.9001692985309613]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1560627665833365		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 1.1560627665833365 | validation: 2.8514433094597167]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.143095932634807		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 1.143095932634807 | validation: 2.8418805801965665]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1800165900852555		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 1.1800165900852555 | validation: 2.8704026318831017]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.172538045040671		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 1.172538045040671 | validation: 2.864370413192359]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1528387923647787		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 1.1528387923647787 | validation: 2.8482101635469355]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1576276821076765		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 1.1576276821076765 | validation: 2.8563433561486518]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1550800352136745		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 1.1550800352136745 | validation: 2.841933426115066]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1636877183877		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 1.1636877183877 | validation: 2.854945469653764]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1592685973652426		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 1.1592685973652426 | validation: 2.887243769856377]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1693046235796232		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 1.1693046235796232 | validation: 2.9432152689389146]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1619299981108329		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 1.1619299981108329 | validation: 2.846037174680439]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1647251033720565		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 1.1647251033720565 | validation: 2.896164381193242]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1517500776284155		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 1.1517500776284155 | validation: 2.8500224028963372]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1703917376757988		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 1.1703917376757988 | validation: 2.871846732272777]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1618933094708426		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 1.1618933094708426 | validation: 2.8468863543182072]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1514559379283558		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 1.1514559379283558 | validation: 2.8489082164950257]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.149074500252393		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 1.149074500252393 | validation: 2.838534777174335]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1535209454801827		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 1.1535209454801827 | validation: 2.8958613737831014]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1612968974927662		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 1.1612968974927662 | validation: 2.8702208424489424]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1480059625631271		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 1.1480059625631271 | validation: 2.836595084041321]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1514463156308357		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 1.1514463156308357 | validation: 2.8659403403259947]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1731854399846244		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 1.1731854399846244 | validation: 2.8906403893849477]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.214308904784689		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 1.214308904784689 | validation: 2.8791838040329423]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1729433567305603		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 1.1729433567305603 | validation: 2.870927194619454]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1604709489603817		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 1.1604709489603817 | validation: 2.8554304288985253]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1552548046406381		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 1.1552548046406381 | validation: 2.837485138873402]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1453878647218767		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 1.1453878647218767 | validation: 2.860546842295205]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1705371136980898		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 1.1705371136980898 | validation: 2.9240883574923613]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1869706253882513		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 1.1869706253882513 | validation: 2.8476249316199653]
	TIME [epoch: 11.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1450219109624442		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 1.1450219109624442 | validation: 2.8655471513899857]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1521675816452903		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 1.1521675816452903 | validation: 2.8573821424472783]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1621933977241161		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 1.1621933977241161 | validation: 2.848485240284851]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1608777142462479		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 1.1608777142462479 | validation: 2.902302858697443]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1560735450481763		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 1.1560735450481763 | validation: 2.8487348647582516]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1496571230245234		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 1.1496571230245234 | validation: 2.8719076100591816]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1494017845957238		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 1.1494017845957238 | validation: 2.894154221364163]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153459496061191		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 1.153459496061191 | validation: 2.849860917646059]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1729517616581258		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 1.1729517616581258 | validation: 2.8824522306025804]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1924481704838674		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 1.1924481704838674 | validation: 2.8622523420158554]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1590719656154371		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 1.1590719656154371 | validation: 2.8620715845589477]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.158498027715563		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 1.158498027715563 | validation: 2.8444146905953307]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.148971134395266		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 1.148971134395266 | validation: 2.8557528984706573]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1421924054055816		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 1.1421924054055816 | validation: 2.865939445376127]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1566401882288337		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 1.1566401882288337 | validation: 2.9517774079993138]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1914536943304697		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 1.1914536943304697 | validation: 2.8837485719012137]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153600718987865		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 1.153600718987865 | validation: 2.8906749861554983]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1617953849945464		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 1.1617953849945464 | validation: 2.85792153837616]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.152064704301776		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 1.152064704301776 | validation: 2.903836268309305]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1538229716433086		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 1.1538229716433086 | validation: 2.8562410480459524]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1486776747814895		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 1.1486776747814895 | validation: 2.8518193786847985]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1482807088536175		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 1.1482807088536175 | validation: 2.887447287750813]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1497546569307815		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 1.1497546569307815 | validation: 2.8521298328700393]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1619453647312048		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 1.1619453647312048 | validation: 2.8541296890656342]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1425923693967799		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 1.1425923693967799 | validation: 2.889429786292212]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150091087849736		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 1.150091087849736 | validation: 2.846600235745633]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150960724930626		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 1.150960724930626 | validation: 2.8469097721632894]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1561276544503376		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 1.1561276544503376 | validation: 2.8666792807698473]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1556800909257432		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 1.1556800909257432 | validation: 2.85160119477765]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1597700673941223		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 1.1597700673941223 | validation: 2.901431357881319]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1578788012871104		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 1.1578788012871104 | validation: 2.857955692610375]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.151016401772278		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 1.151016401772278 | validation: 2.86686672846656]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1490220915108327		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 1.1490220915108327 | validation: 2.888660301104679]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1668160754800128		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 1.1668160754800128 | validation: 2.904122349642563]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1568651769225995		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 1.1568651769225995 | validation: 2.8563411563031513]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1471460875680168		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 1.1471460875680168 | validation: 2.8398731334219987]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1508453256729394		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 1.1508453256729394 | validation: 2.880089564718686]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1603790769205589		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 1.1603790769205589 | validation: 2.8629137556796707]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1406318276133753		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 1.1406318276133753 | validation: 2.8393630664538505]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150450954848297		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 1.150450954848297 | validation: 2.8399174317749867]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1875088507382385		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 1.1875088507382385 | validation: 2.8494199927364487]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.168393919850827		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 1.168393919850827 | validation: 2.9000939393263145]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1594690745165526		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 1.1594690745165526 | validation: 2.880561231991462]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.170540707764753		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 1.170540707764753 | validation: 2.842315366952006]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.147190069227418		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 1.147190069227418 | validation: 2.8459041758258032]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1503625143750555		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 1.1503625143750555 | validation: 2.8576687192630015]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1460802159827765		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 1.1460802159827765 | validation: 2.8641114033289417]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1466899437121745		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 1.1466899437121745 | validation: 2.8720199336403693]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1501152290026848		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 1.1501152290026848 | validation: 2.8328491906294575]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_1127.pth
	Model improved!!!
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1479411042894818		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 1.1479411042894818 | validation: 2.8487301570036356]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1461224852265628		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 1.1461224852265628 | validation: 2.8557450938806324]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1420417730172159		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 1.1420417730172159 | validation: 2.8707413425654478]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1551147052488002		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 1.1551147052488002 | validation: 2.8952848131192503]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.147974773850751		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 1.147974773850751 | validation: 2.886601903519536]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1594249415480715		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 1.1594249415480715 | validation: 2.8540011781502863]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1591330347980868		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 1.1591330347980868 | validation: 2.897543288562432]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.17302332753045		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 1.17302332753045 | validation: 2.9040136466474156]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.162609160021337		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 1.162609160021337 | validation: 2.84297219284365]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1550262070786785		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 1.1550262070786785 | validation: 2.878881257951156]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1694402062006306		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 1.1694402062006306 | validation: 2.860649305888151]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1486211520090777		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 1.1486211520090777 | validation: 2.844970621361944]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153967322083586		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 1.153967322083586 | validation: 2.891395812417709]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.225406501211641		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 1.225406501211641 | validation: 2.9365510346381023]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1702814088215432		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 1.1702814088215432 | validation: 2.858522813349619]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1495387725548112		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 1.1495387725548112 | validation: 2.904032561563294]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.158937601422434		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 1.158937601422434 | validation: 2.8421134320712564]
	TIME [epoch: 11.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1429939941285665		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 1.1429939941285665 | validation: 2.876423340047944]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.163189008291654		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 1.163189008291654 | validation: 2.846913828599919]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.166448943379212		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 1.166448943379212 | validation: 2.8567322727439395]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1506554907889184		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 1.1506554907889184 | validation: 2.844593502164819]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1432958724775868		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 1.1432958724775868 | validation: 2.876804603636536]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1604611092086456		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 1.1604611092086456 | validation: 2.8468334675842732]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154256915408199		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 1.154256915408199 | validation: 2.846524019671246]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1477369717471837		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 1.1477369717471837 | validation: 2.9062283317156417]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1569585657097443		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 1.1569585657097443 | validation: 2.84759563186284]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1465349188011396		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 1.1465349188011396 | validation: 2.867854081029858]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1579777519286814		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 1.1579777519286814 | validation: 2.9045642972945944]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.198397195415491		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 1.198397195415491 | validation: 2.855873197420554]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1564183776380996		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 1.1564183776380996 | validation: 2.8851802017912895]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.158065738128226		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 1.158065738128226 | validation: 2.8517984051080703]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1416612507296884		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 1.1416612507296884 | validation: 2.843591455212334]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1412186053167215		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 1.1412186053167215 | validation: 2.856646029395981]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.16359394041417		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 1.16359394041417 | validation: 2.8456324079450663]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1569272844934697		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 1.1569272844934697 | validation: 2.8923723910483012]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1577059225279456		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 1.1577059225279456 | validation: 2.854080954872169]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.151193570059457		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 1.151193570059457 | validation: 2.8815509444430503]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1696293964214102		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 1.1696293964214102 | validation: 2.89333870343394]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1770734844501043		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 1.1770734844501043 | validation: 2.875108713436723]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1587699814121986		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 1.1587699814121986 | validation: 2.8478589432701518]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1443664611749682		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 1.1443664611749682 | validation: 2.848090647649798]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1444301798710286		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 1.1444301798710286 | validation: 2.841303397465323]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1501527867195849		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 1.1501527867195849 | validation: 2.8402562657184807]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.149160179751401		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 1.149160179751401 | validation: 2.858601285356093]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1447814788082435		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 1.1447814788082435 | validation: 2.8703759647909304]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1490339988679703		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 1.1490339988679703 | validation: 2.8513710357000672]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1544814697376733		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 1.1544814697376733 | validation: 2.8445135146816565]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1491091318698508		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 1.1491091318698508 | validation: 2.860787382279875]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1492466105985695		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 1.1492466105985695 | validation: 2.8903269375727483]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1513031887240675		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 1.1513031887240675 | validation: 2.8656701888777305]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1454682426535399		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 1.1454682426535399 | validation: 2.861652798141663]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1543361303067934		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 1.1543361303067934 | validation: 2.8484919711823866]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1443381224698332		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 1.1443381224698332 | validation: 2.8483936701503003]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1481106283996216		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 1.1481106283996216 | validation: 2.857362272404726]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1480555424005014		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 1.1480555424005014 | validation: 2.8608095369897244]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1470592247780316		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 1.1470592247780316 | validation: 2.889301444529553]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1460562064908066		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 1.1460562064908066 | validation: 2.8441073631572635]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1453010388933176		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 1.1453010388933176 | validation: 2.8405072779216805]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1513772256205077		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 1.1513772256205077 | validation: 2.8488623163436855]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1545874876105382		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 1.1545874876105382 | validation: 2.874519849135035]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1568846445830738		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 1.1568846445830738 | validation: 2.8878597966365986]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.166843665923263		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 1.166843665923263 | validation: 2.90785568918148]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1654816712096765		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 1.1654816712096765 | validation: 2.8542156943378107]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.149725246997658		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 1.149725246997658 | validation: 2.86137240147476]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1503077439130434		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 1.1503077439130434 | validation: 2.8686747455550274]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1436759751075123		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 1.1436759751075123 | validation: 2.834720054714528]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1424449339565153		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 1.1424449339565153 | validation: 2.8588767092932783]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1519837727534148		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 1.1519837727534148 | validation: 2.850702999280502]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1391880035170916		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 1.1391880035170916 | validation: 2.851717616206877]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1431652760623836		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 1.1431652760623836 | validation: 2.84871430282232]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1495856135644276		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 1.1495856135644276 | validation: 2.8508404310867217]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1421282648261475		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 1.1421282648261475 | validation: 2.8602666414421654]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1453348485249242		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 1.1453348485249242 | validation: 2.840509670009266]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1852089919836661		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 1.1852089919836661 | validation: 2.8395830263515798]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1495802550961858		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 1.1495802550961858 | validation: 2.887801286147496]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1624664423270046		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 1.1624664423270046 | validation: 2.833365378775777]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1519765084209577		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 1.1519765084209577 | validation: 2.8459192639387814]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1417472421178028		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 1.1417472421178028 | validation: 2.8491590369303412]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1431378643451642		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 1.1431378643451642 | validation: 2.8459721934534388]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1562100507257136		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 1.1562100507257136 | validation: 2.846432083343421]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1550614614679042		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 1.1550614614679042 | validation: 2.8652013642264875]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1537786769128733		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 1.1537786769128733 | validation: 2.843215856565738]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.143950247144357		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 1.143950247144357 | validation: 2.870845360546117]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.14744693089404		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 1.14744693089404 | validation: 2.869624518779001]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1447908552314423		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 1.1447908552314423 | validation: 2.8450005529032047]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1436560949861578		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 1.1436560949861578 | validation: 2.8417481526463892]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1433801735604137		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 1.1433801735604137 | validation: 2.8393136803532526]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1446533362425404		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 1.1446533362425404 | validation: 2.8496167454678853]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1431376901953876		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 1.1431376901953876 | validation: 2.853284828728899]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.149650180187779		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 1.149650180187779 | validation: 2.863223943231148]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1466495471872877		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 1.1466495471872877 | validation: 2.8443483356505412]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1394502497872285		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 1.1394502497872285 | validation: 2.850124636804302]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1433993425315758		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 1.1433993425315758 | validation: 2.83421641796641]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1469054122770974		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 1.1469054122770974 | validation: 2.882737977342822]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1483555225543995		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 1.1483555225543995 | validation: 2.8377534540199636]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1512448968657376		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 1.1512448968657376 | validation: 2.8732845853718025]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1470303810851428		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 1.1470303810851428 | validation: 2.84183393582553]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1484648594008158		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 1.1484648594008158 | validation: 2.846994156081976]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1544035158101917		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 1.1544035158101917 | validation: 2.8427247281928096]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1446459873646977		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 1.1446459873646977 | validation: 2.842224455025098]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1688563330908526		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 1.1688563330908526 | validation: 2.838825113709896]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144261718406434		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 1.144261718406434 | validation: 2.8385427440560558]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1472645930813952		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 1.1472645930813952 | validation: 2.839758084726379]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1549557919853493		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 1.1549557919853493 | validation: 2.861952372376613]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1534648318164886		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 1.1534648318164886 | validation: 2.849399831744711]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1428003573669678		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 1.1428003573669678 | validation: 2.8393001293276496]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1485567338101723		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 1.1485567338101723 | validation: 2.848945819591403]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1443790105802727		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 1.1443790105802727 | validation: 2.857270566509826]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1363207483930753		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 1.1363207483930753 | validation: 2.8651401513793666]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1466625177395706		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 1.1466625177395706 | validation: 2.8452257474599656]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1446751432631477		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 1.1446751432631477 | validation: 2.853683748026828]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381247526468556		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 1.1381247526468556 | validation: 2.862941541262408]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1508913747572886		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 1.1508913747572886 | validation: 2.857557299220375]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1466387809605545		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 1.1466387809605545 | validation: 2.833036013378101]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153324715938623		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 1.153324715938623 | validation: 2.8477958327266104]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1430994320712953		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 1.1430994320712953 | validation: 2.849125483713876]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.14563237765913		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 1.14563237765913 | validation: 2.8418840530635174]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1484866355036516		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 1.1484866355036516 | validation: 2.852650461670403]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1570928319950076		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 1.1570928319950076 | validation: 2.840699262082591]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.160246574294865		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 1.160246574294865 | validation: 2.8368825166777247]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1524471940747312		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 1.1524471940747312 | validation: 2.9070323570569125]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.165903198471188		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 1.165903198471188 | validation: 2.8786410962035838]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1565867595518764		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 1.1565867595518764 | validation: 2.871789105661719]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1458507824844921		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 1.1458507824844921 | validation: 2.840014369498275]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381022664076688		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 1.1381022664076688 | validation: 2.8682510637115946]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1717506082042652		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 1.1717506082042652 | validation: 2.902367940229486]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1561916190136534		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 1.1561916190136534 | validation: 2.8825717209228547]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1550019318780507		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 1.1550019318780507 | validation: 2.85536728865898]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.145650313410346		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 1.145650313410346 | validation: 2.835610963985398]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1421482514478394		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 1.1421482514478394 | validation: 2.8518645747913527]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1510047573325115		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 1.1510047573325115 | validation: 2.944129755117118]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1905979603820165		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 1.1905979603820165 | validation: 2.8613502043571577]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1503089914085882		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 1.1503089914085882 | validation: 2.8674274003889697]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1432922824998144		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 1.1432922824998144 | validation: 2.862959290898293]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1448050252346875		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 1.1448050252346875 | validation: 2.885939846549117]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1512565570935314		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 1.1512565570935314 | validation: 2.862354481582861]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140887952440358		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 1.140887952440358 | validation: 2.865760332237151]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1478449973315432		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 1.1478449973315432 | validation: 2.891932555810693]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1530895386922053		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 1.1530895386922053 | validation: 2.858432496045281]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1477962208016577		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 1.1477962208016577 | validation: 2.8636570623048287]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1426162044791435		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 1.1426162044791435 | validation: 2.8553408505234428]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1481257443465211		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 1.1481257443465211 | validation: 2.8834936500109656]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1526630560230902		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 1.1526630560230902 | validation: 2.86075780967788]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1439829968588477		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 1.1439829968588477 | validation: 2.8486344710428546]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139394356060966		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 1.139394356060966 | validation: 2.8468724681843858]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1431448177835173		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 1.1431448177835173 | validation: 2.842064137481375]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1427761788283102		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 1.1427761788283102 | validation: 2.849152889565604]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1468700278173376		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 1.1468700278173376 | validation: 2.852888468534497]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1493585388268535		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 1.1493585388268535 | validation: 2.862613289309677]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1539111870187597		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 1.1539111870187597 | validation: 2.8557945938725227]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1449061809455348		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 1.1449061809455348 | validation: 2.840138268946084]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1433500763519837		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 1.1433500763519837 | validation: 2.8650110386452496]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.157937496717605		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 1.157937496717605 | validation: 2.8895775228214062]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1470405624293214		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 1.1470405624293214 | validation: 2.8516143924067503]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1419857128769315		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 1.1419857128769315 | validation: 2.848167899468231]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1475164616989182		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 1.1475164616989182 | validation: 2.882540617535846]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1556405086777688		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 1.1556405086777688 | validation: 2.8984224410096693]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1482685399117312		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 1.1482685399117312 | validation: 2.8381782416848482]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1425345462686782		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 1.1425345462686782 | validation: 2.8541463681611003]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1376084173656698		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 1.1376084173656698 | validation: 2.8636559177661947]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1427872383685922		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 1.1427872383685922 | validation: 2.84133000249131]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1506494777704623		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 1.1506494777704623 | validation: 2.8804300451686893]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1466405265164974		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 1.1466405265164974 | validation: 2.855624411044894]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140863501776205		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 1.140863501776205 | validation: 2.8473227789122206]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1410507956557696		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 1.1410507956557696 | validation: 2.8428466718225955]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1459356047946605		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 1.1459356047946605 | validation: 2.864486021576817]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1384107170352642		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 1.1384107170352642 | validation: 2.8447677500844333]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1512950961235635		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 1.1512950961235635 | validation: 2.9023893245353953]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1612349945622216		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 1.1612349945622216 | validation: 2.864534342349085]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1406770825597268		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 1.1406770825597268 | validation: 2.84282077045405]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1437886724189548		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 1.1437886724189548 | validation: 2.844377498928734]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139451170179137		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 1.139451170179137 | validation: 2.8600702694145923]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1452606216923606		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 1.1452606216923606 | validation: 2.836331277930699]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.143262558732252		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 1.143262558732252 | validation: 2.890893146808756]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.160973172923547		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 1.160973172923547 | validation: 2.910541641725971]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.169441718222791		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 1.169441718222791 | validation: 2.897516136038618]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1571784429108125		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 1.1571784429108125 | validation: 2.8453262186991295]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1416907166376542		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 1.1416907166376542 | validation: 2.826355767663192]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240310_044559/states/model_tr_study203_1305.pth
	Model improved!!!
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.147903013699739		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 1.147903013699739 | validation: 2.849684979921124]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1412525056095486		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 1.1412525056095486 | validation: 2.8449063328616946]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1560740829802336		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 1.1560740829802336 | validation: 2.846325212218766]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142995885441389		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 1.142995885441389 | validation: 2.8740295685299877]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1509563961962805		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 1.1509563961962805 | validation: 2.8660144366090274]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142948600044764		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 1.142948600044764 | validation: 2.8408500440023263]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1474215677680302		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 1.1474215677680302 | validation: 2.870932002580038]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.152404378640194		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 1.152404378640194 | validation: 2.8628653683296217]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423045200971451		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 1.1423045200971451 | validation: 2.8479659345835056]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1433443438939774		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 1.1433443438939774 | validation: 2.8398681507140804]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1407355539651758		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 1.1407355539651758 | validation: 2.8539786815170545]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144119144908538		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 1.144119144908538 | validation: 2.8455415931029133]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141802339496737		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 1.141802339496737 | validation: 2.8466716994629917]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423411835160673		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 1.1423411835160673 | validation: 2.843345472178415]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1554337239133723		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 1.1554337239133723 | validation: 2.8429095152166246]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1493354614501583		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 1.1493354614501583 | validation: 2.850625144414018]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423134272136106		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 1.1423134272136106 | validation: 2.8487512481602546]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1349285040372505		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 1.1349285040372505 | validation: 2.8576359963679225]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1419515675620178		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 1.1419515675620178 | validation: 2.885578966903139]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.152871845962756		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 1.152871845962756 | validation: 2.852756221030751]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1376506999434628		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 1.1376506999434628 | validation: 2.8505098304377303]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1505411675407793		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 1.1505411675407793 | validation: 2.874008388885756]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1424236313264229		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 1.1424236313264229 | validation: 2.844965885339209]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423734223328812		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 1.1423734223328812 | validation: 2.8507911563610446]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.148881813015392		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 1.148881813015392 | validation: 2.8624718931436237]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1456932662343755		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 1.1456932662343755 | validation: 2.849346621810275]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1434449467127168		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 1.1434449467127168 | validation: 2.8656141085304503]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1428791105396476		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 1.1428791105396476 | validation: 2.8792315745979837]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141484947726524		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 1.141484947726524 | validation: 2.861157271973823]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1394130978425865		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 1.1394130978425865 | validation: 2.856493381823512]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1438338231555858		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 1.1438338231555858 | validation: 2.854954755911033]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141606713060201		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 1.141606713060201 | validation: 2.8615683361922755]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1640576544365382		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 1.1640576544365382 | validation: 2.8608031013708994]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142698144453857		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 1.142698144453857 | validation: 2.8500120491282654]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1393289264641766		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 1.1393289264641766 | validation: 2.8600746507689263]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146776829827828		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 1.146776829827828 | validation: 2.8802317701232174]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1427238352659859		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 1.1427238352659859 | validation: 2.8428765139571146]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142699923516525		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 1.142699923516525 | validation: 2.8521125101774993]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1454332395290407		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 1.1454332395290407 | validation: 2.8709324556694504]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1503766497089447		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 1.1503766497089447 | validation: 2.88561393192395]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1448371877386891		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 1.1448371877386891 | validation: 2.877324129947543]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1505895317823953		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 1.1505895317823953 | validation: 2.847924656914691]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1436638115120774		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 1.1436638115120774 | validation: 2.8496081835184763]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1447613868258792		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 1.1447613868258792 | validation: 2.853193320208597]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1408111748173047		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 1.1408111748173047 | validation: 2.865383185348167]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1445125857702585		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 1.1445125857702585 | validation: 2.870848543446182]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1455135808040422		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 1.1455135808040422 | validation: 2.856540283242067]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1440818824345982		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 1.1440818824345982 | validation: 2.8712641034995907]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.14270751685674		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 1.14270751685674 | validation: 2.853426173088295]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140195688715341		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 1.140195688715341 | validation: 2.8548773554768925]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1546896109028602		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 1.1546896109028602 | validation: 2.8827898428575667]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1540475995811736		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 1.1540475995811736 | validation: 2.8781237982234416]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1556864663700275		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 1.1556864663700275 | validation: 2.9106788109850283]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1620600587954488		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 1.1620600587954488 | validation: 2.861317763896107]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136627692051296		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 1.136627692051296 | validation: 2.8448603583008008]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1398669569811652		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 1.1398669569811652 | validation: 2.859568527821168]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1406823746205648		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 1.1406823746205648 | validation: 2.8484262068450086]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1462867191283754		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 1.1462867191283754 | validation: 2.848707940271087]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1444881232982733		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 1.1444881232982733 | validation: 2.8453005469271075]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1430794664962518		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 1.1430794664962518 | validation: 2.8403578032638093]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1586796078703334		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 1.1586796078703334 | validation: 2.841675346352496]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141250731869974		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 1.141250731869974 | validation: 2.841537216828742]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1402474067665322		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 1.1402474067665322 | validation: 2.8501850616953157]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1401261475696005		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 1.1401261475696005 | validation: 2.851155281542926]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1470777844832554		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 1.1470777844832554 | validation: 2.852995167281221]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1473043148097601		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 1.1473043148097601 | validation: 2.8456254283040243]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1452522428071172		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 1.1452522428071172 | validation: 2.865202058402677]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1481680059834598		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 1.1481680059834598 | validation: 2.849597440929851]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.143132785409122		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 1.143132785409122 | validation: 2.834878212354311]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142945117798372		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 1.142945117798372 | validation: 2.847155276802795]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140041417029477		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 1.140041417029477 | validation: 2.8397424855338977]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423974525828848		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 1.1423974525828848 | validation: 2.8571430768518935]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142691619222754		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 1.142691619222754 | validation: 2.8761012655489866]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1498329269754919		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 1.1498329269754919 | validation: 2.886799373441686]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1498670325541378		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 1.1498670325541378 | validation: 2.884376671219343]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.172621174333138		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 1.172621174333138 | validation: 2.861921778519047]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1411776121245745		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 1.1411776121245745 | validation: 2.865921720718571]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.151498623025009		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 1.151498623025009 | validation: 2.858202158865517]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140820122654519		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 1.140820122654519 | validation: 2.8403138316848096]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1583140537041767		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 1.1583140537041767 | validation: 2.8527229545706025]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1580500382107606		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 1.1580500382107606 | validation: 2.838866627704074]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1395695776091677		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 1.1395695776091677 | validation: 2.8717043481245206]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1404931312531268		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 1.1404931312531268 | validation: 2.85416044985745]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1411938838594036		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 1.1411938838594036 | validation: 2.8497513197153728]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140893578740222		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 1.140893578740222 | validation: 2.8389731112082552]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1330630723169124		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 1.1330630723169124 | validation: 2.852791502215111]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1424054639412942		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 1.1424054639412942 | validation: 2.859696537441504]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144879762727155		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 1.144879762727155 | validation: 2.8464682871949676]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1400473482785358		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 1.1400473482785358 | validation: 2.8560824955543014]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1446417036436745		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 1.1446417036436745 | validation: 2.8449972294662302]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1397981002253603		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 1.1397981002253603 | validation: 2.853843929064862]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142339797933813		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 1.142339797933813 | validation: 2.8416309594321087]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142407944553475		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 1.142407944553475 | validation: 2.865359938763736]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1506142019149799		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 1.1506142019149799 | validation: 2.868508984512912]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1409201731418166		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 1.1409201731418166 | validation: 2.8434372187146835]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137543235352767		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 1.137543235352767 | validation: 2.8602064857694063]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1519621264016444		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 1.1519621264016444 | validation: 2.860954986711992]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1410886119986565		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 1.1410886119986565 | validation: 2.8395330320153547]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139412918168309		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 1.139412918168309 | validation: 2.8592666610669766]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1368531277161067		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 1.1368531277161067 | validation: 2.8599844157815855]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1443333862031557		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 1.1443333862031557 | validation: 2.8777405667420806]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423300852731235		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 1.1423300852731235 | validation: 2.8731018570563913]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153156866073643		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 1.153156866073643 | validation: 2.8594404254129313]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364699002276226		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 1.1364699002276226 | validation: 2.842403532526347]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1470546096572818		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 1.1470546096572818 | validation: 2.8441790934880213]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1410822846661104		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 1.1410822846661104 | validation: 2.842241734716333]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1490760019346087		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 1.1490760019346087 | validation: 2.8354672411285176]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1454033903478031		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 1.1454033903478031 | validation: 2.8550824567809054]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1492310853928032		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 1.1492310853928032 | validation: 2.8447675899788307]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1406198480630747		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 1.1406198480630747 | validation: 2.851009557344932]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137578298013002		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 1.137578298013002 | validation: 2.85907074230495]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1425231922914434		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 1.1425231922914434 | validation: 2.871799748758722]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1484560511966686		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 1.1484560511966686 | validation: 2.885158311680759]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.158345736117538		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 1.158345736117538 | validation: 2.8757471061292295]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1421510892885194		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 1.1421510892885194 | validation: 2.849697976987888]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.145987317520124		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 1.145987317520124 | validation: 2.8484795645278878]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1414319085654703		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 1.1414319085654703 | validation: 2.837917605429124]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142705045831244		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 1.142705045831244 | validation: 2.8362226129613686]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1502784353773396		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 1.1502784353773396 | validation: 2.850131008932526]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1430948860946628		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 1.1430948860946628 | validation: 2.8536660110434826]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1425057250403827		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 1.1425057250403827 | validation: 2.8467199584060583]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1393604553084913		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 1.1393604553084913 | validation: 2.847593056797291]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1438840093616913		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 1.1438840093616913 | validation: 2.835725042610949]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1415563160864055		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 1.1415563160864055 | validation: 2.84774157490797]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137668822228421		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 1.137668822228421 | validation: 2.844332194199115]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139135404240841		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 1.139135404240841 | validation: 2.855317829172343]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423492725965343		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 1.1423492725965343 | validation: 2.871783617429867]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1490029359471752		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 1.1490029359471752 | validation: 2.8531885890480293]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1475732252209367		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 1.1475732252209367 | validation: 2.8554313718720197]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1394770978055524		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 1.1394770978055524 | validation: 2.8587954935983566]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1355544177768293		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 1.1355544177768293 | validation: 2.8485399923595986]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1385326760431096		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 1.1385326760431096 | validation: 2.8402617705369506]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137509000622976		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 1.137509000622976 | validation: 2.8527061708893062]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1407904675467555		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 1.1407904675467555 | validation: 2.844968141731227]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.145007111425491		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 1.145007111425491 | validation: 2.833329823865345]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1407202005616945		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 1.1407202005616945 | validation: 2.857535969863284]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381122819758103		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 1.1381122819758103 | validation: 2.851716543746525]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1416213084350249		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 1.1416213084350249 | validation: 2.8730447455227432]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1445554812842367		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 1.1445554812842367 | validation: 2.8536987412895867]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136843020255721		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 1.136843020255721 | validation: 2.8453669629321308]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142900511940157		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 1.142900511940157 | validation: 2.835510226072821]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.14429699935669		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 1.14429699935669 | validation: 2.83757800302833]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1452427218166006		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 1.1452427218166006 | validation: 2.849137819910721]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140257483410413		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 1.140257483410413 | validation: 2.8382872287604797]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1439155694536574		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 1.1439155694536574 | validation: 2.839379909059901]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1404740232068311		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 1.1404740232068311 | validation: 2.8653475286824555]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1440277932702838		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 1.1440277932702838 | validation: 2.842989649878316]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423308962418424		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 1.1423308962418424 | validation: 2.8409363937276755]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1375976245745567		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 1.1375976245745567 | validation: 2.8467802534769224]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1380609513292355		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 1.1380609513292355 | validation: 2.8648031381226406]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1456180419997555		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 1.1456180419997555 | validation: 2.840570854502786]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1476210092377495		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 1.1476210092377495 | validation: 2.84172531916143]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1495875560016466		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 1.1495875560016466 | validation: 2.840877078020824]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1473213992122915		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 1.1473213992122915 | validation: 2.8384802068578745]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1519261899047175		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 1.1519261899047175 | validation: 2.8337544359784728]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1456417120557738		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 1.1456417120557738 | validation: 2.8511604317166594]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138523808305293		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 1.138523808305293 | validation: 2.8610866878494425]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1405626203098083		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 1.1405626203098083 | validation: 2.8545980848784627]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1407575358845388		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 1.1407575358845388 | validation: 2.854883346687536]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1344804414835596		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 1.1344804414835596 | validation: 2.8614273899376736]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1426716042567606		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 1.1426716042567606 | validation: 2.838429020893051]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1445312474959721		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 1.1445312474959721 | validation: 2.834306390235637]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.143049650044932		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 1.143049650044932 | validation: 2.8524936182344005]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1418795732280589		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 1.1418795732280589 | validation: 2.8597559741056613]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140183534015367		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 1.140183534015367 | validation: 2.8532567799510913]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140963676232457		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 1.140963676232457 | validation: 2.862561182507473]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1439933547056294		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 1.1439933547056294 | validation: 2.843008738439256]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.143881058856641		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 1.143881058856641 | validation: 2.847910405390538]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1408783474124125		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 1.1408783474124125 | validation: 2.8686256295216435]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150221784858848		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 1.150221784858848 | validation: 2.8547673705225796]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142220123200554		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 1.142220123200554 | validation: 2.8504454905066736]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1431858881140007		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 1.1431858881140007 | validation: 2.846954855881069]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1416347877629172		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 1.1416347877629172 | validation: 2.8492869577338844]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1420014776092486		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 1.1420014776092486 | validation: 2.850650497497902]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1430771661695032		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 1.1430771661695032 | validation: 2.855607817692053]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1461988901321896		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 1.1461988901321896 | validation: 2.850435813695605]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1501562436826358		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 1.1501562436826358 | validation: 2.8654555800754378]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1532773565604137		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 1.1532773565604137 | validation: 2.861783919000499]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1449034150113595		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 1.1449034150113595 | validation: 2.857613031734811]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1383198512457686		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 1.1383198512457686 | validation: 2.8422241348521893]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1349461577983257		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 1.1349461577983257 | validation: 2.851603465374671]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1454541689176123		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 1.1454541689176123 | validation: 2.8523422166841734]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1451684886079168		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 1.1451684886079168 | validation: 2.858864880622188]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141748502641899		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 1.141748502641899 | validation: 2.8550887534034426]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142747978067791		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 1.142747978067791 | validation: 2.856587748568462]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1429438380121602		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 1.1429438380121602 | validation: 2.8364922427451775]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1451751669188284		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 1.1451751669188284 | validation: 2.8410134931846533]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1373466358967486		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 1.1373466358967486 | validation: 2.8498390289205577]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1392845624889305		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 1.1392845624889305 | validation: 2.85321214021787]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.133737725879151		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 1.133737725879151 | validation: 2.85437184036686]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1417465500165784		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 1.1417465500165784 | validation: 2.8462213110204697]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1352651561086486		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 1.1352651561086486 | validation: 2.8559021058587644]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1387915997395446		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 1.1387915997395446 | validation: 2.839056771585751]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1461411800927146		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 1.1461411800927146 | validation: 2.8351868404728986]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1434961376467172		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 1.1434961376467172 | validation: 2.856429919744635]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1415007091126945		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 1.1415007091126945 | validation: 2.8598847356863097]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140033381456481		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 1.140033381456481 | validation: 2.8449480974901302]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1383487817339386		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 1.1383487817339386 | validation: 2.8486597607007655]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1395137709611327		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 1.1395137709611327 | validation: 2.850736611279814]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1393361636972386		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 1.1393361636972386 | validation: 2.8422709524388337]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1440755790374313		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 1.1440755790374313 | validation: 2.8454848161126125]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1471851571550868		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 1.1471851571550868 | validation: 2.8482079939204135]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1357124107269265		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 1.1357124107269265 | validation: 2.8539219821790303]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138049652265008		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 1.138049652265008 | validation: 2.8557043050654074]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1378333925678978		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 1.1378333925678978 | validation: 2.8467334513690856]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1357968184747869		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 1.1357968184747869 | validation: 2.8460531080191336]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1369677103038929		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 1.1369677103038929 | validation: 2.8470285746565804]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1374607301852446		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 1.1374607301852446 | validation: 2.844928798026081]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1419152900704204		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 1.1419152900704204 | validation: 2.8554133746597308]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1386441067188473		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 1.1386441067188473 | validation: 2.8554496931796542]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1386165041835066		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 1.1386165041835066 | validation: 2.85160322011254]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141037027755312		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 1.141037027755312 | validation: 2.8463169448844616]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1361086403353666		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 1.1361086403353666 | validation: 2.853249978598843]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1369594906333946		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 1.1369594906333946 | validation: 2.840622684919731]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1395008445103074		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 1.1395008445103074 | validation: 2.843677901336261]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1433946667453863		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 1.1433946667453863 | validation: 2.8347286352884558]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1375458084651315		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 1.1375458084651315 | validation: 2.8363735748757803]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1383003981145972		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 1.1383003981145972 | validation: 2.844733933083384]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1345591588637103		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 1.1345591588637103 | validation: 2.851308978997339]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1376574210899233		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 1.1376574210899233 | validation: 2.8515067892212023]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1403082914018503		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 1.1403082914018503 | validation: 2.852149029543115]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13841570310555		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 1.13841570310555 | validation: 2.864882692759897]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1473384607628858		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 1.1473384607628858 | validation: 2.8557171701793562]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1355217591437654		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 1.1355217591437654 | validation: 2.8462583479888286]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1373010659351315		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 1.1373010659351315 | validation: 2.841777873690193]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.14101547739111		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 1.14101547739111 | validation: 2.8489651213371032]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1385163502874551		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 1.1385163502874551 | validation: 2.8528950853865855]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139106808091146		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 1.139106808091146 | validation: 2.8539537833324213]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1436901389675909		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 1.1436901389675909 | validation: 2.851064927809948]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1428168023079297		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 1.1428168023079297 | validation: 2.8645857612867336]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1417034064990426		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 1.1417034064990426 | validation: 2.8496880951043044]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1394018923652196		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 1.1394018923652196 | validation: 2.8490389356683647]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137810745076972		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 1.137810745076972 | validation: 2.8521825977273108]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136228571557166		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 1.136228571557166 | validation: 2.8456391483530514]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1410283425093621		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 1.1410283425093621 | validation: 2.8376134811924376]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1410927966636364		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 1.1410927966636364 | validation: 2.8345114143911836]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1422143792288102		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 1.1422143792288102 | validation: 2.844689706527672]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.145317220305678		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 1.145317220305678 | validation: 2.8444855052259084]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1387963780759451		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 1.1387963780759451 | validation: 2.8499128751307694]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137264066088061		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 1.137264066088061 | validation: 2.8530704829925684]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1416812442503412		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 1.1416812442503412 | validation: 2.8509028213290937]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1421699235042109		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 1.1421699235042109 | validation: 2.838677834043098]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1371947120453179		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 1.1371947120453179 | validation: 2.850955664552338]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1406047067460383		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 1.1406047067460383 | validation: 2.8507237764902986]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140362109939998		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 1.140362109939998 | validation: 2.856257118589546]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1388678289477818		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 1.1388678289477818 | validation: 2.841167146367645]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1393036924476851		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 1.1393036924476851 | validation: 2.843183398272127]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1375555540345874		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 1.1375555540345874 | validation: 2.839328823479654]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1414342291001816		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 1.1414342291001816 | validation: 2.8544300461976047]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138498290952124		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 1.138498290952124 | validation: 2.8424935216081826]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1487039393316008		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 1.1487039393316008 | validation: 2.840147772848184]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142361968542424		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 1.142361968542424 | validation: 2.8447869258206975]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1387998701445552		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 1.1387998701445552 | validation: 2.8606718644555067]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1421809356192263		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 1.1421809356192263 | validation: 2.8479191417562904]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1377934532908238		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 1.1377934532908238 | validation: 2.846390436845303]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1370632969556738		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 1.1370632969556738 | validation: 2.8369388379972493]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144176023591031		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 1.144176023591031 | validation: 2.8321998669837085]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1370164408936096		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 1.1370164408936096 | validation: 2.8494016744609634]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.143276554950624		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 1.143276554950624 | validation: 2.849584688264509]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1383608935636809		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 1.1383608935636809 | validation: 2.8413693233211474]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1379202726730142		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 1.1379202726730142 | validation: 2.861268305051392]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1394886741198045		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 1.1394886741198045 | validation: 2.8666058207688576]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1405807733324598		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 1.1405807733324598 | validation: 2.8659670165510227]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1443641277785013		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 1.1443641277785013 | validation: 2.844693878975886]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1350927910658022		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 1.1350927910658022 | validation: 2.846433565172038]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1390482535864734		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 1.1390482535864734 | validation: 2.8501584219268783]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1400481516370617		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 1.1400481516370617 | validation: 2.862149101801632]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1360459403272234		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 1.1360459403272234 | validation: 2.8649247366732493]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1392846488864417		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 1.1392846488864417 | validation: 2.845345475598724]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135603644867536		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 1.135603644867536 | validation: 2.8458626893848384]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136967279216672		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 1.136967279216672 | validation: 2.8595688695558557]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1428328360516975		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 1.1428328360516975 | validation: 2.867920258191186]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1427684421470246		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 1.1427684421470246 | validation: 2.84944556491508]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1371840454377802		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 1.1371840454377802 | validation: 2.852959189241125]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1356561059609722		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 1.1356561059609722 | validation: 2.856095036695375]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1386976186504827		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 1.1386976186504827 | validation: 2.8477717368999946]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13622530166531		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 1.13622530166531 | validation: 2.8460186733961814]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1378636761805472		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 1.1378636761805472 | validation: 2.8522044857248043]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1378110389000033		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 1.1378110389000033 | validation: 2.8499221931102046]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1353106903273653		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 1.1353106903273653 | validation: 2.8413148611112367]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1413296633648529		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 1.1413296633648529 | validation: 2.836755492100019]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1400836983328366		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 1.1400836983328366 | validation: 2.8476691239404914]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1393570979160474		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 1.1393570979160474 | validation: 2.844172949401446]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1356849310422277		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 1.1356849310422277 | validation: 2.84625929665033]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1361831136497733		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 1.1361831136497733 | validation: 2.8445412259738316]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381664387835775		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 1.1381664387835775 | validation: 2.8366425351616615]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1417716035441239		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 1.1417716035441239 | validation: 2.850244693664532]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1400288377826469		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 1.1400288377826469 | validation: 2.844766893383943]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1369948840650297		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 1.1369948840650297 | validation: 2.84581971019652]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1377140899467526		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 1.1377140899467526 | validation: 2.8413662436268554]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1406429470467088		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 1.1406429470467088 | validation: 2.844256993575866]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1386763203304269		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 1.1386763203304269 | validation: 2.835704018825641]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1464103919716888		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 1.1464103919716888 | validation: 2.8410285828514725]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1491629066643707		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 1.1491629066643707 | validation: 2.8348375179172547]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1440922403878433		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 1.1440922403878433 | validation: 2.8418956407000087]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1394710544427042		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 1.1394710544427042 | validation: 2.8402685755784605]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135496482847949		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 1.135496482847949 | validation: 2.8433737398352723]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1388981222394579		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 1.1388981222394579 | validation: 2.8366681216288665]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423774115684595		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 1.1423774115684595 | validation: 2.835149314236702]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1367515849520915		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 1.1367515849520915 | validation: 2.848220986398797]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138585291586568		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 1.138585291586568 | validation: 2.8367542001623525]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1374744316402536		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 1.1374744316402536 | validation: 2.8407389387442783]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1361338531079548		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 1.1361338531079548 | validation: 2.8393955724526325]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1417762124017592		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 1.1417762124017592 | validation: 2.8467922113672888]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1384683527871866		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 1.1384683527871866 | validation: 2.8361247384142976]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1393974480182194		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 1.1393974480182194 | validation: 2.8491800202675974]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1405202882801493		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 1.1405202882801493 | validation: 2.84336352375342]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1401120260191289		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 1.1401120260191289 | validation: 2.842445806087823]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1350196484449302		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 1.1350196484449302 | validation: 2.8544026080620872]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1389490862712621		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 1.1389490862712621 | validation: 2.8487521000743645]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137943147122868		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 1.137943147122868 | validation: 2.845492799390853]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141495926793966		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 1.141495926793966 | validation: 2.8500819243207607]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1394873302272952		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 1.1394873302272952 | validation: 2.834278944045822]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1352671929675342		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 1.1352671929675342 | validation: 2.837715365404404]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.134302919788567		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 1.134302919788567 | validation: 2.840764572567508]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1422168301945927		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 1.1422168301945927 | validation: 2.8383846306182523]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1355743434475447		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 1.1355743434475447 | validation: 2.8446689162463885]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1397425159434442		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 1.1397425159434442 | validation: 2.843681713688169]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1365541823276752		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 1.1365541823276752 | validation: 2.85696507116803]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1430464049215616		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 1.1430464049215616 | validation: 2.8481343644271346]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.134760196622047		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 1.134760196622047 | validation: 2.8545591823671157]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1391798756505715		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 1.1391798756505715 | validation: 2.8556649944382353]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1402306489399336		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 1.1402306489399336 | validation: 2.8461522446661514]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1348965270863003		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 1.1348965270863003 | validation: 2.849284631815464]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1450145149894835		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 1.1450145149894835 | validation: 2.862951970357447]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1414969504210166		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 1.1414969504210166 | validation: 2.8513675581526523]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.132636481192052		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 1.132636481192052 | validation: 2.845360567896104]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1391263464694403		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 1.1391263464694403 | validation: 2.8559218552157537]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.145808649313021		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 1.145808649313021 | validation: 2.8578256462857268]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142583378532827		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 1.142583378532827 | validation: 2.8691961190536435]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1410371078382138		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 1.1410371078382138 | validation: 2.859031062757938]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1390133969120624		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 1.1390133969120624 | validation: 2.85688129732272]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1397790271762762		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 1.1397790271762762 | validation: 2.855020582559886]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1400790616143621		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 1.1400790616143621 | validation: 2.8683146802484725]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1408863094555604		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 1.1408863094555604 | validation: 2.8482620254794018]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1413752836515845		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 1.1413752836515845 | validation: 2.8538941205297]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.15012284017897		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 1.15012284017897 | validation: 2.8618321803953255]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1429771646115385		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 1.1429771646115385 | validation: 2.846082789665286]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1402736646152642		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 1.1402736646152642 | validation: 2.843165173895153]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1392772324295781		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 1.1392772324295781 | validation: 2.8369693008463477]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137554299723591		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 1.137554299723591 | validation: 2.8518656432722356]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1360253601695818		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 1.1360253601695818 | validation: 2.8529734182328172]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1353438787776875		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 1.1353438787776875 | validation: 2.8499189599258745]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137339443166247		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 1.137339443166247 | validation: 2.8358000301909083]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1474443659021953		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 1.1474443659021953 | validation: 2.832887670926956]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1386141758949546		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 1.1386141758949546 | validation: 2.848020489316434]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1387197086381056		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 1.1387197086381056 | validation: 2.8329655980796487]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381243149866866		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 1.1381243149866866 | validation: 2.842072079814269]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141449890570292		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 1.141449890570292 | validation: 2.8380646908577867]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1437724398943352		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 1.1437724398943352 | validation: 2.8410736738749907]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1399515847412984		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 1.1399515847412984 | validation: 2.839616908333102]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1403114222094652		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 1.1403114222094652 | validation: 2.8520492735468874]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1374990860935912		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 1.1374990860935912 | validation: 2.86060042589303]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1395536096550931		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 1.1395536096550931 | validation: 2.851006291781006]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1380521112446331		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 1.1380521112446331 | validation: 2.8480740426094884]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1405513509552856		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 1.1405513509552856 | validation: 2.8441755425409623]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1400480111047298		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 1.1400480111047298 | validation: 2.842769876345173]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1323350893584552		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 1.1323350893584552 | validation: 2.8509369372298448]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1337817499466394		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 1.1337817499466394 | validation: 2.857316004764275]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138134268225732		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 1.138134268225732 | validation: 2.859256671557289]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1323697190046094		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 1.1323697190046094 | validation: 2.8377315551219686]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1379557632257888		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 1.1379557632257888 | validation: 2.8632260199499058]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1383074526818011		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 1.1383074526818011 | validation: 2.8538025289471274]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1385737574451997		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 1.1385737574451997 | validation: 2.8383837114940804]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1481566224793518		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 1.1481566224793518 | validation: 2.8388603807868926]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1421789761992325		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 1.1421789761992325 | validation: 2.844657500979506]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1376075822587397		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 1.1376075822587397 | validation: 2.844077891330999]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1419306563306961		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 1.1419306563306961 | validation: 2.8596180851752386]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1384412176422667		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 1.1384412176422667 | validation: 2.854803279965156]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1379364863790307		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 1.1379364863790307 | validation: 2.8488792809515844]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1371022971211433		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 1.1371022971211433 | validation: 2.8494190108444135]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139652011751868		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 1.139652011751868 | validation: 2.845832591770437]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1371064458654376		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 1.1371064458654376 | validation: 2.856619752747217]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1407770205327818		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 1.1407770205327818 | validation: 2.8688954351432416]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1405762908131198		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 1.1405762908131198 | validation: 2.8644561532536783]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1390483895719918		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 1.1390483895719918 | validation: 2.8466406190516405]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1365205608025775		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 1.1365205608025775 | validation: 2.845502867879874]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139326877986024		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 1.139326877986024 | validation: 2.8576925585822632]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140200799260886		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 1.140200799260886 | validation: 2.845486725423559]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1387824224074004		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 1.1387824224074004 | validation: 2.851825150959696]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1393357663164072		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 1.1393357663164072 | validation: 2.8494478762687643]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1343942681897226		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 1.1343942681897226 | validation: 2.8474709093623938]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1369711386340446		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 1.1369711386340446 | validation: 2.847719758059726]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1362910888209468		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 1.1362910888209468 | validation: 2.845088752220868]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1327830056814459		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 1.1327830056814459 | validation: 2.846259101413487]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1377966874697336		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 1.1377966874697336 | validation: 2.847845661003888]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1396385809991108		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 1.1396385809991108 | validation: 2.842265323630223]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364947364164089		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 1.1364947364164089 | validation: 2.8468329415430094]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1377716264029953		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 1.1377716264029953 | validation: 2.849534171770042]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1390843212511972		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 1.1390843212511972 | validation: 2.8558459425706646]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381932578532248		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 1.1381932578532248 | validation: 2.8492379182319825]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1373951830599642		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 1.1373951830599642 | validation: 2.852032754666821]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137643579441764		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 1.137643579441764 | validation: 2.861418757492022]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136211983598101		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 1.136211983598101 | validation: 2.8486840399771016]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1332725698195683		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 1.1332725698195683 | validation: 2.8529690523391116]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1358881909280223		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 1.1358881909280223 | validation: 2.8554565929881415]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1398938726397094		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 1.1398938726397094 | validation: 2.861393113976064]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1384273144928765		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 1.1384273144928765 | validation: 2.860483315951609]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139019060113672		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 1.139019060113672 | validation: 2.845896395573532]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1371352631484133		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 1.1371352631484133 | validation: 2.855959884192623]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1363977672199617		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 1.1363977672199617 | validation: 2.8471993131225886]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138666846379317		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 1.138666846379317 | validation: 2.850313086961492]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1387831412248868		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 1.1387831412248868 | validation: 2.843123831966104]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1362936705211117		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 1.1362936705211117 | validation: 2.847214278425864]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1375750121169341		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 1.1375750121169341 | validation: 2.851785021435768]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136382607764494		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 1.136382607764494 | validation: 2.8582048345257873]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1350828742888452		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 1.1350828742888452 | validation: 2.8494299970765917]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1388642996277196		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 1.1388642996277196 | validation: 2.8477886808950497]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1362974495374236		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 1.1362974495374236 | validation: 2.8453802570126414]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1361189386241397		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 1.1361189386241397 | validation: 2.8461662342438956]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1339956096856794		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 1.1339956096856794 | validation: 2.850887247455444]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1354893845613336		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 1.1354893845613336 | validation: 2.8586919714840917]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1409544227536959		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 1.1409544227536959 | validation: 2.8543609996746024]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1397022503896748		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 1.1397022503896748 | validation: 2.855476048485341]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1478370835634863		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 1.1478370835634863 | validation: 2.850226681155206]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1394457095306596		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 1.1394457095306596 | validation: 2.849528312532525]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1386633008397984		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 1.1386633008397984 | validation: 2.849904736089197]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1349886307934511		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 1.1349886307934511 | validation: 2.8394125685349785]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1378988037068858		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 1.1378988037068858 | validation: 2.8460455169980885]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1352595862870274		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 1.1352595862870274 | validation: 2.840525048090036]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1392953025004793		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 1.1392953025004793 | validation: 2.839121944039815]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1386269239026288		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 1.1386269239026288 | validation: 2.836942736459157]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138873472469057		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 1.138873472469057 | validation: 2.851291431815788]
	TIME [epoch: 11.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1357837340438623		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 1.1357837340438623 | validation: 2.84090691728995]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1343260311089514		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 1.1343260311089514 | validation: 2.844497833668675]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1358002596075765		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 1.1358002596075765 | validation: 2.8462305693164316]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1418070041849022		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 1.1418070041849022 | validation: 2.8558411434703443]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1351077693532887		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 1.1351077693532887 | validation: 2.8450072023150024]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1383449679126505		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 1.1383449679126505 | validation: 2.848577411115907]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1335916076091215		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 1.1335916076091215 | validation: 2.854795592737166]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139066983213591		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 1.139066983213591 | validation: 2.8537303028324943]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1358070174657666		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 1.1358070174657666 | validation: 2.8623075206216186]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1341815458413158		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 1.1341815458413158 | validation: 2.84998535161411]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1368584935098347		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 1.1368584935098347 | validation: 2.842174539484639]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1410882227652501		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 1.1410882227652501 | validation: 2.84823935901743]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1437055107850207		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 1.1437055107850207 | validation: 2.852402712340736]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1406116664805148		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 1.1406116664805148 | validation: 2.8546388396961446]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1382143844095853		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 1.1382143844095853 | validation: 2.858553762726197]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1398430964662563		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 1.1398430964662563 | validation: 2.869533564799219]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423798821194775		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 1.1423798821194775 | validation: 2.8610759065801687]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1380389887141864		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 1.1380389887141864 | validation: 2.8547415960281843]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1375104801581908		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 1.1375104801581908 | validation: 2.854202408589814]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1410343433502483		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 1.1410343433502483 | validation: 2.8395139881861917]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1376278253366081		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 1.1376278253366081 | validation: 2.8468598951710526]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381077582863641		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 1.1381077582863641 | validation: 2.8495159602699487]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1380374197046539		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 1.1380374197046539 | validation: 2.8431920584596244]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142414398511403		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 1.142414398511403 | validation: 2.8344881387911425]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1377944680182692		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 1.1377944680182692 | validation: 2.846852199717563]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1406763653292613		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 1.1406763653292613 | validation: 2.83745867361337]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1353408192339571		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 1.1353408192339571 | validation: 2.8470488758048327]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1398377436424707		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 1.1398377436424707 | validation: 2.8529280741623153]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1404795761516944		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 1.1404795761516944 | validation: 2.8572760617481077]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1433963626336878		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 1.1433963626336878 | validation: 2.8471323228444]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.147384027980544		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 1.147384027980544 | validation: 2.8563897483898137]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142308040321702		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 1.142308040321702 | validation: 2.8637662921334015]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135798760985121		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 1.135798760985121 | validation: 2.8511029631503666]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.134336467751456		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 1.134336467751456 | validation: 2.8549580400501204]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1343252700921853		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 1.1343252700921853 | validation: 2.8494649151966582]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1323169859567184		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 1.1323169859567184 | validation: 2.8526367830495203]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139572371472907		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 1.139572371472907 | validation: 2.8406224669647657]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1372599763768274		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 1.1372599763768274 | validation: 2.843962090313894]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1315388253763954		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 1.1315388253763954 | validation: 2.847774430895686]
	TIME [epoch: 11.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1372557743464373		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 1.1372557743464373 | validation: 2.855454303265976]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1356477630196289		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 1.1356477630196289 | validation: 2.846117827096989]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1383285818419182		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 1.1383285818419182 | validation: 2.8478105934096276]
	TIME [epoch: 11.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1397064657894764		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 1.1397064657894764 | validation: 2.8648683690177323]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1382678740082544		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 1.1382678740082544 | validation: 2.8546355094645146]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1368536177518376		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 1.1368536177518376 | validation: 2.852423405311031]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140584634082634		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 1.140584634082634 | validation: 2.849393167112776]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135031326317543		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 1.135031326317543 | validation: 2.846012489042678]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1363480043322731		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 1.1363480043322731 | validation: 2.8445260237586694]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1386880259349947		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 1.1386880259349947 | validation: 2.8496878901645943]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1330627559734383		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 1.1330627559734383 | validation: 2.8515478875504754]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1353135544217925		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 1.1353135544217925 | validation: 2.8513299258672573]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1337086440529776		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 1.1337086440529776 | validation: 2.8417457638673422]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364284069169752		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 1.1364284069169752 | validation: 2.841852701575709]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1350357203221804		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 1.1350357203221804 | validation: 2.8416772672623636]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364867793929683		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 1.1364867793929683 | validation: 2.8397276100249194]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1379295701768037		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 1.1379295701768037 | validation: 2.8502532566809795]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1401219669152909		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 1.1401219669152909 | validation: 2.846763945852243]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1382206733922717		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 1.1382206733922717 | validation: 2.8425199154880754]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136199707189284		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 1.136199707189284 | validation: 2.845931784417834]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1336467070845726		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 1.1336467070845726 | validation: 2.8452637986209415]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1353744452653323		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 1.1353744452653323 | validation: 2.835330029860778]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1377829042477137		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 1.1377829042477137 | validation: 2.83620520462718]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1375447923843978		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 1.1375447923843978 | validation: 2.8346885759422924]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1346372658967874		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 1.1346372658967874 | validation: 2.84547958275059]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1387165975770044		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 1.1387165975770044 | validation: 2.8533468823487262]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1344365345006266		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 1.1344365345006266 | validation: 2.850788263349233]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1380324751059687		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 1.1380324751059687 | validation: 2.854388310978776]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1338703557730039		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 1.1338703557730039 | validation: 2.854043392965161]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1371257167587865		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 1.1371257167587865 | validation: 2.8595749366209304]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1348227554143424		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 1.1348227554143424 | validation: 2.841118900539492]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137832530257246		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 1.137832530257246 | validation: 2.8568722621360645]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381204475167102		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 1.1381204475167102 | validation: 2.861498099723407]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138801321407302		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 1.138801321407302 | validation: 2.8578829826205356]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1396254692353336		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 1.1396254692353336 | validation: 2.850553149390096]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140728840855902		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 1.140728840855902 | validation: 2.851998721583883]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1341096453262176		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 1.1341096453262176 | validation: 2.8586325019309147]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1409652227219853		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 1.1409652227219853 | validation: 2.857452241825181]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1368312168990629		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 1.1368312168990629 | validation: 2.852337158774606]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1359987018318338		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 1.1359987018318338 | validation: 2.839496221428874]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141006732635269		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 1.141006732635269 | validation: 2.8454744497527362]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1359570058338742		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 1.1359570058338742 | validation: 2.8453430853822126]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1357655376317566		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 1.1357655376317566 | validation: 2.839907812532217]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1358372513151307		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 1.1358372513151307 | validation: 2.8402997795985945]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135994164654558		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 1.135994164654558 | validation: 2.8555884790746076]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1340302470692254		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 1.1340302470692254 | validation: 2.848535773766539]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1338366169255367		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 1.1338366169255367 | validation: 2.8412658357698444]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136139464107872		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 1.136139464107872 | validation: 2.853669738962149]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1382571532563523		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 1.1382571532563523 | validation: 2.849662107375457]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1340671701595568		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 1.1340671701595568 | validation: 2.844831032020798]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13330953344683		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 1.13330953344683 | validation: 2.8502222326266624]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1349785925542266		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 1.1349785925542266 | validation: 2.8437538705656515]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1384840094748743		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 1.1384840094748743 | validation: 2.8475519307856123]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1404974301061994		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 1.1404974301061994 | validation: 2.851333477220399]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1377261552513942		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 1.1377261552513942 | validation: 2.8535877364425404]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1338795570510734		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 1.1338795570510734 | validation: 2.8414019943166062]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1355243679907594		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 1.1355243679907594 | validation: 2.848729188847603]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1358950687975602		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 1.1358950687975602 | validation: 2.8413210012440415]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1347877663980386		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 1.1347877663980386 | validation: 2.846153050251146]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1382812803784503		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 1.1382812803784503 | validation: 2.841076227996434]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1385137275226325		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 1.1385137275226325 | validation: 2.8504687626324263]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1353742744146111		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 1.1353742744146111 | validation: 2.8399023008427755]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1368143620703088		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 1.1368143620703088 | validation: 2.8448593558005735]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1369645733916836		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 1.1369645733916836 | validation: 2.8467737488268843]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1372048966669985		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 1.1372048966669985 | validation: 2.844263025393075]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1388963991628842		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 1.1388963991628842 | validation: 2.8489544892378347]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1361812811079997		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 1.1361812811079997 | validation: 2.8418765636869576]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364287482557955		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 1.1364287482557955 | validation: 2.8453788242366063]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137458243592509		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 1.137458243592509 | validation: 2.8474298658142776]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1420961340940377		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 1.1420961340940377 | validation: 2.839700372081992]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1356652918372965		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 1.1356652918372965 | validation: 2.835489587562526]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1419039988482569		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 1.1419039988482569 | validation: 2.8377630848565962]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139120529409047		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 1.139120529409047 | validation: 2.842250388502206]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1367988429009406		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 1.1367988429009406 | validation: 2.8381532479345974]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137703813609737		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 1.137703813609737 | validation: 2.851611627554853]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140135842763076		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 1.140135842763076 | validation: 2.852575324578144]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139722286453001		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 1.139722286453001 | validation: 2.860041925215139]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135709007453873		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 1.135709007453873 | validation: 2.846721363061349]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1369565237966868		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 1.1369565237966868 | validation: 2.842908928111416]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1347275604004212		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 1.1347275604004212 | validation: 2.8483554270025198]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1362827729996299		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 1.1362827729996299 | validation: 2.846538964229112]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1375137056176845		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 1.1375137056176845 | validation: 2.838110110806878]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13315633687731		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 1.13315633687731 | validation: 2.843727990648652]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1385470231401091		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 1.1385470231401091 | validation: 2.8588635381775283]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13503021431609		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 1.13503021431609 | validation: 2.848995975181671]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136611437903043		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 1.136611437903043 | validation: 2.8535582611208374]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1306704942453747		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 1.1306704942453747 | validation: 2.849684614291045]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364267644210717		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 1.1364267644210717 | validation: 2.847378370138804]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1379132826277947		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 1.1379132826277947 | validation: 2.843796461934366]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137093463105784		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 1.137093463105784 | validation: 2.8525497212130437]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136667380066863		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 1.136667380066863 | validation: 2.8449881954379936]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1394625163975194		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 1.1394625163975194 | validation: 2.8421594939697274]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1323829044725755		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 1.1323829044725755 | validation: 2.8442346356332435]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1389405010546854		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 1.1389405010546854 | validation: 2.836884088189213]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1385804095722925		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 1.1385804095722925 | validation: 2.8376985135211577]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1405613623973432		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 1.1405613623973432 | validation: 2.843513853149135]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1378600285496554		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 1.1378600285496554 | validation: 2.841152805036395]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1379769871295469		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 1.1379769871295469 | validation: 2.8516875622695097]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1355993572975378		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 1.1355993572975378 | validation: 2.8428737568094538]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1365522170616449		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 1.1365522170616449 | validation: 2.844761730925767]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1354473603122637		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 1.1354473603122637 | validation: 2.8474431694392615]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1432516968716337		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 1.1432516968716337 | validation: 2.847708817249361]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1378357038486853		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 1.1378357038486853 | validation: 2.8549085241902525]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1382129393114568		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 1.1382129393114568 | validation: 2.84462396173287]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1366850275577196		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 1.1366850275577196 | validation: 2.8423468943439554]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135759360406174		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 1.135759360406174 | validation: 2.8292705341431437]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1365160356148534		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 1.1365160356148534 | validation: 2.8399552380279682]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137222001198327		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 1.137222001198327 | validation: 2.8453371065745046]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1373993360827848		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 1.1373993360827848 | validation: 2.840285862260744]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138272395386434		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 1.138272395386434 | validation: 2.846885956586817]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1387195026173287		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 1.1387195026173287 | validation: 2.8651286133998894]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1402223301536338		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 1.1402223301536338 | validation: 2.858421301256289]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1389661842946341		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 1.1389661842946341 | validation: 2.851239944562514]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1352842649300654		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 1.1352842649300654 | validation: 2.8446681996451013]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1363273965811234		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 1.1363273965811234 | validation: 2.8362394760703573]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1334556639765854		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 1.1334556639765854 | validation: 2.8461603514729075]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364473146832752		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 1.1364473146832752 | validation: 2.841350782927674]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1380316490195295		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 1.1380316490195295 | validation: 2.84314072945597]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364357708004253		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 1.1364357708004253 | validation: 2.839687863717146]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1361063836725305		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 1.1361063836725305 | validation: 2.8374604269239496]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1405343827605265		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 1.1405343827605265 | validation: 2.8561914378663404]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1368828856664897		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 1.1368828856664897 | validation: 2.8473823078419174]
	TIME [epoch: 11.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1350514248378618		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 1.1350514248378618 | validation: 2.842494810315418]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1329231248440768		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 1.1329231248440768 | validation: 2.8400886083515355]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1382139032979977		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 1.1382139032979977 | validation: 2.8510001202777273]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1383658773672636		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 1.1383658773672636 | validation: 2.842719235376314]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1336881725047723		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 1.1336881725047723 | validation: 2.8555387122264064]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1331707816865972		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 1.1331707816865972 | validation: 2.843382334553217]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1372960165638275		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 1.1372960165638275 | validation: 2.860289610578451]
	TIME [epoch: 11.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136320975243775		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 1.136320975243775 | validation: 2.8394949258428426]
	TIME [epoch: 11.5 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1324002839605056		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 1.1324002839605056 | validation: 2.847808234122035]
	TIME [epoch: 11.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1336266027491047		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 1.1336266027491047 | validation: 2.8525099279453845]
	TIME [epoch: 11.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1373343471091566		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 1.1373343471091566 | validation: 2.8450033064375715]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1338074685944899		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 1.1338074685944899 | validation: 2.8482296905561624]
	TIME [epoch: 11.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1398384813250924		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 1.1398384813250924 | validation: 2.8438158778403007]
	TIME [epoch: 11.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1358407516309486		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 1.1358407516309486 | validation: 2.8524380618702105]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137365415756629		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 1.137365415756629 | validation: 2.856861716617946]
	TIME [epoch: 11.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381153613885595		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 1.1381153613885595 | validation: 2.852612011297666]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1390747775763637		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 1.1390747775763637 | validation: 2.861994516522114]
	TIME [epoch: 11.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.132676423245294		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 1.132676423245294 | validation: 2.853448929977188]
	TIME [epoch: 11.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1394572162082133		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 1.1394572162082133 | validation: 2.861356954789323]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1359985368637089		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 1.1359985368637089 | validation: 2.8459606986583]
	TIME [epoch: 11.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364328737531757		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 1.1364328737531757 | validation: 2.842307953191605]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1362790014447897		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 1.1362790014447897 | validation: 2.863124362701609]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1347252817334705		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 1.1347252817334705 | validation: 2.8405284869735374]
	TIME [epoch: 11.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.133041145236889		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 1.133041145236889 | validation: 2.84434827134676]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137405759367508		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 1.137405759367508 | validation: 2.8439025538366427]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1417558014299125		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 1.1417558014299125 | validation: 2.841923409264314]
	TIME [epoch: 11.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1338241317408784		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 1.1338241317408784 | validation: 2.8445533840494184]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1390882209267532		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 1.1390882209267532 | validation: 2.8504089698714568]
	TIME [epoch: 11.5 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1349847725321964		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 1.1349847725321964 | validation: 2.8458689633227534]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137805056470889		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 1.137805056470889 | validation: 2.8552162750531456]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1354348535551608		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 1.1354348535551608 | validation: 2.8521424412062504]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1347463507455626		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 1.1347463507455626 | validation: 2.850035206091814]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1402875604138958		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 1.1402875604138958 | validation: 2.854777560606751]
	TIME [epoch: 11.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.134566169194998		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 1.134566169194998 | validation: 2.854452004596624]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1340538584936728		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 1.1340538584936728 | validation: 2.8447022366164623]
	TIME [epoch: 11.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1376047877637405		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 1.1376047877637405 | validation: 2.839112023686652]
	TIME [epoch: 11.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1354533488260432		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 1.1354533488260432 | validation: 2.8475430782668174]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138557033523559		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 1.138557033523559 | validation: 2.8517892936092766]
	TIME [epoch: 11.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1341771554945923		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 1.1341771554945923 | validation: 2.856970682311587]
	TIME [epoch: 11.5 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1382272183370585		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 1.1382272183370585 | validation: 2.857115719043496]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13259021812995		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 1.13259021812995 | validation: 2.843798024200669]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135535748917401		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 1.135535748917401 | validation: 2.851872976174905]
	TIME [epoch: 11.5 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1346030366271043		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 1.1346030366271043 | validation: 2.8505447305683163]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364184925733685		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 1.1364184925733685 | validation: 2.862302284283079]
	TIME [epoch: 11.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1378974079120394		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 1.1378974079120394 | validation: 2.861245940813069]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136750794324923		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 1.136750794324923 | validation: 2.85071297051917]
	TIME [epoch: 11.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1325328159793036		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 1.1325328159793036 | validation: 2.851101559894882]
	TIME [epoch: 11.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1370079264626505		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 1.1370079264626505 | validation: 2.8476353950094215]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1395800101029239		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 1.1395800101029239 | validation: 2.859050964625086]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137589929813131		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 1.137589929813131 | validation: 2.8508901490135066]
	TIME [epoch: 11.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1414547691559915		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 1.1414547691559915 | validation: 2.8507009046727103]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1377332847005428		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 1.1377332847005428 | validation: 2.8620082071316837]
	TIME [epoch: 11.5 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1413986830475216		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 1.1413986830475216 | validation: 2.8453371084925574]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1375067065809743		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 1.1375067065809743 | validation: 2.851802480552455]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1380735185791169		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 1.1380735185791169 | validation: 2.852401489358623]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137358272503002		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 1.137358272503002 | validation: 2.8562164068324227]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381164720899175		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 1.1381164720899175 | validation: 2.856721215564481]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1338772241717388		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 1.1338772241717388 | validation: 2.841562935232519]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1323226449584474		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 1.1323226449584474 | validation: 2.8472030856010444]
	TIME [epoch: 11.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1366711730627048		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 1.1366711730627048 | validation: 2.85342814061591]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1370520893347082		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 1.1370520893347082 | validation: 2.850646625794137]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1375726070381575		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 1.1375726070381575 | validation: 2.846607272235543]
	TIME [epoch: 11.5 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140926405086753		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 1.140926405086753 | validation: 2.8511512781271917]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1410219329132967		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 1.1410219329132967 | validation: 2.8479188980710752]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1361586450745125		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 1.1361586450745125 | validation: 2.8586661852842674]
	TIME [epoch: 11.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1345223804251128		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 1.1345223804251128 | validation: 2.858552714929745]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1373703075089676		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 1.1373703075089676 | validation: 2.852859633896663]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1367704928437807		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 1.1367704928437807 | validation: 2.8582382510097406]
	TIME [epoch: 11.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1404240529996132		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 1.1404240529996132 | validation: 2.8457656659338455]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139623669863541		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 1.139623669863541 | validation: 2.853765265607899]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1349909356434473		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 1.1349909356434473 | validation: 2.8436478611353193]
	TIME [epoch: 11.5 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.132239004493755		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 1.132239004493755 | validation: 2.8468693799469658]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1393693272178154		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 1.1393693272178154 | validation: 2.8374926434067107]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1353162704771105		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 1.1353162704771105 | validation: 2.8489817411919285]
	TIME [epoch: 11.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1384258122567659		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 1.1384258122567659 | validation: 2.8442872328791386]
	TIME [epoch: 11.5 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1367862298368159		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 1.1367862298368159 | validation: 2.8469107525846034]
	TIME [epoch: 11.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137802344513693		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 1.137802344513693 | validation: 2.8505359373310317]
	TIME [epoch: 11.5 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1354615974060798		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 1.1354615974060798 | validation: 2.8599489521898227]
	TIME [epoch: 11.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1340694847744515		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 1.1340694847744515 | validation: 2.8418757934481165]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1416004010270384		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 1.1416004010270384 | validation: 2.85043678454659]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1363091418080933		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 1.1363091418080933 | validation: 2.848562732223741]
	TIME [epoch: 11.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1361523997540264		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 1.1361523997540264 | validation: 2.858304920105166]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1369807312222808		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 1.1369807312222808 | validation: 2.8494263106166775]
	TIME [epoch: 11.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1378947202916292		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 1.1378947202916292 | validation: 2.848017464340401]
	TIME [epoch: 11.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1333475549046688		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 1.1333475549046688 | validation: 2.861876399242407]
	TIME [epoch: 11.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137272069347911		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 1.137272069347911 | validation: 2.8546506356286994]
	TIME [epoch: 11.5 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1341926539633174		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 1.1341926539633174 | validation: 2.8441572576716725]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1396069634639978		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 1.1396069634639978 | validation: 2.850385419247067]
	TIME [epoch: 11.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1356915261534906		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 1.1356915261534906 | validation: 2.8498771301663646]
	TIME [epoch: 11.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135309000313996		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 1.135309000313996 | validation: 2.850507667798408]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1360876047065955		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 1.1360876047065955 | validation: 2.85597013153487]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1384976610637292		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 1.1384976610637292 | validation: 2.8574881732704194]
	TIME [epoch: 11.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1385045145532013		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 1.1385045145532013 | validation: 2.8581589871938244]
	TIME [epoch: 11.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1367579763759408		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 1.1367579763759408 | validation: 2.8503385238434285]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1336193108035026		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 1.1336193108035026 | validation: 2.848566354258578]
	TIME [epoch: 11.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1356710868116147		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 1.1356710868116147 | validation: 2.8563068746253624]
	TIME [epoch: 11.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13497883661422		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 1.13497883661422 | validation: 2.8376905647404134]
	TIME [epoch: 11.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1387559876927194		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 1.1387559876927194 | validation: 2.851407285435836]
	TIME [epoch: 11.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140040785341429		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 1.140040785341429 | validation: 2.84737179528468]
	TIME [epoch: 11.5 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1404615955989412		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 1.1404615955989412 | validation: 2.8496042221111426]
	TIME [epoch: 11.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1351620664256976		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 1.1351620664256976 | validation: 2.8327121856644433]
	TIME [epoch: 11.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423087874132203		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 1.1423087874132203 | validation: 2.8486228310771993]
	TIME [epoch: 11.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1415906054596145		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 1.1415906054596145 | validation: 2.838418626436287]
	TIME [epoch: 11.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135181227502599		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 1.135181227502599 | validation: 2.8477698158319527]
	TIME [epoch: 11.5 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1398641423245766		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 1.1398641423245766 | validation: 2.8466927713734633]
	TIME [epoch: 11.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1392303028842048		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 1.1392303028842048 | validation: 2.8476342358979183]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1343288760936108		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 1.1343288760936108 | validation: 2.8421695920818495]
	TIME [epoch: 11.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1374084367314872		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 1.1374084367314872 | validation: 2.8422462456020394]
	TIME [epoch: 11.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13149239077274		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 1.13149239077274 | validation: 2.8417301756971973]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1411513621238176		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 1.1411513621238176 | validation: 2.8398078513850034]
	TIME [epoch: 11.5 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1374026562527346		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 1.1374026562527346 | validation: 2.8461877664631947]
	TIME [epoch: 11.5 sec]
Finished training in 23154.843 seconds.
