Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r4', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4158179649

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.7791182892766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.7791182892766 | validation: 9.821070283605007]
	TIME [epoch: 105 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.431279678074723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.431279678074723 | validation: 8.419118623295907]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.188672995562666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.188672995562666 | validation: 8.312037008163575]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.376317127183334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.376317127183334 | validation: 8.608332803101298]
	TIME [epoch: 27.8 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.145338095841844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.145338095841844 | validation: 9.6354876443866]
	TIME [epoch: 27.9 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.624876089832354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.624876089832354 | validation: 8.281828257874372]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.991704658329491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.991704658329491 | validation: 9.46026135929577]
	TIME [epoch: 27.9 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.142649693006968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.142649693006968 | validation: 7.985690868363079]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.762004454599214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.762004454599214 | validation: 7.951789216398516]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.6576003639025005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6576003639025005 | validation: 7.41242926504626]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.260173811855403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.260173811855403 | validation: 7.640421814495546]
	TIME [epoch: 27.9 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.677337031581402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.677337031581402 | validation: 6.531094439250084]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.392175701145311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.392175701145311 | validation: 6.535411665680017]
	TIME [epoch: 27.8 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.360978247396414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.360978247396414 | validation: 6.585722915782178]
	TIME [epoch: 27.9 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.248995182727707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.248995182727707 | validation: 6.378977436255524]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.127399720962298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.127399720962298 | validation: 6.261340125930692]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.187625518247468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.187625518247468 | validation: 6.1692362139596515]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.086582350328025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.086582350328025 | validation: 6.38803685139339]
	TIME [epoch: 27.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.154692108614046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.154692108614046 | validation: 6.0113641949999534]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.26726757460013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.26726757460013 | validation: 6.639696052275108]
	TIME [epoch: 27.9 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.241444534963484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.241444534963484 | validation: 6.2618834815292805]
	TIME [epoch: 28 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.134552089234148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.134552089234148 | validation: 5.9967568423610045]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.318918517536213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.318918517536213 | validation: 5.92233798560528]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.792075234804003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.792075234804003 | validation: 6.1913917249582555]
	TIME [epoch: 28 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.788805000227637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.788805000227637 | validation: 5.978648037652784]
	TIME [epoch: 27.9 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8398421755442955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8398421755442955 | validation: 6.070132616633514]
	TIME [epoch: 27.9 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.822609186463113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.822609186463113 | validation: 5.927727353923347]
	TIME [epoch: 27.9 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.691309957884394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.691309957884394 | validation: 5.883061176946474]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.962549549377724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.962549549377724 | validation: 5.997214717254517]
	TIME [epoch: 27.9 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8912045686062555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8912045686062555 | validation: 5.997633068734021]
	TIME [epoch: 27.9 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.72404869053579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.72404869053579 | validation: 5.7423179868296055]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.730519943347947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.730519943347947 | validation: 5.756419495791331]
	TIME [epoch: 28 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.401261108146605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.401261108146605 | validation: 7.181415954756582]
	TIME [epoch: 27.9 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.620375586395685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.620375586395685 | validation: 6.465058787377205]
	TIME [epoch: 27.9 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.146210686188729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.146210686188729 | validation: 5.882445547910385]
	TIME [epoch: 28 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.75440434352583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.75440434352583 | validation: 5.72313739355443]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.720648922134497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.720648922134497 | validation: 5.962157210338037]
	TIME [epoch: 27.9 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.748424305177876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.748424305177876 | validation: 5.706212542510969]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.614060424011382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.614060424011382 | validation: 6.182952467737107]
	TIME [epoch: 27.9 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.855481879685066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.855481879685066 | validation: 5.905872581799756]
	TIME [epoch: 27.9 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.59127366256503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.59127366256503 | validation: 6.250406368215249]
	TIME [epoch: 27.9 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.141557709754026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.141557709754026 | validation: 5.818596813594828]
	TIME [epoch: 27.9 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.596461712548246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.596461712548246 | validation: 5.448906061881176]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3218015380800425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3218015380800425 | validation: 5.269538305020235]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.836776657807046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.836776657807046 | validation: 6.806086694334993]
	TIME [epoch: 27.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.662903133125476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.662903133125476 | validation: 6.17381451311326]
	TIME [epoch: 27.9 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.61624054464767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.61624054464767 | validation: 5.441073746262324]
	TIME [epoch: 27.9 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.027984017776108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.027984017776108 | validation: 6.137277884377711]
	TIME [epoch: 27.9 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.43030354670551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.43030354670551 | validation: 5.403251555848308]
	TIME [epoch: 28.2 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.250777948745386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.250777948745386 | validation: 5.436123053748881]
	TIME [epoch: 27.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.143963852859889		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.143963852859889 | validation: 6.477007239397708]
	TIME [epoch: 27.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.006162906480795		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 6.006162906480795 | validation: 5.76623434524553]
	TIME [epoch: 27.9 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.371772240728842		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.371772240728842 | validation: 4.955033271665419]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.315468986543964		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 6.315468986543964 | validation: 7.674908650383793]
	TIME [epoch: 27.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.044440884443412		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 7.044440884443412 | validation: 5.55724069164795]
	TIME [epoch: 27.9 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2096884004034285		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 6.2096884004034285 | validation: 8.408731551278443]
	TIME [epoch: 27.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.00689411883523		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 8.00689411883523 | validation: 7.367839197793996]
	TIME [epoch: 27.9 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.560206798091374		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 6.560206798091374 | validation: 5.694134074753951]
	TIME [epoch: 27.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.422396260366733		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.422396260366733 | validation: 5.539723194923218]
	TIME [epoch: 27.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.413703762611732		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.413703762611732 | validation: 6.149500513488503]
	TIME [epoch: 27.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7715650247913075		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 6.7715650247913075 | validation: 9.382081390173738]
	TIME [epoch: 27.9 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.990555797502688		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 7.990555797502688 | validation: 5.3544593592758565]
	TIME [epoch: 27.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.466826779941108		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 5.466826779941108 | validation: 7.134416849896208]
	TIME [epoch: 27.9 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.335834293432937		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 7.335834293432937 | validation: 7.015533777049768]
	TIME [epoch: 27.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7744358742849204		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 5.7744358742849204 | validation: 5.353102038671421]
	TIME [epoch: 27.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.16665627582922		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.16665627582922 | validation: 5.606751019120971]
	TIME [epoch: 27.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.332780240808031		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 5.332780240808031 | validation: 5.141436382146119]
	TIME [epoch: 27.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.214327796711202		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 5.214327796711202 | validation: 5.290541362503728]
	TIME [epoch: 27.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.991564288941821		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.991564288941821 | validation: 5.249821744950716]
	TIME [epoch: 27.9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6617661963144394		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.6617661963144394 | validation: 5.310089022492441]
	TIME [epoch: 27.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0738521139425625		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 5.0738521139425625 | validation: 5.042518983654776]
	TIME [epoch: 27.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.798423419385676		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.798423419385676 | validation: 4.876110315252915]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.550234453697172		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.550234453697172 | validation: 4.466915929662238]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.679173586024877		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.679173586024877 | validation: 6.124938166244838]
	TIME [epoch: 27.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.147456303639201		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 5.147456303639201 | validation: 4.640756960123205]
	TIME [epoch: 27.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.29854663558706		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 5.29854663558706 | validation: 4.8923336099454255]
	TIME [epoch: 27.9 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.66179465694229		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.66179465694229 | validation: 4.648533827403909]
	TIME [epoch: 27.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.369636342903985		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.369636342903985 | validation: 4.3223699714814465]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.188012718415548		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.188012718415548 | validation: 4.404302516418024]
	TIME [epoch: 27.9 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.164104832348977		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.164104832348977 | validation: 8.6439884816187]
	TIME [epoch: 27.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.703735282458473		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 8.703735282458473 | validation: 8.50599172099118]
	TIME [epoch: 27.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.378469365060766		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 8.378469365060766 | validation: 8.433543255720968]
	TIME [epoch: 27.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.271573887282202		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 8.271573887282202 | validation: 8.204107347983756]
	TIME [epoch: 27.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.955953822541298		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 6.955953822541298 | validation: 9.450245789234344]
	TIME [epoch: 27.9 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.930754598333342		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 8.930754598333342 | validation: 8.070810010268662]
	TIME [epoch: 27.9 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.266545362126406		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 7.266545362126406 | validation: 6.627553290629005]
	TIME [epoch: 27.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.668757030189762		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 5.668757030189762 | validation: 5.275185344217902]
	TIME [epoch: 27.9 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.942079844535093		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 4.942079844535093 | validation: 5.092111080624749]
	TIME [epoch: 27.9 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8018373049614365		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.8018373049614365 | validation: 5.425904075648816]
	TIME [epoch: 27.9 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6597658040469705		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 6.6597658040469705 | validation: 6.944291357786244]
	TIME [epoch: 27.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.020407194261409		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 7.020407194261409 | validation: 7.381022436580566]
	TIME [epoch: 27.9 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6823263778634026		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 6.6823263778634026 | validation: 5.936187167820221]
	TIME [epoch: 27.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.852227731537458		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 5.852227731537458 | validation: 5.755767429089547]
	TIME [epoch: 27.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.527047751895273		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 5.527047751895273 | validation: 5.519014366076521]
	TIME [epoch: 27.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.126728932625395		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 5.126728932625395 | validation: 5.118381406105721]
	TIME [epoch: 27.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.93936812501956		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.93936812501956 | validation: 4.930014148333795]
	TIME [epoch: 28 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.243119067518734		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 6.243119067518734 | validation: 6.7020008160732765]
	TIME [epoch: 27.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.020697388147118		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 7.020697388147118 | validation: 6.456193570906695]
	TIME [epoch: 27.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.88854265978683		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 5.88854265978683 | validation: 5.531350011360433]
	TIME [epoch: 27.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.561901674715708		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 5.561901674715708 | validation: 5.126024332106895]
	TIME [epoch: 28 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9551870733204115		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 4.9551870733204115 | validation: 5.45842703587439]
	TIME [epoch: 27.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5537348091621155		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 6.5537348091621155 | validation: 7.045635298224567]
	TIME [epoch: 27.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.254865284170969		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 6.254865284170969 | validation: 5.356547946340528]
	TIME [epoch: 28 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.970744780910085		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 5.970744780910085 | validation: 6.443818664123437]
	TIME [epoch: 27.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.120247875552836		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 6.120247875552836 | validation: 6.116989665502565]
	TIME [epoch: 28 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9243570411856075		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 5.9243570411856075 | validation: 5.7590162034651335]
	TIME [epoch: 27.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.816273467031355		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 5.816273467031355 | validation: 5.562973272988573]
	TIME [epoch: 27.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.396526063198542		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 5.396526063198542 | validation: 5.318886794035891]
	TIME [epoch: 27.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2558504034147955		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 5.2558504034147955 | validation: 5.153005222242012]
	TIME [epoch: 27.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6774277943272375		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 5.6774277943272375 | validation: 6.622939729368014]
	TIME [epoch: 27.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.933410717476345		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 6.933410717476345 | validation: 6.5990852886552815]
	TIME [epoch: 27.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.014753081228187		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 6.014753081228187 | validation: 5.526067999426056]
	TIME [epoch: 28 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.178547927694117		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 5.178547927694117 | validation: 5.265089005092121]
	TIME [epoch: 27.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.194967640933585		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 5.194967640933585 | validation: 5.298254653935062]
	TIME [epoch: 27.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.963082087139105		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.963082087139105 | validation: 5.0643348810765065]
	TIME [epoch: 27.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.932734561994683		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 4.932734561994683 | validation: 5.395885626051945]
	TIME [epoch: 27.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.420326760751294		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 5.420326760751294 | validation: 6.005166609841212]
	TIME [epoch: 27.9 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.306263094458317		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 6.306263094458317 | validation: 6.559240612372576]
	TIME [epoch: 27.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.158095686036718		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 6.158095686036718 | validation: 6.006304223627856]
	TIME [epoch: 27.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.662696848814118		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 6.662696848814118 | validation: 6.576754547373736]
	TIME [epoch: 27.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.092443465226243		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 6.092443465226243 | validation: 5.719409722920599]
	TIME [epoch: 27.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.577150744006474		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 5.577150744006474 | validation: 5.694954879793544]
	TIME [epoch: 27.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5050321515673595		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 5.5050321515673595 | validation: 5.449470617935261]
	TIME [epoch: 27.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.309427489306715		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 5.309427489306715 | validation: 5.336877783198165]
	TIME [epoch: 27.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.018711157754252		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 5.018711157754252 | validation: 5.266162619359521]
	TIME [epoch: 27.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.94148755706126		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 4.94148755706126 | validation: 4.748134379509404]
	TIME [epoch: 27.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50854521433078		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 4.50854521433078 | validation: 4.327647686264556]
	TIME [epoch: 27.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.275503024453784		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 4.275503024453784 | validation: 4.347832454157944]
	TIME [epoch: 27.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.32574215604279		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 4.32574215604279 | validation: 4.631020276738192]
	TIME [epoch: 28 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.185566265748842		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 4.185566265748842 | validation: 5.513951306361461]
	TIME [epoch: 27.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.27687586465508		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 6.27687586465508 | validation: 8.024960473202865]
	TIME [epoch: 27.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.625779151759794		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 8.625779151759794 | validation: 7.891199010928725]
	TIME [epoch: 27.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.443044296367928		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 6.443044296367928 | validation: 5.164075631266769]
	TIME [epoch: 27.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.648244187134008		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 4.648244187134008 | validation: 4.2872129761333415]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9983898813436203		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.9983898813436203 | validation: 4.785090979725358]
	TIME [epoch: 27.9 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.407799548553879		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 4.407799548553879 | validation: 3.966994899058789]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.997844887994443		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.997844887994443 | validation: 3.7663076230713317]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.866617864303229		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.866617864303229 | validation: 3.8362285622123142]
	TIME [epoch: 27.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5846449851936493		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.5846449851936493 | validation: 3.372112041260838]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.121409324898817		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 5.121409324898817 | validation: 4.917335224610147]
	TIME [epoch: 27.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.787980238245044		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 4.787980238245044 | validation: 4.152775853476989]
	TIME [epoch: 27.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.632945209160188		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.632945209160188 | validation: 3.223325490306869]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2512081446340244		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.2512081446340244 | validation: 3.364067133389233]
	TIME [epoch: 27.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6753330477851827		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.6753330477851827 | validation: 3.039270343997322]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2046036902342743		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.2046036902342743 | validation: 5.28367813586107]
	TIME [epoch: 27.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.415474243359765		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 6.415474243359765 | validation: 7.276473068030912]
	TIME [epoch: 27.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.934463276291341		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 6.934463276291341 | validation: 6.325924760190319]
	TIME [epoch: 27.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.947552704805464		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 6.947552704805464 | validation: 6.686746547090247]
	TIME [epoch: 27.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.377385843197166		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 6.377385843197166 | validation: 5.4390611727349025]
	TIME [epoch: 27.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.741861100626622		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 4.741861100626622 | validation: 4.084146301337549]
	TIME [epoch: 27.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7973633582987807		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.7973633582987807 | validation: 4.34766892215617]
	TIME [epoch: 27.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5956405264156994		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.5956405264156994 | validation: 3.3908189636263626]
	TIME [epoch: 27.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.576557376866947		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.576557376866947 | validation: 3.1630668049661206]
	TIME [epoch: 27.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3434215798287905		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.3434215798287905 | validation: 3.1595974819990045]
	TIME [epoch: 27.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.039145652149762		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.039145652149762 | validation: 2.76175156841923]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.932900900364346		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.932900900364346 | validation: 2.807028590985062]
	TIME [epoch: 27.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8010267632585526		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.8010267632585526 | validation: 3.0081108699465844]
	TIME [epoch: 27.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3096411522444225		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.3096411522444225 | validation: 2.7558904567520774]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.804187773963842		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.804187773963842 | validation: 2.6851886076041627]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7726190359852962		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.7726190359852962 | validation: 6.703789616208873]
	TIME [epoch: 27.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.280921965532949		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 7.280921965532949 | validation: 6.584019928522458]
	TIME [epoch: 27.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5290157041541885		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 6.5290157041541885 | validation: 5.911961240129838]
	TIME [epoch: 27.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.041944812821651		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 5.041944812821651 | validation: 3.0943748728060543]
	TIME [epoch: 27.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.041601825900261		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.041601825900261 | validation: 2.475688170728318]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.582403997904477		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.582403997904477 | validation: 2.3262196543461915]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.965483624512604		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.965483624512604 | validation: 2.5360769132221153]
	TIME [epoch: 27.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4072631828452726		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.4072631828452726 | validation: 2.7994763860569702]
	TIME [epoch: 27.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.663423319294181		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.663423319294181 | validation: 2.3917976030259025]
	TIME [epoch: 27.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6658647765157726		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.6658647765157726 | validation: 2.1754685220182033]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.596596880589776		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.596596880589776 | validation: 2.08128912341289]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2556181814621703		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.2556181814621703 | validation: 3.6372398135237574]
	TIME [epoch: 27.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7776882888135845		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.7776882888135845 | validation: 3.098742590647149]
	TIME [epoch: 27.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.940955236527593		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.940955236527593 | validation: 2.218396927766863]
	TIME [epoch: 27.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.192353993505758		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.192353993505758 | validation: 2.237106617881252]
	TIME [epoch: 27.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1711843644338202		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.1711843644338202 | validation: 2.3003983902995726]
	TIME [epoch: 27.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266017627068657		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.266017627068657 | validation: 1.8763281914571843]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9068053240307032		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.9068053240307032 | validation: 4.73395751132119]
	TIME [epoch: 27.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.440728214670951		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 6.440728214670951 | validation: 6.455029236001567]
	TIME [epoch: 27.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.442368020236062		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 6.442368020236062 | validation: 6.19018394256364]
	TIME [epoch: 27.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.340624391630166		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 6.340624391630166 | validation: 6.157404857569615]
	TIME [epoch: 27.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.269199714945053		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 6.269199714945053 | validation: 6.156476195156018]
	TIME [epoch: 27.9 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.319546970498283		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 6.319546970498283 | validation: 6.215363240171964]
	TIME [epoch: 27.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.307887674579141		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 6.307887674579141 | validation: 6.193175854901397]
	TIME [epoch: 27.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.292904459293202		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 6.292904459293202 | validation: 6.084300028923048]
	TIME [epoch: 27.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.315645671393268		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 6.315645671393268 | validation: 6.151158617818196]
	TIME [epoch: 27.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5159710172641745		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 6.5159710172641745 | validation: 6.08637937879193]
	TIME [epoch: 27.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.202581783614642		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 6.202581783614642 | validation: 6.064881397568333]
	TIME [epoch: 27.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.207659789916337		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 6.207659789916337 | validation: 6.06260281593158]
	TIME [epoch: 27.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.178591914255028		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 6.178591914255028 | validation: 6.122292526503706]
	TIME [epoch: 27.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.163951349686432		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 6.163951349686432 | validation: 6.1243153825670404]
	TIME [epoch: 27.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.147321303474195		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 6.147321303474195 | validation: 5.9740239794643575]
	TIME [epoch: 27.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.122369105001891		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 6.122369105001891 | validation: 5.970227569372291]
	TIME [epoch: 27.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.135775320496674		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 6.135775320496674 | validation: 5.943380034005576]
	TIME [epoch: 27.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.095486662423464		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 6.095486662423464 | validation: 5.95056633184406]
	TIME [epoch: 27.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.032789614531056		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 6.032789614531056 | validation: 5.907544715716528]
	TIME [epoch: 27.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.071188038096828		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 6.071188038096828 | validation: 5.898820561685445]
	TIME [epoch: 27.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.01492880478013		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 6.01492880478013 | validation: 5.934848057497161]
	TIME [epoch: 27.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.082124326257154		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 6.082124326257154 | validation: 5.925215029436998]
	TIME [epoch: 27.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.018321934025409		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 6.018321934025409 | validation: 5.92521886608394]
	TIME [epoch: 27.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.044634652388743		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 6.044634652388743 | validation: 5.946222642262687]
	TIME [epoch: 27.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.084326265927411		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 6.084326265927411 | validation: 5.914256360651791]
	TIME [epoch: 27.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.086717124676159		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 6.086717124676159 | validation: 5.913982416222612]
	TIME [epoch: 27.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9830573653166335		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 5.9830573653166335 | validation: 5.849527763230078]
	TIME [epoch: 27.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.038526491630385		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 6.038526491630385 | validation: 5.870972655750604]
	TIME [epoch: 27.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.961876065277082		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 5.961876065277082 | validation: 5.961513413819492]
	TIME [epoch: 27.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.968727225809952		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 5.968727225809952 | validation: 5.914065720265508]
	TIME [epoch: 27.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.025776619857844		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 6.025776619857844 | validation: 5.831973454131706]
	TIME [epoch: 27.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.088245756472228		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 6.088245756472228 | validation: 5.820142679599786]
	TIME [epoch: 27.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.036169724915845		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 6.036169724915845 | validation: 5.837288884098917]
	TIME [epoch: 27.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.010612556086947		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 6.010612556086947 | validation: 5.827478175569771]
	TIME [epoch: 27.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.94100406377617		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 5.94100406377617 | validation: 5.849775390543058]
	TIME [epoch: 27.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.936559883828341		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 5.936559883828341 | validation: 6.104354832187275]
	TIME [epoch: 27.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.063652664896835		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 6.063652664896835 | validation: 5.934708795190029]
	TIME [epoch: 27.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.010322435835328		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 6.010322435835328 | validation: 5.862466281529219]
	TIME [epoch: 27.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.986803778777102		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 5.986803778777102 | validation: 5.876464171026931]
	TIME [epoch: 27.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.959136073434052		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 5.959136073434052 | validation: 5.984448006691646]
	TIME [epoch: 27.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.96472853649434		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 5.96472853649434 | validation: 5.8073680063909885]
	TIME [epoch: 27.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.05671272426876		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 6.05671272426876 | validation: 5.9109534924350395]
	TIME [epoch: 27.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.95107627157957		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 5.95107627157957 | validation: 5.855839618748008]
	TIME [epoch: 27.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.909152459166023		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 5.909152459166023 | validation: 5.817956771951413]
	TIME [epoch: 27.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9804999891390525		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 5.9804999891390525 | validation: 5.964033073091006]
	TIME [epoch: 27.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.937312275229857		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 5.937312275229857 | validation: 6.189942811802298]
	TIME [epoch: 27.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.044256463099379		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 6.044256463099379 | validation: 5.852922598202119]
	TIME [epoch: 27.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.956212678717776		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 5.956212678717776 | validation: 5.758855802445615]
	TIME [epoch: 27.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.919305059564111		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 5.919305059564111 | validation: 5.765372480585581]
	TIME [epoch: 27.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9932829165997985		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 5.9932829165997985 | validation: 5.854551198932373]
	TIME [epoch: 27.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.987245119760162		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 5.987245119760162 | validation: 5.7843710273150135]
	TIME [epoch: 27.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9946504849017135		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 5.9946504849017135 | validation: 5.798689005068471]
	TIME [epoch: 27.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.004992896692627		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 6.004992896692627 | validation: 5.784196951113452]
	TIME [epoch: 27.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.916972144148893		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 5.916972144148893 | validation: 5.76536693643875]
	TIME [epoch: 27.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.965148381168387		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 5.965148381168387 | validation: 5.826348403654334]
	TIME [epoch: 27.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.010326145281688		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 6.010326145281688 | validation: 5.746032470934113]
	TIME [epoch: 27.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.943326826272598		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 5.943326826272598 | validation: 5.750605820788245]
	TIME [epoch: 27.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.963705647060675		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 5.963705647060675 | validation: 5.79812663524363]
	TIME [epoch: 27.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.89956973113375		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 5.89956973113375 | validation: 6.101336206289223]
	TIME [epoch: 27.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.038103839812013		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 6.038103839812013 | validation: 5.779139652659346]
	TIME [epoch: 27.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.896528548283788		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 5.896528548283788 | validation: 5.735400662938588]
	TIME [epoch: 27.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.950825523751113		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 5.950825523751113 | validation: 5.761925903350494]
	TIME [epoch: 27.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.906980196154661		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 5.906980196154661 | validation: 5.759140309530369]
	TIME [epoch: 27.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.974774552219511		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 5.974774552219511 | validation: 5.86524184083605]
	TIME [epoch: 27.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.987779712696664		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 5.987779712696664 | validation: 5.894305748476239]
	TIME [epoch: 27.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.952603921881817		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 5.952603921881817 | validation: 5.883664055529425]
	TIME [epoch: 27.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.93809459988349		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 5.93809459988349 | validation: 5.756083748775488]
	TIME [epoch: 27.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.888332164376789		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 5.888332164376789 | validation: 5.843400878730681]
	TIME [epoch: 27.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.933118728705358		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 5.933118728705358 | validation: 5.847579764133111]
	TIME [epoch: 27.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.898954368419602		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 5.898954368419602 | validation: 5.932581521485928]
	TIME [epoch: 27.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.004355902942528		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 6.004355902942528 | validation: 5.71077832387982]
	TIME [epoch: 27.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.984255582078748		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 5.984255582078748 | validation: 5.741925175035309]
	TIME [epoch: 27.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.920682888367663		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 5.920682888367663 | validation: 5.730562178099095]
	TIME [epoch: 27.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.91301685558084		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 5.91301685558084 | validation: 5.744343382531707]
	TIME [epoch: 27.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.878128154345431		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 5.878128154345431 | validation: 5.739429769671294]
	TIME [epoch: 27.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9199523382322505		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 5.9199523382322505 | validation: 6.0313680838842245]
	TIME [epoch: 27.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.073766333092539		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 6.073766333092539 | validation: 5.846457397422821]
	TIME [epoch: 27.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.966912947268884		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 5.966912947268884 | validation: 5.855441847667372]
	TIME [epoch: 27.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.947307986620566		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 5.947307986620566 | validation: 5.7763833117846]
	TIME [epoch: 27.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.93904355300176		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 5.93904355300176 | validation: 5.794137971331022]
	TIME [epoch: 27.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.915190801074332		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 5.915190801074332 | validation: 5.865452375723322]
	TIME [epoch: 27.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.976380871601462		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 5.976380871601462 | validation: 5.756226462408624]
	TIME [epoch: 27.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.082156784293412		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 6.082156784293412 | validation: 5.969582161285084]
	TIME [epoch: 27.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.962855326075395		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 5.962855326075395 | validation: 5.865256770738247]
	TIME [epoch: 27.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.951691087131806		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 5.951691087131806 | validation: 5.788223238485146]
	TIME [epoch: 27.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.902344487042519		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 5.902344487042519 | validation: 5.744275323636938]
	TIME [epoch: 27.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.897619217750047		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 5.897619217750047 | validation: 6.203773372357247]
	TIME [epoch: 27.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.077787905570334		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 6.077787905570334 | validation: 5.785856778551761]
	TIME [epoch: 27.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.933310346979692		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 5.933310346979692 | validation: 5.829997040042599]
	TIME [epoch: 27.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.917451704472949		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 5.917451704472949 | validation: 5.787465539568624]
	TIME [epoch: 27.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.916481310589017		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 5.916481310589017 | validation: 5.966152698423783]
	TIME [epoch: 27.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.963132962820791		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 5.963132962820791 | validation: 6.395903813063194]
	TIME [epoch: 27.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.094347994067777		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 7.094347994067777 | validation: 6.123269565877494]
	TIME [epoch: 28 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.060785779071706		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 6.060785779071706 | validation: 6.20160651074384]
	TIME [epoch: 27.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.04587833196046		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 6.04587833196046 | validation: 5.777490039253407]
	TIME [epoch: 27.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.152427837566319		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 6.152427837566319 | validation: 6.291958563670846]
	TIME [epoch: 27.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.144061119214684		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 6.144061119214684 | validation: 5.839755523602736]
	TIME [epoch: 27.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.906914909125906		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 5.906914909125906 | validation: 5.802125727568084]
	TIME [epoch: 27.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.901217927627485		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 5.901217927627485 | validation: 5.938647620247356]
	TIME [epoch: 27.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.020751321740413		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 6.020751321740413 | validation: 5.889063241818003]
	TIME [epoch: 27.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.968536834645389		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 5.968536834645389 | validation: 5.757482412809643]
	TIME [epoch: 27.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.935570176479328		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 5.935570176479328 | validation: 5.7463198301425455]
	TIME [epoch: 27.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9326140299892245		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 5.9326140299892245 | validation: 5.71144506222792]
	TIME [epoch: 27.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.915194893505668		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 5.915194893505668 | validation: 5.945782750135246]
	TIME [epoch: 27.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.008588594065458		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 6.008588594065458 | validation: 5.821129770397625]
	TIME [epoch: 27.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.934514797141323		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 5.934514797141323 | validation: 5.912503725498982]
	TIME [epoch: 27.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.042851630965927		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 6.042851630965927 | validation: 6.17034425340242]
	TIME [epoch: 27.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0531447851849265		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 6.0531447851849265 | validation: 5.769186758638645]
	TIME [epoch: 27.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.886482968470293		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 5.886482968470293 | validation: 5.6951207154043315]
	TIME [epoch: 27.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.86752376577121		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 5.86752376577121 | validation: 5.749581198421952]
	TIME [epoch: 27.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.846563461285097		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 5.846563461285097 | validation: 5.780315712585771]
	TIME [epoch: 27.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.89504957597257		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 5.89504957597257 | validation: 5.82441601806043]
	TIME [epoch: 27.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.922237252636025		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 5.922237252636025 | validation: 5.748034679239565]
	TIME [epoch: 27.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.864263706322488		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 5.864263706322488 | validation: 6.010627808383049]
	TIME [epoch: 27.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.994213042864911		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 5.994213042864911 | validation: 6.055329573435606]
	TIME [epoch: 27.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.989532736930859		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 5.989532736930859 | validation: 5.721417662629557]
	TIME [epoch: 27.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.951018701032178		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 5.951018701032178 | validation: 5.930568506090494]
	TIME [epoch: 27.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.953138381386857		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 5.953138381386857 | validation: 5.8187097843290125]
	TIME [epoch: 27.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.020123121044573		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 6.020123121044573 | validation: 5.773306238691082]
	TIME [epoch: 27.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.01716326156875		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 6.01716326156875 | validation: 5.726782876459717]
	TIME [epoch: 27.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.946618030031184		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 5.946618030031184 | validation: 6.073103331204432]
	TIME [epoch: 27.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.997402997267004		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 5.997402997267004 | validation: 5.756349743507947]
	TIME [epoch: 27.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.921794055296741		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 5.921794055296741 | validation: 5.803981862857864]
	TIME [epoch: 27.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.886446310436551		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 5.886446310436551 | validation: 5.7089275223766105]
	TIME [epoch: 27.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.86255069051063		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 5.86255069051063 | validation: 5.777850576084454]
	TIME [epoch: 27.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.884689129191315		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 5.884689129191315 | validation: 5.778310234790135]
	TIME [epoch: 27.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.879398439898658		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 5.879398439898658 | validation: 5.731559256619221]
	TIME [epoch: 27.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9182753328065525		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 5.9182753328065525 | validation: 5.784871186082505]
	TIME [epoch: 27.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8668077042919355		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 5.8668077042919355 | validation: 5.695572362806845]
	TIME [epoch: 27.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8620123446315775		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 5.8620123446315775 | validation: 5.6985001551918275]
	TIME [epoch: 27.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.90215637414708		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 5.90215637414708 | validation: 5.680897003926495]
	TIME [epoch: 27.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.892826148834657		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 5.892826148834657 | validation: 5.652854673503663]
	TIME [epoch: 27.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.891680306446469		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 5.891680306446469 | validation: 5.7230978048102]
	TIME [epoch: 27.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.867020788597238		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 5.867020788597238 | validation: 5.703701430822726]
	TIME [epoch: 27.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.90816308653789		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 5.90816308653789 | validation: 5.707373112756711]
	TIME [epoch: 27.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8447996704393805		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 5.8447996704393805 | validation: 5.695964201931624]
	TIME [epoch: 27.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.875346757315796		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 5.875346757315796 | validation: 5.733922161792092]
	TIME [epoch: 27.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.855653253417761		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 5.855653253417761 | validation: 5.760230625872862]
	TIME [epoch: 27.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8614635549189344		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 5.8614635549189344 | validation: 5.845786444291434]
	TIME [epoch: 27.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.875184373075272		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 5.875184373075272 | validation: 5.658671244763442]
	TIME [epoch: 27.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.826390260715276		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 5.826390260715276 | validation: 5.681634770707551]
	TIME [epoch: 27.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.930090277584709		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 5.930090277584709 | validation: 5.687678273736679]
	TIME [epoch: 27.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.89202852151396		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 5.89202852151396 | validation: 5.694275876797888]
	TIME [epoch: 27.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.873663013724721		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 5.873663013724721 | validation: 5.776146060644258]
	TIME [epoch: 27.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.907631174691559		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 5.907631174691559 | validation: 5.691259556021181]
	TIME [epoch: 27.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.840013193810078		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 5.840013193810078 | validation: 7.07272385979916]
	TIME [epoch: 27.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.648301450556229		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 6.648301450556229 | validation: 5.8090163262784005]
	TIME [epoch: 27.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.107793564802147		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 6.107793564802147 | validation: 5.797507018888624]
	TIME [epoch: 27.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.077360730924477		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 6.077360730924477 | validation: 5.889748027697283]
	TIME [epoch: 27.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.960834613843571		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 5.960834613843571 | validation: 5.851327667993967]
	TIME [epoch: 27.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.987735605924863		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 5.987735605924863 | validation: 5.7831731171610885]
	TIME [epoch: 27.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.041742638650688		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 6.041742638650688 | validation: 5.916128957995318]
	TIME [epoch: 27.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.418640558927796		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 6.418640558927796 | validation: 6.635268640317504]
	TIME [epoch: 27.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7839997022067795		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 6.7839997022067795 | validation: 5.7866570768788375]
	TIME [epoch: 27.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.926576940533812		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 5.926576940533812 | validation: 5.695565832325833]
	TIME [epoch: 27.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.835916048197348		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 5.835916048197348 | validation: 5.717162882183896]
	TIME [epoch: 27.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.010894943049063		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 6.010894943049063 | validation: 5.917508750722768]
	TIME [epoch: 27.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.877617209648022		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 5.877617209648022 | validation: 5.923264483410573]
	TIME [epoch: 27.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.845480687899218		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 5.845480687899218 | validation: 5.808052147835844]
	TIME [epoch: 27.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.824190641829771		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 5.824190641829771 | validation: 5.66154799303424]
	TIME [epoch: 27.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.841161528238166		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 5.841161528238166 | validation: 5.6585155869463755]
	TIME [epoch: 27.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.80366290918888		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 5.80366290918888 | validation: 5.649229464591124]
	TIME [epoch: 27.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7935289771934135		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 5.7935289771934135 | validation: 5.616133085570384]
	TIME [epoch: 27.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.791750449216741		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 5.791750449216741 | validation: 5.689606728568633]
	TIME [epoch: 27.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.782322545133556		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 5.782322545133556 | validation: 5.767923122531035]
	TIME [epoch: 27.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.866598564920092		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 5.866598564920092 | validation: 5.697558847447994]
	TIME [epoch: 27.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.947949524259042		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 5.947949524259042 | validation: 6.322326668784016]
	TIME [epoch: 27.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.978532704741513		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 5.978532704741513 | validation: 5.60798826137089]
	TIME [epoch: 27.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.854850888504793		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 5.854850888504793 | validation: 5.757437170655295]
	TIME [epoch: 27.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.827217945869695		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 5.827217945869695 | validation: 5.655536139989758]
	TIME [epoch: 27.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.962228478751076		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 5.962228478751076 | validation: 5.699596813749154]
	TIME [epoch: 27.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.87754987491365		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 5.87754987491365 | validation: 5.867264189541932]
	TIME [epoch: 27.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.305798785370515		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 6.305798785370515 | validation: 6.678660625994624]
	TIME [epoch: 27.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.149356253537184		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 6.149356253537184 | validation: 5.89844710876582]
	TIME [epoch: 27.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.939459230230759		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 5.939459230230759 | validation: 5.638888501323136]
	TIME [epoch: 27.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.85448818254419		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 5.85448818254419 | validation: 5.742598930817564]
	TIME [epoch: 27.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.892078460186424		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 5.892078460186424 | validation: 6.113478844409889]
	TIME [epoch: 27.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.145081452548284		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 7.145081452548284 | validation: 8.487980910659896]
	TIME [epoch: 27.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.005788020025289		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 8.005788020025289 | validation: 8.335947791547387]
	TIME [epoch: 27.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.836240422183049		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 7.836240422183049 | validation: 7.26942667782459]
	TIME [epoch: 27.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.648276348985248		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 5.648276348985248 | validation: 4.847520856935473]
	TIME [epoch: 27.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468041630287518		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 4.468041630287518 | validation: 4.3040814022756635]
	TIME [epoch: 27.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.534449422861584		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 4.534449422861584 | validation: 5.361071827354931]
	TIME [epoch: 27.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.924213384261716		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 4.924213384261716 | validation: 4.008314825946012]
	TIME [epoch: 27.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.044637267925948		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 4.044637267925948 | validation: 5.46541884885396]
	TIME [epoch: 27.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.848581450877624		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 3.848581450877624 | validation: 2.804142124889562]
	TIME [epoch: 27.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.340738962574455		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 2.340738962574455 | validation: 2.0831697682307557]
	TIME [epoch: 27.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.998649997672814		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.998649997672814 | validation: 2.865230622135093]
	TIME [epoch: 27.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0896365993979678		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 2.0896365993979678 | validation: 2.7894864603670473]
	TIME [epoch: 27.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9161840823153666		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.9161840823153666 | validation: 1.9974017849886576]
	TIME [epoch: 27.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.10361240740277		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 2.10361240740277 | validation: 1.6511365168359975]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6033868766802564		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.6033868766802564 | validation: 1.8354159685449452]
	TIME [epoch: 27.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.566378809993313		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 2.566378809993313 | validation: 1.6795650183267654]
	TIME [epoch: 27.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.011044206704705		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 2.011044206704705 | validation: 1.7879295226816263]
	TIME [epoch: 27.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.719283864111353		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.719283864111353 | validation: 1.8931713595331963]
	TIME [epoch: 27.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9468150581721462		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.9468150581721462 | validation: 2.3322296557809072]
	TIME [epoch: 27.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9198361120712015		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.9198361120712015 | validation: 1.5078228673185436]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.965939080002438		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.965939080002438 | validation: 3.513832414206106]
	TIME [epoch: 27.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.255708764324678		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 2.255708764324678 | validation: 2.387612959118506]
	TIME [epoch: 27.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7492915306880739		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.7492915306880739 | validation: 1.7046282568105238]
	TIME [epoch: 28 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.089156262772402		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 2.089156262772402 | validation: 3.0461764979588684]
	TIME [epoch: 27.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.861035114893349		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.861035114893349 | validation: 1.4319003000943642]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6152653944219324		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.6152653944219324 | validation: 1.3721602136617173]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.575015306617475		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.575015306617475 | validation: 3.177573407143948]
	TIME [epoch: 28 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9329609597730233		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 2.9329609597730233 | validation: 2.5266384673524853]
	TIME [epoch: 27.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8816012886986218		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.8816012886986218 | validation: 1.3905323822971725]
	TIME [epoch: 28 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3442820412209588		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.3442820412209588 | validation: 1.5161072428986944]
	TIME [epoch: 28 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6797747825019567		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.6797747825019567 | validation: 1.8559320048184702]
	TIME [epoch: 28 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.85435997618874		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.85435997618874 | validation: 2.562930404947972]
	TIME [epoch: 28 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9840812665091547		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.9840812665091547 | validation: 1.8415583203018642]
	TIME [epoch: 27.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6036410777607881		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.6036410777607881 | validation: 1.4447435314605763]
	TIME [epoch: 27.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3951977927196455		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.3951977927196455 | validation: 2.27535868248071]
	TIME [epoch: 28 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8627404602573454		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.8627404602573454 | validation: 1.6001516399321647]
	TIME [epoch: 27.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5108320766844006		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.5108320766844006 | validation: 1.5694138823131767]
	TIME [epoch: 28 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8377753112116604		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.8377753112116604 | validation: 2.7320632810359298]
	TIME [epoch: 28 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0683360925856715		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 2.0683360925856715 | validation: 1.6293083644660766]
	TIME [epoch: 27.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4036444621071085		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.4036444621071085 | validation: 1.442192316992789]
	TIME [epoch: 27.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6775127069077107		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.6775127069077107 | validation: 1.408344926662043]
	TIME [epoch: 27.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4916418196433916		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.4916418196433916 | validation: 5.251373615998]
	TIME [epoch: 27.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.979838499593658		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 5.979838499593658 | validation: 5.812171511458758]
	TIME [epoch: 27.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.010897249363169		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 6.010897249363169 | validation: 4.847741717788546]
	TIME [epoch: 27.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4701578428334146		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 3.4701578428334146 | validation: 1.7869076749677728]
	TIME [epoch: 27.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9938422124339281		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.9938422124339281 | validation: 4.646360037073402]
	TIME [epoch: 28 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6443549592944473		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 2.6443549592944473 | validation: 1.877063533892299]
	TIME [epoch: 28 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.206265299599332		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 2.206265299599332 | validation: 1.9089665771502144]
	TIME [epoch: 27.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7689470460205814		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.7689470460205814 | validation: 1.7208905984185359]
	TIME [epoch: 28 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8342819119669422		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.8342819119669422 | validation: 1.5779161804043234]
	TIME [epoch: 28 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6713723713605233		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.6713723713605233 | validation: 1.6008688663938653]
	TIME [epoch: 27.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3947564794737932		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.3947564794737932 | validation: 2.3717516689314766]
	TIME [epoch: 28 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.566443426846205		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.566443426846205 | validation: 1.4983909414506928]
	TIME [epoch: 28 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8719565595276504		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.8719565595276504 | validation: 3.873137321192377]
	TIME [epoch: 27.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7030662116805577		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 2.7030662116805577 | validation: 1.749686926633462]
	TIME [epoch: 27.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4297507009477952		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.4297507009477952 | validation: 3.776353721803646]
	TIME [epoch: 27.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5689760989087467		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 2.5689760989087467 | validation: 1.5888637339490124]
	TIME [epoch: 27.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.696562308736118		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.696562308736118 | validation: 3.6677974242861024]
	TIME [epoch: 27.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3215711400327796		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 2.3215711400327796 | validation: 1.456978379049644]
	TIME [epoch: 27.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7555458901000907		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.7555458901000907 | validation: 1.8316540458653285]
	TIME [epoch: 27.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4623866568314594		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.4623866568314594 | validation: 1.2726271323556995]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2965598102101445		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.2965598102101445 | validation: 2.1825306033391603]
	TIME [epoch: 27.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0476418018923015		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 2.0476418018923015 | validation: 1.4841953589618744]
	TIME [epoch: 27.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3554898246012375		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.3554898246012375 | validation: 1.299807376682319]
	TIME [epoch: 28 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.533689643501935		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.533689643501935 | validation: 1.3966747214002642]
	TIME [epoch: 28 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.526575458569286		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.526575458569286 | validation: 1.2813482554916606]
	TIME [epoch: 27.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5731168412190817		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.5731168412190817 | validation: 1.3805504767858126]
	TIME [epoch: 28 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5193997384954976		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.5193997384954976 | validation: 4.44545147919482]
	TIME [epoch: 28 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.875633885507152		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 5.875633885507152 | validation: 6.026327468942205]
	TIME [epoch: 27.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.956884603263128		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 5.956884603263128 | validation: 5.8294444181677685]
	TIME [epoch: 27.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.904350280907159		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 5.904350280907159 | validation: 5.737129522596399]
	TIME [epoch: 27.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.85215881449038		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 5.85215881449038 | validation: 5.724784561480673]
	TIME [epoch: 27.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.840454397867267		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 5.840454397867267 | validation: 5.7120920987453365]
	TIME [epoch: 27.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.850464822507349		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 5.850464822507349 | validation: 5.700035190667438]
	TIME [epoch: 27.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.85424648595753		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 5.85424648595753 | validation: 5.712483352155998]
	TIME [epoch: 27.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.85111972291428		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 5.85111972291428 | validation: 6.179411757804055]
	TIME [epoch: 27.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.065039194917984		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 6.065039194917984 | validation: 5.77549089100039]
	TIME [epoch: 27.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.031951959122744		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 6.031951959122744 | validation: 6.388054034235837]
	TIME [epoch: 27.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.095717517943915		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 6.095717517943915 | validation: 5.94320703254494]
	TIME [epoch: 27.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.933034899532395		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 5.933034899532395 | validation: 5.928646074033118]
	TIME [epoch: 27.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.921636640557858		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 5.921636640557858 | validation: 5.908543683818291]
	TIME [epoch: 27.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.915659436849884		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 5.915659436849884 | validation: 5.9536916408294145]
	TIME [epoch: 27.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.930230057019092		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 5.930230057019092 | validation: 5.923098343459713]
	TIME [epoch: 27.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.153701094005371		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 6.153701094005371 | validation: 6.103395802485505]
	TIME [epoch: 27.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.052855154296818		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 6.052855154296818 | validation: 5.9635933336251865]
	TIME [epoch: 27.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.957430761522153		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 5.957430761522153 | validation: 5.932015286998649]
	TIME [epoch: 27.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.007517354876741		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 6.007517354876741 | validation: 6.062635370731157]
	TIME [epoch: 27.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.987793986497287		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 5.987793986497287 | validation: 6.007361511076856]
	TIME [epoch: 27.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.080811921315437		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 6.080811921315437 | validation: 6.128348434352961]
	TIME [epoch: 27.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0643526745945335		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 6.0643526745945335 | validation: 6.0886677496394785]
	TIME [epoch: 27.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.111014323199782		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 6.111014323199782 | validation: 6.140642766841166]
	TIME [epoch: 27.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1037900119368755		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 6.1037900119368755 | validation: 6.260419384132761]
	TIME [epoch: 27.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.172884155951602		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 6.172884155951602 | validation: 6.139454849494318]
	TIME [epoch: 27.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1263954243496475		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 6.1263954243496475 | validation: 6.262842807225454]
	TIME [epoch: 27.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.187369609374993		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 6.187369609374993 | validation: 6.204492067545163]
	TIME [epoch: 27.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.093614325972158		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 6.093614325972158 | validation: 6.832808069643568]
	TIME [epoch: 27.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.331611810758401		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 6.331611810758401 | validation: 6.3774170058832]
	TIME [epoch: 27.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.26390257655688		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 6.26390257655688 | validation: 6.494788653897232]
	TIME [epoch: 27.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.299694060432069		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 6.299694060432069 | validation: 6.323073651320249]
	TIME [epoch: 27.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.253307040015065		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 6.253307040015065 | validation: 6.3348201573834055]
	TIME [epoch: 27.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.205833600778212		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 6.205833600778212 | validation: 6.23098254222558]
	TIME [epoch: 27.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1774225034844985		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 6.1774225034844985 | validation: 6.2333752098132145]
	TIME [epoch: 27.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.222962609687883		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 6.222962609687883 | validation: 6.378960644742437]
	TIME [epoch: 27.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.194692657891633		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 6.194692657891633 | validation: 6.207001437332434]
	TIME [epoch: 27.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.136867434138239		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 6.136867434138239 | validation: 6.317697540664053]
	TIME [epoch: 27.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.136552799716206		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 6.136552799716206 | validation: 6.167680664114512]
	TIME [epoch: 27.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.97509960668593		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 5.97509960668593 | validation: 5.931861828095749]
	TIME [epoch: 27.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.851404163911665		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 5.851404163911665 | validation: 5.989564408721487]
	TIME [epoch: 27.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.221753469362944		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 6.221753469362944 | validation: 6.299896296622515]
	TIME [epoch: 27.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.149145961271068		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 6.149145961271068 | validation: 6.146519203439612]
	TIME [epoch: 27.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.060334003747977		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 6.060334003747977 | validation: 6.253746755910602]
	TIME [epoch: 27.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.093098024478151		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 6.093098024478151 | validation: 6.152705281283207]
	TIME [epoch: 27.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.997627295245418		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 5.997627295245418 | validation: 6.061434311952976]
	TIME [epoch: 27.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.120238156408811		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 6.120238156408811 | validation: 6.091949257932894]
	TIME [epoch: 27.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0375159494248525		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 6.0375159494248525 | validation: 6.147160444954186]
	TIME [epoch: 27.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.066723400035732		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 6.066723400035732 | validation: 6.089433914853203]
	TIME [epoch: 27.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.999469922258788		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 5.999469922258788 | validation: 6.234824004848219]
	TIME [epoch: 27.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.033245475375473		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 6.033245475375473 | validation: 6.1932078317579435]
	TIME [epoch: 27.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.990414048582436		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 5.990414048582436 | validation: 6.130648306033098]
	TIME [epoch: 27.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4590982600944775		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 6.4590982600944775 | validation: 7.234113683340941]
	TIME [epoch: 27.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.918457275612308		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 7.918457275612308 | validation: 9.03475606430969]
	TIME [epoch: 27.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.148791798830082		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 9.148791798830082 | validation: 8.808044769400432]
	TIME [epoch: 27.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.252767408298594		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 9.252767408298594 | validation: 10.053003842130519]
	TIME [epoch: 27.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.996199405441512		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 9.996199405441512 | validation: 9.749940483106492]
	TIME [epoch: 27.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.213752361870183		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 9.213752361870183 | validation: 8.095423619856383]
	TIME [epoch: 27.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.7553931653211885		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 7.7553931653211885 | validation: 6.440062825650795]
	TIME [epoch: 27.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.334291244469588		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 6.334291244469588 | validation: 5.7629506269725495]
	TIME [epoch: 27.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.995328796248919		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 5.995328796248919 | validation: 5.762271157255093]
	TIME [epoch: 27.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.903691094857809		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 5.903691094857809 | validation: 5.7401579245788]
	TIME [epoch: 27.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.82373437633277		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 5.82373437633277 | validation: 5.745576406535001]
	TIME [epoch: 27.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.410547457400682		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 6.410547457400682 | validation: 6.302742710448542]
	TIME [epoch: 27.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.078383843708637		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 6.078383843708637 | validation: 5.669314779166487]
	TIME [epoch: 27.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.077466591512764		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 6.077466591512764 | validation: 5.926560673597208]
	TIME [epoch: 27.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.440206095195494		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 6.440206095195494 | validation: 6.088399342869179]
	TIME [epoch: 27.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.477824382184926		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 6.477824382184926 | validation: 6.159093467109516]
	TIME [epoch: 27.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.425977079375025		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 6.425977079375025 | validation: 6.116904438150307]
	TIME [epoch: 27.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.382442601700038		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 6.382442601700038 | validation: 5.874115076463818]
	TIME [epoch: 27.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.220958185810684		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 6.220958185810684 | validation: 5.787996786758177]
	TIME [epoch: 27.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1415651058585095		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 6.1415651058585095 | validation: 5.696536603314769]
	TIME [epoch: 27.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.93346644239446		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 5.93346644239446 | validation: 5.515789556350471]
	TIME [epoch: 27.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.750558720696386		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 5.750558720696386 | validation: 5.219894840060638]
	TIME [epoch: 27.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6308838015458065		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 4.6308838015458065 | validation: 3.763141003626523]
	TIME [epoch: 27.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0975788255023535		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 3.0975788255023535 | validation: 3.1782130737038345]
	TIME [epoch: 27.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.661803401176969		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 2.661803401176969 | validation: 2.606636228148017]
	TIME [epoch: 27.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5900410498838693		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 2.5900410498838693 | validation: 2.2690400776735387]
	TIME [epoch: 28 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0401086309368193		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 2.0401086309368193 | validation: 2.105661919830838]
	TIME [epoch: 28 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.837375042269795		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.837375042269795 | validation: 3.2198461611683955]
	TIME [epoch: 28 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2515475589003193		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 2.2515475589003193 | validation: 2.156063793119891]
	TIME [epoch: 28 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7906367408546764		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.7906367408546764 | validation: 2.061434553426096]
	TIME [epoch: 28 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1024090736988095		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 2.1024090736988095 | validation: 1.5977039355447835]
	TIME [epoch: 27.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4084800552046641		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 1.4084800552046641 | validation: 1.4552449928575675]
	TIME [epoch: 28 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.41405130954763		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.41405130954763 | validation: 1.3077856302833744]
	TIME [epoch: 28 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2856210672651338		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.2856210672651338 | validation: 1.2029440240161056]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2277688821784194		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.2277688821784194 | validation: 1.3878397556060151]
	TIME [epoch: 28 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3204640527743379		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.3204640527743379 | validation: 2.1473375730766215]
	TIME [epoch: 28 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5056996621114673		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.5056996621114673 | validation: 1.591087243906235]
	TIME [epoch: 28 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3415782654218418		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.3415782654218418 | validation: 1.265403254871312]
	TIME [epoch: 28 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1592743992640582		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.1592743992640582 | validation: 1.8920466990478428]
	TIME [epoch: 28 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073258616685149		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 2.073258616685149 | validation: 1.188297184676008]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_512.pth
	Model improved!!!
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4869649691606353		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.4869649691606353 | validation: 1.0392572748668152]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_513.pth
	Model improved!!!
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2331713406147515		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.2331713406147515 | validation: 1.0620244930294527]
	TIME [epoch: 27.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144718464481907		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.144718464481907 | validation: 2.3776426222168094]
	TIME [epoch: 27.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4088860046329863		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 1.4088860046329863 | validation: 1.6950869177431003]
	TIME [epoch: 27.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4172621615340748		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.4172621615340748 | validation: 1.2888807914118616]
	TIME [epoch: 27.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1950335358319037		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.1950335358319037 | validation: 1.737937960117096]
	TIME [epoch: 27.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1800462286190843		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.1800462286190843 | validation: 2.4239390415441693]
	TIME [epoch: 28 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4594752631187922		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.4594752631187922 | validation: 1.0461659531341758]
	TIME [epoch: 27.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5129100457735407		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 1.5129100457735407 | validation: 1.3998774496314048]
	TIME [epoch: 27.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174198721621573		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.174198721621573 | validation: 1.0420204527350614]
	TIME [epoch: 28 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0656356081904717		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.0656356081904717 | validation: 1.1175353313793204]
	TIME [epoch: 27.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2755426030020733		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.2755426030020733 | validation: 1.0705344419763423]
	TIME [epoch: 27.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.001757066302087		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 1.001757066302087 | validation: 2.1580345770422715]
	TIME [epoch: 27.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3909714559451827		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.3909714559451827 | validation: 1.1092799641148827]
	TIME [epoch: 27.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9879639992302879		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.9879639992302879 | validation: 2.343961294934033]
	TIME [epoch: 27.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4942866493082247		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.4942866493082247 | validation: 2.105703169120529]
	TIME [epoch: 27.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3231197839406428		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.3231197839406428 | validation: 1.5170241416841532]
	TIME [epoch: 27.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.401524376443887		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 1.401524376443887 | validation: 1.529905991871219]
	TIME [epoch: 27.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1624760501338272		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.1624760501338272 | validation: 1.6610712432577341]
	TIME [epoch: 27.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2512100646689635		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.2512100646689635 | validation: 1.1191184400730907]
	TIME [epoch: 27.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.373818742992813		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.373818742992813 | validation: 1.6242032933732247]
	TIME [epoch: 27.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2527526445544197		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.2527526445544197 | validation: 1.0423994020224314]
	TIME [epoch: 27.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.206408051547546		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 1.206408051547546 | validation: 1.4861623421544077]
	TIME [epoch: 27.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.089509441145815		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 1.089509441145815 | validation: 1.2065517892131818]
	TIME [epoch: 27.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9692515678038462		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.9692515678038462 | validation: 1.827848266403547]
	TIME [epoch: 28 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2844002830436367		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 1.2844002830436367 | validation: 1.0817269604930606]
	TIME [epoch: 27.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.346592701674701		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 2.346592701674701 | validation: 5.92492968651326]
	TIME [epoch: 27.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.903695140351387		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 5.903695140351387 | validation: 5.7730240994031385]
	TIME [epoch: 27.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8510414221883185		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 5.8510414221883185 | validation: 5.850889742801792]
	TIME [epoch: 27.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.841261623495989		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 5.841261623495989 | validation: 5.741109553001472]
	TIME [epoch: 27.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.747328822140599		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 5.747328822140599 | validation: 5.634773358890339]
	TIME [epoch: 27.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.769347176929387		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 5.769347176929387 | validation: 5.647793287532355]
	TIME [epoch: 27.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.733461417336388		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 5.733461417336388 | validation: 5.6421099526629295]
	TIME [epoch: 27.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.827681723062799		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 5.827681723062799 | validation: 5.7883253760517235]
	TIME [epoch: 27.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.95621436953442		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 5.95621436953442 | validation: 5.820850151134655]
	TIME [epoch: 27.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.764927236973667		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 5.764927236973667 | validation: 5.7050724270787025]
	TIME [epoch: 27.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.77795623004084		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 5.77795623004084 | validation: 5.701866758703436]
	TIME [epoch: 27.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.770320091511162		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 5.770320091511162 | validation: 5.776980045529324]
	TIME [epoch: 27.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7557877160523825		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 5.7557877160523825 | validation: 5.63988916028589]
	TIME [epoch: 27.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.712911646057631		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 5.712911646057631 | validation: 5.636962619569315]
	TIME [epoch: 27.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.712683657911689		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 5.712683657911689 | validation: 5.688365313117876]
	TIME [epoch: 27.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.72827332731166		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 5.72827332731166 | validation: 5.614841931944299]
	TIME [epoch: 27.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.751236885657639		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 5.751236885657639 | validation: 6.1675872236746425]
	TIME [epoch: 27.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.930794208690246		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 5.930794208690246 | validation: 5.634706613837595]
	TIME [epoch: 27.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.716234228546304		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 5.716234228546304 | validation: 5.625140964913924]
	TIME [epoch: 27.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.699531537089567		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 5.699531537089567 | validation: 5.631002951127745]
	TIME [epoch: 27.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.724362918222622		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 5.724362918222622 | validation: 5.574635878900815]
	TIME [epoch: 27.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.668245917116381		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 5.668245917116381 | validation: 4.989695729088147]
	TIME [epoch: 27.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.088284301494643		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 4.088284301494643 | validation: 1.5841065422562566]
	TIME [epoch: 27.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1574428899710059		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 1.1574428899710059 | validation: 1.1837772623484533]
	TIME [epoch: 27.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2940648389677771		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 1.2940648389677771 | validation: 1.2452098350588714]
	TIME [epoch: 27.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0143247546835474		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 1.0143247546835474 | validation: 1.1221064707732584]
	TIME [epoch: 27.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9318119669930608		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.9318119669930608 | validation: 1.9915473167066728]
	TIME [epoch: 28 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.373437490052484		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 1.373437490052484 | validation: 1.0728025840417081]
	TIME [epoch: 27.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0101221060858494		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.0101221060858494 | validation: 1.919355694548807]
	TIME [epoch: 27.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.460537841018204		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 1.460537841018204 | validation: 1.146950542305775]
	TIME [epoch: 27.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2602600921977263		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 1.2602600921977263 | validation: 1.0259427558611456]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_569.pth
	Model improved!!!
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2082042869728928		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.2082042869728928 | validation: 1.3867077087330495]
	TIME [epoch: 27.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2991705389336654		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 1.2991705389336654 | validation: 1.5323400217184144]
	TIME [epoch: 27.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2990245303095782		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 1.2990245303095782 | validation: 1.045514522759768]
	TIME [epoch: 27.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0174203153477175		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 1.0174203153477175 | validation: 1.3937186451731924]
	TIME [epoch: 27.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8239045985172988		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 1.8239045985172988 | validation: 1.5898738419941933]
	TIME [epoch: 27.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2763258058602058		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 1.2763258058602058 | validation: 1.1617555426001063]
	TIME [epoch: 28 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9842198772790105		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.9842198772790105 | validation: 1.0139188763637927]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_576.pth
	Model improved!!!
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.133342830929776		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 1.133342830929776 | validation: 1.1504613947479683]
	TIME [epoch: 27.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1935774864317203		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 1.1935774864317203 | validation: 1.2122093465668606]
	TIME [epoch: 28 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1311527996588682		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 1.1311527996588682 | validation: 1.1882690083980476]
	TIME [epoch: 27.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.005723528699198		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 1.005723528699198 | validation: 0.9630363405715708]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_580.pth
	Model improved!!!
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0827217059529963		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 1.0827217059529963 | validation: 1.0387234636545335]
	TIME [epoch: 27.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9741524804895269		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.9741524804895269 | validation: 0.9378486413867863]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9065618393908781		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.9065618393908781 | validation: 0.9271698409778896]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_583.pth
	Model improved!!!
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1403758996795927		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 1.1403758996795927 | validation: 0.9376919213488296]
	TIME [epoch: 28 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0059502854085265		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 1.0059502854085265 | validation: 0.9305296870558519]
	TIME [epoch: 28 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0148606803402953		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 1.0148606803402953 | validation: 1.1637766916956387]
	TIME [epoch: 28 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9250832799233735		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.9250832799233735 | validation: 1.4493488948198558]
	TIME [epoch: 28 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0614976759349715		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 1.0614976759349715 | validation: 1.06206050309967]
	TIME [epoch: 28 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8732539584043182		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.8732539584043182 | validation: 0.9005892777003794]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_589.pth
	Model improved!!!
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9713369738633587		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.9713369738633587 | validation: 1.791135007066772]
	TIME [epoch: 28 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239706794062943		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.239706794062943 | validation: 0.8505981641491281]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_591.pth
	Model improved!!!
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0627449812820497		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 1.0627449812820497 | validation: 0.91056258779124]
	TIME [epoch: 28 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9190665886923918		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.9190665886923918 | validation: 1.2578149452253988]
	TIME [epoch: 27.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0226891905532187		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 1.0226891905532187 | validation: 1.27731027207648]
	TIME [epoch: 27.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3902338320279468		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 1.3902338320279468 | validation: 4.638917285840928]
	TIME [epoch: 27.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.501653793981535		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 2.501653793981535 | validation: 1.3392203113784873]
	TIME [epoch: 27.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2527649491459614		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 1.2527649491459614 | validation: 1.1896906590254208]
	TIME [epoch: 27.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5781910601017204		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 1.5781910601017204 | validation: 2.905048454640996]
	TIME [epoch: 27.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3714975061545098		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 1.3714975061545098 | validation: 0.9647018378600558]
	TIME [epoch: 27.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0924779092197372		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 1.0924779092197372 | validation: 1.0552447696195335]
	TIME [epoch: 27.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9396917501846729		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.9396917501846729 | validation: 0.895931489073338]
	TIME [epoch: 27.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8442923785657857		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.8442923785657857 | validation: 1.0155640373338115]
	TIME [epoch: 27.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8699207250574629		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.8699207250574629 | validation: 2.2439032624470903]
	TIME [epoch: 28 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7384356261712612		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 1.7384356261712612 | validation: 1.4829668752926801]
	TIME [epoch: 27.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1209890107887766		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 1.1209890107887766 | validation: 1.6332169044562992]
	TIME [epoch: 27.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.102909194168		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.102909194168 | validation: 1.2496922693208365]
	TIME [epoch: 27.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.811842648287884		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 1.811842648287884 | validation: 2.232893375159085]
	TIME [epoch: 27.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6981682980067316		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 1.6981682980067316 | validation: 1.4675231342471482]
	TIME [epoch: 27.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0984361820934527		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 1.0984361820934527 | validation: 1.097870364826219]
	TIME [epoch: 27.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0651187278692673		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 1.0651187278692673 | validation: 1.14415347933633]
	TIME [epoch: 27.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0468889072813674		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 1.0468889072813674 | validation: 1.1566101625359577]
	TIME [epoch: 27.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9910390316447806		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.9910390316447806 | validation: 2.1392216682175875]
	TIME [epoch: 27.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.119782934743254		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 2.119782934743254 | validation: 3.2639211443753346]
	TIME [epoch: 27.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2938132321011797		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 2.2938132321011797 | validation: 1.6404374147858358]
	TIME [epoch: 27.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2454074891944118		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 1.2454074891944118 | validation: 1.007628256945056]
	TIME [epoch: 28 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9262185737264883		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.9262185737264883 | validation: 1.0601310398103336]
	TIME [epoch: 28 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2966973781689215		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 1.2966973781689215 | validation: 0.8816188376786969]
	TIME [epoch: 27.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1383131738996546		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 1.1383131738996546 | validation: 0.9156631719665747]
	TIME [epoch: 28 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8979328322540844		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.8979328322540844 | validation: 1.2452221847692557]
	TIME [epoch: 28 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9387786073447663		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.9387786073447663 | validation: 1.8933126193305156]
	TIME [epoch: 27.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.207180206881281		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 1.207180206881281 | validation: 1.0219390453110968]
	TIME [epoch: 28 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9267918991265903		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.9267918991265903 | validation: 0.9855626178560539]
	TIME [epoch: 27.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.083567726092394		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 1.083567726092394 | validation: 1.0883241544120066]
	TIME [epoch: 27.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9225333229182263		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.9225333229182263 | validation: 0.9400186237846321]
	TIME [epoch: 28 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9118905995484284		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.9118905995484284 | validation: 1.8739474186337348]
	TIME [epoch: 28 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2899855142842496		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 1.2899855142842496 | validation: 1.6121653621428162]
	TIME [epoch: 27.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.133140343028197		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 1.133140343028197 | validation: 1.131540220228567]
	TIME [epoch: 27.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1267615834642746		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 1.1267615834642746 | validation: 1.4827220929990192]
	TIME [epoch: 27.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.049265208996686		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 1.049265208996686 | validation: 1.6826830094364211]
	TIME [epoch: 27.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1793115444393747		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 1.1793115444393747 | validation: 0.9730611879167672]
	TIME [epoch: 28 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9727935113275226		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.9727935113275226 | validation: 1.0543650877050073]
	TIME [epoch: 27.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1856720080177894		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 1.1856720080177894 | validation: 0.9613760550679313]
	TIME [epoch: 27.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9629551524479254		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.9629551524479254 | validation: 1.0175835330148606]
	TIME [epoch: 27.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2339556066285202		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 1.2339556066285202 | validation: 1.7844408898292758]
	TIME [epoch: 27.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1491213983064539		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 1.1491213983064539 | validation: 1.2891063416143813]
	TIME [epoch: 27.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9568968880791837		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.9568968880791837 | validation: 0.9394760251545567]
	TIME [epoch: 28 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8677971544129185		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.8677971544129185 | validation: 1.2679761747320242]
	TIME [epoch: 27.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3317262229879345		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 2.3317262229879345 | validation: 4.823043101621762]
	TIME [epoch: 27.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3948674785140067		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 2.3948674785140067 | validation: 1.0714000188477473]
	TIME [epoch: 27.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8878076812056708		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.8878076812056708 | validation: 1.515788677916134]
	TIME [epoch: 27.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0177314558477186		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 1.0177314558477186 | validation: 1.1782072096140201]
	TIME [epoch: 27.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8836793181287825		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.8836793181287825 | validation: 1.4794896505474286]
	TIME [epoch: 28 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1125983902251364		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 1.1125983902251364 | validation: 0.9316190894851255]
	TIME [epoch: 27.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2700084462821577		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 1.2700084462821577 | validation: 1.0961767739152293]
	TIME [epoch: 27.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2427289028881634		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.2427289028881634 | validation: 1.0504567720743558]
	TIME [epoch: 27.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8438535008419018		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.8438535008419018 | validation: 0.8651000595722848]
	TIME [epoch: 27.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.885443697771507		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.885443697771507 | validation: 0.8633059823260729]
	TIME [epoch: 27.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0526113902918084		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 1.0526113902918084 | validation: 1.011219229500393]
	TIME [epoch: 28 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0209854596726093		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 1.0209854596726093 | validation: 1.0041728358650073]
	TIME [epoch: 27.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9249210562524413		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.9249210562524413 | validation: 0.8900199473651079]
	TIME [epoch: 27.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8354493282394171		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.8354493282394171 | validation: 0.9370759606770085]
	TIME [epoch: 28 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8649021227688879		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.8649021227688879 | validation: 1.667693618647081]
	TIME [epoch: 27.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.175115818989998		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 1.175115818989998 | validation: 1.0089447866964114]
	TIME [epoch: 27.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0979765061900364		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 1.0979765061900364 | validation: 0.9983141175788024]
	TIME [epoch: 28 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9901765153496651		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.9901765153496651 | validation: 2.950172780202519]
	TIME [epoch: 27.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0587328477717124		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 2.0587328477717124 | validation: 1.0778434155978498]
	TIME [epoch: 27.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9001047971858387		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.9001047971858387 | validation: 1.2319717704368442]
	TIME [epoch: 27.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239838766128957		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 1.239838766128957 | validation: 1.7161937677988364]
	TIME [epoch: 27.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4627849697277586		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 1.4627849697277586 | validation: 1.5060024693539071]
	TIME [epoch: 27.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1539893387180393		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 1.1539893387180393 | validation: 1.031452012908224]
	TIME [epoch: 27.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8700891322058877		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.8700891322058877 | validation: 0.8548374285581788]
	TIME [epoch: 27.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8574646568992462		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.8574646568992462 | validation: 1.0478398821908461]
	TIME [epoch: 28 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8592069745754038		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.8592069745754038 | validation: 1.1162412413567233]
	TIME [epoch: 28.1 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.049267724060825		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 1.049267724060825 | validation: 1.2297087690929203]
	TIME [epoch: 27.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0113996432275885		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 1.0113996432275885 | validation: 1.023151688725285]
	TIME [epoch: 27.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.948838077458428		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.948838077458428 | validation: 1.1209698300791402]
	TIME [epoch: 27.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033855464151853		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 1.033855464151853 | validation: 1.1955892326356385]
	TIME [epoch: 27.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.081732636764709		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 1.081732636764709 | validation: 1.1541745626325397]
	TIME [epoch: 27.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8563661034644289		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.8563661034644289 | validation: 1.409995912551812]
	TIME [epoch: 27.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2423275699739214		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 1.2423275699739214 | validation: 0.9725544217708394]
	TIME [epoch: 27.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.889061946654578		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.889061946654578 | validation: 1.029348308554888]
	TIME [epoch: 27.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.858484518769116		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.858484518769116 | validation: 1.2643731860228462]
	TIME [epoch: 27.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0910806908792408		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 1.0910806908792408 | validation: 1.2586717105005378]
	TIME [epoch: 27.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4899798425081479		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 1.4899798425081479 | validation: 2.381379996026139]
	TIME [epoch: 27.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2509976157505234		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 1.2509976157505234 | validation: 0.9364287317559863]
	TIME [epoch: 27.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8352350221998881		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.8352350221998881 | validation: 0.9247599987521424]
	TIME [epoch: 27.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9365128183497685		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.9365128183497685 | validation: 0.8715019581092398]
	TIME [epoch: 27.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8816497773545068		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.8816497773545068 | validation: 0.9954239556545212]
	TIME [epoch: 27.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9334505840270708		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.9334505840270708 | validation: 1.1679705270366216]
	TIME [epoch: 28 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8532495767910542		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.8532495767910542 | validation: 0.8939830685496857]
	TIME [epoch: 28 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7837908102852738		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.7837908102852738 | validation: 1.2952526384029608]
	TIME [epoch: 28 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0159422930802453		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 1.0159422930802453 | validation: 0.9323457532569926]
	TIME [epoch: 28 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2694377822418947		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 1.2694377822418947 | validation: 0.8584175300487297]
	TIME [epoch: 27.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244881354677855		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 1.244881354677855 | validation: 1.2594945902860286]
	TIME [epoch: 27.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9718778183485483		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.9718778183485483 | validation: 0.8962640050645166]
	TIME [epoch: 27.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9642391952510687		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.9642391952510687 | validation: 1.1361961128284455]
	TIME [epoch: 27.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9272363988746256		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.9272363988746256 | validation: 1.4694711623815926]
	TIME [epoch: 27.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9923558796457863		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.9923558796457863 | validation: 1.1490107235665512]
	TIME [epoch: 27.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9054749753081919		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.9054749753081919 | validation: 1.2722003421686983]
	TIME [epoch: 28 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9111282844276497		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.9111282844276497 | validation: 1.252942263213749]
	TIME [epoch: 28 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0115510733102553		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 1.0115510733102553 | validation: 1.088241433855865]
	TIME [epoch: 27.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.71358121475283		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 1.71358121475283 | validation: 5.388822174501097]
	TIME [epoch: 28 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5956510593411055		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 5.5956510593411055 | validation: 5.156770551978834]
	TIME [epoch: 27.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.060860944073264		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 3.060860944073264 | validation: 1.5581355242660733]
	TIME [epoch: 28 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2327892156018088		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 1.2327892156018088 | validation: 0.8827137710017459]
	TIME [epoch: 28 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9904058565769159		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.9904058565769159 | validation: 1.505453101132479]
	TIME [epoch: 27.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0337393278799212		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 1.0337393278799212 | validation: 0.8912695161448096]
	TIME [epoch: 27.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8413699446081268		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.8413699446081268 | validation: 2.2928579569133998]
	TIME [epoch: 28 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3851647069199033		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 1.3851647069199033 | validation: 0.9075999466930241]
	TIME [epoch: 27.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.298225999391015		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 1.298225999391015 | validation: 1.2332348918512814]
	TIME [epoch: 27.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2359105493659772		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 1.2359105493659772 | validation: 1.7094614549118199]
	TIME [epoch: 28 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0176009593542275		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 1.0176009593542275 | validation: 1.0695413395269586]
	TIME [epoch: 27.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9095680597963087		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.9095680597963087 | validation: 0.8637611460917303]
	TIME [epoch: 27.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7840049485968024		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.7840049485968024 | validation: 1.4959462473761023]
	TIME [epoch: 28 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.35620735554672		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 1.35620735554672 | validation: 2.1495192588699497]
	TIME [epoch: 27.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2946373816763799		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 1.2946373816763799 | validation: 1.1098070040147363]
	TIME [epoch: 28 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8627854146148196		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.8627854146148196 | validation: 1.4738607460939148]
	TIME [epoch: 27.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.985858477719979		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.985858477719979 | validation: 1.1942130417461534]
	TIME [epoch: 27.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0152781509236388		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 1.0152781509236388 | validation: 0.9559434935667601]
	TIME [epoch: 28 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9982394384707298		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.9982394384707298 | validation: 1.1919750469422912]
	TIME [epoch: 27.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8626767366143935		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.8626767366143935 | validation: 0.8371622741329438]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_711.pth
	Model improved!!!
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8307713472131011		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.8307713472131011 | validation: 1.6367740238740909]
	TIME [epoch: 28 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1628708107442443		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 1.1628708107442443 | validation: 1.2348319359723647]
	TIME [epoch: 27.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.920356274580469		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.920356274580469 | validation: 0.8615124390706791]
	TIME [epoch: 28 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9177679328780537		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.9177679328780537 | validation: 0.928350029438889]
	TIME [epoch: 28 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0628914396704985		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 1.0628914396704985 | validation: 1.420838205187547]
	TIME [epoch: 27.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9971184667573193		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.9971184667573193 | validation: 0.9638839907376894]
	TIME [epoch: 27.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1448063729671591		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 1.1448063729671591 | validation: 1.2816918706070635]
	TIME [epoch: 28 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9301035954331693		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.9301035954331693 | validation: 1.2224077543696488]
	TIME [epoch: 27.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9517034416632966		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.9517034416632966 | validation: 1.0887386203374814]
	TIME [epoch: 28 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8649564619841039		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.8649564619841039 | validation: 1.0262974305710952]
	TIME [epoch: 27.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8401395541118668		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.8401395541118668 | validation: 0.8636289345552257]
	TIME [epoch: 27.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.803753917098761		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.803753917098761 | validation: 0.9110716524726185]
	TIME [epoch: 28 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8878194828963287		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.8878194828963287 | validation: 1.038222551874968]
	TIME [epoch: 28 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9073561327812912		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.9073561327812912 | validation: 0.81308694586817]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_725.pth
	Model improved!!!
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7769123262197136		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.7769123262197136 | validation: 0.9406877081632063]
	TIME [epoch: 28 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1440326964700764		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 1.1440326964700764 | validation: 0.8160770476091946]
	TIME [epoch: 28 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9500128766426329		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.9500128766426329 | validation: 1.0486974835734595]
	TIME [epoch: 27.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0355827508623754		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 1.0355827508623754 | validation: 1.610538318226237]
	TIME [epoch: 28 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9851078954565567		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.9851078954565567 | validation: 1.1235546289205316]
	TIME [epoch: 28 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8789704699178207		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.8789704699178207 | validation: 1.030942432296748]
	TIME [epoch: 27.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.90087727902408		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.90087727902408 | validation: 1.3837658058697813]
	TIME [epoch: 28 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1260749746349192		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 1.1260749746349192 | validation: 1.152904865761944]
	TIME [epoch: 27.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8908138612208292		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.8908138612208292 | validation: 0.8164100026425968]
	TIME [epoch: 27.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9617199413049103		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.9617199413049103 | validation: 1.3644328687094376]
	TIME [epoch: 27.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.622937518041728		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 2.622937518041728 | validation: 2.3086002403732913]
	TIME [epoch: 27.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3072107418049164		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 1.3072107418049164 | validation: 1.7731659822101224]
	TIME [epoch: 27.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0777922452582174		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 1.0777922452582174 | validation: 0.9036841405739726]
	TIME [epoch: 27.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9121890610533994		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 2.9121890610533994 | validation: 5.199363303770744]
	TIME [epoch: 27.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.253749164763674		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 5.253749164763674 | validation: 5.812472173459894]
	TIME [epoch: 27.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.971482344243059		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 5.971482344243059 | validation: 5.851964866894211]
	TIME [epoch: 27.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.793413887742981		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 5.793413887742981 | validation: 5.64516197374252]
	TIME [epoch: 27.9 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6851531141338425		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 5.6851531141338425 | validation: 5.526186649771294]
	TIME [epoch: 27.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.655381877602642		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 5.655381877602642 | validation: 5.607027424624787]
	TIME [epoch: 27.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.66407825612185		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 5.66407825612185 | validation: 5.52770904341922]
	TIME [epoch: 27.9 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.658611735432536		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 5.658611735432536 | validation: 5.497757043647315]
	TIME [epoch: 27.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.638742306493916		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 5.638742306493916 | validation: 5.550702246389074]
	TIME [epoch: 27.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.685224950542855		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 5.685224950542855 | validation: 5.502740635378564]
	TIME [epoch: 27.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.636858375660589		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 5.636858375660589 | validation: 5.53241336838516]
	TIME [epoch: 27.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.649240300623846		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 5.649240300623846 | validation: 5.519573264656159]
	TIME [epoch: 27.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.62390738007894		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 5.62390738007894 | validation: 5.519458449273066]
	TIME [epoch: 27.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.631064730960248		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 5.631064730960248 | validation: 5.520351838643205]
	TIME [epoch: 27.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.621764373861685		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 5.621764373861685 | validation: 5.41641521414888]
	TIME [epoch: 27.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.586812040028941		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 5.586812040028941 | validation: 5.531806430377781]
	TIME [epoch: 27.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.653731329172267		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 5.653731329172267 | validation: 5.560066537193652]
	TIME [epoch: 27.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.641590551108081		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 5.641590551108081 | validation: 5.498804331492933]
	TIME [epoch: 27.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.619533443048507		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 5.619533443048507 | validation: 5.496946560852542]
	TIME [epoch: 27.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6324565408641725		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 5.6324565408641725 | validation: 5.5474432375678]
	TIME [epoch: 27.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.637872074921299		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 5.637872074921299 | validation: 5.545021453795102]
	TIME [epoch: 27.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.652209993988211		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 5.652209993988211 | validation: 5.500102037022931]
	TIME [epoch: 27.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.623072889477554		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 5.623072889477554 | validation: 5.504137156308348]
	TIME [epoch: 27.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.653040741785649		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 5.653040741785649 | validation: 5.577773285060964]
	TIME [epoch: 27.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.657477938244202		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 5.657477938244202 | validation: 5.539374786150371]
	TIME [epoch: 27.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.626912898400864		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 5.626912898400864 | validation: 5.486708315525059]
	TIME [epoch: 27.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.616659653454706		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 5.616659653454706 | validation: 5.513672173824464]
	TIME [epoch: 27.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.64049991855865		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 5.64049991855865 | validation: 5.563824602732571]
	TIME [epoch: 27.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.669675698618518		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 5.669675698618518 | validation: 5.553015011095006]
	TIME [epoch: 27.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.63644351847947		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 5.63644351847947 | validation: 5.50892865245739]
	TIME [epoch: 27.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.626872189994335		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 5.626872189994335 | validation: 5.504713995288682]
	TIME [epoch: 27.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.636165852682707		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 5.636165852682707 | validation: 5.503713228738634]
	TIME [epoch: 27.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.625550922037475		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 5.625550922037475 | validation: 5.5403153362994155]
	TIME [epoch: 27.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6191192348260435		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 5.6191192348260435 | validation: 5.504799178049914]
	TIME [epoch: 27.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.63018546648544		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 5.63018546648544 | validation: 5.498445891654278]
	TIME [epoch: 28 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.625109603246445		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 5.625109603246445 | validation: 5.690798755373101]
	TIME [epoch: 27.9 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.964051314159024		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 5.964051314159024 | validation: 5.651151596268435]
	TIME [epoch: 27.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.661306178349511		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 5.661306178349511 | validation: 5.519425337776276]
	TIME [epoch: 27.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.627980836748009		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 5.627980836748009 | validation: 5.525763599037738]
	TIME [epoch: 27.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.626124348871829		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 5.626124348871829 | validation: 5.524390609776165]
	TIME [epoch: 27.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.618477255045082		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 5.618477255045082 | validation: 5.560062172000958]
	TIME [epoch: 27.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.63738855882408		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 5.63738855882408 | validation: 5.569365108560298]
	TIME [epoch: 27.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.659840866492006		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 5.659840866492006 | validation: 5.5843845858414305]
	TIME [epoch: 27.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.635746334952402		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 5.635746334952402 | validation: 5.552019182053372]
	TIME [epoch: 27.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.627241107063824		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 5.627241107063824 | validation: 5.560383108582483]
	TIME [epoch: 27.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6454245816300475		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 5.6454245816300475 | validation: 5.585647976373998]
	TIME [epoch: 27.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.660203959663477		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 5.660203959663477 | validation: 5.524602851030259]
	TIME [epoch: 27.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.61068545870094		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 5.61068545870094 | validation: 5.553129026493116]
	TIME [epoch: 27.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.658945893011344		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 5.658945893011344 | validation: 5.5274289880324226]
	TIME [epoch: 27.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.640309533603837		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 5.640309533603837 | validation: 5.525297125270133]
	TIME [epoch: 27.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.637391195168561		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 5.637391195168561 | validation: 5.537669952705483]
	TIME [epoch: 27.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.619588734440725		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 5.619588734440725 | validation: 5.543496994541939]
	TIME [epoch: 27.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6373033808042665		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 5.6373033808042665 | validation: 5.511949496134839]
	TIME [epoch: 27.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.638567249302948		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 5.638567249302948 | validation: 5.571079973238065]
	TIME [epoch: 27.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.791332639876934		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 5.791332639876934 | validation: 5.916663021553352]
	TIME [epoch: 27.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.837495309453337		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 5.837495309453337 | validation: 5.5158316743648035]
	TIME [epoch: 27.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.630660782792715		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 5.630660782792715 | validation: 5.506024424480962]
	TIME [epoch: 27.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6538672035633954		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 5.6538672035633954 | validation: 5.508164593364354]
	TIME [epoch: 27.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.670538948311407		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 5.670538948311407 | validation: 5.463533551371836]
	TIME [epoch: 27.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.606610129744501		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 5.606610129744501 | validation: 5.4737676600481135]
	TIME [epoch: 27.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.638270606221949		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 5.638270606221949 | validation: 5.482264276907212]
	TIME [epoch: 27.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.594759896417122		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 5.594759896417122 | validation: 5.493114982624859]
	TIME [epoch: 27.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7580845704285375		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 5.7580845704285375 | validation: 5.783889740244302]
	TIME [epoch: 27.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.906204663834494		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 5.906204663834494 | validation: 5.67897696970216]
	TIME [epoch: 27.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.798612981058774		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 5.798612981058774 | validation: 5.556659945857048]
	TIME [epoch: 27.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.653205632550118		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 5.653205632550118 | validation: 5.471949566962117]
	TIME [epoch: 27.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.611187570611907		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 5.611187570611907 | validation: 5.482469612170158]
	TIME [epoch: 27.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.605144602323781		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 5.605144602323781 | validation: 5.552430914979132]
	TIME [epoch: 27.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.62628052020899		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 5.62628052020899 | validation: 5.501731157132788]
	TIME [epoch: 27.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.606758247564399		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 5.606758247564399 | validation: 5.503237693539711]
	TIME [epoch: 27.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.605330292094949		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 5.605330292094949 | validation: 5.505835996492796]
	TIME [epoch: 27.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6166661278528665		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 5.6166661278528665 | validation: 5.4832330146195725]
	TIME [epoch: 27.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.604255040035907		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 5.604255040035907 | validation: 5.486556928401097]
	TIME [epoch: 27.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.649880069178113		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 5.649880069178113 | validation: 5.5169585833256995]
	TIME [epoch: 27.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.602340697464214		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 5.602340697464214 | validation: 5.490646213585822]
	TIME [epoch: 27.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5982067382875185		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 5.5982067382875185 | validation: 5.488538162168817]
	TIME [epoch: 27.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.602866555638492		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 5.602866555638492 | validation: 5.473572389369638]
	TIME [epoch: 27.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.621494127714423		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 5.621494127714423 | validation: 5.5119852333732045]
	TIME [epoch: 27.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.667535278296718		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 5.667535278296718 | validation: 5.545084690281973]
	TIME [epoch: 27.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.761358390626055		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 5.761358390626055 | validation: 5.679591108734833]
	TIME [epoch: 27.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.835116426032328		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 5.835116426032328 | validation: 5.666646831042401]
	TIME [epoch: 27.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.771210648822161		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 5.771210648822161 | validation: 5.561378393536269]
	TIME [epoch: 27.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.659087444516811		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 5.659087444516811 | validation: 5.461092520842807]
	TIME [epoch: 27.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.613522219740737		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 5.613522219740737 | validation: 5.4660857657498605]
	TIME [epoch: 27.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.647575988426458		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 5.647575988426458 | validation: 5.593799242279979]
	TIME [epoch: 27.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.695279750376016		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 5.695279750376016 | validation: 5.491860770018548]
	TIME [epoch: 27.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.616992556625327		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 5.616992556625327 | validation: 5.465693112550381]
	TIME [epoch: 27.9 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.601960666050123		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 5.601960666050123 | validation: 5.456910151023173]
	TIME [epoch: 27.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.591418474585292		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 5.591418474585292 | validation: 5.444828179666573]
	TIME [epoch: 27.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.592653348036846		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 5.592653348036846 | validation: 5.445942556253458]
	TIME [epoch: 27.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6167692115265195		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 5.6167692115265195 | validation: 5.455235804175413]
	TIME [epoch: 27.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.616954635933534		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 5.616954635933534 | validation: 5.5607958621045075]
	TIME [epoch: 27.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.660097591954163		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 5.660097591954163 | validation: 5.454799685286564]
	TIME [epoch: 27.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.614356916274852		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 5.614356916274852 | validation: 5.464865080398283]
	TIME [epoch: 27.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.601100303768874		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 5.601100303768874 | validation: 5.459462956179395]
	TIME [epoch: 27.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.604859353212224		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 5.604859353212224 | validation: 5.507084633291174]
	TIME [epoch: 27.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.666267360235247		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 5.666267360235247 | validation: 5.494295124143055]
	TIME [epoch: 27.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.602124688390908		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 5.602124688390908 | validation: 5.452397074806665]
	TIME [epoch: 27.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.588882465459564		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 5.588882465459564 | validation: 5.459528069509904]
	TIME [epoch: 27.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.579077169215867		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 5.579077169215867 | validation: 5.474663872373409]
	TIME [epoch: 27.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.628542312227908		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 5.628542312227908 | validation: 5.49942182673606]
	TIME [epoch: 27.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.583202995768875		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 5.583202995768875 | validation: 5.479480120371077]
	TIME [epoch: 27.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.582785497843126		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 5.582785497843126 | validation: 5.481534069477671]
	TIME [epoch: 27.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.603447951496003		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 5.603447951496003 | validation: 5.5066824909077585]
	TIME [epoch: 27.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.637327737452552		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 5.637327737452552 | validation: 5.490786744343618]
	TIME [epoch: 27.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.62635030543026		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 5.62635030543026 | validation: 5.472904114199982]
	TIME [epoch: 27.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.594614639737258		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 5.594614639737258 | validation: 5.441380925487831]
	TIME [epoch: 27.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.602698925390183		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 5.602698925390183 | validation: 5.49735712696501]
	TIME [epoch: 27.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.604174485445601		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 5.604174485445601 | validation: 5.495206499397864]
	TIME [epoch: 27.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.597810898190685		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 5.597810898190685 | validation: 5.463380180578111]
	TIME [epoch: 27.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.573338232468102		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 5.573338232468102 | validation: 5.447779719702495]
	TIME [epoch: 27.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.583503027729288		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 5.583503027729288 | validation: 5.469454901425185]
	TIME [epoch: 27.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.578263359180236		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 5.578263359180236 | validation: 5.4575764149061365]
	TIME [epoch: 27.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5892378282252695		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 5.5892378282252695 | validation: 5.476873952750101]
	TIME [epoch: 27.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.579905279083462		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 5.579905279083462 | validation: 5.444540982067085]
	TIME [epoch: 27.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.595242599015614		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 5.595242599015614 | validation: 5.450513878871387]
	TIME [epoch: 28 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.587066240475627		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 5.587066240475627 | validation: 5.482142666868289]
	TIME [epoch: 27.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.623305996495194		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 5.623305996495194 | validation: 5.481518810548291]
	TIME [epoch: 27.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.640194920008227		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 5.640194920008227 | validation: 5.505561825544651]
	TIME [epoch: 27.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.590447965763239		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 5.590447965763239 | validation: 5.462204631831619]
	TIME [epoch: 27.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.708699053440515		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 5.708699053440515 | validation: 5.680968919924249]
	TIME [epoch: 27.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.807950138553825		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 5.807950138553825 | validation: 5.713655870084124]
	TIME [epoch: 27.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8649040999658215		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 5.8649040999658215 | validation: 5.675884830664675]
	TIME [epoch: 27.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8183420993913515		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 5.8183420993913515 | validation: 5.7618509217090335]
	TIME [epoch: 27.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.857560432014735		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 5.857560432014735 | validation: 5.595487268103088]
	TIME [epoch: 27.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.765507289992896		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 5.765507289992896 | validation: 5.6299606845409835]
	TIME [epoch: 27.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.778447383236125		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 5.778447383236125 | validation: 5.60960858113016]
	TIME [epoch: 27.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.737272752569485		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 5.737272752569485 | validation: 5.5702990108869725]
	TIME [epoch: 27.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.705648729017349		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 5.705648729017349 | validation: 5.571813981570308]
	TIME [epoch: 27.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.710122294881063		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 5.710122294881063 | validation: 5.582856426735453]
	TIME [epoch: 27.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.685016013279382		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 5.685016013279382 | validation: 5.5462270755321]
	TIME [epoch: 27.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.651632995098199		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 5.651632995098199 | validation: 5.481889771201869]
	TIME [epoch: 27.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.606107141773144		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 5.606107141773144 | validation: 5.501538596475025]
	TIME [epoch: 27.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.59338462396582		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 5.59338462396582 | validation: 5.471875404910056]
	TIME [epoch: 28 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6033153335252734		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 5.6033153335252734 | validation: 5.551759346885274]
	TIME [epoch: 27.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.682439631024866		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 5.682439631024866 | validation: 5.568280050522673]
	TIME [epoch: 27.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6896179576302535		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 5.6896179576302535 | validation: 5.604368669100161]
	TIME [epoch: 27.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.664735663986264		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 5.664735663986264 | validation: 5.533676718509845]
	TIME [epoch: 27.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.634987847264902		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 5.634987847264902 | validation: 5.52210153093858]
	TIME [epoch: 27.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.627888107651409		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 5.627888107651409 | validation: 5.501038621572509]
	TIME [epoch: 27.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.650541040707138		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 5.650541040707138 | validation: 5.572575466716223]
	TIME [epoch: 27.8 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.636409921556795		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 5.636409921556795 | validation: 5.553746060463639]
	TIME [epoch: 27.9 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.683131652633058		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 5.683131652633058 | validation: 5.508394897751571]
	TIME [epoch: 27.9 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.620303306565762		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 5.620303306565762 | validation: 5.555999457766986]
	TIME [epoch: 27.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.628568635363876		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 5.628568635363876 | validation: 5.518348763114216]
	TIME [epoch: 27.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.610182019947786		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 5.610182019947786 | validation: 5.466547248692375]
	TIME [epoch: 27.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.577881546584129		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 5.577881546584129 | validation: 5.468218627591589]
	TIME [epoch: 27.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.586532812895564		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 5.586532812895564 | validation: 5.5139257158620625]
	TIME [epoch: 27.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.597240163632999		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 5.597240163632999 | validation: 5.486880091150333]
	TIME [epoch: 27.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.605345555404311		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 5.605345555404311 | validation: 5.493092587995147]
	TIME [epoch: 27.9 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.608601648485554		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 5.608601648485554 | validation: 5.510618479168161]
	TIME [epoch: 27.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.603368977850705		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 5.603368977850705 | validation: 5.557226496794523]
	TIME [epoch: 27.9 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6172780382585294		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 5.6172780382585294 | validation: 5.51228428283124]
	TIME [epoch: 27.9 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.59137567770496		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 5.59137567770496 | validation: 5.513448247606107]
	TIME [epoch: 27.9 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.590570328633201		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 5.590570328633201 | validation: 5.514615989435089]
	TIME [epoch: 27.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.590135881710119		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 5.590135881710119 | validation: 5.51517693350977]
	TIME [epoch: 27.9 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.587558472741427		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 5.587558472741427 | validation: 5.479380199254115]
	TIME [epoch: 27.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.574111009228667		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 5.574111009228667 | validation: 5.505850707562643]
	TIME [epoch: 27.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.587902075503891		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 5.587902075503891 | validation: 5.507548011440457]
	TIME [epoch: 27.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.61118026188013		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 5.61118026188013 | validation: 5.532792132865272]
	TIME [epoch: 28 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6094002259423785		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 5.6094002259423785 | validation: 5.516946837016667]
	TIME [epoch: 27.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.593911979070907		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 5.593911979070907 | validation: 5.5053926003132485]
	TIME [epoch: 27.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.589242579582588		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 5.589242579582588 | validation: 5.522065424852769]
	TIME [epoch: 27.9 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.587829689273343		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 5.587829689273343 | validation: 5.548959288155867]
	TIME [epoch: 27.9 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.612740003366328		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 5.612740003366328 | validation: 5.501827581144524]
	TIME [epoch: 27.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.601963721161909		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 5.601963721161909 | validation: 5.508550922442752]
	TIME [epoch: 27.9 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.603687033146159		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 5.603687033146159 | validation: 5.484150989910675]
	TIME [epoch: 27.9 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.602680292876931		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 5.602680292876931 | validation: 5.488555089261264]
	TIME [epoch: 27.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.625560345043743		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 5.625560345043743 | validation: 5.486568100338307]
	TIME [epoch: 27.9 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.57961476204237		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 5.57961476204237 | validation: 5.44837079759053]
	TIME [epoch: 27.9 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.579586817172888		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 5.579586817172888 | validation: 5.45919785045045]
	TIME [epoch: 27.9 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.558750629698952		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 5.558750629698952 | validation: 5.463047612510049]
	TIME [epoch: 28 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.577654173412605		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 5.577654173412605 | validation: 5.5158785942188135]
	TIME [epoch: 27.9 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.584507420588102		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 5.584507420588102 | validation: 5.48892294662623]
	TIME [epoch: 27.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.592753647528019		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 5.592753647528019 | validation: 5.468429320630273]
	TIME [epoch: 28 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.576182564974088		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 5.576182564974088 | validation: 5.45365710030017]
	TIME [epoch: 27.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5831503744957995		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 5.5831503744957995 | validation: 5.548598533528952]
	TIME [epoch: 27.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.678591987837786		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 5.678591987837786 | validation: 5.574167174733051]
	TIME [epoch: 27.9 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.828292840188451		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 5.828292840188451 | validation: 6.005235673734356]
	TIME [epoch: 27.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.222833090977623		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 6.222833090977623 | validation: 6.284324115404573]
	TIME [epoch: 27.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.58214710211833		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 6.58214710211833 | validation: 6.8145573139916475]
	TIME [epoch: 27.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.984567499853904		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 6.984567499853904 | validation: 6.757818118230094]
	TIME [epoch: 27.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.855976429336669		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 6.855976429336669 | validation: 6.482167834946463]
	TIME [epoch: 27.9 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6622037926009465		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 6.6622037926009465 | validation: 6.47813627259587]
	TIME [epoch: 27.9 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5809148209596025		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 6.5809148209596025 | validation: 6.265267756061613]
	TIME [epoch: 27.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.358431780872582		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 6.358431780872582 | validation: 6.161528119674095]
	TIME [epoch: 27.9 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.206041049511292		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 6.206041049511292 | validation: 5.896232132341795]
	TIME [epoch: 27.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.986041007954355		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 5.986041007954355 | validation: 5.84937917201473]
	TIME [epoch: 27.9 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0238971385269995		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 6.0238971385269995 | validation: 5.882400252283876]
	TIME [epoch: 27.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.046338585574251		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 6.046338585574251 | validation: 5.876509354960417]
	TIME [epoch: 27.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.061891989442157		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 6.061891989442157 | validation: 5.815331921460946]
	TIME [epoch: 27.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.899848716439715		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 5.899848716439715 | validation: 5.613141134783027]
	TIME [epoch: 27.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.761182212714657		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 5.761182212714657 | validation: 5.53884762002176]
	TIME [epoch: 27.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.667589381848685		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 5.667589381848685 | validation: 5.5030541352855735]
	TIME [epoch: 27.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.619825171535372		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 5.619825171535372 | validation: 5.461972093229786]
	TIME [epoch: 27.9 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5839894758976145		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 5.5839894758976145 | validation: 5.431787597146988]
	TIME [epoch: 27.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.570727817800844		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 5.570727817800844 | validation: 5.440633622370392]
	TIME [epoch: 27.8 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.578992037364985		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 5.578992037364985 | validation: 5.45437815100794]
	TIME [epoch: 27.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.580445539804569		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 5.580445539804569 | validation: 5.434037561567284]
	TIME [epoch: 27.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.57217765227905		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 5.57217765227905 | validation: 5.441968090811438]
	TIME [epoch: 27.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.575059529296748		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 5.575059529296748 | validation: 5.435878381857251]
	TIME [epoch: 27.9 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5773040584365745		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 5.5773040584365745 | validation: 5.4510644743839185]
	TIME [epoch: 27.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5923346066226705		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 5.5923346066226705 | validation: 5.507127688987853]
	TIME [epoch: 27.9 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.607929071263488		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 5.607929071263488 | validation: 5.440847368548796]
	TIME [epoch: 27.9 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5707006883687855		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 5.5707006883687855 | validation: 5.427360459342428]
	TIME [epoch: 27.9 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.567185027226173		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 5.567185027226173 | validation: 5.438961195618999]
	TIME [epoch: 27.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.562478366214918		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 5.562478366214918 | validation: 5.4336935923975735]
	TIME [epoch: 27.9 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.573683286228874		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 5.573683286228874 | validation: 5.433692847588792]
	TIME [epoch: 27.9 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.566099645722579		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 5.566099645722579 | validation: 5.4326313848641385]
	TIME [epoch: 27.9 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.57233137217698		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 5.57233137217698 | validation: 5.452512512975649]
	TIME [epoch: 27.9 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.586798366764715		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 5.586798366764715 | validation: 5.44200244295986]
	TIME [epoch: 27.9 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.568030815964963		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 5.568030815964963 | validation: 5.42183181880205]
	TIME [epoch: 27.9 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.59413145818194		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 5.59413145818194 | validation: 5.58955463436179]
	TIME [epoch: 27.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.754914496170198		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 5.754914496170198 | validation: 5.652240457184344]
	TIME [epoch: 27.9 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.832518868574645		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 5.832518868574645 | validation: 5.6964625202706385]
	TIME [epoch: 27.9 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.763274226167363		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 5.763274226167363 | validation: 5.5916596372935405]
	TIME [epoch: 27.9 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.673072926540176		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 5.673072926540176 | validation: 5.466419167370124]
	TIME [epoch: 27.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5988174449451975		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 5.5988174449451975 | validation: 5.460437412256676]
	TIME [epoch: 27.9 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.587359666678699		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 5.587359666678699 | validation: 5.4223627091034965]
	TIME [epoch: 27.9 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.573797211517436		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 5.573797211517436 | validation: 5.449344468091919]
	TIME [epoch: 27.9 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.579625571707855		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 5.579625571707855 | validation: 5.440609801860619]
	TIME [epoch: 27.9 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.596340157029629		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 5.596340157029629 | validation: 5.434985173939792]
	TIME [epoch: 27.9 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.569021748710309		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 5.569021748710309 | validation: 5.4600048332740325]
	TIME [epoch: 27.9 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.598568695320586		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 5.598568695320586 | validation: 5.43443531228108]
	TIME [epoch: 27.9 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.583571200239738		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 5.583571200239738 | validation: 5.47350125792058]
	TIME [epoch: 27.9 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.615901368590114		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 5.615901368590114 | validation: 5.472672730930164]
	TIME [epoch: 27.9 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.639821642105506		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 5.639821642105506 | validation: 5.460745087894877]
	TIME [epoch: 27.9 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.632260210721152		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 5.632260210721152 | validation: 5.464362252660404]
	TIME [epoch: 27.9 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.58485444353926		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 5.58485444353926 | validation: 5.4232091995819385]
	TIME [epoch: 27.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.572583318445444		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 5.572583318445444 | validation: 5.422046153368765]
	TIME [epoch: 27.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.57576607839662		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 5.57576607839662 | validation: 5.422756397039577]
	TIME [epoch: 27.9 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.579600988238014		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 5.579600988238014 | validation: 5.432925732331945]
	TIME [epoch: 27.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.577171910307999		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 5.577171910307999 | validation: 5.450109138171809]
	TIME [epoch: 27.9 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.593329464928679		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 5.593329464928679 | validation: 5.44481800992676]
	TIME [epoch: 27.9 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.588989562934877		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 5.588989562934877 | validation: 5.433112251050769]
	TIME [epoch: 27.9 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.621304912487312		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 5.621304912487312 | validation: 5.5378618244016105]
	TIME [epoch: 27.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6295891770344895		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 5.6295891770344895 | validation: 5.427162950170469]
	TIME [epoch: 27.9 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.585396729324208		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 5.585396729324208 | validation: 5.4318052736309435]
	TIME [epoch: 27.9 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.565149952635323		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 5.565149952635323 | validation: 5.419536400212597]
	TIME [epoch: 27.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5709187769225395		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 5.5709187769225395 | validation: 5.433973178875004]
	TIME [epoch: 27.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.59093042630035		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 5.59093042630035 | validation: 5.443781752293708]
	TIME [epoch: 27.9 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6018391851929845		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 5.6018391851929845 | validation: 5.490300006250135]
	TIME [epoch: 27.9 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.681519654559289		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 5.681519654559289 | validation: 5.584642819474393]
	TIME [epoch: 27.8 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7211992073328926		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 5.7211992073328926 | validation: 5.594925823691603]
	TIME [epoch: 27.9 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.666909033656575		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 5.666909033656575 | validation: 5.454168435739457]
	TIME [epoch: 27.9 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.599021414705683		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 5.599021414705683 | validation: 5.431315116450336]
	TIME [epoch: 27.8 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.578394293989747		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 5.578394293989747 | validation: 5.433558165154783]
	TIME [epoch: 27.9 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.589757965122052		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 5.589757965122052 | validation: 5.475097069205001]
	TIME [epoch: 27.9 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.652731051746277		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 5.652731051746277 | validation: 5.556400735353905]
	TIME [epoch: 27.9 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.675748959356552		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 5.675748959356552 | validation: 5.492304123440788]
	TIME [epoch: 27.9 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6045037270503375		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 5.6045037270503375 | validation: 5.414636757321772]
	TIME [epoch: 27.9 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5700134666027		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 5.5700134666027 | validation: 5.423938335735864]
	TIME [epoch: 27.9 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.587727264809879		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 5.587727264809879 | validation: 5.459481031234755]
	TIME [epoch: 27.9 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.667842860949314		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 5.667842860949314 | validation: 5.556660877786437]
	TIME [epoch: 27.9 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742528952231145		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 5.742528952231145 | validation: 5.627713251045066]
	TIME [epoch: 27.9 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.748458908549699		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 5.748458908549699 | validation: 5.563155540566981]
	TIME [epoch: 27.9 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.687167806585958		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 5.687167806585958 | validation: 5.5868028838750075]
	TIME [epoch: 27.9 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.801301722113837		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 5.801301722113837 | validation: 5.743688544370919]
	TIME [epoch: 27.9 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.866365346510567		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 5.866365346510567 | validation: 5.706468661998902]
	TIME [epoch: 27.9 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.891347868712668		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 5.891347868712668 | validation: 5.855291642598378]
	TIME [epoch: 27.9 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1361458285292905		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 6.1361458285292905 | validation: 6.085322007119376]
	TIME [epoch: 27.9 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.321709744997429		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 6.321709744997429 | validation: 6.393950037316901]
	TIME [epoch: 27.9 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.521169531139893		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 6.521169531139893 | validation: 6.2281203774667055]
	TIME [epoch: 27.9 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.467649574458283		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 6.467649574458283 | validation: 6.308928396743356]
	TIME [epoch: 27.9 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.514216533056734		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 6.514216533056734 | validation: 6.18175228256388]
	TIME [epoch: 27.9 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.479355422620634		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 6.479355422620634 | validation: 6.269140071005737]
	TIME [epoch: 27.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.507314278122986		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 6.507314278122986 | validation: 6.022184901574704]
	TIME [epoch: 27.9 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2093403782627705		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 6.2093403782627705 | validation: 5.744890240666025]
	TIME [epoch: 27.9 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.954508185080554		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 5.954508185080554 | validation: 5.596500009483139]
	TIME [epoch: 27.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.704275336600896		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 5.704275336600896 | validation: 5.2833826616600845]
	TIME [epoch: 27.9 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.288256685892601		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 5.288256685892601 | validation: 4.562901746851766]
	TIME [epoch: 27.9 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.228481226190222		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 4.228481226190222 | validation: 3.2994485620048035]
	TIME [epoch: 27.9 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5168516716529195		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 2.5168516716529195 | validation: 2.130309220499494]
	TIME [epoch: 27.9 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6814965382734939		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 1.6814965382734939 | validation: 1.715198922638603]
	TIME [epoch: 28 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4717958550159123		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 1.4717958550159123 | validation: 1.5896673481284622]
	TIME [epoch: 27.9 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3615889391024016		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 1.3615889391024016 | validation: 1.502294534475564]
	TIME [epoch: 27.9 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3430498164588156		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 1.3430498164588156 | validation: 1.3531501733804203]
	TIME [epoch: 27.9 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2830221389177425		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 1.2830221389177425 | validation: 1.3074997874294738]
	TIME [epoch: 27.9 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.26502325772188		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 1.26502325772188 | validation: 1.655401912338017]
	TIME [epoch: 27.9 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2296330706942582		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 1.2296330706942582 | validation: 1.2645520522921876]
	TIME [epoch: 27.9 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1698892305393458		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 1.1698892305393458 | validation: 1.2814066022522572]
	TIME [epoch: 27.9 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1308870537980358		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 1.1308870537980358 | validation: 1.4377358248352452]
	TIME [epoch: 28 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1600874676919253		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 1.1600874676919253 | validation: 1.3290378712038202]
	TIME [epoch: 28 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1508720727916486		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 1.1508720727916486 | validation: 1.1942664779701884]
	TIME [epoch: 28 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1309614517941984		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 1.1309614517941984 | validation: 1.3348844851414527]
	TIME [epoch: 28 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.098655112712646		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 1.098655112712646 | validation: 1.1236193963880907]
	TIME [epoch: 28 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0720653469970949		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 1.0720653469970949 | validation: 1.2893446240891615]
	TIME [epoch: 27.9 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0656315073807276		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 1.0656315073807276 | validation: 1.223169334703664]
	TIME [epoch: 28 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0031198591579928		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 1.0031198591579928 | validation: 1.0887915847922125]
	TIME [epoch: 27.9 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9892291644194858		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.9892291644194858 | validation: 1.0054386590043167]
	TIME [epoch: 27.9 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9447310390312316		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.9447310390312316 | validation: 1.0183681791462968]
	TIME [epoch: 27.9 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9215875893175456		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.9215875893175456 | validation: 1.1171169693940022]
	TIME [epoch: 27.9 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.981230307513297		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.981230307513297 | validation: 1.105470579389704]
	TIME [epoch: 27.9 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9486219237131673		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.9486219237131673 | validation: 1.0130433425617187]
	TIME [epoch: 28 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8658090323971068		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.8658090323971068 | validation: 1.1946281547522442]
	TIME [epoch: 28 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9589519044205194		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.9589519044205194 | validation: 0.9682004059427626]
	TIME [epoch: 27.9 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9056217616085196		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.9056217616085196 | validation: 1.2028101478350477]
	TIME [epoch: 28 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9226013887851433		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.9226013887851433 | validation: 1.1839700215178734]
	TIME [epoch: 27.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9160189641956017		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.9160189641956017 | validation: 0.9807692259454922]
	TIME [epoch: 27.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8182324305518959		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.8182324305518959 | validation: 0.8888974155644473]
	TIME [epoch: 27.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7829046461138871		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.7829046461138871 | validation: 0.8697255667193119]
	TIME [epoch: 27.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.793766324981665		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.793766324981665 | validation: 0.9728313217888578]
	TIME [epoch: 28 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8276397194363974		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.8276397194363974 | validation: 0.8769721154265763]
	TIME [epoch: 28 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8913117265099688		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.8913117265099688 | validation: 0.9496204131278626]
	TIME [epoch: 27.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0006243445832128		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 1.0006243445832128 | validation: 1.033257220270586]
	TIME [epoch: 28 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8165974806720412		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.8165974806720412 | validation: 1.0430765150209944]
	TIME [epoch: 28 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8977882353548872		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.8977882353548872 | validation: 0.8918324839016186]
	TIME [epoch: 27.9 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7788206000281408		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.7788206000281408 | validation: 0.8529248201965841]
	TIME [epoch: 27.9 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9599697131896715		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.9599697131896715 | validation: 1.1098993996155833]
	TIME [epoch: 27.9 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8446190247404721		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.8446190247404721 | validation: 0.9559961813594124]
	TIME [epoch: 27.9 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9616443893678865		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.9616443893678865 | validation: 0.8152184828883288]
	TIME [epoch: 27.9 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9286841209043768		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.9286841209043768 | validation: 0.9438232959413639]
	TIME [epoch: 27.9 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7821682106471688		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.7821682106471688 | validation: 0.8825028895316379]
	TIME [epoch: 27.9 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.756724714163978		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.756724714163978 | validation: 0.8483043566393059]
	TIME [epoch: 27.9 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.900761055304103		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.900761055304103 | validation: 0.9034235970637088]
	TIME [epoch: 27.9 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7307521445050962		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.7307521445050962 | validation: 0.805504031073925]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_1054.pth
	Model improved!!!
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171402879051667		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.7171402879051667 | validation: 0.7795732957046786]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_1055.pth
	Model improved!!!
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7749172170356582		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.7749172170356582 | validation: 1.1915099478184656]
	TIME [epoch: 27.9 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9362433841145388		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.9362433841145388 | validation: 0.8138002806332031]
	TIME [epoch: 27.9 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7837382843118761		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.7837382843118761 | validation: 0.8160771245749189]
	TIME [epoch: 27.9 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248142897869995		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.7248142897869995 | validation: 0.8316629565708852]
	TIME [epoch: 27.9 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7816697763599113		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.7816697763599113 | validation: 0.8206174248296432]
	TIME [epoch: 27.9 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7782270438767726		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.7782270438767726 | validation: 0.8157273561959285]
	TIME [epoch: 27.9 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8872139558248862		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.8872139558248862 | validation: 1.1227119756835264]
	TIME [epoch: 27.9 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.918459148260507		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.918459148260507 | validation: 0.7983112346658098]
	TIME [epoch: 27.9 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7655447905294908		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.7655447905294908 | validation: 1.1066610215645083]
	TIME [epoch: 27.9 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.836642179325259		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.836642179325259 | validation: 0.7803406764642601]
	TIME [epoch: 27.9 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207998851568959		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.7207998851568959 | validation: 1.2080303373416745]
	TIME [epoch: 27.9 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8779432094589604		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.8779432094589604 | validation: 0.8211712656348092]
	TIME [epoch: 27.9 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9016346447699364		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.9016346447699364 | validation: 0.8412448249028452]
	TIME [epoch: 27.9 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7904401405690862		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.7904401405690862 | validation: 0.8203835314101042]
	TIME [epoch: 27.9 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7397375963654506		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.7397375963654506 | validation: 0.8608922648426]
	TIME [epoch: 27.9 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7907569140182887		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.7907569140182887 | validation: 1.3069423992683349]
	TIME [epoch: 27.9 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234753140580569		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 1.234753140580569 | validation: 0.8559034548812585]
	TIME [epoch: 27.9 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7099716590395163		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.7099716590395163 | validation: 0.8470141944471111]
	TIME [epoch: 27.9 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042896171832247		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.7042896171832247 | validation: 0.9300268950632136]
	TIME [epoch: 27.9 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7778985979253648		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.7778985979253648 | validation: 0.7918505254367965]
	TIME [epoch: 27.9 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865353795597626		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.6865353795597626 | validation: 0.8132139164041524]
	TIME [epoch: 27.9 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7100005730987551		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.7100005730987551 | validation: 0.8340711716891963]
	TIME [epoch: 27.9 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879322395908429		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.6879322395908429 | validation: 0.838057617708655]
	TIME [epoch: 27.9 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7569881354299561		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.7569881354299561 | validation: 0.783643802960187]
	TIME [epoch: 27.9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7364233413169368		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.7364233413169368 | validation: 0.8933024059922064]
	TIME [epoch: 27.9 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7384075713462018		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.7384075713462018 | validation: 0.8422255834111482]
	TIME [epoch: 27.9 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712249214506449		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.712249214506449 | validation: 0.8233045215082052]
	TIME [epoch: 27.9 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8129309668283101		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.8129309668283101 | validation: 0.8184770528141817]
	TIME [epoch: 27.9 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7012715500620998		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.7012715500620998 | validation: 0.7941547697623702]
	TIME [epoch: 27.9 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042460336668606		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.7042460336668606 | validation: 0.811938945338066]
	TIME [epoch: 27.9 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8987356888785132		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.8987356888785132 | validation: 0.9598839298255976]
	TIME [epoch: 27.9 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719310314621108		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.719310314621108 | validation: 0.8134623925614008]
	TIME [epoch: 27.9 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6906110788249642		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.6906110788249642 | validation: 0.8430857034018047]
	TIME [epoch: 27.9 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7169503765309717		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.7169503765309717 | validation: 0.8113019564079106]
	TIME [epoch: 27.9 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7496003470730662		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.7496003470730662 | validation: 0.7984812172123017]
	TIME [epoch: 27.9 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6806953549251162		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.6806953549251162 | validation: 0.84323480477553]
	TIME [epoch: 27.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6918139816237483		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.6918139816237483 | validation: 0.7909212269362002]
	TIME [epoch: 27.9 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7481409779762209		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.7481409779762209 | validation: 0.8090759367055619]
	TIME [epoch: 27.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6969071650813232		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.6969071650813232 | validation: 0.9292946163046384]
	TIME [epoch: 27.9 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.86022043909142		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.86022043909142 | validation: 0.909101462755452]
	TIME [epoch: 27.9 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8677165695910476		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.8677165695910476 | validation: 0.8384539990803278]
	TIME [epoch: 27.9 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7133154749298197		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.7133154749298197 | validation: 0.8301067553528415]
	TIME [epoch: 27.9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.799634498467777		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.799634498467777 | validation: 0.8363593569467406]
	TIME [epoch: 27.9 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030086474824826		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.7030086474824826 | validation: 0.7741704232227576]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_1099.pth
	Model improved!!!
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7632996613365071		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.7632996613365071 | validation: 0.8171980005203503]
	TIME [epoch: 27.9 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7674154717773927		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.7674154717773927 | validation: 0.7610924492088239]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_1101.pth
	Model improved!!!
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7128495786708187		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.7128495786708187 | validation: 0.8208759232407354]
	TIME [epoch: 27.9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6764023752063302		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.6764023752063302 | validation: 0.7858900323723108]
	TIME [epoch: 27.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7441127799048382		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.7441127799048382 | validation: 0.765896106957299]
	TIME [epoch: 27.9 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265424856252005		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.7265424856252005 | validation: 1.3613976366440645]
	TIME [epoch: 27.9 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0563376319138387		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 1.0563376319138387 | validation: 0.7586659808036186]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_1106.pth
	Model improved!!!
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7608298689745454		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.7608298689745454 | validation: 0.7913887951809855]
	TIME [epoch: 27.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.707175657922658		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.707175657922658 | validation: 0.7631304983875485]
	TIME [epoch: 27.9 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6618429257616867		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.6618429257616867 | validation: 0.7612112294945889]
	TIME [epoch: 27.9 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7439468954724162		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.7439468954724162 | validation: 0.8962193975474452]
	TIME [epoch: 27.9 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7374629734461902		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.7374629734461902 | validation: 0.9445940498002906]
	TIME [epoch: 27.9 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7305283052141633		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.7305283052141633 | validation: 0.7996925051465007]
	TIME [epoch: 27.9 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849858487089919		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.6849858487089919 | validation: 0.7506353171611687]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_1113.pth
	Model improved!!!
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187177100500242		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.7187177100500242 | validation: 0.7538148992722694]
	TIME [epoch: 27.9 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7670425638436518		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.7670425638436518 | validation: 0.7426594389874148]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_1115.pth
	Model improved!!!
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6779336256819272		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.6779336256819272 | validation: 0.8141582858752894]
	TIME [epoch: 27.9 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.854891092677137		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.854891092677137 | validation: 0.7890134863601582]
	TIME [epoch: 27.9 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6934072034595296		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.6934072034595296 | validation: 0.7869361695072885]
	TIME [epoch: 27.9 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8900395763590863		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.8900395763590863 | validation: 0.9319428894764223]
	TIME [epoch: 27.9 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712712549573455		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.712712549573455 | validation: 0.7505443742474043]
	TIME [epoch: 27.9 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6676973240794025		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.6676973240794025 | validation: 0.782914768679383]
	TIME [epoch: 27.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6977563714363311		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.6977563714363311 | validation: 0.7821793898570618]
	TIME [epoch: 27.9 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6778607912586119		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.6778607912586119 | validation: 0.7894260218463868]
	TIME [epoch: 27.9 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854219262260043		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.6854219262260043 | validation: 0.7718394675172644]
	TIME [epoch: 27.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6669600379529608		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.6669600379529608 | validation: 0.7441006307212348]
	TIME [epoch: 27.9 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231747079802291		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.7231747079802291 | validation: 0.7375939907230447]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240310_003041/states/model_tr_study5_1126.pth
	Model improved!!!
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835554077265692		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.6835554077265692 | validation: 0.7475553494577889]
	TIME [epoch: 27.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888734869997895		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.6888734869997895 | validation: 0.7875636570317776]
	TIME [epoch: 27.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7320204123863201		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.7320204123863201 | validation: 0.9292875890077136]
	TIME [epoch: 27.9 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7471246652083248		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.7471246652083248 | validation: 0.8168671616229748]
	TIME [epoch: 27.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968110054022283		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.6968110054022283 | validation: 0.7636933838586256]
	TIME [epoch: 27.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7005812878606825		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.7005812878606825 | validation: 0.8152391477110136]
	TIME [epoch: 27.9 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7367865497660174		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.7367865497660174 | validation: 0.7432336377872628]
	TIME [epoch: 27.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6731486851440404		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.6731486851440404 | validation: 0.7611648757046497]
	TIME [epoch: 27.9 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.67056140434022		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.67056140434022 | validation: 0.7751299829568966]
	TIME [epoch: 27.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6664934239301694		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.6664934239301694 | validation: 0.7995497772766931]
	TIME [epoch: 27.9 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023649534185871		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.7023649534185871 | validation: 0.7663665921208193]
	TIME [epoch: 27.9 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.669788695714561		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.669788695714561 | validation: 0.7653424640239463]
	TIME [epoch: 27.9 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7011287205617708		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.7011287205617708 | validation: 0.8310442767597002]
	TIME [epoch: 27.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7515770077650888		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.7515770077650888 | validation: 0.9772847468532444]
	TIME [epoch: 27.9 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7281120709678298		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.7281120709678298 | validation: 0.7759940349177004]
	TIME [epoch: 27.9 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6714302830980732		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.6714302830980732 | validation: 0.7803159280922611]
	TIME [epoch: 27.9 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9005406221476249		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.9005406221476249 | validation: 1.2852189455538303]
	TIME [epoch: 27.9 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8576823473830124		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.8576823473830124 | validation: 0.8766311540054692]
	TIME [epoch: 27.9 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9742086133233127		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.9742086133233127 | validation: 0.8729470967229779]
	TIME [epoch: 27.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234397760355085		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.7234397760355085 | validation: 0.8265008749438321]
	TIME [epoch: 27.9 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7118112033287491		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.7118112033287491 | validation: 0.7701329496256055]
	TIME [epoch: 27.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7941296994557749		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.7941296994557749 | validation: 0.8325478930487171]
	TIME [epoch: 27.9 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7440680958509288		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.7440680958509288 | validation: 0.7822100473166814]
	TIME [epoch: 27.9 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850687502683287		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.6850687502683287 | validation: 0.7736313136153935]
	TIME [epoch: 27.9 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6734955803985793		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.6734955803985793 | validation: 0.8059016586243191]
	TIME [epoch: 27.9 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6791181052497005		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.6791181052497005 | validation: 0.749033379069035]
	TIME [epoch: 27.9 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6776187306791459		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.6776187306791459 | validation: 0.7825965592107598]
	TIME [epoch: 27.9 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7026515869637748		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.7026515869637748 | validation: 0.8995108146511633]
	TIME [epoch: 27.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7032079562095391		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.7032079562095391 | validation: 0.8305802230013299]
	TIME [epoch: 27.9 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7537127094012945		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.7537127094012945 | validation: 0.7685149365673806]
	TIME [epoch: 27.9 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832008347479372		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.6832008347479372 | validation: 0.7930740049465407]
	TIME [epoch: 27.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7616193568313905		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.7616193568313905 | validation: 0.8163484233628896]
	TIME [epoch: 27.9 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6904447447196221		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.6904447447196221 | validation: 0.771067270528651]
	TIME [epoch: 27.9 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6620000897474039		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.6620000897474039 | validation: 0.7896964918676486]
	TIME [epoch: 27.9 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6926750392801322		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.6926750392801322 | validation: 0.9020871430245159]
	TIME [epoch: 27.9 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7531679735845213		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.7531679735845213 | validation: 0.7909884452785702]
	TIME [epoch: 27.9 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255037620373725		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.7255037620373725 | validation: 0.8640501764510751]
	TIME [epoch: 27.9 sec]
EPOCH 1164/2000:
	Training over batches...
