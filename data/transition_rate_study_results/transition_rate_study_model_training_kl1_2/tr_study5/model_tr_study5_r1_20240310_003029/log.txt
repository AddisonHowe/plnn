Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r1', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 253810791

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.744879979271774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.744879979271774 | validation: 8.751835721425435]
	TIME [epoch: 113 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.38898489371022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.38898489371022 | validation: 7.206630714450516]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.878151626144676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.878151626144676 | validation: 8.916161723278647]
	TIME [epoch: 24.9 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.8995281932634835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.8995281932634835 | validation: 6.402957224816912]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.63687920201639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.63687920201639 | validation: 5.989288993049099]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.025111939621543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.025111939621543 | validation: 5.98913527367933]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.836589990543096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.836589990543096 | validation: 6.217015812230269]
	TIME [epoch: 25 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.033796282839607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.033796282839607 | validation: 5.8439816381348635]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.55251477915196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.55251477915196 | validation: 5.711085718599957]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.666541205026378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.666541205026378 | validation: 5.739288585180762]
	TIME [epoch: 25 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.659396824118133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.659396824118133 | validation: 5.686690702899383]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.602351907881359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.602351907881359 | validation: 5.638251857143864]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.646881500670255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.646881500670255 | validation: 7.736631965985337]
	TIME [epoch: 25 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.876431117053939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.876431117053939 | validation: 5.733030585146639]
	TIME [epoch: 25 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.634812627102607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.634812627102607 | validation: 5.348088879623181]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.601754868936997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.601754868936997 | validation: 5.642017526915323]
	TIME [epoch: 25 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.777948204733098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.777948204733098 | validation: 5.499692468818498]
	TIME [epoch: 25 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.616392212219393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.616392212219393 | validation: 5.5575043479031825]
	TIME [epoch: 25 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.654907827460872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.654907827460872 | validation: 5.871685428486594]
	TIME [epoch: 25 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.693316962912841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.693316962912841 | validation: 5.739210041703727]
	TIME [epoch: 25 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.723062385365187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.723062385365187 | validation: 5.6088910786534125]
	TIME [epoch: 25 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.643817194659525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.643817194659525 | validation: 5.596037417214785]
	TIME [epoch: 25 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.550202384750913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.550202384750913 | validation: 5.479892545900352]
	TIME [epoch: 25 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.532046581394977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.532046581394977 | validation: 5.620022920221799]
	TIME [epoch: 25 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.720749496182599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.720749496182599 | validation: 5.480045990451905]
	TIME [epoch: 25 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.945607859609042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.945607859609042 | validation: 12.43331623910885]
	TIME [epoch: 25 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.811033143253171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.811033143253171 | validation: 6.093783810354638]
	TIME [epoch: 25 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.175696718524223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.175696718524223 | validation: 6.06168548070486]
	TIME [epoch: 25 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0147346287140175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0147346287140175 | validation: 5.866468023823704]
	TIME [epoch: 25 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7804164514256025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7804164514256025 | validation: 5.6930060362649035]
	TIME [epoch: 25 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.734151532611286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.734151532611286 | validation: 5.589259107187952]
	TIME [epoch: 25 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.702931823930055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.702931823930055 | validation: 5.566851243484593]
	TIME [epoch: 25 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.812669430795527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.812669430795527 | validation: 5.829208722506736]
	TIME [epoch: 25 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.723952633301845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.723952633301845 | validation: 5.562347955230978]
	TIME [epoch: 25 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.743363851254957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.743363851254957 | validation: 5.735746668141331]
	TIME [epoch: 25 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.602179473349349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.602179473349349 | validation: 5.714436247464053]
	TIME [epoch: 25 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.500273083704704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.500273083704704 | validation: 7.573233313529971]
	TIME [epoch: 25 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.0810337628669995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.0810337628669995 | validation: 5.730189229267615]
	TIME [epoch: 25 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.757209035658695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.757209035658695 | validation: 5.603555741795003]
	TIME [epoch: 25 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.731087455349302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.731087455349302 | validation: 5.98950198437868]
	TIME [epoch: 24.9 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.654083512596233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.654083512596233 | validation: 5.526275196011141]
	TIME [epoch: 25 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.474157868567664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.474157868567664 | validation: 5.475629633491929]
	TIME [epoch: 25 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.756264675230035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.756264675230035 | validation: 5.4279392695987]
	TIME [epoch: 25 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.458337618980613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.458337618980613 | validation: 5.553555958331996]
	TIME [epoch: 25 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.489625256990932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.489625256990932 | validation: 5.312724060022881]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.407709456487152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.407709456487152 | validation: 5.15800494117175]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8953570335878736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8953570335878736 | validation: 6.946464831179817]
	TIME [epoch: 25 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.105554374132725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.105554374132725 | validation: 5.599183909277217]
	TIME [epoch: 24.9 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.999909573369621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.999909573369621 | validation: 5.593516990930147]
	TIME [epoch: 25 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4308285584471445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4308285584471445 | validation: 5.32140220720592]
	TIME [epoch: 25 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.40528008747761		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.40528008747761 | validation: 5.2340764264495885]
	TIME [epoch: 24.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.406459158563506		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.406459158563506 | validation: 5.723887949676073]
	TIME [epoch: 25 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.692433707675159		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.692433707675159 | validation: 5.222465735839109]
	TIME [epoch: 25 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.35265395319394		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.35265395319394 | validation: 5.117225181663549]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.497123984708605		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 6.497123984708605 | validation: 5.091486702357574]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.525959647446366		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 6.525959647446366 | validation: 5.143931791389177]
	TIME [epoch: 24.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.239087631977778		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.239087631977778 | validation: 5.02493296345802]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2174059442617216		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 5.2174059442617216 | validation: 4.9765593315345695]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.101415960990807		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.101415960990807 | validation: 4.874326062762499]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.388891996394859		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.388891996394859 | validation: 5.943275820038498]
	TIME [epoch: 24.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.694133796012036		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.694133796012036 | validation: 4.939566170252152]
	TIME [epoch: 24.9 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.04097172424208		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.04097172424208 | validation: 4.880248214277095]
	TIME [epoch: 24.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5227329618190275		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 5.5227329618190275 | validation: 5.373351090711317]
	TIME [epoch: 24.9 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.377415717621738		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 5.377415717621738 | validation: 5.08225412955224]
	TIME [epoch: 24.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.973627663442267		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.973627663442267 | validation: 4.882397541687726]
	TIME [epoch: 25 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.950951054497895		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.950951054497895 | validation: 4.875010174502056]
	TIME [epoch: 25 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.868923125855272		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.868923125855272 | validation: 4.694882676135752]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.574782347178525		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 5.574782347178525 | validation: 5.362657544126754]
	TIME [epoch: 25 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.350260306172384		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 5.350260306172384 | validation: 4.733080724169372]
	TIME [epoch: 25 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.535350210815898		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.535350210815898 | validation: 5.39426415198452]
	TIME [epoch: 25 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.114957858296657		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 5.114957858296657 | validation: 4.775162724265126]
	TIME [epoch: 25 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.391812895485887		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 5.391812895485887 | validation: 4.643729051469161]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.15750810900061		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 5.15750810900061 | validation: 4.742181505067344]
	TIME [epoch: 25 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.746144426323609		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.746144426323609 | validation: 4.562604748225299]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.558364208923821		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 5.558364208923821 | validation: 6.406689202365665]
	TIME [epoch: 25 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.590562151295815		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 5.590562151295815 | validation: 4.716676820828525]
	TIME [epoch: 24.9 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.535100700194782		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 5.535100700194782 | validation: 7.065846542582023]
	TIME [epoch: 25 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.704455062626672		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 5.704455062626672 | validation: 4.7412785960271515]
	TIME [epoch: 25 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.766063658348042		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.766063658348042 | validation: 4.647227268573654]
	TIME [epoch: 25 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.035771012480919		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 5.035771012480919 | validation: 4.580010037773577]
	TIME [epoch: 25 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.686261784283069		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.686261784283069 | validation: 4.741961885311054]
	TIME [epoch: 25 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.560977468948594		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.560977468948594 | validation: 4.456444913985175]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.607640254999827		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.607640254999827 | validation: 5.109212575880086]
	TIME [epoch: 25 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.778963906281616		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.778963906281616 | validation: 4.47134377198405]
	TIME [epoch: 25 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.429624093331393		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.429624093331393 | validation: 4.209942120317991]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.284244989873515		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 4.284244989873515 | validation: 4.092976316828854]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2662939563740885		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.2662939563740885 | validation: 4.018697403485798]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.254788561881371		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 4.254788561881371 | validation: 3.9214933770473777]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.980773127663345		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.980773127663345 | validation: 4.042578824290205]
	TIME [epoch: 25 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9239392026708595		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.9239392026708595 | validation: 4.252207075349191]
	TIME [epoch: 25 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.04951564954584		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.04951564954584 | validation: 3.6985543964295493]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9421967411783685		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.9421967411783685 | validation: 3.6465236165246564]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.629694534773513		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.629694534773513 | validation: 5.542172212254104]
	TIME [epoch: 25 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1566960807978415		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 5.1566960807978415 | validation: 3.704503971194924]
	TIME [epoch: 24.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.942642904151246		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.942642904151246 | validation: 3.389076270811305]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.662784023350833		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.662784023350833 | validation: 3.4460576842952166]
	TIME [epoch: 25 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.423853089437072		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.423853089437072 | validation: 3.7256168332306685]
	TIME [epoch: 25 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4461032031181835		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.4461032031181835 | validation: 3.519666083639373]
	TIME [epoch: 25 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3410708837842362		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.3410708837842362 | validation: 3.2567296371139003]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.386014316409053		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.386014316409053 | validation: 3.281385489789397]
	TIME [epoch: 25 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1188676799410135		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.1188676799410135 | validation: 2.9004501881266482]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1254959145051107		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.1254959145051107 | validation: 2.8278516307843318]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3625685409689337		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.3625685409689337 | validation: 2.761268499487569]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2111997341218057		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.2111997341218057 | validation: 2.6869945576122523]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.832282361226651		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.832282361226651 | validation: 2.629669479713273]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.595377927427073		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.595377927427073 | validation: 2.942796966504705]
	TIME [epoch: 25 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7332732703486		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.7332732703486 | validation: 2.976016436931593]
	TIME [epoch: 24.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.631035176624613		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.631035176624613 | validation: 3.1917042665346096]
	TIME [epoch: 25 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.009988244083779		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.009988244083779 | validation: 3.169859216341955]
	TIME [epoch: 25 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9108571410681585		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.9108571410681585 | validation: 3.817487541870445]
	TIME [epoch: 25 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.076654550830246		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.076654550830246 | validation: 2.7987484851350866]
	TIME [epoch: 24.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.687660029513531		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.687660029513531 | validation: 2.781611435578779]
	TIME [epoch: 25 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.444709931058407		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.444709931058407 | validation: 2.126528778099296]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4656189074439543		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.4656189074439543 | validation: 2.4377005849869677]
	TIME [epoch: 25 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5320308807875325		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.5320308807875325 | validation: 2.4702718700242148]
	TIME [epoch: 25 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3570922380075747		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.3570922380075747 | validation: 2.2780765402224072]
	TIME [epoch: 25 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3236906432076525		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.3236906432076525 | validation: 2.253063492963261]
	TIME [epoch: 25 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7582485887014743		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.7582485887014743 | validation: 2.446166788481215]
	TIME [epoch: 24.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.592634037111226		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.592634037111226 | validation: 2.4109556957984957]
	TIME [epoch: 25 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284554691024076		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.284554691024076 | validation: 2.7581988847962124]
	TIME [epoch: 25 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.330248268817754		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.330248268817754 | validation: 2.6290746781805883]
	TIME [epoch: 25 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7915452757768664		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.7915452757768664 | validation: 2.683781773992208]
	TIME [epoch: 24.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.219535253587394		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.219535253587394 | validation: 2.0677749869096127]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1490709417468894		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.1490709417468894 | validation: 2.061797894106055]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312083895088937		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.312083895088937 | validation: 2.9524476588708524]
	TIME [epoch: 24.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.526908812066223		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.526908812066223 | validation: 2.5403337095804703]
	TIME [epoch: 25 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5278471198979884		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.5278471198979884 | validation: 3.421293930201589]
	TIME [epoch: 25 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7135951522802766		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.7135951522802766 | validation: 2.70039322890626]
	TIME [epoch: 24.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314675443890177		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.314675443890177 | validation: 2.0279784437890895]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.225475257364155		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.225475257364155 | validation: 2.7401135711428912]
	TIME [epoch: 25 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.987099551171712		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.987099551171712 | validation: 2.533999794353928]
	TIME [epoch: 25 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.957580064270181		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.957580064270181 | validation: 1.8885482933368467]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9974409875335932		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.9974409875335932 | validation: 1.9132039614147736]
	TIME [epoch: 25 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7918015200963728		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.7918015200963728 | validation: 1.9881166889614992]
	TIME [epoch: 24.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9008400566382393		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.9008400566382393 | validation: 2.1110097987384835]
	TIME [epoch: 25 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9097440755528794		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.9097440755528794 | validation: 2.494890565325193]
	TIME [epoch: 24.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4458602111893413		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.4458602111893413 | validation: 2.616739737465523]
	TIME [epoch: 25 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7693955023317542		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.7693955023317542 | validation: 2.3413249988708977]
	TIME [epoch: 25 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.744301915672593		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.744301915672593 | validation: 2.827954134480232]
	TIME [epoch: 25 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4583201731402116		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.4583201731402116 | validation: 2.1269910111810963]
	TIME [epoch: 25 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.159482733162662		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.159482733162662 | validation: 2.5223017756604187]
	TIME [epoch: 25 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4796192110755753		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.4796192110755753 | validation: 1.8797421628783815]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6499930212236114		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.6499930212236114 | validation: 1.8888955826526945]
	TIME [epoch: 25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6317156258039514		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.6317156258039514 | validation: 1.6195394036811417]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7044489510910719		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.7044489510910719 | validation: 1.5889024042136175]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8170975410196397		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.8170975410196397 | validation: 1.9734732810437123]
	TIME [epoch: 25 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9510868522717635		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.9510868522717635 | validation: 2.470228434326801]
	TIME [epoch: 25 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.766058733337582		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.766058733337582 | validation: 1.520487882021991]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3020869672217588		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.3020869672217588 | validation: 2.2979418232655697]
	TIME [epoch: 25 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.377195501080558		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.377195501080558 | validation: 1.7952455319738017]
	TIME [epoch: 25 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9256800860039156		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.9256800860039156 | validation: 2.0660303046859054]
	TIME [epoch: 25 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7066328460611526		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.7066328460611526 | validation: 2.5017672256018297]
	TIME [epoch: 25 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6321921226824747		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.6321921226824747 | validation: 2.034144315646642]
	TIME [epoch: 25 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2645507701268928		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.2645507701268928 | validation: 2.53240659710355]
	TIME [epoch: 25 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8657207534861104		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.8657207534861104 | validation: 2.892918121105041]
	TIME [epoch: 25 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3933842155657317		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.3933842155657317 | validation: 1.9847611004550758]
	TIME [epoch: 25 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1291959412785237		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.1291959412785237 | validation: 1.9027251260672886]
	TIME [epoch: 25 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1742180654495677		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.1742180654495677 | validation: 4.7415656601261205]
	TIME [epoch: 25 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2755785511823468		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.2755785511823468 | validation: 2.920152052340311]
	TIME [epoch: 25 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.506341938894807		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.506341938894807 | validation: 1.9630977804000893]
	TIME [epoch: 25 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.893495528065307		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.893495528065307 | validation: 1.5314805723933012]
	TIME [epoch: 25 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5758942398383986		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.5758942398383986 | validation: 2.7254400945694135]
	TIME [epoch: 25 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.413452445158569		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.413452445158569 | validation: 1.9684167856401562]
	TIME [epoch: 25 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1421395392940306		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.1421395392940306 | validation: 1.8917562523105818]
	TIME [epoch: 25 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.36817927834354		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.36817927834354 | validation: 2.856955939420315]
	TIME [epoch: 25 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.379995188323739		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.379995188323739 | validation: 2.0627070293654053]
	TIME [epoch: 25 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.18571811835376		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.18571811835376 | validation: 2.392012869052947]
	TIME [epoch: 25 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053262745200941		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.053262745200941 | validation: 2.671185067097955]
	TIME [epoch: 25 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8795498920890576		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.8795498920890576 | validation: 4.086423558371757]
	TIME [epoch: 25 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6072482717979644		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.6072482717979644 | validation: 1.5108295310956106]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5846478802469344		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.5846478802469344 | validation: 1.5506400408337124]
	TIME [epoch: 25 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4472347107413541		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.4472347107413541 | validation: 1.3909882695810623]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240310_003029/states/model_tr_study5_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3799925357673335		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.3799925357673335 | validation: 1.5100014221704505]
	TIME [epoch: 25 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7566488255457582		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.7566488255457582 | validation: 1.4168462196649154]
	TIME [epoch: 25 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6965746987564447		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.6965746987564447 | validation: 3.2172836381404673]
	TIME [epoch: 25 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.38530287722852		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.38530287722852 | validation: 2.0313303283614594]
	TIME [epoch: 25 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5822678019074097		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 3.5822678019074097 | validation: 6.949764793544794]
	TIME [epoch: 25 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.78317410765271		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 6.78317410765271 | validation: 5.43395242656896]
	TIME [epoch: 25 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.16942480135097		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 6.16942480135097 | validation: 5.407827408664002]
	TIME [epoch: 25 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.226325092423196		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 6.226325092423196 | validation: 5.698019721855074]
	TIME [epoch: 25 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.158856851285765		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 6.158856851285765 | validation: 5.628377296239395]
	TIME [epoch: 25 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.243419498108747		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 6.243419498108747 | validation: 5.502543148004275]
	TIME [epoch: 25 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.07408266573254		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 6.07408266573254 | validation: 5.41863889727557]
	TIME [epoch: 25 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.132450901033899		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 6.132450901033899 | validation: 5.415177156351653]
	TIME [epoch: 25 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1149462443205		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 6.1149462443205 | validation: 5.278993000902797]
	TIME [epoch: 25 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.033447066423194		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 6.033447066423194 | validation: 5.432944636708621]
	TIME [epoch: 25 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.030153055692654		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 6.030153055692654 | validation: 5.6391573936438935]
	TIME [epoch: 25 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.16000475290485		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 6.16000475290485 | validation: 5.262989010760966]
	TIME [epoch: 25 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.064281753549926		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 6.064281753549926 | validation: 5.217957438021122]
	TIME [epoch: 25 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.073202907399588		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 6.073202907399588 | validation: 5.247650724581251]
	TIME [epoch: 25 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.009112928242648		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 6.009112928242648 | validation: 5.613557024909665]
	TIME [epoch: 25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.151084253541648		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 6.151084253541648 | validation: 5.206322825668422]
	TIME [epoch: 25 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.992432625195508		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 5.992432625195508 | validation: 5.202189490512994]
	TIME [epoch: 25 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.038702927556393		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 6.038702927556393 | validation: 5.390856158297937]
	TIME [epoch: 25 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.032590612621526		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 6.032590612621526 | validation: 5.255275762804174]
	TIME [epoch: 25 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.022943186432375		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 6.022943186432375 | validation: 5.571450117604824]
	TIME [epoch: 25 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.170634700037584		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 6.170634700037584 | validation: 5.224731122108997]
	TIME [epoch: 25 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9866970461475795		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 5.9866970461475795 | validation: 5.194182098753961]
	TIME [epoch: 25 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.032895386040394		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 6.032895386040394 | validation: 5.2108306727857565]
	TIME [epoch: 25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.023930147257527		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 6.023930147257527 | validation: 5.536506091529282]
	TIME [epoch: 25 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.107169260319534		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 6.107169260319534 | validation: 5.247593330810526]
	TIME [epoch: 25 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.036085897618403		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 6.036085897618403 | validation: 5.272474051004824]
	TIME [epoch: 25 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.064360485479787		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 6.064360485479787 | validation: 5.785790906883646]
	TIME [epoch: 25 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.272570069587249		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 6.272570069587249 | validation: 5.610568647390094]
	TIME [epoch: 25 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.15958017574118		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 6.15958017574118 | validation: 6.112507347956421]
	TIME [epoch: 25 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.245191403496628		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 6.245191403496628 | validation: 5.375201891971464]
	TIME [epoch: 25 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.973347709520208		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 5.973347709520208 | validation: 5.407242343303844]
	TIME [epoch: 25 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.026411330139498		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 6.026411330139498 | validation: 5.518365332946339]
	TIME [epoch: 25 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.023591438251145		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 6.023591438251145 | validation: 5.53896202629375]
	TIME [epoch: 25 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.024581461230456		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 6.024581461230456 | validation: 5.354952269945777]
	TIME [epoch: 25 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.017419426504221		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 6.017419426504221 | validation: 5.23451849415425]
	TIME [epoch: 25 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.997688279004845		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 5.997688279004845 | validation: 5.317977751047494]
	TIME [epoch: 25 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.992014115482398		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 5.992014115482398 | validation: 5.191111557646094]
	TIME [epoch: 25 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.008077455271847		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 6.008077455271847 | validation: 5.270265720944139]
	TIME [epoch: 25 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.991332953102828		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 5.991332953102828 | validation: 5.447924525695299]
	TIME [epoch: 25 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.054961060541981		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 6.054961060541981 | validation: 5.480741871337968]
	TIME [epoch: 25 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.090162558297338		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 6.090162558297338 | validation: 5.3333710432715975]
	TIME [epoch: 25 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.062846682629932		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 6.062846682629932 | validation: 5.216270916394745]
	TIME [epoch: 25 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.073947372409337		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 6.073947372409337 | validation: 5.6342935934256655]
	TIME [epoch: 25 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.165850126372237		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 6.165850126372237 | validation: 5.529934750348857]
	TIME [epoch: 25 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.120964804294989		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 6.120964804294989 | validation: 5.4926172345519175]
	TIME [epoch: 25 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.10551746621671		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 6.10551746621671 | validation: 5.360727525847699]
	TIME [epoch: 24.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.032293650716444		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 6.032293650716444 | validation: 5.453896072545267]
	TIME [epoch: 25 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0952161504788425		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 6.0952161504788425 | validation: 5.809998817865522]
	TIME [epoch: 25 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.150900720997673		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 6.150900720997673 | validation: 5.521565807525956]
	TIME [epoch: 24.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.041199350865899		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 6.041199350865899 | validation: 5.46982548757733]
	TIME [epoch: 25 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.984640682943441		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 5.984640682943441 | validation: 5.220611877116601]
	TIME [epoch: 25 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.078892058207987		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 6.078892058207987 | validation: 6.180435526910771]
	TIME [epoch: 25 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.217574857461758		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 6.217574857461758 | validation: 5.33297557309816]
	TIME [epoch: 25 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0725768853082265		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 6.0725768853082265 | validation: 5.411143198580715]
	TIME [epoch: 25 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.06484878818266		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 6.06484878818266 | validation: 5.346903926316168]
	TIME [epoch: 24.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.112902277077193		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 6.112902277077193 | validation: 5.358289240672796]
	TIME [epoch: 25 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.002095083517274		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 6.002095083517274 | validation: 5.357749208885078]
	TIME [epoch: 25 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.005767821445636		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 6.005767821445636 | validation: 5.351671535477285]
	TIME [epoch: 24.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.084007220023115		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 6.084007220023115 | validation: 5.38124979820656]
	TIME [epoch: 25 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.133549237225747		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 6.133549237225747 | validation: 5.328020301154846]
	TIME [epoch: 25 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.050283474785534		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 6.050283474785534 | validation: 5.457050396531768]
	TIME [epoch: 24.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.48393116154823		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 6.48393116154823 | validation: 5.3213456067819065]
	TIME [epoch: 25 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.062700773103563		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 6.062700773103563 | validation: 5.401282905641501]
	TIME [epoch: 25 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.15060136215549		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 6.15060136215549 | validation: 5.5010798790512085]
	TIME [epoch: 24.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0386160706471355		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 6.0386160706471355 | validation: 5.250339358603612]
	TIME [epoch: 25 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.998437528950563		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 5.998437528950563 | validation: 5.29213352393093]
	TIME [epoch: 25 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.944275344756827		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 5.944275344756827 | validation: 5.413331797708911]
	TIME [epoch: 24.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.070090154372535		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 6.070090154372535 | validation: 5.395436879381557]
	TIME [epoch: 25 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.989434672728554		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 5.989434672728554 | validation: 5.2734431986553565]
	TIME [epoch: 25 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0027386389256545		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 6.0027386389256545 | validation: 5.594645828050589]
	TIME [epoch: 25 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.097519036239258		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 6.097519036239258 | validation: 5.283205115080509]
	TIME [epoch: 25 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.992269712290129		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 5.992269712290129 | validation: 6.7183583707433]
	TIME [epoch: 25 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.381347947902372		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 6.381347947902372 | validation: 5.2312634345620985]
	TIME [epoch: 25 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.938791108512289		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 5.938791108512289 | validation: 5.196993708010681]
	TIME [epoch: 25 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.975749079150996		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 5.975749079150996 | validation: 5.209122471660075]
	TIME [epoch: 25 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.000080056952773		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 6.000080056952773 | validation: 5.403034993463591]
	TIME [epoch: 25 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.070835404469467		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 6.070835404469467 | validation: 5.408941918422613]
	TIME [epoch: 25 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.997031924227359		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 5.997031924227359 | validation: 5.548457873412888]
	TIME [epoch: 25 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9967147565910395		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 5.9967147565910395 | validation: 5.307547292325303]
	TIME [epoch: 25 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.047103683146451		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 6.047103683146451 | validation: 5.427423284327248]
	TIME [epoch: 25 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.995481032404646		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 5.995481032404646 | validation: 5.541931354091521]
	TIME [epoch: 24.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.989066817514705		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 5.989066817514705 | validation: 5.259360029383239]
	TIME [epoch: 25 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.028621077372119		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 6.028621077372119 | validation: 5.235361185000443]
	TIME [epoch: 25 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.942576072957156		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 5.942576072957156 | validation: 5.39562681625599]
	TIME [epoch: 25 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.96668230201862		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 5.96668230201862 | validation: 5.212916998877236]
	TIME [epoch: 25 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.97176823061433		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 5.97176823061433 | validation: 5.1678045317209955]
	TIME [epoch: 25 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.950908007624971		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 5.950908007624971 | validation: 5.738189146558282]
	TIME [epoch: 24.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.113734916303523		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 6.113734916303523 | validation: 5.258762502863277]
	TIME [epoch: 25 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8987265014172365		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 5.8987265014172365 | validation: 5.325272149758652]
	TIME [epoch: 24.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.044217950572114		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 6.044217950572114 | validation: 5.5339038476265285]
	TIME [epoch: 24.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.993238574884172		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 5.993238574884172 | validation: 5.411271712495773]
	TIME [epoch: 24.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.959453523931545		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 5.959453523931545 | validation: 5.179215556278018]
	TIME [epoch: 24.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.942475736690348		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 5.942475736690348 | validation: 5.153397766287394]
	TIME [epoch: 24.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.018430621145328		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 6.018430621145328 | validation: 5.298996776995628]
	TIME [epoch: 24.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.913810440449648		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 5.913810440449648 | validation: 5.277639648239171]
	TIME [epoch: 24.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.894202955431193		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 5.894202955431193 | validation: 5.231752761501732]
	TIME [epoch: 24.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.938696365967197		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 5.938696365967197 | validation: 5.280484661338735]
	TIME [epoch: 24.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.914793170262638		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 5.914793170262638 | validation: 5.137094715789997]
	TIME [epoch: 24.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.882298051210771		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 5.882298051210771 | validation: 5.153626614341744]
	TIME [epoch: 24.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.556725601569726		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 6.556725601569726 | validation: 6.857629547766862]
	TIME [epoch: 24.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.611980590465236		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 6.611980590465236 | validation: 5.183711400299406]
	TIME [epoch: 24.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.019136789241703		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 6.019136789241703 | validation: 5.142836365219734]
	TIME [epoch: 24.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.869261242553858		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 5.869261242553858 | validation: 5.1587420249033755]
	TIME [epoch: 25 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.935725212957898		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 5.935725212957898 | validation: 5.387605856962559]
	TIME [epoch: 24.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.221879858731553		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 6.221879858731553 | validation: 5.386666351221361]
	TIME [epoch: 24.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.994009332364472		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 5.994009332364472 | validation: 5.226828166232669]
	TIME [epoch: 24.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.926681768828082		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 5.926681768828082 | validation: 5.165533120394326]
	TIME [epoch: 24.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.873723292034656		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 5.873723292034656 | validation: 5.517640850321993]
	TIME [epoch: 24.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.98024158526688		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 5.98024158526688 | validation: 5.169712296678682]
	TIME [epoch: 24.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.002509692955329		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 6.002509692955329 | validation: 5.161883710560637]
	TIME [epoch: 25 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.887459785650496		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 5.887459785650496 | validation: 5.150376191890842]
	TIME [epoch: 24.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.927577289403305		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 5.927577289403305 | validation: 5.338713300693923]
	TIME [epoch: 24.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.956696521803937		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 5.956696521803937 | validation: 5.168659595705484]
	TIME [epoch: 25 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.01342846820233		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 6.01342846820233 | validation: 5.140811357640193]
	TIME [epoch: 24.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.907281285684869		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 5.907281285684869 | validation: 5.492509120041521]
	TIME [epoch: 24.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.150161627588355		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 6.150161627588355 | validation: 5.453521957597039]
	TIME [epoch: 24.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.923925934782248		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 5.923925934782248 | validation: 5.2145677043731204]
	TIME [epoch: 25 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.912811087205158		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 5.912811087205158 | validation: 5.18314588124975]
	TIME [epoch: 25 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.888451162092644		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 5.888451162092644 | validation: 5.365720210159231]
	TIME [epoch: 25 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.906605788219549		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 5.906605788219549 | validation: 5.224871768000653]
	TIME [epoch: 25 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.913321249555086		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 5.913321249555086 | validation: 5.49453593478582]
	TIME [epoch: 24.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.982660302436123		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 5.982660302436123 | validation: 5.175519755261875]
	TIME [epoch: 24.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.889532946124245		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 5.889532946124245 | validation: 5.179957373960412]
	TIME [epoch: 25 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.910091662358994		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 5.910091662358994 | validation: 5.1292058571385475]
	TIME [epoch: 24.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8713666637844515		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 5.8713666637844515 | validation: 5.155226576251413]
	TIME [epoch: 25 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.033430271965004		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 6.033430271965004 | validation: 5.229125221322475]
	TIME [epoch: 24.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9397812405440265		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 5.9397812405440265 | validation: 5.179390273057145]
	TIME [epoch: 25 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.926924395734685		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 5.926924395734685 | validation: 5.215727502916708]
	TIME [epoch: 24.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.893815962107911		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 5.893815962107911 | validation: 5.373262225392359]
	TIME [epoch: 25 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.954283034119637		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 5.954283034119637 | validation: 5.282223502486785]
	TIME [epoch: 24.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.888307243165313		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 5.888307243165313 | validation: 5.311751991717574]
	TIME [epoch: 25 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.941554540568996		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 5.941554540568996 | validation: 5.373413863085152]
	TIME [epoch: 24.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.011828631375471		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 6.011828631375471 | validation: 5.329680369664524]
	TIME [epoch: 25 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.011596059219458		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 6.011596059219458 | validation: 5.15355373689967]
	TIME [epoch: 25 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.881411365010793		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 5.881411365010793 | validation: 5.212756231896561]
	TIME [epoch: 24.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.985384576371233		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 5.985384576371233 | validation: 5.444670250863096]
	TIME [epoch: 24.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.918148072233588		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 5.918148072233588 | validation: 5.201069436683686]
	TIME [epoch: 25 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.894158407497779		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 5.894158407497779 | validation: 5.194701879716035]
	TIME [epoch: 25 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.928203477696586		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 5.928203477696586 | validation: 5.190663899965121]
	TIME [epoch: 24.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.885612512024429		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 5.885612512024429 | validation: 5.129640028849748]
	TIME [epoch: 25 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.869528505856351		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 5.869528505856351 | validation: 5.17844515804713]
	TIME [epoch: 25 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.902557962596759		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 5.902557962596759 | validation: 5.153714620190849]
	TIME [epoch: 24.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0235988884909855		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 6.0235988884909855 | validation: 5.400305569361915]
	TIME [epoch: 25 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.055228594838252		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 6.055228594838252 | validation: 5.364441311461755]
	TIME [epoch: 25 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.001771352080627		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 6.001771352080627 | validation: 5.225872494484172]
	TIME [epoch: 25 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.991291033286309		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 5.991291033286309 | validation: 5.369129669972176]
	TIME [epoch: 25 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.983351271374123		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 5.983351271374123 | validation: 5.213354157526419]
	TIME [epoch: 25 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9170862859881375		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 5.9170862859881375 | validation: 5.376870833087488]
	TIME [epoch: 24.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.960983658286926		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 5.960983658286926 | validation: 5.210348234547287]
	TIME [epoch: 25 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8893341681428595		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 5.8893341681428595 | validation: 5.370224843489912]
	TIME [epoch: 25 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.921576854093557		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 5.921576854093557 | validation: 5.176427432580235]
	TIME [epoch: 24.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.886282092340294		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 5.886282092340294 | validation: 5.166417871291077]
	TIME [epoch: 24.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.894221366224434		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 5.894221366224434 | validation: 5.201866061903555]
	TIME [epoch: 24.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8931401894825175		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 5.8931401894825175 | validation: 5.221866481406652]
	TIME [epoch: 24.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9539123070152264		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 5.9539123070152264 | validation: 5.262530892271311]
	TIME [epoch: 25 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.903515524887887		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 5.903515524887887 | validation: 5.144181543585851]
	TIME [epoch: 25 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.861433019460633		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 5.861433019460633 | validation: 5.143984876471063]
	TIME [epoch: 25 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.864855766916387		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 5.864855766916387 | validation: 5.1235683353941095]
	TIME [epoch: 25 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.065967684974792		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 6.065967684974792 | validation: 5.242786633399614]
	TIME [epoch: 25 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.981949174943064		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 5.981949174943064 | validation: 5.1302955403068315]
	TIME [epoch: 24.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1226353576793375		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 6.1226353576793375 | validation: 5.171054367349139]
	TIME [epoch: 24.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.95675782045471		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 5.95675782045471 | validation: 5.341277471008559]
	TIME [epoch: 25 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.95888610837126		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 5.95888610837126 | validation: 5.154505983394837]
	TIME [epoch: 25 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8819329994223555		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 5.8819329994223555 | validation: 5.0974487907076735]
	TIME [epoch: 25 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.890428835105928		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 5.890428835105928 | validation: 5.091531410013277]
	TIME [epoch: 25 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.861235329037708		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 5.861235329037708 | validation: 5.111803085172981]
	TIME [epoch: 25 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.866592748827446		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 5.866592748827446 | validation: 5.115863037299426]
	TIME [epoch: 25 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.861686263754163		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 5.861686263754163 | validation: 5.194431461216456]
	TIME [epoch: 25 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8489243197228316		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 5.8489243197228316 | validation: 5.229137844731806]
	TIME [epoch: 25 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9119204639040115		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 5.9119204639040115 | validation: 5.182595392531438]
	TIME [epoch: 25 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.894832981731998		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 5.894832981731998 | validation: 5.110975368344079]
	TIME [epoch: 25 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9255856765008605		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 5.9255856765008605 | validation: 5.1776532587126205]
	TIME [epoch: 25 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.940770346585445		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 5.940770346585445 | validation: 5.156280167017096]
	TIME [epoch: 25 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9070141085287515		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 5.9070141085287515 | validation: 5.28331478141791]
	TIME [epoch: 25 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.066984632962534		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 6.066984632962534 | validation: 5.561366202600992]
	TIME [epoch: 24.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0625170365744925		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 6.0625170365744925 | validation: 5.147493390158798]
	TIME [epoch: 24.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8696348449695055		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 5.8696348449695055 | validation: 5.468479646749444]
	TIME [epoch: 25 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.562212960611791		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 6.562212960611791 | validation: 5.428282304524238]
	TIME [epoch: 24.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.036777687816828		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 6.036777687816828 | validation: 5.46164032576293]
	TIME [epoch: 25 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9888690419887		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 5.9888690419887 | validation: 5.103862365420768]
	TIME [epoch: 25 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.881304437986248		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 5.881304437986248 | validation: 5.20105126423301]
	TIME [epoch: 25 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.347274081258888		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 6.347274081258888 | validation: 6.943422631858728]
	TIME [epoch: 25 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.551166791468784		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 7.551166791468784 | validation: 6.748514691474707]
	TIME [epoch: 24.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.365014712398493		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 7.365014712398493 | validation: 5.968164916858075]
	TIME [epoch: 24.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.485319718502875		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 6.485319718502875 | validation: 5.5433902059610665]
	TIME [epoch: 25 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.291923189578174		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 6.291923189578174 | validation: 5.469621253292457]
	TIME [epoch: 25 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.202564394200937		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 6.202564394200937 | validation: 5.523954015574544]
	TIME [epoch: 25 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.254404287573356		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 6.254404287573356 | validation: 5.487900809428331]
	TIME [epoch: 25 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.209503398995903		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 6.209503398995903 | validation: 5.4800270073140975]
	TIME [epoch: 25 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.246986632266968		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 6.246986632266968 | validation: 5.3812794802121635]
	TIME [epoch: 24.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.183070943781123		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 6.183070943781123 | validation: 5.636005106057983]
	TIME [epoch: 25 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.370037815558792		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 6.370037815558792 | validation: 6.34446770916508]
	TIME [epoch: 25 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.56452992051358		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 6.56452992051358 | validation: 5.466650153638489]
	TIME [epoch: 24.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.121448485922979		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 6.121448485922979 | validation: 5.329969039798177]
	TIME [epoch: 24.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.988780239576911		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 5.988780239576911 | validation: 5.340449130101625]
	TIME [epoch: 24.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.000609982005896		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 6.000609982005896 | validation: 5.4778812793540625]
	TIME [epoch: 24.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.05344145214024		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 6.05344145214024 | validation: 5.343164832149841]
	TIME [epoch: 24.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.995920425763696		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 5.995920425763696 | validation: 5.404684515558929]
	TIME [epoch: 24.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0205574031357205		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 6.0205574031357205 | validation: 5.3242896018756]
	TIME [epoch: 24.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.989126354321329		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 5.989126354321329 | validation: 5.373355081238011]
	TIME [epoch: 24.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0255884105143025		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 6.0255884105143025 | validation: 5.289182435963155]
	TIME [epoch: 24.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.987740204393566		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 5.987740204393566 | validation: 5.429722090994445]
	TIME [epoch: 24.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.120308185230769		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 6.120308185230769 | validation: 5.4731511828137105]
	TIME [epoch: 25 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.183551828787444		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 6.183551828787444 | validation: 5.53899854370409]
	TIME [epoch: 24.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.098044313191334		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 6.098044313191334 | validation: 5.395292440377167]
	TIME [epoch: 25 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.058744199807305		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 6.058744199807305 | validation: 5.39654364201816]
	TIME [epoch: 24.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0904407523225546		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 6.0904407523225546 | validation: 5.429729545926472]
	TIME [epoch: 24.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.108718243524171		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 6.108718243524171 | validation: 5.449820053779583]
	TIME [epoch: 24.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.092707492656481		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 6.092707492656481 | validation: 5.432608102936885]
	TIME [epoch: 24.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.085834705392803		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 6.085834705392803 | validation: 5.501335382901773]
	TIME [epoch: 24.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.093820365519877		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 6.093820365519877 | validation: 5.418344057669867]
	TIME [epoch: 24.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.085057662669779		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 6.085057662669779 | validation: 5.507798233843118]
	TIME [epoch: 24.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1986830566856295		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 6.1986830566856295 | validation: 5.531214479572191]
	TIME [epoch: 24.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.188621881846215		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 6.188621881846215 | validation: 5.490282532578097]
	TIME [epoch: 24.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2303502714129735		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 6.2303502714129735 | validation: 5.5151559538049275]
	TIME [epoch: 24.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.238774433037768		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 6.238774433037768 | validation: 5.504090356002851]
	TIME [epoch: 24.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2165520430624115		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 6.2165520430624115 | validation: 5.523762401710772]
	TIME [epoch: 24.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.215581782075306		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 6.215581782075306 | validation: 5.482773835152612]
	TIME [epoch: 24.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2191044513678815		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 6.2191044513678815 | validation: 5.502751450511619]
	TIME [epoch: 24.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.279042164928233		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 6.279042164928233 | validation: 5.536085591302337]
	TIME [epoch: 25 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.265031739871001		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 6.265031739871001 | validation: 5.684063208214645]
	TIME [epoch: 25 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.149766409593043		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 6.149766409593043 | validation: 5.4918585630035786]
	TIME [epoch: 25 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.102440938642977		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 6.102440938642977 | validation: 5.488181541232497]
	TIME [epoch: 25 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.115772124150895		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 6.115772124150895 | validation: 5.455322889971171]
	TIME [epoch: 24.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.136691625616169		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 6.136691625616169 | validation: 5.413378061441866]
	TIME [epoch: 25 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.613051872143681		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 6.613051872143681 | validation: 6.698618307063057]
	TIME [epoch: 25 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.673895559543176		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 6.673895559543176 | validation: 5.563231381394026]
	TIME [epoch: 24.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.290068435528914		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 6.290068435528914 | validation: 5.457693248743064]
	TIME [epoch: 25 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2448750541675295		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 6.2448750541675295 | validation: 5.500331360681662]
	TIME [epoch: 25 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.294692479838639		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 6.294692479838639 | validation: 5.586377376178368]
	TIME [epoch: 24.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.218461032770425		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 6.218461032770425 | validation: 5.505976059498007]
	TIME [epoch: 24.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.280661322378597		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 6.280661322378597 | validation: 5.630056900248428]
	TIME [epoch: 25 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4912477684838255		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 6.4912477684838255 | validation: 5.645926698893701]
	TIME [epoch: 25 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.435143176523827		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 6.435143176523827 | validation: 5.606272255299922]
	TIME [epoch: 25 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.505511042700933		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 6.505511042700933 | validation: 5.648412668616222]
	TIME [epoch: 25 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.468619691194455		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 6.468619691194455 | validation: 5.578991840530969]
	TIME [epoch: 24.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.443963472547835		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 6.443963472547835 | validation: 5.623670017992213]
	TIME [epoch: 25 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.474343179350665		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 6.474343179350665 | validation: 5.56602335562877]
	TIME [epoch: 25 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.420678365200269		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 6.420678365200269 | validation: 5.782701948973814]
	TIME [epoch: 25 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.683031369252256		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 6.683031369252256 | validation: 5.784957188517468]
	TIME [epoch: 25 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.696358922812201		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 6.696358922812201 | validation: 5.873671603532578]
	TIME [epoch: 24.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.663074593183395		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 6.663074593183395 | validation: 5.669496732397144]
	TIME [epoch: 25 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.582620607012429		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 6.582620607012429 | validation: 5.667588156131151]
	TIME [epoch: 24.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.578407482543166		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 6.578407482543166 | validation: 5.6732600984444765]
	TIME [epoch: 25 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.571852815759117		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 6.571852815759117 | validation: 5.636172428884246]
	TIME [epoch: 24.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.528159502886507		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 6.528159502886507 | validation: 5.716370416043467]
	TIME [epoch: 25 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.657174402574283		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 6.657174402574283 | validation: 5.696763666207098]
	TIME [epoch: 25 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.557210170475443		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 6.557210170475443 | validation: 5.642036964317376]
	TIME [epoch: 24.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6016602183226585		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 6.6016602183226585 | validation: 5.72145402418078]
	TIME [epoch: 24.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.712998219635569		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 6.712998219635569 | validation: 5.744013826116725]
	TIME [epoch: 25 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.723934322479859		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 6.723934322479859 | validation: 5.919182478931437]
	TIME [epoch: 24.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.746719216103564		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 6.746719216103564 | validation: 5.78497131301549]
	TIME [epoch: 25 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.680367081071329		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 6.680367081071329 | validation: 5.714225120416853]
	TIME [epoch: 24.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.686797419147033		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 6.686797419147033 | validation: 5.759124785342606]
	TIME [epoch: 24.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.673327024430279		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 6.673327024430279 | validation: 5.916496799537406]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.704703699548503		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 6.704703699548503 | validation: 5.784667432878934]
	TIME [epoch: 25 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.673711556053366		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 6.673711556053366 | validation: 5.722607356780076]
	TIME [epoch: 24.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.76659468392479		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 6.76659468392479 | validation: 6.0383019110208025]
	TIME [epoch: 25 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.815610802409359		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 6.815610802409359 | validation: 5.861707745417408]
	TIME [epoch: 24.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.703305803201426		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 6.703305803201426 | validation: 5.745338868223906]
	TIME [epoch: 25 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.646715852128419		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 6.646715852128419 | validation: 5.765740876765319]
	TIME [epoch: 25 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.685674943014956		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 6.685674943014956 | validation: 5.77304063640102]
	TIME [epoch: 25 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.698202788296849		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 6.698202788296849 | validation: 5.74337064183678]
	TIME [epoch: 24.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.659382805006713		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 6.659382805006713 | validation: 5.7823157255409]
	TIME [epoch: 25 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.667696793651775		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 6.667696793651775 | validation: 5.809458085752511]
	TIME [epoch: 25 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.669664910535214		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 6.669664910535214 | validation: 5.864772880190562]
	TIME [epoch: 25 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.679984705071833		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 6.679984705071833 | validation: 5.922767785527437]
	TIME [epoch: 25 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.801698436926598		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 6.801698436926598 | validation: 5.690359220911762]
	TIME [epoch: 24.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.633532518651902		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 6.633532518651902 | validation: 5.771163857309184]
	TIME [epoch: 25 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.85997245094415		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 6.85997245094415 | validation: 5.788782007445227]
	TIME [epoch: 25 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.698089396043359		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 6.698089396043359 | validation: 5.768721211952878]
	TIME [epoch: 25 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.64394583160877		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 6.64394583160877 | validation: 5.7796454000631865]
	TIME [epoch: 25 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.64864407856611		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 6.64864407856611 | validation: 5.735471220167194]
	TIME [epoch: 25 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.641231002181295		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 6.641231002181295 | validation: 5.717595397008893]
	TIME [epoch: 25 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.68987513216085		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 6.68987513216085 | validation: 5.856411225179384]
	TIME [epoch: 25 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7399968023611505		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 6.7399968023611505 | validation: 5.751685953425837]
	TIME [epoch: 25 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.743622409077312		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 6.743622409077312 | validation: 5.790893913834248]
	TIME [epoch: 24.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.666289729199266		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 6.666289729199266 | validation: 5.761207680159562]
	TIME [epoch: 24.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7233351485004675		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 6.7233351485004675 | validation: 5.957876092654234]
	TIME [epoch: 25 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.729500139649366		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 6.729500139649366 | validation: 5.7325376267284]
	TIME [epoch: 24.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.634158674462904		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 6.634158674462904 | validation: 5.699420452623902]
	TIME [epoch: 24.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.67891956251458		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 6.67891956251458 | validation: 5.749873138951646]
	TIME [epoch: 25 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.615709861297192		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 6.615709861297192 | validation: 5.7639821852647035]
	TIME [epoch: 25 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6405424173660155		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 6.6405424173660155 | validation: 5.765336834193771]
	TIME [epoch: 24.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.646973487424305		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 6.646973487424305 | validation: 5.713222691486762]
	TIME [epoch: 25 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.703411327273999		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 6.703411327273999 | validation: 5.87058018847765]
	TIME [epoch: 24.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.817993220639753		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 6.817993220639753 | validation: 5.857919824640876]
	TIME [epoch: 24.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7216305746768334		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 6.7216305746768334 | validation: 5.771252044602522]
	TIME [epoch: 24.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.727174672870116		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 6.727174672870116 | validation: 6.026734328650941]
	TIME [epoch: 24.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.773895602952944		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 6.773895602952944 | validation: 5.849465592645646]
	TIME [epoch: 25 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.756812413063006		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 6.756812413063006 | validation: 5.969741897463798]
	TIME [epoch: 24.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.725322750868052		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 6.725322750868052 | validation: 5.968809130809989]
	TIME [epoch: 25 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.753332431438626		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 6.753332431438626 | validation: 5.877355315199174]
	TIME [epoch: 24.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.702596235049127		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 6.702596235049127 | validation: 5.7651581486419285]
	TIME [epoch: 24.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.705264745029411		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 6.705264745029411 | validation: 5.849927257535785]
	TIME [epoch: 24.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.725885517780837		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 6.725885517780837 | validation: 5.784042129795653]
	TIME [epoch: 24.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.723331188225897		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 6.723331188225897 | validation: 5.80620626852941]
	TIME [epoch: 24.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.717608242911545		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 6.717608242911545 | validation: 6.073563429116713]
	TIME [epoch: 24.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.777119572021682		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 6.777119572021682 | validation: 6.029953685527339]
	TIME [epoch: 24.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.799600204746085		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 6.799600204746085 | validation: 5.882828532781134]
	TIME [epoch: 25 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.782470650527314		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 6.782470650527314 | validation: 5.811912568697626]
	TIME [epoch: 24.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.732142182791472		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 6.732142182791472 | validation: 5.8847276814503395]
	TIME [epoch: 24.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.745499613258003		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 6.745499613258003 | validation: 5.950581622959179]
	TIME [epoch: 24.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.782872724598992		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 6.782872724598992 | validation: 5.817225077641762]
	TIME [epoch: 24.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.772121531263238		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 6.772121531263238 | validation: 5.8220550745855695]
	TIME [epoch: 24.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.734350731527817		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 6.734350731527817 | validation: 5.812297291365123]
	TIME [epoch: 25 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.721354672671091		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 6.721354672671091 | validation: 5.848917329880644]
	TIME [epoch: 25 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.711547521938407		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 6.711547521938407 | validation: 5.9508831072674]
	TIME [epoch: 24.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.71096468571924		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 6.71096468571924 | validation: 5.81625192653494]
	TIME [epoch: 24.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.766828903829115		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 6.766828903829115 | validation: 6.0403333245045205]
	TIME [epoch: 24.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.748956811854557		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 6.748956811854557 | validation: 5.802889102083086]
	TIME [epoch: 24.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.725717832569488		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 6.725717832569488 | validation: 5.920955750013049]
	TIME [epoch: 25 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.713911941891854		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 6.713911941891854 | validation: 5.936532933094022]
	TIME [epoch: 24.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6838323883026725		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 6.6838323883026725 | validation: 5.874230149600353]
	TIME [epoch: 24.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.714288331904236		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 6.714288331904236 | validation: 5.951131194277655]
	TIME [epoch: 24.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.731745255987289		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 6.731745255987289 | validation: 6.208581250337352]
	TIME [epoch: 24.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.798834505733124		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 6.798834505733124 | validation: 5.912995331637981]
	TIME [epoch: 25 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.737197389070561		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 6.737197389070561 | validation: 5.925552226690741]
	TIME [epoch: 25 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.693285616530932		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 6.693285616530932 | validation: 5.856779182800924]
	TIME [epoch: 25 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.716782698614757		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 6.716782698614757 | validation: 5.909125380906396]
	TIME [epoch: 24.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.697222953732172		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 6.697222953732172 | validation: 5.907158708232061]
	TIME [epoch: 25 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.675414414723595		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 6.675414414723595 | validation: 6.055012322821193]
	TIME [epoch: 25 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.715214291988667		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 6.715214291988667 | validation: 5.97414403981508]
	TIME [epoch: 25 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6975725133988435		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 6.6975725133988435 | validation: 5.922826416535904]
	TIME [epoch: 25 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.714244256689391		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 6.714244256689391 | validation: 6.047598452263456]
	TIME [epoch: 25 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7426584726573955		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 6.7426584726573955 | validation: 5.897853418028013]
	TIME [epoch: 25 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.743526592546022		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 6.743526592546022 | validation: 5.986300825161952]
	TIME [epoch: 25 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7272670733150015		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 6.7272670733150015 | validation: 5.940975282617871]
	TIME [epoch: 25 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.703836038434733		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 6.703836038434733 | validation: 5.91544104602348]
	TIME [epoch: 25 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.735167682171191		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 6.735167682171191 | validation: 5.922745289381472]
	TIME [epoch: 25 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.673373205254342		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 6.673373205254342 | validation: 5.922110379648046]
	TIME [epoch: 25 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.732982946689349		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 6.732982946689349 | validation: 5.968830322748088]
	TIME [epoch: 25 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.694438090306049		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 6.694438090306049 | validation: 5.906290815158821]
	TIME [epoch: 25 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.680765377540907		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 6.680765377540907 | validation: 5.8577929494085]
	TIME [epoch: 24.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.685621309552376		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 6.685621309552376 | validation: 5.945902531411727]
	TIME [epoch: 25 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.700220406196074		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 6.700220406196074 | validation: 5.928863654035322]
	TIME [epoch: 25 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.684565608622664		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 6.684565608622664 | validation: 5.8672925319868545]
	TIME [epoch: 25 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.693859881793513		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 6.693859881793513 | validation: 5.882185647792263]
	TIME [epoch: 24.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.689967242373038		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 6.689967242373038 | validation: 5.9184255060472974]
	TIME [epoch: 25 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.707897662345072		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 6.707897662345072 | validation: 5.8518648058894955]
	TIME [epoch: 25 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.67579833441482		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 6.67579833441482 | validation: 5.9348272342602195]
	TIME [epoch: 24.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.718807856843314		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 6.718807856843314 | validation: 5.90203023428623]
	TIME [epoch: 25 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.707737554052464		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 6.707737554052464 | validation: 5.965173120855668]
	TIME [epoch: 25 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.723212402975343		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 6.723212402975343 | validation: 5.847047807320051]
	TIME [epoch: 25 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.729113253645778		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 6.729113253645778 | validation: 5.860218300781007]
	TIME [epoch: 25 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.699862082923981		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 6.699862082923981 | validation: 5.872200387765373]
	TIME [epoch: 25 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.666098878737153		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 6.666098878737153 | validation: 5.8823987357260465]
	TIME [epoch: 25 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.680894226805704		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 6.680894226805704 | validation: 5.8946095755875385]
	TIME [epoch: 25 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.679813203367076		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 6.679813203367076 | validation: 5.925020385003752]
	TIME [epoch: 25 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.69498984356017		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 6.69498984356017 | validation: 5.850056601220524]
	TIME [epoch: 24.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.703211971811037		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 6.703211971811037 | validation: 5.99290964054962]
	TIME [epoch: 25 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.727720961360517		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 6.727720961360517 | validation: 5.863576175331077]
	TIME [epoch: 25 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.674118203947065		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 6.674118203947065 | validation: 5.860602474487385]
	TIME [epoch: 25 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.656973291475476		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 6.656973291475476 | validation: 5.971158480668446]
	TIME [epoch: 24.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.740088852627343		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 6.740088852627343 | validation: 5.944028480571951]
	TIME [epoch: 25 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.703780258607873		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 6.703780258607873 | validation: 5.844983978003379]
	TIME [epoch: 24.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.649584826670113		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 6.649584826670113 | validation: 5.818149139694842]
	TIME [epoch: 25 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.695474273701446		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 6.695474273701446 | validation: 5.906779817785917]
	TIME [epoch: 25 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.716998532136466		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 6.716998532136466 | validation: 5.860434598984665]
	TIME [epoch: 25 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.647916583160287		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 6.647916583160287 | validation: 5.885609484470503]
	TIME [epoch: 24.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.664975151182217		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 6.664975151182217 | validation: 5.86005066662171]
	TIME [epoch: 25 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.719526584423103		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 6.719526584423103 | validation: 5.946481867748405]
	TIME [epoch: 24.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.687827070761201		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 6.687827070761201 | validation: 5.875489149140086]
	TIME [epoch: 24.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.657676192498473		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 6.657676192498473 | validation: 5.809489347631187]
	TIME [epoch: 25 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.668821438661986		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 6.668821438661986 | validation: 5.83514358549611]
	TIME [epoch: 24.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.658124096945782		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 6.658124096945782 | validation: 5.815956265528148]
	TIME [epoch: 25 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6413684102316415		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 6.6413684102316415 | validation: 5.874283458578361]
	TIME [epoch: 24.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.683642451365155		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 6.683642451365155 | validation: 5.813743921471645]
	TIME [epoch: 24.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.712586019113146		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 6.712586019113146 | validation: 5.88464165673696]
	TIME [epoch: 25 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.662679150437435		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 6.662679150437435 | validation: 5.868210406853037]
	TIME [epoch: 25 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.729431876311364		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 6.729431876311364 | validation: 5.851887041721093]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.664724232239215		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 6.664724232239215 | validation: 5.820425135589192]
	TIME [epoch: 24.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.665797773252199		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 6.665797773252199 | validation: 5.8329489214691375]
	TIME [epoch: 24.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.674647073544474		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 6.674647073544474 | validation: 5.949874605249857]
	TIME [epoch: 24.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.699140322142778		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 6.699140322142778 | validation: 5.83621331076062]
	TIME [epoch: 24.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.671333579711506		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 6.671333579711506 | validation: 5.8690144790593495]
	TIME [epoch: 25 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.649377337637793		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 6.649377337637793 | validation: 5.886297489687122]
	TIME [epoch: 25 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.664245754851255		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 6.664245754851255 | validation: 5.829153993150132]
	TIME [epoch: 25 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.647168328712851		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 6.647168328712851 | validation: 5.823999990288279]
	TIME [epoch: 25 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.655916217754393		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 6.655916217754393 | validation: 5.892886994884284]
	TIME [epoch: 25 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6721272090283925		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 6.6721272090283925 | validation: 5.876151288510588]
	TIME [epoch: 25 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.648407586344981		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 6.648407586344981 | validation: 5.843935595045507]
	TIME [epoch: 25 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.640906088037127		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 6.640906088037127 | validation: 5.820672751777713]
	TIME [epoch: 24.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6544907647905465		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 6.6544907647905465 | validation: 5.816752156503387]
	TIME [epoch: 25 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.684711100175073		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 6.684711100175073 | validation: 5.8717194460096485]
	TIME [epoch: 25 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.679036363344815		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 6.679036363344815 | validation: 5.776823913409617]
	TIME [epoch: 25 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.697432664104383		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 6.697432664104383 | validation: 5.950772551691093]
	TIME [epoch: 25 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.689286776398145		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 6.689286776398145 | validation: 5.630570699311817]
	TIME [epoch: 25 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.590056853076583		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 6.590056853076583 | validation: 5.544844550282723]
	TIME [epoch: 25 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.585305758724008		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 6.585305758724008 | validation: 5.739380433638603]
	TIME [epoch: 25 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.674653781246889		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 6.674653781246889 | validation: 5.6729567322138985]
	TIME [epoch: 25 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.641651383995857		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 6.641651383995857 | validation: 5.725470951178188]
	TIME [epoch: 24.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.603592157751074		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 6.603592157751074 | validation: 5.58882504704092]
	TIME [epoch: 25 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.52122080674669		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 6.52122080674669 | validation: 5.560974444904709]
	TIME [epoch: 25 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.612981301594543		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 6.612981301594543 | validation: 5.676249203441121]
	TIME [epoch: 25 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.400676640327093		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 6.400676640327093 | validation: 5.548345704721753]
	TIME [epoch: 25 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.233161140037474		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 6.233161140037474 | validation: 5.605296936220072]
	TIME [epoch: 25 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0984632878382765		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 6.0984632878382765 | validation: 5.513922704651413]
	TIME [epoch: 25 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3026895568374925		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 6.3026895568374925 | validation: 6.070683694146618]
	TIME [epoch: 25 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.26737753036911		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 7.26737753036911 | validation: 7.337995667819612]
	TIME [epoch: 25 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.082862527272932		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 8.082862527272932 | validation: 7.447420363514123]
	TIME [epoch: 25 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.861264400164332		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 7.861264400164332 | validation: 6.772154042507898]
	TIME [epoch: 25 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.201580473955384		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 7.201580473955384 | validation: 6.288233140703084]
	TIME [epoch: 25 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.068907118835547		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 7.068907118835547 | validation: 6.072504686382578]
	TIME [epoch: 25 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.375592247425836		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 6.375592247425836 | validation: 5.336286921083642]
	TIME [epoch: 25 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.000050012210583		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 6.000050012210583 | validation: 5.561837208704098]
	TIME [epoch: 25 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.262900794690012		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 6.262900794690012 | validation: 5.897544305809423]
	TIME [epoch: 25 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.625730681821022		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 6.625730681821022 | validation: 5.849547046587365]
	TIME [epoch: 25 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2769961011291375		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 6.2769961011291375 | validation: 5.72483704402115]
	TIME [epoch: 25 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.256234853228193		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 6.256234853228193 | validation: 5.580734078178795]
	TIME [epoch: 24.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.046253714664621		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 6.046253714664621 | validation: 5.4623826179259805]
	TIME [epoch: 25 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.938842397791117		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 5.938842397791117 | validation: 5.2942028307881515]
	TIME [epoch: 25 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.975720155775465		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 5.975720155775465 | validation: 5.516712007725356]
	TIME [epoch: 25 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.398957223579558		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 6.398957223579558 | validation: 5.95337053011447]
	TIME [epoch: 25 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.517206243904581		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 6.517206243904581 | validation: 5.676246822410915]
	TIME [epoch: 24.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.452744412794481		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 6.452744412794481 | validation: 5.592630260378731]
	TIME [epoch: 24.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.297211351947902		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 6.297211351947902 | validation: 5.468713361265141]
	TIME [epoch: 24.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.046828896050385		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 6.046828896050385 | validation: 5.351728145821916]
	TIME [epoch: 25 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.91204342536233		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 5.91204342536233 | validation: 5.3229285669384465]
	TIME [epoch: 24.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.010622061857753		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 6.010622061857753 | validation: 5.555389489085651]
	TIME [epoch: 25 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.010479103050545		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 6.010479103050545 | validation: 5.502493655014239]
	TIME [epoch: 24.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.958108491308018		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 5.958108491308018 | validation: 5.3118411617132875]
	TIME [epoch: 25 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.833851024011258		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 5.833851024011258 | validation: 5.209025825090631]
	TIME [epoch: 25 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.740112425417919		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 5.740112425417919 | validation: 5.143520434769848]
	TIME [epoch: 25 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.73429191093924		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 5.73429191093924 | validation: 5.191653159992497]
	TIME [epoch: 24.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.735925512242407		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 5.735925512242407 | validation: 5.151655540999436]
	TIME [epoch: 24.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6993632868289215		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 5.6993632868289215 | validation: 5.05169289723183]
	TIME [epoch: 24.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.64294499598714		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 5.64294499598714 | validation: 5.212937967508997]
	TIME [epoch: 24.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.743971389512218		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 5.743971389512218 | validation: 5.180546127044329]
	TIME [epoch: 25 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.10007898019756		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 6.10007898019756 | validation: 6.173267114763892]
	TIME [epoch: 24.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.931034040788971		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 6.931034040788971 | validation: 6.758272960261626]
	TIME [epoch: 24.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.967316192354769		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 6.967316192354769 | validation: 5.748955201311867]
	TIME [epoch: 25 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.378962659547047		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 6.378962659547047 | validation: 6.066653523669279]
	TIME [epoch: 25 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.452517337005907		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 6.452517337005907 | validation: 5.903965887170739]
	TIME [epoch: 24.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0701072018676285		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 6.0701072018676285 | validation: 5.289574973768577]
	TIME [epoch: 25 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7069336943547135		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 5.7069336943547135 | validation: 5.127232851468143]
	TIME [epoch: 24.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.778173651455627		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 5.778173651455627 | validation: 5.044657673711461]
	TIME [epoch: 25 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.643333069569283		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 5.643333069569283 | validation: 5.0513109791329605]
	TIME [epoch: 24.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.75178512274383		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 5.75178512274383 | validation: 5.494374213525181]
	TIME [epoch: 25 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2214986467619555		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 6.2214986467619555 | validation: 5.578108214818736]
	TIME [epoch: 25 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.090603713013596		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 6.090603713013596 | validation: 5.352354393900553]
	TIME [epoch: 25 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.003033522130993		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 6.003033522130993 | validation: 5.479552055110845]
	TIME [epoch: 25 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2715635130673775		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 6.2715635130673775 | validation: 6.022069962846199]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.336386467025738		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 6.336386467025738 | validation: 5.814212793849015]
	TIME [epoch: 25 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.375354094354389		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 6.375354094354389 | validation: 6.0366835637932175]
	TIME [epoch: 24.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.693009904015927		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 6.693009904015927 | validation: 6.01741459861282]
	TIME [epoch: 24.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.333041054854114		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 6.333041054854114 | validation: 5.570927627711926]
	TIME [epoch: 24.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.988387693999622		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 5.988387693999622 | validation: 5.321043918862849]
	TIME [epoch: 25 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.990532170913342		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 5.990532170913342 | validation: 5.7499845682706425]
	TIME [epoch: 24.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.207402799123633		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 6.207402799123633 | validation: 5.746052278402849]
	TIME [epoch: 24.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.201339684647284		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 6.201339684647284 | validation: 5.556257820771923]
	TIME [epoch: 24.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.214349767510147		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 6.214349767510147 | validation: 5.726865152942132]
	TIME [epoch: 25 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.370699376063702		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 6.370699376063702 | validation: 5.664418854911101]
	TIME [epoch: 24.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.818855366323687		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 6.818855366323687 | validation: 6.862773852452196]
	TIME [epoch: 25 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.839981761041224		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 7.839981761041224 | validation: 6.607266002260826]
	TIME [epoch: 25 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.92386733747594		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 6.92386733747594 | validation: 5.663458654467381]
	TIME [epoch: 25 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.299575689503312		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 6.299575689503312 | validation: 5.633675801513432]
	TIME [epoch: 24.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.27656704186764		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 6.27656704186764 | validation: 5.644867686229377]
	TIME [epoch: 25 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.342417311369221		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 6.342417311369221 | validation: 5.598025913513639]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.12989372537594		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 6.12989372537594 | validation: 5.328373447686017]
	TIME [epoch: 25 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.99034970050376		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 5.99034970050376 | validation: 5.589169965150379]
	TIME [epoch: 25 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.397303037386588		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 6.397303037386588 | validation: 6.273149810079469]
	TIME [epoch: 25 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.107813173033552		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 7.107813173033552 | validation: 6.687578475641093]
	TIME [epoch: 25 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.1930592465495655		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 7.1930592465495655 | validation: 6.904298873801972]
	TIME [epoch: 25 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.7578372617529165		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 7.7578372617529165 | validation: 7.4670490457350684]
	TIME [epoch: 24.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.012738609583822		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 8.012738609583822 | validation: 7.4771322857548865]
	TIME [epoch: 24.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.106276264628878		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 8.106276264628878 | validation: 7.40554812230852]
	TIME [epoch: 24.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.068073008807563		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 8.068073008807563 | validation: 7.519686416226878]
	TIME [epoch: 24.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.232124989033672		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 8.232124989033672 | validation: 7.731485546462652]
	TIME [epoch: 25 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.79407069939847		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 8.79407069939847 | validation: 7.91647590988232]
	TIME [epoch: 24.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.709863967468754		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 8.709863967468754 | validation: 7.705951887798959]
	TIME [epoch: 24.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.327215038363633		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 8.327215038363633 | validation: 7.547619893977883]
	TIME [epoch: 24.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.140587278210115		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 8.140587278210115 | validation: 7.284306158105875]
	TIME [epoch: 24.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.163248294563166		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 8.163248294563166 | validation: 7.591273715485403]
	TIME [epoch: 24.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.211848674259565		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 8.211848674259565 | validation: 7.3181740182182775]
	TIME [epoch: 25 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.19209100012369		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 8.19209100012369 | validation: 7.663790818541244]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.791026528517438		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 8.791026528517438 | validation: 7.95215159822739]
	TIME [epoch: 25 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.01210753828468		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 9.01210753828468 | validation: 7.908956118478986]
	TIME [epoch: 25 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.911880203988876		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 8.911880203988876 | validation: 7.960541570715608]
	TIME [epoch: 25 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.938247721787484		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 8.938247721787484 | validation: 7.7829884646920435]
	TIME [epoch: 24.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.69455183052173		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 8.69455183052173 | validation: 7.50576092960325]
	TIME [epoch: 25 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.398331315637874		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 8.398331315637874 | validation: 7.356982699666287]
	TIME [epoch: 24.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.082364096015667		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 8.082364096015667 | validation: 6.900728458521922]
	TIME [epoch: 24.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.809065805416021		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 7.809065805416021 | validation: 7.137614821653506]
	TIME [epoch: 24.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.181133727695618		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 8.181133727695618 | validation: 7.355825585538175]
	TIME [epoch: 25 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.459279150369332		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 8.459279150369332 | validation: 7.2023820386791675]
	TIME [epoch: 24.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.79893111434426		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 7.79893111434426 | validation: 6.322200142479519]
	TIME [epoch: 25 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.76397502726808		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 6.76397502726808 | validation: 5.746785032208287]
	TIME [epoch: 24.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.216287331238151		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 6.216287331238151 | validation: 5.707586912453089]
	TIME [epoch: 24.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.302078422083644		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 6.302078422083644 | validation: 5.747542277925594]
	TIME [epoch: 25 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.36858072832519		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 6.36858072832519 | validation: 5.7427984336268905]
	TIME [epoch: 24.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2551104730304985		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 6.2551104730304985 | validation: 5.481527300796554]
	TIME [epoch: 24.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.050496377869337		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 6.050496377869337 | validation: 5.511173602333959]
	TIME [epoch: 25 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0083265095587315		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 6.0083265095587315 | validation: 5.372325943466502]
	TIME [epoch: 25 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.927962252724311		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 5.927962252724311 | validation: 5.343520805946191]
	TIME [epoch: 24.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.035130336046248		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 6.035130336046248 | validation: 5.416708846274828]
	TIME [epoch: 24.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0028568407553085		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 6.0028568407553085 | validation: 5.264865983692682]
	TIME [epoch: 25 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.912198997239929		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 5.912198997239929 | validation: 5.315872957652902]
	TIME [epoch: 25 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.965722652475534		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 5.965722652475534 | validation: 5.328846811899759]
	TIME [epoch: 24.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.010631088202518		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 6.010631088202518 | validation: 5.5318879061314465]
	TIME [epoch: 24.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.40112160235852		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 6.40112160235852 | validation: 6.086985084608795]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.253573318107337		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 7.253573318107337 | validation: 6.465231042486287]
	TIME [epoch: 24.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.975404886760278		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 6.975404886760278 | validation: 5.870688465571734]
	TIME [epoch: 24.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.599219309292004		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 6.599219309292004 | validation: 6.207588511424453]
	TIME [epoch: 24.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.791604773049699		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 6.791604773049699 | validation: 5.687567938502175]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.218596045442275		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 6.218596045442275 | validation: 5.403154996464413]
	TIME [epoch: 24.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2169774947039045		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 6.2169774947039045 | validation: 5.652630650778913]
	TIME [epoch: 24.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.289653142821558		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 6.289653142821558 | validation: 5.449035938909774]
	TIME [epoch: 24.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.138091274890066		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 6.138091274890066 | validation: 5.397915942122508]
	TIME [epoch: 24.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1242131374656985		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 6.1242131374656985 | validation: 5.309447868843629]
	TIME [epoch: 24.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.059229266372455		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 6.059229266372455 | validation: 5.318199497449539]
	TIME [epoch: 25 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.011895904677544		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 6.011895904677544 | validation: 5.274770338290485]
	TIME [epoch: 25 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.973641750845754		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 5.973641750845754 | validation: 5.249951246378733]
	TIME [epoch: 25 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.055351548261077		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 6.055351548261077 | validation: 5.315417377407621]
	TIME [epoch: 24.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.111734084285669		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 6.111734084285669 | validation: 5.425274025575634]
	TIME [epoch: 25 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.13997209162586		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 6.13997209162586 | validation: 5.355104890711307]
	TIME [epoch: 24.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.252267913866985		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 6.252267913866985 | validation: 5.471146164474369]
	TIME [epoch: 24.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1656398131067345		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 6.1656398131067345 | validation: 5.333552229301802]
	TIME [epoch: 24.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.190660423004207		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 6.190660423004207 | validation: 5.478867007523395]
	TIME [epoch: 24.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.212770793755745		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 6.212770793755745 | validation: 5.405643521257739]
	TIME [epoch: 25 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.161123252762226		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 6.161123252762226 | validation: 5.4450527948883956]
	TIME [epoch: 24.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.114368102206685		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 6.114368102206685 | validation: 5.407140839050192]
	TIME [epoch: 24.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.182366095495766		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 6.182366095495766 | validation: 5.437480945963557]
	TIME [epoch: 24.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.215112025453671		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 6.215112025453671 | validation: 5.410360837546189]
	TIME [epoch: 24.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.130744644729354		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 6.130744644729354 | validation: 5.26777864072536]
	TIME [epoch: 24.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.025373668313709		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 6.025373668313709 | validation: 5.238428791417826]
	TIME [epoch: 25 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0685117482981905		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 6.0685117482981905 | validation: 5.403159573498092]
	TIME [epoch: 24.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.169001982421555		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 6.169001982421555 | validation: 5.363004884137256]
	TIME [epoch: 24.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.117535382329683		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 6.117535382329683 | validation: 5.337423638269702]
	TIME [epoch: 24.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0823750463874		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 6.0823750463874 | validation: 5.364830933413016]
	TIME [epoch: 24.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.15889620906105		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 6.15889620906105 | validation: 5.348829175902586]
	TIME [epoch: 24.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.21275062191699		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 6.21275062191699 | validation: 5.478741566275451]
	TIME [epoch: 25 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.177665232570611		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 6.177665232570611 | validation: 5.339788382725059]
	TIME [epoch: 25 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.254977731268178		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 6.254977731268178 | validation: 5.456638365151632]
	TIME [epoch: 24.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.311785510766047		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 6.311785510766047 | validation: 5.558066281893048]
	TIME [epoch: 25 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.312804806655323		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 6.312804806655323 | validation: 5.531120453202167]
	TIME [epoch: 24.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.32626117504309		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 6.32626117504309 | validation: 5.471257483202524]
	TIME [epoch: 24.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.205403550566426		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 6.205403550566426 | validation: 5.35785950451982]
	TIME [epoch: 24.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.08461696609352		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 6.08461696609352 | validation: 5.326468675919784]
	TIME [epoch: 24.9 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.075518203750528		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 6.075518203750528 | validation: 5.428303337125961]
	TIME [epoch: 24.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.076325766789913		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 6.076325766789913 | validation: 5.424880525352373]
	TIME [epoch: 24.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.315829693532588		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 6.315829693532588 | validation: 5.867107073711351]
	TIME [epoch: 24.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.518162938353565		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 6.518162938353565 | validation: 5.7173540058960475]
	TIME [epoch: 24.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3071917151584085		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 6.3071917151584085 | validation: 5.796360591350943]
	TIME [epoch: 24.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.369438456536489		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 6.369438456536489 | validation: 5.601011349827595]
	TIME [epoch: 24.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.303550754711421		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 6.303550754711421 | validation: 5.689074914115103]
	TIME [epoch: 24.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.345427568726913		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 6.345427568726913 | validation: 5.856842154331248]
	TIME [epoch: 25 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.442576914099581		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 6.442576914099581 | validation: 5.760813323225709]
	TIME [epoch: 24.9 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.234054930192954		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 6.234054930192954 | validation: 5.435637248417491]
	TIME [epoch: 24.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.04053625095359		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 6.04053625095359 | validation: 5.301412557523885]
	TIME [epoch: 25 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.924714594998551		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 5.924714594998551 | validation: 5.142749307203558]
	TIME [epoch: 24.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.860552700607503		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 5.860552700607503 | validation: 5.184339879198486]
	TIME [epoch: 24.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.923824959181422		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 5.923824959181422 | validation: 5.190836574779208]
	TIME [epoch: 24.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.863711992440287		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 5.863711992440287 | validation: 5.125902102875152]
	TIME [epoch: 25 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.829936603294747		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 5.829936603294747 | validation: 5.119993939782056]
	TIME [epoch: 24.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.80882999201091		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 5.80882999201091 | validation: 5.102619163799136]
	TIME [epoch: 25 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.798404497322765		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 5.798404497322765 | validation: 5.106003049092184]
	TIME [epoch: 25 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.814726869491899		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 5.814726869491899 | validation: 5.134017198848924]
	TIME [epoch: 24.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.800023351915651		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 5.800023351915651 | validation: 5.106399699946406]
	TIME [epoch: 24.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7952131066284505		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 5.7952131066284505 | validation: 5.133140438847115]
	TIME [epoch: 25 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.840911039204289		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 5.840911039204289 | validation: 5.10950963031049]
	TIME [epoch: 24.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.814002946186779		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 5.814002946186779 | validation: 5.138610021424356]
	TIME [epoch: 24.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.794242643946892		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 5.794242643946892 | validation: 5.117472908394956]
	TIME [epoch: 25 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.792234911132891		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 5.792234911132891 | validation: 5.138656639272482]
	TIME [epoch: 24.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.800622076310499		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 5.800622076310499 | validation: 5.080996176904518]
	TIME [epoch: 25 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7724470091853		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 5.7724470091853 | validation: 5.085275378597431]
	TIME [epoch: 25 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.770484741776994		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 5.770484741776994 | validation: 5.07746690500799]
	TIME [epoch: 24.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.771214740886475		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 5.771214740886475 | validation: 5.088616719373556]
	TIME [epoch: 25 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.775464358496384		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 5.775464358496384 | validation: 5.094278428496689]
	TIME [epoch: 25 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.835140293086052		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 5.835140293086052 | validation: 5.120591285728355]
	TIME [epoch: 24.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.792658204119317		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 5.792658204119317 | validation: 5.085129345879572]
	TIME [epoch: 25 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.779338465069632		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 5.779338465069632 | validation: 5.095505062181102]
	TIME [epoch: 25 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.776197664076606		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 5.776197664076606 | validation: 5.059135604468612]
	TIME [epoch: 24.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.770593246904808		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 5.770593246904808 | validation: 5.102755021740643]
	TIME [epoch: 25 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.828462039222332		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 5.828462039222332 | validation: 5.21538282752413]
	TIME [epoch: 25 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.914219908519787		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 5.914219908519787 | validation: 5.251211881628952]
	TIME [epoch: 24.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9209910731203035		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 5.9209910731203035 | validation: 5.36905766658178]
	TIME [epoch: 25 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9089105587967214		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 5.9089105587967214 | validation: 5.1243431945275155]
	TIME [epoch: 24.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.813764727418063		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 5.813764727418063 | validation: 5.110774867473061]
	TIME [epoch: 24.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.794411443564353		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 5.794411443564353 | validation: 5.107870388677308]
	TIME [epoch: 24.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.78217259474155		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 5.78217259474155 | validation: 5.074553693444151]
	TIME [epoch: 25 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.808253806339651		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 5.808253806339651 | validation: 5.150317008238943]
	TIME [epoch: 24.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.972499797931237		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 5.972499797931237 | validation: 5.174605415406408]
	TIME [epoch: 25 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.839578643362342		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 5.839578643362342 | validation: 5.1192232173389]
	TIME [epoch: 25 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.824121064515556		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 5.824121064515556 | validation: 5.11843680874648]
	TIME [epoch: 24.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8078690215669955		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 5.8078690215669955 | validation: 5.116752247875114]
	TIME [epoch: 24.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.815864597884927		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 5.815864597884927 | validation: 5.063623151560332]
	TIME [epoch: 25 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.782433382577318		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 5.782433382577318 | validation: 5.069686170558405]
	TIME [epoch: 24.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.788615679364831		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 5.788615679364831 | validation: 5.098167290349941]
	TIME [epoch: 25 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.787004309338102		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 5.787004309338102 | validation: 5.04167643183523]
	TIME [epoch: 24.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.754174264613037		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 5.754174264613037 | validation: 5.055288900885257]
	TIME [epoch: 24.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.76808219875063		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 5.76808219875063 | validation: 5.066651709893791]
	TIME [epoch: 24.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.765163267405942		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 5.765163267405942 | validation: 5.049273158135985]
	TIME [epoch: 24.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.753165426893135		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 5.753165426893135 | validation: 5.110653415890492]
	TIME [epoch: 24.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.787745073038932		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 5.787745073038932 | validation: 5.048149651862491]
	TIME [epoch: 25 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.75023480458157		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 5.75023480458157 | validation: 5.059958131906011]
	TIME [epoch: 24.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.765552034472068		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 5.765552034472068 | validation: 5.047906499830004]
	TIME [epoch: 24.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.758694529017182		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 5.758694529017182 | validation: 5.044814972529764]
	TIME [epoch: 25 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.756159022787076		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 5.756159022787076 | validation: 5.06805056077241]
	TIME [epoch: 24.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8166952451550005		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 5.8166952451550005 | validation: 5.087981527054029]
	TIME [epoch: 24.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.844031321519758		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 5.844031321519758 | validation: 5.089594475862232]
	TIME [epoch: 24.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.839912550710195		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 5.839912550710195 | validation: 5.070917674640726]
	TIME [epoch: 24.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.807456458111884		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 5.807456458111884 | validation: 5.074496511120458]
	TIME [epoch: 24.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.822673949303668		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 5.822673949303668 | validation: 5.078398477177379]
	TIME [epoch: 24.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.81304303247007		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 5.81304303247007 | validation: 5.114415617499261]
	TIME [epoch: 24.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.810115446121097		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 5.810115446121097 | validation: 5.1180522728748]
	TIME [epoch: 25 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.81978007829081		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 5.81978007829081 | validation: 5.0898736586407205]
	TIME [epoch: 25 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.791699763004181		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 5.791699763004181 | validation: 5.103806162500615]
	TIME [epoch: 24.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.782483193489492		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 5.782483193489492 | validation: 5.051929020845365]
	TIME [epoch: 24.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.783429567474835		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 5.783429567474835 | validation: 5.102038370445187]
	TIME [epoch: 24.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.834736473786832		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 5.834736473786832 | validation: 5.05678112804829]
	TIME [epoch: 25 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8054476577567975		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 5.8054476577567975 | validation: 5.095960424308423]
	TIME [epoch: 24.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.852977768071351		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 5.852977768071351 | validation: 5.064534100227085]
	TIME [epoch: 25 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.851019587504966		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 5.851019587504966 | validation: 5.078913275096794]
	TIME [epoch: 25 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.836490228233583		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 5.836490228233583 | validation: 5.0670040511040435]
	TIME [epoch: 24.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8071981526502965		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 5.8071981526502965 | validation: 5.045735336505027]
	TIME [epoch: 24.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.795475372187509		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 5.795475372187509 | validation: 5.053140519959588]
	TIME [epoch: 24.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.824335533044819		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 5.824335533044819 | validation: 5.109836270723493]
	TIME [epoch: 24.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.869194966927358		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 5.869194966927358 | validation: 5.082024660474066]
	TIME [epoch: 25 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.957433790583609		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 5.957433790583609 | validation: 5.178544880229561]
	TIME [epoch: 25 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.991193183477078		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 5.991193183477078 | validation: 5.177839904803728]
	TIME [epoch: 24.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.947809507748529		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 5.947809507748529 | validation: 5.105507977442351]
	TIME [epoch: 25 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.905522823330978		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 5.905522823330978 | validation: 5.092473130613359]
	TIME [epoch: 24.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.843387466431307		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 5.843387466431307 | validation: 5.067763181149379]
	TIME [epoch: 24.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.815987897158539		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 5.815987897158539 | validation: 5.064871958792684]
	TIME [epoch: 25 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.79761128340763		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 5.79761128340763 | validation: 5.041978421476056]
	TIME [epoch: 24.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.799858044111051		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 5.799858044111051 | validation: 5.051566632495142]
	TIME [epoch: 24.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.81095335431528		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 5.81095335431528 | validation: 5.077966996096861]
	TIME [epoch: 25 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8804625846797975		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 5.8804625846797975 | validation: 5.154262212700026]
	TIME [epoch: 25 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.856553585796336		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 5.856553585796336 | validation: 5.050320804466183]
	TIME [epoch: 24.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.804467336645951		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 5.804467336645951 | validation: 5.069585051684294]
	TIME [epoch: 24.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.822906237017027		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 5.822906237017027 | validation: 5.067338293353762]
	TIME [epoch: 25 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.792021749935825		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 5.792021749935825 | validation: 5.040399816544318]
	TIME [epoch: 24.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.783810492942653		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 5.783810492942653 | validation: 5.093219424360264]
	TIME [epoch: 25 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.815470282572945		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 5.815470282572945 | validation: 5.040292008382453]
	TIME [epoch: 24.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.76497617614497		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 5.76497617614497 | validation: 5.038623476665854]
	TIME [epoch: 24.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.756330151519676		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 5.756330151519676 | validation: 5.049110418901561]
	TIME [epoch: 24.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.767911596805188		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 5.767911596805188 | validation: 5.070542014873156]
	TIME [epoch: 24.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.780092412423883		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 5.780092412423883 | validation: 5.032035680179128]
	TIME [epoch: 24.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.760784055292088		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 5.760784055292088 | validation: 5.051817945852906]
	TIME [epoch: 24.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.833540910878023		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 5.833540910878023 | validation: 5.133772593933684]
	TIME [epoch: 24.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.790055099536189		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 5.790055099536189 | validation: 5.059548924352531]
	TIME [epoch: 24.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.767818114963478		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 5.767818114963478 | validation: 5.04850136211286]
	TIME [epoch: 24.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.750679905452468		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 5.750679905452468 | validation: 5.0316568625387506]
	TIME [epoch: 25 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.74274353381745		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 5.74274353381745 | validation: 5.029613654849386]
	TIME [epoch: 24.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.74047867063827		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 5.74047867063827 | validation: 5.039483032724287]
	TIME [epoch: 24.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.759641882612723		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 5.759641882612723 | validation: 5.049998139062482]
	TIME [epoch: 24.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7535730360647035		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 5.7535730360647035 | validation: 5.032351556016566]
	TIME [epoch: 24.9 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7479039654271356		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 5.7479039654271356 | validation: 5.026833388624797]
	TIME [epoch: 25 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742879843036139		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 5.742879843036139 | validation: 5.031297406783311]
	TIME [epoch: 25 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.756433082733157		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 5.756433082733157 | validation: 5.059326946042124]
	TIME [epoch: 24.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.778903177732082		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 5.778903177732082 | validation: 5.028588864048343]
	TIME [epoch: 24.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.732542202506151		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 5.732542202506151 | validation: 5.022984579389775]
	TIME [epoch: 24.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.756017218288353		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 5.756017218288353 | validation: 5.0866287917518855]
	TIME [epoch: 24.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8289134447343995		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 5.8289134447343995 | validation: 5.121365282743766]
	TIME [epoch: 24.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.830328120727549		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 5.830328120727549 | validation: 5.043967540797763]
	TIME [epoch: 25 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.749197049884609		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 5.749197049884609 | validation: 5.024934225822993]
	TIME [epoch: 24.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.738363359502741		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 5.738363359502741 | validation: 5.0199648126006124]
	TIME [epoch: 24.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7512373220722575		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 5.7512373220722575 | validation: 5.024046794218392]
	TIME [epoch: 25 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.738678139131089		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 5.738678139131089 | validation: 5.003126280592881]
	TIME [epoch: 25 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.731568212732552		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 5.731568212732552 | validation: 4.990147806610777]
	TIME [epoch: 24.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.740809613580227		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 5.740809613580227 | validation: 5.017212462491726]
	TIME [epoch: 25 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.748269045778735		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 5.748269045778735 | validation: 5.014953332851627]
	TIME [epoch: 24.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.777406157428608		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 5.777406157428608 | validation: 5.135545259235012]
	TIME [epoch: 25 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.926793226771691		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 5.926793226771691 | validation: 5.189242606906546]
	TIME [epoch: 24.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.906379537972748		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 5.906379537972748 | validation: 5.054966157987206]
	TIME [epoch: 25 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.818593992329718		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 5.818593992329718 | validation: 5.055710174831453]
	TIME [epoch: 25 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8157132068456034		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 5.8157132068456034 | validation: 5.048275172020963]
	TIME [epoch: 25 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.854329219899112		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 5.854329219899112 | validation: 5.084107462752524]
	TIME [epoch: 25 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.867789205969765		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 5.867789205969765 | validation: 5.081052250276022]
	TIME [epoch: 25 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.832064200289576		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 5.832064200289576 | validation: 5.0586892422445215]
	TIME [epoch: 25 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.786960663648392		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 5.786960663648392 | validation: 5.102866286696966]
	TIME [epoch: 25 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.823387103845224		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 5.823387103845224 | validation: 5.1344520957457735]
	TIME [epoch: 24.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.840916335812549		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 5.840916335812549 | validation: 5.102752380296235]
	TIME [epoch: 25 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.782202939201685		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 5.782202939201685 | validation: 5.006624471419282]
	TIME [epoch: 25 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.740632996703926		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 5.740632996703926 | validation: 5.017909464983919]
	TIME [epoch: 25 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.757814488512162		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 5.757814488512162 | validation: 5.028050675565441]
	TIME [epoch: 24.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.806765915988114		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 5.806765915988114 | validation: 5.02202073926469]
	TIME [epoch: 24.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.770929434005984		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 5.770929434005984 | validation: 5.000698295626889]
	TIME [epoch: 24.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.744369080174359		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 5.744369080174359 | validation: 5.008148413805361]
	TIME [epoch: 24.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.749845783039312		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 5.749845783039312 | validation: 5.011499050150703]
	TIME [epoch: 24.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.772578879851667		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 5.772578879851667 | validation: 5.045289362666959]
	TIME [epoch: 25 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.789986352120517		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 5.789986352120517 | validation: 5.013484600162832]
	TIME [epoch: 24.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.763196704377545		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 5.763196704377545 | validation: 5.013947690406371]
	TIME [epoch: 25 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.780422865681452		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 5.780422865681452 | validation: 5.050405737852045]
	TIME [epoch: 24.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7714055467142025		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 5.7714055467142025 | validation: 5.006566773180781]
	TIME [epoch: 25 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7700519750661785		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 5.7700519750661785 | validation: 5.05295817711538]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.762008254630873		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 5.762008254630873 | validation: 5.005613963236819]
	TIME [epoch: 25 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.745759055777549		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 5.745759055777549 | validation: 4.988090756444351]
	TIME [epoch: 25 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.74771805411393		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 5.74771805411393 | validation: 5.003205287804019]
	TIME [epoch: 25 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.765123613915524		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 5.765123613915524 | validation: 5.014213692346255]
	TIME [epoch: 25 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7791349863459125		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 5.7791349863459125 | validation: 5.012409575924097]
	TIME [epoch: 25 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.751846272497276		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 5.751846272497276 | validation: 5.001635367926808]
	TIME [epoch: 24.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.756240833038452		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 5.756240833038452 | validation: 5.005971574927559]
	TIME [epoch: 25 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7594926830532645		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 5.7594926830532645 | validation: 5.01896514684622]
	TIME [epoch: 24.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.750328074060695		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 5.750328074060695 | validation: 5.015195751906559]
	TIME [epoch: 25 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.74792098854449		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 5.74792098854449 | validation: 4.988353203486518]
	TIME [epoch: 24.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.739861183276004		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 5.739861183276004 | validation: 5.000315253122075]
	TIME [epoch: 25 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.749422747920835		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 5.749422747920835 | validation: 4.996043300708199]
	TIME [epoch: 25 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.749239033443347		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 5.749239033443347 | validation: 4.994527729612294]
	TIME [epoch: 24.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.734425065377685		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 5.734425065377685 | validation: 5.002517490507043]
	TIME [epoch: 24.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7348038497220495		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 5.7348038497220495 | validation: 4.992306593476517]
	TIME [epoch: 24.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.743000958892257		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 5.743000958892257 | validation: 5.010849395116864]
	TIME [epoch: 24.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.740684944262702		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 5.740684944262702 | validation: 5.018710631454383]
	TIME [epoch: 24.9 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.729996415742541		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 5.729996415742541 | validation: 5.006604776701019]
	TIME [epoch: 24.9 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.774948174573707		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 5.774948174573707 | validation: 5.110882852125797]
	TIME [epoch: 24.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.824514506282795		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 5.824514506282795 | validation: 5.053353992583761]
	TIME [epoch: 24.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.773517687695333		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 5.773517687695333 | validation: 5.061220339390963]
	TIME [epoch: 24.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.767023163391686		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 5.767023163391686 | validation: 5.035082978961058]
	TIME [epoch: 24.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.736895378690615		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 5.736895378690615 | validation: 4.993414167132697]
	TIME [epoch: 24.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.729082723624186		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 5.729082723624186 | validation: 5.019507417637433]
	TIME [epoch: 24.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.732746156541753		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 5.732746156541753 | validation: 5.036114269743927]
	TIME [epoch: 24.9 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.764288140113397		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 5.764288140113397 | validation: 5.066455569953827]
	TIME [epoch: 24.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8292475588247505		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 5.8292475588247505 | validation: 5.137397426893967]
	TIME [epoch: 24.9 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.868118717239126		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 5.868118717239126 | validation: 5.125688705326943]
	TIME [epoch: 25 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8348994337384426		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 5.8348994337384426 | validation: 5.037468902989879]
	TIME [epoch: 25 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.763881862604453		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 5.763881862604453 | validation: 4.999419774230697]
	TIME [epoch: 25 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.74113758272327		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 5.74113758272327 | validation: 4.999355472634981]
	TIME [epoch: 25 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.726943139793408		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 5.726943139793408 | validation: 4.9864507782867316]
	TIME [epoch: 25 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7295217015305795		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 5.7295217015305795 | validation: 5.0009766066392425]
	TIME [epoch: 25 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.722015253373385		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 5.722015253373385 | validation: 4.997557176238167]
	TIME [epoch: 24.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.732580970794141		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 5.732580970794141 | validation: 5.092859523578266]
	TIME [epoch: 24.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.853365057617962		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 5.853365057617962 | validation: 5.105179299956994]
	TIME [epoch: 24.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.77984621582342		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 5.77984621582342 | validation: 4.995606303891901]
	TIME [epoch: 25 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.722798012733115		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 5.722798012733115 | validation: 5.003320100326223]
	TIME [epoch: 25 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.736480666404511		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 5.736480666404511 | validation: 5.049509378191259]
	TIME [epoch: 25 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7528806857943735		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 5.7528806857943735 | validation: 5.012440191927841]
	TIME [epoch: 24.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.741321338296702		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 5.741321338296702 | validation: 5.040773685658313]
	TIME [epoch: 25 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.732943512765947		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 5.732943512765947 | validation: 4.991258719452579]
	TIME [epoch: 25 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.717070233779449		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 5.717070233779449 | validation: 4.991024349257745]
	TIME [epoch: 25 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.73176001342525		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 5.73176001342525 | validation: 4.995072351223904]
	TIME [epoch: 25 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718476214771545		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 5.718476214771545 | validation: 4.9901469528536415]
	TIME [epoch: 25 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718896977042217		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 5.718896977042217 | validation: 4.994138632786626]
	TIME [epoch: 24.9 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.71947640060186		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 5.71947640060186 | validation: 4.993448761014425]
	TIME [epoch: 24.9 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.714142086415596		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 5.714142086415596 | validation: 4.980627952010675]
	TIME [epoch: 24.9 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7150550123303265		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 5.7150550123303265 | validation: 4.992158015345403]
	TIME [epoch: 24.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.722481455108346		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 5.722481455108346 | validation: 5.007246339477187]
	TIME [epoch: 25 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.762417279790765		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 5.762417279790765 | validation: 5.0786332021488185]
	TIME [epoch: 25 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7829258821998595		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 5.7829258821998595 | validation: 5.027193424337454]
	TIME [epoch: 25 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.724764622031546		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 5.724764622031546 | validation: 4.999947354821563]
	TIME [epoch: 25 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.723588263546459		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 5.723588263546459 | validation: 5.006118469979878]
	TIME [epoch: 25 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.73907261801423		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 5.73907261801423 | validation: 5.0575930388959955]
	TIME [epoch: 24.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.806378196095817		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 5.806378196095817 | validation: 5.019360513438216]
	TIME [epoch: 24.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7418356603526455		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 5.7418356603526455 | validation: 5.001580273137789]
	TIME [epoch: 24.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.765002670725354		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 5.765002670725354 | validation: 5.028897332736413]
	TIME [epoch: 24.9 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.738876042837585		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 5.738876042837585 | validation: 5.003502189031045]
	TIME [epoch: 24.9 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.720150462157874		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 5.720150462157874 | validation: 4.992449808761683]
	TIME [epoch: 24.9 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7263090053266845		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 5.7263090053266845 | validation: 5.026487006678847]
	TIME [epoch: 24.9 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742878908457641		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 5.742878908457641 | validation: 5.0145106872880865]
	TIME [epoch: 24.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.748928865764702		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 5.748928865764702 | validation: 5.046227110219708]
	TIME [epoch: 24.9 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7720180765536435		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 5.7720180765536435 | validation: 5.013529575699817]
	TIME [epoch: 24.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742939261285697		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 5.742939261285697 | validation: 5.041167594451282]
	TIME [epoch: 24.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.775815795646421		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 5.775815795646421 | validation: 5.07029754654935]
	TIME [epoch: 24.9 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.786829933291566		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 5.786829933291566 | validation: 5.09305281444689]
	TIME [epoch: 24.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8086492828499505		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 5.8086492828499505 | validation: 5.173911298821909]
	TIME [epoch: 24.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.872748185322016		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 5.872748185322016 | validation: 5.189754094786764]
	TIME [epoch: 24.9 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.842243825861408		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 5.842243825861408 | validation: 5.184132567758933]
	TIME [epoch: 24.9 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.861942089562793		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 5.861942089562793 | validation: 5.1437067893101815]
	TIME [epoch: 24.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.785620843657777		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 5.785620843657777 | validation: 5.058768754767093]
	TIME [epoch: 24.9 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.741939109995252		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 5.741939109995252 | validation: 5.017140480358745]
	TIME [epoch: 24.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.725033321516392		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 5.725033321516392 | validation: 5.0054495490829956]
	TIME [epoch: 24.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.724979183907539		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 5.724979183907539 | validation: 5.005685794289584]
	TIME [epoch: 24.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.722480802273957		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 5.722480802273957 | validation: 5.017022757825496]
	TIME [epoch: 24.9 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.724937258831988		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 5.724937258831988 | validation: 5.006673438930989]
	TIME [epoch: 25 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.730082899230077		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 5.730082899230077 | validation: 5.006818709421739]
	TIME [epoch: 24.9 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.747920195616123		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 5.747920195616123 | validation: 5.0615901749992664]
	TIME [epoch: 24.9 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.762514871540045		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 5.762514871540045 | validation: 5.028215825694177]
	TIME [epoch: 24.9 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.767893950057108		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 5.767893950057108 | validation: 5.066508263118746]
	TIME [epoch: 24.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.774731008391499		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 5.774731008391499 | validation: 5.040705550748068]
	TIME [epoch: 24.9 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.776381653451006		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 5.776381653451006 | validation: 5.039821834666]
	TIME [epoch: 24.9 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.759568297270186		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 5.759568297270186 | validation: 5.006208219745231]
	TIME [epoch: 24.9 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.725888495757325		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 5.725888495757325 | validation: 4.992641706485413]
	TIME [epoch: 24.9 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.709307656577558		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 5.709307656577558 | validation: 4.997470991550822]
	TIME [epoch: 24.9 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.71532955367752		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 5.71532955367752 | validation: 5.012359419222979]
	TIME [epoch: 24.9 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.734504874595094		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 5.734504874595094 | validation: 5.035600305301281]
	TIME [epoch: 24.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.749845450460288		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 5.749845450460288 | validation: 4.999796181499801]
	TIME [epoch: 24.9 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.714572437618596		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 5.714572437618596 | validation: 4.999759286550861]
	TIME [epoch: 24.9 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7183727643691125		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 5.7183727643691125 | validation: 5.005970143705092]
	TIME [epoch: 24.9 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.758924645813386		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 5.758924645813386 | validation: 5.0723016274177795]
	TIME [epoch: 24.9 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.782850383995388		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 5.782850383995388 | validation: 5.023752823012544]
	TIME [epoch: 24.9 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.741005508114121		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 5.741005508114121 | validation: 5.020851350118029]
	TIME [epoch: 24.9 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.729750742879603		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 5.729750742879603 | validation: 4.993236236942008]
	TIME [epoch: 24.9 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7178594384070145		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 5.7178594384070145 | validation: 4.9887649053811325]
	TIME [epoch: 24.9 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.713684930794615		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 5.713684930794615 | validation: 5.001511079511722]
	TIME [epoch: 24.9 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.729583393628823		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 5.729583393628823 | validation: 5.0095636656078]
	TIME [epoch: 24.9 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.727842151622791		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 5.727842151622791 | validation: 4.994698445347093]
	TIME [epoch: 24.9 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.732708145861223		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 5.732708145861223 | validation: 4.995415298925559]
	TIME [epoch: 24.9 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.726801230210543		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 5.726801230210543 | validation: 4.993947809829616]
	TIME [epoch: 25 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.715785686958978		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 5.715785686958978 | validation: 4.9943723083641895]
	TIME [epoch: 25 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.730521205126359		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 5.730521205126359 | validation: 4.998436825482495]
	TIME [epoch: 25 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.738579609501257		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 5.738579609501257 | validation: 5.0048719615954305]
	TIME [epoch: 24.9 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.728292265088207		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 5.728292265088207 | validation: 4.989389068592499]
	TIME [epoch: 24.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.720731742931979		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 5.720731742931979 | validation: 4.994583229739719]
	TIME [epoch: 24.9 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.720280981628603		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 5.720280981628603 | validation: 4.996347826293471]
	TIME [epoch: 24.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.719876190219214		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 5.719876190219214 | validation: 5.0029889467816115]
	TIME [epoch: 25 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.72109903740966		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 5.72109903740966 | validation: 5.01110248333317]
	TIME [epoch: 24.9 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.729162152937075		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 5.729162152937075 | validation: 5.028316132905501]
	TIME [epoch: 24.9 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.73873126454429		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 5.73873126454429 | validation: 5.020052758751218]
	TIME [epoch: 24.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7212919594488305		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 5.7212919594488305 | validation: 5.012514424959688]
	TIME [epoch: 24.9 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7291507371111186		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 5.7291507371111186 | validation: 4.982239950817969]
	TIME [epoch: 24.9 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.717359048390531		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 5.717359048390531 | validation: 4.99733238167857]
	TIME [epoch: 24.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.748712389504028		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 5.748712389504028 | validation: 5.0157862076996365]
	TIME [epoch: 24.9 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.734282431978327		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 5.734282431978327 | validation: 4.981030105190622]
	TIME [epoch: 24.9 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.717382495856744		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 5.717382495856744 | validation: 5.000160221779439]
	TIME [epoch: 25 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7261949947777495		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 5.7261949947777495 | validation: 4.987602215423092]
	TIME [epoch: 25 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.716500494550322		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 5.716500494550322 | validation: 4.978165208318546]
	TIME [epoch: 25 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.719974586304026		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 5.719974586304026 | validation: 4.977132122067473]
	TIME [epoch: 25 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7145685077835155		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 5.7145685077835155 | validation: 4.966070682480894]
	TIME [epoch: 25 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.719562813103687		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 5.719562813103687 | validation: 4.9727643659558005]
	TIME [epoch: 24.9 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.711955733256763		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 5.711955733256763 | validation: 4.975738750187608]
	TIME [epoch: 24.9 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.711466832453046		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 5.711466832453046 | validation: 4.983007658291345]
	TIME [epoch: 24.9 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.714075900321785		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 5.714075900321785 | validation: 4.997670394889806]
	TIME [epoch: 25 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.709870846590717		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 5.709870846590717 | validation: 4.99877917885889]
	TIME [epoch: 25 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718618003443138		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 5.718618003443138 | validation: 5.007165566205622]
	TIME [epoch: 25 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.724059713757266		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 5.724059713757266 | validation: 5.024483242188664]
	TIME [epoch: 25 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.736112735683713		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 5.736112735683713 | validation: 5.0158549849348155]
	TIME [epoch: 25 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.716748672584944		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 5.716748672584944 | validation: 5.017053656272279]
	TIME [epoch: 25 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.723451981882949		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 5.723451981882949 | validation: 5.016815827478401]
	TIME [epoch: 25 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7284016522196515		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 5.7284016522196515 | validation: 4.988367831582182]
	TIME [epoch: 25 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.711489183969018		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 5.711489183969018 | validation: 4.992571451482588]
	TIME [epoch: 25 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.717474271561296		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 5.717474271561296 | validation: 4.965128448582683]
	TIME [epoch: 25 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.711895672521241		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 5.711895672521241 | validation: 4.9729578747582766]
	TIME [epoch: 25 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.713505808227743		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 5.713505808227743 | validation: 4.974575381732714]
	TIME [epoch: 25 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.722939071144606		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 5.722939071144606 | validation: 4.992850296951635]
	TIME [epoch: 25 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.725610669354409		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 5.725610669354409 | validation: 4.985019088797451]
	TIME [epoch: 25 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.721803523309383		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 5.721803523309383 | validation: 5.027695615222002]
	TIME [epoch: 24.9 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.759447288830238		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 5.759447288830238 | validation: 5.00650673140352]
	TIME [epoch: 25 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.717102958384776		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 5.717102958384776 | validation: 4.988414389904862]
	TIME [epoch: 25 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.720410814623083		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 5.720410814623083 | validation: 4.984236184016547]
	TIME [epoch: 25 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.707724425537806		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 5.707724425537806 | validation: 4.979187467656014]
	TIME [epoch: 25 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.70913095458541		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 5.70913095458541 | validation: 5.000205924199793]
	TIME [epoch: 25 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.727566785219109		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 5.727566785219109 | validation: 4.977261321455363]
	TIME [epoch: 25 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.710007156019206		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 5.710007156019206 | validation: 4.998971159705104]
	TIME [epoch: 25 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.707274092354177		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 5.707274092354177 | validation: 4.98304780714097]
	TIME [epoch: 25 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.708866083531001		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 5.708866083531001 | validation: 4.9865732190986485]
	TIME [epoch: 25 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.722002728501244		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 5.722002728501244 | validation: 4.987061591583655]
	TIME [epoch: 25 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.712990113466138		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 5.712990113466138 | validation: 4.994095037870978]
	TIME [epoch: 25 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.707023363301472		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 5.707023363301472 | validation: 4.987950685632027]
	TIME [epoch: 24.9 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.722532861439471		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 5.722532861439471 | validation: 5.064355162958931]
	TIME [epoch: 25 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.784212631354578		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 5.784212631354578 | validation: 5.0248648771779925]
	TIME [epoch: 24.9 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.743594985939525		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 5.743594985939525 | validation: 5.034161334768749]
	TIME [epoch: 24.9 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.796524685948279		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 5.796524685948279 | validation: 5.023909126367293]
	TIME [epoch: 25 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.73753494028365		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 5.73753494028365 | validation: 4.984625345301506]
	TIME [epoch: 24.9 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718591420726082		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 5.718591420726082 | validation: 4.9927492542290075]
	TIME [epoch: 24.9 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.709665142986965		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 5.709665142986965 | validation: 4.990571450720706]
	TIME [epoch: 24.9 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.743752521448066		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 5.743752521448066 | validation: 5.029654967003513]
	TIME [epoch: 25 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.752704466751583		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 5.752704466751583 | validation: 5.004702064273001]
	TIME [epoch: 24.9 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7243956686890325		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 5.7243956686890325 | validation: 4.996043693581736]
	TIME [epoch: 25 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718590941219588		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 5.718590941219588 | validation: 4.984819147409093]
	TIME [epoch: 25 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7162097355794455		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 5.7162097355794455 | validation: 4.983016057257917]
	TIME [epoch: 25 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.719274564975468		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 5.719274564975468 | validation: 4.9960379173282625]
	TIME [epoch: 25 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7160843086201005		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 5.7160843086201005 | validation: 4.986683918944343]
	TIME [epoch: 24.9 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.733140485160894		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 5.733140485160894 | validation: 5.028350733448978]
	TIME [epoch: 24.9 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.732872000796527		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 5.732872000796527 | validation: 5.002908414964278]
	TIME [epoch: 24.9 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718186272935272		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 5.718186272935272 | validation: 4.990684167915202]
	TIME [epoch: 25 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.712046215397848		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 5.712046215397848 | validation: 4.977961517714192]
	TIME [epoch: 25 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.746064225818504		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 5.746064225818504 | validation: 5.003706387651125]
	TIME [epoch: 24.9 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742462187358743		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 5.742462187358743 | validation: 5.008124063077657]
	TIME [epoch: 24.9 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.757042532431454		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 5.757042532431454 | validation: 5.010010130684846]
	TIME [epoch: 24.9 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.763563224278636		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 5.763563224278636 | validation: 4.99841650773281]
	TIME [epoch: 24.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.759506957494933		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 5.759506957494933 | validation: 5.017915757096189]
	TIME [epoch: 24.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.761130407726871		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 5.761130407726871 | validation: 5.015056468747965]
	TIME [epoch: 25 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.772650609624485		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 5.772650609624485 | validation: 5.011664786797621]
	TIME [epoch: 25 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.765309267331689		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 5.765309267331689 | validation: 5.013055721504495]
	TIME [epoch: 25 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.781504769906958		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 5.781504769906958 | validation: 5.008513108761889]
	TIME [epoch: 24.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.760765407527526		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 5.760765407527526 | validation: 5.025783398233147]
	TIME [epoch: 24.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.775553175555697		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 5.775553175555697 | validation: 5.04472245673415]
	TIME [epoch: 24.9 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.789512247502892		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 5.789512247502892 | validation: 5.019881174848599]
	TIME [epoch: 25 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7626525357644995		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 5.7626525357644995 | validation: 5.004000811730599]
	TIME [epoch: 24.9 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.750107220542445		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 5.750107220542445 | validation: 5.00139908055246]
	TIME [epoch: 24.9 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.775971972646438		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 5.775971972646438 | validation: 5.02034053899221]
	TIME [epoch: 24.9 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.805621333602376		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 5.805621333602376 | validation: 5.017029525663204]
	TIME [epoch: 25 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.792333814825886		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 5.792333814825886 | validation: 5.019796299730179]
	TIME [epoch: 24.9 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.770320042557735		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 5.770320042557735 | validation: 4.995724947392604]
	TIME [epoch: 24.9 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.772839594866869		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 5.772839594866869 | validation: 5.019986561415367]
	TIME [epoch: 24.9 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.762541240489849		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 5.762541240489849 | validation: 4.999820093530645]
	TIME [epoch: 24.9 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.752671182658862		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 5.752671182658862 | validation: 5.024848390712434]
	TIME [epoch: 25 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.760452330152855		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 5.760452330152855 | validation: 5.04653900438789]
	TIME [epoch: 24.9 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.757683280313508		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 5.757683280313508 | validation: 5.013733196175054]
	TIME [epoch: 25 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.745205885465142		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 5.745205885465142 | validation: 5.012120491781184]
	TIME [epoch: 24.9 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.730450171337908		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 5.730450171337908 | validation: 5.003842830732521]
	TIME [epoch: 24.9 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.733460348501842		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 5.733460348501842 | validation: 5.018252612230024]
	TIME [epoch: 25 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.768340673940535		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 5.768340673940535 | validation: 5.08531192005896]
	TIME [epoch: 24.9 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.800203094756845		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 5.800203094756845 | validation: 5.046678411259011]
	TIME [epoch: 25 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.762764516729814		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 5.762764516729814 | validation: 4.992666110273878]
	TIME [epoch: 25 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.719622994091707		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 5.719622994091707 | validation: 4.9762298654473645]
	TIME [epoch: 24.9 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.710912053161629		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 5.710912053161629 | validation: 4.965621060619783]
	TIME [epoch: 24.9 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.710160823488183		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 5.710160823488183 | validation: 4.982582312436572]
	TIME [epoch: 24.9 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742060189152255		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 5.742060189152255 | validation: 5.011983197584709]
	TIME [epoch: 24.9 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742727587146187		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 5.742727587146187 | validation: 5.038083259670028]
	TIME [epoch: 24.9 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.743589912486449		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 5.743589912486449 | validation: 5.006893812636401]
	TIME [epoch: 24.9 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.744872541154704		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 5.744872541154704 | validation: 5.025285875272624]
	TIME [epoch: 24.9 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.747050397162424		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 5.747050397162424 | validation: 5.002707643806721]
	TIME [epoch: 24.9 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7286295854564715		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 5.7286295854564715 | validation: 4.994899054973432]
	TIME [epoch: 24.9 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.722877400009989		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 5.722877400009989 | validation: 5.015716159783352]
	TIME [epoch: 24.9 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7559256810238		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 5.7559256810238 | validation: 5.061404412291217]
	TIME [epoch: 24.9 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.789708440464825		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 5.789708440464825 | validation: 5.056074209313703]
	TIME [epoch: 25 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.770798586339503		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 5.770798586339503 | validation: 5.011281274668216]
	TIME [epoch: 24.9 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.737287058425286		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 5.737287058425286 | validation: 5.002838558472977]
	TIME [epoch: 24.9 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.725678391172064		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 5.725678391172064 | validation: 4.987493776623463]
	TIME [epoch: 24.9 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.715184936565106		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 5.715184936565106 | validation: 4.9915018144913885]
	TIME [epoch: 24.9 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.717845596760123		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 5.717845596760123 | validation: 4.975344047719149]
	TIME [epoch: 25 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.70978941562599		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 5.70978941562599 | validation: 5.000327735440222]
	TIME [epoch: 25 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.727397194230617		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 5.727397194230617 | validation: 4.978387102189132]
	TIME [epoch: 24.9 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.709713068352739		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 5.709713068352739 | validation: 4.974203745122028]
	TIME [epoch: 24.9 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.712851324265889		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 5.712851324265889 | validation: 4.978024497265801]
	TIME [epoch: 24.9 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718683006827476		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 5.718683006827476 | validation: 4.993953100775811]
	TIME [epoch: 24.9 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.710746695450249		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 5.710746695450249 | validation: 4.9819712653900705]
	TIME [epoch: 24.9 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.711586563384612		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 5.711586563384612 | validation: 4.988215177147597]
	TIME [epoch: 25 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.713960446646827		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 5.713960446646827 | validation: 4.976285975985088]
	TIME [epoch: 24.9 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.723838864143635		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 5.723838864143635 | validation: 4.961216063909824]
	TIME [epoch: 24.9 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.715989681417563		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 5.715989681417563 | validation: 4.966461208363724]
	TIME [epoch: 24.9 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.709236324337463		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 5.709236324337463 | validation: 4.987669845737953]
	TIME [epoch: 24.9 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.709156165054242		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 5.709156165054242 | validation: 4.968441099332816]
	TIME [epoch: 24.9 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.711413781794091		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 5.711413781794091 | validation: 4.982796159273882]
	TIME [epoch: 25 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7105690221346315		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 5.7105690221346315 | validation: 4.984082399228889]
	TIME [epoch: 24.9 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7067974847287575		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 5.7067974847287575 | validation: 4.967942826507482]
	TIME [epoch: 24.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7125200664118445		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 5.7125200664118445 | validation: 4.974482433928244]
	TIME [epoch: 24.9 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718164578102062		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 5.718164578102062 | validation: 4.967865577188629]
	TIME [epoch: 24.9 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.715355608249233		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 5.715355608249233 | validation: 4.972462551104597]
	TIME [epoch: 24.9 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.714354530203128		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 5.714354530203128 | validation: 4.982226585450937]
	TIME [epoch: 25 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.70940847753957		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 5.70940847753957 | validation: 4.97996857564003]
	TIME [epoch: 24.9 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.707428844407267		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 5.707428844407267 | validation: 4.981353704562958]
	TIME [epoch: 24.9 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.709785978152452		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 5.709785978152452 | validation: 4.977035079123012]
	TIME [epoch: 24.9 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7100098073149566		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 5.7100098073149566 | validation: 4.985798874872615]
	TIME [epoch: 24.9 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.712334525906738		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 5.712334525906738 | validation: 4.984321670041997]
	TIME [epoch: 24.9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.723909853219391		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 5.723909853219391 | validation: 5.001016569777896]
	TIME [epoch: 25 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.726201970336379		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 5.726201970336379 | validation: 4.990326025883171]
	TIME [epoch: 24.9 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7222177440908055		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 5.7222177440908055 | validation: 4.9862226036406945]
	TIME [epoch: 24.9 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718161898856361		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 5.718161898856361 | validation: 4.984728041051297]
	TIME [epoch: 24.9 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.71922508163327		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 5.71922508163327 | validation: 4.994358878457428]
	TIME [epoch: 25 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718962626994583		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 5.718962626994583 | validation: 4.996299604648639]
	TIME [epoch: 24.9 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.728419755887089		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 5.728419755887089 | validation: 5.019298561822579]
	TIME [epoch: 24.9 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.737797176144591		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 5.737797176144591 | validation: 5.022296790643046]
	TIME [epoch: 24.9 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.757047875352503		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 5.757047875352503 | validation: 5.0772159632191105]
	TIME [epoch: 24.9 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.795465337893621		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 5.795465337893621 | validation: 5.06709576076477]
	TIME [epoch: 24.9 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.786671404088732		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 5.786671404088732 | validation: 5.048505512945072]
	TIME [epoch: 24.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.786181910443518		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 5.786181910443518 | validation: 5.0777685826816645]
	TIME [epoch: 24.9 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.772533024151261		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 5.772533024151261 | validation: 5.017414411141421]
	TIME [epoch: 24.9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7432293172753255		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 5.7432293172753255 | validation: 5.018783876126832]
	TIME [epoch: 25 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.73631785841785		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 5.73631785841785 | validation: 5.01813364204501]
	TIME [epoch: 24.9 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7278466484679225		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 5.7278466484679225 | validation: 5.004405393899871]
	TIME [epoch: 25 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.72851496093132		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 5.72851496093132 | validation: 5.010475134679985]
	TIME [epoch: 24.9 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.722809825339059		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 5.722809825339059 | validation: 4.9922201010806075]
	TIME [epoch: 24.9 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.717218298377829		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 5.717218298377829 | validation: 4.984466550278816]
	TIME [epoch: 24.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.72363007486134		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 5.72363007486134 | validation: 4.988471406559317]
	TIME [epoch: 25 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.719788995358954		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 5.719788995358954 | validation: 5.008377917130728]
	TIME [epoch: 24.9 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.723950348727591		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 5.723950348727591 | validation: 4.98619177959085]
	TIME [epoch: 24.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718021936522943		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 5.718021936522943 | validation: 4.998508516160075]
	TIME [epoch: 24.9 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.719056121056896		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 5.719056121056896 | validation: 5.009524354502067]
	TIME [epoch: 24.9 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.730539164634847		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 5.730539164634847 | validation: 5.02977311761132]
	TIME [epoch: 24.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.735588098302071		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 5.735588098302071 | validation: 5.03727503306477]
	TIME [epoch: 24.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742159069378291		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 5.742159069378291 | validation: 5.017041379822347]
	TIME [epoch: 24.9 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.728187908082958		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 5.728187908082958 | validation: 5.000091194788797]
	TIME [epoch: 24.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.723731154594936		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 5.723731154594936 | validation: 4.9979474302801234]
	TIME [epoch: 24.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.71883300683429		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 5.71883300683429 | validation: 5.004866199570722]
	TIME [epoch: 24.9 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.719262616408967		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 5.719262616408967 | validation: 5.01575166403366]
	TIME [epoch: 24.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.745912817294454		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 5.745912817294454 | validation: 5.040357649983082]
	TIME [epoch: 24.9 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.737498660016037		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 5.737498660016037 | validation: 5.03711805349428]
	TIME [epoch: 24.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.737695548161042		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 5.737695548161042 | validation: 5.029847765550161]
	TIME [epoch: 25 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.748695998424402		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 5.748695998424402 | validation: 5.105182374407502]
	TIME [epoch: 24.9 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.792131889564853		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 5.792131889564853 | validation: 5.121849592917124]
	TIME [epoch: 24.9 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.780051461211258		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 5.780051461211258 | validation: 5.091266325082203]
	TIME [epoch: 24.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.768097361338225		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 5.768097361338225 | validation: 5.102059040690973]
	TIME [epoch: 24.9 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.753685273617421		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 5.753685273617421 | validation: 5.040455770819188]
	TIME [epoch: 24.9 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.75779878312956		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 5.75779878312956 | validation: 5.045012568852847]
	TIME [epoch: 24.9 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.749599294176192		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 5.749599294176192 | validation: 5.045450794750953]
	TIME [epoch: 25 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7462058254275385		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 5.7462058254275385 | validation: 5.024185541156211]
	TIME [epoch: 24.9 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.746444447105999		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 5.746444447105999 | validation: 5.0394024052795166]
	TIME [epoch: 25 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7486977783408		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 5.7486977783408 | validation: 5.0188510367524115]
	TIME [epoch: 24.9 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.740143932752085		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 5.740143932752085 | validation: 5.025027557406263]
	TIME [epoch: 24.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.732009944839348		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 5.732009944839348 | validation: 5.018361230207429]
	TIME [epoch: 24.9 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.734390579221349		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 5.734390579221349 | validation: 5.022366052245921]
	TIME [epoch: 24.9 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.734969717244009		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 5.734969717244009 | validation: 5.024164534389551]
	TIME [epoch: 24.9 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7307921043981525		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 5.7307921043981525 | validation: 5.023547550100574]
	TIME [epoch: 24.9 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.73652868022796		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 5.73652868022796 | validation: 5.023525285955016]
	TIME [epoch: 24.9 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.741215161225595		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 5.741215161225595 | validation: 5.024562551544318]
	TIME [epoch: 24.9 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7462028063503885		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 5.7462028063503885 | validation: 5.0277842819605345]
	TIME [epoch: 25 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7545937367524465		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 5.7545937367524465 | validation: 5.015277812238055]
	TIME [epoch: 24.9 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.735694383783369		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 5.735694383783369 | validation: 5.011878686272476]
	TIME [epoch: 24.9 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.731225097805087		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 5.731225097805087 | validation: 4.995717785597735]
	TIME [epoch: 24.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.735671917412395		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 5.735671917412395 | validation: 5.029458347601853]
	TIME [epoch: 25 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.76649958530648		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 5.76649958530648 | validation: 5.027580307629354]
	TIME [epoch: 24.9 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.741875207548621		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 5.741875207548621 | validation: 5.014958370611852]
	TIME [epoch: 24.9 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.728115470630004		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 5.728115470630004 | validation: 5.03216426843848]
	TIME [epoch: 24.9 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.730025377798599		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 5.730025377798599 | validation: 4.996373839602269]
	TIME [epoch: 24.9 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7312238965493005		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 5.7312238965493005 | validation: 5.006395539874915]
	TIME [epoch: 25 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.728459131034201		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 5.728459131034201 | validation: 5.0124156372854864]
	TIME [epoch: 25 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.72623265053988		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 5.72623265053988 | validation: 5.020721543653255]
	TIME [epoch: 24.9 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.731836363210209		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 5.731836363210209 | validation: 5.0213793610688455]
	TIME [epoch: 25 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.752949342861889		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 5.752949342861889 | validation: 5.031678399422786]
	TIME [epoch: 25 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.737765891128822		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 5.737765891128822 | validation: 5.022838312064957]
	TIME [epoch: 24.9 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.721060095570532		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 5.721060095570532 | validation: 5.016657169965057]
	TIME [epoch: 24.9 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.728437482154889		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 5.728437482154889 | validation: 5.0016886936776395]
	TIME [epoch: 25 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.724854943469894		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 5.724854943469894 | validation: 5.010609708524235]
	TIME [epoch: 24.9 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.72744399249176		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 5.72744399249176 | validation: 5.012695855311518]
	TIME [epoch: 25 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.731077704714295		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 5.731077704714295 | validation: 5.008419373920252]
	TIME [epoch: 25 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.728542792369504		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 5.728542792369504 | validation: 4.998179395705708]
	TIME [epoch: 24.9 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.724937546152599		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 5.724937546152599 | validation: 5.003734285743321]
	TIME [epoch: 25 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.72876597748263		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 5.72876597748263 | validation: 5.012555572452781]
	TIME [epoch: 25 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.728303751665717		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 5.728303751665717 | validation: 5.0097665247948555]
	TIME [epoch: 24.9 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.733185930353818		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 5.733185930353818 | validation: 5.0176246216587]
	TIME [epoch: 25 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.751388235680375		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 5.751388235680375 | validation: 5.069653203421299]
	TIME [epoch: 25 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.780425660175873		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 5.780425660175873 | validation: 5.075809724990317]
	TIME [epoch: 24.9 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.747376588211124		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 5.747376588211124 | validation: 5.008506456633106]
	TIME [epoch: 25 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.731650547952842		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 5.731650547952842 | validation: 5.011046514322659]
	TIME [epoch: 25 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.730813427731537		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 5.730813427731537 | validation: 5.019664558452]
	TIME [epoch: 24.9 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.74137515772832		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 5.74137515772832 | validation: 5.064780467362526]
	TIME [epoch: 25 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.746156389453281		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 5.746156389453281 | validation: 5.016798920155447]
	TIME [epoch: 25 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.743784425004929		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 5.743784425004929 | validation: 5.025685168030412]
	TIME [epoch: 24.9 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742153569272232		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 5.742153569272232 | validation: 5.027871250091648]
	TIME [epoch: 25 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.740071407895521		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 5.740071407895521 | validation: 5.07532323825478]
	TIME [epoch: 25 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7452895270457915		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 5.7452895270457915 | validation: 5.022192502236652]
	TIME [epoch: 24.9 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.741686545927208		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 5.741686545927208 | validation: 5.020388612716129]
	TIME [epoch: 24.9 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.735558551358849		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 5.735558551358849 | validation: 5.027671933505828]
	TIME [epoch: 24.9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.740617018987454		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 5.740617018987454 | validation: 5.025441568937152]
	TIME [epoch: 24.9 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.735344955926615		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 5.735344955926615 | validation: 5.029600747193837]
	TIME [epoch: 24.9 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.749913178533939		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 5.749913178533939 | validation: 5.070332191799225]
	TIME [epoch: 25 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.745552838262831		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 5.745552838262831 | validation: 5.073125088840624]
	TIME [epoch: 24.9 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.758543109243495		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 5.758543109243495 | validation: 5.098927952703631]
	TIME [epoch: 24.9 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.795747015094221		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 5.795747015094221 | validation: 5.0963963825810925]
	TIME [epoch: 25 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.782116506707422		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 5.782116506707422 | validation: 5.067850246106618]
	TIME [epoch: 24.9 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.805089687564557		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 5.805089687564557 | validation: 5.128987439942546]
	TIME [epoch: 25 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.818599287102082		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 5.818599287102082 | validation: 5.12526311546001]
	TIME [epoch: 24.9 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8265152056005896		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 5.8265152056005896 | validation: 5.15886039892573]
	TIME [epoch: 24.9 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.825836950455978		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 5.825836950455978 | validation: 5.13880519926203]
	TIME [epoch: 24.9 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.804926855741611		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 5.804926855741611 | validation: 5.1266396073733596]
	TIME [epoch: 24.9 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.780319814177229		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 5.780319814177229 | validation: 5.081736468105429]
	TIME [epoch: 24.8 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.776852128531084		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 5.776852128531084 | validation: 5.059799961385318]
	TIME [epoch: 24.9 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.788890810115428		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 5.788890810115428 | validation: 5.104741794909193]
	TIME [epoch: 25 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.818852208998672		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 5.818852208998672 | validation: 5.118036558063296]
	TIME [epoch: 24.9 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.821288212106152		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 5.821288212106152 | validation: 5.139069373032479]
	TIME [epoch: 25 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.825057554164601		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 5.825057554164601 | validation: 5.159686227397436]
	TIME [epoch: 25 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.84524628949883		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 5.84524628949883 | validation: 5.163667093233742]
	TIME [epoch: 24.9 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.824896625002613		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 5.824896625002613 | validation: 5.121421080233736]
	TIME [epoch: 25 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.792267535385122		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 5.792267535385122 | validation: 5.110928746958973]
	TIME [epoch: 25 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.831144498472849		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 5.831144498472849 | validation: 5.122405029885924]
	TIME [epoch: 24.9 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.84030298860916		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 5.84030298860916 | validation: 5.1671734158577864]
	TIME [epoch: 24.9 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.835741297863386		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 5.835741297863386 | validation: 5.138685002116558]
	TIME [epoch: 24.9 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.836834850256116		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 5.836834850256116 | validation: 5.153654468476318]
	TIME [epoch: 24.9 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.829311974710352		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 5.829311974710352 | validation: 5.162546680252557]
	TIME [epoch: 24.9 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7906996044992285		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 5.7906996044992285 | validation: 5.148596332325236]
	TIME [epoch: 24.9 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.801371945318226		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 5.801371945318226 | validation: 5.130819466572046]
	TIME [epoch: 24.9 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.790584309168484		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 5.790584309168484 | validation: 5.106442772948875]
	TIME [epoch: 24.9 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.784168532871233		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 5.784168532871233 | validation: 5.096704712028298]
	TIME [epoch: 24.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.760875014677375		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 5.760875014677375 | validation: 5.12649049021791]
	TIME [epoch: 24.9 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.770991612070907		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 5.770991612070907 | validation: 5.0319604462718726]
	TIME [epoch: 24.9 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.761814137641525		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 5.761814137641525 | validation: 5.097341360511159]
	TIME [epoch: 25 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.784003671238859		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 5.784003671238859 | validation: 5.103317640024131]
	TIME [epoch: 24.9 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.785596899733993		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 5.785596899733993 | validation: 5.101507960481232]
	TIME [epoch: 24.9 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.774444595863748		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 5.774444595863748 | validation: 5.0776349647970465]
	TIME [epoch: 24.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7612429222224995		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 5.7612429222224995 | validation: 5.065671804517053]
	TIME [epoch: 24.9 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7513896072043265		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 5.7513896072043265 | validation: 5.044021215899573]
	TIME [epoch: 24.9 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.749245073493293		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 5.749245073493293 | validation: 5.02931012615388]
	TIME [epoch: 24.9 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.753036451054412		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 5.753036451054412 | validation: 5.06750218962822]
	TIME [epoch: 24.9 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.752476425036927		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 5.752476425036927 | validation: 5.028227017862694]
	TIME [epoch: 25 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.748456678537387		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 5.748456678537387 | validation: 5.050060648488331]
	TIME [epoch: 25 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.746056929248344		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 5.746056929248344 | validation: 5.029450929719224]
	TIME [epoch: 24.9 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.747394600099053		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 5.747394600099053 | validation: 5.0215324112405835]
	TIME [epoch: 24.9 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7429240318316435		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 5.7429240318316435 | validation: 5.019222487215439]
	TIME [epoch: 24.9 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.741914967986296		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 5.741914967986296 | validation: 5.056852230571299]
	TIME [epoch: 24.9 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.745047359574389		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 5.745047359574389 | validation: 5.067661550170547]
	TIME [epoch: 24.9 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.737979575964289		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 5.737979575964289 | validation: 5.022732586342053]
	TIME [epoch: 24.9 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742186633233498		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 5.742186633233498 | validation: 5.062495437779457]
	TIME [epoch: 24.9 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.741505640394704		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 5.741505640394704 | validation: 5.063458969803382]
	TIME [epoch: 24.9 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.73882013636166		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 5.73882013636166 | validation: 5.011480034632411]
	TIME [epoch: 24.9 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.737365510786068		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 5.737365510786068 | validation: 5.06402957718224]
	TIME [epoch: 24.8 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7419727793517		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 5.7419727793517 | validation: 5.071598348782989]
	TIME [epoch: 24.9 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.734830235040286		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 5.734830235040286 | validation: 5.026876813246625]
	TIME [epoch: 24.9 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.732963345127007		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 5.732963345127007 | validation: 5.092886412208166]
	TIME [epoch: 24.9 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.744784973694786		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 5.744784973694786 | validation: 5.0797762836832145]
	TIME [epoch: 24.9 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.747097538348535		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 5.747097538348535 | validation: 5.033311383930375]
	TIME [epoch: 24.9 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.752413530659394		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 5.752413530659394 | validation: 5.056944663120342]
	TIME [epoch: 24.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.743755277853124		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 5.743755277853124 | validation: 5.069549389572006]
	TIME [epoch: 24.9 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.751178223125309		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 5.751178223125309 | validation: 5.071412941095931]
	TIME [epoch: 24.9 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.743871236095258		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 5.743871236095258 | validation: 5.017922414648133]
	TIME [epoch: 24.9 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.744207831935867		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 5.744207831935867 | validation: 5.060740565865775]
	TIME [epoch: 24.9 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.748697773926634		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 5.748697773926634 | validation: 5.063255279144587]
	TIME [epoch: 24.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.741551866162183		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 5.741551866162183 | validation: 5.0707606842753945]
	TIME [epoch: 24.9 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.749082520075612		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 5.749082520075612 | validation: 5.068495114032162]
	TIME [epoch: 24.9 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.745982953910929		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 5.745982953910929 | validation: 5.100884020390066]
	TIME [epoch: 24.9 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.759476236196771		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 5.759476236196771 | validation: 5.086942742644061]
	TIME [epoch: 24.9 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.763663581136546		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 5.763663581136546 | validation: 5.111023014054267]
	TIME [epoch: 24.9 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.779023787179799		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 5.779023787179799 | validation: 5.076301238870587]
	TIME [epoch: 24.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.757904605001489		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 5.757904605001489 | validation: 5.097890401497983]
	TIME [epoch: 24.9 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7541499933724145		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 5.7541499933724145 | validation: 5.084707570342967]
	TIME [epoch: 24.9 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.795363239972864		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 5.795363239972864 | validation: 5.122313100159651]
	TIME [epoch: 24.9 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.787236609461902		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 5.787236609461902 | validation: 5.133842083194124]
	TIME [epoch: 24.9 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.796631712627292		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 5.796631712627292 | validation: 5.133469513526624]
	TIME [epoch: 24.9 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.812649065906833		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 5.812649065906833 | validation: 5.104126792183617]
	TIME [epoch: 24.9 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.800215208998499		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 5.800215208998499 | validation: 5.110597248906742]
	TIME [epoch: 24.9 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.764260813712507		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 5.764260813712507 | validation: 5.075131842681673]
	TIME [epoch: 24.9 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.753857558503126		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 5.753857558503126 | validation: 5.112507818265299]
	TIME [epoch: 24.9 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.765049131543799		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 5.765049131543799 | validation: 5.080771887098863]
	TIME [epoch: 24.9 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.755191904833549		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 5.755191904833549 | validation: 5.081020005161135]
	TIME [epoch: 25 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.758303485452736		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 5.758303485452736 | validation: 5.1041995047689115]
	TIME [epoch: 25 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.781231061485194		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 5.781231061485194 | validation: 5.116844753782252]
	TIME [epoch: 24.9 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.78558421648338		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 5.78558421648338 | validation: 5.137910100986318]
	TIME [epoch: 25 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.795793509618954		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 5.795793509618954 | validation: 5.091904747841154]
	TIME [epoch: 25 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.77528193747106		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 5.77528193747106 | validation: 5.095162962080658]
	TIME [epoch: 24.8 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.754835958744556		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 5.754835958744556 | validation: 5.068295080646285]
	TIME [epoch: 24.9 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.759556223517763		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 5.759556223517763 | validation: 5.0205796604138655]
	TIME [epoch: 24.9 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.769574419198342		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 5.769574419198342 | validation: 5.053844591207945]
	TIME [epoch: 24.9 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.762930042471323		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 5.762930042471323 | validation: 5.069846908813292]
	TIME [epoch: 24.9 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742939695151331		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 5.742939695151331 | validation: 5.032656034095954]
	TIME [epoch: 25 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742380934015415		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 5.742380934015415 | validation: 5.071278911413748]
	TIME [epoch: 24.9 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.741125795820553		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 5.741125795820553 | validation: 5.06840201035672]
	TIME [epoch: 25 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.752750009633297		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 5.752750009633297 | validation: 5.029584356919509]
	TIME [epoch: 25 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.757932655685336		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 5.757932655685336 | validation: 5.0395141622762125]
	TIME [epoch: 24.9 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.751317578102421		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 5.751317578102421 | validation: 5.038182426485811]
	TIME [epoch: 24.9 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.753687571014058		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 5.753687571014058 | validation: 5.033410643687603]
	TIME [epoch: 24.9 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.76002269209792		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 5.76002269209792 | validation: 5.023852482699125]
	TIME [epoch: 24.9 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7532516566522		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 5.7532516566522 | validation: 5.028249256670278]
	TIME [epoch: 24.9 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.752575811774601		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 5.752575811774601 | validation: 5.03576808022214]
	TIME [epoch: 24.9 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.757473571300108		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 5.757473571300108 | validation: 5.068978528375982]
	TIME [epoch: 24.9 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742159984779554		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 5.742159984779554 | validation: 5.020020385615989]
	TIME [epoch: 24.9 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7481856371755455		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 5.7481856371755455 | validation: 5.03510371405744]
	TIME [epoch: 24.9 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.760237978091145		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 5.760237978091145 | validation: 5.035268314204048]
	TIME [epoch: 24.9 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.755460113892988		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 5.755460113892988 | validation: 5.029954914715643]
	TIME [epoch: 24.9 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.750704965575231		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 5.750704965575231 | validation: 5.0217544519687625]
	TIME [epoch: 25 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.747695953114892		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 5.747695953114892 | validation: 5.01924242446]
	TIME [epoch: 24.9 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.736052719105627		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 5.736052719105627 | validation: 5.018179069785041]
	TIME [epoch: 25 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7412268354024025		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 5.7412268354024025 | validation: 5.01782749176306]
	TIME [epoch: 25 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.749104105692936		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 5.749104105692936 | validation: 5.036247503158291]
	TIME [epoch: 25 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.758743898610752		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 5.758743898610752 | validation: 5.0417718095929]
	TIME [epoch: 24.9 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7582367136691985		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 5.7582367136691985 | validation: 5.034481943136275]
	TIME [epoch: 25 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.743209893198251		[learning rate: 0.00011822]
