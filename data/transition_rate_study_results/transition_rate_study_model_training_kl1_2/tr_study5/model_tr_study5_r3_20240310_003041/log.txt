Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r3', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4055955526

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.404777664407373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.404777664407373 | validation: 11.1255086465891]
	TIME [epoch: 106 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.254028475635671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.254028475635671 | validation: 11.118636861619848]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.173026892092478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.173026892092478 | validation: 10.590021667997599]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.88174442922798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.88174442922798 | validation: 10.43102825942838]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.381026754075807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.381026754075807 | validation: 9.344245058940727]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.02465390489289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.02465390489289 | validation: 8.180541904143972]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.723613226413081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.723613226413081 | validation: 7.643646751458235]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.413979793965183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.413979793965183 | validation: 7.5484881190970485]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.22415660772859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.22415660772859 | validation: 7.449160519561124]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9951325966572355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9951325966572355 | validation: 7.405503610906783]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.261000951357031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.261000951357031 | validation: 7.128873284354634]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.797791265029549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.797791265029549 | validation: 6.905624129076592]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.561303301351012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.561303301351012 | validation: 6.532914384015828]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.331213814475781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.331213814475781 | validation: 6.384126839893959]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.322999026428728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.322999026428728 | validation: 6.333911362472046]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.21457955162542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.21457955162542 | validation: 6.253165870798678]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.075814714590181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.075814714590181 | validation: 6.260337479338667]
	TIME [epoch: 27.7 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.10956314011314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.10956314011314 | validation: 6.114478688208444]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.121129460961737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.121129460961737 | validation: 5.943642213774435]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.954287243886526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.954287243886526 | validation: 6.003121524541824]
	TIME [epoch: 27.8 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.096308538468417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.096308538468417 | validation: 5.947157766098216]
	TIME [epoch: 27.8 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.039111260294661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.039111260294661 | validation: 6.1130386680490805]
	TIME [epoch: 27.7 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0517315159090135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0517315159090135 | validation: 5.8437392352792]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8883996995726005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8883996995726005 | validation: 6.29819657528913]
	TIME [epoch: 27.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.132058915016133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.132058915016133 | validation: 6.006272298713391]
	TIME [epoch: 27.7 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.024825367253317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.024825367253317 | validation: 6.074258190917292]
	TIME [epoch: 27.8 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.456161228072319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.456161228072319 | validation: 5.880719478087685]
	TIME [epoch: 27.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.859436480549558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.859436480549558 | validation: 5.872911600269437]
	TIME [epoch: 27.7 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.811806420343915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.811806420343915 | validation: 6.577020111582974]
	TIME [epoch: 27.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.207142565913288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.207142565913288 | validation: 5.722785700279185]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.803854474542833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.803854474542833 | validation: 6.010958781965602]
	TIME [epoch: 27.7 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.966594471432655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.966594471432655 | validation: 5.732776414975348]
	TIME [epoch: 27.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.754358892001765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.754358892001765 | validation: 5.821270739501629]
	TIME [epoch: 27.8 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.807060818710169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.807060818710169 | validation: 5.736920275654502]
	TIME [epoch: 27.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.739757486297645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.739757486297645 | validation: 5.652080322048903]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.621464362512077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.621464362512077 | validation: 5.653598305335636]
	TIME [epoch: 27.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.753230331935509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.753230331935509 | validation: 5.643792920012652]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.616798253285188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.616798253285188 | validation: 5.8174728220361205]
	TIME [epoch: 27.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.656678065673193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.656678065673193 | validation: 5.732342067359523]
	TIME [epoch: 27.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.810590856207067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.810590856207067 | validation: 5.5341050631689965]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.493290796870747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.493290796870747 | validation: 5.475971993415427]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.486311123086175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.486311123086175 | validation: 6.3923792800141905]
	TIME [epoch: 27.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.233936989976707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.233936989976707 | validation: 6.035734445584897]
	TIME [epoch: 27.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.077997464043847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.077997464043847 | validation: 7.3778347229068775]
	TIME [epoch: 27.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.989816358120068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.989816358120068 | validation: 5.801601701677657]
	TIME [epoch: 27.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.785079831371314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.785079831371314 | validation: 5.718489624253034]
	TIME [epoch: 27.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.719490603416846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.719490603416846 | validation: 5.5449296815563915]
	TIME [epoch: 27.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.532895618729553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.532895618729553 | validation: 5.5273349318305565]
	TIME [epoch: 27.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.420626479229513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.420626479229513 | validation: 5.369944439523977]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.523842430144909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.523842430144909 | validation: 5.5571673022675645]
	TIME [epoch: 27.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.903569370652504		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.903569370652504 | validation: 5.97235079700178]
	TIME [epoch: 27.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.86535443001215		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.86535443001215 | validation: 5.484594349470923]
	TIME [epoch: 27.7 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.944478033026097		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.944478033026097 | validation: 6.493195240028056]
	TIME [epoch: 27.7 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7340857820227855		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.7340857820227855 | validation: 5.5410517851009375]
	TIME [epoch: 27.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4507809055536285		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.4507809055536285 | validation: 5.390488309073471]
	TIME [epoch: 27.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3225902268288525		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.3225902268288525 | validation: 5.203395503320653]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.174309591315314		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 6.174309591315314 | validation: 6.382436912675651]
	TIME [epoch: 27.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.158366250484039		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 6.158366250484039 | validation: 6.752994569596945]
	TIME [epoch: 27.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.479862535310112		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 6.479862535310112 | validation: 5.950976476655317]
	TIME [epoch: 27.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718695571383103		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.718695571383103 | validation: 5.887819431770522]
	TIME [epoch: 27.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.685270738161092		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.685270738161092 | validation: 5.518201486810751]
	TIME [epoch: 27.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.513963339748221		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.513963339748221 | validation: 5.5091168024934545]
	TIME [epoch: 27.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.375526571620182		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 5.375526571620182 | validation: 5.149537450084472]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3358477154741495		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 5.3358477154741495 | validation: 5.723963294273099]
	TIME [epoch: 27.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.666087213005033		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 5.666087213005033 | validation: 5.8274304666556445]
	TIME [epoch: 27.8 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.668045195164953		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.668045195164953 | validation: 5.325243814394496]
	TIME [epoch: 27.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.630286934373904		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 5.630286934373904 | validation: 6.1787230701040174]
	TIME [epoch: 27.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.647890880060933		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 5.647890880060933 | validation: 4.9600735558288624]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.943298270754815		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.943298270754815 | validation: 4.913199905454882]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.184084129677396		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.184084129677396 | validation: 5.206497304227496]
	TIME [epoch: 27.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.061858262846909		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 5.061858262846909 | validation: 5.357101860366488]
	TIME [epoch: 27.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.061300511197598		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 5.061300511197598 | validation: 4.8252732035155494]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.736067775657545		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.736067775657545 | validation: 4.9156134024641425]
	TIME [epoch: 27.8 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.871509221380341		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 6.871509221380341 | validation: 5.716070522980077]
	TIME [epoch: 27.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.278407745451397		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 5.278407745451397 | validation: 4.763963791435745]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.25466668526445		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 5.25466668526445 | validation: 6.753693606018429]
	TIME [epoch: 27.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.734227091403316		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 6.734227091403316 | validation: 5.843270346726122]
	TIME [epoch: 27.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.460148481291741		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 5.460148481291741 | validation: 5.253263943116571]
	TIME [epoch: 27.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.012010410495275		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 5.012010410495275 | validation: 5.323161796989358]
	TIME [epoch: 27.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.683322153283282		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 8.683322153283282 | validation: 9.163472883280642]
	TIME [epoch: 27.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.586441321254916		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 6.586441321254916 | validation: 5.07799411376745]
	TIME [epoch: 27.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.965170788144467		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.965170788144467 | validation: 5.812577510594795]
	TIME [epoch: 27.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.727105594658456		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 5.727105594658456 | validation: 5.007730360355293]
	TIME [epoch: 27.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.99531067658958		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.99531067658958 | validation: 5.552264638561646]
	TIME [epoch: 27.7 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.146454314660196		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 5.146454314660196 | validation: 5.551388402170241]
	TIME [epoch: 27.7 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.582068805458124		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 5.582068805458124 | validation: 5.361165420566757]
	TIME [epoch: 27.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.222392513335997		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 5.222392513335997 | validation: 4.884441668800149]
	TIME [epoch: 27.7 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.682025781649919		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 4.682025781649919 | validation: 4.631163635525515]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.046615379923557		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 5.046615379923557 | validation: 4.618529369422075]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.620347928778478		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.620347928778478 | validation: 5.1384905753148065]
	TIME [epoch: 27.7 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.839889288677245		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.839889288677245 | validation: 4.8467411933517495]
	TIME [epoch: 27.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.945844370550083		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 4.945844370550083 | validation: 4.4776624401347345]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.566945690397623		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.566945690397623 | validation: 4.449511343653967]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.588442772164961		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.588442772164961 | validation: 4.965108887774412]
	TIME [epoch: 27.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.780321721384629		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.780321721384629 | validation: 4.756007608510211]
	TIME [epoch: 27.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5541354451753975		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.5541354451753975 | validation: 4.230153771532742]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.264374830068004		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 4.264374830068004 | validation: 4.062772595366111]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.243940209077127		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 4.243940209077127 | validation: 4.019976837953797]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.950168594300443		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.950168594300443 | validation: 3.9205725935937936]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.136481556894536		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 4.136481556894536 | validation: 3.61538313176178]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.132745516546189		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 4.132745516546189 | validation: 3.6536058807871012]
	TIME [epoch: 27.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.983335351976695		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.983335351976695 | validation: 3.981141529351292]
	TIME [epoch: 27.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.805212663661117		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.805212663661117 | validation: 3.622766943623891]
	TIME [epoch: 27.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.011760860934372		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.011760860934372 | validation: 4.830585922225397]
	TIME [epoch: 27.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.13435109744287		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 4.13435109744287 | validation: 4.65108572748514]
	TIME [epoch: 27.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.104531977936138		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 4.104531977936138 | validation: 3.6338773113751563]
	TIME [epoch: 27.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.624487838912384		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.624487838912384 | validation: 3.609717809152592]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5491071028021377		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.5491071028021377 | validation: 5.412382769774304]
	TIME [epoch: 27.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.703672631805331		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.703672631805331 | validation: 3.2284908189712156]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.285715462855201		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.285715462855201 | validation: 3.017028475149054]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.069771167812445		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.069771167812445 | validation: 3.190659100813551]
	TIME [epoch: 27.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.384809111152281		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.384809111152281 | validation: 3.2372473231505636]
	TIME [epoch: 27.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.084588307078712		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.084588307078712 | validation: 2.945030575232979]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8785634732299155		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.8785634732299155 | validation: 2.767709678683587]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1327942457757105		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.1327942457757105 | validation: 2.7425376636958485]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.679550365779835		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.679550365779835 | validation: 2.830877605302088]
	TIME [epoch: 27.7 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6388858030231694		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.6388858030231694 | validation: 2.5804720284894427]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7059033918713946		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.7059033918713946 | validation: 3.1597263265991344]
	TIME [epoch: 27.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0343129265794024		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.0343129265794024 | validation: 2.5047634770016565]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5598381246735245		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.5598381246735245 | validation: 2.868989949003561]
	TIME [epoch: 27.7 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.725481466771566		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.725481466771566 | validation: 2.5559126900945084]
	TIME [epoch: 27.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.744858916372479		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.744858916372479 | validation: 2.9406929748656068]
	TIME [epoch: 27.7 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8655091641132975		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.8655091641132975 | validation: 2.5053987646083433]
	TIME [epoch: 27.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4302003753555645		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.4302003753555645 | validation: 2.4717910685249858]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9048720475407803		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.9048720475407803 | validation: 2.4058993746629374]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6009723231645427		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.6009723231645427 | validation: 2.386504278394174]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3828485748300827		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.3828485748300827 | validation: 2.032187246770054]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1130231772144694		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.1130231772144694 | validation: 3.350654455725695]
	TIME [epoch: 27.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358364443396123		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.358364443396123 | validation: 2.397311749374356]
	TIME [epoch: 27.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6573596623798923		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.6573596623798923 | validation: 2.8301238139393274]
	TIME [epoch: 27.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2450463589490575		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.2450463589490575 | validation: 2.9488140404512695]
	TIME [epoch: 27.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.743926275864412		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.743926275864412 | validation: 3.0645478095538365]
	TIME [epoch: 27.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8935325608981075		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.8935325608981075 | validation: 2.420802418069829]
	TIME [epoch: 27.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7405564459666385		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.7405564459666385 | validation: 2.6201091929600517]
	TIME [epoch: 27.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.490010093534176		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.490010093534176 | validation: 2.584397432599132]
	TIME [epoch: 27.7 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3528031400676275		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.3528031400676275 | validation: 2.6977555083790983]
	TIME [epoch: 27.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2174297454984377		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.2174297454984377 | validation: 2.1861232353230746]
	TIME [epoch: 27.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.580574188470958		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.580574188470958 | validation: 2.59562878389764]
	TIME [epoch: 27.7 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.361621322365543		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.361621322365543 | validation: 2.6853781142207898]
	TIME [epoch: 27.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257407579967226		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.257407579967226 | validation: 2.0482469261474656]
	TIME [epoch: 27.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.184953346517205		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.184953346517205 | validation: 1.9220817255659102]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.146672083905785		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.146672083905785 | validation: 4.2762073504824185]
	TIME [epoch: 27.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5783968689892505		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.5783968689892505 | validation: 2.484001919256881]
	TIME [epoch: 27.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268140584952599		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.268140584952599 | validation: 2.5639775796925863]
	TIME [epoch: 27.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.555941141380676		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.555941141380676 | validation: 2.289015862845515]
	TIME [epoch: 27.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1277635188015998		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.1277635188015998 | validation: 2.205863622532934]
	TIME [epoch: 27.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6924070647699274		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.6924070647699274 | validation: 2.7663406700099107]
	TIME [epoch: 27.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294087898516459		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 2.294087898516459 | validation: 3.2246882088151096]
	TIME [epoch: 27.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3742368454755978		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.3742368454755978 | validation: 2.1293017114813813]
	TIME [epoch: 27.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8470386367194833		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.8470386367194833 | validation: 2.741025738861196]
	TIME [epoch: 27.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251277610872615		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.251277610872615 | validation: 2.444464698705935]
	TIME [epoch: 27.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.357916866620764		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.357916866620764 | validation: 2.0426045692109343]
	TIME [epoch: 27.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0175976451370206		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.0175976451370206 | validation: 1.8122111098861131]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0327602187774216		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.0327602187774216 | validation: 2.1533579715609092]
	TIME [epoch: 27.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0398261001035443		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.0398261001035443 | validation: 1.7081372593715138]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9013557332907227		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.9013557332907227 | validation: 2.4655812841676954]
	TIME [epoch: 27.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0849259584730677		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.0849259584730677 | validation: 2.6946887861999675]
	TIME [epoch: 27.7 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.128799016035004		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.128799016035004 | validation: 2.1824223605760995]
	TIME [epoch: 27.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.204022970808704		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.204022970808704 | validation: 1.7854430362676295]
	TIME [epoch: 27.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.218504983894738		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.218504983894738 | validation: 1.7752593951380642]
	TIME [epoch: 27.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8669123922577353		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.8669123922577353 | validation: 2.3438949733807166]
	TIME [epoch: 27.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1180749890998585		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.1180749890998585 | validation: 2.560779880439115]
	TIME [epoch: 27.7 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.090203958297297		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.090203958297297 | validation: 1.8270052870606046]
	TIME [epoch: 27.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1134547588399157		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.1134547588399157 | validation: 1.9429735800204126]
	TIME [epoch: 27.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.021527960973046		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.021527960973046 | validation: 1.626975789778529]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2458542987530454		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.2458542987530454 | validation: 2.4909838125456747]
	TIME [epoch: 27.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0677907700297897		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.0677907700297897 | validation: 1.7662229432085377]
	TIME [epoch: 27.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.884760489144476		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.884760489144476 | validation: 2.0260797885824315]
	TIME [epoch: 27.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2120356477545364		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.2120356477545364 | validation: 3.2843751727691335]
	TIME [epoch: 27.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2076626307250296		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.2076626307250296 | validation: 2.088784393358445]
	TIME [epoch: 27.7 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2667965794130445		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.2667965794130445 | validation: 2.3690777974606823]
	TIME [epoch: 27.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0202043683313815		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.0202043683313815 | validation: 1.6448516151962513]
	TIME [epoch: 27.7 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.915265516886621		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.915265516886621 | validation: 1.9184221164131436]
	TIME [epoch: 27.7 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.965044622174993		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.965044622174993 | validation: 1.8467384567827023]
	TIME [epoch: 27.7 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.821109060913566		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 4.821109060913566 | validation: 4.247870159820638]
	TIME [epoch: 27.7 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0575656769150457		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 3.0575656769150457 | validation: 2.4804074429067318]
	TIME [epoch: 27.7 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.368313367739038		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.368313367739038 | validation: 1.7501653820078198]
	TIME [epoch: 27.7 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2908967072633155		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.2908967072633155 | validation: 2.3634212060993467]
	TIME [epoch: 27.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.09079838538666		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.09079838538666 | validation: 2.199265122600653]
	TIME [epoch: 27.7 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.624272755376041		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.624272755376041 | validation: 1.705607471564532]
	TIME [epoch: 27.7 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9520697022365856		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.9520697022365856 | validation: 1.9365085248844032]
	TIME [epoch: 27.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1894021352157966		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.1894021352157966 | validation: 1.8830280319714001]
	TIME [epoch: 27.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9594220576839245		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.9594220576839245 | validation: 1.7951593943044821]
	TIME [epoch: 27.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278430614436905		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.278430614436905 | validation: 1.9974866741308541]
	TIME [epoch: 27.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1865406197386554		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.1865406197386554 | validation: 2.6363924173735085]
	TIME [epoch: 27.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0413100968549664		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.0413100968549664 | validation: 3.0919702047831352]
	TIME [epoch: 27.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9283068934182532		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.9283068934182532 | validation: 2.196028734727979]
	TIME [epoch: 27.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.930280639659443		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.930280639659443 | validation: 1.5915813504951581]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.047863968582411		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.047863968582411 | validation: 1.6044213366133455]
	TIME [epoch: 27.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.006820485342615		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 2.006820485342615 | validation: 1.8997378872724868]
	TIME [epoch: 27.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4084200242843044		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.4084200242843044 | validation: 2.952634517347235]
	TIME [epoch: 27.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9818760302505811		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.9818760302505811 | validation: 1.7509534700873366]
	TIME [epoch: 27.7 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6755197515833657		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.6755197515833657 | validation: 3.70479420748023]
	TIME [epoch: 27.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9145489168131005		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.9145489168131005 | validation: 2.571970028245494]
	TIME [epoch: 27.7 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2417858670384185		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.2417858670384185 | validation: 3.279127953884498]
	TIME [epoch: 27.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.636664958721899		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.636664958721899 | validation: 2.1177299359474113]
	TIME [epoch: 27.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9515724507230274		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.9515724507230274 | validation: 1.7565144748362047]
	TIME [epoch: 27.7 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.691448229936506		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.691448229936506 | validation: 1.898946443963209]
	TIME [epoch: 27.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7144770551842319		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.7144770551842319 | validation: 1.9559129198092935]
	TIME [epoch: 27.8 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8903382150311394		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.8903382150311394 | validation: 2.5675231002849257]
	TIME [epoch: 27.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.598092401858038		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.598092401858038 | validation: 2.0717837900350786]
	TIME [epoch: 27.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.738120224181697		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.738120224181697 | validation: 1.4118568885945735]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7394505791911816		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.7394505791911816 | validation: 2.053221896267334]
	TIME [epoch: 27.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.883056417407847		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.883056417407847 | validation: 2.5710464802504136]
	TIME [epoch: 27.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.618009983519337		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.618009983519337 | validation: 2.251583789805215]
	TIME [epoch: 27.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7928028997989995		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.7928028997989995 | validation: 1.6455040138767865]
	TIME [epoch: 27.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9893522410905455		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.9893522410905455 | validation: 1.8709720339808196]
	TIME [epoch: 27.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9386386833619		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.9386386833619 | validation: 2.098739992998429]
	TIME [epoch: 27.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0823789271203617		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.0823789271203617 | validation: 1.8154157802246207]
	TIME [epoch: 27.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.592574279274407		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.592574279274407 | validation: 2.1361704527400467]
	TIME [epoch: 27.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8486784995397105		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.8486784995397105 | validation: 1.647194037807596]
	TIME [epoch: 27.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7251679480363433		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.7251679480363433 | validation: 1.5037992279831645]
	TIME [epoch: 27.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7795364717893296		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.7795364717893296 | validation: 2.4899755742177563]
	TIME [epoch: 27.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0007155803682912		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.0007155803682912 | validation: 1.5310539857218908]
	TIME [epoch: 27.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.657914815796553		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.657914815796553 | validation: 2.68119232078696]
	TIME [epoch: 27.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.47956593174649		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 5.47956593174649 | validation: 3.0259480247408432]
	TIME [epoch: 27.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1448650875492485		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.1448650875492485 | validation: 2.148251176153198]
	TIME [epoch: 27.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.892647678557547		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.892647678557547 | validation: 3.4061933015838752]
	TIME [epoch: 27.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5817773916067877		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.5817773916067877 | validation: 1.6987983943237417]
	TIME [epoch: 27.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8425674721832181		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.8425674721832181 | validation: 1.4968133454318122]
	TIME [epoch: 27.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0723496776104935		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.0723496776104935 | validation: 1.610012128166059]
	TIME [epoch: 27.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6568798727635237		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.6568798727635237 | validation: 1.444802782576831]
	TIME [epoch: 27.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8126325961863365		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.8126325961863365 | validation: 1.7448889076116587]
	TIME [epoch: 27.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8939010189641996		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.8939010189641996 | validation: 1.866530496171492]
	TIME [epoch: 27.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8335550390866633		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.8335550390866633 | validation: 1.2669233025209012]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5387091580442933		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.5387091580442933 | validation: 2.578019682788309]
	TIME [epoch: 27.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3250332584222964		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.3250332584222964 | validation: 2.512321357045152]
	TIME [epoch: 27.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2509311669023506		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.2509311669023506 | validation: 1.6147869931589889]
	TIME [epoch: 27.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.56386423691549		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.56386423691549 | validation: 2.268334767284793]
	TIME [epoch: 27.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064484636472663		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.064484636472663 | validation: 1.7749701150922266]
	TIME [epoch: 27.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9530275906599062		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.9530275906599062 | validation: 1.5721136597258025]
	TIME [epoch: 27.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7271462601848437		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.7271462601848437 | validation: 1.730639360489958]
	TIME [epoch: 27.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5951202730986496		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.5951202730986496 | validation: 1.7044201742995477]
	TIME [epoch: 27.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8545270911706866		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.8545270911706866 | validation: 2.915877130709858]
	TIME [epoch: 27.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.657314672898904		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.657314672898904 | validation: 1.9062408915489217]
	TIME [epoch: 27.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7911980528351865		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.7911980528351865 | validation: 1.5261400970496233]
	TIME [epoch: 27.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7425631693442796		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.7425631693442796 | validation: 2.3413294769444755]
	TIME [epoch: 27.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.932016266690998		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.932016266690998 | validation: 1.9594575444621691]
	TIME [epoch: 27.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0859760747786673		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.0859760747786673 | validation: 2.070691710935796]
	TIME [epoch: 27.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067078027910615		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.067078027910615 | validation: 2.2863321591667587]
	TIME [epoch: 27.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.401907719797613		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.401907719797613 | validation: 1.8732248324100516]
	TIME [epoch: 27.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9824816935897638		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.9824816935897638 | validation: 1.9561514986011008]
	TIME [epoch: 27.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8880926711602972		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.8880926711602972 | validation: 2.4333801303731573]
	TIME [epoch: 27.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8397599550076893		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.8397599550076893 | validation: 2.2311350037102136]
	TIME [epoch: 27.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.833525129560039		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.833525129560039 | validation: 1.910720631824432]
	TIME [epoch: 27.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2061405409930295		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.2061405409930295 | validation: 2.8231125689187326]
	TIME [epoch: 27.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294424564607879		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 2.294424564607879 | validation: 2.35046229798135]
	TIME [epoch: 27.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9259621573956394		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.9259621573956394 | validation: 1.9354589010415242]
	TIME [epoch: 27.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9072439083992125		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.9072439083992125 | validation: 2.6900371420745386]
	TIME [epoch: 27.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7311320938421884		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.7311320938421884 | validation: 1.7950710128169158]
	TIME [epoch: 27.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7803487147038326		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.7803487147038326 | validation: 2.104049715681024]
	TIME [epoch: 27.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8173616968215511		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.8173616968215511 | validation: 1.4944859033296052]
	TIME [epoch: 27.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8483625552670189		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.8483625552670189 | validation: 1.6366104209289112]
	TIME [epoch: 27.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.869927644281731		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.869927644281731 | validation: 1.5547789534470509]
	TIME [epoch: 27.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6203648561083415		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.6203648561083415 | validation: 1.9020666488140823]
	TIME [epoch: 27.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3633126240046574		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.3633126240046574 | validation: 2.5587665588158344]
	TIME [epoch: 27.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0449842633039186		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 3.0449842633039186 | validation: 1.8453688386136031]
	TIME [epoch: 27.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1340190640935		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.1340190640935 | validation: 2.0101372586233626]
	TIME [epoch: 27.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.491971404501907		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.491971404501907 | validation: 2.056430671597303]
	TIME [epoch: 27.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9437287029716064		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.9437287029716064 | validation: 1.8681531693117392]
	TIME [epoch: 27.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9682894275167278		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.9682894275167278 | validation: 1.835172995644275]
	TIME [epoch: 27.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6311635221845937		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.6311635221845937 | validation: 1.986794417577231]
	TIME [epoch: 27.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.030243405737786		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.030243405737786 | validation: 1.4711751361503356]
	TIME [epoch: 27.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5948108604747988		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.5948108604747988 | validation: 1.402928910229704]
	TIME [epoch: 27.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7559469463828095		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.7559469463828095 | validation: 1.8271300190113067]
	TIME [epoch: 27.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9016172872713475		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.9016172872713475 | validation: 1.3749638506541573]
	TIME [epoch: 27.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6583306117288146		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.6583306117288146 | validation: 1.940818689833987]
	TIME [epoch: 27.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.080963794399507		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 2.080963794399507 | validation: 1.5741558153893092]
	TIME [epoch: 27.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8969990567165855		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.8969990567165855 | validation: 1.6346188043262957]
	TIME [epoch: 27.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6907920177850624		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.6907920177850624 | validation: 1.3680057341673728]
	TIME [epoch: 27.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6836207195432689		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.6836207195432689 | validation: 2.1265460630861184]
	TIME [epoch: 27.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5609121612679226		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.5609121612679226 | validation: 1.4256979331223232]
	TIME [epoch: 27.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.718462959214056		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.718462959214056 | validation: 6.612476718811162]
	TIME [epoch: 27.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.505583614902578		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 4.505583614902578 | validation: 1.723857544789089]
	TIME [epoch: 27.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0890425973406797		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.0890425973406797 | validation: 1.9139966363618521]
	TIME [epoch: 27.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7537657063724914		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.7537657063724914 | validation: 1.2834330373011593]
	TIME [epoch: 27.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1888540029875294		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.1888540029875294 | validation: 2.187096010848122]
	TIME [epoch: 27.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7243201817574434		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.7243201817574434 | validation: 1.8563772007808814]
	TIME [epoch: 27.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3206860378959493		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 2.3206860378959493 | validation: 2.4998388039164356]
	TIME [epoch: 27.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3768309547168354		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 2.3768309547168354 | validation: 1.322814438746698]
	TIME [epoch: 27.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.827666839265103		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.827666839265103 | validation: 1.6769135143140543]
	TIME [epoch: 27.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7136237315842249		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.7136237315842249 | validation: 1.5234279012486798]
	TIME [epoch: 27.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5481482515294094		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.5481482515294094 | validation: 1.4169112562409294]
	TIME [epoch: 27.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5417666559946002		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.5417666559946002 | validation: 1.5549438363660113]
	TIME [epoch: 27.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4964435419814308		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.4964435419814308 | validation: 1.7624962962262842]
	TIME [epoch: 27.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6050310299200794		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.6050310299200794 | validation: 1.254683266867192]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8248219905538403		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.8248219905538403 | validation: 1.8666042842208277]
	TIME [epoch: 27.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5503135199166613		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.5503135199166613 | validation: 1.2594036735067107]
	TIME [epoch: 27.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5187358977956409		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.5187358977956409 | validation: 1.7275324769356184]
	TIME [epoch: 27.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6068338089846539		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.6068338089846539 | validation: 1.6317113571470696]
	TIME [epoch: 27.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6227798646940828		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.6227798646940828 | validation: 2.328749227941258]
	TIME [epoch: 27.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9084202861597082		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.9084202861597082 | validation: 2.42672874021058]
	TIME [epoch: 27.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254659675894998		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.254659675894998 | validation: 1.8920173440134176]
	TIME [epoch: 27.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7131885844085213		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.7131885844085213 | validation: 1.9577685041683806]
	TIME [epoch: 27.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6147760466837267		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.6147760466837267 | validation: 1.5924395885553368]
	TIME [epoch: 27.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4663899932812332		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.4663899932812332 | validation: 1.320530175475023]
	TIME [epoch: 27.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4447295115970258		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.4447295115970258 | validation: 1.4985382694099951]
	TIME [epoch: 27.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4420198719016242		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.4420198719016242 | validation: 1.1292083386825937]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_298.pth
	Model improved!!!
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3134551722429855		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.3134551722429855 | validation: 1.717066649189777]
	TIME [epoch: 27.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4130282665906049		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.4130282665906049 | validation: 1.9731911136661475]
	TIME [epoch: 27.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.808907034968954		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.808907034968954 | validation: 1.2148728298537697]
	TIME [epoch: 27.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4922949386432869		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.4922949386432869 | validation: 3.0441113797799666]
	TIME [epoch: 27.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.232062614779727		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 2.232062614779727 | validation: 1.3133149893187785]
	TIME [epoch: 27.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.825131823082326		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.825131823082326 | validation: 1.8953680409973948]
	TIME [epoch: 27.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5976967115981981		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.5976967115981981 | validation: 2.9541184904983733]
	TIME [epoch: 27.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6846605960346963		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 3.6846605960346963 | validation: 2.699320935352331]
	TIME [epoch: 27.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1640447600397446		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 2.1640447600397446 | validation: 1.4600821920389147]
	TIME [epoch: 27.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.436246356389783		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.436246356389783 | validation: 2.455342143464419]
	TIME [epoch: 27.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1089185263843833		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.1089185263843833 | validation: 1.745946975464924]
	TIME [epoch: 27.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7237304793070758		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.7237304793070758 | validation: 1.4191789843568512]
	TIME [epoch: 27.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5301952285347251		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.5301952285347251 | validation: 1.3157198269782677]
	TIME [epoch: 27.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6064882995346494		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.6064882995346494 | validation: 1.4814121483479459]
	TIME [epoch: 27.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5336878120437236		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.5336878120437236 | validation: 1.1956185534575026]
	TIME [epoch: 27.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5689612787433784		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.5689612787433784 | validation: 1.6557567412462753]
	TIME [epoch: 27.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5809876080595826		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.5809876080595826 | validation: 1.733264205701517]
	TIME [epoch: 27.7 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.64482381120808		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.64482381120808 | validation: 1.4539861311364832]
	TIME [epoch: 27.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5905726667417168		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.5905726667417168 | validation: 1.4697390640593235]
	TIME [epoch: 27.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5425650854461253		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.5425650854461253 | validation: 1.5258733911119806]
	TIME [epoch: 27.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5362048027375357		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.5362048027375357 | validation: 1.3201492837008937]
	TIME [epoch: 27.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6128554419180954		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.6128554419180954 | validation: 1.391362443609421]
	TIME [epoch: 27.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.363733840337731		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.363733840337731 | validation: 1.0847868629157755]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5508210585965658		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.5508210585965658 | validation: 1.7408884852225575]
	TIME [epoch: 27.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5945637272476945		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.5945637272476945 | validation: 1.0484609528533628]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5260677494992618		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.5260677494992618 | validation: 1.249353739243369]
	TIME [epoch: 27.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4784334544671076		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.4784334544671076 | validation: 1.1493932107024478]
	TIME [epoch: 27.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1242217600949387		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.1242217600949387 | validation: 1.1152312605141337]
	TIME [epoch: 27.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5597493807861103		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.5597493807861103 | validation: 1.786442599205637]
	TIME [epoch: 27.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3565559270669256		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.3565559270669256 | validation: 1.4055843369818093]
	TIME [epoch: 27.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.35029769155307		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.35029769155307 | validation: 1.3772351767395445]
	TIME [epoch: 27.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4771704791079436		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.4771704791079436 | validation: 1.2606714487694608]
	TIME [epoch: 27.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136523492479541		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.136523492479541 | validation: 1.6343719113004318]
	TIME [epoch: 27.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06063390528553		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 2.06063390528553 | validation: 1.2505180637293276]
	TIME [epoch: 27.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9215582520722863		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.9215582520722863 | validation: 1.616340153895037]
	TIME [epoch: 27.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.394144539204786		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.394144539204786 | validation: 2.0704234875817673]
	TIME [epoch: 27.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.422550794422373		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.422550794422373 | validation: 1.0786309017353213]
	TIME [epoch: 27.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3499034344138623		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.3499034344138623 | validation: 1.5562575165557808]
	TIME [epoch: 27.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1823912655370976		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 2.1823912655370976 | validation: 2.177447984182342]
	TIME [epoch: 27.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9687164025781554		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.9687164025781554 | validation: 1.6276124991746852]
	TIME [epoch: 27.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.660679497522939		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.660679497522939 | validation: 1.8785802989974965]
	TIME [epoch: 27.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6924536432295672		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.6924536432295672 | validation: 1.1294158212060477]
	TIME [epoch: 27.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.419411375528043		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.419411375528043 | validation: 1.0575094383375983]
	TIME [epoch: 27.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.327395794569561		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.327395794569561 | validation: 1.8347965135746755]
	TIME [epoch: 27.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5178304234804167		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.5178304234804167 | validation: 2.609175639276332]
	TIME [epoch: 27.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9436723250895998		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.9436723250895998 | validation: 2.6358940325274065]
	TIME [epoch: 27.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8152799679651095		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.8152799679651095 | validation: 1.772987537889561]
	TIME [epoch: 27.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3561809938718414		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.3561809938718414 | validation: 1.0996026774830705]
	TIME [epoch: 27.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5493824923818966		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.5493824923818966 | validation: 1.1743145745628334]
	TIME [epoch: 27.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6798040932045162		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.6798040932045162 | validation: 1.768392736629263]
	TIME [epoch: 27.7 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7022892452392415		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.7022892452392415 | validation: 1.4926501276619915]
	TIME [epoch: 27.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3311059796777087		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.3311059796777087 | validation: 0.9613171013046813]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7018399851211747		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.7018399851211747 | validation: 2.222319865943718]
	TIME [epoch: 27.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2784647434098755		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 2.2784647434098755 | validation: 1.188848940456027]
	TIME [epoch: 27.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3814747293179035		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.3814747293179035 | validation: 1.3930155779457167]
	TIME [epoch: 27.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4527413077246758		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.4527413077246758 | validation: 1.1807297344736367]
	TIME [epoch: 27.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7176370281046305		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.7176370281046305 | validation: 1.7951758436637364]
	TIME [epoch: 27.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4862163879423604		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.4862163879423604 | validation: 1.1423445260715759]
	TIME [epoch: 27.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4556822648884138		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.4556822648884138 | validation: 2.254477059492355]
	TIME [epoch: 27.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5837213120276863		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.5837213120276863 | validation: 1.0975504402626615]
	TIME [epoch: 27.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9129205563513694		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.9129205563513694 | validation: 1.234797010575421]
	TIME [epoch: 27.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4856230420519978		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.4856230420519978 | validation: 2.980293237539716]
	TIME [epoch: 27.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8973705795174987		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.8973705795174987 | validation: 1.7743101926365483]
	TIME [epoch: 27.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4261882745460692		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.4261882745460692 | validation: 1.683457377284181]
	TIME [epoch: 27.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3267221211022517		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.3267221211022517 | validation: 1.2150905325410906]
	TIME [epoch: 27.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4193956689674898		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.4193956689674898 | validation: 1.2170253494497434]
	TIME [epoch: 27.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3734098994813544		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.3734098994813544 | validation: 1.3002502076207696]
	TIME [epoch: 27.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6123662908240544		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.6123662908240544 | validation: 1.075617460664432]
	TIME [epoch: 27.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1543501316197005		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.1543501316197005 | validation: 0.9761848979986512]
	TIME [epoch: 27.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0618721687779487		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.0618721687779487 | validation: 1.0878717256652488]
	TIME [epoch: 27.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.576846416051471		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.576846416051471 | validation: 1.427311384686172]
	TIME [epoch: 27.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3404012377375507		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.3404012377375507 | validation: 1.7651873186757663]
	TIME [epoch: 27.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3027697950294328		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.3027697950294328 | validation: 1.1489157625136446]
	TIME [epoch: 27.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4288995635118715		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.4288995635118715 | validation: 3.7961263915215118]
	TIME [epoch: 27.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4995541873964235		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 2.4995541873964235 | validation: 1.6670286962761176]
	TIME [epoch: 27.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4871795588507581		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.4871795588507581 | validation: 1.0492931297081247]
	TIME [epoch: 27.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.125791228183957		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.125791228183957 | validation: 1.7965289036805012]
	TIME [epoch: 27.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3058646691765143		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.3058646691765143 | validation: 1.83951917462113]
	TIME [epoch: 27.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4709430706439621		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.4709430706439621 | validation: 1.1394267448515902]
	TIME [epoch: 27.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3133968757635617		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.3133968757635617 | validation: 1.9123427298733882]
	TIME [epoch: 27.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7185739905168071		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.7185739905168071 | validation: 1.4343454714936468]
	TIME [epoch: 27.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5949825702913332		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.5949825702913332 | validation: 2.261004802683527]
	TIME [epoch: 27.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5440930999394338		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.5440930999394338 | validation: 0.9968533769591353]
	TIME [epoch: 27.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.421955007242477		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.421955007242477 | validation: 1.281428004379058]
	TIME [epoch: 27.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.17183392124082		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.17183392124082 | validation: 1.1918146755701495]
	TIME [epoch: 27.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1851650534714355		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.1851650534714355 | validation: 1.0566161132175647]
	TIME [epoch: 27.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0260964675753117		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.0260964675753117 | validation: 1.2740376574737728]
	TIME [epoch: 27.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.675478585170482		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.675478585170482 | validation: 1.9317519426588041]
	TIME [epoch: 27.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.428845739520181		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 2.428845739520181 | validation: 2.001451846774414]
	TIME [epoch: 27.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3425643845515798		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.3425643845515798 | validation: 1.3859820925049622]
	TIME [epoch: 27.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1926893462598478		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.1926893462598478 | validation: 1.5227270925880014]
	TIME [epoch: 27.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2144780777278257		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.2144780777278257 | validation: 0.9399162714040321]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059630992503939		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.059630992503939 | validation: 1.2103239236668528]
	TIME [epoch: 27.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1931777689470495		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.1931777689470495 | validation: 2.035315169091413]
	TIME [epoch: 27.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.804299141251783		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.804299141251783 | validation: 1.2008971955937398]
	TIME [epoch: 27.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6140592799631939		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.6140592799631939 | validation: 1.1556769328610634]
	TIME [epoch: 27.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3485431716862437		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.3485431716862437 | validation: 1.1383549003134588]
	TIME [epoch: 27.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.326969138978726		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.326969138978726 | validation: 1.305884642119949]
	TIME [epoch: 27.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617648647664153		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.0617648647664153 | validation: 0.9527005987692553]
	TIME [epoch: 27.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0991848878445973		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.0991848878445973 | validation: 0.9671385800413531]
	TIME [epoch: 27.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5055031758762125		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.5055031758762125 | validation: 1.1531780083710674]
	TIME [epoch: 27.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8705944013802647		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.8705944013802647 | validation: 0.9575985394568227]
	TIME [epoch: 27.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0659622006985907		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.0659622006985907 | validation: 1.0081261254504126]
	TIME [epoch: 27.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1942680429318213		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.1942680429318213 | validation: 1.0640261476036992]
	TIME [epoch: 27.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1318552419693169		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.1318552419693169 | validation: 1.5081280737856906]
	TIME [epoch: 27.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1965165628583525		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.1965165628583525 | validation: 1.260181816741941]
	TIME [epoch: 27.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4127951061502486		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.4127951061502486 | validation: 0.992322284186888]
	TIME [epoch: 27.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2544405487977077		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.2544405487977077 | validation: 1.0058455209774122]
	TIME [epoch: 27.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.076070071740321		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 2.076070071740321 | validation: 4.150283176301461]
	TIME [epoch: 27.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.324846516466052		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 2.324846516466052 | validation: 1.0178588656111325]
	TIME [epoch: 27.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2081446710847192		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.2081446710847192 | validation: 1.3271171592386357]
	TIME [epoch: 27.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0433468680565345		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.0433468680565345 | validation: 1.341595244387076]
	TIME [epoch: 27.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.180218004062684		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.180218004062684 | validation: 1.2820143458792592]
	TIME [epoch: 27.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3367156125592712		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.3367156125592712 | validation: 0.94406865064358]
	TIME [epoch: 27.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3159844489401373		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.3159844489401373 | validation: 1.3520749364021618]
	TIME [epoch: 27.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1840689662263333		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.1840689662263333 | validation: 1.1953042803532778]
	TIME [epoch: 27.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2679224343947326		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.2679224343947326 | validation: 1.5922941312716414]
	TIME [epoch: 27.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5763327935166225		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.5763327935166225 | validation: 0.86243241285321]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8920151368624559		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.8920151368624559 | validation: 1.6187896362341732]
	TIME [epoch: 27.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3886322274879805		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.3886322274879805 | validation: 1.0997753678866447]
	TIME [epoch: 27.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0054718897405497		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.0054718897405497 | validation: 0.7909599370442021]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135205349707354		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.135205349707354 | validation: 1.4561139517245811]
	TIME [epoch: 27.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.717846990874921		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.717846990874921 | validation: 1.7293059104189628]
	TIME [epoch: 27.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4560967129761102		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.4560967129761102 | validation: 1.2019082590887806]
	TIME [epoch: 27.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2299716847782014		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.2299716847782014 | validation: 0.8469454491588084]
	TIME [epoch: 27.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0006305941567881		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.0006305941567881 | validation: 0.7594234578911568]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1442007955863314		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.1442007955863314 | validation: 1.2764994548110569]
	TIME [epoch: 27.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0492087232235687		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.0492087232235687 | validation: 0.7306628187888159]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3014116680052947		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.3014116680052947 | validation: 2.1882139801389195]
	TIME [epoch: 27.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287991580748732		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 2.287991580748732 | validation: 1.946982596360102]
	TIME [epoch: 27.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.048762632572127		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 2.048762632572127 | validation: 1.7678995607322174]
	TIME [epoch: 27.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9447662531641305		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.9447662531641305 | validation: 1.6925378258151804]
	TIME [epoch: 27.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6640179709268232		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.6640179709268232 | validation: 1.604020528445401]
	TIME [epoch: 27.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.530734112541111		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 2.530734112541111 | validation: 1.9584574773739525]
	TIME [epoch: 27.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6328295409077056		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.6328295409077056 | validation: 1.32463943347537]
	TIME [epoch: 27.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4439862299447728		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.4439862299447728 | validation: 1.124417201309814]
	TIME [epoch: 27.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064315002997251		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.064315002997251 | validation: 1.465912558380204]
	TIME [epoch: 27.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4024881445534525		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.4024881445534525 | validation: 1.332032775368407]
	TIME [epoch: 27.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4007090980869663		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.4007090980869663 | validation: 0.8449140239423603]
	TIME [epoch: 27.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4951081890616802		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.4951081890616802 | validation: 1.5538865242124396]
	TIME [epoch: 27.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.618630369879914		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.618630369879914 | validation: 0.9021574061423041]
	TIME [epoch: 27.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2101183080755096		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.2101183080755096 | validation: 1.3291003672229338]
	TIME [epoch: 27.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5928427903183129		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.5928427903183129 | validation: 0.8406949531644042]
	TIME [epoch: 27.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9699449983188285		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.9699449983188285 | validation: 1.1615462051903385]
	TIME [epoch: 27.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0087846885587657		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.0087846885587657 | validation: 0.7977272811152426]
	TIME [epoch: 27.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0247376549547258		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.0247376549547258 | validation: 1.0573697675791462]
	TIME [epoch: 27.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0470384036259095		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.0470384036259095 | validation: 1.116178298247414]
	TIME [epoch: 27.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2942689990483354		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.2942689990483354 | validation: 1.3382542903616386]
	TIME [epoch: 27.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.496143905955782		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.496143905955782 | validation: 0.7764890706203766]
	TIME [epoch: 27.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2114562498306085		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.2114562498306085 | validation: 1.0978844672822756]
	TIME [epoch: 27.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0011406960900886		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.0011406960900886 | validation: 1.018558099104697]
	TIME [epoch: 27.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.971730791400091		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.971730791400091 | validation: 1.1445100726734578]
	TIME [epoch: 27.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0434554153263371		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.0434554153263371 | validation: 0.9246387375041293]
	TIME [epoch: 27.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9956132911268406		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.9956132911268406 | validation: 0.7498255274828072]
	TIME [epoch: 27.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0130276933340387		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.0130276933340387 | validation: 1.0957719903903205]
	TIME [epoch: 27.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.369625786333945		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.369625786333945 | validation: 0.9006103618131244]
	TIME [epoch: 27.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8825504040490855		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.8825504040490855 | validation: 0.7388820322520527]
	TIME [epoch: 27.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9225585497980953		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.9225585497980953 | validation: 1.0274629657588292]
	TIME [epoch: 27.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.036000414281673		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.036000414281673 | validation: 1.072532690386949]
	TIME [epoch: 27.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9040677839169681		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.9040677839169681 | validation: 0.7878836884342911]
	TIME [epoch: 27.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9781951012099573		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.9781951012099573 | validation: 1.2974702999300052]
	TIME [epoch: 27.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.242150781214097		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.242150781214097 | validation: 1.1217773486701663]
	TIME [epoch: 27.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1982269285550537		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.1982269285550537 | validation: 0.8869571825618355]
	TIME [epoch: 27.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9385175054080017		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.9385175054080017 | validation: 0.8352187858682814]
	TIME [epoch: 27.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4905887768675377		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.4905887768675377 | validation: 1.4424771754778136]
	TIME [epoch: 27.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7601822727931349		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.7601822727931349 | validation: 1.7060692513600484]
	TIME [epoch: 27.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3536912104693741		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.3536912104693741 | validation: 1.2839491309398268]
	TIME [epoch: 27.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0293920593432406		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.0293920593432406 | validation: 1.232717539372421]
	TIME [epoch: 27.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6061330831717862		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.6061330831717862 | validation: 0.8526712256725877]
	TIME [epoch: 27.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3054841615558508		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.3054841615558508 | validation: 1.3505759289204318]
	TIME [epoch: 27.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3750150132731855		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.3750150132731855 | validation: 0.810382386056958]
	TIME [epoch: 27.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8486995124316041		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.8486995124316041 | validation: 0.8430362876392988]
	TIME [epoch: 27.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0882480486649597		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.0882480486649597 | validation: 1.9436891341153932]
	TIME [epoch: 27.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2270200407175764		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.2270200407175764 | validation: 0.7239825704561748]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0111745876810923		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.0111745876810923 | validation: 1.5744950478140591]
	TIME [epoch: 27.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6356369244236082		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.6356369244236082 | validation: 1.602582815344892]
	TIME [epoch: 27.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.522504485591058		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.522504485591058 | validation: 1.721394285827494]
	TIME [epoch: 27.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4870629431895166		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.4870629431895166 | validation: 0.8787856460763647]
	TIME [epoch: 27.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8824251966589216		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.8824251966589216 | validation: 1.0621625983729996]
	TIME [epoch: 27.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.099750760895535		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.099750760895535 | validation: 1.63856903790761]
	TIME [epoch: 27.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.093839469273512		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.093839469273512 | validation: 0.6935826932508331]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9406991672194844		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.9406991672194844 | validation: 1.0196411841955462]
	TIME [epoch: 27.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9448682633844168		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.9448682633844168 | validation: 0.8690330948737135]
	TIME [epoch: 27.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8814479203236651		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.8814479203236651 | validation: 0.8698223213462589]
	TIME [epoch: 27.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.277637855615978		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.277637855615978 | validation: 1.8117789715855468]
	TIME [epoch: 27.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6462317596862113		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.6462317596862113 | validation: 1.571129159067371]
	TIME [epoch: 27.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6117261671734235		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.6117261671734235 | validation: 0.8586447480113668]
	TIME [epoch: 27.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8076668729598996		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.8076668729598996 | validation: 0.9035458406552204]
	TIME [epoch: 27.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.770925248150701		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.770925248150701 | validation: 0.9561049008763545]
	TIME [epoch: 27.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0408168308711185		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.0408168308711185 | validation: 1.479308206460622]
	TIME [epoch: 27.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2180591160879506		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.2180591160879506 | validation: 0.8064439896481601]
	TIME [epoch: 27.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8889286616749406		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.8889286616749406 | validation: 2.1129733895087357]
	TIME [epoch: 27.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1921304164740891		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.1921304164740891 | validation: 0.7528987740638988]
	TIME [epoch: 27.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8339321685454097		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.8339321685454097 | validation: 1.6391894463346108]
	TIME [epoch: 27.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2462854864961768		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.2462854864961768 | validation: 0.7889170340400092]
	TIME [epoch: 27.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8048345027215592		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.8048345027215592 | validation: 1.2884284174099452]
	TIME [epoch: 27.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9511125909736038		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.9511125909736038 | validation: 0.7177546329279146]
	TIME [epoch: 27.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8401812679795009		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.8401812679795009 | validation: 1.1111955203137507]
	TIME [epoch: 27.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0347378274381616		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.0347378274381616 | validation: 0.9629183236666927]
	TIME [epoch: 27.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3033931411206887		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.3033931411206887 | validation: 0.620853450812035]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2829358478136375		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.2829358478136375 | validation: 1.7207102712975273]
	TIME [epoch: 27.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6131427162848686		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.6131427162848686 | validation: 1.17338763784585]
	TIME [epoch: 27.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2348004436943414		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.2348004436943414 | validation: 0.8177678945580078]
	TIME [epoch: 27.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7998578380639689		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.7998578380639689 | validation: 0.7881083693385105]
	TIME [epoch: 27.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7707369858152777		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.7707369858152777 | validation: 0.5969028563822456]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_503.pth
	Model improved!!!
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.945671221787975		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.945671221787975 | validation: 1.7540726327872085]
	TIME [epoch: 27.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9796164306520674		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.9796164306520674 | validation: 1.1620237953059316]
	TIME [epoch: 27.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9937879768693306		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.9937879768693306 | validation: 1.1466277131573133]
	TIME [epoch: 27.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0559935207889277		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.0559935207889277 | validation: 0.9905654408492012]
	TIME [epoch: 27.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5209278121097274		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.5209278121097274 | validation: 0.7787867846232596]
	TIME [epoch: 27.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8220530289068304		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.8220530289068304 | validation: 0.9413452447208377]
	TIME [epoch: 27.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1592307599067566		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 2.1592307599067566 | validation: 1.827093430675475]
	TIME [epoch: 27.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1392469072591849		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.1392469072591849 | validation: 1.6234079912359838]
	TIME [epoch: 27.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2403391255604899		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.2403391255604899 | validation: 1.4259311130755636]
	TIME [epoch: 27.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1568482034070942		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.1568482034070942 | validation: 0.732007743504301]
	TIME [epoch: 27.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8846058241060726		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.8846058241060726 | validation: 0.7112817304478577]
	TIME [epoch: 27.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8513042957051262		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.8513042957051262 | validation: 0.8013288576518913]
	TIME [epoch: 27.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8469598000600704		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.8469598000600704 | validation: 0.7219234658014488]
	TIME [epoch: 27.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9952475097643247		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.9952475097643247 | validation: 1.4381779409966813]
	TIME [epoch: 27.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8820355876229248		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.8820355876229248 | validation: 1.785088243758822]
	TIME [epoch: 27.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.113669722658642		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.113669722658642 | validation: 0.6820935321529324]
	TIME [epoch: 27.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0216153757148243		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.0216153757148243 | validation: 0.7202692101335681]
	TIME [epoch: 27.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9289804896083406		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.9289804896083406 | validation: 1.2980993162937546]
	TIME [epoch: 27.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0771084988190616		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.0771084988190616 | validation: 2.6398438552326544]
	TIME [epoch: 27.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9214866035209266		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.9214866035209266 | validation: 0.7975917079787508]
	TIME [epoch: 27.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0611035707852339		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.0611035707852339 | validation: 1.1507211260449504]
	TIME [epoch: 27.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.181846460408377		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 1.181846460408377 | validation: 0.9921160510903159]
	TIME [epoch: 27.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1015787295695814		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.1015787295695814 | validation: 1.0699429579972954]
	TIME [epoch: 27.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1713246887563937		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.1713246887563937 | validation: 1.493719497252376]
	TIME [epoch: 27.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4442497825690541		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.4442497825690541 | validation: 1.4442359464159575]
	TIME [epoch: 27.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.167184306894985		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.167184306894985 | validation: 0.8309592366990508]
	TIME [epoch: 27.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0280094536795317		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 1.0280094536795317 | validation: 1.139014302724351]
	TIME [epoch: 27.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8696441719703105		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.8696441719703105 | validation: 2.2985770103391276]
	TIME [epoch: 27.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5932669637983143		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.5932669637983143 | validation: 0.9575687719166428]
	TIME [epoch: 27.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0313986827843875		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.0313986827843875 | validation: 1.4375039962764278]
	TIME [epoch: 27.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.09726118481897		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 2.09726118481897 | validation: 0.8053789181497072]
	TIME [epoch: 27.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8662444267061208		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.8662444267061208 | validation: 0.7232593295537615]
	TIME [epoch: 27.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9015540039057789		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.9015540039057789 | validation: 0.9652952105447189]
	TIME [epoch: 27.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1899235800018746		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 1.1899235800018746 | validation: 1.314607639386372]
	TIME [epoch: 27.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9583517813056107		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.9583517813056107 | validation: 0.8395992004011466]
	TIME [epoch: 27.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8565220022954589		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.8565220022954589 | validation: 2.0888737380069777]
	TIME [epoch: 27.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1673548491360954		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.1673548491360954 | validation: 0.6795087089691144]
	TIME [epoch: 27.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0235090621903833		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.0235090621903833 | validation: 0.7529046408592379]
	TIME [epoch: 27.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8619004329598683		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.8619004329598683 | validation: 1.4760468084820186]
	TIME [epoch: 27.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0668937391855		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 1.0668937391855 | validation: 1.3764000340123494]
	TIME [epoch: 27.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9049563344400267		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 1.9049563344400267 | validation: 0.8280925676774079]
	TIME [epoch: 27.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2189695968992926		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 1.2189695968992926 | validation: 0.8781001845807833]
	TIME [epoch: 27.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8339943281159468		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.8339943281159468 | validation: 0.8857208715370589]
	TIME [epoch: 27.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8124333577207428		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.8124333577207428 | validation: 0.9411174766508694]
	TIME [epoch: 27.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9347477684205412		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.9347477684205412 | validation: 0.6883427868304304]
	TIME [epoch: 27.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.131553122868342		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 1.131553122868342 | validation: 0.9268354171866358]
	TIME [epoch: 27.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9150207296448889		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.9150207296448889 | validation: 1.0219012181357148]
	TIME [epoch: 27.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9523872276553645		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.9523872276553645 | validation: 1.18817322492487]
	TIME [epoch: 27.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8873461047407238		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.8873461047407238 | validation: 0.899795857673167]
	TIME [epoch: 27.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9124449593045005		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.9124449593045005 | validation: 1.0485353433894493]
	TIME [epoch: 27.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9732611937349084		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.9732611937349084 | validation: 0.9147343138652451]
	TIME [epoch: 27.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7955320415486079		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.7955320415486079 | validation: 1.0948831965806078]
	TIME [epoch: 27.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8143384205262114		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.8143384205262114 | validation: 0.9636748816350391]
	TIME [epoch: 27.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7556193336565493		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.7556193336565493 | validation: 0.5762495866031534]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_557.pth
	Model improved!!!
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9167597440589274		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.9167597440589274 | validation: 2.639689896281081]
	TIME [epoch: 27.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7745381353693608		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.7745381353693608 | validation: 1.2301618998600392]
	TIME [epoch: 27.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.052916217248118		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 1.052916217248118 | validation: 0.6163397681297598]
	TIME [epoch: 27.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9254535743008758		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.9254535743008758 | validation: 0.7290364772820775]
	TIME [epoch: 27.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7291176673277558		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.7291176673277558 | validation: 1.2813956230974441]
	TIME [epoch: 27.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9221451774285594		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.9221451774285594 | validation: 0.6520789073970891]
	TIME [epoch: 27.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8576173656119921		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.8576173656119921 | validation: 1.4536678764435937]
	TIME [epoch: 27.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.45205048292694		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 1.45205048292694 | validation: 0.7650924129274955]
	TIME [epoch: 27.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8969468375081948		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.8969468375081948 | validation: 1.0787468401937992]
	TIME [epoch: 27.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3785820022133843		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.3785820022133843 | validation: 3.780122549017684]
	TIME [epoch: 27.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.446763979109337		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 2.446763979109337 | validation: 1.3742299931226467]
	TIME [epoch: 27.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9853622684347811		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.9853622684347811 | validation: 0.6409236096103438]
	TIME [epoch: 27.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7684141349513726		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.7684141349513726 | validation: 0.6405510804423554]
	TIME [epoch: 27.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8374938736624937		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.8374938736624937 | validation: 0.5675943009949467]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_571.pth
	Model improved!!!
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617062836563906		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 1.0617062836563906 | validation: 0.6390964859899725]
	TIME [epoch: 27.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6897605410630226		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.6897605410630226 | validation: 0.7736892356626004]
	TIME [epoch: 27.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8081965190782183		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.8081965190782183 | validation: 0.9482127964869201]
	TIME [epoch: 27.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8984547533290432		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.8984547533290432 | validation: 0.5216805558950182]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_575.pth
	Model improved!!!
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6166950236895543		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.6166950236895543 | validation: 1.0620910077936074]
	TIME [epoch: 27.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9624372975491271		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.9624372975491271 | validation: 0.7334147565315036]
	TIME [epoch: 27.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6581428850707707		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.6581428850707707 | validation: 0.9283513021226305]
	TIME [epoch: 27.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8066261186070744		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.8066261186070744 | validation: 0.7387333537342375]
	TIME [epoch: 27.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252681804155543		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.7252681804155543 | validation: 0.5963907121776367]
	TIME [epoch: 27.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7671305347745927		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.7671305347745927 | validation: 0.7542712358545041]
	TIME [epoch: 27.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7600467907984829		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.7600467907984829 | validation: 0.6981695216892656]
	TIME [epoch: 27.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7427598986290467		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.7427598986290467 | validation: 0.6298755016735145]
	TIME [epoch: 27.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.821846516585375		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.821846516585375 | validation: 0.7273440661351727]
	TIME [epoch: 27.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6252410346852064		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.6252410346852064 | validation: 0.5505844962718466]
	TIME [epoch: 27.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7016025589600443		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.7016025589600443 | validation: 0.6112545647354338]
	TIME [epoch: 27.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7463459607211826		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.7463459607211826 | validation: 0.5201079665611245]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_587.pth
	Model improved!!!
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7084397257004587		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.7084397257004587 | validation: 0.7287989805026195]
	TIME [epoch: 27.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731010629480615		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.731010629480615 | validation: 0.7672991491518201]
	TIME [epoch: 27.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8202285468392909		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.8202285468392909 | validation: 0.6152364447786238]
	TIME [epoch: 27.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6906030046877776		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.6906030046877776 | validation: 0.6788991443741602]
	TIME [epoch: 27.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8347765789514949		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.8347765789514949 | validation: 0.45671234562632185]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_592.pth
	Model improved!!!
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5849768444117212		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.5849768444117212 | validation: 0.5382733702206618]
	TIME [epoch: 27.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7902561297149545		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.7902561297149545 | validation: 0.9247519265069056]
	TIME [epoch: 27.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7692486856882639		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.7692486856882639 | validation: 0.7343670168500307]
	TIME [epoch: 27.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8037173312838857		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.8037173312838857 | validation: 1.1369066790105113]
	TIME [epoch: 27.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9393932789862227		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.9393932789862227 | validation: 1.0857133297414252]
	TIME [epoch: 27.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7911187891938947		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.7911187891938947 | validation: 0.6528959346877358]
	TIME [epoch: 27.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845092352481851		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.6845092352481851 | validation: 0.6630634661330161]
	TIME [epoch: 27.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8958777629121797		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.8958777629121797 | validation: 0.8094925879562831]
	TIME [epoch: 27.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6511637564343502		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.6511637564343502 | validation: 1.3165090744799464]
	TIME [epoch: 27.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1698814863458604		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 1.1698814863458604 | validation: 0.9275801838272765]
	TIME [epoch: 27.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7562095257648909		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.7562095257648909 | validation: 0.6703744699698315]
	TIME [epoch: 27.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.726210430868356		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.726210430868356 | validation: 0.4918131401257419]
	TIME [epoch: 27.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5949338936326777		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.5949338936326777 | validation: 1.4099285589804424]
	TIME [epoch: 27.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138010892630916		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.138010892630916 | validation: 0.6332807627831651]
	TIME [epoch: 27.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9642916561452888		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.9642916561452888 | validation: 0.7014052022443983]
	TIME [epoch: 27.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845953176199231		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.6845953176199231 | validation: 0.640763461792489]
	TIME [epoch: 27.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8287009321177933		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.8287009321177933 | validation: 0.9248444413558607]
	TIME [epoch: 27.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7541346188067158		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.7541346188067158 | validation: 0.6969967878691835]
	TIME [epoch: 27.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6217685878033857		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.6217685878033857 | validation: 0.4706300725370296]
	TIME [epoch: 27.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.59442479738126		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.59442479738126 | validation: 0.47860067358514213]
	TIME [epoch: 27.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6088633764560845		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.6088633764560845 | validation: 0.7345482466314396]
	TIME [epoch: 27.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7909377800402919		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.7909377800402919 | validation: 1.1145780860872523]
	TIME [epoch: 27.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7432920480036698		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.7432920480036698 | validation: 0.49616220045447523]
	TIME [epoch: 27.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5772651108543398		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5772651108543398 | validation: 0.7544262423888215]
	TIME [epoch: 27.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7010181493740446		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.7010181493740446 | validation: 1.012048817766903]
	TIME [epoch: 27.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7338856444021237		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.7338856444021237 | validation: 0.7079391023187221]
	TIME [epoch: 27.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6449494792750026		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.6449494792750026 | validation: 0.6141603781908913]
	TIME [epoch: 27.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5643545496148643		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.5643545496148643 | validation: 0.5167595001369432]
	TIME [epoch: 27.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5786768075489186		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.5786768075489186 | validation: 0.828801270852066]
	TIME [epoch: 27.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.652128021647682		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.652128021647682 | validation: 0.822259012373116]
	TIME [epoch: 27.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6779741202838733		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.6779741202838733 | validation: 0.5862099453312303]
	TIME [epoch: 27.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5606964354203451		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.5606964354203451 | validation: 0.4320904850067996]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_624.pth
	Model improved!!!
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5449991040627973		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.5449991040627973 | validation: 0.8506431622294574]
	TIME [epoch: 27.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.766195129771932		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.766195129771932 | validation: 0.7182902307142485]
	TIME [epoch: 27.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.252279870474305		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 1.252279870474305 | validation: 1.0998242755507863]
	TIME [epoch: 27.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0891628276951348		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 1.0891628276951348 | validation: 0.7907571560526]
	TIME [epoch: 27.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0579857412549334		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 1.0579857412549334 | validation: 1.3028942999628088]
	TIME [epoch: 27.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0101138006455148		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 1.0101138006455148 | validation: 0.695374788755353]
	TIME [epoch: 27.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6555466012028621		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.6555466012028621 | validation: 0.8737327182254643]
	TIME [epoch: 27.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8010869316169575		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.8010869316169575 | validation: 0.9306333187052138]
	TIME [epoch: 27.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6781459648288678		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.6781459648288678 | validation: 0.6235979732933463]
	TIME [epoch: 27.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6017171687126561		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.6017171687126561 | validation: 0.632697669028325]
	TIME [epoch: 27.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6092416503550531		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.6092416503550531 | validation: 1.7900996822952715]
	TIME [epoch: 27.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3297076604748468		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 1.3297076604748468 | validation: 0.49311927814123396]
	TIME [epoch: 27.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235011909843726		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.6235011909843726 | validation: 0.5123670818795616]
	TIME [epoch: 27.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1057961731940573		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 1.1057961731940573 | validation: 1.067509994630335]
	TIME [epoch: 27.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0458669856993188		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 1.0458669856993188 | validation: 0.6771473028319187]
	TIME [epoch: 27.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9179065553431058		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.9179065553431058 | validation: 0.7947395959782213]
	TIME [epoch: 27.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6077783216389971		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.6077783216389971 | validation: 0.6296155571034235]
	TIME [epoch: 27.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7157455108826267		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.7157455108826267 | validation: 0.6890492290775672]
	TIME [epoch: 27.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5511448301696404		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.5511448301696404 | validation: 0.44599011411972045]
	TIME [epoch: 27.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839299764157934		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.4839299764157934 | validation: 0.8339352156441526]
	TIME [epoch: 27.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6610362613639504		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.6610362613639504 | validation: 0.4780249821170979]
	TIME [epoch: 27.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6926471304280223		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.6926471304280223 | validation: 0.7867402885165486]
	TIME [epoch: 27.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.852373379743036		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.852373379743036 | validation: 0.6924123052286629]
	TIME [epoch: 27.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.54594873023301		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.54594873023301 | validation: 0.7122192432289585]
	TIME [epoch: 27.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6138240875472903		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.6138240875472903 | validation: 1.411369980123932]
	TIME [epoch: 27.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9594314606413001		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.9594314606413001 | validation: 0.6270814122858249]
	TIME [epoch: 27.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.85038955673191		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.85038955673191 | validation: 0.4992254405400799]
	TIME [epoch: 27.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6889966648068004		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.6889966648068004 | validation: 0.6129139031776542]
	TIME [epoch: 27.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9773571013520623		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.9773571013520623 | validation: 0.9314714482913936]
	TIME [epoch: 27.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8168998724865897		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.8168998724865897 | validation: 0.6393738896978625]
	TIME [epoch: 27.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7593616371326083		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.7593616371326083 | validation: 0.7446675436645679]
	TIME [epoch: 27.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0084268570610242		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 1.0084268570610242 | validation: 0.5588139420739265]
	TIME [epoch: 27.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7155204336077396		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.7155204336077396 | validation: 0.42253865789497513]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_657.pth
	Model improved!!!
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6685091299870956		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.6685091299870956 | validation: 0.8290659708852954]
	TIME [epoch: 27.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6696326904000597		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.6696326904000597 | validation: 0.7708701113321428]
	TIME [epoch: 27.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.703544544692578		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.703544544692578 | validation: 0.7635466757763542]
	TIME [epoch: 27.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3707070140302409		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 1.3707070140302409 | validation: 0.8176841536923192]
	TIME [epoch: 27.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055569115266966		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.7055569115266966 | validation: 0.46976947590347595]
	TIME [epoch: 27.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6151777787131921		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.6151777787131921 | validation: 0.49360073665945026]
	TIME [epoch: 27.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7473586166284754		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.7473586166284754 | validation: 1.020251526943731]
	TIME [epoch: 27.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6257840865783625		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.6257840865783625 | validation: 0.521441636069482]
	TIME [epoch: 27.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540773071198193		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.5540773071198193 | validation: 0.4951222085466392]
	TIME [epoch: 27.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.52633798153869		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.52633798153869 | validation: 0.4783068951719955]
	TIME [epoch: 27.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5555225928664639		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.5555225928664639 | validation: 1.1742780478139947]
	TIME [epoch: 27.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.92786156589462		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.92786156589462 | validation: 0.5709204519704716]
	TIME [epoch: 27.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5264605396960846		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.5264605396960846 | validation: 0.4900712005655793]
	TIME [epoch: 27.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5814035494397959		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.5814035494397959 | validation: 0.4306082053194568]
	TIME [epoch: 27.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5598659916120104		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.5598659916120104 | validation: 0.5785699526293956]
	TIME [epoch: 27.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7399308969307867		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.7399308969307867 | validation: 0.9892019697264176]
	TIME [epoch: 27.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9572495816343984		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.9572495816343984 | validation: 0.9580495315424565]
	TIME [epoch: 27.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8253676898528006		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.8253676898528006 | validation: 0.9089720798692499]
	TIME [epoch: 27.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5938740065591718		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.5938740065591718 | validation: 0.5392609279035366]
	TIME [epoch: 27.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5899158996059976		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.5899158996059976 | validation: 0.6272251501165931]
	TIME [epoch: 27.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5924318730357032		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.5924318730357032 | validation: 0.5367062179659082]
	TIME [epoch: 27.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7846778503565739		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.7846778503565739 | validation: 0.786615585141146]
	TIME [epoch: 27.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5447051567789709		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.5447051567789709 | validation: 0.4305692665220549]
	TIME [epoch: 27.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6999202105591539		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.6999202105591539 | validation: 1.0614235938213217]
	TIME [epoch: 27.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7597910510215855		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.7597910510215855 | validation: 0.49034623373177083]
	TIME [epoch: 27.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6577953517613884		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.6577953517613884 | validation: 0.4074067390694729]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5348485579501746		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.5348485579501746 | validation: 0.6100215229516941]
	TIME [epoch: 27.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6308230852891199		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.6308230852891199 | validation: 0.6113941795313721]
	TIME [epoch: 27.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5224503093089115		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.5224503093089115 | validation: 0.460944256146621]
	TIME [epoch: 27.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.545714984325192		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.545714984325192 | validation: 0.6526789223935157]
	TIME [epoch: 27.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5425342439250754		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.5425342439250754 | validation: 0.7986813053724535]
	TIME [epoch: 27.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6074293873817821		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.6074293873817821 | validation: 0.4401698049254037]
	TIME [epoch: 27.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8539041747003798		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.8539041747003798 | validation: 0.6110741381766139]
	TIME [epoch: 27.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5804850476551769		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.5804850476551769 | validation: 0.568222824055769]
	TIME [epoch: 27.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8228148926243896		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.8228148926243896 | validation: 0.5226548727985516]
	TIME [epoch: 27.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7077094162701927		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.7077094162701927 | validation: 0.43071181024356514]
	TIME [epoch: 27.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4906736099164777		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.4906736099164777 | validation: 0.5581131221177161]
	TIME [epoch: 27.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5303674599954389		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.5303674599954389 | validation: 0.5243749345526383]
	TIME [epoch: 27.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.562161563736288		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.562161563736288 | validation: 0.4253020894742501]
	TIME [epoch: 27.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4498942484270453		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.4498942484270453 | validation: 0.42143972116879524]
	TIME [epoch: 27.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5147771391887417		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.5147771391887417 | validation: 0.4061691158098646]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6453048631849069		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.6453048631849069 | validation: 1.100462621130186]
	TIME [epoch: 27.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6427146902053729		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.6427146902053729 | validation: 0.4801557457406699]
	TIME [epoch: 27.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5086150938782041		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.5086150938782041 | validation: 0.7862827684103604]
	TIME [epoch: 27.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6055931329386804		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.6055931329386804 | validation: 0.6496728740906619]
	TIME [epoch: 27.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5174221666122334		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.5174221666122334 | validation: 0.5437584459273943]
	TIME [epoch: 27.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6636078725605234		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.6636078725605234 | validation: 0.4227947978919018]
	TIME [epoch: 27.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6330116429257099		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.6330116429257099 | validation: 0.910093732452549]
	TIME [epoch: 27.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7638079555212448		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.7638079555212448 | validation: 0.8879485863516564]
	TIME [epoch: 27.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7846765480265518		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.7846765480265518 | validation: 0.6173886772494227]
	TIME [epoch: 27.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5475191272915033		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.5475191272915033 | validation: 0.3547417864633156]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_708.pth
	Model improved!!!
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5774197070777158		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.5774197070777158 | validation: 0.5624494540079273]
	TIME [epoch: 27.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5591723651929975		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.5591723651929975 | validation: 0.4604843051965776]
	TIME [epoch: 27.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5449760660112988		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.5449760660112988 | validation: 0.6919177571235019]
	TIME [epoch: 27.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6770625657486181		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.6770625657486181 | validation: 0.484686772092785]
	TIME [epoch: 27.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5612308710973979		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.5612308710973979 | validation: 0.41588758340655774]
	TIME [epoch: 27.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5961890035465426		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.5961890035465426 | validation: 0.7149079255297877]
	TIME [epoch: 27.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7077169388087707		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.7077169388087707 | validation: 0.5600521998374534]
	TIME [epoch: 27.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5169073725216664		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.5169073725216664 | validation: 0.4874748622051553]
	TIME [epoch: 27.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6286264760906517		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.6286264760906517 | validation: 0.4453882790493377]
	TIME [epoch: 27.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6307367441993231		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.6307367441993231 | validation: 0.4038004778522103]
	TIME [epoch: 27.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4705384349120665		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.4705384349120665 | validation: 0.5470862952579991]
	TIME [epoch: 27.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6531837479461498		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.6531837479461498 | validation: 0.38272883405965324]
	TIME [epoch: 27.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5046057680283137		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.5046057680283137 | validation: 0.41173886129305987]
	TIME [epoch: 27.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4809932994243816		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.4809932994243816 | validation: 0.5128512706664123]
	TIME [epoch: 27.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6467119895390683		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.6467119895390683 | validation: 0.5933173425268915]
	TIME [epoch: 27.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825958752418779		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.6825958752418779 | validation: 0.49026194181007343]
	TIME [epoch: 27.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5032122073757035		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.5032122073757035 | validation: 0.5254685867543356]
	TIME [epoch: 27.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6126239836829326		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.6126239836829326 | validation: 0.7887850522996089]
	TIME [epoch: 27.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6741634450819523		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.6741634450819523 | validation: 0.45564687466079945]
	TIME [epoch: 27.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5212069450357184		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.5212069450357184 | validation: 0.5549434692005653]
	TIME [epoch: 27.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8158648000920097		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.8158648000920097 | validation: 0.5448817500153628]
	TIME [epoch: 27.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5185203513961636		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.5185203513961636 | validation: 0.6770774809369161]
	TIME [epoch: 27.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6892682316050541		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.6892682316050541 | validation: 0.6189863065913034]
	TIME [epoch: 27.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5980149068593128		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.5980149068593128 | validation: 0.5549166966829142]
	TIME [epoch: 27.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.523394218352974		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.523394218352974 | validation: 0.5146064306278266]
	TIME [epoch: 27.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112040350376819		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.5112040350376819 | validation: 0.3760401583200065]
	TIME [epoch: 27.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5631473868964731		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.5631473868964731 | validation: 0.767490011601924]
	TIME [epoch: 27.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5287750720997112		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.5287750720997112 | validation: 0.8956567349228193]
	TIME [epoch: 27.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6438556375532747		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.6438556375532747 | validation: 0.6080805772490535]
	TIME [epoch: 27.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5003022041458427		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.5003022041458427 | validation: 0.7035405853517257]
	TIME [epoch: 27.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5270037987746046		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.5270037987746046 | validation: 0.43678306260703076]
	TIME [epoch: 27.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44382378102570624		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.44382378102570624 | validation: 0.7054916982687085]
	TIME [epoch: 27.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5268490785638011		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.5268490785638011 | validation: 0.3646774611204077]
	TIME [epoch: 27.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4797256978770391		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.4797256978770391 | validation: 0.5306865215194444]
	TIME [epoch: 27.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5782897610068958		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.5782897610068958 | validation: 0.580781010480819]
	TIME [epoch: 27.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6320742808102233		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.6320742808102233 | validation: 0.5671371921442765]
	TIME [epoch: 27.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6013497049493066		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.6013497049493066 | validation: 0.6175777425609154]
	TIME [epoch: 27.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0298363337641459		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 1.0298363337641459 | validation: 0.509110428752181]
	TIME [epoch: 27.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6293252249225882		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.6293252249225882 | validation: 0.8218856765791407]
	TIME [epoch: 27.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5813267109364886		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.5813267109364886 | validation: 0.5204223030970377]
	TIME [epoch: 27.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44695602362730724		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.44695602362730724 | validation: 0.4923193599690675]
	TIME [epoch: 27.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4459468289412622		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.4459468289412622 | validation: 0.4922512333108132]
	TIME [epoch: 27.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48379282453233013		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.48379282453233013 | validation: 0.3077711081072986]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_751.pth
	Model improved!!!
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42913974778654757		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.42913974778654757 | validation: 0.5589025212641162]
	TIME [epoch: 27.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48222601836041684		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.48222601836041684 | validation: 0.45710225899628476]
	TIME [epoch: 27.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.570723298852507		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.570723298852507 | validation: 0.8926379118556109]
	TIME [epoch: 27.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.629224677478253		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.629224677478253 | validation: 0.5473605577727048]
	TIME [epoch: 27.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44166194620914756		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.44166194620914756 | validation: 0.347315941714158]
	TIME [epoch: 27.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5858833911931486		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.5858833911931486 | validation: 0.5861502724037785]
	TIME [epoch: 27.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8635846078656184		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.8635846078656184 | validation: 0.62883505940896]
	TIME [epoch: 27.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8983771033919211		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.8983771033919211 | validation: 0.6366859669197676]
	TIME [epoch: 27.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6300259110653738		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.6300259110653738 | validation: 0.41983422466707965]
	TIME [epoch: 27.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3910307574268089		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.3910307574268089 | validation: 0.31272312921989764]
	TIME [epoch: 27.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4363571320708853		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.4363571320708853 | validation: 0.3383393162732145]
	TIME [epoch: 27.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39838280728748154		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.39838280728748154 | validation: 0.3759759201909422]
	TIME [epoch: 27.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33008089932177387		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.33008089932177387 | validation: 0.4080325634889023]
	TIME [epoch: 27.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4774882150733587		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.4774882150733587 | validation: 0.312159800547188]
	TIME [epoch: 27.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47017385820260804		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.47017385820260804 | validation: 0.5012253503358063]
	TIME [epoch: 27.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48331818948579436		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.48331818948579436 | validation: 0.3811332287718318]
	TIME [epoch: 27.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4364801320683298		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.4364801320683298 | validation: 0.4068386094268186]
	TIME [epoch: 27.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45027984057489356		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.45027984057489356 | validation: 0.4795160287463572]
	TIME [epoch: 27.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.525661466899148		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.525661466899148 | validation: 0.36048520371543424]
	TIME [epoch: 27.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4113015938844806		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.4113015938844806 | validation: 0.5014272125672313]
	TIME [epoch: 27.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4636782581509034		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.4636782581509034 | validation: 0.6965930634232292]
	TIME [epoch: 27.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46384093776738944		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.46384093776738944 | validation: 0.3782827967664739]
	TIME [epoch: 27.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41706691677188906		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.41706691677188906 | validation: 0.4059254997036152]
	TIME [epoch: 27.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46677689883531925		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.46677689883531925 | validation: 0.30761735378648813]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_775.pth
	Model improved!!!
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36279340526718357		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.36279340526718357 | validation: 0.337656111274634]
	TIME [epoch: 27.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41186735251178624		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.41186735251178624 | validation: 0.30004745956022105]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_777.pth
	Model improved!!!
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45641886988048125		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.45641886988048125 | validation: 0.4849305874035914]
	TIME [epoch: 27.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4574555762081249		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.4574555762081249 | validation: 0.31685265317280226]
	TIME [epoch: 27.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6449436988475551		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.6449436988475551 | validation: 1.062404326853612]
	TIME [epoch: 27.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6456733055065218		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.6456733055065218 | validation: 0.4573815206803501]
	TIME [epoch: 27.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4355465728594056		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.4355465728594056 | validation: 0.39691897135362125]
	TIME [epoch: 27.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5739866641426796		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.5739866641426796 | validation: 0.4300054264605245]
	TIME [epoch: 27.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38081730879102693		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.38081730879102693 | validation: 0.6278293217778723]
	TIME [epoch: 27.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5822760034487252		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.5822760034487252 | validation: 0.8613811533380575]
	TIME [epoch: 27.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822427960349419		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.6822427960349419 | validation: 0.4769379580055545]
	TIME [epoch: 27.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.59153548996687		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.59153548996687 | validation: 0.493034801438835]
	TIME [epoch: 27.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5362525199858224		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.5362525199858224 | validation: 0.3646303439918212]
	TIME [epoch: 27.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43272895517603616		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.43272895517603616 | validation: 0.7287288967349429]
	TIME [epoch: 27.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.583838035204999		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.583838035204999 | validation: 1.3710253847362524]
	TIME [epoch: 27.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.090837229346139		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 1.090837229346139 | validation: 0.5285433135007084]
	TIME [epoch: 27.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5974623305573117		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.5974623305573117 | validation: 0.38243282962470687]
	TIME [epoch: 27.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4336331508224475		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.4336331508224475 | validation: 0.3652992233388158]
	TIME [epoch: 27.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4381825376869565		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.4381825376869565 | validation: 0.5911757339356567]
	TIME [epoch: 27.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4910396602158772		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.4910396602158772 | validation: 1.2547895506950897]
	TIME [epoch: 27.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8137017560722798		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.8137017560722798 | validation: 0.5053102108269126]
	TIME [epoch: 27.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.760162043602578		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.760162043602578 | validation: 0.7983817733920131]
	TIME [epoch: 27.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7517627063097446		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.7517627063097446 | validation: 0.842275008617433]
	TIME [epoch: 27.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.546898403675101		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.546898403675101 | validation: 0.41009774412371086]
	TIME [epoch: 27.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4964647394784353		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.4964647394784353 | validation: 0.3268986170711895]
	TIME [epoch: 27.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6414956345246101		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.6414956345246101 | validation: 0.5625356439102819]
	TIME [epoch: 27.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5909232462375591		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.5909232462375591 | validation: 0.8352015211426753]
	TIME [epoch: 27.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5967927157554345		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.5967927157554345 | validation: 0.30313534176288504]
	TIME [epoch: 27.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7479568388001798		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.7479568388001798 | validation: 0.5238731071045634]
	TIME [epoch: 27.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4877295702112838		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.4877295702112838 | validation: 0.3032768233281088]
	TIME [epoch: 27.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033682754577835		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.5033682754577835 | validation: 0.45029112732056364]
	TIME [epoch: 27.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5020913889991934		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.5020913889991934 | validation: 0.42087152472999884]
	TIME [epoch: 27.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5632323561407925		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.5632323561407925 | validation: 0.4943326972069828]
	TIME [epoch: 27.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4202231561367482		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.4202231561367482 | validation: 0.35685974749180865]
	TIME [epoch: 27.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.430394217393549		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.430394217393549 | validation: 0.40164515817878865]
	TIME [epoch: 27.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42520476832705495		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.42520476832705495 | validation: 0.8205070096937332]
	TIME [epoch: 27.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6799700208870157		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.6799700208870157 | validation: 0.2762575808347522]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_812.pth
	Model improved!!!
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3375843972130032		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.3375843972130032 | validation: 0.41995087654418795]
	TIME [epoch: 27.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.623734092969857		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.623734092969857 | validation: 0.5385379224440286]
	TIME [epoch: 27.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.595683057044302		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.595683057044302 | validation: 0.4318022215461948]
	TIME [epoch: 27.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.665357457126256		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.665357457126256 | validation: 0.622398010431676]
	TIME [epoch: 27.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815476304595567		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.6815476304595567 | validation: 0.4335643395019183]
	TIME [epoch: 27.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41419330095602663		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.41419330095602663 | validation: 0.3135579570955462]
	TIME [epoch: 27.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41650640287649315		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.41650640287649315 | validation: 0.3711584030626798]
	TIME [epoch: 27.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3662374379189879		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.3662374379189879 | validation: 0.3209300511444392]
	TIME [epoch: 27.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.613672081287373		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.613672081287373 | validation: 0.67322715887284]
	TIME [epoch: 27.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5611311921942543		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.5611311921942543 | validation: 0.2997010896888682]
	TIME [epoch: 27.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4968849674645226		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.4968849674645226 | validation: 0.3485123296276252]
	TIME [epoch: 27.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4612789021807896		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.4612789021807896 | validation: 0.4405451655004455]
	TIME [epoch: 27.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4096853421114379		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.4096853421114379 | validation: 0.5462088783441873]
	TIME [epoch: 27.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44099204600845615		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.44099204600845615 | validation: 0.30949506334763643]
	TIME [epoch: 27.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45670763676945136		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.45670763676945136 | validation: 0.6257901611406518]
	TIME [epoch: 27.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201258068204053		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.7201258068204053 | validation: 0.5964478206314026]
	TIME [epoch: 27.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6167291276669963		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.6167291276669963 | validation: 0.634520036177559]
	TIME [epoch: 27.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4972304405690704		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.4972304405690704 | validation: 0.42530970483481995]
	TIME [epoch: 27.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6345038660981881		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.6345038660981881 | validation: 0.29206222562028905]
	TIME [epoch: 27.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33042835904186574		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.33042835904186574 | validation: 0.36869436462358124]
	TIME [epoch: 27.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4064769717423178		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.4064769717423178 | validation: 0.2792254503822716]
	TIME [epoch: 27.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3166995589037295		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.3166995589037295 | validation: 0.4128030353402905]
	TIME [epoch: 27.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4265047591592209		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.4265047591592209 | validation: 0.34802027443151384]
	TIME [epoch: 27.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4364362584067281		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.4364362584067281 | validation: 0.831305893435059]
	TIME [epoch: 27.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5832768022965694		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.5832768022965694 | validation: 0.4368608208601715]
	TIME [epoch: 27.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5723686878014427		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.5723686878014427 | validation: 1.6366554348421665]
	TIME [epoch: 27.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5861721786980247		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 1.5861721786980247 | validation: 0.5617279113183055]
	TIME [epoch: 27.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4200322485222349		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.4200322485222349 | validation: 0.32336131782326716]
	TIME [epoch: 27.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4215866466880747		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.4215866466880747 | validation: 0.33980148871666216]
	TIME [epoch: 27.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5737719977874447		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.5737719977874447 | validation: 0.6457565634637691]
	TIME [epoch: 27.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43372341758727606		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.43372341758727606 | validation: 0.29601305939145234]
	TIME [epoch: 27.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4415981551246289		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.4415981551246289 | validation: 0.4809665253943555]
	TIME [epoch: 27.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5219203000407455		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.5219203000407455 | validation: 0.5296779584240254]
	TIME [epoch: 27.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.71339772256164		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.71339772256164 | validation: 0.939330484247069]
	TIME [epoch: 27.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5455875068600919		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.5455875068600919 | validation: 0.5446650163820944]
	TIME [epoch: 27.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677783858200938		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.5677783858200938 | validation: 0.38388425864952863]
	TIME [epoch: 27.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4767108349983631		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.4767108349983631 | validation: 0.603335196396428]
	TIME [epoch: 27.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4794274595190367		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.4794274595190367 | validation: 0.3993363560339359]
	TIME [epoch: 27.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45028398093032196		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.45028398093032196 | validation: 0.2676972648666602]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_851.pth
	Model improved!!!
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336074104292825		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.3336074104292825 | validation: 0.3364761152289315]
	TIME [epoch: 27.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42192155407711396		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.42192155407711396 | validation: 0.5086558569158235]
	TIME [epoch: 27.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4337445275625788		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.4337445275625788 | validation: 0.6643114330001743]
	TIME [epoch: 27.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40486871926257756		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.40486871926257756 | validation: 0.3214134919079517]
	TIME [epoch: 27.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37486987155878426		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.37486987155878426 | validation: 0.37351500576073626]
	TIME [epoch: 27.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35599925922752973		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.35599925922752973 | validation: 0.2695176664925262]
	TIME [epoch: 27.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4183089843612588		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.4183089843612588 | validation: 0.3897835098382833]
	TIME [epoch: 27.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570144928403569		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.3570144928403569 | validation: 0.35360929279578324]
	TIME [epoch: 27.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34133364200425464		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.34133364200425464 | validation: 0.4281328629123425]
	TIME [epoch: 27.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3856150897646911		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.3856150897646911 | validation: 0.4598514334468174]
	TIME [epoch: 27.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40208257675479997		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.40208257675479997 | validation: 0.43147905555249677]
	TIME [epoch: 27.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33276108724224307		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.33276108724224307 | validation: 0.5294720606795338]
	TIME [epoch: 27.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4822345092295247		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.4822345092295247 | validation: 1.0271516221454224]
	TIME [epoch: 27.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6676002005400257		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.6676002005400257 | validation: 0.4294622157639641]
	TIME [epoch: 27.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39931045471064136		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.39931045471064136 | validation: 0.5896173588453818]
	TIME [epoch: 27.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4553997724957607		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.4553997724957607 | validation: 0.4709164094605033]
	TIME [epoch: 27.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.445423799042037		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.445423799042037 | validation: 0.30240864711458754]
	TIME [epoch: 27.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3257847352497108		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.3257847352497108 | validation: 0.35667422359149714]
	TIME [epoch: 27.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35088236583967347		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.35088236583967347 | validation: 0.3953673547000115]
	TIME [epoch: 27.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3170313249631522		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.3170313249631522 | validation: 0.4530286753838955]
	TIME [epoch: 27.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47481485940779655		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.47481485940779655 | validation: 0.3692541702835308]
	TIME [epoch: 27.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40986235217504574		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.40986235217504574 | validation: 0.3519222331316709]
	TIME [epoch: 27.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2987411051923834		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.2987411051923834 | validation: 0.300640279198991]
	TIME [epoch: 27.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518473567819233		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.3518473567819233 | validation: 0.3921728593295528]
	TIME [epoch: 27.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4070416900896884		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.4070416900896884 | validation: 0.3724387283036694]
	TIME [epoch: 27.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3377671169173452		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.3377671169173452 | validation: 0.3939512943965077]
	TIME [epoch: 27.8 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3408055761850889		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.3408055761850889 | validation: 0.4138642678676871]
	TIME [epoch: 27.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38836901147925623		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.38836901147925623 | validation: 0.368459705044644]
	TIME [epoch: 27.8 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3855696989288292		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.3855696989288292 | validation: 0.3650796257987677]
	TIME [epoch: 27.9 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3353427316441632		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.3353427316441632 | validation: 0.3264313461200198]
	TIME [epoch: 27.9 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40065795096085166		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.40065795096085166 | validation: 0.403500975881413]
	TIME [epoch: 27.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41271434687973496		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.41271434687973496 | validation: 0.2915847416930711]
	TIME [epoch: 27.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3221893602171705		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.3221893602171705 | validation: 0.318949080805302]
	TIME [epoch: 27.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842167243331716		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.2842167243331716 | validation: 0.24716641898145494]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_885.pth
	Model improved!!!
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3323926219206014		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.3323926219206014 | validation: 0.3151647074447764]
	TIME [epoch: 27.8 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4628245605788543		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.4628245605788543 | validation: 0.4475952805412222]
	TIME [epoch: 27.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33372002203818973		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.33372002203818973 | validation: 0.4189333320903559]
	TIME [epoch: 27.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.527380912632949		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.527380912632949 | validation: 0.35367025239950717]
	TIME [epoch: 27.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43517541942988625		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.43517541942988625 | validation: 0.41519889963433726]
	TIME [epoch: 27.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3682845368559905		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.3682845368559905 | validation: 0.5828981193227736]
	TIME [epoch: 27.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5627744633457261		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.5627744633457261 | validation: 0.4467154729986747]
	TIME [epoch: 27.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45978887435255333		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.45978887435255333 | validation: 0.3665737291437399]
	TIME [epoch: 27.8 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925387781283758		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.3925387781283758 | validation: 0.3366331607331053]
	TIME [epoch: 27.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40659743072553856		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.40659743072553856 | validation: 0.4543413728322132]
	TIME [epoch: 27.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4445769941621215		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.4445769941621215 | validation: 0.34943373835877994]
	TIME [epoch: 27.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40568666300933465		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.40568666300933465 | validation: 0.5715992652743017]
	TIME [epoch: 27.8 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49358381705888627		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.49358381705888627 | validation: 0.3332275008150024]
	TIME [epoch: 27.8 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3005063483340615		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.3005063483340615 | validation: 0.3310001183382053]
	TIME [epoch: 27.8 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3375799575780196		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.3375799575780196 | validation: 0.3583064382325917]
	TIME [epoch: 27.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3069416484715686		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.3069416484715686 | validation: 0.2854829379198013]
	TIME [epoch: 27.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2831307440456011		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.2831307440456011 | validation: 0.2686882223814764]
	TIME [epoch: 27.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31759578103787145		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.31759578103787145 | validation: 0.3496613045094347]
	TIME [epoch: 27.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4047630390136633		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.4047630390136633 | validation: 0.45705117928125183]
	TIME [epoch: 27.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39819483721315185		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.39819483721315185 | validation: 0.2887983367611667]
	TIME [epoch: 27.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37016916315164516		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.37016916315164516 | validation: 0.3078531261818206]
	TIME [epoch: 27.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3359896997327546		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.3359896997327546 | validation: 0.45112258649232245]
	TIME [epoch: 27.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3875149744488629		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.3875149744488629 | validation: 0.42973982382904213]
	TIME [epoch: 27.8 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4240723573985363		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.4240723573985363 | validation: 0.5036296344638356]
	TIME [epoch: 27.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.667009154822501		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.667009154822501 | validation: 0.5608890739421969]
	TIME [epoch: 27.9 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4931770022989368		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.4931770022989368 | validation: 0.3183920244724225]
	TIME [epoch: 27.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3854409024313048		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.3854409024313048 | validation: 0.2724201089027102]
	TIME [epoch: 27.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372290445350249		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.3372290445350249 | validation: 0.2983023114767171]
	TIME [epoch: 27.9 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32708432137116816		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.32708432137116816 | validation: 0.29899729593237123]
	TIME [epoch: 27.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34126499472049077		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.34126499472049077 | validation: 0.4694470394922492]
	TIME [epoch: 27.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5710172225788143		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.5710172225788143 | validation: 0.3042206068792777]
	TIME [epoch: 27.7 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4338733113841847		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.4338733113841847 | validation: 0.44069005233574254]
	TIME [epoch: 27.7 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4862928008951068		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.4862928008951068 | validation: 0.471984411364172]
	TIME [epoch: 27.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4603576819317967		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.4603576819317967 | validation: 0.3937934563178782]
	TIME [epoch: 27.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40336198948840657		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.40336198948840657 | validation: 0.2807680098197827]
	TIME [epoch: 27.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3126722012776202		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.3126722012776202 | validation: 0.40084600087713634]
	TIME [epoch: 27.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4191055190442031		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.4191055190442031 | validation: 0.4266652966087689]
	TIME [epoch: 27.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35645248724600354		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.35645248724600354 | validation: 0.2716988125025831]
	TIME [epoch: 27.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3209997202607262		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.3209997202607262 | validation: 0.2751046213518607]
	TIME [epoch: 27.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3504007811384918		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.3504007811384918 | validation: 0.4518825602839644]
	TIME [epoch: 27.8 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36251208888710407		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.36251208888710407 | validation: 0.5253686362773758]
	TIME [epoch: 27.7 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5241389418358858		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.5241389418358858 | validation: 0.34072916152005234]
	TIME [epoch: 27.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3020283399965788		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.3020283399965788 | validation: 0.4966326292630291]
	TIME [epoch: 27.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36141182796507426		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.36141182796507426 | validation: 0.34591362626436245]
	TIME [epoch: 27.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3634528629933964		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.3634528629933964 | validation: 0.3669736249743719]
	TIME [epoch: 27.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37993873244187343		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.37993873244187343 | validation: 0.2814157038215351]
	TIME [epoch: 27.8 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3476236732286566		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.3476236732286566 | validation: 0.6603323804960597]
	TIME [epoch: 27.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8280122697270615		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.8280122697270615 | validation: 1.0668312722232345]
	TIME [epoch: 27.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6535609139345676		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.6535609139345676 | validation: 0.2554650339961937]
	TIME [epoch: 27.8 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28243076731351024		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.28243076731351024 | validation: 0.34221276343651896]
	TIME [epoch: 27.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3247537597330386		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.3247537597330386 | validation: 0.30041365416485605]
	TIME [epoch: 27.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.315107044719578		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.315107044719578 | validation: 0.40701803571864814]
	TIME [epoch: 27.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38257336014854915		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.38257336014854915 | validation: 0.41596389965870373]
	TIME [epoch: 27.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3572222939270093		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.3572222939270093 | validation: 0.33762864876625287]
	TIME [epoch: 27.8 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34924819752199987		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.34924819752199987 | validation: 0.7071298033984548]
	TIME [epoch: 27.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5482079915805683		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.5482079915805683 | validation: 0.31942437185214556]
	TIME [epoch: 27.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33275064414922834		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.33275064414922834 | validation: 0.3437726800280144]
	TIME [epoch: 27.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4173797637264604		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.4173797637264604 | validation: 0.9328434742089097]
	TIME [epoch: 27.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7144281508067531		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.7144281508067531 | validation: 0.3830003402089829]
	TIME [epoch: 27.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933663992595666		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.3933663992595666 | validation: 0.49218280418266847]
	TIME [epoch: 27.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5611645914320004		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.5611645914320004 | validation: 0.6552329480365424]
	TIME [epoch: 27.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48096620596991674		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.48096620596991674 | validation: 0.4247896902652605]
	TIME [epoch: 27.9 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41454611277638836		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.41454611277638836 | validation: 0.5922295018921487]
	TIME [epoch: 27.7 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46773601707693685		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.46773601707693685 | validation: 0.34344453238071043]
	TIME [epoch: 27.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39085863105544655		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.39085863105544655 | validation: 0.4257218583041133]
	TIME [epoch: 27.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3531033378924509		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.3531033378924509 | validation: 0.32991098233091426]
	TIME [epoch: 27.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3772747661776444		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.3772747661776444 | validation: 0.330478004291024]
	TIME [epoch: 27.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42366272846489617		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.42366272846489617 | validation: 0.37152623587798983]
	TIME [epoch: 27.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3054212671234572		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.3054212671234572 | validation: 0.2553858499840143]
	TIME [epoch: 27.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28278851152315404		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.28278851152315404 | validation: 0.2537254161827486]
	TIME [epoch: 27.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333718340041398		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.333718340041398 | validation: 0.3488570232851004]
	TIME [epoch: 27.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40072854074808406		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.40072854074808406 | validation: 0.6985514641366939]
	TIME [epoch: 27.8 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6011492639412588		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.6011492639412588 | validation: 0.38657976582196923]
	TIME [epoch: 27.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771587732591102		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.3771587732591102 | validation: 0.2586533158311818]
	TIME [epoch: 27.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333884688979484		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.333884688979484 | validation: 0.2691394230686915]
	TIME [epoch: 27.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2880516977674451		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.2880516977674451 | validation: 0.32203069347694985]
	TIME [epoch: 27.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49373283822468655		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.49373283822468655 | validation: 0.42771522633785125]
	TIME [epoch: 27.8 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35714489514026077		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.35714489514026077 | validation: 0.40322538916721384]
	TIME [epoch: 27.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5821744430065482		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.5821744430065482 | validation: 0.5395031264502265]
	TIME [epoch: 27.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4188056993106246		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.4188056993106246 | validation: 0.29675094332698526]
	TIME [epoch: 27.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29766117633780365		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.29766117633780365 | validation: 0.28800957773281716]
	TIME [epoch: 27.9 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28837202210072		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.28837202210072 | validation: 0.27418903839742026]
	TIME [epoch: 27.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28592708762922175		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.28592708762922175 | validation: 0.31525352972575865]
	TIME [epoch: 27.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3880961140256066		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.3880961140256066 | validation: 0.6004024173565748]
	TIME [epoch: 27.8 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4358756564013829		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.4358756564013829 | validation: 0.3402589395116135]
	TIME [epoch: 27.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37102545568376716		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.37102545568376716 | validation: 0.5392616367763948]
	TIME [epoch: 27.8 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36239598823916674		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.36239598823916674 | validation: 0.24811522429566524]
	TIME [epoch: 27.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2924578811302967		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.2924578811302967 | validation: 0.2830886279476492]
	TIME [epoch: 27.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38154771193808346		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.38154771193808346 | validation: 0.3311822559440176]
	TIME [epoch: 27.8 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440761575463124		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.3440761575463124 | validation: 0.4017675197168279]
	TIME [epoch: 27.9 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3883277860441567		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.3883277860441567 | validation: 0.3308510582399628]
	TIME [epoch: 27.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31473840421996385		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.31473840421996385 | validation: 0.2673725370971429]
	TIME [epoch: 27.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32928371048084376		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.32928371048084376 | validation: 0.33551407739864575]
	TIME [epoch: 27.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29680953170704705		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.29680953170704705 | validation: 0.24648531888908692]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_979.pth
	Model improved!!!
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26804087545724997		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.26804087545724997 | validation: 0.26748119375943646]
	TIME [epoch: 27.7 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331873097493712		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.331873097493712 | validation: 0.5026602258018187]
	TIME [epoch: 27.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3244627814913496		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.3244627814913496 | validation: 0.26870860882388525]
	TIME [epoch: 27.9 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3233626460960969		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.3233626460960969 | validation: 0.2905651589870301]
	TIME [epoch: 27.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26960431379392263		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.26960431379392263 | validation: 0.25181565148345364]
	TIME [epoch: 27.8 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3090699350056948		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.3090699350056948 | validation: 0.2659858773428455]
	TIME [epoch: 27.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25567922092228035		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.25567922092228035 | validation: 0.29687304676538534]
	TIME [epoch: 27.8 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31170654302993195		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.31170654302993195 | validation: 0.3300027190741187]
	TIME [epoch: 27.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352044552905063		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.3352044552905063 | validation: 0.27380010327936843]
	TIME [epoch: 27.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31499139096881157		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.31499139096881157 | validation: 0.28586343746356646]
	TIME [epoch: 27.9 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30894726651464705		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.30894726651464705 | validation: 0.32871083389333794]
	TIME [epoch: 27.8 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.291823458412884		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.291823458412884 | validation: 0.369520067865158]
	TIME [epoch: 27.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3327397519398676		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.3327397519398676 | validation: 0.4893293912115276]
	TIME [epoch: 27.8 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4027697645978675		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.4027697645978675 | validation: 0.41632482834331114]
	TIME [epoch: 27.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925440690992124		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.2925440690992124 | validation: 0.28517870270289286]
	TIME [epoch: 27.8 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3069977141464927		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.3069977141464927 | validation: 0.4089977474804627]
	TIME [epoch: 27.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4428555808778092		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.4428555808778092 | validation: 0.45163508834245847]
	TIME [epoch: 27.8 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4562201385888812		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.4562201385888812 | validation: 0.3634770962482476]
	TIME [epoch: 27.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3502231928627196		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.3502231928627196 | validation: 0.29812614932529147]
	TIME [epoch: 27.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29116485488917837		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.29116485488917837 | validation: 0.3198925634242523]
	TIME [epoch: 27.8 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4262068532081559		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.4262068532081559 | validation: 0.2862848596623385]
	TIME [epoch: 27.8 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3199054906117329		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.3199054906117329 | validation: 0.5133864972513237]
	TIME [epoch: 27.8 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7022240813204362		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.7022240813204362 | validation: 0.5846289209992565]
	TIME [epoch: 27.8 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36164523151565064		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.36164523151565064 | validation: 0.33009091625281545]
	TIME [epoch: 27.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.317404775936707		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.317404775936707 | validation: 0.34312155445849796]
	TIME [epoch: 27.9 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3816035339807061		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.3816035339807061 | validation: 0.4053702260579928]
	TIME [epoch: 27.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3894550445269664		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.3894550445269664 | validation: 0.3704663970702854]
	TIME [epoch: 27.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5482425148326291		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.5482425148326291 | validation: 0.5611819802684471]
	TIME [epoch: 27.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42484660649845196		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.42484660649845196 | validation: 0.3819424194628458]
	TIME [epoch: 27.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3931783976179515		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.3931783976179515 | validation: 0.34394323005300337]
	TIME [epoch: 27.9 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3152721111027333		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.3152721111027333 | validation: 0.3250338869651072]
	TIME [epoch: 27.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44466955361867044		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.44466955361867044 | validation: 0.5325419680018204]
	TIME [epoch: 27.8 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5101150286246958		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.5101150286246958 | validation: 0.37041021770419746]
	TIME [epoch: 27.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35939878711243123		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.35939878711243123 | validation: 0.2883574950893359]
	TIME [epoch: 27.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3581271733161636		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.3581271733161636 | validation: 0.30529453140327883]
	TIME [epoch: 27.8 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34888333633409263		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.34888333633409263 | validation: 0.366887293125875]
	TIME [epoch: 27.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5532394288310424		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.5532394288310424 | validation: 0.7708958002490266]
	TIME [epoch: 27.9 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6123296535007163		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.6123296535007163 | validation: 0.38400479212063576]
	TIME [epoch: 27.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3455141651110515		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.3455141651110515 | validation: 0.29519671786857277]
	TIME [epoch: 27.8 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3233374822650627		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.3233374822650627 | validation: 0.3314132245593472]
	TIME [epoch: 27.8 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049010418481361		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.5049010418481361 | validation: 0.55142810749179]
	TIME [epoch: 27.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35701780282633594		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.35701780282633594 | validation: 0.2628982321516909]
	TIME [epoch: 27.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26289061610685277		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.26289061610685277 | validation: 0.3015110688137767]
	TIME [epoch: 27.9 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496739034591535		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.3496739034591535 | validation: 0.36020716414674253]
	TIME [epoch: 27.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765765123434219		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.3765765123434219 | validation: 0.3063945413028714]
	TIME [epoch: 27.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34999522416165346		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.34999522416165346 | validation: 0.5675965250312135]
	TIME [epoch: 27.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5172180025500918		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.5172180025500918 | validation: 0.46737727287836167]
	TIME [epoch: 27.9 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3258344205548256		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.3258344205548256 | validation: 0.2856531239233858]
	TIME [epoch: 27.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3428421966199284		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.3428421966199284 | validation: 0.4560707304023589]
	TIME [epoch: 27.8 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4338162403878473		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.4338162403878473 | validation: 0.2890329521798866]
	TIME [epoch: 27.8 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28146010337896066		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.28146010337896066 | validation: 0.28682402139803675]
	TIME [epoch: 27.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2608843163174537		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.2608843163174537 | validation: 0.2906085966385249]
	TIME [epoch: 27.8 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4604382060551846		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.4604382060551846 | validation: 0.6373438828568233]
	TIME [epoch: 27.8 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.419094597889527		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.419094597889527 | validation: 0.4334303749736607]
	TIME [epoch: 27.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38958389286779893		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.38958389286779893 | validation: 0.4919073162969641]
	TIME [epoch: 27.8 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3523479609346748		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.3523479609346748 | validation: 0.37880985248105886]
	TIME [epoch: 27.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35974629434420985		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.35974629434420985 | validation: 0.28327398394123804]
	TIME [epoch: 27.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3203753188384552		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.3203753188384552 | validation: 0.26564425423655974]
	TIME [epoch: 27.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28062982925593954		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.28062982925593954 | validation: 0.24559033995951937]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_1038.pth
	Model improved!!!
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28611716041536883		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.28611716041536883 | validation: 0.3579999287764712]
	TIME [epoch: 27.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3686320088945334		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.3686320088945334 | validation: 0.2690245502522642]
	TIME [epoch: 27.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2795277348094263		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.2795277348094263 | validation: 0.22947826689619802]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_1041.pth
	Model improved!!!
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25235071054765484		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.25235071054765484 | validation: 0.23852339811605702]
	TIME [epoch: 27.8 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25727567404487595		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.25727567404487595 | validation: 0.2318536107431057]
	TIME [epoch: 27.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2540106265691211		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.2540106265691211 | validation: 0.2911798275148942]
	TIME [epoch: 27.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2938108592183272		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.2938108592183272 | validation: 0.2803751090051846]
	TIME [epoch: 27.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36962465771053615		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.36962465771053615 | validation: 0.2549321404989724]
	TIME [epoch: 27.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674966056300372		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.2674966056300372 | validation: 0.23230579607674956]
	TIME [epoch: 27.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26815366432683885		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.26815366432683885 | validation: 0.23091800892234438]
	TIME [epoch: 27.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2844951069597919		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.2844951069597919 | validation: 0.26498322240618266]
	TIME [epoch: 27.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2554502392111604		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.2554502392111604 | validation: 0.21279605065804327]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_1050.pth
	Model improved!!!
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24796154079748525		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.24796154079748525 | validation: 0.22591634395975568]
	TIME [epoch: 27.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2694541636928853		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.2694541636928853 | validation: 0.2077234925589065]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240310_003041/states/model_tr_study5_1052.pth
	Model improved!!!
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586542575353886		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.2586542575353886 | validation: 0.3176177437988518]
	TIME [epoch: 28.1 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4211415039436576		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.4211415039436576 | validation: 0.525677050421737]
	TIME [epoch: 27.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48044967983840714		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.48044967983840714 | validation: 0.6550314834452378]
	TIME [epoch: 27.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4380381257093066		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.4380381257093066 | validation: 0.3168884765937655]
	TIME [epoch: 27.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2661531047022419		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.2661531047022419 | validation: 0.22570047790177622]
	TIME [epoch: 27.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2928387427730041		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.2928387427730041 | validation: 0.3744523283932826]
	TIME [epoch: 27.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3027279130728718		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.3027279130728718 | validation: 0.2758383121819237]
	TIME [epoch: 27.9 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2649907758498955		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.2649907758498955 | validation: 0.2616145833618014]
	TIME [epoch: 27.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2619793936128554		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.2619793936128554 | validation: 0.3254465229949706]
	TIME [epoch: 27.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26091345284900413		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.26091345284900413 | validation: 0.3461276162529444]
	TIME [epoch: 27.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29729684930348665		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.29729684930348665 | validation: 0.27478641411536997]
	TIME [epoch: 27.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27580890889042675		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.27580890889042675 | validation: 0.28120435681768285]
	TIME [epoch: 27.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28976762114569654		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.28976762114569654 | validation: 0.3267088455754799]
	TIME [epoch: 27.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35177892963440605		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.35177892963440605 | validation: 0.2909856537314738]
	TIME [epoch: 27.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.267691376149876		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.267691376149876 | validation: 0.2804135920389145]
	TIME [epoch: 27.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666462204841626		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.2666462204841626 | validation: 0.3227074125822565]
	TIME [epoch: 27.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3869417979586701		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.3869417979586701 | validation: 0.2886431146539932]
	TIME [epoch: 27.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34063176697958075		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.34063176697958075 | validation: 0.33551941117935535]
	TIME [epoch: 27.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30341476741845735		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.30341476741845735 | validation: 0.2964889404817265]
	TIME [epoch: 27.8 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28834883412441176		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.28834883412441176 | validation: 0.26345767840289896]
	TIME [epoch: 27.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24517307364323757		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.24517307364323757 | validation: 0.2491343832157415]
	TIME [epoch: 27.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2874936050497907		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.2874936050497907 | validation: 0.29938396318607924]
	TIME [epoch: 27.8 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31681388113092435		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.31681388113092435 | validation: 0.37560487982679136]
	TIME [epoch: 27.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31383151761504197		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.31383151761504197 | validation: 0.25565983218144445]
	TIME [epoch: 27.8 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24091319200416988		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.24091319200416988 | validation: 0.3387932090877713]
	TIME [epoch: 27.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3952562196219185		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.3952562196219185 | validation: 0.45339726092972477]
	TIME [epoch: 27.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42061505608097666		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.42061505608097666 | validation: 0.3008877828639896]
	TIME [epoch: 27.9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.265079503101351		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.265079503101351 | validation: 0.2761613583326153]
	TIME [epoch: 27.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28368894376513054		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.28368894376513054 | validation: 0.3037564248831113]
	TIME [epoch: 27.8 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29254606601456346		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.29254606601456346 | validation: 0.2681752853482592]
	TIME [epoch: 27.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33787049764849836		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.33787049764849836 | validation: 0.310502503947997]
	TIME [epoch: 27.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24974237208658856		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.24974237208658856 | validation: 0.24330603656031818]
	TIME [epoch: 27.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24647560060694093		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.24647560060694093 | validation: 0.2601221036141713]
	TIME [epoch: 27.9 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2493651058581855		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.2493651058581855 | validation: 0.22480182684707337]
	TIME [epoch: 27.8 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24182065225471047		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.24182065225471047 | validation: 0.2879900566257577]
	TIME [epoch: 27.9 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26233310685453154		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.26233310685453154 | validation: 0.24539836573340762]
	TIME [epoch: 27.9 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27955837497100633		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.27955837497100633 | validation: 0.3469867979569004]
	TIME [epoch: 27.8 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31038002708527745		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.31038002708527745 | validation: 0.36065524634812846]
	TIME [epoch: 27.9 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2701811299299135		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.2701811299299135 | validation: 0.2791255725073952]
	TIME [epoch: 27.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2566709690842126		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.2566709690842126 | validation: 0.2269846271840365]
	TIME [epoch: 27.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2268419919387974		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.2268419919387974 | validation: 0.2284887465049769]
	TIME [epoch: 27.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2517420944302777		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.2517420944302777 | validation: 0.2937618707308659]
	TIME [epoch: 27.9 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25825269511706117		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.25825269511706117 | validation: 0.22180050832148762]
	TIME [epoch: 27.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2488013392632361		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.2488013392632361 | validation: 0.2671334652797134]
	TIME [epoch: 27.9 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2781298368471427		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.2781298368471427 | validation: 0.25062670473156096]
	TIME [epoch: 27.9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2895202948583403		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.2895202948583403 | validation: 0.374760776972655]
	TIME [epoch: 27.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3292703496273794		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.3292703496273794 | validation: 0.2570962164770452]
	TIME [epoch: 27.9 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2774412417264357		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.2774412417264357 | validation: 0.2757860208455651]
	TIME [epoch: 27.9 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3246066497828411		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.3246066497828411 | validation: 0.32901339365085974]
	TIME [epoch: 27.8 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3102411680708703		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.3102411680708703 | validation: 0.2650683685568727]
	TIME [epoch: 27.9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3913666518884619		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.3913666518884619 | validation: 0.3330016880925021]
	TIME [epoch: 27.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2673289479543825		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.2673289479543825 | validation: 0.25258745429699947]
	TIME [epoch: 27.8 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27943947820386633		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.27943947820386633 | validation: 0.3003396840025964]
	TIME [epoch: 27.9 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33054945076061804		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.33054945076061804 | validation: 0.3491338324946088]
	TIME [epoch: 27.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2983611240144102		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.2983611240144102 | validation: 0.2440278517003637]
	TIME [epoch: 27.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3013671520358277		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.3013671520358277 | validation: 0.3618561013333513]
	TIME [epoch: 27.9 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3819289562182766		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.3819289562182766 | validation: 0.3755332339198598]
	TIME [epoch: 27.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3394722210560779		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.3394722210560779 | validation: 0.30796899532908967]
	TIME [epoch: 27.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3794740551821003		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.3794740551821003 | validation: 0.3085548976092886]
	TIME [epoch: 27.9 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3099911770018881		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.3099911770018881 | validation: 0.39482571181072884]
	TIME [epoch: 27.8 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30474687769278064		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.30474687769278064 | validation: 0.23623673137826942]
	TIME [epoch: 27.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23227042358937017		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.23227042358937017 | validation: 0.21834865890635993]
	TIME [epoch: 27.9 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24017332478473746		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.24017332478473746 | validation: 0.26508093079582656]
	TIME [epoch: 27.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2359500671608939		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.2359500671608939 | validation: 0.2277378160906997]
	TIME [epoch: 27.9 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2797099470654486		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.2797099470654486 | validation: 0.3292420246945831]
	TIME [epoch: 27.9 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454558393312995		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.3454558393312995 | validation: 0.213479199088497]
	TIME [epoch: 27.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28224223268551796		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.28224223268551796 | validation: 0.4065582586473813]
	TIME [epoch: 27.9 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2807861908951895		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.2807861908951895 | validation: 0.21470974757341071]
	TIME [epoch: 27.9 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24710595128616653		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.24710595128616653 | validation: 0.20975612231239965]
	TIME [epoch: 27.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24217504963025727		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.24217504963025727 | validation: 0.24607505649706254]
	TIME [epoch: 27.9 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26506844793261175		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.26506844793261175 | validation: 0.27198643794208593]
	TIME [epoch: 27.9 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25203541892956777		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.25203541892956777 | validation: 0.21309481522951745]
	TIME [epoch: 27.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24818553265283755		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.24818553265283755 | validation: 0.289906672308092]
	TIME [epoch: 27.9 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2638725956431157		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.2638725956431157 | validation: 0.2313748196571245]
	TIME [epoch: 27.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2927591060719604		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.2927591060719604 | validation: 0.3037329263068395]
	TIME [epoch: 27.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764494614772885		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.2764494614772885 | validation: 0.31221506339294436]
	TIME [epoch: 27.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3348650072158287		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.3348650072158287 | validation: 0.28367843227057266]
	TIME [epoch: 27.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27454038878105164		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.27454038878105164 | validation: 0.2745919325652911]
	TIME [epoch: 27.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2944447496964562		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.2944447496964562 | validation: 0.28286316196140227]
	TIME [epoch: 27.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3392748489885345		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.3392748489885345 | validation: 0.27326416793026614]
	TIME [epoch: 27.8 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2826332551319917		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.2826332551319917 | validation: 0.2919665294604216]
	TIME [epoch: 27.8 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26976888027571455		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.26976888027571455 | validation: 0.24218408566381644]
	TIME [epoch: 27.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.244998334166925		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.244998334166925 | validation: 0.249152347450257]
	TIME [epoch: 27.8 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2410875749628766		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.2410875749628766 | validation: 0.24351680305727438]
	TIME [epoch: 27.8 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858762831117829		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.2858762831117829 | validation: 0.26866431598296264]
	TIME [epoch: 27.8 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2575329677210618		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.2575329677210618 | validation: 0.23912300330153521]
	TIME [epoch: 27.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595793282128066		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.2595793282128066 | validation: 0.40524500860969753]
	TIME [epoch: 27.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32180556529190374		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.32180556529190374 | validation: 0.227949685907529]
	TIME [epoch: 27.9 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26996120582930305		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.26996120582930305 | validation: 0.3279837354813027]
	TIME [epoch: 27.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30397346295473937		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.30397346295473937 | validation: 0.2390754462793702]
	TIME [epoch: 27.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.245739503422565		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.245739503422565 | validation: 0.23132792295967342]
	TIME [epoch: 27.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2296219939315079		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.2296219939315079 | validation: 0.26254738265285815]
	TIME [epoch: 27.8 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2710409790842993		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.2710409790842993 | validation: 0.25195158438190585]
	TIME [epoch: 27.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28491752093755285		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.28491752093755285 | validation: 0.4407285427286052]
	TIME [epoch: 27.9 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3309675243542226		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.3309675243542226 | validation: 0.3536960366752145]
	TIME [epoch: 27.8 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2800866861837593		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.2800866861837593 | validation: 0.23967058889107634]
	TIME [epoch: 27.9 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26406585044712255		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.26406585044712255 | validation: 0.34244613024101855]
	TIME [epoch: 27.9 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26114998833625036		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.26114998833625036 | validation: 0.2337685429003089]
	TIME [epoch: 27.8 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24070736558310507		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.24070736558310507 | validation: 0.3176235311796815]
	TIME [epoch: 27.8 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285942020114278		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.285942020114278 | validation: 0.2519969103040248]
	TIME [epoch: 27.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876204812395128		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.2876204812395128 | validation: 0.24226623163971645]
	TIME [epoch: 27.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2255121492599002		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.2255121492599002 | validation: 0.22436989880707603]
	TIME [epoch: 27.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2399230549979236		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.2399230549979236 | validation: 0.22712917551099096]
	TIME [epoch: 27.9 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23285186008194678		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.23285186008194678 | validation: 0.24678223727204213]
	TIME [epoch: 27.8 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25863608451000475		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.25863608451000475 | validation: 0.2508637196112171]
	TIME [epoch: 27.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2236651244869432		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.2236651244869432 | validation: 0.27250330478368306]
	TIME [epoch: 27.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3188959461299155		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.3188959461299155 | validation: 0.3528693562768341]
	TIME [epoch: 27.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29478611228624935		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.29478611228624935 | validation: 0.26995960957137277]
	TIME [epoch: 27.8 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000323866069101		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.3000323866069101 | validation: 0.29907402441821895]
	TIME [epoch: 27.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29622903665344646		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.29622903665344646 | validation: 0.23519477707815578]
	TIME [epoch: 27.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2549834462010042		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.2549834462010042 | validation: 0.27719358601103744]
	TIME [epoch: 27.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758766483126127		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.2758766483126127 | validation: 0.25840773497935265]
	TIME [epoch: 27.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29147856117177356		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.29147856117177356 | validation: 0.23184193793354843]
	TIME [epoch: 27.8 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2502014214793726		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.2502014214793726 | validation: 0.27704652095672594]
	TIME [epoch: 27.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26097504993390397		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.26097504993390397 | validation: 0.3766688940886472]
	TIME [epoch: 27.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31812447169443536		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.31812447169443536 | validation: 0.33157440102320634]
	TIME [epoch: 27.9 sec]
EPOCH 1169/2000:
	Training over batches...
