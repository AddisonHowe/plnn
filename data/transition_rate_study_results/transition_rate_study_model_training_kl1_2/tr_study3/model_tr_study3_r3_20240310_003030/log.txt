Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r3', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2247357576

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.968431711142244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.968431711142244 | validation: 8.705901806933099]
	TIME [epoch: 89.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.444156748829123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.444156748829123 | validation: 9.455239851767388]
	TIME [epoch: 13 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.27498554607082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.27498554607082 | validation: 7.2800851120525305]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.116799046754812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.116799046754812 | validation: 7.760420522133246]
	TIME [epoch: 12.9 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.048568001606826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.048568001606826 | validation: 6.539692746230569]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.677159142246792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.677159142246792 | validation: 6.763468068143286]
	TIME [epoch: 12.9 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.94602415682862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.94602415682862 | validation: 6.589909288291779]
	TIME [epoch: 12.9 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.569655309952292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.569655309952292 | validation: 6.434513001784929]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.537759190836647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.537759190836647 | validation: 6.365084253685421]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.590054356022367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.590054356022367 | validation: 6.237232855441627]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.402735920692606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.402735920692606 | validation: 6.368199667022629]
	TIME [epoch: 12.9 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.35480379352331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.35480379352331 | validation: 5.876279286670593]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.075553556452859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.075553556452859 | validation: 5.677873151403998]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.945433726825442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.945433726825442 | validation: 5.432000050655062]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.654029932119376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.654029932119376 | validation: 5.220031308252607]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.749398956514163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.749398956514163 | validation: 6.112018703110553]
	TIME [epoch: 13 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5031173506908155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5031173506908155 | validation: 5.316612058167273]
	TIME [epoch: 12.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.59881498542532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.59881498542532 | validation: 5.236859980817603]
	TIME [epoch: 12.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.528828850038971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.528828850038971 | validation: 5.596324217365226]
	TIME [epoch: 13 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.633247951279235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.633247951279235 | validation: 4.90742430938747]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.118975974123571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.118975974123571 | validation: 6.0121869107386985]
	TIME [epoch: 12.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.167241629113777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.167241629113777 | validation: 6.047153043616104]
	TIME [epoch: 13 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.680664417247408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.680664417247408 | validation: 4.889128087523516]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9964924900210566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9964924900210566 | validation: 5.475872830168762]
	TIME [epoch: 12.9 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.830141496501833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.830141496501833 | validation: 5.905181343891566]
	TIME [epoch: 13 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.20233809428521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.20233809428521 | validation: 5.669655733507791]
	TIME [epoch: 12.9 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.101886680902506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.101886680902506 | validation: 4.343125578892725]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.625427267980685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.625427267980685 | validation: 4.650815734758255]
	TIME [epoch: 12.9 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.52920790750901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.52920790750901 | validation: 5.0789155150816905]
	TIME [epoch: 13 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.376889027004289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.376889027004289 | validation: 5.784534518550147]
	TIME [epoch: 12.9 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.020049573333108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.020049573333108 | validation: 4.406005293947664]
	TIME [epoch: 13 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452718376675738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.452718376675738 | validation: 5.135210190733967]
	TIME [epoch: 13 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.894748484658315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.894748484658315 | validation: 4.9482287160100595]
	TIME [epoch: 12.9 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.931001978715469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.931001978715469 | validation: 4.620700988600952]
	TIME [epoch: 12.9 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.001323681971114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.001323681971114 | validation: 5.634840225795492]
	TIME [epoch: 13 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.121353930593736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.121353930593736 | validation: 3.993776481403685]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.328178439906536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.328178439906536 | validation: 4.845721665984004]
	TIME [epoch: 13 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.508068339732809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.508068339732809 | validation: 4.872188058309048]
	TIME [epoch: 13 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8741390826820705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8741390826820705 | validation: 4.60341386880358]
	TIME [epoch: 13 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.549199512774077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.549199512774077 | validation: 3.8664354694887253]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5099712864311154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5099712864311154 | validation: 4.502274750768366]
	TIME [epoch: 13 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.288105031919639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.288105031919639 | validation: 3.872613598860586]
	TIME [epoch: 13 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.071358347788846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.071358347788846 | validation: 3.9425061996604986]
	TIME [epoch: 12.9 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8477205753372674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8477205753372674 | validation: 5.9661604704613795]
	TIME [epoch: 13 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.606388230463214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.606388230463214 | validation: 4.397462318186274]
	TIME [epoch: 13 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.439009636690854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.439009636690854 | validation: 3.7841880920420534]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.100548081072249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.100548081072249 | validation: 4.004533143625617]
	TIME [epoch: 12.9 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.067967904915156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.067967904915156 | validation: 4.664537458980007]
	TIME [epoch: 13 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461245136264957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.461245136264957 | validation: 4.2225856124998735]
	TIME [epoch: 12.9 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9716825309704413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9716825309704413 | validation: 3.9798041680855007]
	TIME [epoch: 12.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.071938912398604		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.071938912398604 | validation: 4.570067666659129]
	TIME [epoch: 13 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.32916957097016		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.32916957097016 | validation: 4.246319730695677]
	TIME [epoch: 13 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.785619073845432		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.785619073845432 | validation: 4.024079130220507]
	TIME [epoch: 13 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.00520599998859		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.00520599998859 | validation: 3.687482021018037]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.412260709755255		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.412260709755255 | validation: 3.9955679567974314]
	TIME [epoch: 13 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.092370574556298		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.092370574556298 | validation: 4.248047461779278]
	TIME [epoch: 13 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.107580671433633		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.107580671433633 | validation: 5.0480453646231505]
	TIME [epoch: 13 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.115139543709569		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.115139543709569 | validation: 3.672802320287674]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.645729928328656		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.645729928328656 | validation: 5.05266345176945]
	TIME [epoch: 13 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.392996754844927		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.392996754844927 | validation: 3.770479346530522]
	TIME [epoch: 13 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.645820175213209		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.645820175213209 | validation: 3.7261190269032705]
	TIME [epoch: 13 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8817862218458576		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.8817862218458576 | validation: 3.27583521678568]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7412623467339623		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.7412623467339623 | validation: 3.7363929633792248]
	TIME [epoch: 13 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6986929913054607		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.6986929913054607 | validation: 4.1441165226135945]
	TIME [epoch: 13 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9938289841922905		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.9938289841922905 | validation: 7.089121220326504]
	TIME [epoch: 13 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.411212989147597		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 6.411212989147597 | validation: 4.16980125014505]
	TIME [epoch: 13 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9081802183086416		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.9081802183086416 | validation: 3.6313143739654197]
	TIME [epoch: 12.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.542576184479402		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.542576184479402 | validation: 5.046828315803144]
	TIME [epoch: 13 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.266655852739725		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.266655852739725 | validation: 3.6698955520379752]
	TIME [epoch: 13 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.774956625713389		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.774956625713389 | validation: 3.285547908324003]
	TIME [epoch: 12.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3882559189968755		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.3882559189968755 | validation: 3.8653487057853613]
	TIME [epoch: 12.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.451057818225169		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.451057818225169 | validation: 3.852351893175409]
	TIME [epoch: 13 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.43762689262009		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.43762689262009 | validation: 3.2168144023508236]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.182952048308293		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.182952048308293 | validation: 3.9220289144726723]
	TIME [epoch: 13 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.194872923111003		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.194872923111003 | validation: 3.186579293210107]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1212312815236505		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.1212312815236505 | validation: 2.9148541708688294]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.284539586426734		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.284539586426734 | validation: 2.7391954508801075]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0798192186576516		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.0798192186576516 | validation: 2.8857123658762327]
	TIME [epoch: 12.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.123718626254889		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.123718626254889 | validation: 2.6324655093111864]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6218803800499275		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.6218803800499275 | validation: 4.22408475409854]
	TIME [epoch: 12.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.54683541371655		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 8.54683541371655 | validation: 11.077856909981861]
	TIME [epoch: 12.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.822665265139936		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 9.822665265139936 | validation: 6.7553758591311155]
	TIME [epoch: 12.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.594030865411075		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 5.594030865411075 | validation: 4.1362133591917845]
	TIME [epoch: 12.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.977704505382735		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.977704505382735 | validation: 3.387037176568484]
	TIME [epoch: 12.9 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.507941999265429		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.507941999265429 | validation: 2.99709063640737]
	TIME [epoch: 12.9 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.583185983557045		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.583185983557045 | validation: 3.4521054890441425]
	TIME [epoch: 12.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6656432483554466		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.6656432483554466 | validation: 3.0458709304072817]
	TIME [epoch: 12.9 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3804858916576257		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.3804858916576257 | validation: 2.8303394025738964]
	TIME [epoch: 12.9 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.950719916914842		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.950719916914842 | validation: 6.252036364889145]
	TIME [epoch: 13 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4961431558637095		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.4961431558637095 | validation: 3.4033134165212564]
	TIME [epoch: 12.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0944288194766676		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.0944288194766676 | validation: 3.2053927983795054]
	TIME [epoch: 12.9 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.172010614803267		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.172010614803267 | validation: 2.661472131856666]
	TIME [epoch: 13 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8989577569987386		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.8989577569987386 | validation: 3.4426826162397437]
	TIME [epoch: 12.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.460366650661541		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.460366650661541 | validation: 3.71371133769164]
	TIME [epoch: 12.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8896884811391708		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.8896884811391708 | validation: 2.4334734813325234]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.049868964437807		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.049868964437807 | validation: 3.1141795814953817]
	TIME [epoch: 13 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9113882846234573		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.9113882846234573 | validation: 2.873089769986202]
	TIME [epoch: 12.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.827871044489095		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.827871044489095 | validation: 2.6687614146263856]
	TIME [epoch: 12.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0989195568606758		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.0989195568606758 | validation: 2.702635476097388]
	TIME [epoch: 13 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20265685179027		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.20265685179027 | validation: 2.804314908717539]
	TIME [epoch: 12.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.875263538949687		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.875263538949687 | validation: 2.569093800552388]
	TIME [epoch: 12.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.931648741777788		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.931648741777788 | validation: 2.7351435890569746]
	TIME [epoch: 13 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7254651000671983		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.7254651000671983 | validation: 2.361837301532474]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.756761221683798		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.756761221683798 | validation: 2.6593547856364204]
	TIME [epoch: 12.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1195432942538033		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.1195432942538033 | validation: 2.2761387755225733]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8581686842142733		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.8581686842142733 | validation: 2.4792382434309035]
	TIME [epoch: 13 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.634082573648999		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.634082573648999 | validation: 3.157717293359116]
	TIME [epoch: 12.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.863647934407633		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.863647934407633 | validation: 2.503252641016335]
	TIME [epoch: 12.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.591265258480962		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.591265258480962 | validation: 2.578629283696797]
	TIME [epoch: 13 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.634721283818981		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.634721283818981 | validation: 2.4379140499715497]
	TIME [epoch: 13 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.485511822212714		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.485511822212714 | validation: 3.1948992567340384]
	TIME [epoch: 12.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8436329001997818		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.8436329001997818 | validation: 2.66869296072353]
	TIME [epoch: 12.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6660191463544294		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.6660191463544294 | validation: 2.5117468835591095]
	TIME [epoch: 13 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2618989619536953		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.2618989619536953 | validation: 2.4311223034871756]
	TIME [epoch: 12.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.775654644752472		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.775654644752472 | validation: 2.2914808593219194]
	TIME [epoch: 13 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.854457607010325		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.854457607010325 | validation: 2.0276415773441974]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.514258123302457		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.514258123302457 | validation: 3.0036752988705655]
	TIME [epoch: 13 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.780056013135391		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.780056013135391 | validation: 2.535716591341262]
	TIME [epoch: 12.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358868818559375		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.358868818559375 | validation: 2.190879880516164]
	TIME [epoch: 13 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2087721034062042		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.2087721034062042 | validation: 3.0163692428464577]
	TIME [epoch: 13 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.154356609082286		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.154356609082286 | validation: 3.2840898930170797]
	TIME [epoch: 12.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.458978678933091		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.458978678933091 | validation: 2.8998496374666645]
	TIME [epoch: 12.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6229709822464438		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.6229709822464438 | validation: 2.2640813316613837]
	TIME [epoch: 13 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276936354974251		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.276936354974251 | validation: 1.9585332891936995]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4634330664017257		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.4634330664017257 | validation: 2.0615635094420095]
	TIME [epoch: 13 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3845363505065142		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.3845363505065142 | validation: 2.0857285382577397]
	TIME [epoch: 13 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.144110363078336		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.144110363078336 | validation: 2.7421468644440137]
	TIME [epoch: 13 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2089181035587075		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.2089181035587075 | validation: 2.070064724057077]
	TIME [epoch: 13 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.459943440053748		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.459943440053748 | validation: 2.4365465526875405]
	TIME [epoch: 13 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1551647958013493		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.1551647958013493 | validation: 2.128957094132529]
	TIME [epoch: 13 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.408741567651324		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.408741567651324 | validation: 2.668887061152199]
	TIME [epoch: 13 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242763650802631		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.242763650802631 | validation: 1.8951335947405352]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0439565074594555		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.0439565074594555 | validation: 1.8652897351704525]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0715371909367954		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.0715371909367954 | validation: 1.974490919831929]
	TIME [epoch: 12.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9376920948655252		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.9376920948655252 | validation: 1.8301045091370862]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8854782325174755		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.8854782325174755 | validation: 2.618320422932237]
	TIME [epoch: 13 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293772789915871		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.293772789915871 | validation: 1.6751181846323535]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.918895026470234		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.918895026470234 | validation: 1.426982145058417]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6805509860310797		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.6805509860310797 | validation: 2.045730356016238]
	TIME [epoch: 12.9 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7425902404698363		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.7425902404698363 | validation: 2.095752022441412]
	TIME [epoch: 12.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6512729178625305		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.6512729178625305 | validation: 1.8342895550227951]
	TIME [epoch: 12.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4184198531745347		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.4184198531745347 | validation: 1.9864697574244923]
	TIME [epoch: 12.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9363480032214884		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.9363480032214884 | validation: 1.8579667807801163]
	TIME [epoch: 12.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8325069286789424		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.8325069286789424 | validation: 1.6977866959948649]
	TIME [epoch: 12.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7904151135360133		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.7904151135360133 | validation: 2.0304453416921273]
	TIME [epoch: 12.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8913152704732026		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.8913152704732026 | validation: 1.3769053170350527]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.715982045630807		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.715982045630807 | validation: 1.7610500868909091]
	TIME [epoch: 13 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7598462361605725		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.7598462361605725 | validation: 1.9174453543965098]
	TIME [epoch: 12.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7465896025976373		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.7465896025976373 | validation: 1.4749549748885356]
	TIME [epoch: 13 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7927987735728865		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.7927987735728865 | validation: 3.0100193367358816]
	TIME [epoch: 13 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9861285441699161		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.9861285441699161 | validation: 1.5059454646839932]
	TIME [epoch: 12.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7881249418008955		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.7881249418008955 | validation: 1.8487501774612343]
	TIME [epoch: 13 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9014211563228565		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.9014211563228565 | validation: 1.3919399938021457]
	TIME [epoch: 12.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7380632563964813		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.7380632563964813 | validation: 1.5366962734043546]
	TIME [epoch: 13 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6314547952257905		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.6314547952257905 | validation: 1.7644334068610625]
	TIME [epoch: 13 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6555496747654015		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.6555496747654015 | validation: 1.436231184151672]
	TIME [epoch: 13 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.053183045262696		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.053183045262696 | validation: 1.5874965909925254]
	TIME [epoch: 13 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9530712778708073		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.9530712778708073 | validation: 1.6083753364262985]
	TIME [epoch: 13 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7496839503170984		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.7496839503170984 | validation: 1.3503701461346873]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5677824187774743		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.5677824187774743 | validation: 1.6753010298056499]
	TIME [epoch: 13 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5140766056265067		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.5140766056265067 | validation: 2.9817269848614205]
	TIME [epoch: 13 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0937431259446155		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.0937431259446155 | validation: 2.165644863684975]
	TIME [epoch: 12.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7988592656064137		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.7988592656064137 | validation: 1.6870908042301778]
	TIME [epoch: 12.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.704140202072896		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.704140202072896 | validation: 1.5059466061377003]
	TIME [epoch: 13 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5170758456958096		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.5170758456958096 | validation: 1.8962892354890826]
	TIME [epoch: 13 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6193174119465072		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.6193174119465072 | validation: 1.5612583834343028]
	TIME [epoch: 13 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.549714090968016		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.549714090968016 | validation: 1.4553801116764018]
	TIME [epoch: 13 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5395316620657788		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.5395316620657788 | validation: 1.6312858886433115]
	TIME [epoch: 13 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6799830539205227		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.6799830539205227 | validation: 1.2835454172915308]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4496481727583321		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.4496481727583321 | validation: 3.4186418322300023]
	TIME [epoch: 13 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4433032702956594		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.4433032702956594 | validation: 2.346629027225709]
	TIME [epoch: 13 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6698465576682013		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.6698465576682013 | validation: 1.2484411003162832]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4488127602450902		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.4488127602450902 | validation: 1.6596730469890129]
	TIME [epoch: 13 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5651457030047415		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.5651457030047415 | validation: 1.3991682832612669]
	TIME [epoch: 13 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.501341303851367		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.501341303851367 | validation: 1.4028198353856407]
	TIME [epoch: 13 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.510414164032508		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.510414164032508 | validation: 1.670624289749732]
	TIME [epoch: 13 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5883093395590466		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.5883093395590466 | validation: 1.1888553525005625]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5473642588529992		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.5473642588529992 | validation: 1.0434002687647932]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3990269751263966		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.3990269751263966 | validation: 1.8714545045746749]
	TIME [epoch: 13 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9655929961798475		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.9655929961798475 | validation: 1.9803706160456578]
	TIME [epoch: 12.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6248937273141537		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.6248937273141537 | validation: 1.1069576044311995]
	TIME [epoch: 13 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6335412890879237		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.6335412890879237 | validation: 1.3415647118271314]
	TIME [epoch: 13 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4171114777333043		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.4171114777333043 | validation: 1.2422004673873335]
	TIME [epoch: 13 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.49194997433197		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.49194997433197 | validation: 2.3597746561352553]
	TIME [epoch: 13 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.663017456739081		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.663017456739081 | validation: 3.1804100612192365]
	TIME [epoch: 13 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.222285666775115		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.222285666775115 | validation: 3.6025762147668683]
	TIME [epoch: 12.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2768335845044243		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.2768335845044243 | validation: 2.03960341276691]
	TIME [epoch: 13 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.545268749369704		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.545268749369704 | validation: 1.0994845469516872]
	TIME [epoch: 13 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3379338913688499		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.3379338913688499 | validation: 1.173203098011434]
	TIME [epoch: 13 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3319397747339834		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.3319397747339834 | validation: 1.1044387171617613]
	TIME [epoch: 13 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.360317166718032		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.360317166718032 | validation: 4.965529687382973]
	TIME [epoch: 13 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8637188998528633		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.8637188998528633 | validation: 2.21435070176629]
	TIME [epoch: 13 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.994656918039922		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.994656918039922 | validation: 1.8265784262319154]
	TIME [epoch: 13 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0339988346360007		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.0339988346360007 | validation: 2.3052559779241037]
	TIME [epoch: 13 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5731225281609398		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.5731225281609398 | validation: 1.4596228142989527]
	TIME [epoch: 13 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6168735106163763		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.6168735106163763 | validation: 3.004331278207733]
	TIME [epoch: 13 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.001163577030068		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.001163577030068 | validation: 1.2973199670529374]
	TIME [epoch: 12.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3411754342857116		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.3411754342857116 | validation: 1.716826267905311]
	TIME [epoch: 13 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4052996322573614		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.4052996322573614 | validation: 2.470716753104641]
	TIME [epoch: 12.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9723385672667648		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.9723385672667648 | validation: 1.924358585383161]
	TIME [epoch: 13 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8043160259357665		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.8043160259357665 | validation: 2.2547790287060803]
	TIME [epoch: 13 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063406706351315		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.063406706351315 | validation: 1.780749887158418]
	TIME [epoch: 13 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7146985233698895		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.7146985233698895 | validation: 2.201040964133252]
	TIME [epoch: 12.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.726924249441521		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.726924249441521 | validation: 2.109031823111187]
	TIME [epoch: 13 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6103080611184442		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.6103080611184442 | validation: 1.335923846031031]
	TIME [epoch: 13 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.08147421744663		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.08147421744663 | validation: 2.3140541439771365]
	TIME [epoch: 13 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9221114398273782		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.9221114398273782 | validation: 1.8863222201808754]
	TIME [epoch: 13 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7845924712136438		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.7845924712136438 | validation: 1.2810537141952392]
	TIME [epoch: 13 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3417629102153759		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.3417629102153759 | validation: 1.3209074654358894]
	TIME [epoch: 13 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3997210917495668		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.3997210917495668 | validation: 2.139625223318674]
	TIME [epoch: 13 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.072493956938965		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.072493956938965 | validation: 1.6244793837498488]
	TIME [epoch: 13 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5551729487943624		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.5551729487943624 | validation: 1.1163344088079403]
	TIME [epoch: 13 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5778471101297908		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.5778471101297908 | validation: 1.1589958901841866]
	TIME [epoch: 13 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3231406648959585		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.3231406648959585 | validation: 1.1290733455098891]
	TIME [epoch: 13 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3117792102090224		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.3117792102090224 | validation: 1.2188443819919084]
	TIME [epoch: 13 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3605590296371548		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.3605590296371548 | validation: 1.1298624876338983]
	TIME [epoch: 13 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2903009801875707		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.2903009801875707 | validation: 1.1719875855217854]
	TIME [epoch: 13 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4113127589214798		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.4113127589214798 | validation: 0.9042816139905479]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1973771684813026		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.1973771684813026 | validation: 0.791259981615363]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3277119113016194		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.3277119113016194 | validation: 1.6373422499391221]
	TIME [epoch: 13 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6216513327686475		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.6216513327686475 | validation: 0.9332834289998329]
	TIME [epoch: 13 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3838373730707239		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.3838373730707239 | validation: 1.061878486860156]
	TIME [epoch: 13 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.091583299904489		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.091583299904489 | validation: 1.0624149343229201]
	TIME [epoch: 13 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2152322534740223		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.2152322534740223 | validation: 0.9154604872820113]
	TIME [epoch: 13 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0910969049662933		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.0910969049662933 | validation: 1.0584774909008232]
	TIME [epoch: 13 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1285390428965552		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.1285390428965552 | validation: 0.8811925620322257]
	TIME [epoch: 13 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0887593453198803		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.0887593453198803 | validation: 1.006648264374399]
	TIME [epoch: 13 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3240508111576634		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.3240508111576634 | validation: 0.7984981440288967]
	TIME [epoch: 13 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2220720570033305		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.2220720570033305 | validation: 0.8965803878468688]
	TIME [epoch: 13 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3463532888132144		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.3463532888132144 | validation: 1.0477636679859834]
	TIME [epoch: 13 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1292661834331734		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.1292661834331734 | validation: 1.1740645510795125]
	TIME [epoch: 13 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.014105498103736		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.014105498103736 | validation: 0.6986379140116722]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0885684981336612		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.0885684981336612 | validation: 0.9749437155015673]
	TIME [epoch: 13 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0934657017452105		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.0934657017452105 | validation: 1.3835524628433586]
	TIME [epoch: 13 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153093886898102		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.153093886898102 | validation: 0.7265274878503354]
	TIME [epoch: 13 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.088449003919801		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.088449003919801 | validation: 0.7388454748715283]
	TIME [epoch: 13 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0417284781429157		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.0417284781429157 | validation: 2.8903496125108075]
	TIME [epoch: 13 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9144289510406118		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.9144289510406118 | validation: 1.8908602728110173]
	TIME [epoch: 13 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6102189581784865		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.6102189581784865 | validation: 1.8928348854434864]
	TIME [epoch: 13 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.467016418158878		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.467016418158878 | validation: 2.405293099935242]
	TIME [epoch: 13 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4641767219087245		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.4641767219087245 | validation: 2.1057689336754635]
	TIME [epoch: 13 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4489955911663044		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.4489955911663044 | validation: 2.3420577210335516]
	TIME [epoch: 13 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5288287018054305		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.5288287018054305 | validation: 1.7314127669700288]
	TIME [epoch: 13 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.209344246789552		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.209344246789552 | validation: 1.115114491305575]
	TIME [epoch: 13 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.113976829262717		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.113976829262717 | validation: 0.8145948880010337]
	TIME [epoch: 13 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0163141033032472		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.0163141033032472 | validation: 0.968106651462069]
	TIME [epoch: 13 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3134348469414536		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.3134348469414536 | validation: 2.294616114694005]
	TIME [epoch: 13 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5047486890808268		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.5047486890808268 | validation: 2.1621109091805137]
	TIME [epoch: 13 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5344286254307373		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.5344286254307373 | validation: 1.6958860546918075]
	TIME [epoch: 13 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3536572027112603		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.3536572027112603 | validation: 1.5436910204525283]
	TIME [epoch: 13 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3833879659401758		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.3833879659401758 | validation: 1.7456783021969475]
	TIME [epoch: 13 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2860903050961383		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.2860903050961383 | validation: 1.7270895842177374]
	TIME [epoch: 13 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4637105478623422		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.4637105478623422 | validation: 1.9583381557711408]
	TIME [epoch: 13 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4692986992366528		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.4692986992366528 | validation: 1.2183114909779107]
	TIME [epoch: 13 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0941548692828935		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.0941548692828935 | validation: 1.8518826614942974]
	TIME [epoch: 13 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4629227326100571		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.4629227326100571 | validation: 1.566886294875171]
	TIME [epoch: 13 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.148927473148852		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.148927473148852 | validation: 1.873202284287105]
	TIME [epoch: 13 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4732975362405698		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.4732975362405698 | validation: 1.6329852578352462]
	TIME [epoch: 13 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2069127625174945		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.2069127625174945 | validation: 1.0707324108590905]
	TIME [epoch: 13 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1964695117076198		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.1964695117076198 | validation: 0.8811607525999976]
	TIME [epoch: 13 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0072141725534272		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.0072141725534272 | validation: 1.7689253618061584]
	TIME [epoch: 13 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5377904228033286		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.5377904228033286 | validation: 1.3798307643947851]
	TIME [epoch: 13 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.59100741251001		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.59100741251001 | validation: 2.414347145479007]
	TIME [epoch: 13 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6157099403785116		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.6157099403785116 | validation: 1.278177229147049]
	TIME [epoch: 13 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4438421504529346		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.4438421504529346 | validation: 1.7069821689927898]
	TIME [epoch: 13 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1860566413350968		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.1860566413350968 | validation: 0.9196374541019186]
	TIME [epoch: 13 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.108036250127892		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.108036250127892 | validation: 1.719360128576618]
	TIME [epoch: 13 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.270669096313689		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.270669096313689 | validation: 1.3351693422015396]
	TIME [epoch: 13 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.922199979888415		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.922199979888415 | validation: 1.787157907900708]
	TIME [epoch: 13 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6272549332947066		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.6272549332947066 | validation: 1.3188778868154025]
	TIME [epoch: 13 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2758192818940721		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.2758192818940721 | validation: 1.046938012015566]
	TIME [epoch: 13 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0424825764967482		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.0424825764967482 | validation: 1.450099147058585]
	TIME [epoch: 13 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1659169459250027		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.1659169459250027 | validation: 0.9437108352798663]
	TIME [epoch: 13 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9236064035185645		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.9236064035185645 | validation: 0.9760247868334793]
	TIME [epoch: 13 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8848520155681718		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.8848520155681718 | validation: 1.0437409222755218]
	TIME [epoch: 13 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9985862273386956		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.9985862273386956 | validation: 0.8462944489345614]
	TIME [epoch: 13 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8740189724901826		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.8740189724901826 | validation: 0.7418889051121825]
	TIME [epoch: 13 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9080801340591169		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.9080801340591169 | validation: 2.1496195629545904]
	TIME [epoch: 13 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.42343300110769		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.42343300110769 | validation: 0.9193434543442163]
	TIME [epoch: 13 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2689958794471525		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.2689958794471525 | validation: 0.9410012587306485]
	TIME [epoch: 13 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0607871634880115		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.0607871634880115 | validation: 0.844358642135131]
	TIME [epoch: 13.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9531952279545315		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.9531952279545315 | validation: 1.059145919835815]
	TIME [epoch: 13 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0874798510380737		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.0874798510380737 | validation: 1.2788662028350866]
	TIME [epoch: 13 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9189370820258658		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.9189370820258658 | validation: 0.8375315476816372]
	TIME [epoch: 13 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8803805950476927		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.8803805950476927 | validation: 0.7633181977604435]
	TIME [epoch: 13 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.954927618677142		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.954927618677142 | validation: 0.5353950221799146]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7087177039840498		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.7087177039840498 | validation: 3.153184517045088]
	TIME [epoch: 13 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7600866369738748		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.7600866369738748 | validation: 1.0377503220158542]
	TIME [epoch: 13 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9335425623254269		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.9335425623254269 | validation: 0.9674543262641149]
	TIME [epoch: 13 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0717663018965142		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.0717663018965142 | validation: 0.7427937315594317]
	TIME [epoch: 13 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0254293086358808		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.0254293086358808 | validation: 1.2558549343669052]
	TIME [epoch: 13 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4156780729506833		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.4156780729506833 | validation: 1.3128636651746615]
	TIME [epoch: 13 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2720240782635746		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.2720240782635746 | validation: 1.142529777086433]
	TIME [epoch: 13 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3761286655104557		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.3761286655104557 | validation: 1.2303053134079645]
	TIME [epoch: 13 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3634284244364065		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.3634284244364065 | validation: 1.1210398484461395]
	TIME [epoch: 13 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2225296076621117		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.2225296076621117 | validation: 0.9809288279092934]
	TIME [epoch: 13 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0536401968531468		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.0536401968531468 | validation: 1.1719328693304523]
	TIME [epoch: 13 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9922892797902914		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.9922892797902914 | validation: 0.9767974993886711]
	TIME [epoch: 13 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0293196045409168		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.0293196045409168 | validation: 0.8082733894733619]
	TIME [epoch: 13 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8121862797811823		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.8121862797811823 | validation: 2.4514948228587743]
	TIME [epoch: 13 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4460524902126124		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.4460524902126124 | validation: 1.3597144380512902]
	TIME [epoch: 13 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.102691107587137		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.102691107587137 | validation: 1.4969943670300212]
	TIME [epoch: 13 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1206916811856893		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.1206916811856893 | validation: 1.8316849596010922]
	TIME [epoch: 13 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.178498703104325		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.178498703104325 | validation: 1.5707500085348858]
	TIME [epoch: 13 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.077736052293261		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.077736052293261 | validation: 1.5274064216960568]
	TIME [epoch: 13 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1795675573941076		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.1795675573941076 | validation: 0.7563381866198415]
	TIME [epoch: 13 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8213956991822371		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.8213956991822371 | validation: 0.9398936500848415]
	TIME [epoch: 13 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8926397293315179		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.8926397293315179 | validation: 0.935402510426789]
	TIME [epoch: 13 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8301259004794524		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.8301259004794524 | validation: 0.7138513133906952]
	TIME [epoch: 13 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187251277990199		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.7187251277990199 | validation: 1.0433291142204137]
	TIME [epoch: 13 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9798329436321049		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.9798329436321049 | validation: 0.7377391781254666]
	TIME [epoch: 13 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7593181553404563		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.7593181553404563 | validation: 0.7297673330948881]
	TIME [epoch: 13 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0336593254809423		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.0336593254809423 | validation: 1.0380319543510859]
	TIME [epoch: 13 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0760338141579873		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.0760338141579873 | validation: 0.7773605383895579]
	TIME [epoch: 13 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2619546409446778		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.2619546409446778 | validation: 0.8654265442796845]
	TIME [epoch: 13 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.954553545808008		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.954553545808008 | validation: 0.9947666421823712]
	TIME [epoch: 13 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.862874625506013		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.862874625506013 | validation: 0.796300329415298]
	TIME [epoch: 13 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7478676624812217		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.7478676624812217 | validation: 0.6348852777059131]
	TIME [epoch: 13 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7329562682161058		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.7329562682161058 | validation: 0.9758354827993148]
	TIME [epoch: 13 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7746144303579666		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.7746144303579666 | validation: 1.2650473647905913]
	TIME [epoch: 13 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3434614920490286		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.3434614920490286 | validation: 0.742236321893481]
	TIME [epoch: 13 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1494064828474606		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.1494064828474606 | validation: 1.3666417178005503]
	TIME [epoch: 13 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2382566393741499		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.2382566393741499 | validation: 1.735900991611347]
	TIME [epoch: 13 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.364764707153207		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.364764707153207 | validation: 1.6338320759842615]
	TIME [epoch: 13 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2939439015491012		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.2939439015491012 | validation: 1.118641474027017]
	TIME [epoch: 13 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174536655203232		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.174536655203232 | validation: 0.6365339906651305]
	TIME [epoch: 13 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0258050827461955		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.0258050827461955 | validation: 0.7354708814032611]
	TIME [epoch: 13 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3080242155767623		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.3080242155767623 | validation: 0.7430700288163707]
	TIME [epoch: 13 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0330176629161667		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.0330176629161667 | validation: 0.6226553037358163]
	TIME [epoch: 13 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196003253576855		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.7196003253576855 | validation: 0.6185202436201224]
	TIME [epoch: 13 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.818267783895714		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.818267783895714 | validation: 0.6720278830773824]
	TIME [epoch: 13.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.770627204994191		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.770627204994191 | validation: 0.9037901624928546]
	TIME [epoch: 13 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8184863694668424		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.8184863694668424 | validation: 1.0566886055888034]
	TIME [epoch: 13 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.301959958005077		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.301959958005077 | validation: 1.396228244475646]
	TIME [epoch: 13 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029758888276386		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.029758888276386 | validation: 1.0927566711547223]
	TIME [epoch: 13 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.935739953757075		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.935739953757075 | validation: 0.5993959700801871]
	TIME [epoch: 13 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7856581314686091		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7856581314686091 | validation: 0.6983272792556368]
	TIME [epoch: 13 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8721150662812094		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.8721150662812094 | validation: 0.5707200752366274]
	TIME [epoch: 13 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8406384613907393		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.8406384613907393 | validation: 1.2733692428586418]
	TIME [epoch: 13 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2145436451372302		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.2145436451372302 | validation: 0.739295844181118]
	TIME [epoch: 13 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0638672269855936		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.0638672269855936 | validation: 0.7350021559479243]
	TIME [epoch: 13 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8058541751933608		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.8058541751933608 | validation: 0.9414461601351153]
	TIME [epoch: 13 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9776522597714297		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.9776522597714297 | validation: 0.749469824383425]
	TIME [epoch: 13 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.758774338390712		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.758774338390712 | validation: 0.7961940382899997]
	TIME [epoch: 13 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8686990828194942		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.8686990828194942 | validation: 0.8575488653802171]
	TIME [epoch: 13 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7962403101204436		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.7962403101204436 | validation: 0.8667676548432611]
	TIME [epoch: 13 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222201791294496		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.7222201791294496 | validation: 1.2290099342610514]
	TIME [epoch: 13 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688286214009264		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.7688286214009264 | validation: 0.5388983626685343]
	TIME [epoch: 13 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6804374210740063		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.6804374210740063 | validation: 0.6408340821113323]
	TIME [epoch: 13 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0818418591333752		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.0818418591333752 | validation: 0.6264176527430805]
	TIME [epoch: 13 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228448601124939		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.7228448601124939 | validation: 0.5467469483268679]
	TIME [epoch: 13 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70018126162753		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.70018126162753 | validation: 0.7602059523421812]
	TIME [epoch: 13 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8264530247692391		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.8264530247692391 | validation: 0.5708272082125018]
	TIME [epoch: 13 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.661906988364298		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.661906988364298 | validation: 0.6751442329102082]
	TIME [epoch: 13 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6967256621427791		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.6967256621427791 | validation: 1.2748985288415537]
	TIME [epoch: 13 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2250331130670482		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.2250331130670482 | validation: 0.7824232258324688]
	TIME [epoch: 13 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0032659366965		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.0032659366965 | validation: 0.7047196935373594]
	TIME [epoch: 13 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7281058190239692		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.7281058190239692 | validation: 0.4393969824699927]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_358.pth
	Model improved!!!
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7835500428532325		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.7835500428532325 | validation: 0.7475176995501025]
	TIME [epoch: 13 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7303798360888127		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.7303798360888127 | validation: 0.8091763764813543]
	TIME [epoch: 13 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7658307378693934		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.7658307378693934 | validation: 0.6628104441277124]
	TIME [epoch: 13 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301522146410402		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.6301522146410402 | validation: 1.2992770619880099]
	TIME [epoch: 13 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8944508378397216		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.8944508378397216 | validation: 0.521313981525348]
	TIME [epoch: 13 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7446405868933932		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.7446405868933932 | validation: 0.49426462938052496]
	TIME [epoch: 13 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6292242376941855		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.6292242376941855 | validation: 0.7137880874342051]
	TIME [epoch: 13 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6294855968814466		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.6294855968814466 | validation: 0.6681556798932576]
	TIME [epoch: 13 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6217381338387213		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.6217381338387213 | validation: 0.4158923162452419]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5313914996967327		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5313914996967327 | validation: 0.9322946658263406]
	TIME [epoch: 13 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7323447270499945		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.7323447270499945 | validation: 0.5013012442125847]
	TIME [epoch: 13 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7887151423902343		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.7887151423902343 | validation: 0.4620532866174538]
	TIME [epoch: 13 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8372610282595407		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.8372610282595407 | validation: 0.506976809608934]
	TIME [epoch: 13 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0293536905377254		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.0293536905377254 | validation: 0.571777977393963]
	TIME [epoch: 13 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8750647004900893		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.8750647004900893 | validation: 0.8898623726177697]
	TIME [epoch: 13 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6953717652594407		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.6953717652594407 | validation: 0.9231194402695019]
	TIME [epoch: 13 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8210316488023178		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.8210316488023178 | validation: 0.7442907543121493]
	TIME [epoch: 13 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5939892558974665		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.5939892558974665 | validation: 0.5129337217760629]
	TIME [epoch: 13 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6621302204331363		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.6621302204331363 | validation: 0.5970493179092989]
	TIME [epoch: 13 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6646454495522726		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.6646454495522726 | validation: 0.8551717721576065]
	TIME [epoch: 13.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9226456966512664		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.9226456966512664 | validation: 0.9392711600957341]
	TIME [epoch: 13 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7116852760752814		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.7116852760752814 | validation: 1.579212935276444]
	TIME [epoch: 13 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2802695601380272		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.2802695601380272 | validation: 0.7852888053037675]
	TIME [epoch: 13 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8877714737749518		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.8877714737749518 | validation: 0.6717815521558659]
	TIME [epoch: 13 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7815538098529837		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.7815538098529837 | validation: 0.4657865659844635]
	TIME [epoch: 13 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9398119646423148		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.9398119646423148 | validation: 0.967560018569386]
	TIME [epoch: 13 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1036470389860287		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.1036470389860287 | validation: 0.5611747098723378]
	TIME [epoch: 13 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886283034719124		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.6886283034719124 | validation: 0.5809746628947385]
	TIME [epoch: 13 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8067936580325786		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.8067936580325786 | validation: 0.8307230390835031]
	TIME [epoch: 13 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8004315322283717		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.8004315322283717 | validation: 0.8574689248917704]
	TIME [epoch: 13 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7094318709459982		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.7094318709459982 | validation: 0.4536881405927234]
	TIME [epoch: 13 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.618128644924782		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.618128644924782 | validation: 0.5792342205501038]
	TIME [epoch: 13 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254629387493666		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.6254629387493666 | validation: 0.7311838509459675]
	TIME [epoch: 13 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6181311962761012		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.6181311962761012 | validation: 0.42755747765429647]
	TIME [epoch: 13 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6485724512638409		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.6485724512638409 | validation: 0.528950394698591]
	TIME [epoch: 13 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7500659273600723		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.7500659273600723 | validation: 0.44026495769136115]
	TIME [epoch: 13 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5370106289808956		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.5370106289808956 | validation: 0.4768504550544468]
	TIME [epoch: 13 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8065275485798581		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.8065275485798581 | validation: 0.7115150342283224]
	TIME [epoch: 13 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8118455830218475		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.8118455830218475 | validation: 0.40156648409123774]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4837294785106052		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.4837294785106052 | validation: 0.4648076178712969]
	TIME [epoch: 13 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6074857320242617		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.6074857320242617 | validation: 0.4252262029611217]
	TIME [epoch: 13 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6401276335906613		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.6401276335906613 | validation: 0.7212996338897392]
	TIME [epoch: 13 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.859913694111094		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.859913694111094 | validation: 1.3620977074135494]
	TIME [epoch: 13.1 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7669069775579259		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.7669069775579259 | validation: 0.49811803375984826]
	TIME [epoch: 13 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6724023068022961		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.6724023068022961 | validation: 0.8003541524199267]
	TIME [epoch: 13 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7181546146557571		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.7181546146557571 | validation: 0.6845924130688178]
	TIME [epoch: 13 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6608243453649646		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.6608243453649646 | validation: 0.6396838464179251]
	TIME [epoch: 13 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.648540722177789		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.648540722177789 | validation: 0.5512423705814987]
	TIME [epoch: 13 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6219815732770412		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.6219815732770412 | validation: 0.5385021506747967]
	TIME [epoch: 13 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5788770577060169		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.5788770577060169 | validation: 0.6648175867656957]
	TIME [epoch: 13 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8313208395141901		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.8313208395141901 | validation: 1.092624225262744]
	TIME [epoch: 13 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.862688204490761		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.862688204490761 | validation: 1.210611930271197]
	TIME [epoch: 13 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7659868163262443		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.7659868163262443 | validation: 0.754315428802108]
	TIME [epoch: 13.1 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6430812587259338		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.6430812587259338 | validation: 0.629982171853394]
	TIME [epoch: 13 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5424579233798694		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.5424579233798694 | validation: 0.3344848053222359]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_413.pth
	Model improved!!!
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6293002148619318		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.6293002148619318 | validation: 0.35791958587906963]
	TIME [epoch: 13 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.551985659959309		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.551985659959309 | validation: 0.5570759185395181]
	TIME [epoch: 13 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47075336736257795		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.47075336736257795 | validation: 0.37702061659508973]
	TIME [epoch: 13 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44217665832396974		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.44217665832396974 | validation: 0.538333057499089]
	TIME [epoch: 13 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5158438778053491		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.5158438778053491 | validation: 0.38550208559102056]
	TIME [epoch: 13 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7531875577471401		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.7531875577471401 | validation: 0.529055790175656]
	TIME [epoch: 13 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5282489854590602		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.5282489854590602 | validation: 1.096499495752464]
	TIME [epoch: 13 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8625450165845844		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.8625450165845844 | validation: 1.094426655049436]
	TIME [epoch: 13 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8834934091672738		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.8834934091672738 | validation: 0.8810979880597242]
	TIME [epoch: 13 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6552639753043858		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.6552639753043858 | validation: 1.1252753364757648]
	TIME [epoch: 13 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870768747072968		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.6870768747072968 | validation: 0.8951695652153475]
	TIME [epoch: 13 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6399840831777345		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.6399840831777345 | validation: 0.3876835067599999]
	TIME [epoch: 13 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.73982458397572		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.73982458397572 | validation: 0.5630938021267575]
	TIME [epoch: 13 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8047926569283146		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.8047926569283146 | validation: 0.4590708850244869]
	TIME [epoch: 13 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248429767515607		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.7248429767515607 | validation: 0.3810722657837917]
	TIME [epoch: 13 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.603512227152604		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.603512227152604 | validation: 0.5044056233053987]
	TIME [epoch: 13 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7112034247333883		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.7112034247333883 | validation: 0.5900069173860129]
	TIME [epoch: 13 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7926161571559089		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.7926161571559089 | validation: 0.8124068500096868]
	TIME [epoch: 13 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6208638367046403		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.6208638367046403 | validation: 0.88594531137594]
	TIME [epoch: 13 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7328730463315096		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.7328730463315096 | validation: 0.5234284730484416]
	TIME [epoch: 13 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48309985368222796		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.48309985368222796 | validation: 0.3632181510847354]
	TIME [epoch: 13 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4668591214501183		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.4668591214501183 | validation: 1.3748989007871901]
	TIME [epoch: 13 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7381401422856407		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.7381401422856407 | validation: 1.0822180087946183]
	TIME [epoch: 13 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701218994824963		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.701218994824963 | validation: 0.8462318835634495]
	TIME [epoch: 13 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6582004889417873		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.6582004889417873 | validation: 0.9594847874806847]
	TIME [epoch: 13.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6558631871637672		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.6558631871637672 | validation: 0.34555359714935596]
	TIME [epoch: 13 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5059218865016334		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.5059218865016334 | validation: 0.7693912728438539]
	TIME [epoch: 13 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141603249448266		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.5141603249448266 | validation: 0.4287165125919232]
	TIME [epoch: 13.1 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4256780401008565		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.4256780401008565 | validation: 0.43333735234292975]
	TIME [epoch: 13 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839526464194008		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.4839526464194008 | validation: 0.5086127493226593]
	TIME [epoch: 13 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47960241388669667		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.47960241388669667 | validation: 0.5155876676008113]
	TIME [epoch: 13.1 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.512353486425232		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.512353486425232 | validation: 0.40646460789389793]
	TIME [epoch: 13 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.510209032034596		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.510209032034596 | validation: 0.3047352742824885]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_446.pth
	Model improved!!!
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4878978248281526		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.4878978248281526 | validation: 0.3672257540693903]
	TIME [epoch: 13 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6924635524422584		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.6924635524422584 | validation: 0.8836912019032781]
	TIME [epoch: 13 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269737830229244		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.5269737830229244 | validation: 0.5448869420067486]
	TIME [epoch: 13 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45919838788843537		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.45919838788843537 | validation: 0.42282199237327744]
	TIME [epoch: 13 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3614818531385203		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.3614818531385203 | validation: 0.37881660606314355]
	TIME [epoch: 13.1 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4495979602131749		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.4495979602131749 | validation: 0.40163799691443175]
	TIME [epoch: 13 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34394989991353947		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.34394989991353947 | validation: 0.5373430256675915]
	TIME [epoch: 13 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4532938004184889		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.4532938004184889 | validation: 0.7517529595314147]
	TIME [epoch: 13 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49568783919394593		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.49568783919394593 | validation: 0.541528186839624]
	TIME [epoch: 13 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.442316534505382		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.442316534505382 | validation: 0.3644780462724684]
	TIME [epoch: 13 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4391918867350306		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.4391918867350306 | validation: 0.4087819138687371]
	TIME [epoch: 13 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805363621164247		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.3805363621164247 | validation: 0.5036119032296542]
	TIME [epoch: 13.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45165463589949983		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.45165463589949983 | validation: 0.7687591946117937]
	TIME [epoch: 13 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5303904904127682		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.5303904904127682 | validation: 0.43985525425519206]
	TIME [epoch: 13 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46749462640862827		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.46749462640862827 | validation: 0.29473589574171494]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5980769112599009		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.5980769112599009 | validation: 0.6779895853928415]
	TIME [epoch: 13 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48955537875086796		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.48955537875086796 | validation: 0.4485969879862277]
	TIME [epoch: 13 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42412386746499187		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.42412386746499187 | validation: 0.2849104060180985]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_464.pth
	Model improved!!!
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3219785099973673		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.3219785099973673 | validation: 0.6022557723317598]
	TIME [epoch: 13 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46725062571346676		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.46725062571346676 | validation: 0.3143431750545051]
	TIME [epoch: 13 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5856474568467392		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.5856474568467392 | validation: 0.24069924092523362]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_467.pth
	Model improved!!!
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30950248150353643		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.30950248150353643 | validation: 0.3882551379912039]
	TIME [epoch: 13.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3597091616457131		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.3597091616457131 | validation: 0.655783336563444]
	TIME [epoch: 13 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5957241344420452		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.5957241344420452 | validation: 0.5181394120807364]
	TIME [epoch: 13 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44837997562939924		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.44837997562939924 | validation: 0.25803847749575026]
	TIME [epoch: 13.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461337214250508		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.3461337214250508 | validation: 0.3212815883838285]
	TIME [epoch: 13 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4191340443276912		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.4191340443276912 | validation: 0.45380886448819396]
	TIME [epoch: 13 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46969526230900044		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.46969526230900044 | validation: 0.4271883762903268]
	TIME [epoch: 13 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4033008622397769		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.4033008622397769 | validation: 0.3578422899862126]
	TIME [epoch: 13 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4260218462446547		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.4260218462446547 | validation: 0.2895228231007756]
	TIME [epoch: 13 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35385536218244645		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.35385536218244645 | validation: 0.2600899593383502]
	TIME [epoch: 13 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36437146442607043		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.36437146442607043 | validation: 0.4900784741019502]
	TIME [epoch: 13.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7017446030786942		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.7017446030786942 | validation: 0.9594102286339293]
	TIME [epoch: 13 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6677247543257926		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.6677247543257926 | validation: 0.9130377264194267]
	TIME [epoch: 13 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6403284580465924		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.6403284580465924 | validation: 0.32605570821277724]
	TIME [epoch: 13 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4597008250915625		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.4597008250915625 | validation: 0.458565803375308]
	TIME [epoch: 13 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45566196088724364		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.45566196088724364 | validation: 0.28338684241022577]
	TIME [epoch: 13 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5353533710910592		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5353533710910592 | validation: 0.3973556962354151]
	TIME [epoch: 13 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4105638682739261		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.4105638682739261 | validation: 0.3673561729286469]
	TIME [epoch: 13 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3697424806961411		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.3697424806961411 | validation: 0.39570308496904477]
	TIME [epoch: 13 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47615839392921944		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.47615839392921944 | validation: 0.31092069937463823]
	TIME [epoch: 13 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4846697572839501		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.4846697572839501 | validation: 0.4816926132748002]
	TIME [epoch: 13 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4574964055222017		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.4574964055222017 | validation: 0.4223344931648136]
	TIME [epoch: 13 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3724594250661221		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.3724594250661221 | validation: 0.31617833496380476]
	TIME [epoch: 13 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365728995585791		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.365728995585791 | validation: 0.8106193420830764]
	TIME [epoch: 13 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5982696145031017		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.5982696145031017 | validation: 0.4631606590180155]
	TIME [epoch: 13 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4576790016999856		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.4576790016999856 | validation: 0.5707262278005822]
	TIME [epoch: 13 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44459182446021994		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.44459182446021994 | validation: 0.6119683905362773]
	TIME [epoch: 13 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44194492484812087		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.44194492484812087 | validation: 0.5290783957852632]
	TIME [epoch: 13 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5629489967714912		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.5629489967714912 | validation: 0.3712410268120743]
	TIME [epoch: 13 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3962041578074542		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.3962041578074542 | validation: 0.39070528617248373]
	TIME [epoch: 13 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5251004143533177		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.5251004143533177 | validation: 0.30443594966545046]
	TIME [epoch: 13 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6174627388487189		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.6174627388487189 | validation: 0.38887132327569374]
	TIME [epoch: 13 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4360528454410978		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.4360528454410978 | validation: 0.5411547465668308]
	TIME [epoch: 13 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5560020629533575		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.5560020629533575 | validation: 0.4057857196158031]
	TIME [epoch: 13 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41201442699338126		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.41201442699338126 | validation: 0.2169706857050927]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_502.pth
	Model improved!!!
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3526021545888612		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.3526021545888612 | validation: 0.5024851459174032]
	TIME [epoch: 13 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42339299561354854		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.42339299561354854 | validation: 0.30249501943706525]
	TIME [epoch: 13 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3967143520945333		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.3967143520945333 | validation: 0.7771187180770504]
	TIME [epoch: 13 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6384139111981374		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.6384139111981374 | validation: 0.4586277602888687]
	TIME [epoch: 13 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48043680629337987		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.48043680629337987 | validation: 0.4042621196576199]
	TIME [epoch: 13 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4090641391689628		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.4090641391689628 | validation: 0.5665034334352933]
	TIME [epoch: 13 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933714963742142		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.3933714963742142 | validation: 0.4434235209025549]
	TIME [epoch: 13 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3653116688173485		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.3653116688173485 | validation: 0.2820004730762172]
	TIME [epoch: 13 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108751492904301		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.3108751492904301 | validation: 0.3296077168623111]
	TIME [epoch: 13 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34199335509685863		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.34199335509685863 | validation: 0.23883933756844972]
	TIME [epoch: 13 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37176845803309644		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.37176845803309644 | validation: 0.23250748545493188]
	TIME [epoch: 13 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36752333688971706		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.36752333688971706 | validation: 0.34195193735638085]
	TIME [epoch: 13 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3078620651769211		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.3078620651769211 | validation: 0.3716354820859511]
	TIME [epoch: 13 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3659355000859811		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.3659355000859811 | validation: 0.3915868117357302]
	TIME [epoch: 13 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33540377948846406		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.33540377948846406 | validation: 0.3013658720162472]
	TIME [epoch: 13 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48954155911717867		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.48954155911717867 | validation: 0.33193724046801565]
	TIME [epoch: 13.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36288039411238393		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.36288039411238393 | validation: 0.38202146482588406]
	TIME [epoch: 13 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.299759175338363		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.299759175338363 | validation: 0.24023600492986416]
	TIME [epoch: 13 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41925486621558744		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.41925486621558744 | validation: 0.38994557551428105]
	TIME [epoch: 13 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37040950721262034		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.37040950721262034 | validation: 0.36502041435431176]
	TIME [epoch: 13 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3351851201126056		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.3351851201126056 | validation: 0.3759645828324365]
	TIME [epoch: 13 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3858189617794721		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.3858189617794721 | validation: 0.26264097135902303]
	TIME [epoch: 13.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4657021398578489		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.4657021398578489 | validation: 0.3450599203123357]
	TIME [epoch: 13 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40001312838567005		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.40001312838567005 | validation: 0.317239941625968]
	TIME [epoch: 13 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528641831934752		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.3528641831934752 | validation: 0.3697813373281981]
	TIME [epoch: 13 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34419173786568125		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.34419173786568125 | validation: 0.2817892475939474]
	TIME [epoch: 13.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3431968401977531		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.3431968401977531 | validation: 0.40335573801783875]
	TIME [epoch: 13 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5537422659940267		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.5537422659940267 | validation: 0.28366518544067715]
	TIME [epoch: 13 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38949652271561874		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.38949652271561874 | validation: 0.352112737466382]
	TIME [epoch: 13 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2941332020751899		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.2941332020751899 | validation: 0.38960884857353817]
	TIME [epoch: 13 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3208333398243524		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.3208333398243524 | validation: 0.2387473425327265]
	TIME [epoch: 13 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5424365379274939		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.5424365379274939 | validation: 0.807479239603181]
	TIME [epoch: 13 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4805577413793948		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.4805577413793948 | validation: 0.33497257553376647]
	TIME [epoch: 13 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915509029614672		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.2915509029614672 | validation: 0.4968711598334398]
	TIME [epoch: 13 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4107372794921681		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.4107372794921681 | validation: 0.2655009320242446]
	TIME [epoch: 13 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26760935317732887		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.26760935317732887 | validation: 0.2584106252088135]
	TIME [epoch: 13.1 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4447265803986926		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.4447265803986926 | validation: 0.5202538950618745]
	TIME [epoch: 13 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5066759955295655		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.5066759955295655 | validation: 0.37513954328616267]
	TIME [epoch: 13 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4202794387516099		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.4202794387516099 | validation: 0.31322781456476456]
	TIME [epoch: 13 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49643886617094235		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.49643886617094235 | validation: 0.36116560518618684]
	TIME [epoch: 13 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3116619514732186		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.3116619514732186 | validation: 0.3649384612532245]
	TIME [epoch: 13 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39483023714527116		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.39483023714527116 | validation: 0.19912782555693181]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_544.pth
	Model improved!!!
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590575366755768		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.2590575366755768 | validation: 0.18656354631001243]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_545.pth
	Model improved!!!
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3648373759203861		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.3648373759203861 | validation: 0.5184161232342629]
	TIME [epoch: 13 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4227644564393333		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.4227644564393333 | validation: 0.23935032507807452]
	TIME [epoch: 13 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3446942374460005		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.3446942374460005 | validation: 0.41760550510857886]
	TIME [epoch: 13.1 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47935512723650375		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.47935512723650375 | validation: 0.20832578044952513]
	TIME [epoch: 13 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.262272700706436		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.262272700706436 | validation: 0.4023599636464458]
	TIME [epoch: 13 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260700647158352		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.7260700647158352 | validation: 0.5869272823148994]
	TIME [epoch: 13 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43134102780098904		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.43134102780098904 | validation: 0.307248565118491]
	TIME [epoch: 13 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3096256002117541		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.3096256002117541 | validation: 0.2956094997226678]
	TIME [epoch: 13 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3257423465506106		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.3257423465506106 | validation: 0.5015226893804032]
	TIME [epoch: 13 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3840361078149524		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.3840361078149524 | validation: 0.3800586100089264]
	TIME [epoch: 13 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31537741276423115		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.31537741276423115 | validation: 0.2199389209064733]
	TIME [epoch: 13 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2328783277769227		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.2328783277769227 | validation: 0.29293077175940324]
	TIME [epoch: 13 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2623569554392088		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.2623569554392088 | validation: 0.27066364863477815]
	TIME [epoch: 13 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2921287106247017		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.2921287106247017 | validation: 0.2923498807037755]
	TIME [epoch: 13 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.283988359741143		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.283988359741143 | validation: 0.32517423054282385]
	TIME [epoch: 13 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38496450081600403		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.38496450081600403 | validation: 0.22578072848883893]
	TIME [epoch: 13.1 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31393247753904774		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.31393247753904774 | validation: 0.26744712788905683]
	TIME [epoch: 13 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27350774580128695		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.27350774580128695 | validation: 0.2569602261036196]
	TIME [epoch: 13 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2682717512023945		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.2682717512023945 | validation: 0.2150017853967263]
	TIME [epoch: 13 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23956413168278756		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.23956413168278756 | validation: 0.23569534904043188]
	TIME [epoch: 13.1 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25105269429969573		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.25105269429969573 | validation: 0.2589001599609096]
	TIME [epoch: 13 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3388911292415226		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.3388911292415226 | validation: 0.6290917954629685]
	TIME [epoch: 13 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41856948308562425		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.41856948308562425 | validation: 0.24565953246911684]
	TIME [epoch: 13.1 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3398389908273382		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.3398389908273382 | validation: 0.2833234970829024]
	TIME [epoch: 13 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3020051937296113		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.3020051937296113 | validation: 0.2439338974571094]
	TIME [epoch: 13 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24478452525260055		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.24478452525260055 | validation: 0.3576994777889793]
	TIME [epoch: 13.1 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2948028587579405		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.2948028587579405 | validation: 0.353880667479191]
	TIME [epoch: 13 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3199920374407274		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.3199920374407274 | validation: 0.2619972432284919]
	TIME [epoch: 13 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2648379546596823		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.2648379546596823 | validation: 0.3163356331995137]
	TIME [epoch: 13 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45622864703838195		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.45622864703838195 | validation: 0.4165051953261571]
	TIME [epoch: 13 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3094625787492561		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.3094625787492561 | validation: 0.21986562468370707]
	TIME [epoch: 13 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28993118486328395		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.28993118486328395 | validation: 0.3647244196345662]
	TIME [epoch: 13 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4074992293208243		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.4074992293208243 | validation: 0.2223079147841915]
	TIME [epoch: 13.1 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28902807944223835		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.28902807944223835 | validation: 0.3878185065847815]
	TIME [epoch: 13 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3150361552959239		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.3150361552959239 | validation: 0.19676553839078945]
	TIME [epoch: 13 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34452374570417954		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.34452374570417954 | validation: 0.35540813061527404]
	TIME [epoch: 13.1 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45847108726158353		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.45847108726158353 | validation: 0.30118709153852463]
	TIME [epoch: 13 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41393538036254485		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.41393538036254485 | validation: 0.34488555749445626]
	TIME [epoch: 13 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3202814653047118		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.3202814653047118 | validation: 0.29791457872840693]
	TIME [epoch: 13 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3104592115061988		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.3104592115061988 | validation: 0.3400092066717275]
	TIME [epoch: 13 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27585828194833006		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.27585828194833006 | validation: 0.1915489295997955]
	TIME [epoch: 13 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23876009916073884		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.23876009916073884 | validation: 0.24333371280060043]
	TIME [epoch: 13 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25411727875827417		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.25411727875827417 | validation: 0.228106067946511]
	TIME [epoch: 13 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33786757273720647		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.33786757273720647 | validation: 0.2866211973178012]
	TIME [epoch: 13 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31989261017478277		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.31989261017478277 | validation: 0.1979084427319939]
	TIME [epoch: 13 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288758856058255		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.288758856058255 | validation: 0.3491696920603349]
	TIME [epoch: 13 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27758151229742534		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.27758151229742534 | validation: 0.20970278501054293]
	TIME [epoch: 13 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45127845679983825		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.45127845679983825 | validation: 0.25655117226530455]
	TIME [epoch: 13 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2873110716288178		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.2873110716288178 | validation: 0.22316872250956174]
	TIME [epoch: 13.1 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25502536105525436		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.25502536105525436 | validation: 0.22886808196836453]
	TIME [epoch: 13 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35698735213706945		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.35698735213706945 | validation: 0.24781097000902788]
	TIME [epoch: 13 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2741584274244121		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.2741584274244121 | validation: 0.27842009190636235]
	TIME [epoch: 13 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21974967157946498		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.21974967157946498 | validation: 0.18026746996571505]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20479136163339662		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.20479136163339662 | validation: 0.273637779555947]
	TIME [epoch: 13 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2596142162510861		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2596142162510861 | validation: 0.22359381638104822]
	TIME [epoch: 13 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3281408335362538		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.3281408335362538 | validation: 0.20743976832959468]
	TIME [epoch: 13 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23158564336842444		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.23158564336842444 | validation: 0.5584254997508944]
	TIME [epoch: 13 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3836658726718416		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.3836658726718416 | validation: 0.1891423001031513]
	TIME [epoch: 13 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22918177835277326		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.22918177835277326 | validation: 0.2180447463564739]
	TIME [epoch: 13 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24415244713940437		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.24415244713940437 | validation: 0.3071874022019411]
	TIME [epoch: 13 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23345091674304624		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.23345091674304624 | validation: 0.2260967618783605]
	TIME [epoch: 13 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24172857093879893		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.24172857093879893 | validation: 0.2472944408636923]
	TIME [epoch: 13 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507236811711336		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.3507236811711336 | validation: 0.15386705849916843]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_608.pth
	Model improved!!!
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1990194027288631		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.1990194027288631 | validation: 0.23580413456852975]
	TIME [epoch: 13 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23424801883023322		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.23424801883023322 | validation: 0.193949012637907]
	TIME [epoch: 13 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2642008326730919		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.2642008326730919 | validation: 0.3333073437464541]
	TIME [epoch: 13.1 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3256691451459037		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.3256691451459037 | validation: 0.2028017531921897]
	TIME [epoch: 13 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32832987540666064		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.32832987540666064 | validation: 0.31414520867807433]
	TIME [epoch: 13 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2457075713928456		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.2457075713928456 | validation: 0.279410219571703]
	TIME [epoch: 13 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28551506398467597		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.28551506398467597 | validation: 0.1804287544277141]
	TIME [epoch: 13 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655329786014511		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.2655329786014511 | validation: 0.18858145173824187]
	TIME [epoch: 13 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2979749619236827		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.2979749619236827 | validation: 0.2158253528973175]
	TIME [epoch: 13 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21596439272802886		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.21596439272802886 | validation: 0.32384864683643905]
	TIME [epoch: 13.1 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2975149547321958		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.2975149547321958 | validation: 0.5465078740214874]
	TIME [epoch: 13 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8886326846194925		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.8886326846194925 | validation: 0.46943552199725236]
	TIME [epoch: 13 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3811052062096967		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.3811052062096967 | validation: 0.35069021870002914]
	TIME [epoch: 13 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44517047914855445		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.44517047914855445 | validation: 0.4241816086508277]
	TIME [epoch: 13 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3844163564969462		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.3844163564969462 | validation: 0.25129850101313983]
	TIME [epoch: 13 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29940793829003565		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.29940793829003565 | validation: 0.28106775838431236]
	TIME [epoch: 13 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26674125850818353		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.26674125850818353 | validation: 0.34308287739117993]
	TIME [epoch: 13 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33900483031002654		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.33900483031002654 | validation: 0.2483775464139435]
	TIME [epoch: 13 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24647417918588793		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.24647417918588793 | validation: 0.22433679070828264]
	TIME [epoch: 13 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35573891092552007		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.35573891092552007 | validation: 0.47452254233645585]
	TIME [epoch: 13 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.326293251014877		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.326293251014877 | validation: 0.3632014465016453]
	TIME [epoch: 13 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29722881131910106		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.29722881131910106 | validation: 0.20736993855561317]
	TIME [epoch: 13 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25333854647781184		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.25333854647781184 | validation: 0.23037171948414734]
	TIME [epoch: 13 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2600222749165586		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.2600222749165586 | validation: 0.5895846807407701]
	TIME [epoch: 13 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.357737980147122		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.357737980147122 | validation: 0.1793567880627733]
	TIME [epoch: 13 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23449594779136973		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.23449594779136973 | validation: 0.29896695642601323]
	TIME [epoch: 13 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2652123413046289		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.2652123413046289 | validation: 0.2084977857855572]
	TIME [epoch: 13 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22503663212790564		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.22503663212790564 | validation: 0.20675083371717884]
	TIME [epoch: 13 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34410554882486905		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.34410554882486905 | validation: 0.18314567650121336]
	TIME [epoch: 13 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22172816078625301		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.22172816078625301 | validation: 0.3668016192982097]
	TIME [epoch: 13 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24596454673874066		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.24596454673874066 | validation: 0.24738316101800928]
	TIME [epoch: 13 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24730389173134681		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.24730389173134681 | validation: 0.5723919629895047]
	TIME [epoch: 13 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41531847464909216		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.41531847464909216 | validation: 0.24447690530341662]
	TIME [epoch: 13.1 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2880249749963182		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.2880249749963182 | validation: 0.299125711767507]
	TIME [epoch: 13 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28019567836361947		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.28019567836361947 | validation: 0.20811821453732537]
	TIME [epoch: 13 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2548511099995162		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.2548511099995162 | validation: 0.23738440768555344]
	TIME [epoch: 13 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24078227340465433		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.24078227340465433 | validation: 0.240666117962433]
	TIME [epoch: 13 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2242067495566599		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.2242067495566599 | validation: 0.2530898944906678]
	TIME [epoch: 13 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23213224621789816		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.23213224621789816 | validation: 0.2343086224432637]
	TIME [epoch: 13 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22526503956928837		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.22526503956928837 | validation: 0.28825644054122007]
	TIME [epoch: 13.1 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30835591804193707		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.30835591804193707 | validation: 0.2317516285812988]
	TIME [epoch: 13 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20378737508577222		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.20378737508577222 | validation: 0.16653393978492242]
	TIME [epoch: 13 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19917467414898507		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.19917467414898507 | validation: 0.5516867202568309]
	TIME [epoch: 13.1 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35504104408675413		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.35504104408675413 | validation: 0.16400851902353353]
	TIME [epoch: 13 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.353213502411206		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.353213502411206 | validation: 0.26240920277718355]
	TIME [epoch: 13 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2962547440156749		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.2962547440156749 | validation: 0.2765050203702649]
	TIME [epoch: 13.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3429890887358071		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.3429890887358071 | validation: 0.2291162220536182]
	TIME [epoch: 13 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29435319241037616		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.29435319241037616 | validation: 0.2380832463952829]
	TIME [epoch: 13 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3082711085892996		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.3082711085892996 | validation: 0.22679510049824025]
	TIME [epoch: 13 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21582387307061096		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.21582387307061096 | validation: 0.17796685139034515]
	TIME [epoch: 13 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27630851616268637		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.27630851616268637 | validation: 0.4871534117996214]
	TIME [epoch: 13 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32993724157345256		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.32993724157345256 | validation: 0.17778951429075968]
	TIME [epoch: 13 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30646865012298447		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.30646865012298447 | validation: 0.19986715873766628]
	TIME [epoch: 13 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23623238516416106		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.23623238516416106 | validation: 0.35609562453673055]
	TIME [epoch: 13 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31357305218539033		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.31357305218539033 | validation: 0.18934906116422046]
	TIME [epoch: 13 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2295796033253535		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.2295796033253535 | validation: 0.1723785420536609]
	TIME [epoch: 13 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24025580211616498		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.24025580211616498 | validation: 0.2124829566513823]
	TIME [epoch: 13 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25523173722957027		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.25523173722957027 | validation: 0.30008670215815725]
	TIME [epoch: 13 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30965388994718007		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.30965388994718007 | validation: 0.2593269404308672]
	TIME [epoch: 13.1 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.249841027662262		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.249841027662262 | validation: 0.31496896350897574]
	TIME [epoch: 13 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38444741921587244		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.38444741921587244 | validation: 0.3092874809784763]
	TIME [epoch: 13 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32605064212969515		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.32605064212969515 | validation: 0.24429557184612022]
	TIME [epoch: 13 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32389201782056903		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.32389201782056903 | validation: 0.28160157165481087]
	TIME [epoch: 13 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.263281095072018		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.263281095072018 | validation: 0.336259358445764]
	TIME [epoch: 13 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2976641540236326		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.2976641540236326 | validation: 0.3000894819852301]
	TIME [epoch: 13 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25916645079831496		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.25916645079831496 | validation: 0.34869998682991393]
	TIME [epoch: 13.1 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2855746608244468		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.2855746608244468 | validation: 0.20154541962771252]
	TIME [epoch: 13 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22995166590177646		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.22995166590177646 | validation: 0.17526108010241323]
	TIME [epoch: 13 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1804265472438862		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.1804265472438862 | validation: 0.1926435808798984]
	TIME [epoch: 13 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24672212392715157		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.24672212392715157 | validation: 0.4189740582748708]
	TIME [epoch: 13 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36855749431968954		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.36855749431968954 | validation: 0.310099666815262]
	TIME [epoch: 13 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27906231929012515		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.27906231929012515 | validation: 0.20114964678351188]
	TIME [epoch: 13.1 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21001735855868442		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.21001735855868442 | validation: 0.21502311868291712]
	TIME [epoch: 13 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20266341244258518		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.20266341244258518 | validation: 0.3379084925524673]
	TIME [epoch: 13 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37242515086274086		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.37242515086274086 | validation: 0.36808529888287317]
	TIME [epoch: 13 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25392422130755166		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.25392422130755166 | validation: 0.2383245067518943]
	TIME [epoch: 13 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2546099256990654		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.2546099256990654 | validation: 0.2630546890678069]
	TIME [epoch: 13 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24418670424034394		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.24418670424034394 | validation: 0.19562060744854579]
	TIME [epoch: 13 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2031010263106375		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.2031010263106375 | validation: 0.4048354299040435]
	TIME [epoch: 13.1 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28281536303131505		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.28281536303131505 | validation: 0.19466009033444542]
	TIME [epoch: 13 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740316820517699		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.2740316820517699 | validation: 1.2242512847422524]
	TIME [epoch: 13 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7992206460403942		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.7992206460403942 | validation: 0.3562224435195982]
	TIME [epoch: 13.1 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28582790275338926		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.28582790275338926 | validation: 0.2435283846254321]
	TIME [epoch: 13 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915043238659266		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.2915043238659266 | validation: 0.23739102194956274]
	TIME [epoch: 13 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2572552869429334		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.2572552869429334 | validation: 0.24511677322930994]
	TIME [epoch: 13 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2772750338752633		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.2772750338752633 | validation: 0.20560438070023682]
	TIME [epoch: 13.1 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20773108189729836		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.20773108189729836 | validation: 0.246532890394339]
	TIME [epoch: 13 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22829203153608477		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.22829203153608477 | validation: 0.3074002791152986]
	TIME [epoch: 13 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2809516859528247		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.2809516859528247 | validation: 0.23017536604291455]
	TIME [epoch: 13.1 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24681336315408758		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.24681336315408758 | validation: 0.2348056068393177]
	TIME [epoch: 13 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.243679688020693		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.243679688020693 | validation: 0.4537198490684509]
	TIME [epoch: 13 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3638449609065193		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.3638449609065193 | validation: 0.26659132814139347]
	TIME [epoch: 13.1 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2255375418168347		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.2255375418168347 | validation: 0.17246422134582315]
	TIME [epoch: 13 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708781568646134		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.1708781568646134 | validation: 0.6702708999463997]
	TIME [epoch: 13 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4772397479800169		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.4772397479800169 | validation: 0.324704612802332]
	TIME [epoch: 13.1 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25734464280617025		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.25734464280617025 | validation: 0.15367509359797946]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_704.pth
	Model improved!!!
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21684502109259918		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.21684502109259918 | validation: 0.28380654876880224]
	TIME [epoch: 13 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23764265681866453		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.23764265681866453 | validation: 0.2848069018339459]
	TIME [epoch: 13 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28122615103951576		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.28122615103951576 | validation: 0.20940701409141516]
	TIME [epoch: 13.1 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2369687837503365		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.2369687837503365 | validation: 0.2972587257114778]
	TIME [epoch: 13 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21577233503344323		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.21577233503344323 | validation: 0.20992841985862062]
	TIME [epoch: 13 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24604305651467356		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.24604305651467356 | validation: 0.24326451347679728]
	TIME [epoch: 13.1 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19471353815559145		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.19471353815559145 | validation: 0.18644566794209463]
	TIME [epoch: 13 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2644432533297878		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.2644432533297878 | validation: 0.2098920447416996]
	TIME [epoch: 13 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1929383249336444		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.1929383249336444 | validation: 0.17766034809725115]
	TIME [epoch: 13 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19549945710702238		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.19549945710702238 | validation: 0.15998532888238076]
	TIME [epoch: 13 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21348025411312338		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.21348025411312338 | validation: 0.14408663882197928]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_715.pth
	Model improved!!!
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26515652101919723		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.26515652101919723 | validation: 0.18416149572056725]
	TIME [epoch: 13 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20359080816008882		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.20359080816008882 | validation: 0.4358341034312758]
	TIME [epoch: 13.1 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31956679548348593		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.31956679548348593 | validation: 0.25375849906031045]
	TIME [epoch: 13 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301003766533413		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.3301003766533413 | validation: 0.2202882271772511]
	TIME [epoch: 13 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23869036524800305		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.23869036524800305 | validation: 0.29407435092454554]
	TIME [epoch: 13 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2637774767804222		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.2637774767804222 | validation: 0.3332542008646631]
	TIME [epoch: 13.1 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22215254427998019		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.22215254427998019 | validation: 0.16011974239773927]
	TIME [epoch: 13 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20361648760699813		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.20361648760699813 | validation: 0.23306985644926032]
	TIME [epoch: 13 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23048310204045797		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.23048310204045797 | validation: 0.19667242614075892]
	TIME [epoch: 13.1 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25094609096192577		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.25094609096192577 | validation: 0.19644926642169533]
	TIME [epoch: 13 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24182289643670424		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.24182289643670424 | validation: 0.34602509432977685]
	TIME [epoch: 13 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32971897560532976		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.32971897560532976 | validation: 0.3699589065404306]
	TIME [epoch: 13.1 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782312765047711		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.2782312765047711 | validation: 0.16660694879374852]
	TIME [epoch: 13 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18258764917390824		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.18258764917390824 | validation: 0.14653919184620642]
	TIME [epoch: 13 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2382215549468102		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.2382215549468102 | validation: 0.21228212530177668]
	TIME [epoch: 13.1 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2089817565608546		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.2089817565608546 | validation: 0.18137700498672824]
	TIME [epoch: 13 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20518360400860253		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.20518360400860253 | validation: 0.17447303738568387]
	TIME [epoch: 13 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003042997473135		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.3003042997473135 | validation: 0.2711387413428454]
	TIME [epoch: 13 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18749081935013		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.18749081935013 | validation: 0.14179954860857769]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_734.pth
	Model improved!!!
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18217290315947215		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.18217290315947215 | validation: 0.4079979642500585]
	TIME [epoch: 13 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3119944365099808		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.3119944365099808 | validation: 0.209334924566059]
	TIME [epoch: 13 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20318264803206468		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.20318264803206468 | validation: 0.28961154821981766]
	TIME [epoch: 13 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22646263200409888		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.22646263200409888 | validation: 0.19857203878786622]
	TIME [epoch: 13 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26924271416767626		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.26924271416767626 | validation: 0.20320196584863137]
	TIME [epoch: 13 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21693022701827588		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.21693022701827588 | validation: 0.1548211599949336]
	TIME [epoch: 13 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18541246045391468		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.18541246045391468 | validation: 0.17968221652792232]
	TIME [epoch: 13 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2138279959011862		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.2138279959011862 | validation: 0.2850770952060126]
	TIME [epoch: 13 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.256255732818669		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.256255732818669 | validation: 0.2032783610113225]
	TIME [epoch: 13 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2033364996211003		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.2033364996211003 | validation: 0.16314697414726062]
	TIME [epoch: 13 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20091390572863388		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.20091390572863388 | validation: 0.3090127451694061]
	TIME [epoch: 13 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26371316154391883		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.26371316154391883 | validation: 0.19891040953330638]
	TIME [epoch: 13 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19413774147123547		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.19413774147123547 | validation: 0.20395870635716123]
	TIME [epoch: 13.1 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17628121667425306		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.17628121667425306 | validation: 0.18811105163561972]
	TIME [epoch: 13 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18913130671926143		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.18913130671926143 | validation: 0.1574753134806596]
	TIME [epoch: 13 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21513554816033392		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.21513554816033392 | validation: 0.2563256288588748]
	TIME [epoch: 13.1 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2098023670516629		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.2098023670516629 | validation: 0.28176869943612676]
	TIME [epoch: 13 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650682109614708		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.2650682109614708 | validation: 0.2221152686201795]
	TIME [epoch: 13 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1855333340216743		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.1855333340216743 | validation: 0.27843599123617485]
	TIME [epoch: 13 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23035669772439146		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.23035669772439146 | validation: 0.19146192172816417]
	TIME [epoch: 13.1 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21524622768799817		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.21524622768799817 | validation: 0.18620058217948007]
	TIME [epoch: 13 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1903832782439196		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.1903832782439196 | validation: 0.19931182385435187]
	TIME [epoch: 13 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19532312710294614		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.19532312710294614 | validation: 0.25309232255151615]
	TIME [epoch: 13.1 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2728511715161993		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.2728511715161993 | validation: 0.14424656869220903]
	TIME [epoch: 13 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15663660867876883		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.15663660867876883 | validation: 0.22069222695180593]
	TIME [epoch: 13 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.178184186569274		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.178184186569274 | validation: 0.1334873026588594]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_760.pth
	Model improved!!!
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.163492333515835		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.163492333515835 | validation: 0.142584345661309]
	TIME [epoch: 13 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17580551988113496		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.17580551988113496 | validation: 0.212910809026796]
	TIME [epoch: 13 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1669432265085748		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.1669432265085748 | validation: 0.17991749785397254]
	TIME [epoch: 13 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21258076961315592		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.21258076961315592 | validation: 0.16671128912030253]
	TIME [epoch: 13 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17095439742374272		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.17095439742374272 | validation: 0.16655447805699278]
	TIME [epoch: 13 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16049971801117996		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.16049971801117996 | validation: 0.14312276034449137]
	TIME [epoch: 13 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17208590690439973		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.17208590690439973 | validation: 0.19242615151612966]
	TIME [epoch: 13 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22554179261346372		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.22554179261346372 | validation: 0.17872162226503296]
	TIME [epoch: 13 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18821994340409962		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.18821994340409962 | validation: 0.18067920034127252]
	TIME [epoch: 13 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15969379144210344		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.15969379144210344 | validation: 0.22601823521065523]
	TIME [epoch: 13 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103648266353139		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.3103648266353139 | validation: 0.23385829178367573]
	TIME [epoch: 13 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17967115576419687		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.17967115576419687 | validation: 0.12181202994946035]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_772.pth
	Model improved!!!
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15073125201557155		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.15073125201557155 | validation: 0.1429358962731687]
	TIME [epoch: 13 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1591961714276075		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.1591961714276075 | validation: 0.2449960268839974]
	TIME [epoch: 13 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31740505012316855		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.31740505012316855 | validation: 0.281228124548768]
	TIME [epoch: 13 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24059295123976884		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.24059295123976884 | validation: 0.16739157257964984]
	TIME [epoch: 13 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17382339891089255		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.17382339891089255 | validation: 0.15498051348660252]
	TIME [epoch: 13 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17933642767532576		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.17933642767532576 | validation: 0.21321733839032456]
	TIME [epoch: 13 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18594229460529887		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.18594229460529887 | validation: 0.20845342536929454]
	TIME [epoch: 13 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20323756144649818		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.20323756144649818 | validation: 0.41989655821832317]
	TIME [epoch: 13 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28519681062474744		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.28519681062474744 | validation: 0.1588436351142055]
	TIME [epoch: 13 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17429032567447741		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.17429032567447741 | validation: 0.19771020764779304]
	TIME [epoch: 13 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19966504208548122		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.19966504208548122 | validation: 0.1774580725866803]
	TIME [epoch: 13 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21405863546994264		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.21405863546994264 | validation: 0.2555404248738951]
	TIME [epoch: 13 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21515112788826368		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.21515112788826368 | validation: 0.219535870078114]
	TIME [epoch: 13 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2417100105402437		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.2417100105402437 | validation: 0.2158987991332169]
	TIME [epoch: 13 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.212576974876782		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.212576974876782 | validation: 0.24928510793734598]
	TIME [epoch: 13 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19577058100907468		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.19577058100907468 | validation: 0.15384783468687624]
	TIME [epoch: 13 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20363328497288777		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.20363328497288777 | validation: 0.27167743066426564]
	TIME [epoch: 13 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2042607164255627		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.2042607164255627 | validation: 0.2775049223523128]
	TIME [epoch: 13 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19654888726039643		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.19654888726039643 | validation: 0.2111910584249929]
	TIME [epoch: 13 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17556859497343136		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.17556859497343136 | validation: 0.17993108260929389]
	TIME [epoch: 13 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16259130870753957		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.16259130870753957 | validation: 0.19894157718774147]
	TIME [epoch: 13 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18454192783261683		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.18454192783261683 | validation: 0.1281788475046375]
	TIME [epoch: 13 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21012506838431905		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.21012506838431905 | validation: 0.1666493077629257]
	TIME [epoch: 13 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2058753238438395		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.2058753238438395 | validation: 0.16754711048983292]
	TIME [epoch: 13 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2504099635494836		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.2504099635494836 | validation: 0.17914919817273314]
	TIME [epoch: 13 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21416058586785391		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.21416058586785391 | validation: 0.22037815942509323]
	TIME [epoch: 13 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1814627770278024		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.1814627770278024 | validation: 0.1642944980668651]
	TIME [epoch: 13 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1696826790546872		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.1696826790546872 | validation: 0.2058351931312783]
	TIME [epoch: 13 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21775281833233165		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.21775281833233165 | validation: 0.22923343602276283]
	TIME [epoch: 13 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18334538854745597		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.18334538854745597 | validation: 0.16540318646522906]
	TIME [epoch: 13 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18685453949313466		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.18685453949313466 | validation: 0.2802281668838183]
	TIME [epoch: 13 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22227116526333365		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.22227116526333365 | validation: 0.23258729248410676]
	TIME [epoch: 13 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21474801708476252		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.21474801708476252 | validation: 0.14115316167980815]
	TIME [epoch: 13 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21960838125383425		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.21960838125383425 | validation: 0.2875212893227062]
	TIME [epoch: 13 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2140166116133386		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.2140166116133386 | validation: 0.15526600896459128]
	TIME [epoch: 13.1 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17006030866557625		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.17006030866557625 | validation: 0.1536469566387832]
	TIME [epoch: 13 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13985231884333474		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.13985231884333474 | validation: 0.19075220028018314]
	TIME [epoch: 13 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2378435610428017		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.2378435610428017 | validation: 0.19486064294542627]
	TIME [epoch: 13 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19092610495924764		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.19092610495924764 | validation: 0.17138258644689722]
	TIME [epoch: 13 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22683206863243588		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.22683206863243588 | validation: 0.22118565709612148]
	TIME [epoch: 13 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2351506773529657		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.2351506773529657 | validation: 0.247010395091974]
	TIME [epoch: 13 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19351898177679355		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.19351898177679355 | validation: 0.17367242700546467]
	TIME [epoch: 13 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18451312993476657		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.18451312993476657 | validation: 0.14700531692089377]
	TIME [epoch: 13 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17462281147031866		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.17462281147031866 | validation: 0.16256232305493762]
	TIME [epoch: 13 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21335077777441444		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.21335077777441444 | validation: 0.14751033860068247]
	TIME [epoch: 13 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15333505441270873		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.15333505441270873 | validation: 0.1727650773831686]
	TIME [epoch: 13 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18405217690544828		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.18405217690544828 | validation: 0.23510219014259506]
	TIME [epoch: 13 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18262003583734182		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.18262003583734182 | validation: 0.17780690858970558]
	TIME [epoch: 13.1 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18432318725861369		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.18432318725861369 | validation: 0.17441829202505096]
	TIME [epoch: 13 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.214041243888625		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.214041243888625 | validation: 0.20880020684951917]
	TIME [epoch: 13 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19339067329704449		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.19339067329704449 | validation: 0.21491993562796605]
	TIME [epoch: 13 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17889943090747565		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.17889943090747565 | validation: 0.13569022688421378]
	TIME [epoch: 13 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15374417398039963		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.15374417398039963 | validation: 0.11453644437639263]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_825.pth
	Model improved!!!
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13831874049618056		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.13831874049618056 | validation: 0.12759598555360863]
	TIME [epoch: 13 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331548340893956		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.1331548340893956 | validation: 0.1080106990781622]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_827.pth
	Model improved!!!
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14000385107091157		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.14000385107091157 | validation: 0.1709000893103633]
	TIME [epoch: 13 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14916054681296292		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.14916054681296292 | validation: 0.24344306872183588]
	TIME [epoch: 13 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22101288750400672		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.22101288750400672 | validation: 0.1423733286074619]
	TIME [epoch: 13 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14374906169501186		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.14374906169501186 | validation: 0.16484339161905937]
	TIME [epoch: 13 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16805129267391694		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.16805129267391694 | validation: 0.20831283275382617]
	TIME [epoch: 13 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17771706108727192		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.17771706108727192 | validation: 0.17394528421884395]
	TIME [epoch: 13 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1893656145331101		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.1893656145331101 | validation: 0.16287785010631814]
	TIME [epoch: 13 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13361457158286208		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.13361457158286208 | validation: 0.13760244210663128]
	TIME [epoch: 13 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21963924196824694		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.21963924196824694 | validation: 0.19602909133463503]
	TIME [epoch: 13 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16954141884220106		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.16954141884220106 | validation: 0.12641178942449433]
	TIME [epoch: 13 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28505476623960063		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.28505476623960063 | validation: 0.41722231626146256]
	TIME [epoch: 13 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3767337784213056		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.3767337784213056 | validation: 0.17438146398977314]
	TIME [epoch: 13 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17779484090940822		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.17779484090940822 | validation: 0.15482539123275363]
	TIME [epoch: 13 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1538262631378089		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.1538262631378089 | validation: 0.13647079944880214]
	TIME [epoch: 13 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16397672518628037		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.16397672518628037 | validation: 0.15901589880841668]
	TIME [epoch: 13 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2061753107126187		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.2061753107126187 | validation: 0.1787543916902458]
	TIME [epoch: 13 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19830952360588516		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.19830952360588516 | validation: 0.16991065289503568]
	TIME [epoch: 13 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1535009348814606		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.1535009348814606 | validation: 0.22746062136478287]
	TIME [epoch: 13 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18430325210180015		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.18430325210180015 | validation: 0.16100113467226324]
	TIME [epoch: 13 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14012991426165813		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.14012991426165813 | validation: 0.21472925694482065]
	TIME [epoch: 13 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20919819534559442		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.20919819534559442 | validation: 0.1772352334810406]
	TIME [epoch: 13 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15725319834756277		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.15725319834756277 | validation: 0.17529809236224334]
	TIME [epoch: 13 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21681912754902402		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.21681912754902402 | validation: 0.19068021176926583]
	TIME [epoch: 13 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15500152620674473		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.15500152620674473 | validation: 0.15154057735309023]
	TIME [epoch: 13 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133473785501935		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.133473785501935 | validation: 0.13799858435968934]
	TIME [epoch: 13 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13640346807084833		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.13640346807084833 | validation: 0.18067534606065494]
	TIME [epoch: 13 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446083190438576		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.1446083190438576 | validation: 0.19942880399712587]
	TIME [epoch: 13 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.235733874652023		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.235733874652023 | validation: 0.13441015702471099]
	TIME [epoch: 13 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13759304145140988		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.13759304145140988 | validation: 0.16834204925006774]
	TIME [epoch: 13 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13466667680144104		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.13466667680144104 | validation: 0.14307359768775457]
	TIME [epoch: 13.1 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315116234629568		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.1315116234629568 | validation: 0.14462562260119857]
	TIME [epoch: 13 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14161495748019576		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.14161495748019576 | validation: 0.1818837012712978]
	TIME [epoch: 13 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15919876128839985		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.15919876128839985 | validation: 0.16710551824362477]
	TIME [epoch: 13.1 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16237594519222753		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.16237594519222753 | validation: 0.15320074696174873]
	TIME [epoch: 13 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13457849807817857		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.13457849807817857 | validation: 0.13978893214750662]
	TIME [epoch: 13 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13973153843013675		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.13973153843013675 | validation: 0.1822720430505039]
	TIME [epoch: 13.1 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16252628914313638		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.16252628914313638 | validation: 0.1843777765411496]
	TIME [epoch: 13 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17431909635652532		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.17431909635652532 | validation: 0.19445925313807336]
	TIME [epoch: 13 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16503786511965174		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.16503786511965174 | validation: 0.1355379896630553]
	TIME [epoch: 13 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14162225401706605		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.14162225401706605 | validation: 0.13639481311208163]
	TIME [epoch: 13.1 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16503741548999035		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.16503741548999035 | validation: 0.13360425702512949]
	TIME [epoch: 13 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14582942551475578		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.14582942551475578 | validation: 0.13902710832375037]
	TIME [epoch: 13 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1447799686012956		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.1447799686012956 | validation: 0.207107566649063]
	TIME [epoch: 13.1 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16997313968101796		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.16997313968101796 | validation: 0.15507396978895407]
	TIME [epoch: 13 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17674272088870355		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.17674272088870355 | validation: 0.13683292403439892]
	TIME [epoch: 13 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15612856896580166		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.15612856896580166 | validation: 0.1436458512011155]
	TIME [epoch: 13 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14779399449566022		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.14779399449566022 | validation: 0.13361785011560795]
	TIME [epoch: 13 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19756017435235007		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.19756017435235007 | validation: 0.16175165089786728]
	TIME [epoch: 13 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896032810341846		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.1896032810341846 | validation: 0.1725117026631653]
	TIME [epoch: 13 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16396049457901296		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.16396049457901296 | validation: 0.15847865128442887]
	TIME [epoch: 13 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16003259970512979		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.16003259970512979 | validation: 0.14188545726670962]
	TIME [epoch: 13 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13755295101334392		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.13755295101334392 | validation: 0.14411700787371215]
	TIME [epoch: 13 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329029167291988		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.1329029167291988 | validation: 0.11778526627411302]
	TIME [epoch: 13.1 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14120322038722685		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.14120322038722685 | validation: 0.16212633386922845]
	TIME [epoch: 13 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21317062911934676		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.21317062911934676 | validation: 0.16161633198370962]
	TIME [epoch: 13 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15424811931153437		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.15424811931153437 | validation: 0.15485395843158217]
	TIME [epoch: 13.1 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15967506512136337		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.15967506512136337 | validation: 0.21321072948689818]
	TIME [epoch: 13 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.167190336172588		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.167190336172588 | validation: 0.15820346537230656]
	TIME [epoch: 13 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385723939569924		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.1385723939569924 | validation: 0.19107671758456962]
	TIME [epoch: 13.1 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1541122594629638		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.1541122594629638 | validation: 0.14556524058008877]
	TIME [epoch: 13 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14197118652689064		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.14197118652689064 | validation: 0.1247509295371161]
	TIME [epoch: 13 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11954429966003191		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.11954429966003191 | validation: 0.12455003370546613]
	TIME [epoch: 13 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13501003294243796		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.13501003294243796 | validation: 0.11761543130215409]
	TIME [epoch: 13.1 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14084752644585868		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.14084752644585868 | validation: 0.1669474753517471]
	TIME [epoch: 13 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18221780806796709		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.18221780806796709 | validation: 0.19290936377131435]
	TIME [epoch: 13 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20256691536730206		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.20256691536730206 | validation: 0.12373112536036236]
	TIME [epoch: 13.1 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14842067183328073		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.14842067183328073 | validation: 0.12616785019422008]
	TIME [epoch: 13 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15205752049175789		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.15205752049175789 | validation: 0.14360544638562384]
	TIME [epoch: 13 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1345314554617439		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.1345314554617439 | validation: 0.16447443434440304]
	TIME [epoch: 13.1 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14651533523018806		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.14651533523018806 | validation: 0.14288779968657728]
	TIME [epoch: 13 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14426844939756556		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.14426844939756556 | validation: 0.1395004948672865]
	TIME [epoch: 13 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13973258095941857		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.13973258095941857 | validation: 0.12561417197788213]
	TIME [epoch: 13.1 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15549492878195		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.15549492878195 | validation: 0.28989516684208794]
	TIME [epoch: 13.1 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19781319911182663		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.19781319911182663 | validation: 0.1891253453357469]
	TIME [epoch: 13 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17227192046146023		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.17227192046146023 | validation: 0.13223830683666787]
	TIME [epoch: 13.1 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11738035668944799		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.11738035668944799 | validation: 0.10837683261808118]
	TIME [epoch: 13.1 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13415001843626306		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.13415001843626306 | validation: 0.15828810684003747]
	TIME [epoch: 13 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1671176675750825		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.1671176675750825 | validation: 0.1139644790909266]
	TIME [epoch: 13.1 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15189294876891007		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.15189294876891007 | validation: 0.12082658205419812]
	TIME [epoch: 13.1 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14745101592770954		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.14745101592770954 | validation: 0.13542352427411913]
	TIME [epoch: 13 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15999922041218187		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.15999922041218187 | validation: 0.13138704521097108]
	TIME [epoch: 13 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12232902170822993		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.12232902170822993 | validation: 0.13748045131069236]
	TIME [epoch: 13.1 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11783766598055513		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.11783766598055513 | validation: 0.15510345623222427]
	TIME [epoch: 13 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307152154037799		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.1307152154037799 | validation: 0.15801094611772507]
	TIME [epoch: 13.1 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17498779385433036		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.17498779385433036 | validation: 0.13826428331391769]
	TIME [epoch: 13 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18251337888208413		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.18251337888208413 | validation: 0.15213348617498004]
	TIME [epoch: 13.1 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16037491285640842		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.16037491285640842 | validation: 0.16469280401668113]
	TIME [epoch: 13 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17324921982276364		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.17324921982276364 | validation: 0.14853672597452036]
	TIME [epoch: 13 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16220296488317776		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.16220296488317776 | validation: 0.15849442597746977]
	TIME [epoch: 13.1 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1457619682411291		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.1457619682411291 | validation: 0.13351158321937046]
	TIME [epoch: 13 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14285319267129032		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.14285319267129032 | validation: 0.14296004928658276]
	TIME [epoch: 13 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1668331223318304		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.1668331223318304 | validation: 0.17800129541410897]
	TIME [epoch: 13.1 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14096681971520014		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.14096681971520014 | validation: 0.13307734720485973]
	TIME [epoch: 13 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141876928114931		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.141876928114931 | validation: 0.17142373331380736]
	TIME [epoch: 13 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17494574721358808		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.17494574721358808 | validation: 0.1859680593022027]
	TIME [epoch: 13 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16680078139539137		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.16680078139539137 | validation: 0.14443594657306383]
	TIME [epoch: 13 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17344531639379768		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.17344531639379768 | validation: 0.22454365229218148]
	TIME [epoch: 13 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17379558429379965		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.17379558429379965 | validation: 0.12736218370092767]
	TIME [epoch: 13.1 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13961406363722123		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.13961406363722123 | validation: 0.12449541060286126]
	TIME [epoch: 13.1 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13922955219515204		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.13922955219515204 | validation: 0.15290529818448165]
	TIME [epoch: 13 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14126612761051194		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.14126612761051194 | validation: 0.14611348499285223]
	TIME [epoch: 13 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14149072093194837		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.14149072093194837 | validation: 0.13176105965865526]
	TIME [epoch: 13.1 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448436407591146		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.1448436407591146 | validation: 0.17717637857290128]
	TIME [epoch: 13 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14700761542479873		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.14700761542479873 | validation: 0.12425548250482646]
	TIME [epoch: 13 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424726565688526		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.1424726565688526 | validation: 0.144754491593402]
	TIME [epoch: 13.1 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485030731056786		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.1485030731056786 | validation: 0.17113509765548607]
	TIME [epoch: 13 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14214957376165116		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.14214957376165116 | validation: 0.12334688059718603]
	TIME [epoch: 13 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15469020575940223		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.15469020575940223 | validation: 0.1521484616231821]
	TIME [epoch: 13.1 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13507928739101918		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.13507928739101918 | validation: 0.12504146883193445]
	TIME [epoch: 13 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.161677433998707		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.161677433998707 | validation: 0.14818310638403862]
	TIME [epoch: 13 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12620438632121608		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.12620438632121608 | validation: 0.11891648876392336]
	TIME [epoch: 13 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11823012772620062		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.11823012772620062 | validation: 0.12031428001336344]
	TIME [epoch: 13 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12817024754356024		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.12817024754356024 | validation: 0.15871235410532722]
	TIME [epoch: 13 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14470877099253285		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.14470877099253285 | validation: 0.11866797609718752]
	TIME [epoch: 13 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338145483377646		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.1338145483377646 | validation: 0.13377593030047524]
	TIME [epoch: 13.1 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12989054019184393		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.12989054019184393 | validation: 0.16065154237431492]
	TIME [epoch: 13 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13042043617066293		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.13042043617066293 | validation: 0.10725686853394457]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_944.pth
	Model improved!!!
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380496981083703		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.1380496981083703 | validation: 0.22428101779394524]
	TIME [epoch: 13.1 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16048838126320628		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.16048838126320628 | validation: 0.11686907899678918]
	TIME [epoch: 13 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13051678062916974		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.13051678062916974 | validation: 0.1600031604322425]
	TIME [epoch: 13 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16394456824121958		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.16394456824121958 | validation: 0.13180580956788504]
	TIME [epoch: 13 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13908711515897007		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.13908711515897007 | validation: 0.14527575824139227]
	TIME [epoch: 13.1 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13622104785848038		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.13622104785848038 | validation: 0.140783901000088]
	TIME [epoch: 13 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12826582327967556		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.12826582327967556 | validation: 0.1452168160659802]
	TIME [epoch: 13 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14109489583582724		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.14109489583582724 | validation: 0.1884482339906628]
	TIME [epoch: 13.1 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14500337610001446		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.14500337610001446 | validation: 0.1397155091411527]
	TIME [epoch: 13 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14736177754250132		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.14736177754250132 | validation: 0.13175143293984967]
	TIME [epoch: 13 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15817301227387812		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.15817301227387812 | validation: 0.17108625290354482]
	TIME [epoch: 13.1 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14763630998278957		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.14763630998278957 | validation: 0.14796531865169615]
	TIME [epoch: 13 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1576747312694873		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.1576747312694873 | validation: 0.1753769232828906]
	TIME [epoch: 13 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13966795225557205		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.13966795225557205 | validation: 0.15733253322989035]
	TIME [epoch: 13 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483752439911593		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.1483752439911593 | validation: 0.1586327673901761]
	TIME [epoch: 13.1 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168337588637158		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.168337588637158 | validation: 0.1340701404641431]
	TIME [epoch: 13 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14915933570918433		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.14915933570918433 | validation: 0.16806818032865523]
	TIME [epoch: 13 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15968749296109855		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.15968749296109855 | validation: 0.16589118757378787]
	TIME [epoch: 13.1 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13060743569879585		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.13060743569879585 | validation: 0.17953897468942348]
	TIME [epoch: 13 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1399977029906075		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.1399977029906075 | validation: 0.13972515765594856]
	TIME [epoch: 13 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13121428173908967		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.13121428173908967 | validation: 0.1367936881193874]
	TIME [epoch: 13.1 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250139991599232		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.1250139991599232 | validation: 0.25706647154137374]
	TIME [epoch: 13 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17193419425657872		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.17193419425657872 | validation: 0.11997608360542879]
	TIME [epoch: 13 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12061873779597684		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.12061873779597684 | validation: 0.11646997191826194]
	TIME [epoch: 13.1 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13006240007836736		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.13006240007836736 | validation: 0.12210358142644044]
	TIME [epoch: 13 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12567175748028375		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.12567175748028375 | validation: 0.1589362450300343]
	TIME [epoch: 13 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16030847997855371		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.16030847997855371 | validation: 0.15029451860733498]
	TIME [epoch: 13 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1691271495202598		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.1691271495202598 | validation: 0.20966543823191658]
	TIME [epoch: 13.1 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17468262342616286		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.17468262342616286 | validation: 0.14113824370401085]
	TIME [epoch: 13 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13106875636058007		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.13106875636058007 | validation: 0.14769784860976837]
	TIME [epoch: 13 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14163877944160436		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.14163877944160436 | validation: 0.12553015492542216]
	TIME [epoch: 13.1 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13312535347127194		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.13312535347127194 | validation: 0.12650748137506004]
	TIME [epoch: 13 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12216576641775707		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.12216576641775707 | validation: 0.1607647893072135]
	TIME [epoch: 13 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13875002684458715		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.13875002684458715 | validation: 0.16357203922284086]
	TIME [epoch: 13.1 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15307723434629372		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.15307723434629372 | validation: 0.1270919885664554]
	TIME [epoch: 13 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12982166269539777		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.12982166269539777 | validation: 0.15156554672780406]
	TIME [epoch: 13 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13931687982404636		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.13931687982404636 | validation: 0.12934500213828803]
	TIME [epoch: 13 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13821908991152776		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.13821908991152776 | validation: 0.16684818131378504]
	TIME [epoch: 13.1 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14510141648281932		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.14510141648281932 | validation: 0.17258456362098312]
	TIME [epoch: 13 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15405292378892643		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.15405292378892643 | validation: 0.16483245924377904]
	TIME [epoch: 13 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13395389033398747		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.13395389033398747 | validation: 0.12383097883641105]
	TIME [epoch: 13 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14647317563094808		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.14647317563094808 | validation: 0.14047591439358553]
	TIME [epoch: 13 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302676232801711		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.1302676232801711 | validation: 0.12851855495832795]
	TIME [epoch: 13 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14023674126989943		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.14023674126989943 | validation: 0.15097088884938992]
	TIME [epoch: 13 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13803064306812987		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.13803064306812987 | validation: 0.1046105132457776]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_989.pth
	Model improved!!!
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11558545173938464		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.11558545173938464 | validation: 0.15943618731148318]
	TIME [epoch: 13 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14961075535816576		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.14961075535816576 | validation: 0.12073597327479119]
	TIME [epoch: 13 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1188220571318348		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.1188220571318348 | validation: 0.13579482673244186]
	TIME [epoch: 13 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.148204355404953		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.148204355404953 | validation: 0.13449984491648537]
	TIME [epoch: 13 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369089157502583		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.1369089157502583 | validation: 0.16539658484101386]
	TIME [epoch: 13 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14238921431680188		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.14238921431680188 | validation: 0.12171384364500677]
	TIME [epoch: 13 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11598292402282066		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.11598292402282066 | validation: 0.1076843043812599]
	TIME [epoch: 13 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11880172662637907		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.11880172662637907 | validation: 0.1082408720841827]
	TIME [epoch: 13 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19449344488717057		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.19449344488717057 | validation: 0.2222051331743291]
	TIME [epoch: 13.1 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838754012316366		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.1838754012316366 | validation: 0.14146448100488396]
	TIME [epoch: 13 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338970832778196		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.1338970832778196 | validation: 0.13212726510430844]
	TIME [epoch: 13 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15244345778583407		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.15244345778583407 | validation: 0.13933079911760649]
	TIME [epoch: 13 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15179320948117678		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.15179320948117678 | validation: 0.18782340127443273]
	TIME [epoch: 13 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20267411038873		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.20267411038873 | validation: 0.14949683888831325]
	TIME [epoch: 13 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13004736216466553		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.13004736216466553 | validation: 0.14344937020038945]
	TIME [epoch: 13 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16658042406005946		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.16658042406005946 | validation: 0.14616500855118963]
	TIME [epoch: 13 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13645702276474103		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.13645702276474103 | validation: 0.1200535546778298]
	TIME [epoch: 13 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11823683990056486		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.11823683990056486 | validation: 0.16599601881990061]
	TIME [epoch: 13 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14258924961130276		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.14258924961130276 | validation: 0.09380136221310138]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1008.pth
	Model improved!!!
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12799166423581165		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.12799166423581165 | validation: 0.12187117644025328]
	TIME [epoch: 13 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11504769975301499		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.11504769975301499 | validation: 0.1110047966478014]
	TIME [epoch: 13 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11244111534945281		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.11244111534945281 | validation: 0.1182200456266005]
	TIME [epoch: 13 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11447601646745888		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.11447601646745888 | validation: 0.12301237257206124]
	TIME [epoch: 13 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11928201913876307		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.11928201913876307 | validation: 0.1396052947033029]
	TIME [epoch: 13 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483254760097567		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.1483254760097567 | validation: 0.1355330866997359]
	TIME [epoch: 13 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15796576739073195		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.15796576739073195 | validation: 0.16361924692901766]
	TIME [epoch: 13.1 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293933688486123		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.1293933688486123 | validation: 0.14149413177713827]
	TIME [epoch: 13 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1198398284832698		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.1198398284832698 | validation: 0.13589071718569679]
	TIME [epoch: 13 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13327037642840994		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.13327037642840994 | validation: 0.14016819104074998]
	TIME [epoch: 13.1 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390804231084839		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.1390804231084839 | validation: 0.10534986361923725]
	TIME [epoch: 13 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11070506254448667		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.11070506254448667 | validation: 0.11583184731158089]
	TIME [epoch: 13 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12777443006076672		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.12777443006076672 | validation: 0.11628104924741912]
	TIME [epoch: 13 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1103883075710625		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.1103883075710625 | validation: 0.1150767260462313]
	TIME [epoch: 13.1 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14216505170393345		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.14216505170393345 | validation: 0.12530876359238324]
	TIME [epoch: 13 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11476764554019171		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.11476764554019171 | validation: 0.11648330768742648]
	TIME [epoch: 13 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12494278005295886		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.12494278005295886 | validation: 0.11210366366443236]
	TIME [epoch: 13 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12088168823099422		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.12088168823099422 | validation: 0.16080271232582796]
	TIME [epoch: 13 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12780735425761194		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.12780735425761194 | validation: 0.14407529762242866]
	TIME [epoch: 13 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16504359540703387		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.16504359540703387 | validation: 0.2159247007613417]
	TIME [epoch: 13 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663453282050978		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.1663453282050978 | validation: 0.13213316940452147]
	TIME [epoch: 13 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12849365637807708		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.12849365637807708 | validation: 0.13818047735138794]
	TIME [epoch: 13 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13149179400310987		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.13149179400310987 | validation: 0.1690243775347415]
	TIME [epoch: 13 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16653531012821193		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.16653531012821193 | validation: 0.21393960591482244]
	TIME [epoch: 13.1 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16671175760271917		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.16671175760271917 | validation: 0.162512455617443]
	TIME [epoch: 13 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13622572286785084		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.13622572286785084 | validation: 0.15049592459638242]
	TIME [epoch: 13 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13576599761722558		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.13576599761722558 | validation: 0.14808310271289876]
	TIME [epoch: 13.1 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323094458696785		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.1323094458696785 | validation: 0.1418873675292061]
	TIME [epoch: 13 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13903786991582948		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.13903786991582948 | validation: 0.15835851425374897]
	TIME [epoch: 13 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16117907829508024		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.16117907829508024 | validation: 0.14162656153773498]
	TIME [epoch: 13 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16074008511275284		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.16074008511275284 | validation: 0.19235865554712867]
	TIME [epoch: 13 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16828925175631004		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.16828925175631004 | validation: 0.12387662597698278]
	TIME [epoch: 13 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12150729991702802		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.12150729991702802 | validation: 0.12122517648932363]
	TIME [epoch: 13 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12346467811295224		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.12346467811295224 | validation: 0.13140917228438304]
	TIME [epoch: 13 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390337532481568		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.1390337532481568 | validation: 0.19471450455450728]
	TIME [epoch: 13 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14971122985482194		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.14971122985482194 | validation: 0.14594025122317603]
	TIME [epoch: 13 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11328570724742512		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.11328570724742512 | validation: 0.13416166771940685]
	TIME [epoch: 13 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12409712683665569		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.12409712683665569 | validation: 0.11112142640345876]
	TIME [epoch: 13 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11189506282682879		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.11189506282682879 | validation: 0.13204048916449132]
	TIME [epoch: 13 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13396971204799688		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.13396971204799688 | validation: 0.1365215734162801]
	TIME [epoch: 13.1 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14515962208878438		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.14515962208878438 | validation: 0.14229384667451941]
	TIME [epoch: 13 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15506498625307563		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.15506498625307563 | validation: 0.1091527081281376]
	TIME [epoch: 13 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10310621013867294		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.10310621013867294 | validation: 0.12154522615812134]
	TIME [epoch: 13 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286453519128178		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.1286453519128178 | validation: 0.12068018274874573]
	TIME [epoch: 13 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11878197606667684		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.11878197606667684 | validation: 0.12618535880960235]
	TIME [epoch: 13 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13405942698842715		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.13405942698842715 | validation: 0.1345063942093201]
	TIME [epoch: 13 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11715544357549215		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.11715544357549215 | validation: 0.11267003862226091]
	TIME [epoch: 13 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11201467680987842		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.11201467680987842 | validation: 0.10875113605627945]
	TIME [epoch: 13 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11100751292484308		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.11100751292484308 | validation: 0.12570244255421933]
	TIME [epoch: 13 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1196285210190187		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.1196285210190187 | validation: 0.16030853289985786]
	TIME [epoch: 13.1 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1476558165546926		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.1476558165546926 | validation: 0.17785098523935247]
	TIME [epoch: 13 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16606093812688572		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.16606093812688572 | validation: 0.17747310681200912]
	TIME [epoch: 13 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15398044974809832		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.15398044974809832 | validation: 0.147986505440027]
	TIME [epoch: 13 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11954293286556196		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.11954293286556196 | validation: 0.1100854463943648]
	TIME [epoch: 13 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11097963291951828		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.11097963291951828 | validation: 0.11314318072248376]
	TIME [epoch: 13 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10465974527514096		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.10465974527514096 | validation: 0.11977629744277327]
	TIME [epoch: 13 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11163502863620622		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.11163502863620622 | validation: 0.10675252153550019]
	TIME [epoch: 13.1 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10753333033595724		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.10753333033595724 | validation: 0.12797636325494888]
	TIME [epoch: 13 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15347355547495217		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.15347355547495217 | validation: 0.13972180989496122]
	TIME [epoch: 13 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133183250329686		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.133183250329686 | validation: 0.15046656116782475]
	TIME [epoch: 13 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276753618355216		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.1276753618355216 | validation: 0.1303910436377286]
	TIME [epoch: 13 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12215339807417988		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.12215339807417988 | validation: 0.13017427057806105]
	TIME [epoch: 13 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252770166438584		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.1252770166438584 | validation: 0.13011354534868477]
	TIME [epoch: 13.1 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13151042318147724		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.13151042318147724 | validation: 0.1449146534824511]
	TIME [epoch: 13 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15223437628453187		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.15223437628453187 | validation: 0.158284526243324]
	TIME [epoch: 13 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156186142117447		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.156186142117447 | validation: 0.1497213083791913]
	TIME [epoch: 13 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312122519719427		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.1312122519719427 | validation: 0.10609553126318359]
	TIME [epoch: 13 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11117275844678105		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.11117275844678105 | validation: 0.11580993870752866]
	TIME [epoch: 13 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.113106234976039		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.113106234976039 | validation: 0.10928660011397638]
	TIME [epoch: 13 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1136681630089538		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.1136681630089538 | validation: 0.10975451397607104]
	TIME [epoch: 13.1 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1116767179226262		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.1116767179226262 | validation: 0.12609674868173212]
	TIME [epoch: 13 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11415767370457777		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.11415767370457777 | validation: 0.10356916361756396]
	TIME [epoch: 13 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10966152740594157		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.10966152740594157 | validation: 0.1306825418231413]
	TIME [epoch: 13.1 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10384228492251829		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.10384228492251829 | validation: 0.12332133811186786]
	TIME [epoch: 13 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11246854650841871		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.11246854650841871 | validation: 0.1186011711235516]
	TIME [epoch: 13 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12021410562671914		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.12021410562671914 | validation: 0.14235338068308445]
	TIME [epoch: 13.1 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11904484192106413		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.11904484192106413 | validation: 0.12340958506960258]
	TIME [epoch: 13 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12210864467130375		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.12210864467130375 | validation: 0.12413408541459993]
	TIME [epoch: 13 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12614702841791875		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.12614702841791875 | validation: 0.15207215708657232]
	TIME [epoch: 13 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11960817612050756		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.11960817612050756 | validation: 0.11454020602177868]
	TIME [epoch: 13.1 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11522992971989565		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.11522992971989565 | validation: 0.11327742331780688]
	TIME [epoch: 13 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257676654238013		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.1257676654238013 | validation: 0.11532051501637394]
	TIME [epoch: 13 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1124737393691904		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.1124737393691904 | validation: 0.09975446979672876]
	TIME [epoch: 13.1 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11065036200608827		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.11065036200608827 | validation: 0.11005887323094798]
	TIME [epoch: 13 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12052773462869007		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.12052773462869007 | validation: 0.11792194705523398]
	TIME [epoch: 13 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125777929238396		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.125777929238396 | validation: 0.18920849949421364]
	TIME [epoch: 13.1 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1387024355852078		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.1387024355852078 | validation: 0.11142818134224652]
	TIME [epoch: 13 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10940946501661766		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.10940946501661766 | validation: 0.10310580024764177]
	TIME [epoch: 13 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11570359324054408		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.11570359324054408 | validation: 0.13430122486654825]
	TIME [epoch: 13.1 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13263213137204846		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.13263213137204846 | validation: 0.13997945293926234]
	TIME [epoch: 13 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11711884986154733		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.11711884986154733 | validation: 0.1128624736541407]
	TIME [epoch: 13 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10856595751454892		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.10856595751454892 | validation: 0.10650052942787203]
	TIME [epoch: 13 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1375289055119172		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.1375289055119172 | validation: 0.11313807429312263]
	TIME [epoch: 13 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11280610710810068		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.11280610710810068 | validation: 0.12881933910112112]
	TIME [epoch: 13 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10697751769181424		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.10697751769181424 | validation: 0.12006711294137452]
	TIME [epoch: 13 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13761453512031546		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.13761453512031546 | validation: 0.14789394927083038]
	TIME [epoch: 13.1 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14165952677274257		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.14165952677274257 | validation: 0.13373024487576277]
	TIME [epoch: 13 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11644974784247487		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.11644974784247487 | validation: 0.13717478659506782]
	TIME [epoch: 13 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11947878181302593		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.11947878181302593 | validation: 0.11006421385915267]
	TIME [epoch: 13 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10995303097788978		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.10995303097788978 | validation: 0.11314756906049912]
	TIME [epoch: 13 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1095099855973517		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.1095099855973517 | validation: 0.11658023266685782]
	TIME [epoch: 13 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10422683488422649		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.10422683488422649 | validation: 0.11989161302045066]
	TIME [epoch: 13 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11859527701269348		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.11859527701269348 | validation: 0.11866215014612255]
	TIME [epoch: 13 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014571222713446		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.1014571222713446 | validation: 0.11422083900626427]
	TIME [epoch: 13 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10575408041107641		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.10575408041107641 | validation: 0.09558232749720302]
	TIME [epoch: 13 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10060442135699368		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.10060442135699368 | validation: 0.11620634328741579]
	TIME [epoch: 13.1 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09812460388765493		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.09812460388765493 | validation: 0.09179675849417114]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1115.pth
	Model improved!!!
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10361150666981164		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.10361150666981164 | validation: 0.1102565407246771]
	TIME [epoch: 13 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11148191773505331		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.11148191773505331 | validation: 0.1112975279756175]
	TIME [epoch: 13.1 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09820648248245459		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.09820648248245459 | validation: 0.1137348257834207]
	TIME [epoch: 13 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09695134157892399		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.09695134157892399 | validation: 0.09492688193711787]
	TIME [epoch: 13 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10288246154316852		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.10288246154316852 | validation: 0.10786902765895377]
	TIME [epoch: 13 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10993145362483292		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.10993145362483292 | validation: 0.14071853700039008]
	TIME [epoch: 13.1 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13760073451390126		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.13760073451390126 | validation: 0.15577800040230422]
	TIME [epoch: 13 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282163458356353		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.1282163458356353 | validation: 0.105230975380652]
	TIME [epoch: 13 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10191979744902935		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.10191979744902935 | validation: 0.10122523727788969]
	TIME [epoch: 13.1 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11071813511027097		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.11071813511027097 | validation: 0.11757745278217996]
	TIME [epoch: 13 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1135873741830078		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.1135873741830078 | validation: 0.10653873407793064]
	TIME [epoch: 13 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10841091112569753		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.10841091112569753 | validation: 0.1022098171990078]
	TIME [epoch: 13.1 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12293130421984354		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.12293130421984354 | validation: 0.10983587229281547]
	TIME [epoch: 13 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11909693504430696		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.11909693504430696 | validation: 0.12258305291660766]
	TIME [epoch: 13 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11197380274366873		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.11197380274366873 | validation: 0.1032289596361465]
	TIME [epoch: 13.1 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10727964183021031		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.10727964183021031 | validation: 0.1251270048572494]
	TIME [epoch: 13 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1068650062102172		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.1068650062102172 | validation: 0.10569670175497065]
	TIME [epoch: 13 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1003661879262902		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.1003661879262902 | validation: 0.10814753516050923]
	TIME [epoch: 13 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1031532549918697		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.1031532549918697 | validation: 0.13545007268863093]
	TIME [epoch: 13.1 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1213440921842498		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.1213440921842498 | validation: 0.11818663856065482]
	TIME [epoch: 13 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10324049481030573		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.10324049481030573 | validation: 0.11361495808462481]
	TIME [epoch: 13 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1235357911829365		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.1235357911829365 | validation: 0.15261851414670627]
	TIME [epoch: 13.1 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12364193651497496		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.12364193651497496 | validation: 0.1241668314328938]
	TIME [epoch: 13 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10949721611656582		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.10949721611656582 | validation: 0.10747126300679458]
	TIME [epoch: 13 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10658618206173391		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.10658618206173391 | validation: 0.09456691157646066]
	TIME [epoch: 13.1 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09893578020444908		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.09893578020444908 | validation: 0.10562290811334013]
	TIME [epoch: 13 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1078839663119841		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.1078839663119841 | validation: 0.10810536099040129]
	TIME [epoch: 13 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10811053145857835		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.10811053145857835 | validation: 0.11113754673027558]
	TIME [epoch: 13 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.102346335322096		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.102346335322096 | validation: 0.11998226079766826]
	TIME [epoch: 13.1 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10983104809750606		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.10983104809750606 | validation: 0.1310531281488044]
	TIME [epoch: 13 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508300526907483		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.1508300526907483 | validation: 0.14718302111294926]
	TIME [epoch: 13 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12221690959371741		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.12221690959371741 | validation: 0.12209941373969299]
	TIME [epoch: 13.1 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10886030309586868		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.10886030309586868 | validation: 0.09019324987943474]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1148.pth
	Model improved!!!
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1061777725532132		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.1061777725532132 | validation: 0.11570477416210659]
	TIME [epoch: 13 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13692350078970753		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.13692350078970753 | validation: 0.10346960005549097]
	TIME [epoch: 13.1 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10441682093515461		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.10441682093515461 | validation: 0.09039725126803623]
	TIME [epoch: 13 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10023579802217608		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.10023579802217608 | validation: 0.09978520161270421]
	TIME [epoch: 13 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1161693196072453		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.1161693196072453 | validation: 0.1774125188625992]
	TIME [epoch: 13 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418861355916296		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.1418861355916296 | validation: 0.12266655733854225]
	TIME [epoch: 13 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10645038295818349		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.10645038295818349 | validation: 0.10798296473766957]
	TIME [epoch: 13 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11111734921553967		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.11111734921553967 | validation: 0.11314227357524867]
	TIME [epoch: 13 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10754416860458144		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.10754416860458144 | validation: 0.10818043213793972]
	TIME [epoch: 13.1 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11414287158807335		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.11414287158807335 | validation: 0.12021031118145799]
	TIME [epoch: 13 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12362618320838634		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.12362618320838634 | validation: 0.11892973053496655]
	TIME [epoch: 13 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16110402065362164		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.16110402065362164 | validation: 0.11814533265714525]
	TIME [epoch: 13.1 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11842409712719545		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.11842409712719545 | validation: 0.126525289681429]
	TIME [epoch: 13 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12461603168030186		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.12461603168030186 | validation: 0.10111971102293257]
	TIME [epoch: 13 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10441372061674473		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.10441372061674473 | validation: 0.09095225044776299]
	TIME [epoch: 13 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0980882078561964		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.0980882078561964 | validation: 0.12742244171675446]
	TIME [epoch: 13 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12946388915022597		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.12946388915022597 | validation: 0.13954345795083847]
	TIME [epoch: 13 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1122935835548058		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.1122935835548058 | validation: 0.13928055406689666]
	TIME [epoch: 13 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12820181681424947		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.12820181681424947 | validation: 0.11278930987339177]
	TIME [epoch: 13.1 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12837664579641178		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.12837664579641178 | validation: 0.11259851213213391]
	TIME [epoch: 13 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10954497858302567		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.10954497858302567 | validation: 0.10999890175606329]
	TIME [epoch: 13 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10504272631955455		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.10504272631955455 | validation: 0.09719933566100476]
	TIME [epoch: 13.1 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10685616755838817		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.10685616755838817 | validation: 0.1094186825249594]
	TIME [epoch: 13 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11051607108027388		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.11051607108027388 | validation: 0.10427050200708032]
	TIME [epoch: 13 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12136654588698029		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.12136654588698029 | validation: 0.11231277772005907]
	TIME [epoch: 13 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10788072759016532		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.10788072759016532 | validation: 0.1030535902139841]
	TIME [epoch: 13 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11118227943852654		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.11118227943852654 | validation: 0.11247975030189493]
	TIME [epoch: 13 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11169072082757653		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.11169072082757653 | validation: 0.10986485210283585]
	TIME [epoch: 13 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09987193991227157		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.09987193991227157 | validation: 0.11287187235587322]
	TIME [epoch: 13 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10989435755728492		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.10989435755728492 | validation: 0.1366563015417117]
	TIME [epoch: 13 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13195715742515904		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.13195715742515904 | validation: 0.11285428747484072]
	TIME [epoch: 13 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11718949994304755		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.11718949994304755 | validation: 0.10900840052412493]
	TIME [epoch: 13.1 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12958104790913938		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.12958104790913938 | validation: 0.13376001155665598]
	TIME [epoch: 13 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13130751725511808		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.13130751725511808 | validation: 0.11973086574351385]
	TIME [epoch: 13 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11493839363383557		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.11493839363383557 | validation: 0.10813788892670662]
	TIME [epoch: 13 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10848534896144625		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.10848534896144625 | validation: 0.09941806993594914]
	TIME [epoch: 13 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12805476779483532		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.12805476779483532 | validation: 0.11992698559772791]
	TIME [epoch: 13 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281035739601036		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.1281035739601036 | validation: 0.123168183439808]
	TIME [epoch: 13 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12553652803308818		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.12553652803308818 | validation: 0.11954996947104407]
	TIME [epoch: 13 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11163731508907318		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.11163731508907318 | validation: 0.1101739600054262]
	TIME [epoch: 13 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1173649940374426		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.1173649940374426 | validation: 0.12808499355207897]
	TIME [epoch: 13 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.116755280831155		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.116755280831155 | validation: 0.12352406507531835]
	TIME [epoch: 13.1 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11788639727835061		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.11788639727835061 | validation: 0.11129898685747236]
	TIME [epoch: 13 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11363045891667775		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.11363045891667775 | validation: 0.13488221644975573]
	TIME [epoch: 13 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12859314631852195		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.12859314631852195 | validation: 0.13672716000892363]
	TIME [epoch: 13 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346601962467678		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.1346601962467678 | validation: 0.1305882977372961]
	TIME [epoch: 13 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11999361030620571		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.11999361030620571 | validation: 0.12078263030114168]
	TIME [epoch: 13 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10637402347138529		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.10637402347138529 | validation: 0.11034478275413019]
	TIME [epoch: 13.1 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10429863065644678		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.10429863065644678 | validation: 0.10522371288436203]
	TIME [epoch: 13 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09637014691463841		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.09637014691463841 | validation: 0.09859786245448923]
	TIME [epoch: 13 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09861760872594028		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.09861760872594028 | validation: 0.09040247863094181]
	TIME [epoch: 13 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09907921020973533		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.09907921020973533 | validation: 0.1121542126095217]
	TIME [epoch: 13.1 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10763373918270627		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.10763373918270627 | validation: 0.09798500856974726]
	TIME [epoch: 13 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10919802636159615		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.10919802636159615 | validation: 0.11393282796060267]
	TIME [epoch: 13 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10826408306254968		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.10826408306254968 | validation: 0.10765029720525401]
	TIME [epoch: 13 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.102393351884261		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.102393351884261 | validation: 0.1123772428314767]
	TIME [epoch: 13 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11460000790777988		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.11460000790777988 | validation: 0.13914663678320227]
	TIME [epoch: 13 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11700356385653178		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.11700356385653178 | validation: 0.10554075928634443]
	TIME [epoch: 13.1 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11491150244227055		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.11491150244227055 | validation: 0.1235317201218302]
	TIME [epoch: 13 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442726295635049		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.10442726295635049 | validation: 0.11888942052782162]
	TIME [epoch: 13 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038624270920938		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.1038624270920938 | validation: 0.10173152008951299]
	TIME [epoch: 13.1 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09547673848317392		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.09547673848317392 | validation: 0.09888862904074]
	TIME [epoch: 13 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09962982619266893		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.09962982619266893 | validation: 0.10483461970436424]
	TIME [epoch: 13 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065678453706506		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.1065678453706506 | validation: 0.12211086850361266]
	TIME [epoch: 13 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038951158212285		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.11038951158212285 | validation: 0.11774832603421242]
	TIME [epoch: 13 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10948217406852878		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.10948217406852878 | validation: 0.10087707972407138]
	TIME [epoch: 13 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10956562937091616		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.10956562937091616 | validation: 0.14352612931264028]
	TIME [epoch: 13 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13339224465523533		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.13339224465523533 | validation: 0.10755950545817315]
	TIME [epoch: 13 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09286152145068877		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.09286152145068877 | validation: 0.09850929851554095]
	TIME [epoch: 13 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09779297069854304		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.09779297069854304 | validation: 0.10916025584001027]
	TIME [epoch: 13 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09874892375805268		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.09874892375805268 | validation: 0.11493996181686215]
	TIME [epoch: 13.1 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11222859725480513		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.11222859725480513 | validation: 0.10034086946716046]
	TIME [epoch: 13 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10002637667910104		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.10002637667910104 | validation: 0.09602966465401715]
	TIME [epoch: 13 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11028974336521462		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.11028974336521462 | validation: 0.1162987305726097]
	TIME [epoch: 13 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10363595108418076		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.10363595108418076 | validation: 0.11018458733294051]
	TIME [epoch: 13.1 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10751474589414481		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.10751474589414481 | validation: 0.11943912856225708]
	TIME [epoch: 13 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11482164979549443		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.11482164979549443 | validation: 0.11781525909647156]
	TIME [epoch: 13 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09642503498738214		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.09642503498738214 | validation: 0.09405845743441017]
	TIME [epoch: 13.1 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10395302378792777		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.10395302378792777 | validation: 0.11616530433053916]
	TIME [epoch: 13 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10875843082504937		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.10875843082504937 | validation: 0.10187663945843145]
	TIME [epoch: 13 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09282496616764904		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.09282496616764904 | validation: 0.1096852802226416]
	TIME [epoch: 13.1 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10240634549054173		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.10240634549054173 | validation: 0.13719441681080732]
	TIME [epoch: 13 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11223468962764181		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.11223468962764181 | validation: 0.10162625922467644]
	TIME [epoch: 13 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09942743885469534		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.09942743885469534 | validation: 0.12024744364523877]
	TIME [epoch: 13.1 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10773815059360385		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.10773815059360385 | validation: 0.10675532540725445]
	TIME [epoch: 13 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10700373888869379		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.10700373888869379 | validation: 0.11906232828662132]
	TIME [epoch: 13 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11453749745253443		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.11453749745253443 | validation: 0.12278597589139147]
	TIME [epoch: 13 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12202680284950164		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.12202680284950164 | validation: 0.12688522904740096]
	TIME [epoch: 13.1 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1071317912411362		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.1071317912411362 | validation: 0.1094371336818039]
	TIME [epoch: 13 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11079958736508935		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.11079958736508935 | validation: 0.13298934656103029]
	TIME [epoch: 13 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11528242633106317		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.11528242633106317 | validation: 0.10943117765233087]
	TIME [epoch: 13 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1025689692691013		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.1025689692691013 | validation: 0.11156548098336407]
	TIME [epoch: 13 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11207183062118856		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.11207183062118856 | validation: 0.12825494528684253]
	TIME [epoch: 13 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10928136626414729		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.10928136626414729 | validation: 0.11112043284881196]
	TIME [epoch: 13 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11048925046489952		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.11048925046489952 | validation: 0.10415146482793664]
	TIME [epoch: 13 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09860192903115014		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.09860192903115014 | validation: 0.10513427897288889]
	TIME [epoch: 13 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09352863568345483		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.09352863568345483 | validation: 0.10817753249464537]
	TIME [epoch: 13 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10898143281281376		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.10898143281281376 | validation: 0.1041264337973123]
	TIME [epoch: 13 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10662104422324803		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.10662104422324803 | validation: 0.10868106060809239]
	TIME [epoch: 13 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10348152925212507		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.10348152925212507 | validation: 0.10463204129314964]
	TIME [epoch: 13 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10335654184399701		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.10335654184399701 | validation: 0.10900476932933013]
	TIME [epoch: 13 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09859533570633652		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.09859533570633652 | validation: 0.1107635771517295]
	TIME [epoch: 13 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10203873551222066		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.10203873551222066 | validation: 0.10392099569496399]
	TIME [epoch: 13 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944413070370969		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.0944413070370969 | validation: 0.09928817177085382]
	TIME [epoch: 13 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10070845730950426		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.10070845730950426 | validation: 0.11148759104158515]
	TIME [epoch: 13 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10021535172066778		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.10021535172066778 | validation: 0.11480933107111546]
	TIME [epoch: 13 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10603641777084225		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.10603641777084225 | validation: 0.11641415057323957]
	TIME [epoch: 13.1 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10326399430720036		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.10326399430720036 | validation: 0.12065274555560443]
	TIME [epoch: 13.1 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11162400140762255		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.11162400140762255 | validation: 0.1384446172806818]
	TIME [epoch: 13 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12032433594707513		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.12032433594707513 | validation: 0.11788891063114428]
	TIME [epoch: 13 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11000150907915217		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.11000150907915217 | validation: 0.11894898464369981]
	TIME [epoch: 13.1 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10931857197154071		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.10931857197154071 | validation: 0.1368126334111326]
	TIME [epoch: 13 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11319461867287034		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.11319461867287034 | validation: 0.1234877172529418]
	TIME [epoch: 13 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12420275593501509		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.12420275593501509 | validation: 0.11009558488291908]
	TIME [epoch: 13.1 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10723687395965849		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.10723687395965849 | validation: 0.0966282208179499]
	TIME [epoch: 13 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09871491079651305		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.09871491079651305 | validation: 0.09557754297416747]
	TIME [epoch: 13 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10175978239129865		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.10175978239129865 | validation: 0.1063136482956114]
	TIME [epoch: 13.1 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1099790437444516		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.1099790437444516 | validation: 0.1206439804212648]
	TIME [epoch: 13.1 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1022260239431631		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.1022260239431631 | validation: 0.1102996914328189]
	TIME [epoch: 13.1 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09108115859918205		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.09108115859918205 | validation: 0.0911381205230957]
	TIME [epoch: 13 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0926814865437601		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.0926814865437601 | validation: 0.09473880717419747]
	TIME [epoch: 13 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09134097388928407		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.09134097388928407 | validation: 0.10664278022302337]
	TIME [epoch: 13 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0963942217728064		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.0963942217728064 | validation: 0.10386606837521146]
	TIME [epoch: 13 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09673862274445504		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.09673862274445504 | validation: 0.13446892319335887]
	TIME [epoch: 13.1 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10789470104856413		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.10789470104856413 | validation: 0.10323463209183885]
	TIME [epoch: 13 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477451055664315		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.10477451055664315 | validation: 0.10469197789290796]
	TIME [epoch: 13.1 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10924642199001594		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.10924642199001594 | validation: 0.13038279810178263]
	TIME [epoch: 13.1 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11525549336912827		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.11525549336912827 | validation: 0.11352414659574635]
	TIME [epoch: 13 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10416086429301591		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.10416086429301591 | validation: 0.12171580410586362]
	TIME [epoch: 13 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11135369874791806		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.11135369874791806 | validation: 0.12624699741355153]
	TIME [epoch: 13.1 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10597258492179573		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.10597258492179573 | validation: 0.10910293251177809]
	TIME [epoch: 13.1 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1013348951784035		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.1013348951784035 | validation: 0.11641688817360218]
	TIME [epoch: 13 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10837531877184421		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.10837531877184421 | validation: 0.1274222542547699]
	TIME [epoch: 13 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11746443870620259		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.11746443870620259 | validation: 0.1266777997943303]
	TIME [epoch: 13.1 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11719257556396531		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.11719257556396531 | validation: 0.1307861006528499]
	TIME [epoch: 13 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11555898890282745		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.11555898890282745 | validation: 0.1197189080773812]
	TIME [epoch: 13 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11570672052013838		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.11570672052013838 | validation: 0.14171427808978848]
	TIME [epoch: 13.1 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11685841267347721		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.11685841267347721 | validation: 0.10473813085339259]
	TIME [epoch: 13.1 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10883906897835112		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.10883906897835112 | validation: 0.10677598237569288]
	TIME [epoch: 13 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10608538336509676		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.10608538336509676 | validation: 0.12736974944558674]
	TIME [epoch: 13.1 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11524047854758113		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.11524047854758113 | validation: 0.123716598341967]
	TIME [epoch: 13 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1172833281377403		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.1172833281377403 | validation: 0.12414715768570236]
	TIME [epoch: 13 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10638434725929163		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.10638434725929163 | validation: 0.1033662013503172]
	TIME [epoch: 13.1 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09903863326868603		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.09903863326868603 | validation: 0.10604696207467114]
	TIME [epoch: 13.1 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09921182053168635		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.09921182053168635 | validation: 0.10735407174193765]
	TIME [epoch: 13 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10319645116566728		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.10319645116566728 | validation: 0.1035986350290127]
	TIME [epoch: 13.1 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10217336159037049		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.10217336159037049 | validation: 0.12088094701660072]
	TIME [epoch: 13.1 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10324406014663354		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.10324406014663354 | validation: 0.1243728803461023]
	TIME [epoch: 13 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10883285391576186		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.10883285391576186 | validation: 0.10900000376047679]
	TIME [epoch: 13.1 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200236680366276		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.10200236680366276 | validation: 0.09599094960710279]
	TIME [epoch: 13.1 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10051316017635163		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.10051316017635163 | validation: 0.11544262297230312]
	TIME [epoch: 13 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1106013259514229		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.1106013259514229 | validation: 0.10895525708325142]
	TIME [epoch: 13.1 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0992707436226908		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.0992707436226908 | validation: 0.1031320906223037]
	TIME [epoch: 13.1 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.098895892805308		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.098895892805308 | validation: 0.09583203600516242]
	TIME [epoch: 13 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09409837284994664		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.09409837284994664 | validation: 0.10919606888192868]
	TIME [epoch: 13 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10362191432681925		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.10362191432681925 | validation: 0.10222891036127141]
	TIME [epoch: 13.1 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0989225928343292		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.0989225928343292 | validation: 0.11768812074421896]
	TIME [epoch: 13.1 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442126115492556		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.10442126115492556 | validation: 0.12321193581458248]
	TIME [epoch: 13.1 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11383870189873348		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.11383870189873348 | validation: 0.11595931622117055]
	TIME [epoch: 13.1 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09509893219449955		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.09509893219449955 | validation: 0.11193492594853155]
	TIME [epoch: 13.1 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09752817602227078		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.09752817602227078 | validation: 0.104369612022778]
	TIME [epoch: 13 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10357466730570919		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.10357466730570919 | validation: 0.09746289426334319]
	TIME [epoch: 13 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10911475602825202		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.10911475602825202 | validation: 0.1080116384093219]
	TIME [epoch: 13 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10350581190728535		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.10350581190728535 | validation: 0.10058551329446389]
	TIME [epoch: 13 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10992736988501964		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.10992736988501964 | validation: 0.09966158792448329]
	TIME [epoch: 13 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10771239706767394		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.10771239706767394 | validation: 0.11885383025260576]
	TIME [epoch: 13.1 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1068934764234119		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.1068934764234119 | validation: 0.09698271756694907]
	TIME [epoch: 13.1 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09870941987669744		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.09870941987669744 | validation: 0.09854074267079305]
	TIME [epoch: 13 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09965992039250818		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.09965992039250818 | validation: 0.10885862828062663]
	TIME [epoch: 13 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10016853900251402		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.10016853900251402 | validation: 0.09980930168603971]
	TIME [epoch: 13.1 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10977556739275546		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.10977556739275546 | validation: 0.10573479908490058]
	TIME [epoch: 13 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.105995767173043		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.105995767173043 | validation: 0.10595446586026201]
	TIME [epoch: 13 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11674300111723329		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.11674300111723329 | validation: 0.1173718264929942]
	TIME [epoch: 13.1 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10546029224990143		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.10546029224990143 | validation: 0.09826160952560069]
	TIME [epoch: 13 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10098513904102484		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.10098513904102484 | validation: 0.10474854789901668]
	TIME [epoch: 13 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11029944223784614		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.11029944223784614 | validation: 0.10517321749834256]
	TIME [epoch: 13.1 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10678416366830783		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.10678416366830783 | validation: 0.12002514671814737]
	TIME [epoch: 13.1 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10337449587515474		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.10337449587515474 | validation: 0.10974938441557175]
	TIME [epoch: 13 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10354781904777671		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.10354781904777671 | validation: 0.11354574388764054]
	TIME [epoch: 13.1 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356063614757011		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.09356063614757011 | validation: 0.10580865011957005]
	TIME [epoch: 13 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10129527044485291		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.10129527044485291 | validation: 0.10284203410975674]
	TIME [epoch: 13 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09675502388087114		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.09675502388087114 | validation: 0.09535337561046638]
	TIME [epoch: 13 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09433138752793829		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.09433138752793829 | validation: 0.09933080967571492]
	TIME [epoch: 13.1 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09286041157265792		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.09286041157265792 | validation: 0.10716288512450822]
	TIME [epoch: 13.1 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09674603334916192		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.09674603334916192 | validation: 0.1113210489173343]
	TIME [epoch: 13 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900347644039957		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.10900347644039957 | validation: 0.12041825821493092]
	TIME [epoch: 13.1 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10393045170582625		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.10393045170582625 | validation: 0.10035123161920016]
	TIME [epoch: 13 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09542828868978871		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.09542828868978871 | validation: 0.09209781506378217]
	TIME [epoch: 13 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09887812123744387		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.09887812123744387 | validation: 0.09994006716099574]
	TIME [epoch: 13.1 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09939940605306834		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.09939940605306834 | validation: 0.10629860811236537]
	TIME [epoch: 13.1 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10803833905076025		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.10803833905076025 | validation: 0.09405171457279864]
	TIME [epoch: 13 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09878815682523495		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.09878815682523495 | validation: 0.0947110669748135]
	TIME [epoch: 13 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10490905884770611		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.10490905884770611 | validation: 0.09012664991144284]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1341.pth
	Model improved!!!
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10406980451268444		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.10406980451268444 | validation: 0.09275145126726642]
	TIME [epoch: 13 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1068214650891337		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.1068214650891337 | validation: 0.1108901974494019]
	TIME [epoch: 13.3 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10455025861166499		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.10455025861166499 | validation: 0.08893078224524364]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1344.pth
	Model improved!!!
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10785711496426842		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.10785711496426842 | validation: 0.1019584631988317]
	TIME [epoch: 13 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11028885354397149		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.11028885354397149 | validation: 0.11273743640642518]
	TIME [epoch: 13 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10353593167460182		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.10353593167460182 | validation: 0.10064550460411749]
	TIME [epoch: 13.1 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10408852476785156		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.10408852476785156 | validation: 0.09508242158335026]
	TIME [epoch: 13 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0994453427004574		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.0994453427004574 | validation: 0.09790898539725666]
	TIME [epoch: 13 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10224788332949766		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.10224788332949766 | validation: 0.10638806380583972]
	TIME [epoch: 13 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11261975742540277		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.11261975742540277 | validation: 0.12320113951066283]
	TIME [epoch: 13.1 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11136772172788445		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.11136772172788445 | validation: 0.10927412070885431]
	TIME [epoch: 13 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09765981526739431		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.09765981526739431 | validation: 0.09620197992889816]
	TIME [epoch: 13 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09563332398308852		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.09563332398308852 | validation: 0.09645627467586118]
	TIME [epoch: 13.1 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09486702507521193		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.09486702507521193 | validation: 0.1054148630109902]
	TIME [epoch: 13 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10433388897488258		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.10433388897488258 | validation: 0.09884294199938616]
	TIME [epoch: 13 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09499857130158058		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.09499857130158058 | validation: 0.09952863480226708]
	TIME [epoch: 13.1 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09798195911128602		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.09798195911128602 | validation: 0.09459358237690689]
	TIME [epoch: 13 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09373423686871239		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.09373423686871239 | validation: 0.09052452543264757]
	TIME [epoch: 13 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10304556035701896		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.10304556035701896 | validation: 0.11605988364453826]
	TIME [epoch: 13 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11577361076942574		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.11577361076942574 | validation: 0.10843615730007938]
	TIME [epoch: 13.1 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477685112144806		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.10477685112144806 | validation: 0.11072489877908062]
	TIME [epoch: 13 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11110587223826388		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.11110587223826388 | validation: 0.11032200284474522]
	TIME [epoch: 13 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10600871648448615		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.10600871648448615 | validation: 0.10995053615745218]
	TIME [epoch: 13.1 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10194197901574541		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.10194197901574541 | validation: 0.10597944947096634]
	TIME [epoch: 13 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1126865486142063		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.1126865486142063 | validation: 0.11463676180405666]
	TIME [epoch: 13 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10764892884146557		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.10764892884146557 | validation: 0.10802703694159593]
	TIME [epoch: 13.1 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10513748949416364		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.10513748949416364 | validation: 0.099136230792056]
	TIME [epoch: 13 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10240185117212848		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.10240185117212848 | validation: 0.12262824150955798]
	TIME [epoch: 13 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10339335153298143		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.10339335153298143 | validation: 0.10689414319989685]
	TIME [epoch: 13.1 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09960684492418902		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.09960684492418902 | validation: 0.10141235839960888]
	TIME [epoch: 13 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10150683862052087		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.10150683862052087 | validation: 0.1090537071828021]
	TIME [epoch: 13 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09487244744574477		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.09487244744574477 | validation: 0.11114479245025619]
	TIME [epoch: 13 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09840224737006717		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.09840224737006717 | validation: 0.09969841178588217]
	TIME [epoch: 13.1 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09940190873466132		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.09940190873466132 | validation: 0.10898601885260104]
	TIME [epoch: 13 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.106459845964878		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.106459845964878 | validation: 0.10527401973727216]
	TIME [epoch: 13 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10311173971053374		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.10311173971053374 | validation: 0.10295752987352659]
	TIME [epoch: 13.1 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10220119221705774		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.10220119221705774 | validation: 0.10200750684395737]
	TIME [epoch: 13 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0969910242209072		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.0969910242209072 | validation: 0.10032288642806332]
	TIME [epoch: 13 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09274555171220486		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.09274555171220486 | validation: 0.10329351148138406]
	TIME [epoch: 13 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09914561825803243		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.09914561825803243 | validation: 0.10501488389396368]
	TIME [epoch: 13 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09965472019598859		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.09965472019598859 | validation: 0.10844615194981824]
	TIME [epoch: 13 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09914629174912995		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.09914629174912995 | validation: 0.10175762504902963]
	TIME [epoch: 13 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10112052450992196		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.10112052450992196 | validation: 0.09899751086066903]
	TIME [epoch: 13 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09405587392995668		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.09405587392995668 | validation: 0.09654622584246504]
	TIME [epoch: 13 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10277178601298098		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.10277178601298098 | validation: 0.10977525535165793]
	TIME [epoch: 13 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11277458393980132		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.11277458393980132 | validation: 0.10022328759211674]
	TIME [epoch: 13.1 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10917781790939222		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.10917781790939222 | validation: 0.11957348238010462]
	TIME [epoch: 13 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10414698130157103		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.10414698130157103 | validation: 0.1054422597012856]
	TIME [epoch: 13 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09609904965173491		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.09609904965173491 | validation: 0.10047098492404093]
	TIME [epoch: 13.1 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09927581257992829		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.09927581257992829 | validation: 0.10979603722701796]
	TIME [epoch: 13 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10068073349598837		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.10068073349598837 | validation: 0.10196950192967298]
	TIME [epoch: 13 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09419355336186569		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.09419355336186569 | validation: 0.10937480695600867]
	TIME [epoch: 13 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10057138078611369		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.10057138078611369 | validation: 0.10760713771986403]
	TIME [epoch: 13 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10420249710090886		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.10420249710090886 | validation: 0.11509266094758985]
	TIME [epoch: 13 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10261124971626177		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.10261124971626177 | validation: 0.09209185142035181]
	TIME [epoch: 13 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09420355901494576		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.09420355901494576 | validation: 0.09838675678656753]
	TIME [epoch: 13.1 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014160775859754		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.1014160775859754 | validation: 0.09663942929328777]
	TIME [epoch: 13 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10497658679998785		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.10497658679998785 | validation: 0.10891971413179154]
	TIME [epoch: 13 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10343944905316849		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.10343944905316849 | validation: 0.10710116928862437]
	TIME [epoch: 13.1 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09254027029215343		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.09254027029215343 | validation: 0.11193270928734073]
	TIME [epoch: 13 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09217032691509179		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.09217032691509179 | validation: 0.1023232149512284]
	TIME [epoch: 13 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967578217444546		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.0967578217444546 | validation: 0.10084420511875014]
	TIME [epoch: 13 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09555391341847114		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.09555391341847114 | validation: 0.1080460605726756]
	TIME [epoch: 13 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10308855336030809		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.10308855336030809 | validation: 0.10200842555191628]
	TIME [epoch: 13 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0977848958478359		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.0977848958478359 | validation: 0.10130881552365863]
	TIME [epoch: 13 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09392407726968317		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.09392407726968317 | validation: 0.09732620784790812]
	TIME [epoch: 13 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09688289938615575		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.09688289938615575 | validation: 0.08868340702874573]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1408.pth
	Model improved!!!
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08940742553700914		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.08940742553700914 | validation: 0.09853466985830388]
	TIME [epoch: 13 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0911051230842687		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.0911051230842687 | validation: 0.09916338045805118]
	TIME [epoch: 13 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09816104219928161		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.09816104219928161 | validation: 0.10456196938855858]
	TIME [epoch: 13 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09717296798553024		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.09717296798553024 | validation: 0.1037603135499562]
	TIME [epoch: 13 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0974467093652803		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.0974467093652803 | validation: 0.105206779586049]
	TIME [epoch: 13 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09529794742618518		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.09529794742618518 | validation: 0.1082817943650967]
	TIME [epoch: 13 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10409716534117688		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.10409716534117688 | validation: 0.08948344951902676]
	TIME [epoch: 13 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09777759641264022		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.09777759641264022 | validation: 0.09421353885856058]
	TIME [epoch: 13 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09623576912933082		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.09623576912933082 | validation: 0.09969898416485118]
	TIME [epoch: 13.1 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08946987443177246		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.08946987443177246 | validation: 0.09550517423070694]
	TIME [epoch: 13 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08739628096282594		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.08739628096282594 | validation: 0.10361972791861825]
	TIME [epoch: 13 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452660432181233		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.09452660432181233 | validation: 0.09664689703588632]
	TIME [epoch: 13.1 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09229119518758425		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.09229119518758425 | validation: 0.09503171650547668]
	TIME [epoch: 13 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09503674326956885		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.09503674326956885 | validation: 0.08617623158383812]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1422.pth
	Model improved!!!
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09367965105679882		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.09367965105679882 | validation: 0.09762624050972658]
	TIME [epoch: 13 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09462927457520434		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.09462927457520434 | validation: 0.10108991796849111]
	TIME [epoch: 13 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0926788786418054		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.0926788786418054 | validation: 0.08915607165113175]
	TIME [epoch: 13 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09070203786053477		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.09070203786053477 | validation: 0.10242616803614263]
	TIME [epoch: 13 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09525976344209769		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.09525976344209769 | validation: 0.08496140236307144]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1427.pth
	Model improved!!!
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09089318253651374		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.09089318253651374 | validation: 0.09787416563174872]
	TIME [epoch: 13 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09655416096181488		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.09655416096181488 | validation: 0.0925053992774804]
	TIME [epoch: 13 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09222430954644159		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.09222430954644159 | validation: 0.08651295262540369]
	TIME [epoch: 13.1 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09294745260761438		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.09294745260761438 | validation: 0.0915973643810081]
	TIME [epoch: 13 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09340343766073606		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.09340343766073606 | validation: 0.09436362118715091]
	TIME [epoch: 13 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09482494865516856		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.09482494865516856 | validation: 0.094735910212269]
	TIME [epoch: 13 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09235269174412017		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.09235269174412017 | validation: 0.09588693489452489]
	TIME [epoch: 13.1 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0968546145781643		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.0968546145781643 | validation: 0.09048957858904222]
	TIME [epoch: 13 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09640906858371986		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.09640906858371986 | validation: 0.09837043701678376]
	TIME [epoch: 13 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09313193628033153		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.09313193628033153 | validation: 0.09851203953554558]
	TIME [epoch: 13.1 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09135199347017042		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.09135199347017042 | validation: 0.09897648472216779]
	TIME [epoch: 13 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09688985067722698		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.09688985067722698 | validation: 0.10219874483443243]
	TIME [epoch: 13 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09409029468319763		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.09409029468319763 | validation: 0.09009884479904617]
	TIME [epoch: 13 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0952972206554546		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.0952972206554546 | validation: 0.08643935462846607]
	TIME [epoch: 13 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09302163421337024		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.09302163421337024 | validation: 0.08781469749294951]
	TIME [epoch: 13 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.092820500938111		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.092820500938111 | validation: 0.09312368874580315]
	TIME [epoch: 13 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09106850587990721		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.09106850587990721 | validation: 0.09733483696255615]
	TIME [epoch: 13.1 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09299013450141042		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.09299013450141042 | validation: 0.09706972336663064]
	TIME [epoch: 13 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0939867686553478		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.0939867686553478 | validation: 0.0964489880177362]
	TIME [epoch: 13 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09296733446800283		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.09296733446800283 | validation: 0.08909477355216183]
	TIME [epoch: 13.1 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09251029505625888		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.09251029505625888 | validation: 0.09209576938599953]
	TIME [epoch: 13 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08808699820088844		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.08808699820088844 | validation: 0.11264952620061645]
	TIME [epoch: 13 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0988300884008943		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.0988300884008943 | validation: 0.11086942872150354]
	TIME [epoch: 13 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09843857475840045		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.09843857475840045 | validation: 0.09149925253373878]
	TIME [epoch: 13 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09002262742621753		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.09002262742621753 | validation: 0.09411942168094743]
	TIME [epoch: 13 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09365782588447838		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.09365782588447838 | validation: 0.10096328768641027]
	TIME [epoch: 13 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.094388548123702		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.094388548123702 | validation: 0.09937196461227281]
	TIME [epoch: 13 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0938925772389585		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.0938925772389585 | validation: 0.09633979195070094]
	TIME [epoch: 13 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09062793459620962		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.09062793459620962 | validation: 0.09783251927342074]
	TIME [epoch: 13 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09437190945727772		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.09437190945727772 | validation: 0.09284290860937112]
	TIME [epoch: 13.1 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0897241722718814		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.0897241722718814 | validation: 0.09633360444633816]
	TIME [epoch: 13 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09128080494554579		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.09128080494554579 | validation: 0.09300149079662713]
	TIME [epoch: 13 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09968731527585799		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.09968731527585799 | validation: 0.12401025765287699]
	TIME [epoch: 13.1 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10669763348204628		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.10669763348204628 | validation: 0.12579534479144172]
	TIME [epoch: 13 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12292867433222547		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.12292867433222547 | validation: 0.11734677207349688]
	TIME [epoch: 13 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114009346087194		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.1114009346087194 | validation: 0.10339797142112205]
	TIME [epoch: 13 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09788274326234139		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.09788274326234139 | validation: 0.09614636144774188]
	TIME [epoch: 13 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09461215365222311		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.09461215365222311 | validation: 0.09356052130949055]
	TIME [epoch: 13 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0964576475245261		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.0964576475245261 | validation: 0.10415317587991745]
	TIME [epoch: 13 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09201708048327002		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.09201708048327002 | validation: 0.09078983636839501]
	TIME [epoch: 13 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09467475537105248		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.09467475537105248 | validation: 0.09061077357644363]
	TIME [epoch: 13 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09043789585430308		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.09043789585430308 | validation: 0.09414789060971238]
	TIME [epoch: 13 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188240120818425		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.09188240120818425 | validation: 0.08864726548439227]
	TIME [epoch: 13 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09134177296751815		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.09134177296751815 | validation: 0.10166819994916843]
	TIME [epoch: 13 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09387276184130294		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.09387276184130294 | validation: 0.09556397269857411]
	TIME [epoch: 13 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08972518969313681		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.08972518969313681 | validation: 0.08818646142035638]
	TIME [epoch: 13 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09033854984499881		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.09033854984499881 | validation: 0.0918105941698911]
	TIME [epoch: 13 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09889634050829987		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.09889634050829987 | validation: 0.08437844724139454]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1475.pth
	Model improved!!!
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09157556627604488		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.09157556627604488 | validation: 0.09273859354412632]
	TIME [epoch: 13 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09221095008516766		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.09221095008516766 | validation: 0.09157851126256154]
	TIME [epoch: 13.1 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09149234219681887		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.09149234219681887 | validation: 0.0933581235484029]
	TIME [epoch: 13 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09546439981742802		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.09546439981742802 | validation: 0.08603108530552063]
	TIME [epoch: 13 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09594185647605993		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.09594185647605993 | validation: 0.09904839090479285]
	TIME [epoch: 13.1 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09562532606643642		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.09562532606643642 | validation: 0.09251366100136903]
	TIME [epoch: 13.1 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10188247953651065		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.10188247953651065 | validation: 0.10735907504830468]
	TIME [epoch: 13 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356830694561653		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.09356830694561653 | validation: 0.10689733241337088]
	TIME [epoch: 13 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0954578942546219		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.0954578942546219 | validation: 0.09380930633184367]
	TIME [epoch: 13.1 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0949959551953816		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.0949959551953816 | validation: 0.09654186615554976]
	TIME [epoch: 13 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09559066948532446		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.09559066948532446 | validation: 0.09577758720063372]
	TIME [epoch: 13 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09352103414450452		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.09352103414450452 | validation: 0.08615022835239713]
	TIME [epoch: 13.1 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08951370372991546		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.08951370372991546 | validation: 0.09695753526106411]
	TIME [epoch: 13 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08935767960011964		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.08935767960011964 | validation: 0.08660349404883386]
	TIME [epoch: 13 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09025073021067873		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.09025073021067873 | validation: 0.09456160166361174]
	TIME [epoch: 13.1 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09393502524625907		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.09393502524625907 | validation: 0.0999423818098094]
	TIME [epoch: 13 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09439015581997007		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.09439015581997007 | validation: 0.09588896719432588]
	TIME [epoch: 13 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09575610179933336		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.09575610179933336 | validation: 0.09698821433042412]
	TIME [epoch: 13.1 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356452559051721		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.09356452559051721 | validation: 0.1050626733327575]
	TIME [epoch: 13 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09130182516682353		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.09130182516682353 | validation: 0.11192183498251064]
	TIME [epoch: 13 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09339439726394055		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.09339439726394055 | validation: 0.11255138288049692]
	TIME [epoch: 13 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0985984425034756		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.0985984425034756 | validation: 0.10703884143143694]
	TIME [epoch: 13.1 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0923767801576273		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.0923767801576273 | validation: 0.09619169321279725]
	TIME [epoch: 13 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09483753943551293		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.09483753943551293 | validation: 0.09692001231144301]
	TIME [epoch: 13 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09204760073042499		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.09204760073042499 | validation: 0.1008350446232078]
	TIME [epoch: 13.1 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09161563960433099		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.09161563960433099 | validation: 0.09117352672458533]
	TIME [epoch: 13 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08920152171833408		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.08920152171833408 | validation: 0.09837132385495322]
	TIME [epoch: 13 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08954543418823646		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.08954543418823646 | validation: 0.09022819241694846]
	TIME [epoch: 13.1 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09458160212949762		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.09458160212949762 | validation: 0.085299922783232]
	TIME [epoch: 13 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0906683153003233		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.0906683153003233 | validation: 0.08797401086068803]
	TIME [epoch: 13 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0955209689799191		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.0955209689799191 | validation: 0.09862495900713814]
	TIME [epoch: 13 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08678564210984321		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.08678564210984321 | validation: 0.0951712151705144]
	TIME [epoch: 13.1 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0916261258844222		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.0916261258844222 | validation: 0.09731461551966651]
	TIME [epoch: 13 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0924952028103479		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.0924952028103479 | validation: 0.095529490043165]
	TIME [epoch: 13 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0929465270059999		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.0929465270059999 | validation: 0.1024722199045232]
	TIME [epoch: 13.1 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09140458135965752		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.09140458135965752 | validation: 0.09014695674214043]
	TIME [epoch: 13 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0939829286658633		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.0939829286658633 | validation: 0.082316750001008]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1512.pth
	Model improved!!!
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08782211028419155		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.08782211028419155 | validation: 0.09242226030399273]
	TIME [epoch: 13 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09767749125098174		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.09767749125098174 | validation: 0.11266757170983495]
	TIME [epoch: 13 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291688127146176		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.10291688127146176 | validation: 0.09850946982620716]
	TIME [epoch: 13 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09352022282005897		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.09352022282005897 | validation: 0.10128520336578536]
	TIME [epoch: 13 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09122525324680908		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.09122525324680908 | validation: 0.09365912730736187]
	TIME [epoch: 13.1 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09278619683433421		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.09278619683433421 | validation: 0.10131968771194086]
	TIME [epoch: 13 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09725220982813385		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.09725220982813385 | validation: 0.09761512751131456]
	TIME [epoch: 13 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09885925303617767		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.09885925303617767 | validation: 0.09988984027796065]
	TIME [epoch: 13.1 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09318260300361768		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.09318260300361768 | validation: 0.09393658830381753]
	TIME [epoch: 13 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09636011388907717		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.09636011388907717 | validation: 0.09623777777203507]
	TIME [epoch: 13 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09135542876604388		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.09135542876604388 | validation: 0.09931969403105555]
	TIME [epoch: 13.1 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09384446857539036		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.09384446857539036 | validation: 0.1078931623417784]
	TIME [epoch: 13 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0960692368367845		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.0960692368367845 | validation: 0.10207957885974256]
	TIME [epoch: 13 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09595844550730145		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.09595844550730145 | validation: 0.10015830715237417]
	TIME [epoch: 13.1 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09291266105793908		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.09291266105793908 | validation: 0.08774939714000608]
	TIME [epoch: 13 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09037029629936441		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.09037029629936441 | validation: 0.09327153517339025]
	TIME [epoch: 13 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09237470410931753		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.09237470410931753 | validation: 0.09016899760904583]
	TIME [epoch: 13 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08639186866457232		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.08639186866457232 | validation: 0.0837909199905441]
	TIME [epoch: 13.1 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08815501977532006		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.08815501977532006 | validation: 0.09598028940642005]
	TIME [epoch: 13 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0959231875431642		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.0959231875431642 | validation: 0.0929002870591475]
	TIME [epoch: 13 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0959745959185475		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.0959745959185475 | validation: 0.10646772925729259]
	TIME [epoch: 13 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11367139242400018		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.11367139242400018 | validation: 0.10998193958008934]
	TIME [epoch: 13 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10906042413667688		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.10906042413667688 | validation: 0.10023863338373323]
	TIME [epoch: 13 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10010588837893802		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.10010588837893802 | validation: 0.10396154651472365]
	TIME [epoch: 13 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09067814715229425		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.09067814715229425 | validation: 0.10073308128295065]
	TIME [epoch: 13 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09349734951136865		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.09349734951136865 | validation: 0.10833283473524816]
	TIME [epoch: 13 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09373769534830804		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.09373769534830804 | validation: 0.09797619685954302]
	TIME [epoch: 13 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09366892052793374		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.09366892052793374 | validation: 0.08287662454581302]
	TIME [epoch: 13.1 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08739262332011075		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.08739262332011075 | validation: 0.08961735804707475]
	TIME [epoch: 13 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09288016638540436		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.09288016638540436 | validation: 0.09847722663465547]
	TIME [epoch: 13 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09617715574449656		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.09617715574449656 | validation: 0.09305812124805428]
	TIME [epoch: 13.1 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08908995794938239		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.08908995794938239 | validation: 0.09334244751460961]
	TIME [epoch: 13 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09079098502899927		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.09079098502899927 | validation: 0.09091188663106448]
	TIME [epoch: 13 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08972319569571224		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.08972319569571224 | validation: 0.08963082208294523]
	TIME [epoch: 13.1 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08811941957235338		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.08811941957235338 | validation: 0.09229078158666112]
	TIME [epoch: 13 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08923961796185179		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.08923961796185179 | validation: 0.09307149525636421]
	TIME [epoch: 13 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08830879332592213		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.08830879332592213 | validation: 0.09939138407773986]
	TIME [epoch: 13 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09333150933151949		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.09333150933151949 | validation: 0.09537709958606709]
	TIME [epoch: 13.1 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09141904337486936		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.09141904337486936 | validation: 0.1062915927611936]
	TIME [epoch: 13 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08586552404066772		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.08586552404066772 | validation: 0.09482668001903555]
	TIME [epoch: 13 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08956845276646268		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.08956845276646268 | validation: 0.08781134620059813]
	TIME [epoch: 13 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09236181288440096		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.09236181288440096 | validation: 0.09761509404201064]
	TIME [epoch: 13 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09762373461290261		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.09762373461290261 | validation: 0.09706891294482922]
	TIME [epoch: 13 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0977478702855988		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.0977478702855988 | validation: 0.09889247044073049]
	TIME [epoch: 13.1 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09202870364016105		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.09202870364016105 | validation: 0.09766923467979993]
	TIME [epoch: 13 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09300357013287502		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.09300357013287502 | validation: 0.10142878133109803]
	TIME [epoch: 13 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09967245388038369		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.09967245388038369 | validation: 0.10345391299155261]
	TIME [epoch: 13.1 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09609713860587453		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.09609713860587453 | validation: 0.10120293189889439]
	TIME [epoch: 13 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09138045426326685		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.09138045426326685 | validation: 0.10118852705654441]
	TIME [epoch: 13 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09575425189729246		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.09575425189729246 | validation: 0.10378702381976704]
	TIME [epoch: 13 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0924560480308705		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.0924560480308705 | validation: 0.09983236480042516]
	TIME [epoch: 13 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09389686847480497		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.09389686847480497 | validation: 0.09892684371953354]
	TIME [epoch: 13 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09246548508796316		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.09246548508796316 | validation: 0.10683857758207042]
	TIME [epoch: 13 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09134126950404842		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.09134126950404842 | validation: 0.10932816202262452]
	TIME [epoch: 13.1 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09341837017693203		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.09341837017693203 | validation: 0.09678917725100936]
	TIME [epoch: 13 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08953477619581471		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.08953477619581471 | validation: 0.09334327007765233]
	TIME [epoch: 13 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09108841842585051		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.09108841842585051 | validation: 0.09174876533265242]
	TIME [epoch: 13 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09266924560872447		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.09266924560872447 | validation: 0.09511537797157732]
	TIME [epoch: 13 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08993133001216659		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.08993133001216659 | validation: 0.0901495662148644]
	TIME [epoch: 13 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09105667185844614		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.09105667185844614 | validation: 0.09656143603418924]
	TIME [epoch: 13 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08967253922451347		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.08967253922451347 | validation: 0.10183539455014538]
	TIME [epoch: 13 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0879794756955322		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.0879794756955322 | validation: 0.09733305663884735]
	TIME [epoch: 13 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08769795361993081		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.08769795361993081 | validation: 0.10042659279046205]
	TIME [epoch: 13 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0913356775757236		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.0913356775757236 | validation: 0.10176364847454095]
	TIME [epoch: 13 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08672507020183245		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.08672507020183245 | validation: 0.0898258930498243]
	TIME [epoch: 13 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08523441441021373		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.08523441441021373 | validation: 0.08515638771997097]
	TIME [epoch: 13 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08959118922661136		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.08959118922661136 | validation: 0.10110053592992481]
	TIME [epoch: 13 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09180007525834818		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.09180007525834818 | validation: 0.10101819284158518]
	TIME [epoch: 13 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09484425269023117		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.09484425269023117 | validation: 0.09304730019449765]
	TIME [epoch: 13 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09222821330296616		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.09222821330296616 | validation: 0.10097454465745129]
	TIME [epoch: 13 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09558583557778627		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.09558583557778627 | validation: 0.10802843033371139]
	TIME [epoch: 13 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09743251667525457		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.09743251667525457 | validation: 0.09832497929874613]
	TIME [epoch: 13 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0918593092201129		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.0918593092201129 | validation: 0.10559563839325506]
	TIME [epoch: 13 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09028156391495235		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.09028156391495235 | validation: 0.09850483410706588]
	TIME [epoch: 13 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09024225802074035		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.09024225802074035 | validation: 0.10269380245779278]
	TIME [epoch: 13 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08870173893858047		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.08870173893858047 | validation: 0.08975188214436024]
	TIME [epoch: 13 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089985603626873		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.089985603626873 | validation: 0.08824295499205566]
	TIME [epoch: 13 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0859017856892107		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.0859017856892107 | validation: 0.09592220887692854]
	TIME [epoch: 13 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08825676369076972		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.08825676369076972 | validation: 0.09476087661437094]
	TIME [epoch: 13 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0887578686605435		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.0887578686605435 | validation: 0.09295124709609046]
	TIME [epoch: 13 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09848515783031007		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.09848515783031007 | validation: 0.09590541561853332]
	TIME [epoch: 13 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0985526306041967		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.0985526306041967 | validation: 0.09714105247281704]
	TIME [epoch: 13 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09603163181040611		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.09603163181040611 | validation: 0.09727294384145303]
	TIME [epoch: 13 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09204006114675096		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.09204006114675096 | validation: 0.09698362357825961]
	TIME [epoch: 13 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0924633413124622		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.0924633413124622 | validation: 0.1038488229364791]
	TIME [epoch: 13 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09361434019934996		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.09361434019934996 | validation: 0.10342768219440755]
	TIME [epoch: 13 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09756906138308472		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.09756906138308472 | validation: 0.10493993415228631]
	TIME [epoch: 13 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09866557458500472		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.09866557458500472 | validation: 0.10205613776576998]
	TIME [epoch: 13 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09320826505364348		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.09320826505364348 | validation: 0.10671903023239251]
	TIME [epoch: 13 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09333054220575349		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.09333054220575349 | validation: 0.10027086489479028]
	TIME [epoch: 13 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09694874050500436		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.09694874050500436 | validation: 0.0991514518441085]
	TIME [epoch: 13 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09175885046912599		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.09175885046912599 | validation: 0.08959971072512658]
	TIME [epoch: 13 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09118552274397222		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.09118552274397222 | validation: 0.1011153578814739]
	TIME [epoch: 13.1 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08681704690629312		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.08681704690629312 | validation: 0.08796025456994581]
	TIME [epoch: 13.1 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08888150066120526		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.08888150066120526 | validation: 0.08828181352885509]
	TIME [epoch: 13 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.087857358221403		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.087857358221403 | validation: 0.0992141578231077]
	TIME [epoch: 13.1 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909032544857398		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.0909032544857398 | validation: 0.09194493205841857]
	TIME [epoch: 13.1 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09761446855677357		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.09761446855677357 | validation: 0.09400156391582011]
	TIME [epoch: 13 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08650765132762589		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.08650765132762589 | validation: 0.0933463636762291]
	TIME [epoch: 13 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08926512440219267		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.08926512440219267 | validation: 0.09622535463812043]
	TIME [epoch: 13 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08999505109001182		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.08999505109001182 | validation: 0.09475385309321127]
	TIME [epoch: 13 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09228234807355706		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.09228234807355706 | validation: 0.10265158289762763]
	TIME [epoch: 13 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09516406804159602		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.09516406804159602 | validation: 0.09682609610910557]
	TIME [epoch: 13.1 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10109078746591618		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.10109078746591618 | validation: 0.09468763828479204]
	TIME [epoch: 13 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0900859133881669		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.0900859133881669 | validation: 0.08867896950905303]
	TIME [epoch: 13 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08657457526961623		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.08657457526961623 | validation: 0.09612815304889705]
	TIME [epoch: 13.1 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08981426130385184		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.08981426130385184 | validation: 0.0990686530729125]
	TIME [epoch: 13 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08765883073523957		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.08765883073523957 | validation: 0.09807613149970161]
	TIME [epoch: 13 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09156982987324462		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.09156982987324462 | validation: 0.0897402122841848]
	TIME [epoch: 13 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09136317374277321		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.09136317374277321 | validation: 0.09341081950441306]
	TIME [epoch: 13.1 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09714436885860699		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.09714436885860699 | validation: 0.09452000540216386]
	TIME [epoch: 13 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08971789945736083		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.08971789945736083 | validation: 0.09743022002279769]
	TIME [epoch: 13 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09211792540910452		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.09211792540910452 | validation: 0.08079346941499914]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1625.pth
	Model improved!!!
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09522146288505012		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.09522146288505012 | validation: 0.09237204763462892]
	TIME [epoch: 13 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09274357643625705		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.09274357643625705 | validation: 0.09064950288440216]
	TIME [epoch: 13 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08999817563930067		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.08999817563930067 | validation: 0.094745009527285]
	TIME [epoch: 13 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09097192876400936		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.09097192876400936 | validation: 0.08736806398464238]
	TIME [epoch: 13.1 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08990326571230382		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.08990326571230382 | validation: 0.09363932507532713]
	TIME [epoch: 13 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08799722684083974		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.08799722684083974 | validation: 0.08949928953543845]
	TIME [epoch: 13 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0913114083862155		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.0913114083862155 | validation: 0.09592312347308365]
	TIME [epoch: 13.1 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0913623002277317		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.0913623002277317 | validation: 0.10545656573652779]
	TIME [epoch: 13 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1008278549026664		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.1008278549026664 | validation: 0.10850093802599452]
	TIME [epoch: 13 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10238310909585305		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.10238310909585305 | validation: 0.10908758627837255]
	TIME [epoch: 13 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09711294784014836		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.09711294784014836 | validation: 0.09665990073256221]
	TIME [epoch: 13 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08660972281210316		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.08660972281210316 | validation: 0.09142742870005202]
	TIME [epoch: 13 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08894663121399506		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.08894663121399506 | validation: 0.10219790161037477]
	TIME [epoch: 13 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09319216206431101		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.09319216206431101 | validation: 0.10556809784853187]
	TIME [epoch: 13.1 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09207810708723298		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.09207810708723298 | validation: 0.09244454135313696]
	TIME [epoch: 13 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0927636243207289		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.0927636243207289 | validation: 0.09393182602978016]
	TIME [epoch: 13 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09157508647930185		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.09157508647930185 | validation: 0.09574448629859567]
	TIME [epoch: 13.1 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08705661570351755		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.08705661570351755 | validation: 0.09348508230531768]
	TIME [epoch: 13 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09279464429287063		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.09279464429287063 | validation: 0.09656598771126867]
	TIME [epoch: 13 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09716224629414641		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.09716224629414641 | validation: 0.08875563002073414]
	TIME [epoch: 13.1 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09147209517389546		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.09147209517389546 | validation: 0.10195118705119517]
	TIME [epoch: 13 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09323230012191533		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.09323230012191533 | validation: 0.09104521024814848]
	TIME [epoch: 13 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08926991009660556		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.08926991009660556 | validation: 0.09691068284344007]
	TIME [epoch: 13.1 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09014804551485922		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.09014804551485922 | validation: 0.10322722765790744]
	TIME [epoch: 13 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09497885207191253		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.09497885207191253 | validation: 0.10361997026117471]
	TIME [epoch: 13 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09538390104729229		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.09538390104729229 | validation: 0.09410718579513244]
	TIME [epoch: 13 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09712969654600521		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.09712969654600521 | validation: 0.10050960243074542]
	TIME [epoch: 13.1 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09652095875130816		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.09652095875130816 | validation: 0.0974108262967539]
	TIME [epoch: 13 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09671800060037397		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.09671800060037397 | validation: 0.0966085472183283]
	TIME [epoch: 13 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944520198596288		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.0944520198596288 | validation: 0.09952239952659275]
	TIME [epoch: 13.1 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09580720729605624		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.09580720729605624 | validation: 0.10154444302157949]
	TIME [epoch: 13 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08971725458288984		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.08971725458288984 | validation: 0.09031387522219987]
	TIME [epoch: 13 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0869059880569126		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.0869059880569126 | validation: 0.09725176093183509]
	TIME [epoch: 13.1 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08795053031806305		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.08795053031806305 | validation: 0.09458219960255514]
	TIME [epoch: 13 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08975067843438955		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.08975067843438955 | validation: 0.09705240544445942]
	TIME [epoch: 13 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08936741231181188		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.08936741231181188 | validation: 0.08939706296338341]
	TIME [epoch: 13 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08871859352875222		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.08871859352875222 | validation: 0.0911612072692612]
	TIME [epoch: 13.1 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08971326737553065		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.08971326737553065 | validation: 0.09185997182947485]
	TIME [epoch: 13 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08579898497388808		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.08579898497388808 | validation: 0.0947844613581893]
	TIME [epoch: 13 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08757018846016532		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.08757018846016532 | validation: 0.09331696970907999]
	TIME [epoch: 13.1 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09092685900422054		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.09092685900422054 | validation: 0.09258383973222724]
	TIME [epoch: 13 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09321387413486469		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.09321387413486469 | validation: 0.10233661389781058]
	TIME [epoch: 13 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08762584166871985		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.08762584166871985 | validation: 0.08679868593268525]
	TIME [epoch: 13.1 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09070627191473098		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.09070627191473098 | validation: 0.09606646361124169]
	TIME [epoch: 13 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08848415610895483		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.08848415610895483 | validation: 0.089678824218914]
	TIME [epoch: 13 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08908629891218524		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.08908629891218524 | validation: 0.09439609973406868]
	TIME [epoch: 13 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09092081431446605		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.09092081431446605 | validation: 0.09352657864013701]
	TIME [epoch: 13.1 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09259689993629604		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.09259689993629604 | validation: 0.09279918677237924]
	TIME [epoch: 13 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09707412092066314		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.09707412092066314 | validation: 0.09425430656669902]
	TIME [epoch: 13 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08883369191025349		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.08883369191025349 | validation: 0.09162043090448908]
	TIME [epoch: 13 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08890168030369841		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.08890168030369841 | validation: 0.09097887181994989]
	TIME [epoch: 13 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09564069120352664		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.09564069120352664 | validation: 0.08402160633086914]
	TIME [epoch: 13 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09296580992590053		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.09296580992590053 | validation: 0.10224460173873577]
	TIME [epoch: 13 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08965203503292789		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.08965203503292789 | validation: 0.09220917754480212]
	TIME [epoch: 13 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09019274399260846		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.09019274399260846 | validation: 0.08950967832926825]
	TIME [epoch: 13 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09033228123182002		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.09033228123182002 | validation: 0.09780185658120168]
	TIME [epoch: 13 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08904600400304491		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.08904600400304491 | validation: 0.08985286877451501]
	TIME [epoch: 13 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09062898615593737		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.09062898615593737 | validation: 0.09463698087839834]
	TIME [epoch: 13 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0868383834810984		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.0868383834810984 | validation: 0.09446557232805738]
	TIME [epoch: 13 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08549412350582569		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.08549412350582569 | validation: 0.09003400368910487]
	TIME [epoch: 13.1 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09342742091485283		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.09342742091485283 | validation: 0.09727585328785711]
	TIME [epoch: 13 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08664815783959494		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.08664815783959494 | validation: 0.1032323412239873]
	TIME [epoch: 13 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08967245525772044		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.08967245525772044 | validation: 0.09659141371120303]
	TIME [epoch: 13.1 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09161809477362873		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.09161809477362873 | validation: 0.10195790315846413]
	TIME [epoch: 13 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0917285468364955		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.0917285468364955 | validation: 0.08420454025679584]
	TIME [epoch: 13 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09042804347137787		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.09042804347137787 | validation: 0.10087916094666609]
	TIME [epoch: 13 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09010897280653671		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.09010897280653671 | validation: 0.09257404931457307]
	TIME [epoch: 13 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08523811220169669		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.08523811220169669 | validation: 0.09258943330270215]
	TIME [epoch: 13 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08802506117989203		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.08802506117989203 | validation: 0.09241250751236935]
	TIME [epoch: 13 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08971118127013031		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.08971118127013031 | validation: 0.1073478416098277]
	TIME [epoch: 13.1 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09384116650560734		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.09384116650560734 | validation: 0.09867129220431627]
	TIME [epoch: 13 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09297074186853885		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.09297074186853885 | validation: 0.09526198862610255]
	TIME [epoch: 13 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09769215147436607		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.09769215147436607 | validation: 0.09679014683260452]
	TIME [epoch: 13.1 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0933288575419078		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.0933288575419078 | validation: 0.1044786457479817]
	TIME [epoch: 13 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09441312941796726		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.09441312941796726 | validation: 0.10525804106301134]
	TIME [epoch: 13 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09011936371544235		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.09011936371544235 | validation: 0.08871979471287128]
	TIME [epoch: 13.1 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08743703292510911		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.08743703292510911 | validation: 0.10392136946986608]
	TIME [epoch: 13 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08830975168874622		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.08830975168874622 | validation: 0.08938195759380439]
	TIME [epoch: 13 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08739323290457136		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.08739323290457136 | validation: 0.09887860158655157]
	TIME [epoch: 13 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09245418080385007		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.09245418080385007 | validation: 0.09403613492006749]
	TIME [epoch: 13 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08495438338165898		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.08495438338165898 | validation: 0.08764122334548514]
	TIME [epoch: 13 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08979405006301702		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.08979405006301702 | validation: 0.08799089772065465]
	TIME [epoch: 13 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08947927451482891		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.08947927451482891 | validation: 0.0900642884179988]
	TIME [epoch: 13.1 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09147219164989734		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.09147219164989734 | validation: 0.09557999483113847]
	TIME [epoch: 13 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08901609647409717		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.08901609647409717 | validation: 0.09601481604744602]
	TIME [epoch: 13 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08997503294421669		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.08997503294421669 | validation: 0.08757005885732269]
	TIME [epoch: 13.1 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09153100451814802		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.09153100451814802 | validation: 0.092265053903702]
	TIME [epoch: 13 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0930060171037583		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.0930060171037583 | validation: 0.09613318563871044]
	TIME [epoch: 13 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09085754517150446		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.09085754517150446 | validation: 0.09298721132148845]
	TIME [epoch: 13.1 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08943566866009499		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.08943566866009499 | validation: 0.09167897028104406]
	TIME [epoch: 13 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08805694986365256		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.08805694986365256 | validation: 0.0855997369636632]
	TIME [epoch: 13 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08634532725805838		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.08634532725805838 | validation: 0.09310546214971016]
	TIME [epoch: 13 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08789676108513014		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.08789676108513014 | validation: 0.0866846816178097]
	TIME [epoch: 13.1 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09077226548391978		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.09077226548391978 | validation: 0.09412668850213271]
	TIME [epoch: 13 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09056126985133796		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.09056126985133796 | validation: 0.09135714106276405]
	TIME [epoch: 13 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08860206109275466		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.08860206109275466 | validation: 0.10232612465060846]
	TIME [epoch: 13 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08955246819195964		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.08955246819195964 | validation: 0.08939832284431436]
	TIME [epoch: 13 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08847648259416999		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.08847648259416999 | validation: 0.08850623305062644]
	TIME [epoch: 13 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0880904932399887		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.0880904932399887 | validation: 0.09052302360434863]
	TIME [epoch: 13.1 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08941629177994087		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.08941629177994087 | validation: 0.09277051041202718]
	TIME [epoch: 13 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08791589879090231		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.08791589879090231 | validation: 0.09544499409237833]
	TIME [epoch: 13 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09023561868477444		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.09023561868477444 | validation: 0.1003337788729143]
	TIME [epoch: 13 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08449306414230129		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.08449306414230129 | validation: 0.08986414339531859]
	TIME [epoch: 13 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09187516960924819		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.09187516960924819 | validation: 0.09194417588732927]
	TIME [epoch: 13 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09386272889831482		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.09386272889831482 | validation: 0.10112686924665053]
	TIME [epoch: 13 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09552229851335906		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.09552229851335906 | validation: 0.09056294026510431]
	TIME [epoch: 13 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09833387755758449		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.09833387755758449 | validation: 0.10393988746671295]
	TIME [epoch: 13 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09486200466792308		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.09486200466792308 | validation: 0.09876042322038359]
	TIME [epoch: 13 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10009113742489392		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.10009113742489392 | validation: 0.09132789675190614]
	TIME [epoch: 13 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09417683799824772		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.09417683799824772 | validation: 0.09067314198868044]
	TIME [epoch: 13 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09056539492730824		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.09056539492730824 | validation: 0.09206878078051581]
	TIME [epoch: 13 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09415354801690616		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.09415354801690616 | validation: 0.09000655662586698]
	TIME [epoch: 13 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08997033883071538		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.08997033883071538 | validation: 0.08315403824458109]
	TIME [epoch: 13 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09048689346954959		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.09048689346954959 | validation: 0.09335823804099076]
	TIME [epoch: 13 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09171559017609239		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.09171559017609239 | validation: 0.09670547590149955]
	TIME [epoch: 13.1 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08919469227531282		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.08919469227531282 | validation: 0.0972769948712791]
	TIME [epoch: 13 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08900106396205104		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.08900106396205104 | validation: 0.09229717356200581]
	TIME [epoch: 13 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09198884765698068		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.09198884765698068 | validation: 0.1035217120131539]
	TIME [epoch: 13.1 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09131156093787093		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.09131156093787093 | validation: 0.09150587214468336]
	TIME [epoch: 13.1 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188031768732956		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.09188031768732956 | validation: 0.08955284039089871]
	TIME [epoch: 13 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08767972598678211		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.08767972598678211 | validation: 0.10359747151096528]
	TIME [epoch: 13 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08869600748277463		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.08869600748277463 | validation: 0.09382586109303441]
	TIME [epoch: 13.1 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08633476979386691		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.08633476979386691 | validation: 0.10025173320950692]
	TIME [epoch: 13.1 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08660831704655053		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.08660831704655053 | validation: 0.097870395800821]
	TIME [epoch: 13 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08519469156024546		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.08519469156024546 | validation: 0.09731423873554931]
	TIME [epoch: 13.1 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09071589573392677		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.09071589573392677 | validation: 0.09826635845075775]
	TIME [epoch: 13 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09100115709686812		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.09100115709686812 | validation: 0.10299784933240412]
	TIME [epoch: 13 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08817916558617102		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.08817916558617102 | validation: 0.0949885502124959]
	TIME [epoch: 13 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09176112898517033		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.09176112898517033 | validation: 0.08736691643821018]
	TIME [epoch: 13.1 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0874150128433009		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.0874150128433009 | validation: 0.08362358831761943]
	TIME [epoch: 13 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08860061494177615		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.08860061494177615 | validation: 0.083828492942722]
	TIME [epoch: 13 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08893952695154111		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.08893952695154111 | validation: 0.08917996900154124]
	TIME [epoch: 13.1 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09030939365152443		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.09030939365152443 | validation: 0.09172960109116382]
	TIME [epoch: 13 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09115988211974504		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.09115988211974504 | validation: 0.09829531920284007]
	TIME [epoch: 13 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0903622146362651		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.0903622146362651 | validation: 0.08223587894430154]
	TIME [epoch: 13.1 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08533063279703736		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.08533063279703736 | validation: 0.09316972521748262]
	TIME [epoch: 13 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09165233442431783		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.09165233442431783 | validation: 0.08246335375513696]
	TIME [epoch: 13 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09032607551477759		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.09032607551477759 | validation: 0.0928502294502093]
	TIME [epoch: 13.1 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08983062442029566		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.08983062442029566 | validation: 0.09273996905429333]
	TIME [epoch: 13 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0951581138369786		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.0951581138369786 | validation: 0.09567746816078306]
	TIME [epoch: 13 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09380156898815087		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.09380156898815087 | validation: 0.09237229043338943]
	TIME [epoch: 13 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09364625136815016		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.09364625136815016 | validation: 0.08808265527961485]
	TIME [epoch: 13 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0928834648086614		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.0928834648086614 | validation: 0.08675403654321744]
	TIME [epoch: 13 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08846197810370596		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.08846197810370596 | validation: 0.07517924322118444]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240310_003030/states/model_tr_study3_1769.pth
	Model improved!!!
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08969759101352476		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.08969759101352476 | validation: 0.08854397333061818]
	TIME [epoch: 13.1 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909970505488228		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.0909970505488228 | validation: 0.09660484249398503]
	TIME [epoch: 13 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08975370379595826		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.08975370379595826 | validation: 0.0844194538184517]
	TIME [epoch: 13 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08980460534363499		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.08980460534363499 | validation: 0.09398641755220861]
	TIME [epoch: 13 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08992231504559825		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.08992231504559825 | validation: 0.09631271845232937]
	TIME [epoch: 13 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08915653201053048		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.08915653201053048 | validation: 0.08562985546438119]
	TIME [epoch: 13 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09007374074831495		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.09007374074831495 | validation: 0.09701873094813877]
	TIME [epoch: 13 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09056170101382605		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.09056170101382605 | validation: 0.09786417018145734]
	TIME [epoch: 13 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909873289846995		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.0909873289846995 | validation: 0.09648680835508429]
	TIME [epoch: 13 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08945348773677576		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.08945348773677576 | validation: 0.09883553688226196]
	TIME [epoch: 13 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09148062126306111		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.09148062126306111 | validation: 0.09168686849964086]
	TIME [epoch: 13.1 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09116992989349453		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.09116992989349453 | validation: 0.09026438471543571]
	TIME [epoch: 13 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09192196111654392		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.09192196111654392 | validation: 0.09408746685141506]
	TIME [epoch: 13 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09247246727699863		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.09247246727699863 | validation: 0.09849154131067246]
	TIME [epoch: 13 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09126650461686407		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.09126650461686407 | validation: 0.09307231294300168]
	TIME [epoch: 13 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09275357031911827		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.09275357031911827 | validation: 0.08979795731181581]
	TIME [epoch: 13 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08876542154450855		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.08876542154450855 | validation: 0.09759830675380615]
	TIME [epoch: 13 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09178323006713596		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.09178323006713596 | validation: 0.09861542411421803]
	TIME [epoch: 13 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09099886304160688		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.09099886304160688 | validation: 0.09472934818694746]
	TIME [epoch: 13 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0906480125094192		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.0906480125094192 | validation: 0.09472061031595445]
	TIME [epoch: 13 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0910158286826394		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.0910158286826394 | validation: 0.08879183048823787]
	TIME [epoch: 13.1 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08737493287161252		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.08737493287161252 | validation: 0.09673054722506644]
	TIME [epoch: 13 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09187960651893874		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.09187960651893874 | validation: 0.08833231998056419]
	TIME [epoch: 13 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0858712896294468		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.0858712896294468 | validation: 0.09283978079421384]
	TIME [epoch: 13.1 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09122941162910306		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.09122941162910306 | validation: 0.08898062514652834]
	TIME [epoch: 13 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08390824622575302		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.08390824622575302 | validation: 0.09267750658276169]
	TIME [epoch: 13 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08643606057623159		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.08643606057623159 | validation: 0.09042209288091806]
	TIME [epoch: 13 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08764476908758237		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.08764476908758237 | validation: 0.08471727794231644]
	TIME [epoch: 13 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08611945961991398		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.08611945961991398 | validation: 0.09172947063871903]
	TIME [epoch: 13 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08854767952885403		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.08854767952885403 | validation: 0.09199876723662775]
	TIME [epoch: 13 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08840401595670673		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.08840401595670673 | validation: 0.0866529212910332]
	TIME [epoch: 13 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0878601792295182		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.0878601792295182 | validation: 0.09435395391308524]
	TIME [epoch: 13 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09338556787341404		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.09338556787341404 | validation: 0.08940425383767693]
	TIME [epoch: 13 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09253098342766491		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.09253098342766491 | validation: 0.08886502867656386]
	TIME [epoch: 13 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08492611384113803		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.08492611384113803 | validation: 0.09421746709617164]
	TIME [epoch: 13 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08784110349924393		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.08784110349924393 | validation: 0.09537003469299726]
	TIME [epoch: 13 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08361238467801134		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.08361238467801134 | validation: 0.08668743748888537]
	TIME [epoch: 13.1 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0854882878755619		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.0854882878755619 | validation: 0.08529048722274489]
	TIME [epoch: 13 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08858188585543278		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.08858188585543278 | validation: 0.08946172527082037]
	TIME [epoch: 13 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08822520727030199		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.08822520727030199 | validation: 0.09016995916966007]
	TIME [epoch: 13 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08427150580977118		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.08427150580977118 | validation: 0.08834083679613443]
	TIME [epoch: 13 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08705608044349376		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.08705608044349376 | validation: 0.09547687964916826]
	TIME [epoch: 13 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08863437714194272		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.08863437714194272 | validation: 0.08986292177057252]
	TIME [epoch: 13 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08748063636788242		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.08748063636788242 | validation: 0.0902259500570139]
	TIME [epoch: 13.1 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08975512716616069		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.08975512716616069 | validation: 0.09034731912890012]
	TIME [epoch: 13 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09045638774113565		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.09045638774113565 | validation: 0.08669972429916242]
	TIME [epoch: 13 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09094617420213391		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.09094617420213391 | validation: 0.09307219268343729]
	TIME [epoch: 13 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09001798032120353		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.09001798032120353 | validation: 0.09929060521455808]
	TIME [epoch: 13 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09154805866039889		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.09154805866039889 | validation: 0.103447069425749]
	TIME [epoch: 13 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0970293162254875		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.0970293162254875 | validation: 0.09700625917786412]
	TIME [epoch: 13 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0914461616887607		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.0914461616887607 | validation: 0.09694868627330303]
	TIME [epoch: 13 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09097773949777062		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.09097773949777062 | validation: 0.0936928456017893]
	TIME [epoch: 13 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08657508034487134		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.08657508034487134 | validation: 0.09164463773563351]
	TIME [epoch: 13 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08492746978145005		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.08492746978145005 | validation: 0.09286014406210956]
	TIME [epoch: 13.1 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08844242563105062		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.08844242563105062 | validation: 0.08927279469161135]
	TIME [epoch: 13 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08903169224107546		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.08903169224107546 | validation: 0.08612269643102316]
	TIME [epoch: 13 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08847142300685074		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.08847142300685074 | validation: 0.09920848760184646]
	TIME [epoch: 13.1 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08589509387005922		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.08589509387005922 | validation: 0.09303499748387715]
	TIME [epoch: 13 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08692621031133367		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.08692621031133367 | validation: 0.09554036551974424]
	TIME [epoch: 13 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09097931010861722		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.09097931010861722 | validation: 0.08806800173665014]
	TIME [epoch: 13.1 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08769673534823587		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.08769673534823587 | validation: 0.09290020633235113]
	TIME [epoch: 13 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09081689305958077		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.09081689305958077 | validation: 0.09168874279522339]
	TIME [epoch: 13 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08466363075483203		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.08466363075483203 | validation: 0.0937682444604129]
	TIME [epoch: 13 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08693254744007985		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.08693254744007985 | validation: 0.08872288059900052]
	TIME [epoch: 13 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089683125622019		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.089683125622019 | validation: 0.09368839147180799]
	TIME [epoch: 13 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08963077562431647		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.08963077562431647 | validation: 0.08892683007694899]
	TIME [epoch: 13 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08845851628724166		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.08845851628724166 | validation: 0.09297214433481182]
	TIME [epoch: 13.1 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08940914786827606		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.08940914786827606 | validation: 0.08644009186636925]
	TIME [epoch: 13 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08396243678217348		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.08396243678217348 | validation: 0.0954912733939688]
	TIME [epoch: 13 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08767034547378148		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.08767034547378148 | validation: 0.08939504506004264]
	TIME [epoch: 13 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09106766376252964		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.09106766376252964 | validation: 0.09155127628929584]
	TIME [epoch: 13 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08698734770673908		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.08698734770673908 | validation: 0.08188430744527558]
	TIME [epoch: 13 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08733389030577818		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.08733389030577818 | validation: 0.08682307602205411]
	TIME [epoch: 13 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09000754361009967		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.09000754361009967 | validation: 0.083535028981887]
	TIME [epoch: 13 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09433254954083688		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.09433254954083688 | validation: 0.08892373141202832]
	TIME [epoch: 13 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08949326704409227		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.08949326704409227 | validation: 0.09006611576201118]
	TIME [epoch: 13 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08907511346047323		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.08907511346047323 | validation: 0.08917401519756105]
	TIME [epoch: 13 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08937808394549615		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.08937808394549615 | validation: 0.09069591001922653]
	TIME [epoch: 13 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08859577613735346		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.08859577613735346 | validation: 0.09368462280681673]
	TIME [epoch: 13 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08994411850939207		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.08994411850939207 | validation: 0.09184050341631551]
	TIME [epoch: 13.1 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0934430322591233		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.0934430322591233 | validation: 0.09176494599094293]
	TIME [epoch: 13 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08683951214683909		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.08683951214683909 | validation: 0.08869673801156454]
	TIME [epoch: 13 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08460559075608234		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.08460559075608234 | validation: 0.09109801354387338]
	TIME [epoch: 13.1 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09092660893019566		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.09092660893019566 | validation: 0.09502773488783507]
	TIME [epoch: 13 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09008839965146566		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.09008839965146566 | validation: 0.08923988901408103]
	TIME [epoch: 13 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08722525134026744		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.08722525134026744 | validation: 0.09239202302813172]
	TIME [epoch: 13 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08873290381702251		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.08873290381702251 | validation: 0.1002669236006696]
	TIME [epoch: 13.1 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861274602100163		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.0861274602100163 | validation: 0.09400909973450898]
	TIME [epoch: 13 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0900742274081394		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.0900742274081394 | validation: 0.09106129300459788]
	TIME [epoch: 13 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0873506808405428		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.0873506808405428 | validation: 0.08058096137455696]
	TIME [epoch: 13.1 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09058228314323326		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.09058228314323326 | validation: 0.09193347251327776]
	TIME [epoch: 13 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08188572665819821		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.08188572665819821 | validation: 0.09077359700923811]
	TIME [epoch: 13 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08887805632953304		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.08887805632953304 | validation: 0.09894026486235877]
	TIME [epoch: 13.1 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08622535726060279		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.08622535726060279 | validation: 0.09047012197166758]
	TIME [epoch: 13 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08928964924534044		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.08928964924534044 | validation: 0.0866918604528973]
	TIME [epoch: 13 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08856275899173296		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.08856275899173296 | validation: 0.0995110248682]
	TIME [epoch: 13.1 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08849578262308906		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.08849578262308906 | validation: 0.09736651234145598]
	TIME [epoch: 13 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08567611495463565		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.08567611495463565 | validation: 0.08900024714792429]
	TIME [epoch: 13 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08810322599092607		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.08810322599092607 | validation: 0.09239097855446585]
	TIME [epoch: 13 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0897175651064138		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.0897175651064138 | validation: 0.08628329728103662]
	TIME [epoch: 13.1 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08871461222705503		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.08871461222705503 | validation: 0.08443771847180007]
	TIME [epoch: 13 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08677547461583983		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.08677547461583983 | validation: 0.08832528875993735]
	TIME [epoch: 13 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08890860605904351		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.08890860605904351 | validation: 0.08361608550966443]
	TIME [epoch: 13.1 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08768144159250674		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.08768144159250674 | validation: 0.08868944804140251]
	TIME [epoch: 13 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08787280113793117		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.08787280113793117 | validation: 0.0864372801525408]
	TIME [epoch: 13 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08937253869452644		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.08937253869452644 | validation: 0.09128116706329138]
	TIME [epoch: 13.1 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09153295186938618		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.09153295186938618 | validation: 0.0879750580850158]
	TIME [epoch: 13.1 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08724269811282027		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.08724269811282027 | validation: 0.09116342023117456]
	TIME [epoch: 13 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0867210840026285		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.0867210840026285 | validation: 0.09406406879857672]
	TIME [epoch: 13.1 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09028402471831079		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.09028402471831079 | validation: 0.09132875303662637]
	TIME [epoch: 13.1 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08964869839875492		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.08964869839875492 | validation: 0.08805322268880911]
	TIME [epoch: 13 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08849874570762142		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.08849874570762142 | validation: 0.08701425797301753]
	TIME [epoch: 13 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0870957997899956		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.0870957997899956 | validation: 0.0920159385858425]
	TIME [epoch: 13.1 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08953864177248003		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.08953864177248003 | validation: 0.08796029766484839]
	TIME [epoch: 13 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08855531796666881		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.08855531796666881 | validation: 0.08834469145620269]
	TIME [epoch: 13 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08929601427485744		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.08929601427485744 | validation: 0.09088027674272844]
	TIME [epoch: 13.1 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0863530904767242		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.0863530904767242 | validation: 0.0894024901327152]
	TIME [epoch: 13 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0911619071070001		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.0911619071070001 | validation: 0.09850488412028308]
	TIME [epoch: 13 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188924634120438		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.09188924634120438 | validation: 0.09002204917099782]
	TIME [epoch: 13.1 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08453175141472415		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.08453175141472415 | validation: 0.09066740464056643]
	TIME [epoch: 13 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08573201863061208		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.08573201863061208 | validation: 0.09470332252055957]
	TIME [epoch: 13 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08680579174729786		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.08680579174729786 | validation: 0.08797684098697575]
	TIME [epoch: 13 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08972266659344409		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.08972266659344409 | validation: 0.0775905449762322]
	TIME [epoch: 13.1 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08843353786201696		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.08843353786201696 | validation: 0.09669425181887263]
	TIME [epoch: 13 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0886802408015375		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.0886802408015375 | validation: 0.08844038573887648]
	TIME [epoch: 13 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08480564714083905		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.08480564714083905 | validation: 0.09236972342085721]
	TIME [epoch: 13 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08776871569434937		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.08776871569434937 | validation: 0.09277937325330608]
	TIME [epoch: 13 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08944599332577405		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.08944599332577405 | validation: 0.09492621422273054]
	TIME [epoch: 13 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08674762200961231		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.08674762200961231 | validation: 0.09448034406866733]
	TIME [epoch: 13 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08778813363627598		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.08778813363627598 | validation: 0.08500258701598211]
	TIME [epoch: 13 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08849317986247388		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.08849317986247388 | validation: 0.08798608744380762]
	TIME [epoch: 13 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08864018828532888		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.08864018828532888 | validation: 0.0892630396291723]
	TIME [epoch: 13 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08833780927229415		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.08833780927229415 | validation: 0.08929260955607805]
	TIME [epoch: 13 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09025087526612069		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.09025087526612069 | validation: 0.08248788119697868]
	TIME [epoch: 13 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09111752509037753		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.09111752509037753 | validation: 0.09198409414324975]
	TIME [epoch: 13 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08951396439382857		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.08951396439382857 | validation: 0.08264511019052866]
	TIME [epoch: 13 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08854790777872988		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.08854790777872988 | validation: 0.0864394640624791]
	TIME [epoch: 13 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08769994526763253		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.08769994526763253 | validation: 0.09412789861376698]
	TIME [epoch: 13 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08717298347994386		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.08717298347994386 | validation: 0.0973644355347825]
	TIME [epoch: 13 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09109549751808102		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.09109549751808102 | validation: 0.08519663445950318]
	TIME [epoch: 13 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08825245386384603		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.08825245386384603 | validation: 0.1002231764216676]
	TIME [epoch: 13 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0890341131956633		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.0890341131956633 | validation: 0.09097555889665206]
	TIME [epoch: 13 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08791452141478129		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.08791452141478129 | validation: 0.09269862263623921]
	TIME [epoch: 13 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08716847433571837		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.08716847433571837 | validation: 0.09002921275829227]
	TIME [epoch: 13 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08402865598778336		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.08402865598778336 | validation: 0.08351707137701406]
	TIME [epoch: 13 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09160086616865659		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.09160086616865659 | validation: 0.08775433465138466]
	TIME [epoch: 13.1 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08366526207019012		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.08366526207019012 | validation: 0.09745652250576271]
	TIME [epoch: 13 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08699957108703608		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.08699957108703608 | validation: 0.09751180697025881]
	TIME [epoch: 13 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09323767677745706		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.09323767677745706 | validation: 0.09278377865153684]
	TIME [epoch: 13 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08642952753331754		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.08642952753331754 | validation: 0.09195190701788375]
	TIME [epoch: 13 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09157894057797716		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.09157894057797716 | validation: 0.08683321068195678]
	TIME [epoch: 13 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09116948084585201		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.09116948084585201 | validation: 0.09334019914113455]
	TIME [epoch: 13.1 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08761299458878787		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.08761299458878787 | validation: 0.0864662321685261]
	TIME [epoch: 13 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0900063992467599		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.0900063992467599 | validation: 0.09244028466600163]
	TIME [epoch: 13 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0905082225706678		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.0905082225706678 | validation: 0.08555729715970835]
	TIME [epoch: 13 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08532255110590675		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.08532255110590675 | validation: 0.08538216409902978]
	TIME [epoch: 13.1 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08547362588586618		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.08547362588586618 | validation: 0.08462774291349995]
	TIME [epoch: 13 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0921804713109517		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.0921804713109517 | validation: 0.08989124842023521]
	TIME [epoch: 13 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08833700709120505		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.08833700709120505 | validation: 0.09276126854171458]
	TIME [epoch: 13 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08585560179245186		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.08585560179245186 | validation: 0.09033643332323191]
	TIME [epoch: 13 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09086752952316063		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.09086752952316063 | validation: 0.09179679444545435]
	TIME [epoch: 13 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09111896098124092		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.09111896098124092 | validation: 0.08957585635968764]
	TIME [epoch: 13.1 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08703078501867978		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.08703078501867978 | validation: 0.0887918046298954]
	TIME [epoch: 13 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09126357971148451		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.09126357971148451 | validation: 0.09219924746437809]
	TIME [epoch: 13 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08809262017327257		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.08809262017327257 | validation: 0.0910152765772977]
	TIME [epoch: 13 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08923517589357148		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.08923517589357148 | validation: 0.09919886253981142]
	TIME [epoch: 13 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08844703764106115		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.08844703764106115 | validation: 0.09517883863524584]
	TIME [epoch: 13 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09175831454882753		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.09175831454882753 | validation: 0.093180734036756]
	TIME [epoch: 13.1 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09073011864493655		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.09073011864493655 | validation: 0.0781277364457632]
	TIME [epoch: 13 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0898510532210863		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.0898510532210863 | validation: 0.09058320483160781]
	TIME [epoch: 13 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09058072895138		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.09058072895138 | validation: 0.09296900473947807]
	TIME [epoch: 13 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09102743653773115		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.09102743653773115 | validation: 0.08251187642000081]
	TIME [epoch: 13.1 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09100488033375966		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.09100488033375966 | validation: 0.09529609234946777]
	TIME [epoch: 13 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08661169859028622		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.08661169859028622 | validation: 0.08771310985383163]
	TIME [epoch: 13 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08875618079950032		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.08875618079950032 | validation: 0.08479457664057385]
	TIME [epoch: 13.1 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08678600844379214		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.08678600844379214 | validation: 0.09325756807103598]
	TIME [epoch: 13 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08723722971705268		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.08723722971705268 | validation: 0.08514020661204505]
	TIME [epoch: 13 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08687997579089868		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.08687997579089868 | validation: 0.0876870562689863]
	TIME [epoch: 13.1 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08624760635902413		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.08624760635902413 | validation: 0.09151225958671769]
	TIME [epoch: 13 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0849393431645511		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.0849393431645511 | validation: 0.08844753422931513]
	TIME [epoch: 13 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0879533944516078		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.0879533944516078 | validation: 0.08348620805084704]
	TIME [epoch: 13 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08979425951840143		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.08979425951840143 | validation: 0.09224016103154639]
	TIME [epoch: 13.1 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08473364008703349		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.08473364008703349 | validation: 0.08831524900673181]
	TIME [epoch: 13 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08634314382068736		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.08634314382068736 | validation: 0.09510954574935791]
	TIME [epoch: 13 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08671458128089285		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.08671458128089285 | validation: 0.09631722561550671]
	TIME [epoch: 13.1 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08555136096537683		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.08555136096537683 | validation: 0.10073407032493302]
	TIME [epoch: 13 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0848257887183162		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.0848257887183162 | validation: 0.09034869589120864]
	TIME [epoch: 13 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08772932092536098		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.08772932092536098 | validation: 0.0943884981556867]
	TIME [epoch: 13.1 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08653301799728046		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.08653301799728046 | validation: 0.10218283434581193]
	TIME [epoch: 13 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08691647031215488		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.08691647031215488 | validation: 0.09706171764007021]
	TIME [epoch: 13 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08658368272457914		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.08658368272457914 | validation: 0.09984361826706352]
	TIME [epoch: 13.1 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883975414733876		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.0883975414733876 | validation: 0.0895871312234973]
	TIME [epoch: 13 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08719977378996002		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.08719977378996002 | validation: 0.09069340128017028]
	TIME [epoch: 13 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08840924381023493		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.08840924381023493 | validation: 0.09655942724022375]
	TIME [epoch: 13 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0896291103840356		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.0896291103840356 | validation: 0.09115636862935986]
	TIME [epoch: 13.1 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0846953474273108		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.0846953474273108 | validation: 0.09826190492859624]
	TIME [epoch: 13 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08884231427493719		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.08884231427493719 | validation: 0.09576799359311529]
	TIME [epoch: 13 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08669224733751754		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.08669224733751754 | validation: 0.10011158303760248]
	TIME [epoch: 13.1 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08861925508539903		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.08861925508539903 | validation: 0.08310722276141748]
	TIME [epoch: 13 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08793331475858132		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.08793331475858132 | validation: 0.08697455168504689]
	TIME [epoch: 13 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08838023283749159		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.08838023283749159 | validation: 0.08848123725369501]
	TIME [epoch: 13 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09143997731784696		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.09143997731784696 | validation: 0.0997096119889432]
	TIME [epoch: 13 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08724762234100111		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.08724762234100111 | validation: 0.0888935187059388]
	TIME [epoch: 13 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08748052266210397		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.08748052266210397 | validation: 0.09051191431014209]
	TIME [epoch: 13.1 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08892338487212173		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.08892338487212173 | validation: 0.0927680735166277]
	TIME [epoch: 13 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08621397360003832		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.08621397360003832 | validation: 0.0927044040745804]
	TIME [epoch: 13 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08623079204934435		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.08623079204934435 | validation: 0.09376822885014086]
	TIME [epoch: 13 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08795691102990069		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.08795691102990069 | validation: 0.08840223033732525]
	TIME [epoch: 13.1 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08670985488355747		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.08670985488355747 | validation: 0.09386429921715207]
	TIME [epoch: 13 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0876290346830712		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.0876290346830712 | validation: 0.09614732020607218]
	TIME [epoch: 13 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09017078000480086		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.09017078000480086 | validation: 0.09351530511838148]
	TIME [epoch: 13.1 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08588239446266113		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.08588239446266113 | validation: 0.10327854608444176]
	TIME [epoch: 13 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883269381729091		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.0883269381729091 | validation: 0.10004783867723845]
	TIME [epoch: 13 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09166901844464695		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.09166901844464695 | validation: 0.09337384764946023]
	TIME [epoch: 13 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08931180922882312		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.08931180922882312 | validation: 0.08679286154296044]
	TIME [epoch: 13 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08631554673033659		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.08631554673033659 | validation: 0.08829806565830893]
	TIME [epoch: 13 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08613845195336883		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.08613845195336883 | validation: 0.08878134451760258]
	TIME [epoch: 13 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08678732804361658		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.08678732804361658 | validation: 0.08417857530486039]
	TIME [epoch: 13 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888367703956356		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.0888367703956356 | validation: 0.09231914696602678]
	TIME [epoch: 13 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08979429821469853		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.08979429821469853 | validation: 0.08967915563196809]
	TIME [epoch: 13 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08428354793093663		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.08428354793093663 | validation: 0.0910102624562448]
	TIME [epoch: 13.1 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08895497763684325		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.08895497763684325 | validation: 0.08065234778769995]
	TIME [epoch: 13 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08781160697574827		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.08781160697574827 | validation: 0.08393117367754754]
	TIME [epoch: 13 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08776823902026207		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.08776823902026207 | validation: 0.08939664059160858]
	TIME [epoch: 13.1 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08790199838704041		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.08790199838704041 | validation: 0.10405498397144552]
	TIME [epoch: 13 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09039605461532109		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.09039605461532109 | validation: 0.0856727786595383]
	TIME [epoch: 13 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08917565424877022		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.08917565424877022 | validation: 0.09131239278022213]
	TIME [epoch: 13 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08299741549069617		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.08299741549069617 | validation: 0.08415394782033758]
	TIME [epoch: 13 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08876159132038586		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.08876159132038586 | validation: 0.09280875297941373]
	TIME [epoch: 13 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08907626639464838		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.08907626639464838 | validation: 0.09342429881429246]
	TIME [epoch: 13 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0875614580869037		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.0875614580869037 | validation: 0.09796733036949937]
	TIME [epoch: 13 sec]
Finished training in 26234.059 seconds.
