Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r0', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1354666570

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.855643575009385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.855643575009385 | validation: 10.910760333584609]
	TIME [epoch: 101 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.828059486006655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.828059486006655 | validation: 10.451956732621648]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.615868584442271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.615868584442271 | validation: 10.331690650382013]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.44115292152335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.44115292152335 | validation: 10.144724738328764]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.29211206865707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.29211206865707 | validation: 9.92945728250294]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.082255234958923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.082255234958923 | validation: 9.652935230219564]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.012786848820124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.012786848820124 | validation: 7.848783076851642]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.425673271620925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.425673271620925 | validation: 7.006885117363581]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.961684275256971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.961684275256971 | validation: 6.842746848383754]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.692868505350008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.692868505350008 | validation: 6.4724907016830375]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.315188559011743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.315188559011743 | validation: 6.001385703895533]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.033054477429597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.033054477429597 | validation: 5.949633408031814]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.853921291949188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.853921291949188 | validation: 5.933995878393797]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.831246170942204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.831246170942204 | validation: 5.946627099229708]
	TIME [epoch: 11.6 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.810576412018804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.810576412018804 | validation: 5.801016931207231]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7733800815986065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7733800815986065 | validation: 5.734302633265777]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.606924923081195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.606924923081195 | validation: 5.569053603833424]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.652665494396896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.652665494396896 | validation: 5.700392268581713]
	TIME [epoch: 11.6 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5008199049142465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5008199049142465 | validation: 5.451583428825729]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.450766777045403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.450766777045403 | validation: 5.477884770071421]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.568468013839498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.568468013839498 | validation: 5.3483800403226995]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.237656127857964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.237656127857964 | validation: 5.31101632211803]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.254965203079091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.254965203079091 | validation: 5.258332298195213]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.177478781789231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.177478781789231 | validation: 5.32060672019559]
	TIME [epoch: 11.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.214440608112935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.214440608112935 | validation: 5.411545677883931]
	TIME [epoch: 11.5 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.459194383081148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.459194383081148 | validation: 5.249089818881755]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1527071065390455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1527071065390455 | validation: 5.190184313720226]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.109367719901129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.109367719901129 | validation: 5.225894971566507]
	TIME [epoch: 11.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.147214313064984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.147214313064984 | validation: 5.252331807692865]
	TIME [epoch: 11.6 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.054452254526937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.054452254526937 | validation: 5.197626428900789]
	TIME [epoch: 11.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.131680808228275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.131680808228275 | validation: 5.068171073929084]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.987121504044755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.987121504044755 | validation: 5.189204156843955]
	TIME [epoch: 11.5 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1542497124309925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1542497124309925 | validation: 4.910862986117839]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.919061551848323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.919061551848323 | validation: 5.076470381108824]
	TIME [epoch: 11.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.919369176450248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.919369176450248 | validation: 4.828168048418968]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.800876670778731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.800876670778731 | validation: 5.658860466686109]
	TIME [epoch: 11.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.583472885975398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.583472885975398 | validation: 5.052717685805807]
	TIME [epoch: 11.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.970324909116448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.970324909116448 | validation: 4.746658177698855]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.032751004599385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.032751004599385 | validation: 5.028343928983933]
	TIME [epoch: 11.5 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.995518070890096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.995518070890096 | validation: 5.73791553440451]
	TIME [epoch: 11.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.194912141607765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.194912141607765 | validation: 4.710385667325016]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.611745814119471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.611745814119471 | validation: 4.903675827880182]
	TIME [epoch: 11.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.65486978688173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.65486978688173 | validation: 5.241983729202818]
	TIME [epoch: 11.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.785602802336378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.785602802336378 | validation: 4.381026952784297]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466894340007393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.466894340007393 | validation: 4.666818727828866]
	TIME [epoch: 11.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.309040295319145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.309040295319145 | validation: 4.231820293573192]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3283232072648925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3283232072648925 | validation: 4.23493062372584]
	TIME [epoch: 11.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.111512873497749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.111512873497749 | validation: 3.9595805001456985]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9595642936144078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9595642936144078 | validation: 3.9156775232025987]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8787480620947177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8787480620947177 | validation: 3.513988092089412]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5586913243874285		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.5586913243874285 | validation: 3.190373504772355]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2969154380360135		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.2969154380360135 | validation: 3.048054973579131]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2832369651517794		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.2832369651517794 | validation: 2.7575741553267723]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.91715446179676		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.91715446179676 | validation: 2.819401606266182]
	TIME [epoch: 11.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.286445206759967		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.286445206759967 | validation: 3.8930673821051203]
	TIME [epoch: 11.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1473084723915816		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.1473084723915816 | validation: 2.925803054904128]
	TIME [epoch: 11.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7261097034469435		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.7261097034469435 | validation: 2.357923917684429]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6142481190784235		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.6142481190784235 | validation: 2.8370515125023212]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7933644531201707		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.7933644531201707 | validation: 2.525880348070008]
	TIME [epoch: 11.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5036879433014		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.5036879433014 | validation: 2.355992031056436]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6416858923239617		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.6416858923239617 | validation: 2.0786864163807075]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3515812070926643		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.3515812070926643 | validation: 2.03648253717746]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3704387253665837		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.3704387253665837 | validation: 2.118199373984605]
	TIME [epoch: 11.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.329983201842218		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.329983201842218 | validation: 3.7337225830247007]
	TIME [epoch: 11.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7871751440494235		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.7871751440494235 | validation: 3.6113080849181145]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.723282977386452		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.723282977386452 | validation: 2.1005880933323757]
	TIME [epoch: 11.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9663351274469414		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.9663351274469414 | validation: 3.1875365082208114]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4888438681816463		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.4888438681816463 | validation: 2.21363377287414]
	TIME [epoch: 11.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2266292984104767		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.2266292984104767 | validation: 2.4627697273835616]
	TIME [epoch: 11.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1085146131021943		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.1085146131021943 | validation: 1.7006584772759004]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2415868909106864		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.2415868909106864 | validation: 1.8469657858834445]
	TIME [epoch: 11.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.007750208899471		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.007750208899471 | validation: 1.7084737947396544]
	TIME [epoch: 11.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3487802296320224		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.3487802296320224 | validation: 1.863296314659195]
	TIME [epoch: 11.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1254542445592386		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.1254542445592386 | validation: 1.5581737967496077]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9077652033172643		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.9077652033172643 | validation: 1.5821221970217685]
	TIME [epoch: 11.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6070118910062763		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.6070118910062763 | validation: 2.4670681461915747]
	TIME [epoch: 11.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2958451315632398		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.2958451315632398 | validation: 1.6594487891251561]
	TIME [epoch: 11.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8650075544169602		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.8650075544169602 | validation: 1.5173499260305818]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7836684960558475		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.7836684960558475 | validation: 2.1497269776719463]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7518561531372334		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.7518561531372334 | validation: 2.5730514319903643]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.188443058660952		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.188443058660952 | validation: 1.7928834232355473]
	TIME [epoch: 11.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6643262506059358		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.6643262506059358 | validation: 2.4976075495880576]
	TIME [epoch: 11.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8940564141006078		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.8940564141006078 | validation: 1.7070130129715175]
	TIME [epoch: 11.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7077573515579432		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.7077573515579432 | validation: 1.8041185762757799]
	TIME [epoch: 11.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9096838458426086		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.9096838458426086 | validation: 2.541285499642205]
	TIME [epoch: 11.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.000203254493426		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.000203254493426 | validation: 1.7895659202653298]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8788348471532168		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.8788348471532168 | validation: 1.4583870244387835]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7585670209913065		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.7585670209913065 | validation: 2.1250458439084223]
	TIME [epoch: 11.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.868290480121648		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.868290480121648 | validation: 1.4468768311494145]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7983132172741718		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.7983132172741718 | validation: 2.0044689233436266]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7684798932029233		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.7684798932029233 | validation: 2.4429732062560054]
	TIME [epoch: 11.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8055792987087504		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.8055792987087504 | validation: 2.2712231635245352]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7612071927200212		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.7612071927200212 | validation: 2.274681474757893]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9235466941820043		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.9235466941820043 | validation: 2.175393241359984]
	TIME [epoch: 11.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2424218351907523		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.2424218351907523 | validation: 2.0711443507960974]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7318529266540297		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.7318529266540297 | validation: 2.0698874331238137]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.879743612725533		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.879743612725533 | validation: 1.8386444838836442]
	TIME [epoch: 11.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5722636805412307		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.5722636805412307 | validation: 1.9448240486944146]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6435099059940386		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.6435099059940386 | validation: 2.4340585629314533]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9545118125852103		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.9545118125852103 | validation: 2.1919739537940464]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7354046699676784		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.7354046699676784 | validation: 1.5598423230535392]
	TIME [epoch: 11.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5894436606304119		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.5894436606304119 | validation: 1.5521397459729815]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8876332193131693		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.8876332193131693 | validation: 2.106090088347806]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7364155348025938		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.7364155348025938 | validation: 2.3173281467016227]
	TIME [epoch: 11.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9362983365381026		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.9362983365381026 | validation: 1.3982648576728554]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3894650692651989		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.3894650692651989 | validation: 2.28172801132196]
	TIME [epoch: 11.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6480475335051752		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.6480475335051752 | validation: 1.4599816154782008]
	TIME [epoch: 11.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7783181055818287		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.7783181055818287 | validation: 1.5804526706138093]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1319621758557856		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.1319621758557856 | validation: 2.1922229051815822]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8059653326683787		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.8059653326683787 | validation: 1.7270682516076175]
	TIME [epoch: 11.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.423613558579809		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.423613558579809 | validation: 1.6700791650639708]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6007392420970552		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.6007392420970552 | validation: 1.64321970834996]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1755735479903833		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.1755735479903833 | validation: 1.3094910754827467]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7527735391606178		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.7527735391606178 | validation: 1.568340056398348]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7959917859076984		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.7959917859076984 | validation: 1.3149981794041883]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0518764916307664		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.0518764916307664 | validation: 1.805059303799719]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1016853743203834		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.1016853743203834 | validation: 1.261082780216937]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2961213677081571		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.2961213677081571 | validation: 1.5241595884863954]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.70980641092418		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.70980641092418 | validation: 1.116833592702637]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3406223606431806		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.3406223606431806 | validation: 1.9092077683187654]
	TIME [epoch: 11.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7431146862837186		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.7431146862837186 | validation: 1.881061597646908]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5798312577562657		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.5798312577562657 | validation: 1.7705475124254424]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6649634451695925		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.6649634451695925 | validation: 1.138012121754718]
	TIME [epoch: 11.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.029499077816057		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.029499077816057 | validation: 1.2441257682779778]
	TIME [epoch: 11.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6411060038887217		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.6411060038887217 | validation: 1.514933615749819]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6817955398628528		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.6817955398628528 | validation: 1.7612071050695108]
	TIME [epoch: 11.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5271710423235882		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.5271710423235882 | validation: 1.5388474247981259]
	TIME [epoch: 11.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4601482279045632		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.4601482279045632 | validation: 1.6095919489594444]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5035163901885156		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.5035163901885156 | validation: 1.0473257977207748]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4058827262432996		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.4058827262432996 | validation: 1.7002965916545376]
	TIME [epoch: 11.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5690593658218557		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.5690593658218557 | validation: 1.5581761487979413]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.434990515296327		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.434990515296327 | validation: 1.0533379767899596]
	TIME [epoch: 11.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1839746682647332		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.1839746682647332 | validation: 1.736121006931636]
	TIME [epoch: 11.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2694652383768499		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.2694652383768499 | validation: 1.29364845744075]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.438826871843094		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.438826871843094 | validation: 1.6791613166234927]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.323327314893923		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.323327314893923 | validation: 1.3475015433586552]
	TIME [epoch: 11.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6487688029036573		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.6487688029036573 | validation: 1.118970331357252]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4745401538983105		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.4745401538983105 | validation: 1.3587576863819657]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4072090013996195		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.4072090013996195 | validation: 1.2602072076111828]
	TIME [epoch: 11.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2876146043258585		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.2876146043258585 | validation: 1.2241401166243207]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2185588483520422		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.2185588483520422 | validation: 1.3717894858760948]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.541415529061361		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.541415529061361 | validation: 1.5768552560374023]
	TIME [epoch: 11.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3880437419978844		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.3880437419978844 | validation: 1.0326990752480072]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.280908761495434		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.280908761495434 | validation: 1.0137163748261964]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3480474116435182		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.3480474116435182 | validation: 1.6963377629820229]
	TIME [epoch: 11.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4994832036611645		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.4994832036611645 | validation: 1.42423156314803]
	TIME [epoch: 11.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2594196338270338		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.2594196338270338 | validation: 1.165880461429973]
	TIME [epoch: 11.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7673920129059124		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.7673920129059124 | validation: 1.0524570621374587]
	TIME [epoch: 11.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0036239472427875		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.0036239472427875 | validation: 1.047104850995193]
	TIME [epoch: 11.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1841489852707718		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.1841489852707718 | validation: 1.9135485046972978]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.443112877653116		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.443112877653116 | validation: 1.757902090993968]
	TIME [epoch: 11.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2259369343830713		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.2259369343830713 | validation: 0.8829690941904804]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1129786675766509		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.1129786675766509 | validation: 1.7861410369673347]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3948360032522842		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.3948360032522842 | validation: 2.6802007025224963]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7261379579911262		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.7261379579911262 | validation: 0.9012010027719762]
	TIME [epoch: 11.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1037771857929868		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.1037771857929868 | validation: 1.58747971058838]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0818444015797533		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.0818444015797533 | validation: 1.8854478573562512]
	TIME [epoch: 11.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0992129042809913		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.0992129042809913 | validation: 0.8782921668162897]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2970535308698719		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.2970535308698719 | validation: 1.4615636663124776]
	TIME [epoch: 11.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3116792119164067		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.3116792119164067 | validation: 1.482853899951277]
	TIME [epoch: 11.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1545831558791677		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.1545831558791677 | validation: 1.0804842408719644]
	TIME [epoch: 11.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4246154036062428		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.4246154036062428 | validation: 1.069842648277232]
	TIME [epoch: 11.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.111982967868347		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.111982967868347 | validation: 1.131665700048907]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9156425725901738		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.9156425725901738 | validation: 1.7566169735975485]
	TIME [epoch: 11.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3964726724342746		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.3964726724342746 | validation: 1.2573576359517242]
	TIME [epoch: 11.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2416957721510593		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.2416957721510593 | validation: 0.7094523296675717]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5847171526659927		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.5847171526659927 | validation: 1.1926757635239422]
	TIME [epoch: 11.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1510592327723084		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.1510592327723084 | validation: 1.7214702330048475]
	TIME [epoch: 11.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.402691255595005		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.402691255595005 | validation: 1.496988742057636]
	TIME [epoch: 11.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5967995885982336		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.5967995885982336 | validation: 1.3167298227142852]
	TIME [epoch: 11.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0794043296982405		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.0794043296982405 | validation: 1.1395747226389903]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7533624416706788		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.7533624416706788 | validation: 1.4094293203656685]
	TIME [epoch: 11.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063243821171921		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.063243821171921 | validation: 1.1002484546465467]
	TIME [epoch: 11.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5194056212415021		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.5194056212415021 | validation: 1.1630456450739197]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3467763903141639		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.3467763903141639 | validation: 0.8354028378100727]
	TIME [epoch: 11.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8373692139930131		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.8373692139930131 | validation: 1.1026738129568343]
	TIME [epoch: 11.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1649097803299635		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.1649097803299635 | validation: 0.9195988240884954]
	TIME [epoch: 11.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.035695111034733		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.035695111034733 | validation: 0.9045555279730049]
	TIME [epoch: 11.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9717974109506728		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.9717974109506728 | validation: 1.022540596317024]
	TIME [epoch: 11.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2030215747070083		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.2030215747070083 | validation: 0.8625672374471816]
	TIME [epoch: 11.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1020292292745262		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.1020292292745262 | validation: 1.015546811598926]
	TIME [epoch: 11.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0028221185879553		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.0028221185879553 | validation: 0.7367713377734724]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.518694632724742		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.518694632724742 | validation: 1.7396949066588554]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0629126563030837		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.0629126563030837 | validation: 0.9345954278107965]
	TIME [epoch: 11.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4750585380399688		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.4750585380399688 | validation: 1.4928709002951104]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4794556368224128		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.4794556368224128 | validation: 1.0452386595972847]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.165543450875371		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.165543450875371 | validation: 0.9477733706313068]
	TIME [epoch: 11.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2373302687270096		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.2373302687270096 | validation: 1.8716106149414706]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.48268958206284		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.48268958206284 | validation: 1.6382747100511756]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3235853314854213		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.3235853314854213 | validation: 1.1003832471555788]
	TIME [epoch: 11.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9678766409068333		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.9678766409068333 | validation: 1.0359786139616791]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0025391353466981		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.0025391353466981 | validation: 1.2089129179837772]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0934812551484436		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.0934812551484436 | validation: 1.1894421690693853]
	TIME [epoch: 11.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0749039210764622		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.0749039210764622 | validation: 0.6992796969311098]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0268850209041949		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.0268850209041949 | validation: 1.5948579290607194]
	TIME [epoch: 11.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3238369154141711		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.3238369154141711 | validation: 1.4520412322733551]
	TIME [epoch: 11.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.164032060308713		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.164032060308713 | validation: 1.2717053681067036]
	TIME [epoch: 11.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0813469287448811		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.0813469287448811 | validation: 0.758372299800379]
	TIME [epoch: 11.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9661807764664128		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.9661807764664128 | validation: 0.9005246582005444]
	TIME [epoch: 11.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8495504545051418		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.8495504545051418 | validation: 0.6461358817351922]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.79757153086251		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.79757153086251 | validation: 1.2107891922030796]
	TIME [epoch: 11.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3135281217999553		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.3135281217999553 | validation: 1.8769404406317474]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2540125806770877		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.2540125806770877 | validation: 1.3381005001426933]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9734890506491971		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.9734890506491971 | validation: 0.840583400406359]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0646838399258856		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.0646838399258856 | validation: 0.8272277716814831]
	TIME [epoch: 11.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2952320643966733		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.2952320643966733 | validation: 0.8473037051641004]
	TIME [epoch: 11.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9797670535219369		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.9797670535219369 | validation: 1.7051486722416893]
	TIME [epoch: 11.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2650431719583957		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.2650431719583957 | validation: 1.229054070697198]
	TIME [epoch: 11.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0515049340168234		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.0515049340168234 | validation: 0.7451807255070985]
	TIME [epoch: 11.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.147487785089926		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.147487785089926 | validation: 0.8112245065825855]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8766361499922415		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.8766361499922415 | validation: 0.7587728842359269]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9838097423988534		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.9838097423988534 | validation: 0.9506325641310752]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9542713071080997		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.9542713071080997 | validation: 0.9081696095323811]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9909139368463034		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.9909139368463034 | validation: 0.907179962775315]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8265483922976654		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.8265483922976654 | validation: 1.1667834454921684]
	TIME [epoch: 11.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.094690846826291		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.094690846826291 | validation: 1.045200229707156]
	TIME [epoch: 11.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9942853476416995		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.9942853476416995 | validation: 1.0613182335959184]
	TIME [epoch: 11.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082087910289556		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.082087910289556 | validation: 0.9052682850050572]
	TIME [epoch: 11.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8046659950793678		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.8046659950793678 | validation: 1.0172414700050232]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9258080592053481		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.9258080592053481 | validation: 1.115686680654074]
	TIME [epoch: 11.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9877981182966478		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.9877981182966478 | validation: 1.2325655470323853]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.049871146338409		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.049871146338409 | validation: 0.989145489986297]
	TIME [epoch: 11.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9399429762757084		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.9399429762757084 | validation: 0.9672829786397827]
	TIME [epoch: 11.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0902399050912495		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.0902399050912495 | validation: 0.9426979784099087]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1561071928732827		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.1561071928732827 | validation: 0.7646739948439205]
	TIME [epoch: 11.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9499612172685453		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.9499612172685453 | validation: 0.6097077495507711]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7115508847805078		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.7115508847805078 | validation: 1.0296466434739886]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9713318446830337		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.9713318446830337 | validation: 1.5610187906681097]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9909591555834897		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.9909591555834897 | validation: 0.6933329535438217]
	TIME [epoch: 11.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9775087883112115		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.9775087883112115 | validation: 0.5521784660983197]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1718190237178048		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.1718190237178048 | validation: 1.053165362451156]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.90717805917881		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.90717805917881 | validation: 0.7721242856444039]
	TIME [epoch: 11.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9121276841076387		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.9121276841076387 | validation: 0.7859030116959447]
	TIME [epoch: 11.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6122008056428832		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.6122008056428832 | validation: 0.8412178326166435]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0989371237810324		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.0989371237810324 | validation: 0.6943611173257047]
	TIME [epoch: 11.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8272167408036565		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.8272167408036565 | validation: 0.8341840518782848]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8335045017920751		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.8335045017920751 | validation: 1.2988853503453675]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0716124817985322		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.0716124817985322 | validation: 0.6813463068378142]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2137005141135049		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.2137005141135049 | validation: 0.7772281649579458]
	TIME [epoch: 11.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7651408754857698		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.7651408754857698 | validation: 0.9325886924287393]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1033335933183566		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.1033335933183566 | validation: 1.2826986186173412]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9921698730343045		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.9921698730343045 | validation: 0.6755523885748519]
	TIME [epoch: 11.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7647419929859185		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.7647419929859185 | validation: 1.1627731269864447]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9111741157072767		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.9111741157072767 | validation: 1.1439055143762082]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7418039396046294		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.7418039396046294 | validation: 0.8029106645345297]
	TIME [epoch: 11.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7329947624509114		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.7329947624509114 | validation: 0.7453310022043047]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9147547281568993		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.9147547281568993 | validation: 1.1810307602961019]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7822298294521388		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.7822298294521388 | validation: 0.6313217911938823]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0026680858026555		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.0026680858026555 | validation: 1.0620956761793516]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9490975579599373		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.9490975579599373 | validation: 0.6326818006816973]
	TIME [epoch: 11.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1961781004714789		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.1961781004714789 | validation: 0.9732854967395886]
	TIME [epoch: 11.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8770610297122757		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.8770610297122757 | validation: 0.6837233403804797]
	TIME [epoch: 11.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7473127840349086		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7473127840349086 | validation: 0.9709445425532495]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1512496968784125		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.1512496968784125 | validation: 0.8286347819350601]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9705143465499013		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.9705143465499013 | validation: 1.2974991939383902]
	TIME [epoch: 11.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8862049041626984		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.8862049041626984 | validation: 0.8133016454476316]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0128041240132966		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.0128041240132966 | validation: 1.1521988217106087]
	TIME [epoch: 11.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.186266580305847		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.186266580305847 | validation: 0.8677596765354622]
	TIME [epoch: 11.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8706026546166813		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.8706026546166813 | validation: 1.0468957708036823]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.911116115183044		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.911116115183044 | validation: 0.983443532265102]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7848158108893653		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.7848158108893653 | validation: 0.9449350453089368]
	TIME [epoch: 11.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8796868008560792		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.8796868008560792 | validation: 0.7099493393693891]
	TIME [epoch: 11.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8770905852397305		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.8770905852397305 | validation: 0.7903142544290723]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7564907484857935		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.7564907484857935 | validation: 0.6799957236379252]
	TIME [epoch: 11.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.889116352027562		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.889116352027562 | validation: 0.9037311984054276]
	TIME [epoch: 11.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0771353287437284		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.0771353287437284 | validation: 0.5258835848295378]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0077884294054875		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.0077884294054875 | validation: 0.7886138738738881]
	TIME [epoch: 11.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9752392319772643		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.9752392319772643 | validation: 0.8800878090901282]
	TIME [epoch: 11.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7770916716323779		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.7770916716323779 | validation: 0.6970597466395577]
	TIME [epoch: 11.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8826580817228095		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.8826580817228095 | validation: 0.7373044611356413]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9888031842461747		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.9888031842461747 | validation: 0.8154396628151713]
	TIME [epoch: 11.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7891651915397333		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.7891651915397333 | validation: 1.3567333842587488]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8446457665801985		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.8446457665801985 | validation: 0.6050685638273017]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9075466619582218		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.9075466619582218 | validation: 1.075705097322647]
	TIME [epoch: 11.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0447337862548152		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.0447337862548152 | validation: 0.8361634366855134]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9205514036761868		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.9205514036761868 | validation: 0.7665152385257185]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7367948667735059		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.7367948667735059 | validation: 0.8221251277764067]
	TIME [epoch: 11.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8080688920199176		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.8080688920199176 | validation: 0.6443341197521049]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8865076987773588		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.8865076987773588 | validation: 0.8904825852796563]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.829269372710868		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.829269372710868 | validation: 1.5091512037930388]
	TIME [epoch: 11.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9539589353507177		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.9539589353507177 | validation: 0.7416170722595766]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7547392599069168		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7547392599069168 | validation: 0.6745307561976204]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9045209376471255		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.9045209376471255 | validation: 0.784459576643459]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9147539212856369		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.9147539212856369 | validation: 0.9349892860323925]
	TIME [epoch: 11.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8709777069967557		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.8709777069967557 | validation: 0.6966389792902838]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680767055347329		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.680767055347329 | validation: 1.0771802825826167]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9350683255469894		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.9350683255469894 | validation: 0.6181960096485013]
	TIME [epoch: 11.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7417980518849894		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.7417980518849894 | validation: 2.1903406103411744]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2159561405623462		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.2159561405623462 | validation: 0.6457343908793189]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7819693421179601		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.7819693421179601 | validation: 0.5579724086595885]
	TIME [epoch: 11.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6109146694841475		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.6109146694841475 | validation: 0.7344393517828474]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7833196791826245		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.7833196791826245 | validation: 1.4985773521942327]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0682942087879177		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.0682942087879177 | validation: 0.589812597875349]
	TIME [epoch: 11.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7021793027261849		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.7021793027261849 | validation: 0.7374034692250774]
	TIME [epoch: 11.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7381212193510165		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.7381212193510165 | validation: 0.7042769046032128]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7148693405763523		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.7148693405763523 | validation: 0.5927858392914778]
	TIME [epoch: 11.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6799139890738908		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.6799139890738908 | validation: 0.7654116283366688]
	TIME [epoch: 11.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7953749378131942		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.7953749378131942 | validation: 0.6355087060350807]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6904960963736464		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.6904960963736464 | validation: 0.6368167858069009]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6656226468540317		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.6656226468540317 | validation: 0.5815251334300008]
	TIME [epoch: 11.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8411704446471523		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.8411704446471523 | validation: 1.2262272638994984]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7644774347745864		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.7644774347745864 | validation: 0.8477890241136925]
	TIME [epoch: 11.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7531522444545858		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.7531522444545858 | validation: 0.8586787161337378]
	TIME [epoch: 11.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683606981678576		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.683606981678576 | validation: 0.7108308571071951]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8148588019659039		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.8148588019659039 | validation: 0.6452423629553452]
	TIME [epoch: 11.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.750064146860131		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.750064146860131 | validation: 0.5448406628185213]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9060840712472473		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.9060840712472473 | validation: 0.9180130502441951]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6319329379643628		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.6319329379643628 | validation: 0.5645543437601421]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.611022368912395		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.611022368912395 | validation: 0.8331829907709846]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6595804442567846		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.6595804442567846 | validation: 0.3942885879854132]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5310464034649226		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.5310464034649226 | validation: 0.5755901887201879]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810244190913414		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5810244190913414 | validation: 0.8688074053571357]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8936656358574607		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.8936656358574607 | validation: 0.5386058438789983]
	TIME [epoch: 11.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5361319538084244		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5361319538084244 | validation: 0.7137687938204951]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8421264757307715		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.8421264757307715 | validation: 0.9808339557239486]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1702646877104912		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.1702646877104912 | validation: 0.530207068769017]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6421227193203468		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.6421227193203468 | validation: 0.48334501373939537]
	TIME [epoch: 11.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6433821050119584		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.6433821050119584 | validation: 0.49821499122185686]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6814451672609544		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.6814451672609544 | validation: 0.8572878730357417]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7063995971839545		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.7063995971839545 | validation: 0.4284734008113399]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6420764324053778		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6420764324053778 | validation: 0.7767430902914747]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7008391804946854		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.7008391804946854 | validation: 0.8651203463619201]
	TIME [epoch: 11.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831313059315895		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.6831313059315895 | validation: 0.7162851331484401]
	TIME [epoch: 11.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7159583864181946		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.7159583864181946 | validation: 0.618570251260095]
	TIME [epoch: 11.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5689482247726262		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.5689482247726262 | validation: 1.1134984703075008]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6910982063466822		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.6910982063466822 | validation: 0.6358887375069298]
	TIME [epoch: 11.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7776037801072073		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.7776037801072073 | validation: 0.5562851518831852]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.996163632388209		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.996163632388209 | validation: 1.2883819156764862]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9958612554971036		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.9958612554971036 | validation: 0.8023959925560228]
	TIME [epoch: 11.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7264992394337415		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.7264992394337415 | validation: 0.7317186721990029]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220031887400062		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.7220031887400062 | validation: 0.5288228711325226]
	TIME [epoch: 11.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6978818550184964		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.6978818550184964 | validation: 0.5775494737040084]
	TIME [epoch: 11.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5764013178115345		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.5764013178115345 | validation: 0.5254276094362086]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6163921193563691		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.6163921193563691 | validation: 0.5353468940061068]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5944677543255483		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.5944677543255483 | validation: 0.5084037381803002]
	TIME [epoch: 11.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028360320613185		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.028360320613185 | validation: 0.5092348039244108]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7681860126368786		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7681860126368786 | validation: 0.4888235490001175]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6554496783970308		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.6554496783970308 | validation: 1.0935810519944096]
	TIME [epoch: 11.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6551872557477321		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.6551872557477321 | validation: 0.749995222191925]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8901231791121831		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.8901231791121831 | validation: 0.7010141638569641]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215906697168559		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.7215906697168559 | validation: 0.592238309878947]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.615884344353621		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.615884344353621 | validation: 0.7908964224306931]
	TIME [epoch: 11.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8319894993272927		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.8319894993272927 | validation: 0.6812387694819921]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7418248261073395		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.7418248261073395 | validation: 0.6040257611436296]
	TIME [epoch: 11.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6772516015437076		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.6772516015437076 | validation: 0.5904696572997701]
	TIME [epoch: 11.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5039258800611685		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.5039258800611685 | validation: 0.43498627786834365]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757220705895094		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5757220705895094 | validation: 0.5784854200873885]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5575125893213216		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.5575125893213216 | validation: 0.43928621400070983]
	TIME [epoch: 11.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6351030508813684		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.6351030508813684 | validation: 0.5677123428623271]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6282840755015923		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.6282840755015923 | validation: 0.5269800996962675]
	TIME [epoch: 11.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5834489135055754		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.5834489135055754 | validation: 0.6855343948128281]
	TIME [epoch: 11.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.960514299209885		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.960514299209885 | validation: 0.6325761512036051]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888948167717565		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.6888948167717565 | validation: 0.43080630889755744]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5012130103640051		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.5012130103640051 | validation: 0.4615816446840148]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5837558718512721		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5837558718512721 | validation: 0.6236073654934915]
	TIME [epoch: 11.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5365416972997658		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.5365416972997658 | validation: 0.6697767826111148]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6074941868120678		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.6074941868120678 | validation: 0.8735658922251844]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7464288616739024		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.7464288616739024 | validation: 1.240063228028237]
	TIME [epoch: 11.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.833064047780221		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.833064047780221 | validation: 0.8762086257836245]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834063511817063		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.6834063511817063 | validation: 1.7372960076446642]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1468125150136328		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.1468125150136328 | validation: 0.6522080701728982]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5447308272202693		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.5447308272202693 | validation: 1.1265917253679083]
	TIME [epoch: 11.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9345453372381533		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.9345453372381533 | validation: 0.7400261810098842]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7467960799860833		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.7467960799860833 | validation: 0.5061581361934432]
	TIME [epoch: 11.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8647352155303344		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.8647352155303344 | validation: 0.8788240848916391]
	TIME [epoch: 11.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6743480331341283		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.6743480331341283 | validation: 1.11565198941377]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7107585024460298		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.7107585024460298 | validation: 0.5548423570590044]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5981203796735122		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5981203796735122 | validation: 0.586291709363343]
	TIME [epoch: 11.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6065397153440797		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.6065397153440797 | validation: 0.659172517034693]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.576474707529783		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.576474707529783 | validation: 0.8411197986657285]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7527415582886665		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.7527415582886665 | validation: 0.6656429012092716]
	TIME [epoch: 11.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8740777249435966		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.8740777249435966 | validation: 0.8023202504377116]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7088390069034862		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.7088390069034862 | validation: 0.6016678936508385]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6030391088674805		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.6030391088674805 | validation: 0.9330099438421721]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236754356075594		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.7236754356075594 | validation: 0.45891578367642555]
	TIME [epoch: 11.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6552828375223567		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.6552828375223567 | validation: 0.6917074869732005]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5567863938710791		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.5567863938710791 | validation: 0.5835867855479347]
	TIME [epoch: 11.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.665645868190176		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.665645868190176 | validation: 0.6092549358208947]
	TIME [epoch: 11.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5802839538714493		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.5802839538714493 | validation: 0.4849646199895109]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6092597133475802		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.6092597133475802 | validation: 0.8298502155782643]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8964235988170921		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.8964235988170921 | validation: 1.0907674982235054]
	TIME [epoch: 11.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7065408652414131		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.7065408652414131 | validation: 0.6522996409994865]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963825480118438		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.6963825480118438 | validation: 0.5887330947842416]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5774514841353829		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.5774514841353829 | validation: 0.682877113146909]
	TIME [epoch: 11.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.560921390045862		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.560921390045862 | validation: 0.5841970143086985]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5331647255550077		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.5331647255550077 | validation: 0.6016478155410944]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5402673373286097		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.5402673373286097 | validation: 0.5741347606023894]
	TIME [epoch: 11.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136683937275468		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.5136683937275468 | validation: 0.6437390120419461]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6279343022190444		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.6279343022190444 | validation: 0.6209874695433538]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5465071708326392		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.5465071708326392 | validation: 1.1721773117965941]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7698704740243246		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.7698704740243246 | validation: 1.0469074565724028]
	TIME [epoch: 11.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7655520988218251		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.7655520988218251 | validation: 0.5534510013170676]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171210322859719		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.7171210322859719 | validation: 0.5485206315317319]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6163030908348318		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.6163030908348318 | validation: 0.4941463226128262]
	TIME [epoch: 11.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5759501224398187		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.5759501224398187 | validation: 0.5611333762121896]
	TIME [epoch: 11.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033781526361393		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.5033781526361393 | validation: 0.6238440711258807]
	TIME [epoch: 11.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5888547094432126		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.5888547094432126 | validation: 0.7605354123763358]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5718816094356551		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.5718816094356551 | validation: 0.43242296035547856]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9947254773662111		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.9947254773662111 | validation: 0.48632883384397213]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6326688339466503		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.6326688339466503 | validation: 0.5357308533664279]
	TIME [epoch: 11.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5820038594111121		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.5820038594111121 | validation: 0.9511798794094256]
	TIME [epoch: 11.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866293652806406		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.6866293652806406 | validation: 0.7505912876247203]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5907547717693106		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.5907547717693106 | validation: 0.8776953106520446]
	TIME [epoch: 11.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9022006251218333		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.9022006251218333 | validation: 0.5940187943809229]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.566058462947196		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.566058462947196 | validation: 0.39545048715645265]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4191003803778276		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.4191003803778276 | validation: 0.6385650478570593]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.514280406758093		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.514280406758093 | validation: 0.6966140355720046]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210309310807232		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.7210309310807232 | validation: 0.4791380485096671]
	TIME [epoch: 11.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8538835966677972		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.8538835966677972 | validation: 0.5449882725786389]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5949073896255321		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.5949073896255321 | validation: 0.45331109924631674]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5789403997070193		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5789403997070193 | validation: 0.46419518986189334]
	TIME [epoch: 11.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6423204977658485		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.6423204977658485 | validation: 0.580542906066912]
	TIME [epoch: 11.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5854794542480094		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.5854794542480094 | validation: 0.5051967065579559]
	TIME [epoch: 11.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6211845313071497		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.6211845313071497 | validation: 0.6247308766175178]
	TIME [epoch: 11.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757961339196733		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.5757961339196733 | validation: 0.8375431843438312]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.607883783002185		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.607883783002185 | validation: 0.6395637814486289]
	TIME [epoch: 11.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3801269561125245		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.3801269561125245 | validation: 1.0895418804905352]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7959386283506394		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.7959386283506394 | validation: 0.450573474339802]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5389419754967565		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.5389419754967565 | validation: 0.8032291468550693]
	TIME [epoch: 11.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7623379393392764		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.7623379393392764 | validation: 0.512157248241538]
	TIME [epoch: 11.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6180915868502077		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.6180915868502077 | validation: 0.5481639909608707]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46466112621874217		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.46466112621874217 | validation: 0.5067413640213125]
	TIME [epoch: 11.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4843225460889268		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.4843225460889268 | validation: 0.4301417518836863]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5762407460592646		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.5762407460592646 | validation: 0.46193266574362424]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.604475827834211		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.604475827834211 | validation: 1.0933841755175018]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8725561230858132		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.8725561230858132 | validation: 0.6962553795163317]
	TIME [epoch: 11.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377293281978932		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.5377293281978932 | validation: 0.7596452343789777]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5214493272450361		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.5214493272450361 | validation: 0.4412459366574251]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5780527407682634		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.5780527407682634 | validation: 0.5776159883794414]
	TIME [epoch: 11.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807363754545677		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.6807363754545677 | validation: 0.41617083223412]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5482159170911914		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.5482159170911914 | validation: 1.279717923675352]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289604573633339		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.7289604573633339 | validation: 0.7202420638224264]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7182490594734342		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.7182490594734342 | validation: 0.6811761769343438]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5313906597283607		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.5313906597283607 | validation: 0.4081577076403174]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4330509353087434		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.4330509353087434 | validation: 0.37616219916435617]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6161282126785613		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.6161282126785613 | validation: 0.4099306187222935]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.677293729040679		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.677293729040679 | validation: 0.46910750249602035]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4814165597805756		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.4814165597805756 | validation: 0.8623913536704045]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.581536120193607		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.581536120193607 | validation: 0.7138133427158617]
	TIME [epoch: 11.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7378555196655795		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.7378555196655795 | validation: 0.4468613410341527]
	TIME [epoch: 11.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47564569451165917		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.47564569451165917 | validation: 0.40283415105042863]
	TIME [epoch: 11.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220312576489265		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.6220312576489265 | validation: 0.5315362057376544]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5813184749436255		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.5813184749436255 | validation: 0.42665209739803667]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5836298173900307		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.5836298173900307 | validation: 0.4977131901635561]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5547392813931254		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5547392813931254 | validation: 0.4527597348648898]
	TIME [epoch: 11.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5738705000399493		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.5738705000399493 | validation: 0.5679261717727817]
	TIME [epoch: 11.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4962272005623164		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.4962272005623164 | validation: 0.46023176194520415]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49059336189003583		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.49059336189003583 | validation: 0.3653888554376462]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_448.pth
	Model improved!!!
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5386096453863306		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.5386096453863306 | validation: 0.43790362523111354]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6640439341951133		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.6640439341951133 | validation: 0.6341717540041979]
	TIME [epoch: 11.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5979372564472745		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.5979372564472745 | validation: 0.6271456011138814]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6610185365555861		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.6610185365555861 | validation: 0.44042038449814563]
	TIME [epoch: 11.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4211118384729767		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.4211118384729767 | validation: 0.5907099003314911]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6442115434929674		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.6442115434929674 | validation: 0.4249713347639342]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5048726222955471		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.5048726222955471 | validation: 0.5287839648480152]
	TIME [epoch: 11.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5099104257042053		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.5099104257042053 | validation: 0.4477203447199831]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5089621852333908		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.5089621852333908 | validation: 0.8037695480854475]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6113951135673489		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.6113951135673489 | validation: 0.39667798409660926]
	TIME [epoch: 11.6 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5212566742577673		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.5212566742577673 | validation: 0.4035675757127978]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5954330265896932		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.5954330265896932 | validation: 0.43315853450007397]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4205051166122674		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.4205051166122674 | validation: 0.44742344182170984]
	TIME [epoch: 11.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4134074039871065		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.4134074039871065 | validation: 0.8495799094749703]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5752517958028505		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.5752517958028505 | validation: 0.6003699692467357]
	TIME [epoch: 11.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.677560392364168		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.677560392364168 | validation: 0.5075178056209714]
	TIME [epoch: 11.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5156333924414572		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.5156333924414572 | validation: 0.42654213811036895]
	TIME [epoch: 11.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3923150141300459		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.3923150141300459 | validation: 0.5606506816955883]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5336241693300399		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.5336241693300399 | validation: 0.7142266955568897]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5015687359498986		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.5015687359498986 | validation: 0.40089836474696733]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.477508012572298		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.477508012572298 | validation: 0.9053335224941467]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6132182876728044		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.6132182876728044 | validation: 0.48151762389197855]
	TIME [epoch: 11.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6450691726617652		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.6450691726617652 | validation: 0.3476780751748633]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6240196415743396		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.6240196415743396 | validation: 0.3662271442255352]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5493835069460355		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.5493835069460355 | validation: 0.47615853882557263]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4995625906600294		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.4995625906600294 | validation: 0.7323133711151223]
	TIME [epoch: 11.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4967774371106153		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.4967774371106153 | validation: 0.5129454783508012]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.605760997581182		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.605760997581182 | validation: 0.43952474502770955]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4803104174479153		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.4803104174479153 | validation: 0.5272178185776253]
	TIME [epoch: 11.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5917396449971268		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.5917396449971268 | validation: 0.3571053691632444]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6201172058322483		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.6201172058322483 | validation: 0.38209476529600567]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5850123574604793		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.5850123574604793 | validation: 0.6731711872332622]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5682250724511961		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.5682250724511961 | validation: 0.5817092266925559]
	TIME [epoch: 11.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.528062157621715		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.528062157621715 | validation: 0.3951500876059148]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419081933514076		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.4419081933514076 | validation: 0.3716388410845049]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4375942492482745		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.4375942492482745 | validation: 0.5027470739507591]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7900478255207969		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.7900478255207969 | validation: 0.5557113413601917]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6074160981132892		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.6074160981132892 | validation: 0.33784880246806104]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_486.pth
	Model improved!!!
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43356668103231144		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.43356668103231144 | validation: 0.5201049904872541]
	TIME [epoch: 11.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396031753142152		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.5396031753142152 | validation: 0.43840974547822475]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45680432745656985		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.45680432745656985 | validation: 0.8702270702136363]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.668815368761956		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.668815368761956 | validation: 0.43586691445095205]
	TIME [epoch: 11.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4208795425606272		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.4208795425606272 | validation: 0.47860967604311255]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44673701793607334		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.44673701793607334 | validation: 0.5010222570732182]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5637418425819705		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.5637418425819705 | validation: 0.6680944084301963]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.61132103107134		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.61132103107134 | validation: 0.4862222580808134]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43253849284216694		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.43253849284216694 | validation: 0.3917460305123104]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5389388572610241		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.5389388572610241 | validation: 0.3918144508045247]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5436670096570295		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.5436670096570295 | validation: 0.47190593933817176]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4887284314381327		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.4887284314381327 | validation: 0.4861617080195017]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5166098039198271		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.5166098039198271 | validation: 0.4761283892784378]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5244489073657115		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.5244489073657115 | validation: 0.3480112893315051]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3484975012809364		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.3484975012809364 | validation: 0.3772019433834234]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.404326474579428		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.404326474579428 | validation: 0.3769741587776339]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45321252491739994		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.45321252491739994 | validation: 0.3297463300756507]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_503.pth
	Model improved!!!
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39250528394331347		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.39250528394331347 | validation: 0.6826342843888957]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072788582995789		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.5072788582995789 | validation: 0.5566818978416965]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44131524664270044		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.44131524664270044 | validation: 0.8042028910411]
	TIME [epoch: 11.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5918516556250136		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.5918516556250136 | validation: 0.9349744255529732]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.57665864995999		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.57665864995999 | validation: 0.4306009722550197]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46987330723281817		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.46987330723281817 | validation: 0.485482959475913]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4766423333620904		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.4766423333620904 | validation: 0.5254808163133663]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5358885517488458		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.5358885517488458 | validation: 0.4592487210520037]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5470942743388365		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.5470942743388365 | validation: 0.6042054549217459]
	TIME [epoch: 11.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4635422947852743		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.4635422947852743 | validation: 0.39479848825521613]
	TIME [epoch: 11.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5134773235753922		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.5134773235753922 | validation: 0.2931323211946006]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_514.pth
	Model improved!!!
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4300002071020209		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.4300002071020209 | validation: 0.43496499381216214]
	TIME [epoch: 11.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48706530823355		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.48706530823355 | validation: 0.42683423395248143]
	TIME [epoch: 11.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5060654907199826		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.5060654907199826 | validation: 0.5704066801312714]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5205335942058128		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.5205335942058128 | validation: 0.5607068199189617]
	TIME [epoch: 11.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48595338191160314		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.48595338191160314 | validation: 0.554885062988782]
	TIME [epoch: 11.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48152270574705025		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.48152270574705025 | validation: 0.5043463960979496]
	TIME [epoch: 11.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5554099440084836		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.5554099440084836 | validation: 0.4878825142040286]
	TIME [epoch: 11.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44092199533658655		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.44092199533658655 | validation: 0.5475085706089398]
	TIME [epoch: 11.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47938526902911505		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.47938526902911505 | validation: 0.42148720691839087]
	TIME [epoch: 11.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43262637964496803		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.43262637964496803 | validation: 0.3887175776410943]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40773561278035886		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.40773561278035886 | validation: 0.4562769425152648]
	TIME [epoch: 11.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44126851334540534		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.44126851334540534 | validation: 0.3868974650094388]
	TIME [epoch: 11.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47010044497842746		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.47010044497842746 | validation: 0.3351772186169811]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44254888817347116		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.44254888817347116 | validation: 0.6431430315932769]
	TIME [epoch: 11.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6064965662148596		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.6064965662148596 | validation: 0.6131096587823964]
	TIME [epoch: 11.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5005849576461282		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.5005849576461282 | validation: 0.463904972501965]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42965061714605274		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.42965061714605274 | validation: 0.38610520785221125]
	TIME [epoch: 11.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5067039117129034		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.5067039117129034 | validation: 0.4473268913238995]
	TIME [epoch: 11.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4417160775176239		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.4417160775176239 | validation: 0.44294083206838636]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41273099553091347		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.41273099553091347 | validation: 0.3696076246885402]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3727850853330399		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.3727850853330399 | validation: 0.573614299909746]
	TIME [epoch: 11.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5615025403200538		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.5615025403200538 | validation: 0.39177389793288386]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44128456963494034		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.44128456963494034 | validation: 0.5286785194633342]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46267309961125214		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.46267309961125214 | validation: 0.3975913147854635]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4428927284269795		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.4428927284269795 | validation: 0.4061199263791524]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4427893462591732		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.4427893462591732 | validation: 0.43744722899850164]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47267752565507704		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.47267752565507704 | validation: 0.543329742575985]
	TIME [epoch: 11.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4180514606211856		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.4180514606211856 | validation: 0.32326761810110444]
	TIME [epoch: 11.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45792589148833107		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.45792589148833107 | validation: 0.5543609498810335]
	TIME [epoch: 11.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47724021613056733		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.47724021613056733 | validation: 0.4392827428373438]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46002880943100266		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.46002880943100266 | validation: 0.38092083977218766]
	TIME [epoch: 11.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301826915346701		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.5301826915346701 | validation: 0.33376939141593087]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47653470403644527		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.47653470403644527 | validation: 0.5204436835748851]
	TIME [epoch: 11.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5017507983537917		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.5017507983537917 | validation: 0.3105958243488503]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35574691930743124		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.35574691930743124 | validation: 0.388901683884134]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42847097279581436		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.42847097279581436 | validation: 0.45025299970652904]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40284150546420394		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.40284150546420394 | validation: 0.45482521404563364]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4716605039141471		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.4716605039141471 | validation: 0.5425986062360584]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4672894816181677		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.4672894816181677 | validation: 0.5060375681253458]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44337115552768414		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.44337115552768414 | validation: 0.3740202592880495]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38669699622035647		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.38669699622035647 | validation: 0.42723229423840636]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4164490587445841		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.4164490587445841 | validation: 0.3518104625592388]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35376351172014464		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.35376351172014464 | validation: 0.29108354982739265]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_557.pth
	Model improved!!!
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5277160642675653		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.5277160642675653 | validation: 0.5392956570774677]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.494980287481543		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.494980287481543 | validation: 1.0133503724538655]
	TIME [epoch: 11.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6219500795704612		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.6219500795704612 | validation: 0.3095243929268825]
	TIME [epoch: 11.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38608556284692563		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.38608556284692563 | validation: 0.33986980873397415]
	TIME [epoch: 11.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3928844271158147		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.3928844271158147 | validation: 0.3516211733965171]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5637855584183605		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.5637855584183605 | validation: 0.3819301512804249]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5300201938777321		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.5300201938777321 | validation: 0.3649100861379677]
	TIME [epoch: 11.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3863554464676907		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.3863554464676907 | validation: 0.5074178832130825]
	TIME [epoch: 11.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049681836763552		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.5049681836763552 | validation: 0.3905677299691846]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41180498095855955		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.41180498095855955 | validation: 0.3455051975147158]
	TIME [epoch: 11.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38742817207144753		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.38742817207144753 | validation: 0.5700290069305607]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6539363683755559		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.6539363683755559 | validation: 0.8158137797026109]
	TIME [epoch: 11.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5735899834349848		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.5735899834349848 | validation: 0.35271920141363083]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6020232069946443		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.6020232069946443 | validation: 0.6148221170429085]
	TIME [epoch: 11.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4496230669809115		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.4496230669809115 | validation: 0.3630628539795551]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45813163212323593		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.45813163212323593 | validation: 0.4342554017650525]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4082284071128575		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.4082284071128575 | validation: 0.4473674363645759]
	TIME [epoch: 11.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42479687420547096		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.42479687420547096 | validation: 0.5587399447756434]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5216622603582945		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.5216622603582945 | validation: 0.42983258676908415]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44961291422688604		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.44961291422688604 | validation: 0.5101783872176969]
	TIME [epoch: 11.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42415976434503305		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.42415976434503305 | validation: 0.3846859011047181]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860028399605262		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.3860028399605262 | validation: 0.558742233146736]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45934035815817453		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.45934035815817453 | validation: 0.6287283966384108]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107946973975834		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.5107946973975834 | validation: 0.4365891806969265]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41860343127400346		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.41860343127400346 | validation: 0.40205542176943043]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3946053548571763		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.3946053548571763 | validation: 0.659541279294198]
	TIME [epoch: 11.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.525097649358287		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.525097649358287 | validation: 0.3347226660834814]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35945609266308776		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.35945609266308776 | validation: 0.3353301922568496]
	TIME [epoch: 11.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3546927912046952		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.3546927912046952 | validation: 0.31401851584185836]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3879841357914623		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.3879841357914623 | validation: 0.4054359841271207]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4626536505003451		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.4626536505003451 | validation: 0.42254020727709174]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36109298255533645		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.36109298255533645 | validation: 0.8008975963101292]
	TIME [epoch: 11.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.498998762258097		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.498998762258097 | validation: 0.406817225437361]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4169312761922448		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.4169312761922448 | validation: 0.4419389179570405]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4950517306639353		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.4950517306639353 | validation: 0.4414773057033169]
	TIME [epoch: 11.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4040507024317741		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.4040507024317741 | validation: 0.39208240453541576]
	TIME [epoch: 11.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41553288398125643		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.41553288398125643 | validation: 0.326451154245271]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38098470485194025		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.38098470485194025 | validation: 0.3479017341464137]
	TIME [epoch: 11.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34501504012027595		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.34501504012027595 | validation: 0.31191138732556256]
	TIME [epoch: 11.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3348966481011907		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.3348966481011907 | validation: 0.3890758608402026]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42273614957669586		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.42273614957669586 | validation: 0.3145625256185647]
	TIME [epoch: 11.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45912963242417865		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.45912963242417865 | validation: 0.395121917942422]
	TIME [epoch: 11.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3512442579170528		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.3512442579170528 | validation: 0.39810234034327524]
	TIME [epoch: 11.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3800919269297297		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.3800919269297297 | validation: 0.43157908154924457]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4138679067299452		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.4138679067299452 | validation: 0.29366869136001866]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3663339937930946		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.3663339937930946 | validation: 0.40482733151989564]
	TIME [epoch: 11.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41124875242100534		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.41124875242100534 | validation: 0.3647534411258903]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37669216161003305		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.37669216161003305 | validation: 0.4131712658174508]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4401334567398766		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.4401334567398766 | validation: 0.3550441709739869]
	TIME [epoch: 11.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32667839737279086		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.32667839737279086 | validation: 0.2975578843968978]
	TIME [epoch: 11.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3672855699097002		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.3672855699097002 | validation: 0.8590896815892144]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.547003312938243		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.547003312938243 | validation: 0.31527017104103244]
	TIME [epoch: 11.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373075807201503		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.373075807201503 | validation: 0.28470295272023444]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_610.pth
	Model improved!!!
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35471252454422675		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.35471252454422675 | validation: 0.4665838949779226]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37493909849518037		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.37493909849518037 | validation: 0.30678092550723884]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3488453614386959		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.3488453614386959 | validation: 0.3675664810964143]
	TIME [epoch: 11.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757163594292358		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.3757163594292358 | validation: 0.2977882158791415]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3286320208879395		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.3286320208879395 | validation: 0.4338518676611188]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5281083930608429		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5281083930608429 | validation: 0.3009266700691023]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3392809983101549		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.3392809983101549 | validation: 0.37659573369868193]
	TIME [epoch: 11.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3271764465967767		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.3271764465967767 | validation: 0.3465316520790306]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472864273189385		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.3472864273189385 | validation: 0.3424688415935415]
	TIME [epoch: 11.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.375810514236406		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.375810514236406 | validation: 0.3918025435211617]
	TIME [epoch: 11.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4036296462282642		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.4036296462282642 | validation: 0.45646470771209124]
	TIME [epoch: 11.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44722039245772804		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.44722039245772804 | validation: 0.5407346709569124]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43305370179508873		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.43305370179508873 | validation: 0.32699664184806665]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3379791558704546		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.3379791558704546 | validation: 0.296912223956002]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31838971278255346		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.31838971278255346 | validation: 0.3692025368968119]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362337172092534		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.362337172092534 | validation: 0.34219002716321484]
	TIME [epoch: 11.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35858889912106096		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.35858889912106096 | validation: 0.2866629430962886]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771428883855774		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.3771428883855774 | validation: 0.4908980655221616]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4018909175739107		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.4018909175739107 | validation: 0.2846327870874302]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_629.pth
	Model improved!!!
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37103629561989954		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.37103629561989954 | validation: 0.3364283409575042]
	TIME [epoch: 11.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38176385214250985		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.38176385214250985 | validation: 0.33436910406647996]
	TIME [epoch: 11.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37588310281029524		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.37588310281029524 | validation: 0.35824359784245136]
	TIME [epoch: 11.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3676291961358018		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.3676291961358018 | validation: 0.3784034358823257]
	TIME [epoch: 11.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.446425896162883		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.446425896162883 | validation: 0.3429932733884391]
	TIME [epoch: 11.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3506498077292181		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.3506498077292181 | validation: 0.3638275980181123]
	TIME [epoch: 11.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38778144555704225		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.38778144555704225 | validation: 0.33872935667876997]
	TIME [epoch: 11.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40748064792990907		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.40748064792990907 | validation: 0.47733786352162727]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38340996738755123		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.38340996738755123 | validation: 0.31298834697126937]
	TIME [epoch: 11.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36226310767664993		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.36226310767664993 | validation: 0.27242031494327734]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3245060901085132		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.3245060901085132 | validation: 0.289308887896037]
	TIME [epoch: 11.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38727076148553924		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.38727076148553924 | validation: 0.38899722889040195]
	TIME [epoch: 11.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695416953525533		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.3695416953525533 | validation: 0.3743648073467157]
	TIME [epoch: 11.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44801658794907734		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.44801658794907734 | validation: 0.3606181259310186]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34179132039710747		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.34179132039710747 | validation: 0.408508180441153]
	TIME [epoch: 11.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35702777302192973		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.35702777302192973 | validation: 0.43152909058913325]
	TIME [epoch: 11.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36273380796805155		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.36273380796805155 | validation: 0.2938434864881493]
	TIME [epoch: 11.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4108831430569928		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.4108831430569928 | validation: 0.31923255512234533]
	TIME [epoch: 11.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34553516246359195		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.34553516246359195 | validation: 0.3075262724793207]
	TIME [epoch: 11.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29874102159721105		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.29874102159721105 | validation: 0.5416276069571141]
	TIME [epoch: 11.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4555894708796488		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.4555894708796488 | validation: 0.3099968095869241]
	TIME [epoch: 11.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37637498453822654		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.37637498453822654 | validation: 0.4047864697168148]
	TIME [epoch: 11.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3394107048653113		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.3394107048653113 | validation: 0.4189885542718685]
	TIME [epoch: 11.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3981972334100342		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.3981972334100342 | validation: 0.3082031637407574]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3972541852294279		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.3972541852294279 | validation: 0.30802588665111846]
	TIME [epoch: 11.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42222624967833		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.42222624967833 | validation: 0.3714159419603857]
	TIME [epoch: 11.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35954335659689074		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.35954335659689074 | validation: 0.4567099743556014]
	TIME [epoch: 11.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.453062912328084		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.453062912328084 | validation: 0.5183257674066896]
	TIME [epoch: 11.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.515062981572421		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.515062981572421 | validation: 0.5757594602247141]
	TIME [epoch: 11.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47191536133891143		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.47191536133891143 | validation: 0.3242576844921157]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4218820436562476		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.4218820436562476 | validation: 0.4172117911780582]
	TIME [epoch: 11.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346656029727183		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.5346656029727183 | validation: 0.43464792184660517]
	TIME [epoch: 11.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3563234685968489		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.3563234685968489 | validation: 0.3519663433052713]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39194436138307837		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.39194436138307837 | validation: 0.37682613536590853]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39800437869027544		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.39800437869027544 | validation: 0.2935353554310949]
	TIME [epoch: 11.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3214058416740119		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.3214058416740119 | validation: 0.3239886837881128]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4193472356573954		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.4193472356573954 | validation: 0.2934227531793735]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2901356087732067		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.2901356087732067 | validation: 0.2967945708847024]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4095373043027115		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.4095373043027115 | validation: 0.4195781236317868]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3261275852012307		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.3261275852012307 | validation: 0.35012935487901387]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3625449727635961		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.3625449727635961 | validation: 0.36464445292288494]
	TIME [epoch: 11.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3590328573358602		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.3590328573358602 | validation: 0.46582514143136367]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4016258846816505		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.4016258846816505 | validation: 0.28732906304570843]
	TIME [epoch: 11.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4496209559935366		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.4496209559935366 | validation: 0.358436390861453]
	TIME [epoch: 11.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3920826424052885		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.3920826424052885 | validation: 0.3010899565376358]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34861706143705484		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.34861706143705484 | validation: 0.43142907426853394]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39129855237924815		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.39129855237924815 | validation: 0.4565438174600156]
	TIME [epoch: 11.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.553089581108889		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.553089581108889 | validation: 0.5100166076312571]
	TIME [epoch: 11.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43252231511415334		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.43252231511415334 | validation: 0.4515034489780218]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3956202044895023		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.3956202044895023 | validation: 0.29807734333884967]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3212758828932811		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.3212758828932811 | validation: 0.3511850161468691]
	TIME [epoch: 11.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.394404328361605		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.394404328361605 | validation: 0.28051793740676123]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28034597193260713		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.28034597193260713 | validation: 0.4014233029483012]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45701649088996993		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.45701649088996993 | validation: 0.37866130560434985]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40482385483337824		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.40482385483337824 | validation: 0.5830935131235532]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4151005692321128		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.4151005692321128 | validation: 0.37916007944596014]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40249088068334743		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.40249088068334743 | validation: 0.34344496331368846]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3250913015153082		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.3250913015153082 | validation: 0.36024511749493715]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42208201801898865		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.42208201801898865 | validation: 0.3029948563168483]
	TIME [epoch: 11.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3070579947641565		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.3070579947641565 | validation: 0.47631581562277175]
	TIME [epoch: 11.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38188826173487167		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.38188826173487167 | validation: 0.3448521260618976]
	TIME [epoch: 11.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3710230107343621		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.3710230107343621 | validation: 0.26852121040024995]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_691.pth
	Model improved!!!
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491446079424373		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.3491446079424373 | validation: 0.3079907834469577]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37655712440398315		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.37655712440398315 | validation: 0.27620926620599795]
	TIME [epoch: 11.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3505821382507092		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.3505821382507092 | validation: 0.36610483337979616]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30983924134225255		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.30983924134225255 | validation: 0.2731476542390439]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32094273509432575		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.32094273509432575 | validation: 0.33418742384755307]
	TIME [epoch: 11.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33499269833142353		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.33499269833142353 | validation: 0.31542226025538944]
	TIME [epoch: 11.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3659352778266306		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.3659352778266306 | validation: 0.3527868664237168]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2972644481602831		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.2972644481602831 | validation: 0.31935515743695175]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3374989096179934		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.3374989096179934 | validation: 0.5503753093768209]
	TIME [epoch: 11.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4830269524605199		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.4830269524605199 | validation: 0.41090549289394945]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3683470555081799		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.3683470555081799 | validation: 0.4598621935178076]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4088998317748752		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.4088998317748752 | validation: 0.29705447708697613]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501072646332072		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.501072646332072 | validation: 0.33640910717405204]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5278324042878634		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.5278324042878634 | validation: 0.3724450478894839]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35293045353213137		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.35293045353213137 | validation: 0.3303400474570792]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36305209341749695		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.36305209341749695 | validation: 0.3306891511357194]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3268076493947224		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.3268076493947224 | validation: 0.36902471305871687]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36531648511804116		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.36531648511804116 | validation: 0.32716722890217326]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31544555604135865		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.31544555604135865 | validation: 0.36758809005099774]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3389050628293425		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.3389050628293425 | validation: 0.30748436488894193]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31682486827532136		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.31682486827532136 | validation: 0.31614755243863807]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31793170991463754		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.31793170991463754 | validation: 0.31517061471642344]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34106772330866153		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.34106772330866153 | validation: 0.388748145442256]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3584780985558482		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.3584780985558482 | validation: 0.3786729818485337]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3509305375533408		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.3509305375533408 | validation: 0.32329330781430915]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31371202631193196		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.31371202631193196 | validation: 0.27074255977241335]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3799632150137649		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.3799632150137649 | validation: 0.33130499534428937]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40419621543966455		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.40419621543966455 | validation: 0.3027650314181789]
	TIME [epoch: 11.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3304316054940012		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.3304316054940012 | validation: 0.28542456313210657]
	TIME [epoch: 11.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29805303087403734		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.29805303087403734 | validation: 0.36043974314677263]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34268402993629504		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.34268402993629504 | validation: 0.3670934356522523]
	TIME [epoch: 11.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3779261485939245		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.3779261485939245 | validation: 0.3182476677862317]
	TIME [epoch: 11.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31398232525646597		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.31398232525646597 | validation: 0.36009568543029175]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453652337886741		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.3453652337886741 | validation: 0.5243388873791183]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3767879812505921		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.3767879812505921 | validation: 0.29075686188430533]
	TIME [epoch: 11.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878377013044473		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.2878377013044473 | validation: 0.3066129161476412]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49333272893143		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.49333272893143 | validation: 0.4864109913483911]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3868868697196479		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.3868868697196479 | validation: 0.524545460293007]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3906089954432908		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.3906089954432908 | validation: 0.338409313774354]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4044738961418018		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.4044738961418018 | validation: 0.319844421013544]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38071779106118153		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.38071779106118153 | validation: 0.3535164754846795]
	TIME [epoch: 11.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35852994343668326		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.35852994343668326 | validation: 0.4461151836623267]
	TIME [epoch: 11.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3598675535111585		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.3598675535111585 | validation: 0.5102522343164374]
	TIME [epoch: 11.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4432760309682411		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.4432760309682411 | validation: 0.3550222333248949]
	TIME [epoch: 11.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33694327646806266		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.33694327646806266 | validation: 0.26010183554631666]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_736.pth
	Model improved!!!
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25518391380995287		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.25518391380995287 | validation: 0.27514650751879144]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2819606292272564		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.2819606292272564 | validation: 0.30506010749927126]
	TIME [epoch: 11.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33924739342247945		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.33924739342247945 | validation: 0.3425516433249149]
	TIME [epoch: 11.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.284080497335455		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.284080497335455 | validation: 0.2691118326226199]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3843160336988657		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.3843160336988657 | validation: 0.33049095392910105]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31946466062838125		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.31946466062838125 | validation: 0.31064353672030626]
	TIME [epoch: 11.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29857016066976283		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.29857016066976283 | validation: 0.2672381496785119]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856614367562839		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.2856614367562839 | validation: 0.2891684832220729]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2908677048219187		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.2908677048219187 | validation: 0.3383004280003701]
	TIME [epoch: 11.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37801747121553764		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.37801747121553764 | validation: 0.2786217468848944]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3330906295230959		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.3330906295230959 | validation: 0.29519042046084665]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3723790501940518		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.3723790501940518 | validation: 0.330635874950363]
	TIME [epoch: 11.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30436458755239004		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.30436458755239004 | validation: 0.3130119461348725]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3382072636452945		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.3382072636452945 | validation: 0.35299963490508]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33010773010559646		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.33010773010559646 | validation: 0.38440779461794494]
	TIME [epoch: 11.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3650865617068507		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.3650865617068507 | validation: 0.3128324398554452]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3747659219033639		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.3747659219033639 | validation: 0.5323727970574408]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4152167249452891		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.4152167249452891 | validation: 0.3131740578839019]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4068061789147249		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.4068061789147249 | validation: 0.3986157552883649]
	TIME [epoch: 11.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32452951269145786		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.32452951269145786 | validation: 0.4696384202455978]
	TIME [epoch: 11.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41111243604096026		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.41111243604096026 | validation: 0.6223929806409284]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4620025823397841		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.4620025823397841 | validation: 0.6066037247930723]
	TIME [epoch: 11.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4510762971677673		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.4510762971677673 | validation: 0.26934333048126674]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2963836685386868		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.2963836685386868 | validation: 0.30237220225811795]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36264568421198007		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.36264568421198007 | validation: 0.33624402931762903]
	TIME [epoch: 11.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3252297997081136		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.3252297997081136 | validation: 0.29267931739596026]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4029059696263305		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.4029059696263305 | validation: 0.2933822439758227]
	TIME [epoch: 11.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3350468262501352		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.3350468262501352 | validation: 0.2801464849743973]
	TIME [epoch: 11.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27172501697431295		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.27172501697431295 | validation: 0.316978950139165]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3274840547357769		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.3274840547357769 | validation: 0.42948801161862593]
	TIME [epoch: 11.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3340403328395413		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.3340403328395413 | validation: 0.32227795616246097]
	TIME [epoch: 11.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39866682357083427		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.39866682357083427 | validation: 0.34117907764050986]
	TIME [epoch: 11.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37369021545678643		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.37369021545678643 | validation: 0.4300481221479649]
	TIME [epoch: 11.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4735270345090457		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.4735270345090457 | validation: 0.31971164739493646]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32255047270042236		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.32255047270042236 | validation: 0.31918072015930965]
	TIME [epoch: 11.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3303745129792144		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.3303745129792144 | validation: 0.3456068270198266]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31133581358686657		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.31133581358686657 | validation: 0.27166658126874127]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28279529726290603		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.28279529726290603 | validation: 0.2963165666197694]
	TIME [epoch: 11.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3064181084236902		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.3064181084236902 | validation: 0.27294626278502876]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39324851184084686		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.39324851184084686 | validation: 0.3340317510417169]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37065943872227763		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.37065943872227763 | validation: 0.26977241089906573]
	TIME [epoch: 11.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2864789096719671		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.2864789096719671 | validation: 0.2566837856325747]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_778.pth
	Model improved!!!
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4315259610932431		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.4315259610932431 | validation: 0.352704364749527]
	TIME [epoch: 11.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36135023540095634		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.36135023540095634 | validation: 0.2946419643710764]
	TIME [epoch: 11.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29213224284751693		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.29213224284751693 | validation: 0.2845167864636046]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27008821716245945		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.27008821716245945 | validation: 0.2776316269223057]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2902681542637317		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.2902681542637317 | validation: 0.2664571307010927]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545336795867943		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.2545336795867943 | validation: 0.26026766510467597]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2648266211886712		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.2648266211886712 | validation: 0.30359977371277647]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36045522753187587		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.36045522753187587 | validation: 0.32668973419785224]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28409248255927594		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.28409248255927594 | validation: 0.44340778523559266]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4070173912709489		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.4070173912709489 | validation: 0.40132220715995887]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38770156766589403		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.38770156766589403 | validation: 0.5907871326738507]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42433610349561407		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.42433610349561407 | validation: 0.33505054984141225]
	TIME [epoch: 11.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3215555284161205		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.3215555284161205 | validation: 0.2674769823280427]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25890007514154123		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.25890007514154123 | validation: 0.353547443363109]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2757968095992474		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.2757968095992474 | validation: 0.24909682772695327]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_793.pth
	Model improved!!!
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2715465757260924		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.2715465757260924 | validation: 0.27355318639252696]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27914453209191786		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.27914453209191786 | validation: 0.25841812866726527]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719236638045305		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.2719236638045305 | validation: 0.38286111086469987]
	TIME [epoch: 11.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3408326975383312		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.3408326975383312 | validation: 0.26698308211016214]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26704253841587156		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.26704253841587156 | validation: 0.2806731473075341]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.257297599627176		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.257297599627176 | validation: 0.33524059398644424]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32542024579868045		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.32542024579868045 | validation: 0.33642467365925116]
	TIME [epoch: 11.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2967847874638911		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.2967847874638911 | validation: 0.30464814066969165]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28780070263048585		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.28780070263048585 | validation: 0.2392331233283938]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_802.pth
	Model improved!!!
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27939412695945826		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.27939412695945826 | validation: 0.25493019131186107]
	TIME [epoch: 11.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28196821070449196		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.28196821070449196 | validation: 0.31297088973664816]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3433632228206567		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.3433632228206567 | validation: 0.5174810122178871]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3841727567869556		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.3841727567869556 | validation: 0.3715720542489052]
	TIME [epoch: 11.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3279703655998515		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.3279703655998515 | validation: 0.34953606594171177]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3310005461804947		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.3310005461804947 | validation: 0.3071922332611336]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26007207999951143		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.26007207999951143 | validation: 0.3026538857514773]
	TIME [epoch: 11.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3186486409920449		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.3186486409920449 | validation: 0.24445162633428477]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2763691136403952		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.2763691136403952 | validation: 0.23822754640670726]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_811.pth
	Model improved!!!
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32143178237917686		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.32143178237917686 | validation: 0.29893828164985475]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29214742774914304		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.29214742774914304 | validation: 0.44866749713366505]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3294719082664267		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.3294719082664267 | validation: 0.26045232967141646]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3390932260563034		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.3390932260563034 | validation: 0.2723285619884699]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29548924746901767		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.29548924746901767 | validation: 0.2475083110908644]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2761575782469138		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.2761575782469138 | validation: 0.2904365162364287]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27326812893913766		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.27326812893913766 | validation: 0.28410505285243476]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33258559566577434		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.33258559566577434 | validation: 0.42066274648173463]
	TIME [epoch: 11.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2965645789042448		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.2965645789042448 | validation: 0.24225555305671775]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3211380533647996		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.3211380533647996 | validation: 0.38396475998166535]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3696699448601777		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.3696699448601777 | validation: 0.3999791721532175]
	TIME [epoch: 11.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3069744950482534		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.3069744950482534 | validation: 0.3932175624341518]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34528659483080415		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.34528659483080415 | validation: 0.32393623798054777]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2983412552256533		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.2983412552256533 | validation: 0.280639815708572]
	TIME [epoch: 11.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25865046995009133		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.25865046995009133 | validation: 0.2870520983077054]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2993480396980569		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.2993480396980569 | validation: 0.2369171540271593]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_827.pth
	Model improved!!!
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30433236964945315		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.30433236964945315 | validation: 0.26836894526008764]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2583184525052657		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.2583184525052657 | validation: 0.25289451044223393]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2828937010143701		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.2828937010143701 | validation: 0.29052431418214036]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740823279891302		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.2740823279891302 | validation: 0.25411914902603944]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2606611861592813		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.2606611861592813 | validation: 0.3316056768313247]
	TIME [epoch: 11.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28972361998772034		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.28972361998772034 | validation: 0.2365672748023241]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_833.pth
	Model improved!!!
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2618107780802109		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.2618107780802109 | validation: 0.26149433058785504]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2893828954446583		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.2893828954446583 | validation: 0.27906541338549384]
	TIME [epoch: 11.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26077147843975446		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.26077147843975446 | validation: 0.264090242389485]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27409248716149287		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.27409248716149287 | validation: 0.26256077963028374]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2727602460933427		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.2727602460933427 | validation: 0.3162219522525139]
	TIME [epoch: 11.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26351034159835346		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.26351034159835346 | validation: 0.2851468726094022]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26217593983302834		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.26217593983302834 | validation: 0.26531242099788915]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3379461866783693		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.3379461866783693 | validation: 0.44098792942099607]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3117644308121309		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.3117644308121309 | validation: 0.2545461261460691]
	TIME [epoch: 11.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25701141604040495		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.25701141604040495 | validation: 0.3096315933439259]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27299809574746425		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.27299809574746425 | validation: 0.2680438796692515]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26092003785333373		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.26092003785333373 | validation: 0.2722361127199801]
	TIME [epoch: 11.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590360286920902		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.2590360286920902 | validation: 0.25102131739734285]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524994320532835		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.2524994320532835 | validation: 0.2738013554633793]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24026703086205892		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.24026703086205892 | validation: 0.2564297308439972]
	TIME [epoch: 11.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26509264367188284		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.26509264367188284 | validation: 0.3072488907267141]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782317958136706		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.2782317958136706 | validation: 0.32270937287209805]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2946572567623705		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.2946572567623705 | validation: 0.26490562316703115]
	TIME [epoch: 11.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519128622110345		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.2519128622110345 | validation: 0.2875918842454086]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28626790533811663		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.28626790533811663 | validation: 0.2952581240261235]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31550259704519246		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.31550259704519246 | validation: 0.3145160321427407]
	TIME [epoch: 11.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28123793168824246		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.28123793168824246 | validation: 0.3273904735569539]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34929469395576873		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.34929469395576873 | validation: 0.2770158930032459]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2944573851953896		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.2944573851953896 | validation: 0.25547538131047964]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24706593521260986		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.24706593521260986 | validation: 0.22770275654004407]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_858.pth
	Model improved!!!
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3288731161604311		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.3288731161604311 | validation: 0.25983703562123034]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25718117540653573		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.25718117540653573 | validation: 0.27120358382331655]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27337838791749575		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.27337838791749575 | validation: 0.32321719547999833]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2994901992147102		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.2994901992147102 | validation: 0.3286151500363896]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31942972674216086		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.31942972674216086 | validation: 0.3583438783479896]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27105346220745746		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.27105346220745746 | validation: 0.38452733873770345]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.302839914259266		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.302839914259266 | validation: 0.3048563516718152]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3363697391566815		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.3363697391566815 | validation: 0.32360630689998376]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2679249964028834		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.2679249964028834 | validation: 0.2667172857881627]
	TIME [epoch: 11.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24882170538025147		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.24882170538025147 | validation: 0.31112614652899284]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2774788680265254		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.2774788680265254 | validation: 0.25304800591670357]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24287598936681803		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.24287598936681803 | validation: 0.2750819274903582]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510557842132308		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.2510557842132308 | validation: 0.26144044974093256]
	TIME [epoch: 11.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24978428229838429		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.24978428229838429 | validation: 0.26753209123479244]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704748194306269		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.2704748194306269 | validation: 0.29295426072124453]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28268694993340304		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.28268694993340304 | validation: 0.35278171781511136]
	TIME [epoch: 11.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32870476285677175		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.32870476285677175 | validation: 0.2985571773742006]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2663929853173635		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.2663929853173635 | validation: 0.26978773244711635]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613870131440571		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.2613870131440571 | validation: 0.28295096486834553]
	TIME [epoch: 11.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2752463690998318		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.2752463690998318 | validation: 0.26177645697678936]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758627074508105		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.2758627074508105 | validation: 0.252821109390157]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29450482022375507		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.29450482022375507 | validation: 0.3361622921726864]
	TIME [epoch: 11.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32769928358896533		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.32769928358896533 | validation: 0.2849712253578219]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28858419627516463		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.28858419627516463 | validation: 0.3562231497598365]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498654521372491		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.3498654521372491 | validation: 0.26261565964778266]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26038125432319353		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.26038125432319353 | validation: 0.2807967880084603]
	TIME [epoch: 11.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25556272782731193		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.25556272782731193 | validation: 0.2684389816536221]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34418122031591475		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.34418122031591475 | validation: 0.3110802109077519]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30373301953124826		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.30373301953124826 | validation: 0.24292183583034557]
	TIME [epoch: 11.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2540789849152365		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.2540789849152365 | validation: 0.2544753364433336]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24587070522333765		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.24587070522333765 | validation: 0.2471646222270536]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2681749000462131		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.2681749000462131 | validation: 0.26360178480574464]
	TIME [epoch: 11.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30481288494098124		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.30481288494098124 | validation: 0.30279159425897006]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2694525286403786		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.2694525286403786 | validation: 0.23742621052621882]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25059449540249257		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.25059449540249257 | validation: 0.2821353679903753]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3767419233304027		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.3767419233304027 | validation: 0.32242831459116034]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26991382909811157		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.26991382909811157 | validation: 0.23058168033972037]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22702057966458322		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.22702057966458322 | validation: 0.23179116661444035]
	TIME [epoch: 11.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31190359838754467		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.31190359838754467 | validation: 0.45864283173724174]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33747796022946125		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.33747796022946125 | validation: 0.2542717582652656]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25269498326159456		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.25269498326159456 | validation: 0.24413466699910294]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26511333522656694		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.26511333522656694 | validation: 0.2891968003241229]
	TIME [epoch: 11.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26744929094857833		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.26744929094857833 | validation: 0.2732813669271357]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2640343260119814		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.2640343260119814 | validation: 0.2551610166604989]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24110477530983576		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.24110477530983576 | validation: 0.31769057539056184]
	TIME [epoch: 11.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30189144401113266		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.30189144401113266 | validation: 0.24731624185549606]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2419311587119382		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.2419311587119382 | validation: 0.2552120416302842]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739360381581295		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.2739360381581295 | validation: 0.28658448109221135]
	TIME [epoch: 11.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29879754288343263		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.29879754288343263 | validation: 0.31362383769230023]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4030086194568374		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.4030086194568374 | validation: 0.4362987643395547]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757309590515043		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.3757309590515043 | validation: 0.2635589902973913]
	TIME [epoch: 11.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2566300120892539		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.2566300120892539 | validation: 0.27626468949188976]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2938622227753449		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.2938622227753449 | validation: 0.26095276941103807]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853986433465994		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.2853986433465994 | validation: 0.28077505146644177]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2616624622031984		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.2616624622031984 | validation: 0.2637678182118147]
	TIME [epoch: 11.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2682956729355686		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.2682956729355686 | validation: 0.2614725644727779]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3174438895296564		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.3174438895296564 | validation: 0.2605784204893159]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24768418375511603		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.24768418375511603 | validation: 0.2626938635549333]
	TIME [epoch: 11.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29563251704522525		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.29563251704522525 | validation: 0.23267503459364844]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25812015773455077		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.25812015773455077 | validation: 0.33474641414209366]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2714680641806442		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.2714680641806442 | validation: 0.2736782278275247]
	TIME [epoch: 11.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27908070379083144		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.27908070379083144 | validation: 0.373982779892226]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3371543857512711		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.3371543857512711 | validation: 0.2520119474242924]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26030560638242456		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.26030560638242456 | validation: 0.28288537267210273]
	TIME [epoch: 11.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2743656133175939		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.2743656133175939 | validation: 0.3397081430755097]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3161853644798912		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.3161853644798912 | validation: 0.2693636303161249]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25599883164296167		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.25599883164296167 | validation: 0.24958988087599956]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23339004650691275		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.23339004650691275 | validation: 0.23507195777680018]
	TIME [epoch: 11.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509053914034884		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.2509053914034884 | validation: 0.2965098822499141]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29080035000901844		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.29080035000901844 | validation: 0.2732332858510836]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645853243017781		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.2645853243017781 | validation: 0.2687219857466953]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259810451330321		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.259810451330321 | validation: 0.28565576855399644]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29522271718514664		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.29522271718514664 | validation: 0.23685058276977622]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2378122067355452		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.2378122067355452 | validation: 0.23384907109299555]
	TIME [epoch: 11.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23838969729163714		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.23838969729163714 | validation: 0.25555498656719733]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42084773817624654		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.42084773817624654 | validation: 0.39193136279425345]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933541233201554		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.2933541233201554 | validation: 0.27826187990919027]
	TIME [epoch: 11.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3067735473724915		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.3067735473724915 | validation: 0.2668124189117573]
	TIME [epoch: 11.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27804232295299613		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.27804232295299613 | validation: 0.3041041017326209]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28945970693040557		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.28945970693040557 | validation: 0.2552128641148716]
	TIME [epoch: 11.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2877835466266475		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.2877835466266475 | validation: 0.34881482259118307]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343632865975633		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.3343632865975633 | validation: 0.30269607717675945]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31546471166016776		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.31546471166016776 | validation: 0.34813525499410375]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30424311091654077		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.30424311091654077 | validation: 0.2622169237747329]
	TIME [epoch: 11.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2469177453735591		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.2469177453735591 | validation: 0.26369587471896877]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2665503607452392		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.2665503607452392 | validation: 0.33009180296472374]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32259278800778923		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.32259278800778923 | validation: 0.27774515717933984]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558847755432167		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.2558847755432167 | validation: 0.25779214424809893]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27601738456760305		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.27601738456760305 | validation: 0.23745819509566274]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25087153831864506		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.25087153831864506 | validation: 0.23992847886206511]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22920528650301128		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.22920528650301128 | validation: 0.2626605452069588]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29824148708979376		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.29824148708979376 | validation: 0.23138383964958428]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2862310816974018		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.2862310816974018 | validation: 0.26058324491546714]
	TIME [epoch: 11.6 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2500693072120544		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.2500693072120544 | validation: 0.22853477248281298]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24045767097630205		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.24045767097630205 | validation: 0.2556070112318185]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.234742956083493		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.234742956083493 | validation: 0.2414286341768446]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24557214480850187		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.24557214480850187 | validation: 0.24695505994788533]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26183749869809125		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.26183749869809125 | validation: 0.33433058368533203]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29283429465158095		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.29283429465158095 | validation: 0.2521087628466751]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24681818459570398		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.24681818459570398 | validation: 0.2586944778257632]
	TIME [epoch: 11.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285765713658713		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.285765713658713 | validation: 0.2554428466127142]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25228049216069953		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.25228049216069953 | validation: 0.263898840179685]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2946374974575616		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.2946374974575616 | validation: 0.2754285292082421]
	TIME [epoch: 11.6 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26272638087778766		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.26272638087778766 | validation: 0.25902166016800343]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30451425690347733		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.30451425690347733 | validation: 0.26608516800791576]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27471345270671854		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.27471345270671854 | validation: 0.3293265316755224]
	TIME [epoch: 11.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30734856672600885		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.30734856672600885 | validation: 0.2985077477086038]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25471440554821384		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.25471440554821384 | validation: 0.2371948979803068]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2631639112714184		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.2631639112714184 | validation: 0.2791560570197363]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30417911361330535		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.30417911361330535 | validation: 0.2895068587878231]
	TIME [epoch: 11.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27411824327174694		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.27411824327174694 | validation: 0.27548206075311343]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3158247201759902		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.3158247201759902 | validation: 0.3145782572987626]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000957110238795		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.3000957110238795 | validation: 0.28087124521383994]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2556541993741574		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.2556541993741574 | validation: 0.2500093046480719]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2647191057653194		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.2647191057653194 | validation: 0.2575900614652407]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25267633647955434		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.25267633647955434 | validation: 0.3197543415456024]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29593370891727966		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.29593370891727966 | validation: 0.22737564848574784]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_975.pth
	Model improved!!!
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23817273299523192		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.23817273299523192 | validation: 0.28139831331025167]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2580849514813395		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.2580849514813395 | validation: 0.2835718102402074]
	TIME [epoch: 11.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25571447999561087		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.25571447999561087 | validation: 0.2345043090568402]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23674917432096465		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.23674917432096465 | validation: 0.24896326494173907]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24162214265061877		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.24162214265061877 | validation: 0.28984602043439595]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34686660173361594		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.34686660173361594 | validation: 0.29079984380315416]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25561385563350636		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.25561385563350636 | validation: 0.25975774633461135]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25476963546854003		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.25476963546854003 | validation: 0.24728891634097852]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2442035700610573		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.2442035700610573 | validation: 0.2532169674322314]
	TIME [epoch: 11.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27357188516237174		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.27357188516237174 | validation: 0.3221303128316207]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2979358088942038		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.2979358088942038 | validation: 0.29826607417321155]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790839154639457		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.2790839154639457 | validation: 0.26480506607021]
	TIME [epoch: 11.6 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24889217503494515		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.24889217503494515 | validation: 0.29210616480078533]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26701007206573696		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.26701007206573696 | validation: 0.24262393322343453]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2697683412342573		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.2697683412342573 | validation: 0.2543136399779802]
	TIME [epoch: 11.6 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.226365249774152		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.226365249774152 | validation: 0.22342457107260744]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_991.pth
	Model improved!!!
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22392038208866175		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.22392038208866175 | validation: 0.22836345624083362]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23536179352253422		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.23536179352253422 | validation: 0.23292386851147895]
	TIME [epoch: 11.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23745291201063673		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.23745291201063673 | validation: 0.2276751124857743]
	TIME [epoch: 11.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25002398889777466		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.25002398889777466 | validation: 0.22883889239890454]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24311570059388432		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.24311570059388432 | validation: 0.26558546406162137]
	TIME [epoch: 11.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24206758829506317		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.24206758829506317 | validation: 0.24671660239641469]
	TIME [epoch: 11.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25196606323448933		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.25196606323448933 | validation: 0.27037948563140474]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23799683428993162		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.23799683428993162 | validation: 0.23313860310786438]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22723410598815635		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.22723410598815635 | validation: 0.24676216603063603]
	TIME [epoch: 11.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23113433330360572		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.23113433330360572 | validation: 0.2609778618986175]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24954323498149272		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.24954323498149272 | validation: 0.24057722240337093]
	TIME [epoch: 11.6 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22840975641955197		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.22840975641955197 | validation: 0.2229899067083226]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1003.pth
	Model improved!!!
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22775666931808036		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.22775666931808036 | validation: 0.23670235009970828]
	TIME [epoch: 11.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2378824965638916		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.2378824965638916 | validation: 0.24323527801995226]
	TIME [epoch: 11.6 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26010906733123157		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.26010906733123157 | validation: 0.2572258219633107]
	TIME [epoch: 11.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24787478753922296		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.24787478753922296 | validation: 0.24282383122768295]
	TIME [epoch: 11.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23191732353855163		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.23191732353855163 | validation: 0.22610156040833104]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2307201658851414		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.2307201658851414 | validation: 0.22271199810370107]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1009.pth
	Model improved!!!
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23955404583055012		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.23955404583055012 | validation: 0.23974536755292836]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2389808599510779		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.2389808599510779 | validation: 0.25162241459879064]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2365125772667374		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.2365125772667374 | validation: 0.2548729071070744]
	TIME [epoch: 11.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2409644939420711		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.2409644939420711 | validation: 0.2447577346621217]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24508662574516832		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.24508662574516832 | validation: 0.24125416925926899]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23212374690610715		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.23212374690610715 | validation: 0.24174550853686647]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22846829473899943		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.22846829473899943 | validation: 0.23789239647069196]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23703896425944437		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.23703896425944437 | validation: 0.22445658670458313]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22957116405645395		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.22957116405645395 | validation: 0.25499573464757047]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2834394799178801		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.2834394799178801 | validation: 0.2715454920720756]
	TIME [epoch: 11.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24239086598538362		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.24239086598538362 | validation: 0.23085927681759433]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21887542691973963		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.21887542691973963 | validation: 0.23735024533384846]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2506387539387207		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.2506387539387207 | validation: 0.32748129817534394]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3291802064973722		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.3291802064973722 | validation: 0.28865068653306397]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29418913940898833		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.29418913940898833 | validation: 0.25316622780045406]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22791467701919238		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.22791467701919238 | validation: 0.21491361158120975]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1025.pth
	Model improved!!!
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25025889706636173		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.25025889706636173 | validation: 0.21861069929228763]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23579287966150947		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.23579287966150947 | validation: 0.2322029079169895]
	TIME [epoch: 11.6 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25572215758367267		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.25572215758367267 | validation: 0.25149792621310113]
	TIME [epoch: 11.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2953393815475371		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.2953393815475371 | validation: 0.30282733250326654]
	TIME [epoch: 11.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27115652292337533		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.27115652292337533 | validation: 0.2437303431567332]
	TIME [epoch: 11.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23837675307173795		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.23837675307173795 | validation: 0.2605494729836223]
	TIME [epoch: 11.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253401791609345		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.253401791609345 | validation: 0.279769151824864]
	TIME [epoch: 11.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2730369945441398		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.2730369945441398 | validation: 0.2254399568234312]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2396671028939755		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.2396671028939755 | validation: 0.2727594903802374]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25005302866155976		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.25005302866155976 | validation: 0.23186596478458613]
	TIME [epoch: 11.6 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23758280445166224		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.23758280445166224 | validation: 0.23320368668157315]
	TIME [epoch: 11.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26233258032937473		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.26233258032937473 | validation: 0.27656557687340366]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28184944652491806		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.28184944652491806 | validation: 0.3377161462967241]
	TIME [epoch: 11.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34229053742660737		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.34229053742660737 | validation: 0.3396887240694852]
	TIME [epoch: 11.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3172741060767903		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.3172741060767903 | validation: 0.297508685154946]
	TIME [epoch: 11.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000839733966335		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.3000839733966335 | validation: 0.23836501112619068]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26350323796566266		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.26350323796566266 | validation: 0.25808210739174386]
	TIME [epoch: 11.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2489094461843424		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.2489094461843424 | validation: 0.24196673056462306]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23097738116346805		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.23097738116346805 | validation: 0.24202438811370505]
	TIME [epoch: 11.6 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24836196804013372		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.24836196804013372 | validation: 0.2513933524522997]
	TIME [epoch: 11.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24465562066484228		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.24465562066484228 | validation: 0.24050752686743104]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24763764026809776		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.24763764026809776 | validation: 0.24371835823773272]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23251225524091412		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.23251225524091412 | validation: 0.23762000472587907]
	TIME [epoch: 11.6 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25208326443774776		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.25208326443774776 | validation: 0.23896888462179783]
	TIME [epoch: 11.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2340681033648211		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.2340681033648211 | validation: 0.25356836059629784]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25355856869293497		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.25355856869293497 | validation: 0.24863877094471296]
	TIME [epoch: 11.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.236176004975334		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.236176004975334 | validation: 0.23272140597501115]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2371326334179626		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.2371326334179626 | validation: 0.25256305184253314]
	TIME [epoch: 11.6 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878570676000754		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.2878570676000754 | validation: 0.2354988050482248]
	TIME [epoch: 11.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23728858035715042		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.23728858035715042 | validation: 0.22005702261208687]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22131695745720664		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.22131695745720664 | validation: 0.24543079331067916]
	TIME [epoch: 11.6 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24903938317314545		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.24903938317314545 | validation: 0.23307189734989409]
	TIME [epoch: 11.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23239554966105946		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.23239554966105946 | validation: 0.23486769509398633]
	TIME [epoch: 11.6 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2355212325991616		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.2355212325991616 | validation: 0.2550919270998261]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2641601926281091		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.2641601926281091 | validation: 0.31012326953482894]
	TIME [epoch: 11.6 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28062333771704384		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.28062333771704384 | validation: 0.2581608919930319]
	TIME [epoch: 11.6 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23653756045754887		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.23653756045754887 | validation: 0.2403343674303949]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2434348116040177		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.2434348116040177 | validation: 0.2300998497621884]
	TIME [epoch: 11.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24019477950537477		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.24019477950537477 | validation: 0.22065747244716336]
	TIME [epoch: 11.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22853969511830585		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.22853969511830585 | validation: 0.22175031471752246]
	TIME [epoch: 11.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2290170058774532		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.2290170058774532 | validation: 0.23487499315217583]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2443675942868847		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.2443675942868847 | validation: 0.2449397211940881]
	TIME [epoch: 11.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2253560732907142		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.2253560732907142 | validation: 0.23893582190089968]
	TIME [epoch: 11.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2371385577236021		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.2371385577236021 | validation: 0.2568078274981962]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2534468184242741		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.2534468184242741 | validation: 0.23268146720776323]
	TIME [epoch: 11.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24730142521472265		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.24730142521472265 | validation: 0.2501209965960397]
	TIME [epoch: 11.6 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23154186574587712		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.23154186574587712 | validation: 0.2246914966879856]
	TIME [epoch: 11.6 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25224505564100747		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.25224505564100747 | validation: 0.2139135782432674]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1073.pth
	Model improved!!!
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21575781683444797		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.21575781683444797 | validation: 0.2324560146814431]
	TIME [epoch: 11.6 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22678067694913356		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.22678067694913356 | validation: 0.21511468297147496]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2159829820571212		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.2159829820571212 | validation: 0.22332492358124614]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22133466607233288		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.22133466607233288 | validation: 0.2594179056648606]
	TIME [epoch: 11.6 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25414239874554295		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.25414239874554295 | validation: 0.274035933189194]
	TIME [epoch: 11.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26243235605595605		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.26243235605595605 | validation: 0.24636922705512368]
	TIME [epoch: 11.6 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23517204658927862		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.23517204658927862 | validation: 0.2383006785933415]
	TIME [epoch: 11.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23442477437062478		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.23442477437062478 | validation: 0.28496376378078764]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2636535617103515		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.2636535617103515 | validation: 0.23499125066609716]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24000546162128253		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.24000546162128253 | validation: 0.21561775138112943]
	TIME [epoch: 11.6 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2411338694416631		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.2411338694416631 | validation: 0.27757385937709395]
	TIME [epoch: 11.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25270897007305576		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.25270897007305576 | validation: 0.2291891758803619]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22550195498889308		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.22550195498889308 | validation: 0.2132233540805284]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1086.pth
	Model improved!!!
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21473733564046846		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.21473733564046846 | validation: 0.2120602337044771]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1087.pth
	Model improved!!!
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21822330806627113		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.21822330806627113 | validation: 0.25717630959758014]
	TIME [epoch: 11.6 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2262717114091048		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.2262717114091048 | validation: 0.21562831020123377]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23529939188383217		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.23529939188383217 | validation: 0.23475228705042775]
	TIME [epoch: 11.6 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24278712998187657		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.24278712998187657 | validation: 0.2457511543111987]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2296014839399255		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.2296014839399255 | validation: 0.2259527311159223]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2637039630243725		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.2637039630243725 | validation: 0.26706407262358306]
	TIME [epoch: 11.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25244763059923414		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.25244763059923414 | validation: 0.2528942623066816]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25100864701292375		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.25100864701292375 | validation: 0.22431558199359536]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23515131285948093		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.23515131285948093 | validation: 0.3328053821270133]
	TIME [epoch: 11.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28372332929708227		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.28372332929708227 | validation: 0.21868658424886966]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2298061802728052		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.2298061802728052 | validation: 0.23278601400410587]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.224346859311932		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.224346859311932 | validation: 0.22487045828764454]
	TIME [epoch: 11.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21751128721318141		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.21751128721318141 | validation: 0.22880489576815083]
	TIME [epoch: 11.6 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21948743212639232		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.21948743212639232 | validation: 0.21782775795323758]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2350550992532802		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.2350550992532802 | validation: 0.2401726165439006]
	TIME [epoch: 11.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22582745943037216		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.22582745943037216 | validation: 0.25753828936984413]
	TIME [epoch: 11.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2526922511134297		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.2526922511134297 | validation: 0.2298859258897047]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26084606021813156		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.26084606021813156 | validation: 0.2375925409169247]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2270213947178472		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.2270213947178472 | validation: 0.25715890916973067]
	TIME [epoch: 11.6 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2343761425545937		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.2343761425545937 | validation: 0.2713680858535457]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839476498884633		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.2839476498884633 | validation: 0.27995581484662935]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26517444721304306		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.26517444721304306 | validation: 0.2405063039724622]
	TIME [epoch: 11.6 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22381293920125475		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.22381293920125475 | validation: 0.23060371584753733]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22403448040890858		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.22403448040890858 | validation: 0.23091050771436883]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22665320277172746		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.22665320277172746 | validation: 0.2168512077863135]
	TIME [epoch: 11.6 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21552005386335496		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.21552005386335496 | validation: 0.21996403225660735]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22623065290675318		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.22623065290675318 | validation: 0.22063544016983458]
	TIME [epoch: 11.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22039390507842296		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.22039390507842296 | validation: 0.2167830683846521]
	TIME [epoch: 11.6 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2312338657704842		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.2312338657704842 | validation: 0.23230596565660663]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2236176690528919		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.2236176690528919 | validation: 0.20956859145687928]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1117.pth
	Model improved!!!
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2165779072040218		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.2165779072040218 | validation: 0.2476222395035936]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27454027786165214		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.27454027786165214 | validation: 0.24407845781615792]
	TIME [epoch: 11.6 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24077516059146126		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.24077516059146126 | validation: 0.24350112657139544]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2514283348101293		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.2514283348101293 | validation: 0.27967876374995065]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26065047326885626		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.26065047326885626 | validation: 0.22985942225223743]
	TIME [epoch: 11.6 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2383031392356805		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.2383031392356805 | validation: 0.23118505277913393]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2240854921107802		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.2240854921107802 | validation: 0.24358605470933412]
	TIME [epoch: 11.6 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24804662654997978		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.24804662654997978 | validation: 0.23794730929669938]
	TIME [epoch: 11.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23757460402535246		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.23757460402535246 | validation: 0.24273792407294445]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25601719804184087		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.25601719804184087 | validation: 0.2645046863381196]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2435921357814652		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.2435921357814652 | validation: 0.2028250614663292]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1128.pth
	Model improved!!!
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21364080678047878		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.21364080678047878 | validation: 0.22126468072482625]
	TIME [epoch: 11.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21769306733265537		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.21769306733265537 | validation: 0.23027516031141218]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25452902717284503		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.25452902717284503 | validation: 0.26586586049223665]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2551577001411285		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.2551577001411285 | validation: 0.26007731362464737]
	TIME [epoch: 11.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2476345217287716		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.2476345217287716 | validation: 0.2408194514203111]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22339326841645257		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.22339326841645257 | validation: 0.2506118558156829]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2303030413086111		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.2303030413086111 | validation: 0.21770124570681687]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2206567735898007		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.2206567735898007 | validation: 0.2432822792901675]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24448360877677544		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.24448360877677544 | validation: 0.24031426327803335]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24197415948791068		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.24197415948791068 | validation: 0.2440599718494265]
	TIME [epoch: 11.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2658810759567322		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.2658810759567322 | validation: 0.21326621348774846]
	TIME [epoch: 11.6 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21147104790188326		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.21147104790188326 | validation: 0.2172467140513532]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21755479404756503		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.21755479404756503 | validation: 0.24064257068032166]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25442399345329436		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.25442399345329436 | validation: 0.25706130292086504]
	TIME [epoch: 11.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25211489540832244		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.25211489540832244 | validation: 0.2510640121879127]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24685110579573866		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.24685110579573866 | validation: 0.2978447117859141]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25228758539768614		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.25228758539768614 | validation: 0.20534200185034995]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23087697873725246		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.23087697873725246 | validation: 0.21307930656274018]
	TIME [epoch: 11.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21474417936615298		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.21474417936615298 | validation: 0.21066395283515338]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2070043444294877		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.2070043444294877 | validation: 0.21260630449880452]
	TIME [epoch: 11.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21598448188833272		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.21598448188833272 | validation: 0.2268133828839747]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24665381956494276		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.24665381956494276 | validation: 0.25446313101157314]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22886357220551512		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.22886357220551512 | validation: 0.21598739813994214]
	TIME [epoch: 11.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21377930415091215		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.21377930415091215 | validation: 0.22495550865633904]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2198126733227606		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.2198126733227606 | validation: 0.24964924440566713]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2533500669541636		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.2533500669541636 | validation: 0.24244170943281732]
	TIME [epoch: 11.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581692101726598		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.2581692101726598 | validation: 0.23247496304748963]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22804265432773926		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.22804265432773926 | validation: 0.21238752412124506]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2168404528387022		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.2168404528387022 | validation: 0.21981278613854227]
	TIME [epoch: 11.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22580196833932287		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.22580196833932287 | validation: 0.23600990922161338]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2392519432080324		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.2392519432080324 | validation: 0.22930754904694214]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2250740155333944		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.2250740155333944 | validation: 0.21270392455288914]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22830715920719635		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.22830715920719635 | validation: 0.2518813589882559]
	TIME [epoch: 11.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2433924911666383		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.2433924911666383 | validation: 0.25489496839064807]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23094526993788164		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.23094526993788164 | validation: 0.2326836627505952]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2183447908822913		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.2183447908822913 | validation: 0.24455742151156565]
	TIME [epoch: 11.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532118668399712		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.2532118668399712 | validation: 0.2188006181084289]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21169671389269593		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.21169671389269593 | validation: 0.22416661261738774]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21274331958268944		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.21274331958268944 | validation: 0.2211723417519945]
	TIME [epoch: 11.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21692366180240003		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.21692366180240003 | validation: 0.2228871472812913]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21827981711232364		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.21827981711232364 | validation: 0.2218648196531049]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2305795870429887		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.2305795870429887 | validation: 0.2095439511553474]
	TIME [epoch: 11.6 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21712078431154822		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.21712078431154822 | validation: 0.2621768683519874]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23623480635462218		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.23623480635462218 | validation: 0.23126602597361065]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23327340094610988		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.23327340094610988 | validation: 0.2591126805476187]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25635309129091266		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.25635309129091266 | validation: 0.23548612742165528]
	TIME [epoch: 11.6 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22879373457747076		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.22879373457747076 | validation: 0.22479868818374044]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505447910333149		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.2505447910333149 | validation: 0.2765186958577403]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581796143807033		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.2581796143807033 | validation: 0.21990422921868638]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.220710021733607		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.220710021733607 | validation: 0.2681373720726345]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26585085114177776		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.26585085114177776 | validation: 0.22416975055063468]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22471491402306812		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.22471491402306812 | validation: 0.23640924730639953]
	TIME [epoch: 11.6 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22710620084961977		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.22710620084961977 | validation: 0.24954596453320757]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22519560304693625		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.22519560304693625 | validation: 0.23578519222370362]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2272856428300351		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.2272856428300351 | validation: 0.23986626861682875]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24714286516781864		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.24714286516781864 | validation: 0.2679504377299522]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2444714622996535		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.2444714622996535 | validation: 0.21283014989115745]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21450032319119705		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.21450032319119705 | validation: 0.21599109188208993]
	TIME [epoch: 11.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20750163212787578		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.20750163212787578 | validation: 0.2067155149197345]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21256342844431944		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.21256342844431944 | validation: 0.21868688814859089]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21082771172173237		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.21082771172173237 | validation: 0.2064523814601899]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21698990226724735		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.21698990226724735 | validation: 0.22900958385430517]
	TIME [epoch: 11.6 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21554196249657762		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.21554196249657762 | validation: 0.20455310854294217]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20565316574491796		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.20565316574491796 | validation: 0.21947419200281748]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2161396014664102		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.2161396014664102 | validation: 0.19907350192853648]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1193.pth
	Model improved!!!
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21447601057378687		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.21447601057378687 | validation: 0.22399050727959194]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.224815280942941		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.224815280942941 | validation: 0.22461539192205507]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23574067965503004		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.23574067965503004 | validation: 0.2631773075792229]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2491954045748493		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.2491954045748493 | validation: 0.2482662822460602]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23094361649040213		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.23094361649040213 | validation: 0.1958776351135743]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1198.pth
	Model improved!!!
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21125978231381276		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.21125978231381276 | validation: 0.23200651994301766]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22613969425485747		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.22613969425485747 | validation: 0.22163226116635695]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22416180487620616		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.22416180487620616 | validation: 0.2182743411616405]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21232924765163394		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.21232924765163394 | validation: 0.21032569373588125]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20915075832741065		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.20915075832741065 | validation: 0.20861451605437256]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22142506646857618		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.22142506646857618 | validation: 0.242266917735271]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22072757620725075		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.22072757620725075 | validation: 0.22815839309270267]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2192894407203341		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.2192894407203341 | validation: 0.21311614784202806]
	TIME [epoch: 11.6 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22020179566515952		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.22020179566515952 | validation: 0.2071347921328736]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2080476618470634		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.2080476618470634 | validation: 0.2134932804730959]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21003500056279104		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.21003500056279104 | validation: 0.20633137832657228]
	TIME [epoch: 11.6 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088210989250655		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.2088210989250655 | validation: 0.22407707905610444]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21001178810058305		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.21001178810058305 | validation: 0.20802705309316985]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22040743867957147		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.22040743867957147 | validation: 0.2188775563045643]
	TIME [epoch: 11.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22616691840068678		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.22616691840068678 | validation: 0.21648582149674453]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2090795640508744		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.2090795640508744 | validation: 0.20541522880359286]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20452553778451882		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.20452553778451882 | validation: 0.19469787642455152]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1215.pth
	Model improved!!!
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.206665151602039		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.206665151602039 | validation: 0.20779763962711]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22115488960230184		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.22115488960230184 | validation: 0.2200769761691367]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22824400261165653		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.22824400261165653 | validation: 0.22434981225840753]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21671720681890538		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.21671720681890538 | validation: 0.20164602706728876]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21716763621935473		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.21716763621935473 | validation: 0.21449154253547292]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2078502554560323		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.2078502554560323 | validation: 0.21033498251311403]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21847175960648849		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.21847175960648849 | validation: 0.22437215819772632]
	TIME [epoch: 11.6 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21383105654609944		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.21383105654609944 | validation: 0.20843186001570563]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21156904954863354		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.21156904954863354 | validation: 0.21288515345914674]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21328929197018232		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.21328929197018232 | validation: 0.21116963380886739]
	TIME [epoch: 11.6 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.208408751456501		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.208408751456501 | validation: 0.20404868689039782]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2055342552953058		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.2055342552953058 | validation: 0.2131139810599656]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2090997837922796		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.2090997837922796 | validation: 0.20207547418803032]
	TIME [epoch: 11.6 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20644458236463126		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.20644458236463126 | validation: 0.2162312170909696]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20683928878190852		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.20683928878190852 | validation: 0.21368452255091455]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23937851270672006		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.23937851270672006 | validation: 0.2847621367064589]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2574353171740826		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.2574353171740826 | validation: 0.2444434217002222]
	TIME [epoch: 11.6 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2204070028021536		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.2204070028021536 | validation: 0.20531235584200672]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20632450659585416		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.20632450659585416 | validation: 0.2007044905908804]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.214264266788236		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.214264266788236 | validation: 0.2167464808559432]
	TIME [epoch: 11.6 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2145670329778974		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.2145670329778974 | validation: 0.22433388988748212]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24965745460391617		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.24965745460391617 | validation: 0.22295242320976955]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21982924494096776		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.21982924494096776 | validation: 0.2199945078106671]
	TIME [epoch: 11.6 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20615999480945466		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.20615999480945466 | validation: 0.21189186007862806]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20861985900262953		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.20861985900262953 | validation: 0.22359265480043608]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21989081394332988		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.21989081394332988 | validation: 0.20779775068955275]
	TIME [epoch: 11.6 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20927359097235027		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.20927359097235027 | validation: 0.21844336460032188]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2152061868371834		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.2152061868371834 | validation: 0.21173720004505064]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20844256107316494		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.20844256107316494 | validation: 0.21528482699561344]
	TIME [epoch: 11.6 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20602450508532164		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.20602450508532164 | validation: 0.20135914197711147]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20812250796372117		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.20812250796372117 | validation: 0.213058610739438]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21895980441236046		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.21895980441236046 | validation: 0.2109080880121511]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22763678523829828		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.22763678523829828 | validation: 0.22257435292321923]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2222525175306319		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.2222525175306319 | validation: 0.20419549228241785]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2085070843112979		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.2085070843112979 | validation: 0.2081443684771476]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20654048312878334		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.20654048312878334 | validation: 0.20984424411027605]
	TIME [epoch: 11.6 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21223292682345407		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.21223292682345407 | validation: 0.20533393018069646]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2114975390660579		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.2114975390660579 | validation: 0.20545981982728292]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20090868551366184		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.20090868551366184 | validation: 0.20287803875458846]
	TIME [epoch: 11.6 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21063303511302617		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.21063303511302617 | validation: 0.19645428216225314]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.202708905417023		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.202708905417023 | validation: 0.2066662796337456]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20468686701677613		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.20468686701677613 | validation: 0.2147575282975734]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21968981227684364		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.21968981227684364 | validation: 0.23321108372812255]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22101032590017744		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.22101032590017744 | validation: 0.22365480576177285]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22902513115951129		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.22902513115951129 | validation: 0.24943196593942957]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23508140457184287		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.23508140457184287 | validation: 0.22670714522352128]
	TIME [epoch: 11.6 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23951755039936834		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.23951755039936834 | validation: 0.22664950355478664]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2143693211246264		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.2143693211246264 | validation: 0.2009496351832831]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21025677289457656		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.21025677289457656 | validation: 0.21152632055613793]
	TIME [epoch: 11.6 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21289605153707325		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.21289605153707325 | validation: 0.20838503294417834]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20487547626603028		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.20487547626603028 | validation: 0.20758903506119247]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21459348200077397		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.21459348200077397 | validation: 0.21531997052718715]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20834095752709805		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.20834095752709805 | validation: 0.2224763031168399]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21033788999522077		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.21033788999522077 | validation: 0.20412271747895305]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2063292462886147		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.2063292462886147 | validation: 0.19988670138496886]
	TIME [epoch: 11.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2164502965931549		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.2164502965931549 | validation: 0.28155997990097953]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26316748038692644		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.26316748038692644 | validation: 0.22546539630360315]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21827065480688992		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.21827065480688992 | validation: 0.21477138020659362]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20988355941676207		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.20988355941676207 | validation: 0.21131429222935652]
	TIME [epoch: 11.6 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20572274302977797		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.20572274302977797 | validation: 0.19788953600515194]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19955668301844487		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.19955668301844487 | validation: 0.20650133402439552]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2026107511071653		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.2026107511071653 | validation: 0.19771796056440974]
	TIME [epoch: 11.6 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20089847920832		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.20089847920832 | validation: 0.21234465303564024]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21241630706809678		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.21241630706809678 | validation: 0.21382684505220886]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20655775854076394		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.20655775854076394 | validation: 0.2145272066530409]
	TIME [epoch: 11.6 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22906829740618256		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.22906829740618256 | validation: 0.227972120645673]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21563202135483472		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.21563202135483472 | validation: 0.2011416666303154]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20578827644044967		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.20578827644044967 | validation: 0.21000608521746567]
	TIME [epoch: 11.6 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21137839708425862		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.21137839708425862 | validation: 0.2245545704592653]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21321452738368085		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.21321452738368085 | validation: 0.20765896748712837]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20992467719087402		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.20992467719087402 | validation: 0.2110355476449041]
	TIME [epoch: 11.6 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22711588593472165		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.22711588593472165 | validation: 0.20724199958047165]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22358144990990392		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.22358144990990392 | validation: 0.22377493262207956]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22617493695203847		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.22617493695203847 | validation: 0.23391658857084807]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21441759576721356		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.21441759576721356 | validation: 0.21591654779229066]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106617497752493		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.2106617497752493 | validation: 0.21606499455140885]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21145007899164583		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.21145007899164583 | validation: 0.20479479141753232]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2028077938815906		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.2028077938815906 | validation: 0.1983410051512625]
	TIME [epoch: 11.6 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1990039385661067		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.1990039385661067 | validation: 0.2040040819439753]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20773033250398368		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.20773033250398368 | validation: 0.2138548669791355]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2138986399669331		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.2138986399669331 | validation: 0.21716783057886438]
	TIME [epoch: 11.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20629455924670786		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.20629455924670786 | validation: 0.20000649781117233]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21343941496091076		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.21343941496091076 | validation: 0.22045664672240736]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2209526510948836		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.2209526510948836 | validation: 0.20513432123128642]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21747846355441253		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.21747846355441253 | validation: 0.22470323300959963]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2294543993584995		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.2294543993584995 | validation: 0.20682653135180196]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2091749935835845		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.2091749935835845 | validation: 0.19266891998346491]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1302.pth
	Model improved!!!
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21283836092458103		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.21283836092458103 | validation: 0.22402815177778374]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21715400692575257		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.21715400692575257 | validation: 0.22434167939056182]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2150377373207375		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.2150377373207375 | validation: 0.2161434993026934]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2110305716798498		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.2110305716798498 | validation: 0.23143342398278471]
	TIME [epoch: 11.6 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22188984514365673		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.22188984514365673 | validation: 0.22370482697646213]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21175278708561093		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.21175278708561093 | validation: 0.19933504820482528]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1994448722981489		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.1994448722981489 | validation: 0.2072478621659769]
	TIME [epoch: 11.6 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20722052368664		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.20722052368664 | validation: 0.2006938989751217]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20402398133438632		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.20402398133438632 | validation: 0.19948522643348285]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2040687145499288		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.2040687145499288 | validation: 0.2010908923081238]
	TIME [epoch: 11.6 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20456236273561434		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.20456236273561434 | validation: 0.20339368292352425]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20590853290128874		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.20590853290128874 | validation: 0.2007683014998754]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20313154568683162		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.20313154568683162 | validation: 0.2051458867393427]
	TIME [epoch: 11.6 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20409550323046305		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.20409550323046305 | validation: 0.22113659497917162]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2173706594334455		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.2173706594334455 | validation: 0.22548370684794594]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20922484437036343		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.20922484437036343 | validation: 0.208827390726974]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20210134187483947		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.20210134187483947 | validation: 0.20378979546506645]
	TIME [epoch: 11.6 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19925468712039024		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.19925468712039024 | validation: 0.19880151338798996]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19974935221830212		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.19974935221830212 | validation: 0.21339398799597134]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20958795395087487		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.20958795395087487 | validation: 0.2107955441344294]
	TIME [epoch: 11.6 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2089009332079731		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.2089009332079731 | validation: 0.2205223370101982]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21299928334691764		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.21299928334691764 | validation: 0.1991205427775165]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20415002902105944		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.20415002902105944 | validation: 0.2053206064235388]
	TIME [epoch: 11.6 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20163670702202147		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.20163670702202147 | validation: 0.19271145926703587]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1993052550727431		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.1993052550727431 | validation: 0.20110589018550262]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20352119264725838		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.20352119264725838 | validation: 0.20125701781191407]
	TIME [epoch: 11.6 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21505205860864915		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.21505205860864915 | validation: 0.23529819253322018]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23068246799995512		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.23068246799995512 | validation: 0.20037831423596475]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2011199442376131		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.2011199442376131 | validation: 0.21193418629106006]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22733188229648948		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.22733188229648948 | validation: 0.23274614204585625]
	TIME [epoch: 11.6 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22075809298705334		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.22075809298705334 | validation: 0.23351973470064052]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2178780507964593		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.2178780507964593 | validation: 0.21492960176823667]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2071820956451887		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.2071820956451887 | validation: 0.20538823510824636]
	TIME [epoch: 11.6 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20581598527732464		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.20581598527732464 | validation: 0.2024245450097272]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.204414691186678		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.204414691186678 | validation: 0.19533578146185765]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19953903609018925		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.19953903609018925 | validation: 0.1985574715681723]
	TIME [epoch: 11.6 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2037666138368907		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.2037666138368907 | validation: 0.21248409836884666]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20765410503472526		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.20765410503472526 | validation: 0.21648369683017965]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21500889781943297		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.21500889781943297 | validation: 0.21536690494796495]
	TIME [epoch: 11.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20717110971640898		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.20717110971640898 | validation: 0.20723750687389447]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20264320392141416		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.20264320392141416 | validation: 0.209103191090911]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20613018185135046		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.20613018185135046 | validation: 0.21007002451260368]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21450548225786684		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.21450548225786684 | validation: 0.20642747970132688]
	TIME [epoch: 11.6 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20445442465232397		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.20445442465232397 | validation: 0.20156526614289888]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19727949395121835		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.19727949395121835 | validation: 0.20241851958362742]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19804996517062515		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.19804996517062515 | validation: 0.19097199176122442]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1348.pth
	Model improved!!!
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2042504499211557		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.2042504499211557 | validation: 0.20261478505281524]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2039389124873147		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.2039389124873147 | validation: 0.20202161142237277]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20410330803219356		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.20410330803219356 | validation: 0.2013095030592683]
	TIME [epoch: 11.6 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20502834142812926		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.20502834142812926 | validation: 0.20467012721313885]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20240508899158272		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.20240508899158272 | validation: 0.1963165614371642]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20132684496689224		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.20132684496689224 | validation: 0.1939842332120032]
	TIME [epoch: 11.6 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20296176170278166		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.20296176170278166 | validation: 0.20986474769954108]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20100063410072905		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.20100063410072905 | validation: 0.2051616959824988]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20612162169726445		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.20612162169726445 | validation: 0.22176542406373054]
	TIME [epoch: 11.6 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2091401019437624		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.2091401019437624 | validation: 0.19997664098188572]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20850286215588607		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.20850286215588607 | validation: 0.20964071829635508]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20758933500631976		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.20758933500631976 | validation: 0.20741834859032932]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21110383861375104		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.21110383861375104 | validation: 0.210071139953849]
	TIME [epoch: 11.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20001390440100464		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.20001390440100464 | validation: 0.19747684746828265]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2019245918920296		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.2019245918920296 | validation: 0.2190904479502882]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.215894901078898		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.215894901078898 | validation: 0.21090195507936166]
	TIME [epoch: 11.6 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20927534394162844		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.20927534394162844 | validation: 0.22798701040244504]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23283407404438333		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.23283407404438333 | validation: 0.22563060221481834]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21557783819803714		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.21557783819803714 | validation: 0.22923742593479826]
	TIME [epoch: 11.6 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21654232859833814		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.21654232859833814 | validation: 0.1919880199106614]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.201731837164446		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.201731837164446 | validation: 0.19934947428596858]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20664274892288403		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.20664274892288403 | validation: 0.20605545096539307]
	TIME [epoch: 11.6 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1970033575200186		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.1970033575200186 | validation: 0.20898335615688043]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1995185027327897		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.1995185027327897 | validation: 0.21470099763605993]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20168048695886376		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.20168048695886376 | validation: 0.2163478634793983]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20292365822492256		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.20292365822492256 | validation: 0.21077598978051368]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20405852454546203		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.20405852454546203 | validation: 0.2108828145389947]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20436846250405966		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.20436846250405966 | validation: 0.2095840219047558]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2029547443226241		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.2029547443226241 | validation: 0.1995031246178116]
	TIME [epoch: 11.6 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20102284521378264		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.20102284521378264 | validation: 0.21225140666086886]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19875451652082057		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.19875451652082057 | validation: 0.19629981692494092]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20507962626998677		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.20507962626998677 | validation: 0.21225362915015977]
	TIME [epoch: 11.6 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2145582930428419		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.2145582930428419 | validation: 0.20607579232038065]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20708859472785784		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.20708859472785784 | validation: 0.20232131838717926]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20332526187344852		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.20332526187344852 | validation: 0.20597679858386428]
	TIME [epoch: 11.6 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19723532268973162		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.19723532268973162 | validation: 0.20399049361417182]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2044091243062769		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.2044091243062769 | validation: 0.20029714822513456]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20707167649572064		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.20707167649572064 | validation: 0.2086268946610985]
	TIME [epoch: 11.6 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2082101228140234		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.2082101228140234 | validation: 0.2025019801721717]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20795871289150958		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.20795871289150958 | validation: 0.21664721415721244]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20841857658106958		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.20841857658106958 | validation: 0.20810909840857328]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19938769162702552		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.19938769162702552 | validation: 0.19643389206614037]
	TIME [epoch: 11.6 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1968415888516171		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.1968415888516171 | validation: 0.1945634447411971]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1960554407068883		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.1960554407068883 | validation: 0.2000523905394933]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2085747351846743		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.2085747351846743 | validation: 0.1973528317965404]
	TIME [epoch: 11.6 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1933967856627566		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.1933967856627566 | validation: 0.18890947412174497]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1394.pth
	Model improved!!!
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19796226958209215		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.19796226958209215 | validation: 0.1923343068029866]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19916231106422905		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.19916231106422905 | validation: 0.20082712488987434]
	TIME [epoch: 11.6 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20138455215813897		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.20138455215813897 | validation: 0.19432394542954481]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19920658652417186		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.19920658652417186 | validation: 0.20015982308575267]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20153007945802912		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.20153007945802912 | validation: 0.18918623467431603]
	TIME [epoch: 11.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2030558748978255		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.2030558748978255 | validation: 0.21060780973525944]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.202000110710768		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.202000110710768 | validation: 0.22226893141691556]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21672947157399003		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.21672947157399003 | validation: 0.20721579087016334]
	TIME [epoch: 11.6 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20120000825945905		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.20120000825945905 | validation: 0.199344604706251]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20123107899625828		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.20123107899625828 | validation: 0.20131794016550614]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21182473716033218		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.21182473716033218 | validation: 0.20583965500329435]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20559447217659677		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.20559447217659677 | validation: 0.19853253827157766]
	TIME [epoch: 11.6 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20079814169876156		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.20079814169876156 | validation: 0.20521338916195864]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21454311175208007		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.21454311175208007 | validation: 0.20598272161720255]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20117641703481953		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.20117641703481953 | validation: 0.19939066309765008]
	TIME [epoch: 11.6 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19929363486718155		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.19929363486718155 | validation: 0.2016439955636941]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19800184868060258		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.19800184868060258 | validation: 0.1991666464896681]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2022255514903129		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.2022255514903129 | validation: 0.2045429285426617]
	TIME [epoch: 11.6 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20468047000324668		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.20468047000324668 | validation: 0.21633967062799087]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20154427879551262		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.20154427879551262 | validation: 0.19342118302075093]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20066401662898353		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.20066401662898353 | validation: 0.20019682257900037]
	TIME [epoch: 11.6 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1995527229469296		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.1995527229469296 | validation: 0.1976447092220619]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19694831946475036		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.19694831946475036 | validation: 0.21474046376828285]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20809243670985839		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.20809243670985839 | validation: 0.22737805896623564]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21504256717629222		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.21504256717629222 | validation: 0.22485454069959537]
	TIME [epoch: 11.6 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22356084939288617		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.22356084939288617 | validation: 0.22971679553408614]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23015941897947018		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.23015941897947018 | validation: 0.24895635650399153]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2399953070291003		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.2399953070291003 | validation: 0.24176880283638305]
	TIME [epoch: 11.6 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22635353178007267		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.22635353178007267 | validation: 0.21441487176885513]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20982382616679704		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.20982382616679704 | validation: 0.20577632537435123]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2015097434927704		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.2015097434927704 | validation: 0.20300007943580248]
	TIME [epoch: 11.6 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1985471625626347		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.1985471625626347 | validation: 0.2143930660905615]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20170501080111025		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.20170501080111025 | validation: 0.20327771956768773]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2066909233687117		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.2066909233687117 | validation: 0.21177497542762658]
	TIME [epoch: 11.6 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22034577074621697		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.22034577074621697 | validation: 0.21796012299656822]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21663098282415102		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.21663098282415102 | validation: 0.21265712124288663]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19706191715202795		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.19706191715202795 | validation: 0.21302964318395826]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2091125238159731		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.2091125238159731 | validation: 0.19894493922568252]
	TIME [epoch: 11.6 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21002455469697512		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.21002455469697512 | validation: 0.22327008348705907]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20977397661091352		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.20977397661091352 | validation: 0.2134298373404418]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20074852236050583		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.20074852236050583 | validation: 0.19952126922101737]
	TIME [epoch: 11.6 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2002510243506224		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.2002510243506224 | validation: 0.20077611494500638]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20116115773176224		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.20116115773176224 | validation: 0.21556248648959972]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2256630122550075		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.2256630122550075 | validation: 0.21026933453494137]
	TIME [epoch: 11.6 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20904742754969047		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.20904742754969047 | validation: 0.20323289639984105]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20303850435083826		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.20303850435083826 | validation: 0.19858343194134176]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20090213273695215		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.20090213273695215 | validation: 0.2009891998576462]
	TIME [epoch: 11.6 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20507199786251368		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.20507199786251368 | validation: 0.19522417406807852]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2050651902275045		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.2050651902275045 | validation: 0.20459244957787256]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20601132570113512		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.20601132570113512 | validation: 0.20548290876129216]
	TIME [epoch: 11.6 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20599697781446916		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.20599697781446916 | validation: 0.1982384777570846]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20243099922680766		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.20243099922680766 | validation: 0.19856299848290618]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1978399562426679		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.1978399562426679 | validation: 0.19712438187375877]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2032049548806174		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.2032049548806174 | validation: 0.20912639228384428]
	TIME [epoch: 11.6 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20239033571543222		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.20239033571543222 | validation: 0.2162419654609914]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21832379589563983		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.21832379589563983 | validation: 0.2184442028875121]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21378863518949184		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.21378863518949184 | validation: 0.2024172259602174]
	TIME [epoch: 11.6 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2040626510763555		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.2040626510763555 | validation: 0.20385226700603287]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20670539134643295		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.20670539134643295 | validation: 0.2027387718633115]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19209897819745458		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.19209897819745458 | validation: 0.19333502489131807]
	TIME [epoch: 11.6 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19369694088392111		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.19369694088392111 | validation: 0.19377341510579385]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19139480071233833		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.19139480071233833 | validation: 0.18935782463923936]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19773861182784092		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.19773861182784092 | validation: 0.20197033397692984]
	TIME [epoch: 11.6 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20111641993438695		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.20111641993438695 | validation: 0.20045027111859554]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20231309451024843		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.20231309451024843 | validation: 0.191060029512944]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19148293758161364		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.19148293758161364 | validation: 0.19348411183654274]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19416801566756353		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.19416801566756353 | validation: 0.1970216364638492]
	TIME [epoch: 11.6 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19898721506059958		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.19898721506059958 | validation: 0.19160059250557246]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20012918625654774		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.20012918625654774 | validation: 0.20024794745714503]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1932602127435235		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.1932602127435235 | validation: 0.2003001009743251]
	TIME [epoch: 11.6 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1950832710499325		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.1950832710499325 | validation: 0.20082281339471816]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18953003866857354		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.18953003866857354 | validation: 0.19256383048859127]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2024664960281832		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.2024664960281832 | validation: 0.2041777519515987]
	TIME [epoch: 11.6 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20086547525006274		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.20086547525006274 | validation: 0.18949091173938384]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2016946321459898		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.2016946321459898 | validation: 0.19031192412423997]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19306072685413425		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.19306072685413425 | validation: 0.210309886198107]
	TIME [epoch: 11.6 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1999338865073702		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.1999338865073702 | validation: 0.20649195007436522]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1976723419769588		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.1976723419769588 | validation: 0.19928505461447457]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19470012158104716		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.19470012158104716 | validation: 0.2041727457944367]
	TIME [epoch: 11.6 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19649725411347777		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.19649725411347777 | validation: 0.2018317568388479]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1973422925912		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.1973422925912 | validation: 0.19544880003532444]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20298870078979783		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.20298870078979783 | validation: 0.197570780568673]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19633624878664596		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.19633624878664596 | validation: 0.20096511256508237]
	TIME [epoch: 11.6 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19940320391812286		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.19940320391812286 | validation: 0.20884620721008731]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21500508505583604		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.21500508505583604 | validation: 0.22134035405037344]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2249566333477456		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.2249566333477456 | validation: 0.21250452348379711]
	TIME [epoch: 11.6 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21738195925941975		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.21738195925941975 | validation: 0.2189797823420657]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21408050163640474		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.21408050163640474 | validation: 0.22145478432239096]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21165901488900862		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.21165901488900862 | validation: 0.2089528657049636]
	TIME [epoch: 11.6 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2053723900205055		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.2053723900205055 | validation: 0.2068651780694147]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20321782344523598		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.20321782344523598 | validation: 0.2039846026692937]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20106179840261998		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.20106179840261998 | validation: 0.2013800663333644]
	TIME [epoch: 11.6 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2077599823042275		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.2077599823042275 | validation: 0.19964935723005753]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20072469750533004		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.20072469750533004 | validation: 0.20010055521634076]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20078779336097946		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.20078779336097946 | validation: 0.19107080056584763]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19682397815075836		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.19682397815075836 | validation: 0.19847916657993964]
	TIME [epoch: 11.6 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19855584035960866		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.19855584035960866 | validation: 0.18912242320267353]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1945154713594897		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.1945154713594897 | validation: 0.21005347537964464]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19616312038330408		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.19616312038330408 | validation: 0.19029418578434154]
	TIME [epoch: 11.6 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1929536374340373		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.1929536374340373 | validation: 0.19654549426827816]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19212059060827402		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.19212059060827402 | validation: 0.20073216222843365]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20443117022440543		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.20443117022440543 | validation: 0.20500619371044118]
	TIME [epoch: 11.6 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2050134296891545		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.2050134296891545 | validation: 0.20475179165794907]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20136210522282422		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.20136210522282422 | validation: 0.20568840242063238]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19481203176479145		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.19481203176479145 | validation: 0.20505161203422367]
	TIME [epoch: 11.6 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19491462421792777		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.19491462421792777 | validation: 0.19656812782137476]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20659515913274376		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.20659515913274376 | validation: 0.20651807601272346]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21399532754240555		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.21399532754240555 | validation: 0.20278514167814263]
	TIME [epoch: 11.6 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19921066568311932		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.19921066568311932 | validation: 0.19692110988524703]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19795568306540534		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.19795568306540534 | validation: 0.1910743067551235]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19840028752472		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.19840028752472 | validation: 0.199078649003126]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21013503067937378		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.21013503067937378 | validation: 0.21628514970141383]
	TIME [epoch: 11.6 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20782698139892766		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.20782698139892766 | validation: 0.2029849798571466]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19692241982742198		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.19692241982742198 | validation: 0.2004649849832345]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20301105061468488		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.20301105061468488 | validation: 0.2140068101625331]
	TIME [epoch: 11.6 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21144209533411612		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.21144209533411612 | validation: 0.20722842210395193]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20090906776051817		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.20090906776051817 | validation: 0.20344061897023052]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19786671378873008		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.19786671378873008 | validation: 0.19421395287463114]
	TIME [epoch: 11.6 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19735034742361077		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.19735034742361077 | validation: 0.1945034301413144]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1974493601011484		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.1974493601011484 | validation: 0.20030484195177373]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19780784915897137		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.19780784915897137 | validation: 0.200102874024042]
	TIME [epoch: 11.6 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20131168668961041		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.20131168668961041 | validation: 0.19974704091648132]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21643287955219537		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.21643287955219537 | validation: 0.21121168247821698]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21508867188788425		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.21508867188788425 | validation: 0.21207465360825278]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20868559769497871		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.20868559769497871 | validation: 0.20339994226119065]
	TIME [epoch: 11.6 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20733937863531027		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.20733937863531027 | validation: 0.20236920465721192]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19901860208918665		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.19901860208918665 | validation: 0.18966640773830082]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19626712682463504		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.19626712682463504 | validation: 0.1902112089800785]
	TIME [epoch: 11.6 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19600137898035166		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.19600137898035166 | validation: 0.19836563823811623]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.194407675352055		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.194407675352055 | validation: 0.20450552497860128]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19894880156665853		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.19894880156665853 | validation: 0.19775327050197597]
	TIME [epoch: 11.6 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20032189469094303		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.20032189469094303 | validation: 0.18978372839370977]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2017130560205871		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.2017130560205871 | validation: 0.19792132939734264]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20624815571132474		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.20624815571132474 | validation: 0.2061775985679811]
	TIME [epoch: 11.6 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.202190971875637		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.202190971875637 | validation: 0.1998732378814747]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19657734225307882		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.19657734225307882 | validation: 0.19902372707749003]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1997050095302989		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.1997050095302989 | validation: 0.195120494150223]
	TIME [epoch: 11.6 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1950587857522541		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.1950587857522541 | validation: 0.19703301855814728]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19419041918533017		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.19419041918533017 | validation: 0.20378324248744734]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1994674273682677		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.1994674273682677 | validation: 0.20700585347558978]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1960875158575794		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.1960875158575794 | validation: 0.1984574937108944]
	TIME [epoch: 11.6 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1967264654090285		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.1967264654090285 | validation: 0.1941045427289466]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19955337602289008		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.19955337602289008 | validation: 0.2007906806338294]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20266164724844604		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.20266164724844604 | validation: 0.20457681287940893]
	TIME [epoch: 11.6 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19539827160098097		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.19539827160098097 | validation: 0.20338038843764977]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19446666518474348		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.19446666518474348 | validation: 0.20324875913411566]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19598587049371086		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.19598587049371086 | validation: 0.1940681152401914]
	TIME [epoch: 11.6 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19868497416597136		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.19868497416597136 | validation: 0.1903118263734713]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19666034760296702		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.19666034760296702 | validation: 0.19588105464742447]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19229339081151242		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.19229339081151242 | validation: 0.1985743476039579]
	TIME [epoch: 11.6 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19187903523673397		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.19187903523673397 | validation: 0.19328027839637976]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19463798939878868		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.19463798939878868 | validation: 0.19022801626813357]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19102225653581284		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.19102225653581284 | validation: 0.1941179744234192]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1960817662023402		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.1960817662023402 | validation: 0.1931481391798111]
	TIME [epoch: 11.6 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.199073934197561		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.199073934197561 | validation: 0.19777206658593802]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2006874269901664		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.2006874269901664 | validation: 0.19906688822245883]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19355124299921503		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.19355124299921503 | validation: 0.1893846539096453]
	TIME [epoch: 11.6 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19659097533769165		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.19659097533769165 | validation: 0.19857303183402755]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19227476402851978		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.19227476402851978 | validation: 0.19115419764838146]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19231880997432432		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.19231880997432432 | validation: 0.18882842559789748]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1554.pth
	Model improved!!!
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1933330199209305		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.1933330199209305 | validation: 0.17444979821850765]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1555.pth
	Model improved!!!
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19380169648941326		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.19380169648941326 | validation: 0.19998971031865875]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20078893307466755		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.20078893307466755 | validation: 0.19514744488867808]
	TIME [epoch: 11.6 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19463569918448986		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.19463569918448986 | validation: 0.19815133496411108]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19514483883387013		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.19514483883387013 | validation: 0.17973963602109969]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19124081457618106		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.19124081457618106 | validation: 0.18704411546369634]
	TIME [epoch: 11.6 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19035770807249114		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.19035770807249114 | validation: 0.18984573940923516]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19461125727599304		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.19461125727599304 | validation: 0.19473854355325818]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19455075878832492		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.19455075878832492 | validation: 0.18871089011909262]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19217510176684244		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.19217510176684244 | validation: 0.19456682722857196]
	TIME [epoch: 11.6 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1949006050030459		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.1949006050030459 | validation: 0.19258745300277025]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.187887199354038		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.187887199354038 | validation: 0.18589201878038472]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1917475006529245		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.1917475006529245 | validation: 0.2011465388345607]
	TIME [epoch: 11.6 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19263845663877588		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.19263845663877588 | validation: 0.1838533715988685]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19542980359238374		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.19542980359238374 | validation: 0.1883548576737406]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1934928486500191		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.1934928486500191 | validation: 0.19080980382213938]
	TIME [epoch: 11.6 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1958903478522352		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.1958903478522352 | validation: 0.19354716063012628]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19218560943219448		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.19218560943219448 | validation: 0.1886313724571488]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19533150027527185		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.19533150027527185 | validation: 0.190714450931889]
	TIME [epoch: 11.6 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.192908338615384		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.192908338615384 | validation: 0.1961086184505168]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19922127879837065		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.19922127879837065 | validation: 0.19901409664580466]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20094982646919735		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.20094982646919735 | validation: 0.19488414266734805]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20415087926256942		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.20415087926256942 | validation: 0.1988431273404642]
	TIME [epoch: 11.6 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19884462073850556		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.19884462073850556 | validation: 0.19332531100413883]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20847252879204997		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.20847252879204997 | validation: 0.20221929937286354]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20297056000228375		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.20297056000228375 | validation: 0.19097947483504588]
	TIME [epoch: 11.6 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20061430251897094		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.20061430251897094 | validation: 0.19608340000464253]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19692192604942335		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.19692192604942335 | validation: 0.20139832801951177]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19771099299760012		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.19771099299760012 | validation: 0.1913162746363214]
	TIME [epoch: 11.6 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1965322363755333		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.1965322363755333 | validation: 0.19133461122090453]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1969439098906985		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.1969439098906985 | validation: 0.19350968664244417]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1939449656838813		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.1939449656838813 | validation: 0.19590687847487523]
	TIME [epoch: 11.6 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19463282906697593		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.19463282906697593 | validation: 0.19990925615212404]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20157326673968817		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.20157326673968817 | validation: 0.20347709563311]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20330853492849377		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.20330853492849377 | validation: 0.1943047325530327]
	TIME [epoch: 11.6 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20569533441398763		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.20569533441398763 | validation: 0.20084854538171054]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20789626766680452		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.20789626766680452 | validation: 0.20372799985788217]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20498995379889245		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.20498995379889245 | validation: 0.1985459416448783]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2041596404055364		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.2041596404055364 | validation: 0.18869590657201712]
	TIME [epoch: 11.6 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19853856057718525		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.19853856057718525 | validation: 0.1912461310921314]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1951160744914725		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.1951160744914725 | validation: 0.18743537497049942]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19913862906428215		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.19913862906428215 | validation: 0.19484621596575913]
	TIME [epoch: 11.6 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20079815559822084		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.20079815559822084 | validation: 0.20340048226472626]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20541366078626158		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.20541366078626158 | validation: 0.1974033300130479]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19996521675102225		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.19996521675102225 | validation: 0.19395973525279198]
	TIME [epoch: 11.6 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19757555011968456		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.19757555011968456 | validation: 0.1958745958325061]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19433336620875713		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.19433336620875713 | validation: 0.19160643379800818]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19577623053924453		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.19577623053924453 | validation: 0.19060369445374442]
	TIME [epoch: 11.6 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19819978267202026		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.19819978267202026 | validation: 0.19964992194580894]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2029202565757824		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.2029202565757824 | validation: 0.19787127451894898]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1998209916964319		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.1998209916964319 | validation: 0.19131092674918332]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19938547932232026		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.19938547932232026 | validation: 0.20034127018429101]
	TIME [epoch: 11.6 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20215571749707129		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.20215571749707129 | validation: 0.18753715843795982]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19967865526732156		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.19967865526732156 | validation: 0.1878922417752517]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19850184851527128		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.19850184851527128 | validation: 0.19953931751243317]
	TIME [epoch: 11.6 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19600451910685374		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.19600451910685374 | validation: 0.18693902465084347]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.195573351803363		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.195573351803363 | validation: 0.19155666323842974]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19362312890839786		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.19362312890839786 | validation: 0.18908726661361955]
	TIME [epoch: 11.6 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19799320801280224		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.19799320801280224 | validation: 0.1895051808465631]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19769683165308752		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.19769683165308752 | validation: 0.19513962106957547]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19472555741738942		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.19472555741738942 | validation: 0.1859353951977397]
	TIME [epoch: 11.6 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19147137386779053		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.19147137386779053 | validation: 0.18960329681922602]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18945510079809472		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.18945510079809472 | validation: 0.19127710862592545]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19224176795016484		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.19224176795016484 | validation: 0.19858622629601702]
	TIME [epoch: 11.6 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19115955773920795		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.19115955773920795 | validation: 0.20021756123588513]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19517390847810917		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.19517390847810917 | validation: 0.20053501620837275]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19020569401263396		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.19020569401263396 | validation: 0.18885717098749374]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19154693057420782		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.19154693057420782 | validation: 0.18671822451293643]
	TIME [epoch: 11.6 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19349759360583008		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.19349759360583008 | validation: 0.18708611231369035]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19344026579636175		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.19344026579636175 | validation: 0.19055212868069532]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1901102691085147		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.1901102691085147 | validation: 0.18665678049383938]
	TIME [epoch: 11.6 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19216802397260127		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.19216802397260127 | validation: 0.1938760178602238]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19105259267075125		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.19105259267075125 | validation: 0.19038980850950574]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20541945325864278		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.20541945325864278 | validation: 0.20067298205611153]
	TIME [epoch: 11.6 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19853118957927318		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.19853118957927318 | validation: 0.19018929604025395]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19404427532772317		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.19404427532772317 | validation: 0.19734682534180173]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19274502232063367		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.19274502232063367 | validation: 0.19733575066574752]
	TIME [epoch: 11.6 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19697480757414476		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.19697480757414476 | validation: 0.1890435302711535]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19439664047444832		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.19439664047444832 | validation: 0.1891774439871908]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19477367757498204		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.19477367757498204 | validation: 0.1837323895417067]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19166607467723892		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.19166607467723892 | validation: 0.18254758936605245]
	TIME [epoch: 11.6 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18871389578510303		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.18871389578510303 | validation: 0.2001501397140752]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1917470273239351		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.1917470273239351 | validation: 0.2059218284338653]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19086687173700598		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.19086687173700598 | validation: 0.19182057895083177]
	TIME [epoch: 11.6 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1895045427053612		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.1895045427053612 | validation: 0.18855386653825895]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19367968970205776		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.19367968970205776 | validation: 0.1915289591693772]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18671967446452087		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.18671967446452087 | validation: 0.18468295527350392]
	TIME [epoch: 11.6 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19058454252351908		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.19058454252351908 | validation: 0.17696424838788363]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1969684197240681		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.1969684197240681 | validation: 0.20029730188854167]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19381094760878603		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.19381094760878603 | validation: 0.1937119915552129]
	TIME [epoch: 11.6 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1980247014856548		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.1980247014856548 | validation: 0.18848805274766925]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1950075233294613		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.1950075233294613 | validation: 0.18264617301618394]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19206507596844333		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.19206507596844333 | validation: 0.19020647762731777]
	TIME [epoch: 11.6 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19236321258937344		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.19236321258937344 | validation: 0.18241010181961778]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1927696616045136		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.1927696616045136 | validation: 0.18792465188232554]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19523699385830992		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.19523699385830992 | validation: 0.1979616941441641]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19235793607715995		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.19235793607715995 | validation: 0.19443960559069112]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19247908136491995		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.19247908136491995 | validation: 0.1877510280227451]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18753678814119362		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.18753678814119362 | validation: 0.18944022697923843]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19549093660973177		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.19549093660973177 | validation: 0.1892233014361677]
	TIME [epoch: 11.6 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19105685089622126		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.19105685089622126 | validation: 0.18569010477385323]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19615470483865402		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.19615470483865402 | validation: 0.1886483695480773]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20014221320234543		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.20014221320234543 | validation: 0.19181630045505152]
	TIME [epoch: 11.6 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1974717628155524		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.1974717628155524 | validation: 0.19507998963304934]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20035508283198836		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.20035508283198836 | validation: 0.1927335051015541]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19321244358322573		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.19321244358322573 | validation: 0.20129130506410653]
	TIME [epoch: 11.6 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2012236074448989		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.2012236074448989 | validation: 0.19977296765763256]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19700781940735562		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.19700781940735562 | validation: 0.19382545663400158]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18888783581554403		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.18888783581554403 | validation: 0.18736576519993292]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1891739404762964		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.1891739404762964 | validation: 0.19624511554151142]
	TIME [epoch: 11.6 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19225915355322193		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.19225915355322193 | validation: 0.1966595372060877]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19076757426046773		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.19076757426046773 | validation: 0.18799246588388882]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19533616892292505		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.19533616892292505 | validation: 0.19678738081106267]
	TIME [epoch: 11.6 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18972627040617743		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.18972627040617743 | validation: 0.18806061708880095]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19733147808074591		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.19733147808074591 | validation: 0.18555680737343672]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19678279118069486		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.19678279118069486 | validation: 0.1912386424355438]
	TIME [epoch: 11.6 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19329993451307634		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.19329993451307634 | validation: 0.18811861836773425]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1936083700839626		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.1936083700839626 | validation: 0.1872203084388482]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19877268938884773		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.19877268938884773 | validation: 0.20045759935001933]
	TIME [epoch: 11.6 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.202271181330296		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.202271181330296 | validation: 0.19074160337865448]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1964316304276038		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.1964316304276038 | validation: 0.19208900650353705]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19386836221171236		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.19386836221171236 | validation: 0.19995310839065444]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19962899614449692		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.19962899614449692 | validation: 0.19815729414878624]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2001051260822732		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.2001051260822732 | validation: 0.19640893570659157]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19741688556507458		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.19741688556507458 | validation: 0.1919524568854647]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1932971646227691		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.1932971646227691 | validation: 0.19616997150214005]
	TIME [epoch: 11.6 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19153806169194648		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.19153806169194648 | validation: 0.18559553927272768]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19237873269040198		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.19237873269040198 | validation: 0.19086470401624073]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1917421494832149		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.1917421494832149 | validation: 0.1898579278942165]
	TIME [epoch: 11.6 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19080477583198255		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.19080477583198255 | validation: 0.19059481421450314]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19149608200127144		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.19149608200127144 | validation: 0.18487175337092437]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1948979889642255		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.1948979889642255 | validation: 0.19943629597908538]
	TIME [epoch: 11.6 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1968966246271787		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.1968966246271787 | validation: 0.19394755746382905]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19615568526054364		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.19615568526054364 | validation: 0.19197042632053068]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18956926580890024		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.18956926580890024 | validation: 0.18512793997362395]
	TIME [epoch: 11.6 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19028396779160148		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.19028396779160148 | validation: 0.19225708443606768]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18856472884586373		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.18856472884586373 | validation: 0.18656501432941908]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1908067762626117		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.1908067762626117 | validation: 0.19109582995825983]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18991766302101207		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.18991766302101207 | validation: 0.19252837989426888]
	TIME [epoch: 11.6 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18835270528535064		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.18835270528535064 | validation: 0.19100872106894254]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19041680930735977		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.19041680930735977 | validation: 0.18837391740416506]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19385813655889353		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.19385813655889353 | validation: 0.1851181875663148]
	TIME [epoch: 11.6 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19206033608371853		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.19206033608371853 | validation: 0.18881676253689642]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19189091367357347		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.19189091367357347 | validation: 0.18130731603400832]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19098440542600564		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.19098440542600564 | validation: 0.19145937422884202]
	TIME [epoch: 11.6 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1895769572418317		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.1895769572418317 | validation: 0.1963455874078648]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1900994873647908		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.1900994873647908 | validation: 0.19093702226932227]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1940157990566899		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.1940157990566899 | validation: 0.19878646971820801]
	TIME [epoch: 11.6 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19023821497860813		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.19023821497860813 | validation: 0.18308342652423076]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18744621002780937		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.18744621002780937 | validation: 0.18690480601705314]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19158112814086675		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.19158112814086675 | validation: 0.18979119953750734]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19321773043136847		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.19321773043136847 | validation: 0.20689875251603568]
	TIME [epoch: 11.6 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19551934137030466		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.19551934137030466 | validation: 0.18774368795643095]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19022584010507804		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.19022584010507804 | validation: 0.18894935128371337]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19114071821741258		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.19114071821741258 | validation: 0.18496913783930968]
	TIME [epoch: 11.6 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19035650297401796		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.19035650297401796 | validation: 0.1984081025317095]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1905105644190801		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.1905105644190801 | validation: 0.19468151089119484]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18930242381309548		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.18930242381309548 | validation: 0.1962964055321752]
	TIME [epoch: 11.6 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1972352507548004		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.1972352507548004 | validation: 0.19208077196387305]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19602126972004102		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.19602126972004102 | validation: 0.1877291723348155]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19301577109542245		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.19301577109542245 | validation: 0.19080550277949698]
	TIME [epoch: 11.6 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18781554921013896		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.18781554921013896 | validation: 0.19795638135983623]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18956961941551465		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.18956961941551465 | validation: 0.19368248336491664]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19128883076300593		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.19128883076300593 | validation: 0.18248323072260214]
	TIME [epoch: 11.6 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18923308077227396		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.18923308077227396 | validation: 0.18480601608175704]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19241170744590408		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.19241170744590408 | validation: 0.19241728691253113]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1921234404839019		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.1921234404839019 | validation: 0.18713756363939535]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18702158274663502		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.18702158274663502 | validation: 0.19360996735656372]
	TIME [epoch: 11.6 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19093957018260418		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.19093957018260418 | validation: 0.1849098865389343]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1920422429785068		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.1920422429785068 | validation: 0.19035824662106166]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1906126368182046		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.1906126368182046 | validation: 0.1942814075463506]
	TIME [epoch: 11.6 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18782502494357955		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.18782502494357955 | validation: 0.18080177499380665]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1919053903554333		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.1919053903554333 | validation: 0.19018427357454662]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19402055584438177		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.19402055584438177 | validation: 0.18967118614185288]
	TIME [epoch: 11.6 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19178750642956055		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.19178750642956055 | validation: 0.18749942490717117]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19119059159394353		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.19119059159394353 | validation: 0.18906297079595902]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1853810948354475		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.1853810948354475 | validation: 0.19335431504129483]
	TIME [epoch: 11.6 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19039449384824844		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.19039449384824844 | validation: 0.1822807746142505]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19009951880307385		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.19009951880307385 | validation: 0.18528092259333778]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1922246257753815		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.1922246257753815 | validation: 0.19079828958592718]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188701986506137		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.188701986506137 | validation: 0.1899895862781228]
	TIME [epoch: 11.6 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18887971225751765		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.18887971225751765 | validation: 0.1887597477469148]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18774496617739683		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.18774496617739683 | validation: 0.17915116353446575]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1942918369945518		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.1942918369945518 | validation: 0.1898127199519314]
	TIME [epoch: 11.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18818320766389707		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.18818320766389707 | validation: 0.19110117214164254]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18909756776120248		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.18909756776120248 | validation: 0.18148058908524214]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18804520253137522		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.18804520253137522 | validation: 0.18899149151235434]
	TIME [epoch: 11.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1924048745446702		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.1924048745446702 | validation: 0.18576942375468058]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19072928215749982		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.19072928215749982 | validation: 0.18571639749948374]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1924878986769068		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.1924878986769068 | validation: 0.19179875971292057]
	TIME [epoch: 11.6 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19341496908050368		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.19341496908050368 | validation: 0.1918686391432684]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1897289163066868		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.1897289163066868 | validation: 0.19028845024072166]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.191684464038249		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.191684464038249 | validation: 0.1915398422612806]
	TIME [epoch: 11.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1903302038594206		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.1903302038594206 | validation: 0.18343730389359195]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18965359572821527		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.18965359572821527 | validation: 0.19147000989444687]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1932260843734399		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.1932260843734399 | validation: 0.1906669229336279]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19157776117649924		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.19157776117649924 | validation: 0.1920048012087523]
	TIME [epoch: 11.6 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19216897416745296		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.19216897416745296 | validation: 0.17587639275487682]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1877697315841747		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.1877697315841747 | validation: 0.19025118097849564]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1875131415845272		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.1875131415845272 | validation: 0.17979138199428982]
	TIME [epoch: 11.6 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1890121712839547		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.1890121712839547 | validation: 0.18880580778482356]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1898335329040493		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.1898335329040493 | validation: 0.19313579758216354]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18994329736001994		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.18994329736001994 | validation: 0.18513272109430878]
	TIME [epoch: 11.6 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19226162353023396		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.19226162353023396 | validation: 0.19464419485852574]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1865665493664552		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.1865665493664552 | validation: 0.18452675583206415]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19070703563721142		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.19070703563721142 | validation: 0.1910195238898427]
	TIME [epoch: 11.6 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18839828219358815		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.18839828219358815 | validation: 0.1895249815449716]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19144826296290984		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.19144826296290984 | validation: 0.18199239468298273]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19034466640362577		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.19034466640362577 | validation: 0.19513487856128342]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19374858536042847		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.19374858536042847 | validation: 0.19768564814499548]
	TIME [epoch: 11.6 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1900706573601027		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.1900706573601027 | validation: 0.2006813710839828]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1956615743270052		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.1956615743270052 | validation: 0.1896966888594551]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19317565466366102		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.19317565466366102 | validation: 0.18792740202859753]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1926342425609249		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.1926342425609249 | validation: 0.19354476269034543]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18593878311304815		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.18593878311304815 | validation: 0.18238798732521247]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18858202109908762		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.18858202109908762 | validation: 0.1917003456567555]
	TIME [epoch: 11.6 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19247234361538773		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.19247234361538773 | validation: 0.19923027461554113]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18827771171280572		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.18827771171280572 | validation: 0.18686918697998914]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19214214031833468		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.19214214031833468 | validation: 0.19239761682472697]
	TIME [epoch: 11.6 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18801005098476428		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.18801005098476428 | validation: 0.18534588314003234]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18754620103793546		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.18754620103793546 | validation: 0.19321002034679052]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18869669450939552		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.18869669450939552 | validation: 0.19121893260019338]
	TIME [epoch: 11.6 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1875710827706686		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.1875710827706686 | validation: 0.18367054338212122]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1855169567329745		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.1855169567329745 | validation: 0.1785921957762645]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18750575451592186		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.18750575451592186 | validation: 0.18555847839129874]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1848403161285932		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.1848403161285932 | validation: 0.1900685541913919]
	TIME [epoch: 11.6 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854508058118352		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.1854508058118352 | validation: 0.18157853191406048]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1872576278833692		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.1872576278833692 | validation: 0.18130022681919108]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18568555312712035		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.18568555312712035 | validation: 0.18513445725185523]
	TIME [epoch: 11.6 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1845408437276882		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.1845408437276882 | validation: 0.19303773626772258]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18985495433170996		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.18985495433170996 | validation: 0.18487527629551687]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18966525338626772		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.18966525338626772 | validation: 0.18163705952585865]
	TIME [epoch: 11.6 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1868050543040471		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.1868050543040471 | validation: 0.18474259234101395]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18691482461539677		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.18691482461539677 | validation: 0.18327917421781462]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18543762096792848		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.18543762096792848 | validation: 0.19273599267672836]
	TIME [epoch: 11.6 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18989354294205793		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.18989354294205793 | validation: 0.18717694115634181]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18930144389804396		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.18930144389804396 | validation: 0.18704243792998654]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1873272042094382		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.1873272042094382 | validation: 0.184534615657546]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18875350115212838		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.18875350115212838 | validation: 0.18561642283635268]
	TIME [epoch: 11.6 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18700986766868957		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.18700986766868957 | validation: 0.18480186305719162]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18928341874225896		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.18928341874225896 | validation: 0.19308658637713735]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19064902937995734		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.19064902937995734 | validation: 0.19373385126087272]
	TIME [epoch: 11.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1907643972418031		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.1907643972418031 | validation: 0.1851162455210931]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1931016599007247		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.1931016599007247 | validation: 0.18000156855259727]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18759832646988864		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.18759832646988864 | validation: 0.1881208126939071]
	TIME [epoch: 11.6 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1891756936284929		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.1891756936284929 | validation: 0.1881889242444587]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18952267963064345		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.18952267963064345 | validation: 0.1971637587686506]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1910867817508776		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.1910867817508776 | validation: 0.18080041833229873]
	TIME [epoch: 11.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1852280308806051		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.1852280308806051 | validation: 0.1835414514443717]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18817660402820346		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.18817660402820346 | validation: 0.18653878791066425]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19265913501029278		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.19265913501029278 | validation: 0.18236102474481264]
	TIME [epoch: 11.6 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1865533660646867		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.1865533660646867 | validation: 0.18859927275263239]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19235570191913393		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.19235570191913393 | validation: 0.19091662833995826]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19194539837563906		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.19194539837563906 | validation: 0.1969855162851441]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1922132866769677		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.1922132866769677 | validation: 0.18911637943347195]
	TIME [epoch: 11.6 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19098568750015632		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.19098568750015632 | validation: 0.19040241859649032]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19203879355918363		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.19203879355918363 | validation: 0.1850285835202981]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899279631337839		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.1899279631337839 | validation: 0.19063930118915243]
	TIME [epoch: 11.6 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19170189781122116		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.19170189781122116 | validation: 0.18164852121769992]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19051862581920048		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.19051862581920048 | validation: 0.19059538967002]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18692480149624488		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.18692480149624488 | validation: 0.19650747362649681]
	TIME [epoch: 11.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18928996697441336		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.18928996697441336 | validation: 0.19721175101401278]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19203397221972948		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.19203397221972948 | validation: 0.1960163718644783]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18617419131914645		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.18617419131914645 | validation: 0.1922678787210605]
	TIME [epoch: 11.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18307965309072732		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.18307965309072732 | validation: 0.18620574199896298]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19231398007576847		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.19231398007576847 | validation: 0.17884314779419355]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899259978695698		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.1899259978695698 | validation: 0.18481302912739017]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19297470796819338		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.19297470796819338 | validation: 0.1841184300873888]
	TIME [epoch: 11.6 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18839614843218808		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.18839614843218808 | validation: 0.17932207864360306]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19021635625294958		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.19021635625294958 | validation: 0.18694792389958043]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1895099218435066		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.1895099218435066 | validation: 0.18745050843966968]
	TIME [epoch: 11.6 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18621282888181342		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.18621282888181342 | validation: 0.19196257681369627]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19169119884371932		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.19169119884371932 | validation: 0.18973363992148085]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1922396484283715		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.1922396484283715 | validation: 0.19712020129250196]
	TIME [epoch: 11.6 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18510186755369384		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.18510186755369384 | validation: 0.19050391321607285]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1869262041050272		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.1869262041050272 | validation: 0.18673336320343395]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19200529392987115		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.19200529392987115 | validation: 0.18466848754805218]
	TIME [epoch: 11.6 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19028940771490988		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.19028940771490988 | validation: 0.19152231143754794]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19333571753811274		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.19333571753811274 | validation: 0.19801589079603424]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19216983857031972		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.19216983857031972 | validation: 0.18307759873088025]
	TIME [epoch: 11.6 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18556086831123764		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.18556086831123764 | validation: 0.19184790681965297]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18954354985071037		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.18954354985071037 | validation: 0.18689030865187697]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18911133830368593		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.18911133830368593 | validation: 0.18693855966911863]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1914079032425144		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.1914079032425144 | validation: 0.1903706725346656]
	TIME [epoch: 11.6 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19057891610411132		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.19057891610411132 | validation: 0.18682036477302352]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18722281965361423		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.18722281965361423 | validation: 0.19300020242870963]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19014821407438962		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.19014821407438962 | validation: 0.18570685694670286]
	TIME [epoch: 11.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18942360970571476		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.18942360970571476 | validation: 0.1812164570232033]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18726561209241577		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.18726561209241577 | validation: 0.19348377707157036]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18454719542548415		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.18454719542548415 | validation: 0.17333872140769205]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240310_003030/states/model_tr_study3_1844.pth
	Model improved!!!
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18584249378244166		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.18584249378244166 | validation: 0.1859805443433708]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19274696140210762		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.19274696140210762 | validation: 0.18706738030919465]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19278370120696858		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.19278370120696858 | validation: 0.1915068664113703]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19306857578557712		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.19306857578557712 | validation: 0.18508923070952157]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1913180264936744		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.1913180264936744 | validation: 0.1918137710032583]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18849037874000862		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.18849037874000862 | validation: 0.182999978676065]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1903879493719799		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.1903879493719799 | validation: 0.1803739121283823]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18592546953850236		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.18592546953850236 | validation: 0.18842136390958975]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896500708209669		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.1896500708209669 | validation: 0.1779616557462279]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19343464837235433		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.19343464837235433 | validation: 0.1747001357817471]
	TIME [epoch: 11.6 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19322216409110032		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.19322216409110032 | validation: 0.18670311536200315]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19390714712022436		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.19390714712022436 | validation: 0.17752540029994385]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19090260571095233		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.19090260571095233 | validation: 0.18676796240437926]
	TIME [epoch: 11.6 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19064722099466855		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.19064722099466855 | validation: 0.18275828365892166]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19177926437271164		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.19177926437271164 | validation: 0.18691196443216698]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19241819719926756		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.19241819719926756 | validation: 0.1860961729036226]
	TIME [epoch: 11.6 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1887202089462212		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.1887202089462212 | validation: 0.19302542599773267]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18844594953997873		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.18844594953997873 | validation: 0.1845940866374259]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.187947499473058		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.187947499473058 | validation: 0.17543586316384235]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19013859534509964		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.19013859534509964 | validation: 0.18773585313231395]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18789388545334504		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.18789388545334504 | validation: 0.1839955196433278]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18759067053923809		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.18759067053923809 | validation: 0.1887687777876255]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19045477215799836		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.19045477215799836 | validation: 0.18968916960625276]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1930451920498632		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.1930451920498632 | validation: 0.1792118126118725]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18803153730704103		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.18803153730704103 | validation: 0.1824300576298287]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18794513821953523		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.18794513821953523 | validation: 0.1860241002133855]
	TIME [epoch: 11.6 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18993223653036242		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.18993223653036242 | validation: 0.18103739413519704]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1857836227883155		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.1857836227883155 | validation: 0.18740771512022888]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18848110512865143		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.18848110512865143 | validation: 0.18732917952012862]
	TIME [epoch: 11.6 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19140728862046982		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.19140728862046982 | validation: 0.1877446353766296]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18786215146673577		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.18786215146673577 | validation: 0.18064213329532172]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19036583527831677		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.19036583527831677 | validation: 0.18903167710545288]
	TIME [epoch: 11.6 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19068174995779646		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.19068174995779646 | validation: 0.18722721103723033]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19122428069126943		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.19122428069126943 | validation: 0.19048646520113743]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19141241691680416		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.19141241691680416 | validation: 0.19406766568964925]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1890306156406959		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.1890306156406959 | validation: 0.18292434968247392]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18812820229403157		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.18812820229403157 | validation: 0.1886756850279445]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1876433730041526		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.1876433730041526 | validation: 0.19300598446664785]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1942265479952425		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.1942265479952425 | validation: 0.18631294969527296]
	TIME [epoch: 11.6 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1883549764797488		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.1883549764797488 | validation: 0.18984482557864776]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19080401060101765		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.19080401060101765 | validation: 0.19014842447527236]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1917658527109526		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.1917658527109526 | validation: 0.18539323407133806]
	TIME [epoch: 11.6 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19094343925755514		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.19094343925755514 | validation: 0.18456065631767568]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18490317713946136		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.18490317713946136 | validation: 0.18066773625716906]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18949114613163456		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.18949114613163456 | validation: 0.184298672466131]
	TIME [epoch: 11.6 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18865968907970046		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.18865968907970046 | validation: 0.1852099054907403]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18796295206671448		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.18796295206671448 | validation: 0.1775352805932259]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1853452851154317		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.1853452851154317 | validation: 0.17820671231956994]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18421005289451142		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.18421005289451142 | validation: 0.1907360391603427]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18693594885964354		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.18693594885964354 | validation: 0.18227664219994652]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18699306871421564		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.18699306871421564 | validation: 0.18197729167919818]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18856710411005562		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.18856710411005562 | validation: 0.17874247006044333]
	TIME [epoch: 11.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1882817885189999		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.1882817885189999 | validation: 0.18213214286665788]
	TIME [epoch: 11.5 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19140921089483218		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.19140921089483218 | validation: 0.18762511018931777]
	TIME [epoch: 11.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1889462924665197		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.1889462924665197 | validation: 0.19490401401236948]
	TIME [epoch: 11.6 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18542979818215943		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.18542979818215943 | validation: 0.1855725875436282]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1914664182287663		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.1914664182287663 | validation: 0.18528595895272873]
	TIME [epoch: 11.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18971810346461354		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.18971810346461354 | validation: 0.1859224651470179]
	TIME [epoch: 11.6 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18111419574591386		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.18111419574591386 | validation: 0.1835278658291694]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18581447573387447		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.18581447573387447 | validation: 0.1793518490868837]
	TIME [epoch: 11.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18841372550795948		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.18841372550795948 | validation: 0.18543179331801005]
	TIME [epoch: 11.6 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18557416391468012		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.18557416391468012 | validation: 0.1861885999849393]
	TIME [epoch: 11.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18689080788976356		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.18689080788976356 | validation: 0.1865884500676313]
	TIME [epoch: 11.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18478282613933367		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.18478282613933367 | validation: 0.18630179186508045]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188568134571939		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.188568134571939 | validation: 0.19649428370454292]
	TIME [epoch: 11.6 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19028504305961935		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.19028504305961935 | validation: 0.1846594924550058]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1904149460795166		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.1904149460795166 | validation: 0.1868906612113925]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18660685198589685		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.18660685198589685 | validation: 0.18501788548712775]
	TIME [epoch: 11.6 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19017300458037514		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.19017300458037514 | validation: 0.19345959920708816]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18758044009492572		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.18758044009492572 | validation: 0.18074965318002087]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19045323889091442		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.19045323889091442 | validation: 0.18660333086681127]
	TIME [epoch: 11.6 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1872375275846041		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.1872375275846041 | validation: 0.18596807789144162]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188090755695584		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.188090755695584 | validation: 0.18718150549020834]
	TIME [epoch: 11.5 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18967995133487442		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.18967995133487442 | validation: 0.1894607785359601]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18872960960593427		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.18872960960593427 | validation: 0.18787215159312096]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18427789881786694		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.18427789881786694 | validation: 0.19128604032814658]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18879569520927098		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.18879569520927098 | validation: 0.19712273517818574]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18840343504515863		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.18840343504515863 | validation: 0.18656816992821662]
	TIME [epoch: 11.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18475000882051337		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.18475000882051337 | validation: 0.19858860564346967]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18862216629828366		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.18862216629828366 | validation: 0.18712266879722855]
	TIME [epoch: 11.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19154548296536342		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.19154548296536342 | validation: 0.185051892244321]
	TIME [epoch: 11.6 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19190466269599576		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.19190466269599576 | validation: 0.1976489261130543]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19473957784905332		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.19473957784905332 | validation: 0.18682731716148848]
	TIME [epoch: 11.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1938388975597483		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.1938388975597483 | validation: 0.1859969663649208]
	TIME [epoch: 11.6 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18765741683311407		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.18765741683311407 | validation: 0.1873280766200336]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18935014528422184		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.18935014528422184 | validation: 0.18867092270996544]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18863013768567363		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.18863013768567363 | validation: 0.18375603354291717]
	TIME [epoch: 11.6 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18673448248164076		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.18673448248164076 | validation: 0.18079297994254934]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19350408885534592		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.19350408885534592 | validation: 0.1908685559794769]
	TIME [epoch: 11.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18960916031460212		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.18960916031460212 | validation: 0.18256809628814125]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19319799822111677		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.19319799822111677 | validation: 0.18992341129266466]
	TIME [epoch: 11.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19031298554769227		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.19031298554769227 | validation: 0.18906874981632105]
	TIME [epoch: 11.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18969796109980655		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.18969796109980655 | validation: 0.18766429703633147]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18805158768081984		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.18805158768081984 | validation: 0.18044485738639984]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18952070532962723		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.18952070532962723 | validation: 0.1787283968928513]
	TIME [epoch: 11.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1840096537198235		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.1840096537198235 | validation: 0.1814832709832038]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18842309374805868		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.18842309374805868 | validation: 0.18263996099270258]
	TIME [epoch: 11.6 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18897010710937007		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.18897010710937007 | validation: 0.19140060055709587]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18707340071103756		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.18707340071103756 | validation: 0.17778965015643686]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1885242963875031		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.1885242963875031 | validation: 0.18063620165401695]
	TIME [epoch: 11.6 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.190034358957845		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.190034358957845 | validation: 0.1821798058358425]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18692898635231514		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.18692898635231514 | validation: 0.18720097957739654]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19160222070175553		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.19160222070175553 | validation: 0.18575384190676705]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18861963192906425		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.18861963192906425 | validation: 0.17665447337773363]
	TIME [epoch: 11.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899662166657447		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.1899662166657447 | validation: 0.18418683146801573]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1897108799065112		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.1897108799065112 | validation: 0.18644121563950067]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1906553594569874		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.1906553594569874 | validation: 0.18864603955220205]
	TIME [epoch: 11.5 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18580481399076906		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.18580481399076906 | validation: 0.1956057708041554]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18691439786791797		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.18691439786791797 | validation: 0.18640398870626895]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18983483203379228		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.18983483203379228 | validation: 0.18007929714536838]
	TIME [epoch: 11.6 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19016671009666586		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.19016671009666586 | validation: 0.19672640715557044]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18631366325049062		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.18631366325049062 | validation: 0.1932527409070584]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18500877479316621		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.18500877479316621 | validation: 0.18171510662108417]
	TIME [epoch: 11.6 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.189920363465691		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.189920363465691 | validation: 0.18913926870350928]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19507465020721115		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.19507465020721115 | validation: 0.18618551673533376]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1890746987050138		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.1890746987050138 | validation: 0.1874695743878987]
	TIME [epoch: 11.6 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18950952824177553		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.18950952824177553 | validation: 0.17437578950937999]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19342595836892304		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.19342595836892304 | validation: 0.18347916567467304]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19312119439047173		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.19312119439047173 | validation: 0.18966824599857796]
	TIME [epoch: 11.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1860520555452972		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.1860520555452972 | validation: 0.18657946882826779]
	TIME [epoch: 11.5 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18643759612709235		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.18643759612709235 | validation: 0.17712990410117016]
	TIME [epoch: 11.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18631660505573994		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.18631660505573994 | validation: 0.19459618000829237]
	TIME [epoch: 11.5 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18844009035413717		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.18844009035413717 | validation: 0.18448726790641318]
	TIME [epoch: 11.6 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18818240434098304		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.18818240434098304 | validation: 0.17694172447233214]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1853246832196114		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.1853246832196114 | validation: 0.18778150857383277]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18636493295272974		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.18636493295272974 | validation: 0.1882769399592172]
	TIME [epoch: 11.6 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18407658953209624		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.18407658953209624 | validation: 0.18391788429010325]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18866203303757428		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.18866203303757428 | validation: 0.18574485735724935]
	TIME [epoch: 11.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18931292443004233		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.18931292443004233 | validation: 0.1801646544421335]
	TIME [epoch: 11.6 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1848489083358553		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.1848489083358553 | validation: 0.18629396939075343]
	TIME [epoch: 11.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188432136048768		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.188432136048768 | validation: 0.19187669640330196]
	TIME [epoch: 11.5 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18757804116433496		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.18757804116433496 | validation: 0.18529881514669264]
	TIME [epoch: 11.6 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18809384308353885		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.18809384308353885 | validation: 0.19243505693139973]
	TIME [epoch: 11.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19269855280642326		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.19269855280642326 | validation: 0.1817582748666631]
	TIME [epoch: 11.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18881524966306856		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.18881524966306856 | validation: 0.18809822622349046]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1895125481652268		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.1895125481652268 | validation: 0.1915557877002009]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18863072862444055		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.18863072862444055 | validation: 0.18430891383546083]
	TIME [epoch: 11.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19192548443431745		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.19192548443431745 | validation: 0.1839424245267184]
	TIME [epoch: 11.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18866333974483046		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.18866333974483046 | validation: 0.1898000613108926]
	TIME [epoch: 11.6 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.192182302651401		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.192182302651401 | validation: 0.19824219660323522]
	TIME [epoch: 11.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19011476594454876		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.19011476594454876 | validation: 0.19187710659351276]
	TIME [epoch: 11.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19010771028962348		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.19010771028962348 | validation: 0.1959458941275209]
	TIME [epoch: 11.6 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19007890689017554		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.19007890689017554 | validation: 0.19509621671170924]
	TIME [epoch: 11.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19325620059926302		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.19325620059926302 | validation: 0.18445085069049585]
	TIME [epoch: 11.5 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19096224521631391		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.19096224521631391 | validation: 0.18834069626302316]
	TIME [epoch: 11.6 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1921091241308719		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.1921091241308719 | validation: 0.18619835483155264]
	TIME [epoch: 11.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19477952932720569		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.19477952932720569 | validation: 0.1968316156803607]
	TIME [epoch: 11.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19163160527510975		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.19163160527510975 | validation: 0.18546927142096847]
	TIME [epoch: 11.6 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1970196094093245		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.1970196094093245 | validation: 0.1877563895034933]
	TIME [epoch: 11.5 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1929055607769707		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.1929055607769707 | validation: 0.197273549323197]
	TIME [epoch: 11.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18981773454259562		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.18981773454259562 | validation: 0.19446938401950434]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1882300114531727		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.1882300114531727 | validation: 0.18929094136344343]
	TIME [epoch: 11.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19192471477488193		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.19192471477488193 | validation: 0.190432549359359]
	TIME [epoch: 11.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1870148275320326		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.1870148275320326 | validation: 0.18989986400551637]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19081196841124992		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.19081196841124992 | validation: 0.19218656848890642]
	TIME [epoch: 11.6 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19015506537616997		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.19015506537616997 | validation: 0.19011934632090022]
	TIME [epoch: 11.5 sec]
Finished training in 23314.323 seconds.
