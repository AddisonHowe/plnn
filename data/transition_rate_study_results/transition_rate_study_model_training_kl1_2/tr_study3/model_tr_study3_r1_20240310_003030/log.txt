Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r1', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1924288627

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.350207172334215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.350207172334215 | validation: 9.414417036330168]
	TIME [epoch: 100 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.441161417940844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.441161417940844 | validation: 8.837769313123129]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.364706764230233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.364706764230233 | validation: 7.919316683560374]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.630237419613083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.630237419613083 | validation: 6.996467529250538]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.206045866991962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.206045866991962 | validation: 6.885681937442944]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.885101273118502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.885101273118502 | validation: 6.476729391572234]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.795776871982021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.795776871982021 | validation: 6.753407123577154]
	TIME [epoch: 11.5 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.477754786192195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.477754786192195 | validation: 6.3015447654474075]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.296107614433078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.296107614433078 | validation: 6.398438859176593]
	TIME [epoch: 11.6 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.219565518532832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.219565518532832 | validation: 6.111647063147877]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.178398801925025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.178398801925025 | validation: 6.159396580676983]
	TIME [epoch: 11.6 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.964477682405974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.964477682405974 | validation: 6.040205620689606]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.825111902633264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.825111902633264 | validation: 5.963425326088586]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7847923370082475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7847923370082475 | validation: 5.886289080302422]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.913862616443994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.913862616443994 | validation: 6.3145380839911995]
	TIME [epoch: 11.6 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.848141880572328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.848141880572328 | validation: 5.836766228872595]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.687182055330963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.687182055330963 | validation: 5.878478155769904]
	TIME [epoch: 11.6 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.68653281080318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.68653281080318 | validation: 5.913293942957704]
	TIME [epoch: 11.6 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.697436843734079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.697436843734079 | validation: 6.082625902851593]
	TIME [epoch: 11.6 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.677651960364924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.677651960364924 | validation: 5.707759961259092]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.56661752541741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.56661752541741 | validation: 5.8358620571424185]
	TIME [epoch: 11.6 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.680439755099883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.680439755099883 | validation: 6.0038261679127025]
	TIME [epoch: 11.6 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.632489423834072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.632489423834072 | validation: 6.614789944547028]
	TIME [epoch: 11.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.761388833133918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.761388833133918 | validation: 5.73605263277673]
	TIME [epoch: 11.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5747103773928846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5747103773928846 | validation: 5.7707231838157576]
	TIME [epoch: 11.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.480772246747496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.480772246747496 | validation: 5.562337828147063]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.462490062155915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.462490062155915 | validation: 5.658095431296517]
	TIME [epoch: 11.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.401356291158954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.401356291158954 | validation: 5.548158605925419]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.411622356737252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.411622356737252 | validation: 5.24722087749058]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.435791867155288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.435791867155288 | validation: 6.9679228862253915]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9939768949148045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9939768949148045 | validation: 5.288020642099691]
	TIME [epoch: 11.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.184560178706659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.184560178706659 | validation: 5.195180511811107]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.294810415420856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.294810415420856 | validation: 5.363587318325206]
	TIME [epoch: 11.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.145877717004167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.145877717004167 | validation: 5.212538214695865]
	TIME [epoch: 11.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.146213065011725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.146213065011725 | validation: 5.093020616128396]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1354181202736395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1354181202736395 | validation: 5.499902166260799]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.099546996066168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.099546996066168 | validation: 4.796788244299155]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.888692694136173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.888692694136173 | validation: 4.8414744200276685]
	TIME [epoch: 11.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.716720559481771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.716720559481771 | validation: 4.7805281001314235]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.854627268117419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.854627268117419 | validation: 4.961554547658972]
	TIME [epoch: 11.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.782441748602777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.782441748602777 | validation: 4.506863379427176]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452379458916175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.452379458916175 | validation: 4.3447235173256455]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.550677201769804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.550677201769804 | validation: 4.374987788955103]
	TIME [epoch: 11.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.288851649968932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.288851649968932 | validation: 4.156785897072049]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.017327143683414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.017327143683414 | validation: 4.80572425679037]
	TIME [epoch: 11.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1105194517512995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1105194517512995 | validation: 4.242625585256425]
	TIME [epoch: 11.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9367670036057314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9367670036057314 | validation: 4.07310966252941]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.436902012757933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.436902012757933 | validation: 3.780468645837926]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.084061850068246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.084061850068246 | validation: 3.7661386748977193]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8869165751831165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8869165751831165 | validation: 3.597803179204395]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.437864547997533		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.437864547997533 | validation: 3.0430161820761574]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7228261301327095		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.7228261301327095 | validation: 3.9617510279311]
	TIME [epoch: 11.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4716650742554576		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.4716650742554576 | validation: 3.259928545360071]
	TIME [epoch: 11.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.033478133242746		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.033478133242746 | validation: 3.1535053682955776]
	TIME [epoch: 11.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.917363764227571		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.917363764227571 | validation: 3.362740816717503]
	TIME [epoch: 11.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.697164075658787		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.697164075658787 | validation: 2.911697874465951]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4896526506016645		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.4896526506016645 | validation: 3.2303183858957714]
	TIME [epoch: 11.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.893101467099388		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.893101467099388 | validation: 2.9420328982674704]
	TIME [epoch: 11.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7149424013464354		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.7149424013464354 | validation: 2.490877105098828]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.714240384448555		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.714240384448555 | validation: 3.059130227039763]
	TIME [epoch: 11.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6478251038169796		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.6478251038169796 | validation: 2.180185488466756]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5888993946938865		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.5888993946938865 | validation: 2.234651601907925]
	TIME [epoch: 11.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.351906314409219		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.351906314409219 | validation: 2.414504848375707]
	TIME [epoch: 11.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286157550440821		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.286157550440821 | validation: 2.0330618761156187]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2039033176257172		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.2039033176257172 | validation: 2.44338660930381]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2827519388022495		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.2827519388022495 | validation: 2.428688937670479]
	TIME [epoch: 11.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2816041374545737		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.2816041374545737 | validation: 3.657476389617331]
	TIME [epoch: 11.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.585537180713413		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.585537180713413 | validation: 2.27723454564618]
	TIME [epoch: 11.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.996416106760438		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.996416106760438 | validation: 1.9785858715573]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.117968815727551		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.117968815727551 | validation: 2.17404510092678]
	TIME [epoch: 11.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2103844452731236		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.2103844452731236 | validation: 1.9433885500797141]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8856772039660137		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.8856772039660137 | validation: 1.6889953238317583]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8760596780528611		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.8760596780528611 | validation: 1.7698339412155237]
	TIME [epoch: 11.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8276098003495205		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.8276098003495205 | validation: 1.8803480829969845]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4090043739513396		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.4090043739513396 | validation: 2.124477159082352]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.006673425876875		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.006673425876875 | validation: 2.497273240972833]
	TIME [epoch: 11.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1367321916584183		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.1367321916584183 | validation: 2.5925486941345905]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.112886576895639		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.112886576895639 | validation: 1.742949588810071]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8743284566456282		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.8743284566456282 | validation: 1.7839303408105758]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.673061515753021		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.673061515753021 | validation: 1.8485962224808064]
	TIME [epoch: 11.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9088700043755504		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.9088700043755504 | validation: 3.9740417278677684]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6032162871359597		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.6032162871359597 | validation: 1.8112985558872674]
	TIME [epoch: 11.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8166531496679785		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.8166531496679785 | validation: 1.9250678330474278]
	TIME [epoch: 11.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8460785555809371		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.8460785555809371 | validation: 2.0817140601819712]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7982389812038198		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.7982389812038198 | validation: 1.788258890761478]
	TIME [epoch: 11.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9336972780609438		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.9336972780609438 | validation: 2.9914050805219676]
	TIME [epoch: 11.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.409581387627616		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.409581387627616 | validation: 2.068717282111775]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.008827513181523		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.008827513181523 | validation: 2.8308316266397218]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0661136467997867		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.0661136467997867 | validation: 2.1440513814101307]
	TIME [epoch: 11.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9903747285752327		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.9903747285752327 | validation: 1.4223361093651579]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5583225766801503		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.5583225766801503 | validation: 1.5342043846059088]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.538207720338033		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.538207720338033 | validation: 1.624457113568671]
	TIME [epoch: 11.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1449051937418933		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.1449051937418933 | validation: 2.1629032810399265]
	TIME [epoch: 11.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9073817196684484		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.9073817196684484 | validation: 1.2784129903609784]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7721134492511836		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.7721134492511836 | validation: 1.733264392727298]
	TIME [epoch: 11.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8136639460889628		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.8136639460889628 | validation: 1.5070203737305354]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8302246409448935		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.8302246409448935 | validation: 2.1779587929046436]
	TIME [epoch: 11.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7591991142127688		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.7591991142127688 | validation: 1.6286776736183861]
	TIME [epoch: 11.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6700746787596277		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.6700746787596277 | validation: 1.3363260500066587]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3973729273254953		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.3973729273254953 | validation: 1.6426910747412367]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.702498688496433		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.702498688496433 | validation: 1.5133342520733135]
	TIME [epoch: 11.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.116742529191925		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.116742529191925 | validation: 2.945969150722659]
	TIME [epoch: 11.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.23956740757962		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.23956740757962 | validation: 1.6337741605732157]
	TIME [epoch: 11.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6613134635053357		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.6613134635053357 | validation: 1.449029639509538]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.925943514726056		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.925943514726056 | validation: 1.2905598599798704]
	TIME [epoch: 11.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6487137357584842		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.6487137357584842 | validation: 1.258969758362177]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7293569535499813		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.7293569535499813 | validation: 3.5472735764428056]
	TIME [epoch: 11.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3490032644434944		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.3490032644434944 | validation: 1.7734979284007175]
	TIME [epoch: 11.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.606376407038423		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.606376407038423 | validation: 2.3028988498030873]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7905258737183425		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.7905258737183425 | validation: 1.2698112835348172]
	TIME [epoch: 11.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5489010335244902		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.5489010335244902 | validation: 1.1402768421414349]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6210232444146826		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.6210232444146826 | validation: 1.2217806037707366]
	TIME [epoch: 11.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6448729213488849		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.6448729213488849 | validation: 1.4166382990961657]
	TIME [epoch: 11.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.646580315627871		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.646580315627871 | validation: 1.804196710257723]
	TIME [epoch: 11.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.651531414205366		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.651531414205366 | validation: 1.2138230329690174]
	TIME [epoch: 11.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5736304772520224		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.5736304772520224 | validation: 1.1524511034672023]
	TIME [epoch: 11.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.543639059359859		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.543639059359859 | validation: 1.2665713479746883]
	TIME [epoch: 11.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.393680481431033		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.393680481431033 | validation: 1.7034263139189387]
	TIME [epoch: 11.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4364199734214615		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.4364199734214615 | validation: 1.1689045684594799]
	TIME [epoch: 11.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1804647419065941		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.1804647419065941 | validation: 1.2238365820594335]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3017463730064798		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.3017463730064798 | validation: 1.362540025068126]
	TIME [epoch: 11.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7026548744093055		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.7026548744093055 | validation: 1.7137042466709382]
	TIME [epoch: 11.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5723664650032851		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.5723664650032851 | validation: 1.0606944944823014]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.290679477998617		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.290679477998617 | validation: 1.3725511014156415]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1447478885245097		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.1447478885245097 | validation: 1.3180451398560995]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4992220315597278		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.4992220315597278 | validation: 1.9575912689724952]
	TIME [epoch: 11.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6046405863166227		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.6046405863166227 | validation: 1.1385521668437921]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3386522918693695		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.3386522918693695 | validation: 0.97481100027299]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.79858723769035		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.79858723769035 | validation: 2.0022463739498515]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7652063535458584		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.7652063535458584 | validation: 4.543230700583221]
	TIME [epoch: 11.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.869041022763959		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.869041022763959 | validation: 1.046434284004695]
	TIME [epoch: 11.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0618196926337549		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.0618196926337549 | validation: 0.9593240240401082]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3097714059896155		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.3097714059896155 | validation: 1.0241758026827665]
	TIME [epoch: 11.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1161030191977117		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.1161030191977117 | validation: 0.8835697354696762]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9956422782410663		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.9956422782410663 | validation: 1.0459573092054064]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1940393648390006		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.1940393648390006 | validation: 0.9666107218467141]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153831930910533		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.153831930910533 | validation: 0.9248876384133674]
	TIME [epoch: 11.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0427870090168003		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.0427870090168003 | validation: 0.9340474165284937]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5165633750044067		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.5165633750044067 | validation: 2.0665614937689476]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7684526319223568		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.7684526319223568 | validation: 1.017403131882566]
	TIME [epoch: 11.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1225635356206278		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.1225635356206278 | validation: 1.0738755196679308]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4527561267670903		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.4527561267670903 | validation: 1.0071297987844343]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3187580358777706		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.3187580358777706 | validation: 1.40911477469754]
	TIME [epoch: 11.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2849571765580918		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.2849571765580918 | validation: 1.0345204654453728]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0350007942075365		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.0350007942075365 | validation: 1.0666349426178567]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1781253577754525		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.1781253577754525 | validation: 1.163050321603719]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3026457822400987		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.3026457822400987 | validation: 1.13223989911554]
	TIME [epoch: 11.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1403900548887647		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.1403900548887647 | validation: 1.2986095452670323]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4803569491814104		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.4803569491814104 | validation: 2.3779298481032787]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6660444292597167		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.6660444292597167 | validation: 1.082369875471603]
	TIME [epoch: 11.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2375083169556538		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.2375083169556538 | validation: 1.0553642946323551]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.306933748724859		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.306933748724859 | validation: 1.0736648746780655]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2915902151576886		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.2915902151576886 | validation: 1.2062885601975197]
	TIME [epoch: 11.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2015269445519892		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.2015269445519892 | validation: 1.5142909513647294]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3254424342806628		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.3254424342806628 | validation: 1.1887036696502111]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2105244473748484		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.2105244473748484 | validation: 1.045789079136551]
	TIME [epoch: 11.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1940716175327244		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.1940716175327244 | validation: 1.050875409784379]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0934490128768655		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.0934490128768655 | validation: 0.9551692658472039]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1283669390157873		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.1283669390157873 | validation: 1.174364615062969]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9615690790152303		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.9615690790152303 | validation: 1.0866767366233059]
	TIME [epoch: 11.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0914358379938482		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.0914358379938482 | validation: 1.1443173493174903]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.048806846186847		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.048806846186847 | validation: 1.0397649876552961]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.896185278130324		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.896185278130324 | validation: 1.149921249182342]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2605842351050915		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.2605842351050915 | validation: 1.102416000534257]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060299013528214		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.060299013528214 | validation: 1.0009000039824796]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.392149406282683		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.392149406282683 | validation: 0.9743934070678175]
	TIME [epoch: 11.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3031183047884944		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.3031183047884944 | validation: 1.0380690727011481]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.123581971090822		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.123581971090822 | validation: 0.95840744139025]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1645342979864761		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.1645342979864761 | validation: 1.1636424238849254]
	TIME [epoch: 11.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.169185404620726		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.169185404620726 | validation: 0.9724244613623096]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2356668779348208		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.2356668779348208 | validation: 1.026588170818284]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0524180810420396		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.0524180810420396 | validation: 1.8553649082362054]
	TIME [epoch: 11.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.555635184058682		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.555635184058682 | validation: 1.1628928820177193]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1442275926824599		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.1442275926824599 | validation: 1.02772976450729]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.129843896430096		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.129843896430096 | validation: 1.4835068069652448]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2248817526484859		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.2248817526484859 | validation: 1.5294536886473395]
	TIME [epoch: 11.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2592342977969893		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.2592342977969893 | validation: 0.9033187345244489]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0979021795905195		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.0979021795905195 | validation: 0.9611067895507032]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4026664070084929		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.4026664070084929 | validation: 1.001814686460889]
	TIME [epoch: 11.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1480700924766332		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.1480700924766332 | validation: 0.8834897253174834]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9274746915276173		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.9274746915276173 | validation: 0.7368648618673049]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8336044455303524		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.8336044455303524 | validation: 0.9684164211591404]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9770973258045141		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.9770973258045141 | validation: 0.9190850354282495]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8580935456531569		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.8580935456531569 | validation: 0.8021649839639358]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9246401547683671		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.9246401547683671 | validation: 1.1966360382453365]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.107788236845163		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.107788236845163 | validation: 0.8035775236184182]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8800126071933707		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.8800126071933707 | validation: 1.0477902682072682]
	TIME [epoch: 11.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.838888937723014		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.838888937723014 | validation: 0.970957696530734]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0943417941406552		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.0943417941406552 | validation: 0.9701877198474449]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7792096503274115		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.7792096503274115 | validation: 0.9503325655918559]
	TIME [epoch: 11.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9371813537277699		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.9371813537277699 | validation: 0.9178338966243809]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.463316884279044		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.463316884279044 | validation: 1.6062826159225057]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.298742189948138		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.298742189948138 | validation: 1.0383015010464414]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.950463420524843		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.950463420524843 | validation: 0.8759509137968436]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9743855416822548		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.9743855416822548 | validation: 1.0273895470643217]
	TIME [epoch: 11.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9943126347012479		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.9943126347012479 | validation: 1.6172226273756543]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.091693941886117		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.091693941886117 | validation: 0.8527857232856525]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8700495332395309		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.8700495332395309 | validation: 1.4426514065761709]
	TIME [epoch: 11.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3126466844548805		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.3126466844548805 | validation: 0.8510914032805594]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9690043502689365		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.9690043502689365 | validation: 1.036801200903717]
	TIME [epoch: 11.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9753134568303505		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.9753134568303505 | validation: 1.0914600658126077]
	TIME [epoch: 11.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0893517711782457		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.0893517711782457 | validation: 0.850604449075658]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9895110717478277		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.9895110717478277 | validation: 0.8773456697535613]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9413011967963897		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.9413011967963897 | validation: 0.8750523397293181]
	TIME [epoch: 11.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.844678364052835		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.844678364052835 | validation: 1.5632912813257998]
	TIME [epoch: 11.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1358571078946755		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.1358571078946755 | validation: 0.7340295143101753]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9019341943422388		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.9019341943422388 | validation: 1.062721631156284]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9221229801324766		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.9221229801324766 | validation: 0.9500459701386327]
	TIME [epoch: 11.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8090613127198607		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.8090613127198607 | validation: 0.6742695202466462]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8080350440148518		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.8080350440148518 | validation: 1.1612343220720065]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0385208419139607		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.0385208419139607 | validation: 0.8444009173888282]
	TIME [epoch: 11.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7542561454148424		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.7542561454148424 | validation: 0.6845380173860711]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8235853637714434		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.8235853637714434 | validation: 0.7856069434906194]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8255466037755101		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.8255466037755101 | validation: 0.8455753323084184]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7833857406972919		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.7833857406972919 | validation: 0.738605853681623]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.814974226363595		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.814974226363595 | validation: 0.7339253735948174]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025022601283403		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.025022601283403 | validation: 1.1370772615786533]
	TIME [epoch: 11.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0232350709920695		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.0232350709920695 | validation: 0.9316661406708611]
	TIME [epoch: 11.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.929367279235232		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.929367279235232 | validation: 1.0043146818796844]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9752228896186468		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.9752228896186468 | validation: 0.8405718719921024]
	TIME [epoch: 11.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0454858803344773		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.0454858803344773 | validation: 0.8849140379182495]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6564134643766847		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.6564134643766847 | validation: 0.9774227618791946]
	TIME [epoch: 11.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7565040412846175		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.7565040412846175 | validation: 0.7887572421672283]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7714701514284393		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.7714701514284393 | validation: 0.6782800930228302]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212269661285435		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.7212269661285435 | validation: 0.8219471979352565]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0130883731127205		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.0130883731127205 | validation: 1.0028506091062925]
	TIME [epoch: 11.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9958101159638543		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.9958101159638543 | validation: 0.8786812362804568]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9173546747219073		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.9173546747219073 | validation: 0.7954566782096956]
	TIME [epoch: 11.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7959457706120698		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.7959457706120698 | validation: 0.9104197543468593]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8934611955024991		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.8934611955024991 | validation: 0.8706770881228363]
	TIME [epoch: 11.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8976356588420464		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.8976356588420464 | validation: 0.737812200403093]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9323995337107982		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.9323995337107982 | validation: 0.7442820801399584]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688472542082865		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.7688472542082865 | validation: 0.6921582633913187]
	TIME [epoch: 11.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7515953665692531		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.7515953665692531 | validation: 0.9385760244339776]
	TIME [epoch: 11.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8037292386251085		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.8037292386251085 | validation: 0.906119925002422]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170670381816642		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.7170670381816642 | validation: 0.5965517534771198]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7592878999463333		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.7592878999463333 | validation: 0.7217595858460081]
	TIME [epoch: 11.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7233981239029916		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.7233981239029916 | validation: 1.0773036484881795]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1042866007280951		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.1042866007280951 | validation: 0.6770795182718472]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9155586867188117		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.9155586867188117 | validation: 0.9446970959995216]
	TIME [epoch: 11.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8801794462176551		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.8801794462176551 | validation: 0.8799462953067597]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8741022754812745		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.8741022754812745 | validation: 1.5157308075188354]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1304565815935395		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.1304565815935395 | validation: 0.7807408302577948]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8153911567774785		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.8153911567774785 | validation: 0.7050869424349782]
	TIME [epoch: 11.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7851750819300279		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.7851750819300279 | validation: 1.5137748207586064]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3784729684439436		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.3784729684439436 | validation: 1.1045345327924656]
	TIME [epoch: 11.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9449896152604067		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.9449896152604067 | validation: 0.710241755263587]
	TIME [epoch: 11.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7985026838852957		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.7985026838852957 | validation: 0.8508295772046712]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7351067583503793		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.7351067583503793 | validation: 0.7023058793533864]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6148906024593126		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.6148906024593126 | validation: 0.8599988899319553]
	TIME [epoch: 11.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9129980371601183		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.9129980371601183 | validation: 0.714677083384503]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833818363788363		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.6833818363788363 | validation: 1.353960435422809]
	TIME [epoch: 11.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9786232496462252		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.9786232496462252 | validation: 1.2571932361311702]
	TIME [epoch: 11.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1786625142708818		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.1786625142708818 | validation: 1.2377765542470505]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9498757601981216		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.9498757601981216 | validation: 0.6757699633142616]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7928022001516636		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7928022001516636 | validation: 1.2205479031542097]
	TIME [epoch: 11.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9896889900032708		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.9896889900032708 | validation: 0.6159402525429234]
	TIME [epoch: 11.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914496304388321		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.6914496304388321 | validation: 1.0288200937513228]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7629732779114131		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.7629732779114131 | validation: 0.6073264683522653]
	TIME [epoch: 11.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5589783690554123		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.5589783690554123 | validation: 0.757782777814911]
	TIME [epoch: 11.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9866360252026475		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.9866360252026475 | validation: 0.8828628862653385]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9497480160909106		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.9497480160909106 | validation: 0.8560000857047007]
	TIME [epoch: 11.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9051594524623541		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.9051594524623541 | validation: 0.8196425201637504]
	TIME [epoch: 11.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9750686675564877		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.9750686675564877 | validation: 0.9170863427427457]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0502006745035375		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.0502006745035375 | validation: 0.9334953380290929]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8893242625036211		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.8893242625036211 | validation: 0.7537976233194518]
	TIME [epoch: 11.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.899405684755514		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.899405684755514 | validation: 0.9262291816678729]
	TIME [epoch: 11.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8599040337366871		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.8599040337366871 | validation: 1.0766131816517122]
	TIME [epoch: 11.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9095180871196025		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.9095180871196025 | validation: 0.6280851808761173]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6669740030529809		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.6669740030529809 | validation: 0.6883035921924117]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6582987658032672		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.6582987658032672 | validation: 0.8616598662709843]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7304656575960404		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.7304656575960404 | validation: 0.6476560816514824]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7141788795336776		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.7141788795336776 | validation: 1.2371965806054672]
	TIME [epoch: 11.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9901486082174316		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.9901486082174316 | validation: 0.6997203836812039]
	TIME [epoch: 11.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7568840965414375		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.7568840965414375 | validation: 0.9917478947627953]
	TIME [epoch: 11.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7414766673340044		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.7414766673340044 | validation: 0.6038995881319965]
	TIME [epoch: 11.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5992656788741184		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.5992656788741184 | validation: 0.7544048802683153]
	TIME [epoch: 11.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8350740520973108		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.8350740520973108 | validation: 0.9874400634012969]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9179661158387243		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.9179661158387243 | validation: 0.921195787326196]
	TIME [epoch: 11.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8223648118850646		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.8223648118850646 | validation: 1.338361861174498]
	TIME [epoch: 11.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9194318696249417		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.9194318696249417 | validation: 0.6393206464855907]
	TIME [epoch: 11.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7021540783267033		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7021540783267033 | validation: 1.0904471096153434]
	TIME [epoch: 11.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8787685006489444		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.8787685006489444 | validation: 0.6499687322165612]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6089612180561259		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.6089612180561259 | validation: 0.6832382260184383]
	TIME [epoch: 11.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6508730527067738		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.6508730527067738 | validation: 0.5649967213042285]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6753551629940192		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.6753551629940192 | validation: 0.8388413733422053]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812830424814734		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6812830424814734 | validation: 0.5860728855752302]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5747140995953294		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.5747140995953294 | validation: 0.7238298348407071]
	TIME [epoch: 11.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9002396260859327		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.9002396260859327 | validation: 1.176856777994154]
	TIME [epoch: 11.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7980237343727117		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.7980237343727117 | validation: 0.5434436844112767]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7337669322071338		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.7337669322071338 | validation: 0.8621301558631761]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9064828727667442		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.9064828727667442 | validation: 0.7858945036673185]
	TIME [epoch: 11.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8687471954892398		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.8687471954892398 | validation: 0.5673222609157008]
	TIME [epoch: 11.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731667573332459		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.731667573332459 | validation: 0.5461172071452499]
	TIME [epoch: 11.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7382276283364588		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.7382276283364588 | validation: 0.7341178907267915]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6267875450255195		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.6267875450255195 | validation: 0.7408302691335201]
	TIME [epoch: 11.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974054258490564		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.6974054258490564 | validation: 0.8179455931928287]
	TIME [epoch: 11.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5854630177626771		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.5854630177626771 | validation: 0.7097082757240735]
	TIME [epoch: 11.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7156224443402429		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.7156224443402429 | validation: 0.7318944099976629]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6357284712403284		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.6357284712403284 | validation: 0.5153702546979261]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8066084947141201		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.8066084947141201 | validation: 0.7796388864901846]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6795473571974544		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6795473571974544 | validation: 0.49308338840081223]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46087939692491575		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.46087939692491575 | validation: 0.5322131907769836]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4983721334998435		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.4983721334998435 | validation: 0.8625148518572382]
	TIME [epoch: 11.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6293188599018664		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.6293188599018664 | validation: 0.5794661293851892]
	TIME [epoch: 11.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5777549635073589		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.5777549635073589 | validation: 0.7516021790151297]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.590208894637155		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.590208894637155 | validation: 0.9606096201959697]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7390690913304387		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.7390690913304387 | validation: 0.5316044821764241]
	TIME [epoch: 11.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5336698186846718		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.5336698186846718 | validation: 0.5440924575017586]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5111805012052038		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.5111805012052038 | validation: 0.47736370176596427]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6042705623017324		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.6042705623017324 | validation: 0.6260048697359684]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5874622072413593		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5874622072413593 | validation: 0.7146749214198885]
	TIME [epoch: 11.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6949517584990248		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.6949517584990248 | validation: 0.6392973516818575]
	TIME [epoch: 11.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6190682704381321		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.6190682704381321 | validation: 1.0620058312518899]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0042288530545422		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.0042288530545422 | validation: 0.8913953427158927]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8497312257415817		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.8497312257415817 | validation: 0.6982203268802026]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7093127411371452		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7093127411371452 | validation: 0.5974109697299831]
	TIME [epoch: 11.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5777415012765094		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5777415012765094 | validation: 0.6117592566154635]
	TIME [epoch: 11.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5245069010151064		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.5245069010151064 | validation: 0.6160584801722686]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5960342136112899		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.5960342136112899 | validation: 0.5591657494515753]
	TIME [epoch: 11.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5997411293719479		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.5997411293719479 | validation: 0.6750459457461551]
	TIME [epoch: 11.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5145232790462807		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.5145232790462807 | validation: 0.6015524341670387]
	TIME [epoch: 11.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243153072324912		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7243153072324912 | validation: 0.6123553517077052]
	TIME [epoch: 11.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6684335549394558		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.6684335549394558 | validation: 0.5650821200331881]
	TIME [epoch: 11.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5182451555995444		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.5182451555995444 | validation: 0.696208761344721]
	TIME [epoch: 11.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7058713418559368		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.7058713418559368 | validation: 0.5973808185087299]
	TIME [epoch: 11.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8666211556720751		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.8666211556720751 | validation: 0.6617108077993737]
	TIME [epoch: 11.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8094916875142837		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.8094916875142837 | validation: 1.0131371190808642]
	TIME [epoch: 11.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7534586276177309		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.7534586276177309 | validation: 0.7444864050725971]
	TIME [epoch: 11.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836185537845425		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.6836185537845425 | validation: 0.5125425086667699]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5486380588370258		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5486380588370258 | validation: 0.7213891776023976]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6587368435110891		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.6587368435110891 | validation: 0.7461036998611397]
	TIME [epoch: 11.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.746118232818917		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.746118232818917 | validation: 0.6624282283780921]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6143185973885357		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.6143185973885357 | validation: 0.6113792512840377]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5779211330376148		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.5779211330376148 | validation: 0.7162193274772105]
	TIME [epoch: 11.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6428515425207674		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.6428515425207674 | validation: 0.5085479276433637]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5132886010151914		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.5132886010151914 | validation: 0.5011189304660807]
	TIME [epoch: 11.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593335341196923		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.5593335341196923 | validation: 0.7714713135254934]
	TIME [epoch: 11.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6784559838653297		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.6784559838653297 | validation: 0.45860885728747086]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5363544245243878		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.5363544245243878 | validation: 0.5658467209490732]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.63318976277174		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.63318976277174 | validation: 0.666896949523732]
	TIME [epoch: 11.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6444082738618606		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.6444082738618606 | validation: 0.5065358491968623]
	TIME [epoch: 11.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4737373180244881		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.4737373180244881 | validation: 0.7841782300392635]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301504012315542		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5301504012315542 | validation: 1.2704371951220548]
	TIME [epoch: 11.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7563992494255796		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.7563992494255796 | validation: 0.4516941600874966]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5999615749829066		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.5999615749829066 | validation: 0.46039824803056223]
	TIME [epoch: 11.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5624481207144125		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5624481207144125 | validation: 0.5583066393758317]
	TIME [epoch: 11.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6472110193497469		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.6472110193497469 | validation: 1.4868633456488243]
	TIME [epoch: 11.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8902237439908376		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.8902237439908376 | validation: 0.4672677377925743]
	TIME [epoch: 11.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4786457706577053		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.4786457706577053 | validation: 0.6210244416424403]
	TIME [epoch: 11.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.866608029466964		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.866608029466964 | validation: 0.677127981070251]
	TIME [epoch: 11.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.893554514415261		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.893554514415261 | validation: 0.743255838338888]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6305230176477087		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.6305230176477087 | validation: 0.574225646444869]
	TIME [epoch: 11.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5940733980685052		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.5940733980685052 | validation: 0.5717351752645996]
	TIME [epoch: 11.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5592396016622387		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5592396016622387 | validation: 0.5271840632626688]
	TIME [epoch: 11.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44065747722093723		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.44065747722093723 | validation: 0.47612339633894224]
	TIME [epoch: 11.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6204833089806854		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.6204833089806854 | validation: 0.7713621931674931]
	TIME [epoch: 11.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8070379517514441		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.8070379517514441 | validation: 0.7367483513244697]
	TIME [epoch: 11.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8509674462024189		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.8509674462024189 | validation: 0.7490099741973538]
	TIME [epoch: 11.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7830160815174019		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.7830160815174019 | validation: 0.7418518408151392]
	TIME [epoch: 11.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7570067038599468		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.7570067038599468 | validation: 0.736149115468317]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931423408721404		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.6931423408721404 | validation: 0.6939685405693103]
	TIME [epoch: 11.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807548819248923		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.6807548819248923 | validation: 0.6289998077086988]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.560956872660368		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.560956872660368 | validation: 0.6828298406453984]
	TIME [epoch: 11.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6126092819277598		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.6126092819277598 | validation: 0.6626836520004434]
	TIME [epoch: 11.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5859342786800414		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.5859342786800414 | validation: 0.6825751799907449]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6978849631046338		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.6978849631046338 | validation: 0.5803264448301475]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5310967041581893		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5310967041581893 | validation: 0.6077082007531612]
	TIME [epoch: 11.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6016260054441516		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.6016260054441516 | validation: 0.5772613141409321]
	TIME [epoch: 11.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6122501798715037		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.6122501798715037 | validation: 0.7766422755415866]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6416120464340996		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.6416120464340996 | validation: 0.5709217388804827]
	TIME [epoch: 11.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.464118858371202		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.464118858371202 | validation: 0.6335956144776442]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7528809827381722		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.7528809827381722 | validation: 0.9534933473002863]
	TIME [epoch: 11.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.734058042195751		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.734058042195751 | validation: 0.550531553768395]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5251656384200871		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.5251656384200871 | validation: 0.5204342200277787]
	TIME [epoch: 11.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6269293052106886		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.6269293052106886 | validation: 0.6176283369233164]
	TIME [epoch: 11.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5165032994875869		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.5165032994875869 | validation: 0.6951305591473637]
	TIME [epoch: 11.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.762474166210455		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.762474166210455 | validation: 0.6590760377301129]
	TIME [epoch: 11.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5698449000296958		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.5698449000296958 | validation: 0.6598889052798523]
	TIME [epoch: 11.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416097418212623		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.5416097418212623 | validation: 0.4956024276112532]
	TIME [epoch: 11.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45992528842366975		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.45992528842366975 | validation: 0.5661870205717163]
	TIME [epoch: 11.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6142158758128298		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.6142158758128298 | validation: 0.4996888327021414]
	TIME [epoch: 11.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49626511342547336		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.49626511342547336 | validation: 0.6580799643422907]
	TIME [epoch: 11.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083037471297952		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.5083037471297952 | validation: 0.816257145274206]
	TIME [epoch: 11.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377432396822505		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.5377432396822505 | validation: 0.7021090646881883]
	TIME [epoch: 11.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4797352863635438		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.4797352863635438 | validation: 0.534087817901234]
	TIME [epoch: 11.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5574283970029624		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.5574283970029624 | validation: 0.5407171952523643]
	TIME [epoch: 11.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6134940065140605		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.6134940065140605 | validation: 0.5914221208514914]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5635140130113689		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.5635140130113689 | validation: 0.5544691656104906]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5316400458709704		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.5316400458709704 | validation: 1.090699511395828]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8605493226144685		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.8605493226144685 | validation: 0.5437653694761169]
	TIME [epoch: 11.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7895237364927989		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.7895237364927989 | validation: 0.9135515056252126]
	TIME [epoch: 11.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7712687106727896		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.7712687106727896 | validation: 0.725178172014285]
	TIME [epoch: 11.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7679845031931012		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.7679845031931012 | validation: 0.5862730135570795]
	TIME [epoch: 11.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5945009582165693		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.5945009582165693 | validation: 0.5946615944999474]
	TIME [epoch: 11.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5462541520526438		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.5462541520526438 | validation: 0.5635345150993717]
	TIME [epoch: 11.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6405979981750513		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.6405979981750513 | validation: 0.7118962942948528]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6594360626330611		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.6594360626330611 | validation: 0.7240999043288983]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5345578778440035		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.5345578778440035 | validation: 0.4448191114165379]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_399.pth
	Model improved!!!
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49170985078378643		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.49170985078378643 | validation: 0.6554455239692288]
	TIME [epoch: 11.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5612494061182915		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.5612494061182915 | validation: 0.6234017209786176]
	TIME [epoch: 11.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5001846208180707		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.5001846208180707 | validation: 0.6114000286618917]
	TIME [epoch: 11.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4780360871464271		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.4780360871464271 | validation: 0.5533548325280213]
	TIME [epoch: 11.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49597147306849454		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.49597147306849454 | validation: 0.5406376373475374]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43358763221277985		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.43358763221277985 | validation: 0.637838606623002]
	TIME [epoch: 11.6 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6213483791009344		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.6213483791009344 | validation: 0.581397467194244]
	TIME [epoch: 11.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5143766556083583		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.5143766556083583 | validation: 0.574167005213906]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6664594624593165		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.6664594624593165 | validation: 0.7196636835227115]
	TIME [epoch: 11.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5463014383956754		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.5463014383956754 | validation: 0.5632767261324434]
	TIME [epoch: 11.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5211663715264431		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.5211663715264431 | validation: 0.45308414861100843]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3864689539806019		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.3864689539806019 | validation: 0.45324811792749314]
	TIME [epoch: 11.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6560005086522558		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.6560005086522558 | validation: 0.8520777553555595]
	TIME [epoch: 11.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5963639862007487		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.5963639862007487 | validation: 0.7206125565106484]
	TIME [epoch: 11.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5150955094296901		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.5150955094296901 | validation: 0.5970877012174317]
	TIME [epoch: 11.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0152834745505415		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.0152834745505415 | validation: 0.589213990675509]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48265437372132297		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.48265437372132297 | validation: 0.46559646450967235]
	TIME [epoch: 11.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42906729553929085		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.42906729553929085 | validation: 0.568036466168511]
	TIME [epoch: 11.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47542751921665727		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.47542751921665727 | validation: 0.5512104619901003]
	TIME [epoch: 11.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5820698868937981		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.5820698868937981 | validation: 1.090789013944349]
	TIME [epoch: 11.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7276343226090389		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.7276343226090389 | validation: 0.4716254292631312]
	TIME [epoch: 11.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4676494843998652		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.4676494843998652 | validation: 0.811950732577619]
	TIME [epoch: 11.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.577737855672025		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.577737855672025 | validation: 0.4657300722851912]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5699608910955717		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.5699608910955717 | validation: 0.49582696129392245]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41758272701585947		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.41758272701585947 | validation: 0.4934794360087437]
	TIME [epoch: 11.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4704766350957341		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.4704766350957341 | validation: 0.4074811657947143]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3795799553104047		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.3795799553104047 | validation: 0.5841450206455177]
	TIME [epoch: 11.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5145507228456334		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.5145507228456334 | validation: 0.5578196458410198]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5152803709747221		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.5152803709747221 | validation: 0.4424970391929556]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47977039083675077		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.47977039083675077 | validation: 0.5055447850685274]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44073980965746906		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.44073980965746906 | validation: 0.4824061188951367]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42269150210175643		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.42269150210175643 | validation: 0.6708671225710359]
	TIME [epoch: 11.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5703629677205793		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.5703629677205793 | validation: 0.6212475639636701]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416162345241792		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.5416162345241792 | validation: 0.4616843920581244]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49391744017384986		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.49391744017384986 | validation: 0.39915126683161817]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35681500647312775		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.35681500647312775 | validation: 0.4063049421973999]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42703003499139797		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.42703003499139797 | validation: 0.7655664606013599]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5972732178128703		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.5972732178128703 | validation: 0.4475356816317805]
	TIME [epoch: 11.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4343022151083916		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.4343022151083916 | validation: 0.47909634475418217]
	TIME [epoch: 11.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500971992938063		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.4500971992938063 | validation: 0.501160540211387]
	TIME [epoch: 11.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40282183989589815		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.40282183989589815 | validation: 0.4371741121881439]
	TIME [epoch: 11.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38498882887041996		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.38498882887041996 | validation: 0.4426148611819795]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37260842179428705		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.37260842179428705 | validation: 0.4502860563078223]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42554006782491577		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.42554006782491577 | validation: 0.47761742990456124]
	TIME [epoch: 11.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4403912963657711		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.4403912963657711 | validation: 0.45236532530547613]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43791940937663065		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.43791940937663065 | validation: 0.527034565357312]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42741605384823944		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.42741605384823944 | validation: 0.5493099431737163]
	TIME [epoch: 11.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5223157159986529		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.5223157159986529 | validation: 0.44605786834031624]
	TIME [epoch: 11.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4450297487623942		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.4450297487623942 | validation: 0.5100223871863925]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416589123720286		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.5416589123720286 | validation: 0.5629414848430895]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4976104372986782		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.4976104372986782 | validation: 0.44896480874830574]
	TIME [epoch: 11.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4034280873157566		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.4034280873157566 | validation: 0.449491077882211]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4036059674189957		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.4036059674189957 | validation: 0.43138259274427415]
	TIME [epoch: 11.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41253503737598957		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.41253503737598957 | validation: 0.4512182994848293]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43507520095549584		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.43507520095549584 | validation: 0.4353740684359459]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4024846035498087		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.4024846035498087 | validation: 0.3986498522528798]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4587150520835183		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.4587150520835183 | validation: 0.6057842699485457]
	TIME [epoch: 11.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.559953271887123		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.559953271887123 | validation: 0.5205335712470365]
	TIME [epoch: 11.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4479601067296728		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.4479601067296728 | validation: 0.4741389721186569]
	TIME [epoch: 11.6 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36963655329360545		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.36963655329360545 | validation: 0.48303160284484664]
	TIME [epoch: 11.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40860212638632065		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.40860212638632065 | validation: 0.43685328973326976]
	TIME [epoch: 11.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3973634987926463		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.3973634987926463 | validation: 0.4896117095311739]
	TIME [epoch: 11.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4241901812987229		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.4241901812987229 | validation: 0.5684497354199142]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5390906339257071		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.5390906339257071 | validation: 0.47065939589929345]
	TIME [epoch: 11.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4669487574582021		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.4669487574582021 | validation: 0.5866889472384028]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5914384745555593		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.5914384745555593 | validation: 0.5216462434403625]
	TIME [epoch: 11.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5385946923344783		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.5385946923344783 | validation: 0.5678865901438974]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5133984153646719		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.5133984153646719 | validation: 0.37468561548087465]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_467.pth
	Model improved!!!
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35279153029899435		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.35279153029899435 | validation: 0.43770216599843254]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39625128212168403		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.39625128212168403 | validation: 0.3732636928561257]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_469.pth
	Model improved!!!
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3053483011853052		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.3053483011853052 | validation: 0.40070112906019667]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42995587396224655		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.42995587396224655 | validation: 0.44843265340146987]
	TIME [epoch: 11.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3529431176821803		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.3529431176821803 | validation: 0.5750676381470027]
	TIME [epoch: 11.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.434148466725198		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.434148466725198 | validation: 0.5295052603944869]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4290182979127075		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.4290182979127075 | validation: 0.5010740407379825]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293586063181799		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.5293586063181799 | validation: 0.548812634301627]
	TIME [epoch: 11.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49465850036856746		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.49465850036856746 | validation: 0.5478285005946978]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4259831450350457		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.4259831450350457 | validation: 0.3754340155323911]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38635104734307624		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.38635104734307624 | validation: 0.37953769862848746]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38851437350061335		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.38851437350061335 | validation: 0.4573159944702087]
	TIME [epoch: 11.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.531415704093404		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.531415704093404 | validation: 0.44867406441236507]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33867073780218065		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.33867073780218065 | validation: 0.4626492204713118]
	TIME [epoch: 11.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4271730311253377		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.4271730311253377 | validation: 0.3881151590782024]
	TIME [epoch: 11.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3539943191237564		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.3539943191237564 | validation: 0.44855865817265683]
	TIME [epoch: 11.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40336084287868323		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.40336084287868323 | validation: 0.3825828469367848]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35263106954748663		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.35263106954748663 | validation: 0.383939885685601]
	TIME [epoch: 11.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3843488548985031		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.3843488548985031 | validation: 0.5641697713139048]
	TIME [epoch: 11.6 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5095329052566375		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.5095329052566375 | validation: 0.39939484321526636]
	TIME [epoch: 11.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3306693530253342		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.3306693530253342 | validation: 0.35607802557357976]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_488.pth
	Model improved!!!
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.323969759314364		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.323969759314364 | validation: 0.35446380736158906]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_489.pth
	Model improved!!!
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3879698067855438		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.3879698067855438 | validation: 0.47497934085599874]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3756561642542769		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.3756561642542769 | validation: 0.5438240989529909]
	TIME [epoch: 11.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6442885078320713		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.6442885078320713 | validation: 0.3415375025185379]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_492.pth
	Model improved!!!
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037115383339281		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.5037115383339281 | validation: 0.41941949685966007]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33929476990258267		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.33929476990258267 | validation: 0.372941330522039]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451121898711634		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.5451121898711634 | validation: 0.6501198105243057]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5688620404732417		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.5688620404732417 | validation: 0.4532156060647206]
	TIME [epoch: 11.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37601826156138723		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.37601826156138723 | validation: 0.367427213517508]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3044823775190503		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.3044823775190503 | validation: 0.5042090343650625]
	TIME [epoch: 11.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.349419641077274		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.349419641077274 | validation: 0.3969092146964054]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34108166556452146		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.34108166556452146 | validation: 0.40043115232594945]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3739713473823403		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.3739713473823403 | validation: 0.38039443533453793]
	TIME [epoch: 11.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41976253112676487		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.41976253112676487 | validation: 0.3764503521143687]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540951619574614		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.3540951619574614 | validation: 0.3998143674150231]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810280851298517		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.3810280851298517 | validation: 0.5145760491798113]
	TIME [epoch: 11.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3611381597750567		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.3611381597750567 | validation: 0.402433441799609]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3894502977759976		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.3894502977759976 | validation: 0.5114541267397802]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6263829259584552		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.6263829259584552 | validation: 0.4998389297905631]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43101266126871784		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.43101266126871784 | validation: 0.517736063570662]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4297171990788469		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.4297171990788469 | validation: 0.3997232527792785]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3843166061031163		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.3843166061031163 | validation: 0.48958681609980614]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42780537086425163		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.42780537086425163 | validation: 0.44500213794253796]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4015157667355766		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.4015157667355766 | validation: 0.5213458087838949]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3874953655359006		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.3874953655359006 | validation: 0.36394279642278626]
	TIME [epoch: 11.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3357415867933842		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.3357415867933842 | validation: 0.3943591668259845]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.454910107381861		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.454910107381861 | validation: 0.5549331921466627]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4155040668489333		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.4155040668489333 | validation: 0.4042719187927868]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37651969570755084		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.37651969570755084 | validation: 0.3615889924340627]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35205675209483345		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.35205675209483345 | validation: 0.4355302227581925]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3420605676696754		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.3420605676696754 | validation: 0.34409673910553396]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38425257727220946		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.38425257727220946 | validation: 0.45458120281013953]
	TIME [epoch: 11.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4347224907349918		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.4347224907349918 | validation: 0.54255075353534]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4253111876859128		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.4253111876859128 | validation: 0.36178948902779906]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.411694484912879		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.411694484912879 | validation: 0.3913556627100691]
	TIME [epoch: 11.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3620661291324555		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.3620661291324555 | validation: 0.4153879249165013]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3083216714929945		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.3083216714929945 | validation: 0.426120295382026]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3700776180378451		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.3700776180378451 | validation: 0.5201684597659163]
	TIME [epoch: 11.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46745526848450064		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.46745526848450064 | validation: 0.5064434975255762]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4397352479096383		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.4397352479096383 | validation: 0.38632117181078196]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35893337880685355		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.35893337880685355 | validation: 0.5052826140456742]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3949643185838855		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.3949643185838855 | validation: 0.3921488653531948]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3339145533583653		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.3339145533583653 | validation: 0.3356997950734852]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_531.pth
	Model improved!!!
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3180906865403337		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.3180906865403337 | validation: 0.3832713258168171]
	TIME [epoch: 11.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35339462885605033		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.35339462885605033 | validation: 0.4814158754959129]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3936611064509259		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.3936611064509259 | validation: 0.5691617090357382]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43042408971734986		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.43042408971734986 | validation: 0.9427287452024083]
	TIME [epoch: 11.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7304090436905442		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.7304090436905442 | validation: 0.4445975131808943]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41589119258975754		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.41589119258975754 | validation: 0.39227856758840435]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2885049800418822		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.2885049800418822 | validation: 0.35305979279905897]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29340199936980277		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.29340199936980277 | validation: 0.43812167414525294]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33354278155991623		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.33354278155991623 | validation: 0.40000277451315297]
	TIME [epoch: 11.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28593109622510726		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.28593109622510726 | validation: 0.35810593465323004]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2844938505792884		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.2844938505792884 | validation: 0.39040670643639197]
	TIME [epoch: 11.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41190939722902953		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.41190939722902953 | validation: 0.37648773927990775]
	TIME [epoch: 11.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34658598641343336		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.34658598641343336 | validation: 0.33773651146285216]
	TIME [epoch: 11.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28666809315097974		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.28666809315097974 | validation: 0.3832625383345256]
	TIME [epoch: 11.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3111445751220126		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.3111445751220126 | validation: 0.30903812808716696]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_546.pth
	Model improved!!!
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2983645690706239		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.2983645690706239 | validation: 0.3153844644086069]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28983024790935896		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.28983024790935896 | validation: 0.5106064596733164]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3969789239335082		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.3969789239335082 | validation: 0.5041386405632085]
	TIME [epoch: 11.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6571778800718356		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.6571778800718356 | validation: 0.5676864785660598]
	TIME [epoch: 11.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44029669491363754		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.44029669491363754 | validation: 0.39937822719124244]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3365699383639826		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.3365699383639826 | validation: 0.3179283574095255]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3342524341074286		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.3342524341074286 | validation: 0.38809656290805594]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440918993589416		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.3440918993589416 | validation: 0.37958618934316757]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3046097193697008		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.3046097193697008 | validation: 0.34261070960935186]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756395779587183		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.2756395779587183 | validation: 0.3583728785476151]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30995036345590704		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.30995036345590704 | validation: 0.29472692907835357]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_557.pth
	Model improved!!!
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3758789292866235		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.3758789292866235 | validation: 0.3338324638012978]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2903136873831353		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.2903136873831353 | validation: 0.3557372042486642]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31575821210184135		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.31575821210184135 | validation: 0.3719804558367846]
	TIME [epoch: 11.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3024551609466236		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.3024551609466236 | validation: 0.37152846115549276]
	TIME [epoch: 11.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37225811972265166		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.37225811972265166 | validation: 0.5244509378447073]
	TIME [epoch: 11.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3520893629335637		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.3520893629335637 | validation: 0.3980430298411721]
	TIME [epoch: 11.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4174267085107776		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.4174267085107776 | validation: 0.35789487305045614]
	TIME [epoch: 11.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093262498304985		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.3093262498304985 | validation: 0.37444284614130086]
	TIME [epoch: 11.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385319405363737		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.3385319405363737 | validation: 0.32386452245925623]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3332955108771487		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.3332955108771487 | validation: 0.36846278507150604]
	TIME [epoch: 11.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36789395510663414		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.36789395510663414 | validation: 0.4209414835059019]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3236065597818102		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.3236065597818102 | validation: 0.47002157023328606]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32242575847118327		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.32242575847118327 | validation: 0.3330765908464962]
	TIME [epoch: 11.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3077829482439538		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.3077829482439538 | validation: 0.4272816817394193]
	TIME [epoch: 11.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39181753004092673		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.39181753004092673 | validation: 0.3384790903538509]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771371834143314		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.2771371834143314 | validation: 0.3110879108913264]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3094097536550007		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.3094097536550007 | validation: 0.3736857580429412]
	TIME [epoch: 11.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.301752536729122		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.301752536729122 | validation: 0.2993301455761247]
	TIME [epoch: 11.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28784125095624846		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.28784125095624846 | validation: 0.42526362360053027]
	TIME [epoch: 11.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4201601863484885		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.4201601863484885 | validation: 0.28451248986881617]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3106694650768405		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.3106694650768405 | validation: 0.5043593974526894]
	TIME [epoch: 11.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41142525779521166		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.41142525779521166 | validation: 0.4212554451922318]
	TIME [epoch: 11.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3158062650972233		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.3158062650972233 | validation: 0.525191366211473]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3474790971746139		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.3474790971746139 | validation: 0.31933397879208913]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2619943942188586		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.2619943942188586 | validation: 0.3869361259073365]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28102333051696404		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.28102333051696404 | validation: 0.4210387823253761]
	TIME [epoch: 11.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3672763990628299		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.3672763990628299 | validation: 0.34615053913526356]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27905635142317137		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.27905635142317137 | validation: 0.3485757089495965]
	TIME [epoch: 11.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3047647553573789		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.3047647553573789 | validation: 0.3244672436492182]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453595974992584		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.3453595974992584 | validation: 0.3592685012466342]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389272432075065		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.389272432075065 | validation: 0.3131287764623024]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3129320806525021		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.3129320806525021 | validation: 0.40881330169893615]
	TIME [epoch: 11.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42695667636551654		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.42695667636551654 | validation: 0.43354937915158526]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3584646302742855		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.3584646302742855 | validation: 0.4122018447720652]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3907268555249559		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.3907268555249559 | validation: 0.42884736846492544]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3420042497313457		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.3420042497313457 | validation: 0.40212384167358495]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846457702490317		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.2846457702490317 | validation: 0.2923812460840948]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25572173101681767		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.25572173101681767 | validation: 0.388473639614762]
	TIME [epoch: 11.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32236651030293295		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.32236651030293295 | validation: 0.45003214530841745]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3758696481409741		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.3758696481409741 | validation: 0.37047489114132953]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4270303676990824		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.4270303676990824 | validation: 0.4187442735667647]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37110255234971967		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.37110255234971967 | validation: 0.31295938254014133]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27724646924088037		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.27724646924088037 | validation: 0.2916271801001563]
	TIME [epoch: 11.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25874904342680893		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.25874904342680893 | validation: 0.2868057981174128]
	TIME [epoch: 11.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.299132213102836		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.299132213102836 | validation: 0.3791160602161986]
	TIME [epoch: 11.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36284717913856607		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.36284717913856607 | validation: 0.37950091955854065]
	TIME [epoch: 11.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4433559188103785		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.4433559188103785 | validation: 0.29860208140364886]
	TIME [epoch: 11.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27079036542232504		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.27079036542232504 | validation: 0.38022284223985525]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2988580889932889		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.2988580889932889 | validation: 0.3329470856549985]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34071376025586825		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.34071376025586825 | validation: 0.36334124001979795]
	TIME [epoch: 11.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28157839635480336		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.28157839635480336 | validation: 0.41466964968521086]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3479368296475987		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.3479368296475987 | validation: 0.3357310811945547]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25514155341144035		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.25514155341144035 | validation: 0.590132887290874]
	TIME [epoch: 11.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46097629377910765		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.46097629377910765 | validation: 0.277402252200758]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_611.pth
	Model improved!!!
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756812424354052		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.2756812424354052 | validation: 0.37346409444316786]
	TIME [epoch: 11.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32572011586810584		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.32572011586810584 | validation: 0.43695723351271526]
	TIME [epoch: 11.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4400953119886556		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.4400953119886556 | validation: 0.412868514472049]
	TIME [epoch: 11.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30540413525652377		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.30540413525652377 | validation: 0.29795799743979845]
	TIME [epoch: 11.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26268112736587684		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.26268112736587684 | validation: 0.3869188204210564]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3121826140493269		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.3121826140493269 | validation: 0.2534020526368082]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_617.pth
	Model improved!!!
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27554589869538904		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.27554589869538904 | validation: 0.4983208286135951]
	TIME [epoch: 11.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30883663997956606		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.30883663997956606 | validation: 0.273536563400764]
	TIME [epoch: 11.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26944980460030354		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.26944980460030354 | validation: 0.33972908144495134]
	TIME [epoch: 11.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25947080224975927		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.25947080224975927 | validation: 0.273642370035311]
	TIME [epoch: 11.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24524470361615885		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.24524470361615885 | validation: 0.2972421189079259]
	TIME [epoch: 11.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2623729920043188		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.2623729920043188 | validation: 0.3091193287520693]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24507843742528818		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.24507843742528818 | validation: 0.28863632620686763]
	TIME [epoch: 11.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24350006749748104		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.24350006749748104 | validation: 0.2806006847076219]
	TIME [epoch: 11.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.263507825273782		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.263507825273782 | validation: 0.23616932233430643]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2553678551612839		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.2553678551612839 | validation: 0.2760476050811421]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30393077501648863		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.30393077501648863 | validation: 0.3141742080481035]
	TIME [epoch: 11.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23426481731823207		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.23426481731823207 | validation: 0.32216960727648475]
	TIME [epoch: 11.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2574504369012906		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.2574504369012906 | validation: 0.3003371843438136]
	TIME [epoch: 11.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23553578937451183		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.23553578937451183 | validation: 0.2965162931512001]
	TIME [epoch: 11.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23423365278190966		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.23423365278190966 | validation: 0.27353956798108925]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24217527835827313		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.24217527835827313 | validation: 0.24849984551077164]
	TIME [epoch: 11.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29234747994776955		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.29234747994776955 | validation: 0.2737222287566807]
	TIME [epoch: 11.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24073303091008566		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.24073303091008566 | validation: 0.2695913483954205]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31816886196976446		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.31816886196976446 | validation: 0.33135308430898264]
	TIME [epoch: 11.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2808525962565207		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.2808525962565207 | validation: 0.2771094798423641]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2631205587678189		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.2631205587678189 | validation: 0.2751624845277815]
	TIME [epoch: 11.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856674799686652		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.2856674799686652 | validation: 0.28814167018258596]
	TIME [epoch: 11.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2319587553250073		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.2319587553250073 | validation: 0.2788162431897909]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2552221422460743		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.2552221422460743 | validation: 0.40422285129112845]
	TIME [epoch: 11.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34098610461621054		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.34098610461621054 | validation: 0.3803635090084596]
	TIME [epoch: 11.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27900575388302234		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.27900575388302234 | validation: 0.29818252596294137]
	TIME [epoch: 11.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595603214811968		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.2595603214811968 | validation: 0.32112164233008417]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3115533541672905		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.3115533541672905 | validation: 0.29935897291763747]
	TIME [epoch: 11.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581384492064165		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.2581384492064165 | validation: 0.2551891270193331]
	TIME [epoch: 11.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24718459600250375		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.24718459600250375 | validation: 0.3167953253780602]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2852950518162417		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.2852950518162417 | validation: 0.34534601018859834]
	TIME [epoch: 11.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650255072426924		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.2650255072426924 | validation: 0.2647169460923755]
	TIME [epoch: 11.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22427980194315839		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.22427980194315839 | validation: 0.3107653823100111]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2633319545942087		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.2633319545942087 | validation: 0.3152175687652447]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25670658155415127		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.25670658155415127 | validation: 0.34694849123226734]
	TIME [epoch: 11.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3746006140379934		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.3746006140379934 | validation: 0.3736276611493872]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28274116741665317		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.28274116741665317 | validation: 0.23043316977310632]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_654.pth
	Model improved!!!
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2721091059816539		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.2721091059816539 | validation: 0.42784742038627677]
	TIME [epoch: 11.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33154469853075075		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.33154469853075075 | validation: 0.42033520665919605]
	TIME [epoch: 11.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3156312402803736		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.3156312402803736 | validation: 0.28746736216077046]
	TIME [epoch: 11.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27113994653021845		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.27113994653021845 | validation: 0.27214796214081083]
	TIME [epoch: 11.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23507653659642003		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.23507653659642003 | validation: 0.28348245305414854]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26189648226187745		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.26189648226187745 | validation: 0.3502659609230351]
	TIME [epoch: 11.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2503987426724685		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.2503987426724685 | validation: 0.2556949763494024]
	TIME [epoch: 11.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2401790885712301		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.2401790885712301 | validation: 0.3019620052418204]
	TIME [epoch: 11.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031338579815591		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.3031338579815591 | validation: 0.3268631786378753]
	TIME [epoch: 11.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626626073362242		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.2626626073362242 | validation: 0.26947749850429215]
	TIME [epoch: 11.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2506926406535094		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.2506926406535094 | validation: 0.4101660217214969]
	TIME [epoch: 11.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3753797991276769		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.3753797991276769 | validation: 0.28006785503543674]
	TIME [epoch: 11.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23314064465983972		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.23314064465983972 | validation: 0.2729593912997098]
	TIME [epoch: 11.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31072466998611054		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.31072466998611054 | validation: 0.2502722432668496]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25916547757477654		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.25916547757477654 | validation: 0.2924145304431474]
	TIME [epoch: 11.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30251014619036865		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.30251014619036865 | validation: 0.32729726718781954]
	TIME [epoch: 11.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2652217720319131		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.2652217720319131 | validation: 0.33485650494882196]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24315882371856923		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.24315882371856923 | validation: 0.2619006719765542]
	TIME [epoch: 11.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21366578246481202		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.21366578246481202 | validation: 0.25500509126020215]
	TIME [epoch: 11.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.249928774706816		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.249928774706816 | validation: 0.3004413608460644]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2220400036846431		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.2220400036846431 | validation: 0.2713985006020034]
	TIME [epoch: 11.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32208965877386786		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.32208965877386786 | validation: 0.3826107103408646]
	TIME [epoch: 11.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28143865339438673		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.28143865339438673 | validation: 0.3176105284705289]
	TIME [epoch: 11.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2446548111716425		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.2446548111716425 | validation: 0.28676645120788413]
	TIME [epoch: 11.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25217008778949523		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.25217008778949523 | validation: 0.32890342978454606]
	TIME [epoch: 11.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2610734246568378		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.2610734246568378 | validation: 0.28096433016490696]
	TIME [epoch: 11.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24808708554401074		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.24808708554401074 | validation: 0.2756081450483387]
	TIME [epoch: 11.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23279002980690766		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.23279002980690766 | validation: 0.2924979235867307]
	TIME [epoch: 11.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2663215203345916		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.2663215203345916 | validation: 0.3432869588119528]
	TIME [epoch: 11.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3009165973640522		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.3009165973640522 | validation: 0.31407543470678734]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23712410245640664		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.23712410245640664 | validation: 0.27230497379635]
	TIME [epoch: 11.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3036851018459386		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.3036851018459386 | validation: 0.3257882532106304]
	TIME [epoch: 11.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27311073607048925		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.27311073607048925 | validation: 0.26429434909975075]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31913274879986026		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.31913274879986026 | validation: 0.5399004749804296]
	TIME [epoch: 11.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.464638863039981		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.464638863039981 | validation: 0.41774938700856157]
	TIME [epoch: 11.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31333027303917027		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.31333027303917027 | validation: 0.2996780180132048]
	TIME [epoch: 11.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24664649950261483		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.24664649950261483 | validation: 0.27664391093861973]
	TIME [epoch: 11.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071885751394031		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.3071885751394031 | validation: 0.3236236028661517]
	TIME [epoch: 11.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24987800112532504		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.24987800112532504 | validation: 0.30877590130802773]
	TIME [epoch: 11.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24902662998473435		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.24902662998473435 | validation: 0.3194381948575391]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28596276682927635		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.28596276682927635 | validation: 0.30413063542238544]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32780624959805676		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.32780624959805676 | validation: 0.3450284165495931]
	TIME [epoch: 11.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25457179158196025		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.25457179158196025 | validation: 0.2682282738396329]
	TIME [epoch: 11.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3280004577702437		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.3280004577702437 | validation: 0.3643541663958928]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31743993212318455		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.31743993212318455 | validation: 0.35627061848088687]
	TIME [epoch: 11.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2494660673906391		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.2494660673906391 | validation: 0.2721591532544412]
	TIME [epoch: 11.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27482817157512296		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.27482817157512296 | validation: 0.31259707409463616]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.300509580783801		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.300509580783801 | validation: 0.35984700168566724]
	TIME [epoch: 11.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31046000549774033		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.31046000549774033 | validation: 0.3107341269872976]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29047105531373485		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.29047105531373485 | validation: 0.35285462924160643]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2567984476068402		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.2567984476068402 | validation: 0.29391032206911305]
	TIME [epoch: 11.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624198204756791		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.2624198204756791 | validation: 0.3004813012427774]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2634795893089697		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.2634795893089697 | validation: 0.2743252212614848]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2422934355821587		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.2422934355821587 | validation: 0.2648483657367112]
	TIME [epoch: 11.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2617773488372652		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.2617773488372652 | validation: 0.2776905442240496]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24690128246588508		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.24690128246588508 | validation: 0.3620457524760474]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28867438823777813		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.28867438823777813 | validation: 0.3001874331483193]
	TIME [epoch: 11.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28635370610690253		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.28635370610690253 | validation: 0.3084743104296168]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22977718004012304		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.22977718004012304 | validation: 0.2820756903540529]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23810234867792784		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.23810234867792784 | validation: 0.29276662369483414]
	TIME [epoch: 11.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2197429187293233		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.2197429187293233 | validation: 0.27183230437186245]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22460966612089026		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.22460966612089026 | validation: 0.26048567874262163]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20691606495845766		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.20691606495845766 | validation: 0.39093198030394327]
	TIME [epoch: 11.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365053688109677		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.365053688109677 | validation: 0.36620642292618344]
	TIME [epoch: 11.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31713901303879377		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.31713901303879377 | validation: 0.32109286976390894]
	TIME [epoch: 11.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27222051443099354		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.27222051443099354 | validation: 0.31684211726152206]
	TIME [epoch: 11.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24613704716332085		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.24613704716332085 | validation: 0.2639054095160016]
	TIME [epoch: 11.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2513214051402151		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.2513214051402151 | validation: 0.24652846913110657]
	TIME [epoch: 11.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21400049359508058		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.21400049359508058 | validation: 0.2803570705373895]
	TIME [epoch: 11.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2725272937564459		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.2725272937564459 | validation: 0.33762880330813005]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2671544648541675		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.2671544648541675 | validation: 0.33626859549073557]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24978966404799052		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.24978966404799052 | validation: 0.32332409778956034]
	TIME [epoch: 11.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23846252190078981		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.23846252190078981 | validation: 0.32350682444161566]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26329750014770764		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.26329750014770764 | validation: 0.26354775100699407]
	TIME [epoch: 11.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25440783151262947		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.25440783151262947 | validation: 0.3084928612149708]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24317034535397639		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.24317034535397639 | validation: 0.2573146266182277]
	TIME [epoch: 11.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2910154147413186		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.2910154147413186 | validation: 0.3997383349725521]
	TIME [epoch: 11.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3066093554691005		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.3066093554691005 | validation: 0.2749391468878106]
	TIME [epoch: 11.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2518078912541881		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.2518078912541881 | validation: 0.27218980758972355]
	TIME [epoch: 11.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23135072197175927		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.23135072197175927 | validation: 0.24992003454836956]
	TIME [epoch: 11.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22343748094293986		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.22343748094293986 | validation: 0.2463976955049789]
	TIME [epoch: 11.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22379755110270022		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.22379755110270022 | validation: 0.2758185906099046]
	TIME [epoch: 11.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24594450948138313		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.24594450948138313 | validation: 0.28093309135813405]
	TIME [epoch: 11.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22549521262158123		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.22549521262158123 | validation: 0.28923280088657827]
	TIME [epoch: 11.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28974140509861024		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.28974140509861024 | validation: 0.29749326616011795]
	TIME [epoch: 11.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2500444498801215		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.2500444498801215 | validation: 0.31182800685871603]
	TIME [epoch: 11.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23783764616246458		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.23783764616246458 | validation: 0.4049572936076833]
	TIME [epoch: 11.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4320559549922095		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.4320559549922095 | validation: 0.32706174568702223]
	TIME [epoch: 11.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3335175098860687		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.3335175098860687 | validation: 0.2643115078350737]
	TIME [epoch: 11.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20892982993744524		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.20892982993744524 | validation: 0.26370462731032246]
	TIME [epoch: 11.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24111855923169379		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.24111855923169379 | validation: 0.24142434620625097]
	TIME [epoch: 11.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2353707221740392		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.2353707221740392 | validation: 0.2289407681780768]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_746.pth
	Model improved!!!
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19610468297754768		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.19610468297754768 | validation: 0.24018391529227462]
	TIME [epoch: 11.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19111751683256353		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.19111751683256353 | validation: 0.2384454957346862]
	TIME [epoch: 11.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21335966733832062		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.21335966733832062 | validation: 0.23749930795700855]
	TIME [epoch: 11.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2150617570403003		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.2150617570403003 | validation: 0.2863092008333235]
	TIME [epoch: 11.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25003113565623636		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.25003113565623636 | validation: 0.2718279183992481]
	TIME [epoch: 11.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27009520966235495		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.27009520966235495 | validation: 0.27895488859912626]
	TIME [epoch: 11.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27726019158046006		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.27726019158046006 | validation: 0.31393011694715534]
	TIME [epoch: 11.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2669384726257772		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.2669384726257772 | validation: 0.3210640018695056]
	TIME [epoch: 11.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613292418397115		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.2613292418397115 | validation: 0.2744238570985124]
	TIME [epoch: 11.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2502592129339499		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.2502592129339499 | validation: 0.3189893568596842]
	TIME [epoch: 11.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2582465961354986		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.2582465961354986 | validation: 0.30800432905535974]
	TIME [epoch: 11.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27610940205445833		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.27610940205445833 | validation: 0.278039587837699]
	TIME [epoch: 11.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.321557223269888		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.321557223269888 | validation: 0.31944761529871146]
	TIME [epoch: 11.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2427776272920269		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.2427776272920269 | validation: 0.2640224561759663]
	TIME [epoch: 11.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21613072985419407		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.21613072985419407 | validation: 0.4245660363211785]
	TIME [epoch: 11.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31005191344176697		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.31005191344176697 | validation: 0.2950834398700706]
	TIME [epoch: 11.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22734940830151149		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.22734940830151149 | validation: 0.2308308764247076]
	TIME [epoch: 11.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2061616499641592		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.2061616499641592 | validation: 0.31430543794274074]
	TIME [epoch: 11.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2854876978577614		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.2854876978577614 | validation: 0.30791252688002924]
	TIME [epoch: 11.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2370511881608434		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.2370511881608434 | validation: 0.26660625297479734]
	TIME [epoch: 11.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2016663237131276		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.2016663237131276 | validation: 0.23216278592597278]
	TIME [epoch: 11.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20676574090323818		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.20676574090323818 | validation: 0.2357469747310409]
	TIME [epoch: 11.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2578555107616323		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.2578555107616323 | validation: 0.39392260609311375]
	TIME [epoch: 11.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31006932358873934		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.31006932358873934 | validation: 0.31911391353695356]
	TIME [epoch: 11.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26423961586201766		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.26423961586201766 | validation: 0.28350971202360714]
	TIME [epoch: 11.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26135301832891655		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.26135301832891655 | validation: 0.2856028889922358]
	TIME [epoch: 11.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22126042855120606		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.22126042855120606 | validation: 0.26350923908156865]
	TIME [epoch: 11.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23949878291663632		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.23949878291663632 | validation: 0.3126100502303467]
	TIME [epoch: 11.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30635533862424186		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.30635533862424186 | validation: 0.3133941261327917]
	TIME [epoch: 11.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26636974288562126		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.26636974288562126 | validation: 0.29775685249719114]
	TIME [epoch: 11.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24994352137937945		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.24994352137937945 | validation: 0.2831061928022374]
	TIME [epoch: 11.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24344279560057022		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.24344279560057022 | validation: 0.2976635125209622]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2176196335151475		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.2176196335151475 | validation: 0.2360186462124602]
	TIME [epoch: 11.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21097042494277582		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.21097042494277582 | validation: 0.22576379536202335]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_780.pth
	Model improved!!!
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23737582753299222		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.23737582753299222 | validation: 0.26343275309827546]
	TIME [epoch: 11.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2940743701323588		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.2940743701323588 | validation: 0.2702794986761093]
	TIME [epoch: 11.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25677727761499236		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.25677727761499236 | validation: 0.3013562791884502]
	TIME [epoch: 11.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26412806736414784		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.26412806736414784 | validation: 0.31332950665672316]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24639053412234185		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.24639053412234185 | validation: 0.2506781172642862]
	TIME [epoch: 11.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20822344774837745		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.20822344774837745 | validation: 0.2608394657702716]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2131825571954898		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.2131825571954898 | validation: 0.24342376398070842]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20133955601429981		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.20133955601429981 | validation: 0.30950145361055903]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25386659793708155		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.25386659793708155 | validation: 0.36568912091397976]
	TIME [epoch: 11.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26012920867424955		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.26012920867424955 | validation: 0.3075346230921498]
	TIME [epoch: 11.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23563209540026114		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.23563209540026114 | validation: 0.27476866295669383]
	TIME [epoch: 11.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22193958170395453		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.22193958170395453 | validation: 0.2895729404882216]
	TIME [epoch: 11.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23540746959389042		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.23540746959389042 | validation: 0.3184078144738378]
	TIME [epoch: 11.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23658177194484		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.23658177194484 | validation: 0.2554587508832292]
	TIME [epoch: 11.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20965088257598408		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.20965088257598408 | validation: 0.2247387779232988]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_795.pth
	Model improved!!!
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19157530063643208		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.19157530063643208 | validation: 0.2339564765465761]
	TIME [epoch: 11.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19523874939010466		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.19523874939010466 | validation: 0.2474370019223874]
	TIME [epoch: 11.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20335800892262562		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.20335800892262562 | validation: 0.2567419990130057]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2173262883585971		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.2173262883585971 | validation: 0.28622403132860097]
	TIME [epoch: 11.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21357827117559186		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.21357827117559186 | validation: 0.2368761938451312]
	TIME [epoch: 11.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20615537164867997		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.20615537164867997 | validation: 0.2232620853588927]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_801.pth
	Model improved!!!
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22688676748280645		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.22688676748280645 | validation: 0.2351454105013716]
	TIME [epoch: 11.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21211149315672145		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.21211149315672145 | validation: 0.28215229542306647]
	TIME [epoch: 11.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755863895873968		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.2755863895873968 | validation: 0.29479325760939584]
	TIME [epoch: 11.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2429614550376151		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.2429614550376151 | validation: 0.3047184692805559]
	TIME [epoch: 11.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2480732946517107		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.2480732946517107 | validation: 0.2645226076412846]
	TIME [epoch: 11.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21281400814353466		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.21281400814353466 | validation: 0.25771577546748986]
	TIME [epoch: 11.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20794844520961725		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.20794844520961725 | validation: 0.2504571006059826]
	TIME [epoch: 11.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21756476158080237		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.21756476158080237 | validation: 0.3342286022598262]
	TIME [epoch: 11.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25583415869311626		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.25583415869311626 | validation: 0.2770913034561707]
	TIME [epoch: 11.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19853184100436483		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.19853184100436483 | validation: 0.2570879035194018]
	TIME [epoch: 11.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24264382587424638		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.24264382587424638 | validation: 0.25881385774582855]
	TIME [epoch: 11.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19359970517420927		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.19359970517420927 | validation: 0.2214461712350564]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_813.pth
	Model improved!!!
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29714083571389827		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.29714083571389827 | validation: 0.37700044213800693]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33447869736583163		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.33447869736583163 | validation: 0.2604727494897655]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22797138043804838		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.22797138043804838 | validation: 0.24006674121764626]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21932745189810604		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.21932745189810604 | validation: 0.24186667704148002]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2003496355705391		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.2003496355705391 | validation: 0.22730915433383372]
	TIME [epoch: 11.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2183051765264385		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.2183051765264385 | validation: 0.2741674714780439]
	TIME [epoch: 11.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20621014394536222		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.20621014394536222 | validation: 0.25093731308159695]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23016939932662434		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.23016939932662434 | validation: 0.22983858289304]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25642756712063863		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.25642756712063863 | validation: 0.38137502956594804]
	TIME [epoch: 11.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24627437534081298		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.24627437534081298 | validation: 0.2366511889026509]
	TIME [epoch: 11.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2216675992605053		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.2216675992605053 | validation: 0.25578627306403784]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20537050199711868		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.20537050199711868 | validation: 0.21413824780873456]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_825.pth
	Model improved!!!
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2067467405701067		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.2067467405701067 | validation: 0.2760786274782435]
	TIME [epoch: 11.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2589254443256478		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.2589254443256478 | validation: 0.2795992895876725]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28033246789599425		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.28033246789599425 | validation: 0.31872379814625346]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3263496541678659		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.3263496541678659 | validation: 0.332793785382064]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2793702759466482		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.2793702759466482 | validation: 0.26370785908418576]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21246329537404113		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.21246329537404113 | validation: 0.2327158502899346]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23325861739885828		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.23325861739885828 | validation: 0.3581796681283979]
	TIME [epoch: 11.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915979966141766		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.2915979966141766 | validation: 0.26006911024328394]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23171561951746467		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.23171561951746467 | validation: 0.21501736285343384]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19427483392629205		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.19427483392629205 | validation: 0.24637790461283424]
	TIME [epoch: 11.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20562611516110177		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.20562611516110177 | validation: 0.24252790347834122]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18342726244229238		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.18342726244229238 | validation: 0.24044874742595937]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19637361621325056		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.19637361621325056 | validation: 0.24484792387176654]
	TIME [epoch: 11.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1936359446659927		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.1936359446659927 | validation: 0.23598048930962812]
	TIME [epoch: 11.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19132396010179512		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.19132396010179512 | validation: 0.2685391338602784]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21650882820010914		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.21650882820010914 | validation: 0.24096648282683625]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1962439167971462		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.1962439167971462 | validation: 0.21524348231063284]
	TIME [epoch: 11.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19210471414400673		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.19210471414400673 | validation: 0.295009304510269]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22033268517028368		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.22033268517028368 | validation: 0.21443689067555965]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18491995192138244		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.18491995192138244 | validation: 0.22919469630012812]
	TIME [epoch: 11.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254233349926072		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.254233349926072 | validation: 0.24170327167931974]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21339538523144627		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.21339538523144627 | validation: 0.2228140588802628]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19829299858522076		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.19829299858522076 | validation: 0.24506212862952162]
	TIME [epoch: 11.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19964221757479006		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.19964221757479006 | validation: 0.23504287753118142]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27858523442305494		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.27858523442305494 | validation: 0.27993826424622453]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2496945285224144		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.2496945285224144 | validation: 0.22174941195285583]
	TIME [epoch: 11.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19221061058519712		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.19221061058519712 | validation: 0.2177018549055636]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18624544606952342		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.18624544606952342 | validation: 0.286863096435589]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20988310987065428		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.20988310987065428 | validation: 0.21654004211713587]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20668039019153295		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.20668039019153295 | validation: 0.3092223188907869]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25729042949013414		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.25729042949013414 | validation: 0.3432426771055143]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24871805036978872		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.24871805036978872 | validation: 0.22735838589668597]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19910992794810284		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.19910992794810284 | validation: 0.2848506519967886]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21407144124425848		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.21407144124425848 | validation: 0.24198639724029503]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22920979213300396		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.22920979213300396 | validation: 0.2505103440401158]
	TIME [epoch: 11.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21175988331706108		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.21175988331706108 | validation: 0.25983637944660276]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20288906948713034		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.20288906948713034 | validation: 0.2219702152695253]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21300594505790915		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.21300594505790915 | validation: 0.27151097027356114]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21573792930018088		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.21573792930018088 | validation: 0.2904250184631675]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22476023362252578		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.22476023362252578 | validation: 0.22180191407038927]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19934015018577		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.19934015018577 | validation: 0.25176769505039487]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19446532700452546		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.19446532700452546 | validation: 0.2354869253197081]
	TIME [epoch: 11.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19887230741113346		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.19887230741113346 | validation: 0.23092021184294936]
	TIME [epoch: 11.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21386630350208047		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.21386630350208047 | validation: 0.26436082142372047]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24964909365118707		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.24964909365118707 | validation: 0.31726410838464547]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2383075210115072		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.2383075210115072 | validation: 0.3104827378500243]
	TIME [epoch: 11.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20703597351184305		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.20703597351184305 | validation: 0.22077042218422238]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17387230363119272		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.17387230363119272 | validation: 0.21911708562045426]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1888850480003254		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.1888850480003254 | validation: 0.22627945480111314]
	TIME [epoch: 11.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20073597249275088		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.20073597249275088 | validation: 0.2658691642038579]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19273013715430382		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.19273013715430382 | validation: 0.2127953733819894]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_876.pth
	Model improved!!!
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1937578979623789		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.1937578979623789 | validation: 0.27111842374104866]
	TIME [epoch: 11.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20224712037742199		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.20224712037742199 | validation: 0.22736720274733352]
	TIME [epoch: 11.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1852922877453606		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.1852922877453606 | validation: 0.2286771720586118]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18693744019409314		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.18693744019409314 | validation: 0.23336963713953393]
	TIME [epoch: 11.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1826573639076907		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.1826573639076907 | validation: 0.21695277757773274]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17920029265530119		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.17920029265530119 | validation: 0.24148217064361915]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20242270828658832		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.20242270828658832 | validation: 0.2079426428639861]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_883.pth
	Model improved!!!
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18258778491410574		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.18258778491410574 | validation: 0.2737303231135853]
	TIME [epoch: 11.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20524111002063714		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.20524111002063714 | validation: 0.22646590127620253]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18083164932853846		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.18083164932853846 | validation: 0.2130714151293287]
	TIME [epoch: 11.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17875744601849314		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.17875744601849314 | validation: 0.21759089461375752]
	TIME [epoch: 11.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17447506097971763		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.17447506097971763 | validation: 0.23432492491338905]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18201411671804515		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.18201411671804515 | validation: 0.2411174306610681]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20965577002314867		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.20965577002314867 | validation: 0.241932127470203]
	TIME [epoch: 11.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19219942369820983		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.19219942369820983 | validation: 0.22502128347347403]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.180183691606246		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.180183691606246 | validation: 0.25894146130757145]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18164933462289687		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.18164933462289687 | validation: 0.23217887169008286]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20689885484130555		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.20689885484130555 | validation: 0.2552126792137098]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2168834509227511		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.2168834509227511 | validation: 0.26053879989037393]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29810025738339085		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.29810025738339085 | validation: 0.3342103468483908]
	TIME [epoch: 11.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2840072803733658		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.2840072803733658 | validation: 0.29631579955968107]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21606599977499386		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.21606599977499386 | validation: 0.23670849946501907]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188885117444052		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.188885117444052 | validation: 0.2470425087683836]
	TIME [epoch: 11.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1934768815985768		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.1934768815985768 | validation: 0.22152806055912544]
	TIME [epoch: 11.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1856958823050576		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.1856958823050576 | validation: 0.24535190153204234]
	TIME [epoch: 11.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18765939161913314		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.18765939161913314 | validation: 0.23069384306825524]
	TIME [epoch: 11.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17789355580975966		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.17789355580975966 | validation: 0.25654657466513753]
	TIME [epoch: 11.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17871720945516217		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.17871720945516217 | validation: 0.21762823824372743]
	TIME [epoch: 11.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17755147005979846		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.17755147005979846 | validation: 0.22639675114666147]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18509371073854958		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.18509371073854958 | validation: 0.2789823972538074]
	TIME [epoch: 11.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2077932575028155		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.2077932575028155 | validation: 0.27668411793882486]
	TIME [epoch: 11.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20570474946809125		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.20570474946809125 | validation: 0.213643194993328]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1837578379820341		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.1837578379820341 | validation: 0.22198512472582763]
	TIME [epoch: 11.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17466218360979474		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.17466218360979474 | validation: 0.2430128215507481]
	TIME [epoch: 11.6 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19184315174175387		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.19184315174175387 | validation: 0.24360063873487328]
	TIME [epoch: 11.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20874504664286908		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.20874504664286908 | validation: 0.21861892296640587]
	TIME [epoch: 11.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17972220508521597		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.17972220508521597 | validation: 0.262141188388615]
	TIME [epoch: 11.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1883095341418741		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.1883095341418741 | validation: 0.2111333479675661]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17373873460624756		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.17373873460624756 | validation: 0.225697984683015]
	TIME [epoch: 11.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18414945290227497		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.18414945290227497 | validation: 0.21909060664743607]
	TIME [epoch: 11.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1753813108447704		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.1753813108447704 | validation: 0.21195016192603666]
	TIME [epoch: 11.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16663436097462642		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.16663436097462642 | validation: 0.2249688840996194]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20771826181318176		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.20771826181318176 | validation: 0.26687520070845305]
	TIME [epoch: 11.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2173368160996513		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.2173368160996513 | validation: 0.24690239662493288]
	TIME [epoch: 11.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2452158572365351		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.2452158572365351 | validation: 0.3062453504427186]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25243405728733737		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.25243405728733737 | validation: 0.28187251191660717]
	TIME [epoch: 11.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21138017298322065		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.21138017298322065 | validation: 0.24283588309572626]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22476670971913404		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.22476670971913404 | validation: 0.29204455158616877]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24912840838567707		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.24912840838567707 | validation: 0.2502691401303375]
	TIME [epoch: 11.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19367560693812313		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.19367560693812313 | validation: 0.22393527389459053]
	TIME [epoch: 11.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1757853179333983		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.1757853179333983 | validation: 0.25643431370804726]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19081724895438174		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.19081724895438174 | validation: 0.24360080380944252]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17826265244460857		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.17826265244460857 | validation: 0.23199642220698954]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766770334138133		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.1766770334138133 | validation: 0.22136482385962125]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17691171449435797		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.17691171449435797 | validation: 0.21200330255828215]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16153023755334905		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.16153023755334905 | validation: 0.21730976863619753]
	TIME [epoch: 11.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1803601848538933		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.1803601848538933 | validation: 0.23280644444968832]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17569659215014785		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.17569659215014785 | validation: 0.20937889568628545]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17764467896017372		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.17764467896017372 | validation: 0.22176618126371317]
	TIME [epoch: 11.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17238961346519674		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.17238961346519674 | validation: 0.2450533251758144]
	TIME [epoch: 11.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18704331088609882		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.18704331088609882 | validation: 0.23623541900084724]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17007300635537267		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.17007300635537267 | validation: 0.22062746851192783]
	TIME [epoch: 11.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19149071523924382		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.19149071523924382 | validation: 0.227911068477265]
	TIME [epoch: 11.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18469641700619055		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.18469641700619055 | validation: 0.20914207995099843]
	TIME [epoch: 11.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18184408006308916		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.18184408006308916 | validation: 0.2196056542942124]
	TIME [epoch: 11.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1658647831670786		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.1658647831670786 | validation: 0.2362844489434866]
	TIME [epoch: 11.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17619729559351444		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.17619729559351444 | validation: 0.2393160616744589]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20019992385267302		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.20019992385267302 | validation: 0.1979489607337692]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_944.pth
	Model improved!!!
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16351261141346507		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.16351261141346507 | validation: 0.22516574710171816]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1763640161513877		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.1763640161513877 | validation: 0.19056084222447098]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_946.pth
	Model improved!!!
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15812337628576809		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.15812337628576809 | validation: 0.23745543785735726]
	TIME [epoch: 11.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18123886876854697		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.18123886876854697 | validation: 0.21089753946337808]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16510387299468646		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.16510387299468646 | validation: 0.21327959024888046]
	TIME [epoch: 11.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1886252176682756		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.1886252176682756 | validation: 0.20969844526273973]
	TIME [epoch: 11.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17026338893177798		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.17026338893177798 | validation: 0.20707253147673158]
	TIME [epoch: 11.6 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18526464911892943		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.18526464911892943 | validation: 0.2764249700227611]
	TIME [epoch: 11.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20600616587427853		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.20600616587427853 | validation: 0.26257814174216443]
	TIME [epoch: 11.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2166040046194665		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.2166040046194665 | validation: 0.24491244913734456]
	TIME [epoch: 11.6 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22590653524664212		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.22590653524664212 | validation: 0.2910883612281302]
	TIME [epoch: 11.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29106068251059286		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.29106068251059286 | validation: 0.2787641671769704]
	TIME [epoch: 11.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2479878622230323		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.2479878622230323 | validation: 0.2513802071799206]
	TIME [epoch: 11.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21548459237350276		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.21548459237350276 | validation: 0.23627756166506558]
	TIME [epoch: 11.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19685287366039014		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.19685287366039014 | validation: 0.23519364831674452]
	TIME [epoch: 11.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1912575093754921		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.1912575093754921 | validation: 0.25047292888777983]
	TIME [epoch: 11.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088262299465415		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.2088262299465415 | validation: 0.23270468597193703]
	TIME [epoch: 11.6 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1793600251487616		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.1793600251487616 | validation: 0.21560197698909883]
	TIME [epoch: 11.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1748719695367834		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.1748719695367834 | validation: 0.23090816075177606]
	TIME [epoch: 11.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19360183896470143		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.19360183896470143 | validation: 0.22572269137896292]
	TIME [epoch: 11.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1915611384485281		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.1915611384485281 | validation: 0.24973160203664202]
	TIME [epoch: 11.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21253626404286655		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.21253626404286655 | validation: 0.25381735826861623]
	TIME [epoch: 11.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19773162265070154		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.19773162265070154 | validation: 0.20665412880170414]
	TIME [epoch: 11.6 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17365236059282982		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.17365236059282982 | validation: 0.22092332742345336]
	TIME [epoch: 11.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17377109147649275		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.17377109147649275 | validation: 0.20935879214850628]
	TIME [epoch: 11.6 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1724513202451869		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.1724513202451869 | validation: 0.21917494601405296]
	TIME [epoch: 11.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18041203369822117		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.18041203369822117 | validation: 0.23098840951312816]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17633636039342446		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.17633636039342446 | validation: 0.20550633623026177]
	TIME [epoch: 11.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17064698449524457		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.17064698449524457 | validation: 0.21535245257458122]
	TIME [epoch: 11.6 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15512263820830313		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.15512263820830313 | validation: 0.19778072462690688]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16464384338261295		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.16464384338261295 | validation: 0.1976815026696039]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16599213554324557		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.16599213554324557 | validation: 0.2147862246158628]
	TIME [epoch: 11.6 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17247212229778758		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.17247212229778758 | validation: 0.2533393932264005]
	TIME [epoch: 11.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19128701179792976		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.19128701179792976 | validation: 0.22494511845423135]
	TIME [epoch: 11.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18132010731028142		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.18132010731028142 | validation: 0.21184239742682312]
	TIME [epoch: 11.6 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1642927151603552		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.1642927151603552 | validation: 0.2083971203555403]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16531688001660158		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.16531688001660158 | validation: 0.22394637701908351]
	TIME [epoch: 11.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20168343550136417		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.20168343550136417 | validation: 0.2596936459400583]
	TIME [epoch: 11.6 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2240375625957311		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.2240375625957311 | validation: 0.2581502003732612]
	TIME [epoch: 11.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20340039999869172		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.20340039999869172 | validation: 0.20895938016038088]
	TIME [epoch: 11.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20900323616496713		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.20900323616496713 | validation: 0.3028217164032332]
	TIME [epoch: 11.6 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2560459693906506		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.2560459693906506 | validation: 0.2615978189673823]
	TIME [epoch: 11.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22227826132416495		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.22227826132416495 | validation: 0.23733240202380226]
	TIME [epoch: 11.6 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19603064740550774		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.19603064740550774 | validation: 0.2109521177756315]
	TIME [epoch: 11.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2050400325101867		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.2050400325101867 | validation: 0.22822334402664596]
	TIME [epoch: 11.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2064077556722967		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.2064077556722967 | validation: 0.22025006304825717]
	TIME [epoch: 11.6 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19187686656989197		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.19187686656989197 | validation: 0.19851264838254754]
	TIME [epoch: 11.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17341158021227443		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.17341158021227443 | validation: 0.22859700854526716]
	TIME [epoch: 11.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18082297763366198		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.18082297763366198 | validation: 0.20558855270544146]
	TIME [epoch: 11.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17829273244566338		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.17829273244566338 | validation: 0.20256545400321394]
	TIME [epoch: 11.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1867477155537218		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.1867477155537218 | validation: 0.2122005508536124]
	TIME [epoch: 11.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19816128468448993		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.19816128468448993 | validation: 0.22305898544835068]
	TIME [epoch: 11.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1691412491139024		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.1691412491139024 | validation: 0.19378943040209065]
	TIME [epoch: 11.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16230620655025238		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.16230620655025238 | validation: 0.19511963975406357]
	TIME [epoch: 11.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17203897054003636		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.17203897054003636 | validation: 0.20011870426595132]
	TIME [epoch: 11.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16112144224777375		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.16112144224777375 | validation: 0.1889018331093749]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1000.pth
	Model improved!!!
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16845653100507313		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.16845653100507313 | validation: 0.217666820554037]
	TIME [epoch: 11.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17567239139456384		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.17567239139456384 | validation: 0.2153192317788831]
	TIME [epoch: 11.6 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17915685485804567		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.17915685485804567 | validation: 0.19814809004775705]
	TIME [epoch: 11.6 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17297019246868328		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.17297019246868328 | validation: 0.18881062859091075]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1004.pth
	Model improved!!!
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15490696555488875		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.15490696555488875 | validation: 0.18981293149067335]
	TIME [epoch: 11.6 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15951546947736647		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.15951546947736647 | validation: 0.18254648579715202]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1006.pth
	Model improved!!!
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1575456956808265		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.1575456956808265 | validation: 0.2250003067295857]
	TIME [epoch: 11.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16613613857666568		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.16613613857666568 | validation: 0.19993935464425236]
	TIME [epoch: 11.6 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15436321494152933		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.15436321494152933 | validation: 0.17727315240887018]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1009.pth
	Model improved!!!
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16214219960607484		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.16214219960607484 | validation: 0.18703864427985312]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17137918044521633		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.17137918044521633 | validation: 0.1961396185706731]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17224349386944843		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.17224349386944843 | validation: 0.24591395922390696]
	TIME [epoch: 11.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20426920490281142		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.20426920490281142 | validation: 0.1918652270484134]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16757293893390904		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.16757293893390904 | validation: 0.20517872240177112]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16257430503366632		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.16257430503366632 | validation: 0.18331422921483168]
	TIME [epoch: 11.6 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15382032649986555		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.15382032649986555 | validation: 0.19671213080870353]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1547682384793932		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.1547682384793932 | validation: 0.21412397650270173]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17394102294676173		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.17394102294676173 | validation: 0.20085222883920342]
	TIME [epoch: 11.6 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17133482458419008		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.17133482458419008 | validation: 0.21288935046383625]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1856833448483877		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.1856833448483877 | validation: 0.21101254407092057]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1765467124962644		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.1765467124962644 | validation: 0.19601074445423655]
	TIME [epoch: 11.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16171869615942838		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.16171869615942838 | validation: 0.21356330562620757]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17434784110672294		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.17434784110672294 | validation: 0.1980929500798066]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1650079205174506		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.1650079205174506 | validation: 0.21948254508561568]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17941535261970304		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.17941535261970304 | validation: 0.17689731429994915]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1025.pth
	Model improved!!!
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16082536789797705		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.16082536789797705 | validation: 0.21983679562228559]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17519546845173126		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.17519546845173126 | validation: 0.22033353167917852]
	TIME [epoch: 11.6 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1700688776409963		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.1700688776409963 | validation: 0.2097148688035499]
	TIME [epoch: 11.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18041608364590805		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.18041608364590805 | validation: 0.23567445153288824]
	TIME [epoch: 11.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17783172384259124		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.17783172384259124 | validation: 0.2505766698982826]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21222479987522178		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.21222479987522178 | validation: 0.22212833760024417]
	TIME [epoch: 11.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16760300555716637		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.16760300555716637 | validation: 0.20330770337109844]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165891303904048		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.165891303904048 | validation: 0.21317492849811706]
	TIME [epoch: 11.6 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.169103387454862		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.169103387454862 | validation: 0.18053365134628918]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15255880768324612		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.15255880768324612 | validation: 0.20982511653123267]
	TIME [epoch: 11.6 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670296244078802		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.1670296244078802 | validation: 0.25399170588550424]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.196378737662821		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.196378737662821 | validation: 0.22178464316046675]
	TIME [epoch: 11.6 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16083822241859044		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.16083822241859044 | validation: 0.1828933693395031]
	TIME [epoch: 11.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1801829757050577		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.1801829757050577 | validation: 0.2109383374119484]
	TIME [epoch: 11.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17296254596739738		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.17296254596739738 | validation: 0.2033356699304671]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16011148789211246		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.16011148789211246 | validation: 0.19165622234013113]
	TIME [epoch: 11.6 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15339034515963668		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.15339034515963668 | validation: 0.1745075265851685]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1042.pth
	Model improved!!!
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14895174048606483		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.14895174048606483 | validation: 0.1866934707758401]
	TIME [epoch: 11.6 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15496125500121782		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.15496125500121782 | validation: 0.20531159508754981]
	TIME [epoch: 11.6 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16282255321952438		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.16282255321952438 | validation: 0.20646336486529643]
	TIME [epoch: 11.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16955446676052274		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.16955446676052274 | validation: 0.2325744786895615]
	TIME [epoch: 11.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1759803295317542		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.1759803295317542 | validation: 0.22933352427757356]
	TIME [epoch: 11.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16341022819803203		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.16341022819803203 | validation: 0.19910655901197313]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15798076436490235		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.15798076436490235 | validation: 0.20365213170590235]
	TIME [epoch: 11.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18472728366213406		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.18472728366213406 | validation: 0.21096903560081032]
	TIME [epoch: 11.6 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663748739683172		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.1663748739683172 | validation: 0.20719784251244355]
	TIME [epoch: 11.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16279249310664337		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.16279249310664337 | validation: 0.21288367583234308]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17297938819321063		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.17297938819321063 | validation: 0.22734003999801253]
	TIME [epoch: 11.6 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18018477225495333		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.18018477225495333 | validation: 0.19249291604977142]
	TIME [epoch: 11.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1622769223570064		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.1622769223570064 | validation: 0.2169084003440171]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17464336577750778		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.17464336577750778 | validation: 0.2390611764960231]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18730196154503062		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.18730196154503062 | validation: 0.23805003287205742]
	TIME [epoch: 11.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18182266665813715		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.18182266665813715 | validation: 0.1965309960477272]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16275849475524104		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.16275849475524104 | validation: 0.20329172198945064]
	TIME [epoch: 11.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18277215008801112		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.18277215008801112 | validation: 0.18737085483739596]
	TIME [epoch: 11.6 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603725163227449		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.1603725163227449 | validation: 0.21529790783591132]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17904685745877771		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.17904685745877771 | validation: 0.19666480773448405]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16723848024203056		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.16723848024203056 | validation: 0.20685086736052946]
	TIME [epoch: 11.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15906324057066534		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.15906324057066534 | validation: 0.19886894749556625]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630341748688162		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.1630341748688162 | validation: 0.19273633346399116]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16591499742509663		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.16591499742509663 | validation: 0.19372820360409237]
	TIME [epoch: 11.6 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17016254159636746		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.17016254159636746 | validation: 0.2384148767421217]
	TIME [epoch: 11.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1875065965645214		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.1875065965645214 | validation: 0.21772564616334844]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16784134252538085		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.16784134252538085 | validation: 0.1963598809042213]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15931730192937082		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.15931730192937082 | validation: 0.19453859133371013]
	TIME [epoch: 11.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15672114373822052		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.15672114373822052 | validation: 0.19512108815582807]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16707581646913508		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.16707581646913508 | validation: 0.2429059356587124]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1859372651498191		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.1859372651498191 | validation: 0.21502219515986223]
	TIME [epoch: 11.6 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16988408278089942		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.16988408278089942 | validation: 0.21812632855428857]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17664934497625992		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.17664934497625992 | validation: 0.2064266196793038]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16199447185585178		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.16199447185585178 | validation: 0.1899222755837567]
	TIME [epoch: 11.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15670701412545165		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.15670701412545165 | validation: 0.21213724559467012]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16726372327789601		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.16726372327789601 | validation: 0.18617337189391275]
	TIME [epoch: 11.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15887680621448952		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.15887680621448952 | validation: 0.18238097312617227]
	TIME [epoch: 11.6 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15181086136518196		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.15181086136518196 | validation: 0.1961676526141596]
	TIME [epoch: 11.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15033452597902763		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.15033452597902763 | validation: 0.20147000291397732]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15761394001112972		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.15761394001112972 | validation: 0.21005751996992927]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16143414679637916		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.16143414679637916 | validation: 0.20384105893815588]
	TIME [epoch: 11.6 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15722283435815249		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.15722283435815249 | validation: 0.19200793666386556]
	TIME [epoch: 11.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15278079168537234		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.15278079168537234 | validation: 0.19917948186825934]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15496153311614214		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.15496153311614214 | validation: 0.1987065468334746]
	TIME [epoch: 11.6 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1519424923162933		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.1519424923162933 | validation: 0.1981219697321594]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14924421433606005		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.14924421433606005 | validation: 0.19228516768155607]
	TIME [epoch: 11.6 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18070378701375744		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.18070378701375744 | validation: 0.23077290778361975]
	TIME [epoch: 11.6 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16370671614824303		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.16370671614824303 | validation: 0.19456701710635682]
	TIME [epoch: 11.6 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16946084034131598		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.16946084034131598 | validation: 0.22932374822084747]
	TIME [epoch: 11.6 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1819811587318314		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.1819811587318314 | validation: 0.21495778349525566]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517401493272727		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.1517401493272727 | validation: 0.20417963666673178]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15215458993897277		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.15215458993897277 | validation: 0.1923824407300046]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15920481295212768		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.15920481295212768 | validation: 0.21892032404602077]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16669342337070214		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.16669342337070214 | validation: 0.1850135886878122]
	TIME [epoch: 11.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14982517996996494		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.14982517996996494 | validation: 0.20015139087677597]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496452688368419		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.1496452688368419 | validation: 0.20528104409859704]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16212000474526833		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.16212000474526833 | validation: 0.21191537750808434]
	TIME [epoch: 11.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16636358137654522		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.16636358137654522 | validation: 0.18737542012925126]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16999263815402044		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.16999263815402044 | validation: 0.20641395426700007]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17756376660818846		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.17756376660818846 | validation: 0.19510656036204485]
	TIME [epoch: 11.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15375157973007597		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.15375157973007597 | validation: 0.18672908768135457]
	TIME [epoch: 11.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14734034153201248		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.14734034153201248 | validation: 0.2046370595525905]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16068045150191979		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.16068045150191979 | validation: 0.2067885622807044]
	TIME [epoch: 11.6 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15246230259649804		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.15246230259649804 | validation: 0.18728459074218176]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515676095897358		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.1515676095897358 | validation: 0.21066734777511462]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550910347599952		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.1550910347599952 | validation: 0.19922502116494023]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14567074282787779		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.14567074282787779 | validation: 0.18815550351063148]
	TIME [epoch: 11.6 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14466115391190956		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.14466115391190956 | validation: 0.18569663595716038]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15668644062300502		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.15668644062300502 | validation: 0.20327206652609295]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16680866796013044		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.16680866796013044 | validation: 0.18794361583839014]
	TIME [epoch: 11.6 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1589274984501151		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.1589274984501151 | validation: 0.18990915656400936]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555805043294024		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.1555805043294024 | validation: 0.19120513688198068]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16358566689056975		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.16358566689056975 | validation: 0.18103645538725688]
	TIME [epoch: 11.6 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16321004835214037		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.16321004835214037 | validation: 0.21325965347639567]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16989449014661867		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.16989449014661867 | validation: 0.21581964157321323]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1689490760311859		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.1689490760311859 | validation: 0.20714666370993068]
	TIME [epoch: 11.6 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1642990524281039		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.1642990524281039 | validation: 0.1982427625589844]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16399603942446556		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.16399603942446556 | validation: 0.2256683040196381]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17755395183129724		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.17755395183129724 | validation: 0.21569327780242098]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1716514205760546		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.1716514205760546 | validation: 0.18491901322400928]
	TIME [epoch: 11.6 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16758562998069265		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.16758562998069265 | validation: 0.23193332447646484]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19114188955325054		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.19114188955325054 | validation: 0.22310148910431643]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1757555292772629		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.1757555292772629 | validation: 0.21762487621543097]
	TIME [epoch: 11.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17133848811789987		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.17133848811789987 | validation: 0.19917551469816105]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1551570610230364		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.1551570610230364 | validation: 0.18469629483157005]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16091019218345878		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.16091019218345878 | validation: 0.17794841682888277]
	TIME [epoch: 11.6 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15416509969237346		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.15416509969237346 | validation: 0.20766996171324706]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16695991839186197		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.16695991839186197 | validation: 0.1935737872840845]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16224107965667323		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.16224107965667323 | validation: 0.1928094089476074]
	TIME [epoch: 11.6 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15387416426178496		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.15387416426178496 | validation: 0.19473933387443004]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16492329709507952		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.16492329709507952 | validation: 0.21730266541302307]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16039591049630325		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.16039591049630325 | validation: 0.1860544776704153]
	TIME [epoch: 11.6 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15813734741432517		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.15813734741432517 | validation: 0.19506519290341026]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17352086234580688		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.17352086234580688 | validation: 0.19477849041319126]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1741138277561955		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.1741138277561955 | validation: 0.18017712451921727]
	TIME [epoch: 11.6 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1653175938201502		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.1653175938201502 | validation: 0.174490325502302]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1138.pth
	Model improved!!!
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15141036756846218		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.15141036756846218 | validation: 0.17896818500784403]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1594772839769368		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.1594772839769368 | validation: 0.1849957262958634]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15480846830600622		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.15480846830600622 | validation: 0.18871862101589187]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15236186759395898		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.15236186759395898 | validation: 0.18232328388272911]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1513568302369379		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.1513568302369379 | validation: 0.19349008332850212]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518429723062068		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.1518429723062068 | validation: 0.19735372844386656]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15282975317370984		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.15282975317370984 | validation: 0.1873590456412591]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477641296556774		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.1477641296556774 | validation: 0.17848412660822896]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15095779075894644		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.15095779075894644 | validation: 0.19333696031338554]
	TIME [epoch: 11.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14133391365805575		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.14133391365805575 | validation: 0.19606140846538972]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14727923808556026		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.14727923808556026 | validation: 0.20707568528264594]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16346699293383812		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.16346699293383812 | validation: 0.22524882528433615]
	TIME [epoch: 11.6 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.164334942524207		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.164334942524207 | validation: 0.19196379729310892]
	TIME [epoch: 11.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544344115666256		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.1544344115666256 | validation: 0.1804326101297427]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15499226124116539		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.15499226124116539 | validation: 0.177872993124441]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438724809114355		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.1438724809114355 | validation: 0.17439340419024163]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1154.pth
	Model improved!!!
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1491237249783573		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.1491237249783573 | validation: 0.17762911043808963]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15229837150468054		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.15229837150468054 | validation: 0.17789298461918293]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14856660278120462		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.14856660278120462 | validation: 0.1980883312282019]
	TIME [epoch: 11.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14427401520587343		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.14427401520587343 | validation: 0.17960029787671605]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14199798981258382		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.14199798981258382 | validation: 0.19008145638375568]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1474642597330545		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.1474642597330545 | validation: 0.1834557241835149]
	TIME [epoch: 11.6 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14229438932276736		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.14229438932276736 | validation: 0.17792665537616362]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14243679811084994		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.14243679811084994 | validation: 0.18924563560301136]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381228653393117		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.1381228653393117 | validation: 0.1820415959628175]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14304785712224638		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.14304785712224638 | validation: 0.1764593458702208]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14226012985708125		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.14226012985708125 | validation: 0.18344132168145308]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14812990908646856		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.14812990908646856 | validation: 0.18685417366446228]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13875135358992102		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.13875135358992102 | validation: 0.17768062074169472]
	TIME [epoch: 11.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13707354133694016		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.13707354133694016 | validation: 0.18277161356501487]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14416933526930592		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.14416933526930592 | validation: 0.1964579329617597]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16090259368236304		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.16090259368236304 | validation: 0.19339274695185593]
	TIME [epoch: 11.6 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1480338061158603		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.1480338061158603 | validation: 0.18050700526368182]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13996413701596366		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.13996413701596366 | validation: 0.1823809597686791]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1507260295955477		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.1507260295955477 | validation: 0.1862271408563171]
	TIME [epoch: 11.6 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1475082587573512		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.1475082587573512 | validation: 0.20118346225842637]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14803267377783824		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.14803267377783824 | validation: 0.19723413546507032]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1519562535931881		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.1519562535931881 | validation: 0.20028911594205487]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15394110067842678		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.15394110067842678 | validation: 0.19011360877275507]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15451758580962827		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.15451758580962827 | validation: 0.1885525113247622]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15425350925952824		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.15425350925952824 | validation: 0.19807467832855338]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16317692703616354		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.16317692703616354 | validation: 0.1943882473847628]
	TIME [epoch: 11.6 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1673660644174938		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.1673660644174938 | validation: 0.20876689198389847]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1736012068446892		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.1736012068446892 | validation: 0.20457203358345222]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16213328623048798		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.16213328623048798 | validation: 0.20394772392853647]
	TIME [epoch: 11.6 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16363408004939411		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.16363408004939411 | validation: 0.21042450675377375]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16175463693373088		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.16175463693373088 | validation: 0.21143196974138023]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15974082296163053		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.15974082296163053 | validation: 0.20078273706191652]
	TIME [epoch: 11.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677360547556193		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.1677360547556193 | validation: 0.1963745443502332]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15283417205770594		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.15283417205770594 | validation: 0.19315046910023564]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15211616932608257		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.15211616932608257 | validation: 0.1952185118641925]
	TIME [epoch: 11.6 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15068065839174125		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.15068065839174125 | validation: 0.19488853984651042]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477941586621176		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.1477941586621176 | validation: 0.19078266280162884]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15529055634675795		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.15529055634675795 | validation: 0.19167716814054736]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468504558774824		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.1468504558774824 | validation: 0.18519772014624994]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14459385786524165		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.14459385786524165 | validation: 0.19594561591699772]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16676559699991628		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.16676559699991628 | validation: 0.20065511500535452]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16484954166913246		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.16484954166913246 | validation: 0.1961005294358961]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1624065654406208		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.1624065654406208 | validation: 0.2053813467199806]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1685460740345701		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.1685460740345701 | validation: 0.20093526335008915]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16309592255536454		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.16309592255536454 | validation: 0.20101009833776418]
	TIME [epoch: 11.6 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16446818550028136		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.16446818550028136 | validation: 0.19557000249787987]
	TIME [epoch: 11.6 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16055919983696854		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.16055919983696854 | validation: 0.1973717291927254]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16568737020386756		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.16568737020386756 | validation: 0.19339353808469878]
	TIME [epoch: 11.6 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17084626795547436		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.17084626795547436 | validation: 0.19723813015422972]
	TIME [epoch: 11.6 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616078302130542		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.1616078302130542 | validation: 0.19142679119375647]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557103214341638		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.1557103214341638 | validation: 0.19932328462626145]
	TIME [epoch: 11.6 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15599857024648361		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.15599857024648361 | validation: 0.17803693056172157]
	TIME [epoch: 11.6 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1548910937129681		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.1548910937129681 | validation: 0.1772380982415933]
	TIME [epoch: 11.6 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15184400195474101		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.15184400195474101 | validation: 0.19156387022877489]
	TIME [epoch: 11.6 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17560240162327295		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.17560240162327295 | validation: 0.23042234151771587]
	TIME [epoch: 11.6 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19393401761831944		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.19393401761831944 | validation: 0.21232393401257632]
	TIME [epoch: 11.6 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17551305186777888		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.17551305186777888 | validation: 0.20426050523432404]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16514340239535255		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.16514340239535255 | validation: 0.1978834998524581]
	TIME [epoch: 11.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15783418206617922		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.15783418206617922 | validation: 0.20498800106092327]
	TIME [epoch: 11.6 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15482626893878831		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.15482626893878831 | validation: 0.19958085008443407]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15289992322848459		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.15289992322848459 | validation: 0.19032060230819206]
	TIME [epoch: 11.6 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153617713096848		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.153617713096848 | validation: 0.1800570086873483]
	TIME [epoch: 11.6 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487549077036352		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.1487549077036352 | validation: 0.19209971768253797]
	TIME [epoch: 11.6 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14964247740618436		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.14964247740618436 | validation: 0.19364512206316767]
	TIME [epoch: 11.6 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14931072879184226		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.14931072879184226 | validation: 0.18837467383659856]
	TIME [epoch: 11.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15268775578714483		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.15268775578714483 | validation: 0.1879839007063775]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15510395965544643		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.15510395965544643 | validation: 0.21673060874654176]
	TIME [epoch: 11.6 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18134064802918548		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.18134064802918548 | validation: 0.2508188670291599]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1840074241132747		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.1840074241132747 | validation: 0.20437266764548662]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530362386260748		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.1530362386260748 | validation: 0.2063675843090347]
	TIME [epoch: 11.6 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16159058462398923		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.16159058462398923 | validation: 0.20982120289554637]
	TIME [epoch: 11.6 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523508006463027		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.1523508006463027 | validation: 0.17737536434836462]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14413872484999907		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.14413872484999907 | validation: 0.18602499307843523]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14439554213008732		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.14439554213008732 | validation: 0.17898178344716215]
	TIME [epoch: 11.6 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.147022448313783		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.147022448313783 | validation: 0.1893578328706573]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379177244563916		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.1379177244563916 | validation: 0.1755371322374596]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14418992384225654		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.14418992384225654 | validation: 0.19218498890341937]
	TIME [epoch: 11.6 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15315719460206317		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.15315719460206317 | validation: 0.18804256045972575]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1655847522168028		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.1655847522168028 | validation: 0.21794262217533913]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16616590827216102		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.16616590827216102 | validation: 0.19288785001628087]
	TIME [epoch: 11.6 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15608670582636994		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.15608670582636994 | validation: 0.18691067638437947]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14770252571772238		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.14770252571772238 | validation: 0.1996014985839767]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14935244435440395		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.14935244435440395 | validation: 0.1920301092032939]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1492119691563475		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.1492119691563475 | validation: 0.2010944061550814]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14437554195470093		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.14437554195470093 | validation: 0.1849585212031966]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487735568674649		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.1487735568674649 | validation: 0.18946755887571876]
	TIME [epoch: 11.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15293787486253657		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.15293787486253657 | validation: 0.19188736243609558]
	TIME [epoch: 11.6 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1475852414772476		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.1475852414772476 | validation: 0.1923372439246518]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488935093644853		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.1488935093644853 | validation: 0.18465080482744942]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15017269170925399		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.15017269170925399 | validation: 0.17843308369124222]
	TIME [epoch: 11.6 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14541639518869529		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.14541639518869529 | validation: 0.16991812652439023]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1245.pth
	Model improved!!!
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481341428281856		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.1481341428281856 | validation: 0.18395295247518278]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15801046624425785		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.15801046624425785 | validation: 0.21293059464650335]
	TIME [epoch: 11.6 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17938758880866387		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.17938758880866387 | validation: 0.20429688854922373]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1755835407794725		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.1755835407794725 | validation: 0.2118165906479126]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17064905829062213		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.17064905829062213 | validation: 0.19401591428761156]
	TIME [epoch: 11.6 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15729697114539998		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.15729697114539998 | validation: 0.18757513823849167]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15869349530905805		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.15869349530905805 | validation: 0.19246943213742884]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16098576869090478		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.16098576869090478 | validation: 0.1864955569924052]
	TIME [epoch: 11.6 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15296191499136488		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.15296191499136488 | validation: 0.18845704840650726]
	TIME [epoch: 11.6 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16109022521333258		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.16109022521333258 | validation: 0.18365066004634806]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14794561668468428		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.14794561668468428 | validation: 0.1817790501749137]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14906969487202382		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.14906969487202382 | validation: 0.19315373293168944]
	TIME [epoch: 11.6 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15472785641407288		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.15472785641407288 | validation: 0.18587147647485247]
	TIME [epoch: 11.6 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14716286265211087		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.14716286265211087 | validation: 0.22229861188958736]
	TIME [epoch: 11.6 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1699151993027303		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.1699151993027303 | validation: 0.20329766298683613]
	TIME [epoch: 11.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478229282870156		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.1478229282870156 | validation: 0.19095749654850275]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143176957324464		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.143176957324464 | validation: 0.1815288138292969]
	TIME [epoch: 11.6 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14315057579715193		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.14315057579715193 | validation: 0.1879423452618319]
	TIME [epoch: 11.6 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13606510706298425		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.13606510706298425 | validation: 0.17643462565568263]
	TIME [epoch: 11.6 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13810029182858724		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.13810029182858724 | validation: 0.1873708764156985]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13756733468058086		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.13756733468058086 | validation: 0.1843087523484946]
	TIME [epoch: 11.6 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355172817842747		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.1355172817842747 | validation: 0.1761891791924067]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374299157763422		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.1374299157763422 | validation: 0.18151502790558866]
	TIME [epoch: 11.6 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13980788429215696		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.13980788429215696 | validation: 0.1985916243331613]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13573321025789709		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.13573321025789709 | validation: 0.18948122884233903]
	TIME [epoch: 11.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14026293740187798		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.14026293740187798 | validation: 0.181276994485999]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14146054666305302		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.14146054666305302 | validation: 0.17756984821283348]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13993062194583544		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.13993062194583544 | validation: 0.18021294931572088]
	TIME [epoch: 11.6 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396348212824841		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.1396348212824841 | validation: 0.1776747098713706]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1444447536366046		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.1444447536366046 | validation: 0.1951108112547841]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14543468860731334		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.14543468860731334 | validation: 0.1761968204389625]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390499938830275		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.1390499938830275 | validation: 0.178666708823681]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14213816687113054		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.14213816687113054 | validation: 0.18738517526000953]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14033174669583026		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.14033174669583026 | validation: 0.17225836824495339]
	TIME [epoch: 11.6 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379321315253501		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.1379321315253501 | validation: 0.17216645219552518]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13749933418591298		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.13749933418591298 | validation: 0.1825591020264241]
	TIME [epoch: 11.6 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421271163109253		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.1421271163109253 | validation: 0.19786751916500145]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15644068873329892		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.15644068873329892 | validation: 0.19241394316589983]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13676845669858437		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.13676845669858437 | validation: 0.19912598780166504]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13756169533287188		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.13756169533287188 | validation: 0.18743081976792694]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14079997002491815		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.14079997002491815 | validation: 0.18147784450237794]
	TIME [epoch: 11.6 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13615689552503546		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.13615689552503546 | validation: 0.17876276045626038]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13810013273921762		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.13810013273921762 | validation: 0.17351231158506866]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14026296797862414		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.14026296797862414 | validation: 0.17952532080071984]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14639518549954694		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.14639518549954694 | validation: 0.1849257330578008]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441413147702142		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.1441413147702142 | validation: 0.17884372381697008]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14864007984221314		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.14864007984221314 | validation: 0.1797167823378245]
	TIME [epoch: 11.6 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13626072308828763		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.13626072308828763 | validation: 0.16714066214304954]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1293.pth
	Model improved!!!
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13519783549975928		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.13519783549975928 | validation: 0.17276585549645035]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334032780455892		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.1334032780455892 | validation: 0.1795412606368315]
	TIME [epoch: 11.6 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13384786291079664		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.13384786291079664 | validation: 0.179957788057594]
	TIME [epoch: 11.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13875524560644623		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.13875524560644623 | validation: 0.17664808339628038]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383176407073536		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.1383176407073536 | validation: 0.17289628866832601]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14036648919255632		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.14036648919255632 | validation: 0.19001443360229914]
	TIME [epoch: 11.6 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13710323020821225		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.13710323020821225 | validation: 0.1725314537129234]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334053296991249		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.1334053296991249 | validation: 0.1622075214705145]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1301.pth
	Model improved!!!
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13380965646960044		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.13380965646960044 | validation: 0.18605117455624462]
	TIME [epoch: 11.6 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14268414725211204		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.14268414725211204 | validation: 0.17402257674022362]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374019564904514		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.1374019564904514 | validation: 0.18082676619851953]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1378959156114644		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.1378959156114644 | validation: 0.18156466785403802]
	TIME [epoch: 11.6 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300287114043652		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.1300287114043652 | validation: 0.1781267827490386]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403957482114502		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.1403957482114502 | validation: 0.19815633633376797]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13932914355584786		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.13932914355584786 | validation: 0.19089044887200143]
	TIME [epoch: 11.6 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13820975572490354		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.13820975572490354 | validation: 0.17575791415591327]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13531103632436225		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.13531103632436225 | validation: 0.17932734719576948]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13137223139169035		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.13137223139169035 | validation: 0.17974647745406025]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13424559338320524		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.13424559338320524 | validation: 0.17050144172261]
	TIME [epoch: 11.6 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13673376580714244		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.13673376580714244 | validation: 0.17538894894419532]
	TIME [epoch: 11.6 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365038817158731		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.1365038817158731 | validation: 0.18131120159426437]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13219217236826408		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.13219217236826408 | validation: 0.1645307572778097]
	TIME [epoch: 11.6 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13605248124468894		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.13605248124468894 | validation: 0.1769304734059402]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1349756517334511		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.1349756517334511 | validation: 0.1722624471875735]
	TIME [epoch: 11.6 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356048254340413		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.1356048254340413 | validation: 0.17834276833893864]
	TIME [epoch: 11.6 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15127842368222336		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.15127842368222336 | validation: 0.18364856487941938]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1593199951599275		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.1593199951599275 | validation: 0.18366002540887302]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523377653887883		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.1523377653887883 | validation: 0.1847023150758613]
	TIME [epoch: 11.6 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621451231323079		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.1621451231323079 | validation: 0.18635132989609499]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16182018121972805		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.16182018121972805 | validation: 0.19716326281727373]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15678638872427902		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.15678638872427902 | validation: 0.19683878609725278]
	TIME [epoch: 11.6 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15185793306755246		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.15185793306755246 | validation: 0.19599644142627612]
	TIME [epoch: 11.6 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14249080394653207		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.14249080394653207 | validation: 0.18337708657839294]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14006940361591663		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.14006940361591663 | validation: 0.17456897497904145]
	TIME [epoch: 11.6 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13883551518796322		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.13883551518796322 | validation: 0.17770216257156585]
	TIME [epoch: 11.6 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13365383973994444		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.13365383973994444 | validation: 0.17606917458154314]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13760185039342332		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.13760185039342332 | validation: 0.1872384346486738]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14362300624087415		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.14362300624087415 | validation: 0.17820828612796522]
	TIME [epoch: 11.6 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138175188472251		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.138175188472251 | validation: 0.17761649400909582]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13776914258661593		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.13776914258661593 | validation: 0.1816813929661797]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13267056155446516		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.13267056155446516 | validation: 0.18447379920413892]
	TIME [epoch: 11.6 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354734967738963		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.1354734967738963 | validation: 0.18210030278184938]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14613944167081316		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.14613944167081316 | validation: 0.17943866670113776]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14813880577999583		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.14813880577999583 | validation: 0.18215238104925463]
	TIME [epoch: 11.6 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14598051161354048		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.14598051161354048 | validation: 0.18258824304736812]
	TIME [epoch: 11.6 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13749986722717908		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.13749986722717908 | validation: 0.18377625219187693]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14587553133495873		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.14587553133495873 | validation: 0.19192110251065433]
	TIME [epoch: 11.6 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14623650068496746		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.14623650068496746 | validation: 0.17918914572491848]
	TIME [epoch: 11.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526483615213023		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.1526483615213023 | validation: 0.18845630490948184]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1511466355719186		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.1511466355719186 | validation: 0.18998362397018106]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1473089114480846		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.1473089114480846 | validation: 0.17521870920657256]
	TIME [epoch: 11.6 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14546975376035023		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.14546975376035023 | validation: 0.18013724186255303]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15570091002172523		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.15570091002172523 | validation: 0.19144765407189382]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15617855816801118		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.15617855816801118 | validation: 0.18994261709899904]
	TIME [epoch: 11.6 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1578326364540865		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.1578326364540865 | validation: 0.1984575281980959]
	TIME [epoch: 11.6 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16484801318921932		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.16484801318921932 | validation: 0.19555865595123817]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15767267952032105		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.15767267952032105 | validation: 0.20547385132965018]
	TIME [epoch: 11.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1580191099534108		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.1580191099534108 | validation: 0.19724804078260852]
	TIME [epoch: 11.6 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15537366380805778		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.15537366380805778 | validation: 0.20651329888834064]
	TIME [epoch: 11.6 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572843459093723		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.1572843459093723 | validation: 0.19282400230060082]
	TIME [epoch: 11.6 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15503394070230425		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.15503394070230425 | validation: 0.18454974437197166]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14863705008477593		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.14863705008477593 | validation: 0.17756230009249688]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1426643775461341		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.1426643775461341 | validation: 0.18522474424668187]
	TIME [epoch: 11.6 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14313039870090025		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.14313039870090025 | validation: 0.17462933827080576]
	TIME [epoch: 11.6 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14416280995336384		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.14416280995336384 | validation: 0.18109300190204977]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14654294294602163		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.14654294294602163 | validation: 0.17775192562753503]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13581928927922188		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.13581928927922188 | validation: 0.17781629966353532]
	TIME [epoch: 11.6 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13774012128876484		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.13774012128876484 | validation: 0.17485123417104576]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1359860932946334		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.1359860932946334 | validation: 0.1786029064442127]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13395255618043694		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.13395255618043694 | validation: 0.17531742044050277]
	TIME [epoch: 11.6 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1412897309523022		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.1412897309523022 | validation: 0.1758196243339896]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14068052124615363		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.14068052124615363 | validation: 0.1804480380746164]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14096843955853364		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.14096843955853364 | validation: 0.1748903120235673]
	TIME [epoch: 11.6 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13601503068840184		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.13601503068840184 | validation: 0.1735419754055122]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.134775304580425		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.134775304580425 | validation: 0.180506779200716]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1467845791342634		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.1467845791342634 | validation: 0.17694779746720596]
	TIME [epoch: 11.6 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13746865896017346		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.13746865896017346 | validation: 0.1718962606021117]
	TIME [epoch: 11.6 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13666951564793312		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.13666951564793312 | validation: 0.17382408200305757]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14118653628619746		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.14118653628619746 | validation: 0.18097384869025313]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346128070158042		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.1346128070158042 | validation: 0.175398436392357]
	TIME [epoch: 11.6 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1388873748592797		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.1388873748592797 | validation: 0.18613276021549197]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13805875537237042		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.13805875537237042 | validation: 0.1744832802284389]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13529414083834676		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.13529414083834676 | validation: 0.1732792456535576]
	TIME [epoch: 11.6 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13441576254915563		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.13441576254915563 | validation: 0.17799639287718763]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13756587535976392		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.13756587535976392 | validation: 0.1813493180280141]
	TIME [epoch: 11.6 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13826666182061814		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.13826666182061814 | validation: 0.17070862816288973]
	TIME [epoch: 11.6 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338960057605193		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.1338960057605193 | validation: 0.17725982349816619]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13510206327692148		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.13510206327692148 | validation: 0.18504371462827007]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14199420877637595		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.14199420877637595 | validation: 0.19093381504647816]
	TIME [epoch: 11.6 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14801811122419453		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.14801811122419453 | validation: 0.18042303357834538]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462187254639996		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.1462187254639996 | validation: 0.17739133052081626]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13886327316561642		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.13886327316561642 | validation: 0.1783208526906423]
	TIME [epoch: 11.6 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13527485493550806		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.13527485493550806 | validation: 0.17697817705165367]
	TIME [epoch: 11.6 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13062010166236798		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.13062010166236798 | validation: 0.16889856532752542]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13334332147084954		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.13334332147084954 | validation: 0.17924649893803443]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1443511659302032		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.1443511659302032 | validation: 0.18317602289045817]
	TIME [epoch: 11.6 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13469515851202948		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.13469515851202948 | validation: 0.1698261692458901]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13635500973470155		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.13635500973470155 | validation: 0.1789876804238342]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13392742320624665		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.13392742320624665 | validation: 0.170591200722112]
	TIME [epoch: 11.6 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304904373980048		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.1304904373980048 | validation: 0.1799898413265327]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335890047609981		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.1335890047609981 | validation: 0.18290461390028612]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317771777171233		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.1317771777171233 | validation: 0.1781733538571327]
	TIME [epoch: 11.6 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13492473621879614		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.13492473621879614 | validation: 0.1809757388532663]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13615035754589788		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.13615035754589788 | validation: 0.1668917363417517]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12824625825592623		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.12824625825592623 | validation: 0.175740832066974]
	TIME [epoch: 11.6 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13463622030350053		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.13463622030350053 | validation: 0.17617046642661294]
	TIME [epoch: 11.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13820245723130498		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.13820245723130498 | validation: 0.18369389088314758]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14036172727416119		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.14036172727416119 | validation: 0.17520214229492292]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13227509027152068		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.13227509027152068 | validation: 0.17523373723926353]
	TIME [epoch: 11.6 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13209906806010785		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.13209906806010785 | validation: 0.17818148638573864]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13262156120187135		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.13262156120187135 | validation: 0.17405776281457583]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342522641013956		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.1342522641013956 | validation: 0.19019847662661066]
	TIME [epoch: 11.6 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13749439204951935		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.13749439204951935 | validation: 0.17997680556732742]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14028895968257407		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.14028895968257407 | validation: 0.18153559127936422]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14372274336899665		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.14372274336899665 | validation: 0.1916962706321647]
	TIME [epoch: 11.6 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16067103815886774		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.16067103815886774 | validation: 0.21037002637561256]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1570170791998488		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.1570170791998488 | validation: 0.1819729692465827]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460520019540888		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.1460520019540888 | validation: 0.18556336725529732]
	TIME [epoch: 11.6 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13481128641493034		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.13481128641493034 | validation: 0.18396703518224264]
	TIME [epoch: 11.6 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339238063003121		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.1339238063003121 | validation: 0.18103694034251352]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13398940335612072		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.13398940335612072 | validation: 0.17566544414423058]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13410042613066064		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.13410042613066064 | validation: 0.16842931002518835]
	TIME [epoch: 11.6 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12973099847453426		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.12973099847453426 | validation: 0.17844168528433715]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13087296952600183		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.13087296952600183 | validation: 0.17281820342203344]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13468439633947457		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.13468439633947457 | validation: 0.17299873934224302]
	TIME [epoch: 11.6 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290355754338678		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.1290355754338678 | validation: 0.17484026443618778]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13084169187397626		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.13084169187397626 | validation: 0.1732333838642198]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13452040278269567		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.13452040278269567 | validation: 0.17584296548923142]
	TIME [epoch: 11.6 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13505146727094594		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.13505146727094594 | validation: 0.16966065710286285]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13324924289230902		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.13324924289230902 | validation: 0.1762699878958359]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286009694484584		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.1286009694484584 | validation: 0.17315758799563466]
	TIME [epoch: 11.6 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310313017792936		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.1310313017792936 | validation: 0.1773668387703875]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302715401055661		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.1302715401055661 | validation: 0.175228808984957]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12984041070492017		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.12984041070492017 | validation: 0.18556590995662384]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.135547126292898		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.135547126292898 | validation: 0.19149331046387577]
	TIME [epoch: 11.6 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15217082790944564		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.15217082790944564 | validation: 0.18661555594185245]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14068079194646557		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.14068079194646557 | validation: 0.18015102560879243]
	TIME [epoch: 11.6 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13721552823413716		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.13721552823413716 | validation: 0.17292728827763376]
	TIME [epoch: 11.6 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13524177552961486		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.13524177552961486 | validation: 0.18556584438933546]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13118997287718395		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.13118997287718395 | validation: 0.18300642534448286]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13500898246401447		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.13500898246401447 | validation: 0.17815023388057769]
	TIME [epoch: 11.6 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13313565460701104		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.13313565460701104 | validation: 0.17555719067375905]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13002582748945554		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.13002582748945554 | validation: 0.17140436876108622]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13872705042291736		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.13872705042291736 | validation: 0.17877241523245269]
	TIME [epoch: 11.6 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13741890063839995		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.13741890063839995 | validation: 0.17776089297356368]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13875664403848179		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.13875664403848179 | validation: 0.16250558136334647]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13293766814437977		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.13293766814437977 | validation: 0.1578165442730137]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1440.pth
	Model improved!!!
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12874977749487107		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.12874977749487107 | validation: 0.16588368484665725]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12857864330985216		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.12857864330985216 | validation: 0.173355115565588]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13267891793782155		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.13267891793782155 | validation: 0.17789283177104392]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322728444978825		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.1322728444978825 | validation: 0.18263686421905156]
	TIME [epoch: 11.6 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13440158631040933		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.13440158631040933 | validation: 0.17607369820910188]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343048608182763		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.1343048608182763 | validation: 0.17182803757819926]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13227354134471106		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.13227354134471106 | validation: 0.16965154249831052]
	TIME [epoch: 11.6 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13754619451363542		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.13754619451363542 | validation: 0.17936789838990685]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13179085423559844		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.13179085423559844 | validation: 0.16648366486917085]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12869884644764673		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.12869884644764673 | validation: 0.1840440254552724]
	TIME [epoch: 11.6 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13203382413610362		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.13203382413610362 | validation: 0.17206803921650246]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325052955743687		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.1325052955743687 | validation: 0.17511698191305997]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276075821723019		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.1276075821723019 | validation: 0.17079841502405071]
	TIME [epoch: 11.6 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12978441547514058		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.12978441547514058 | validation: 0.17397069815682698]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13688081711278843		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.13688081711278843 | validation: 0.1868126032497157]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13560965275753717		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.13560965275753717 | validation: 0.18049694914325862]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13575199414652386		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.13575199414652386 | validation: 0.17744772077295282]
	TIME [epoch: 11.6 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342679578345658		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.1342679578345658 | validation: 0.17854620633283588]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13217808665243463		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.13217808665243463 | validation: 0.1796999540154935]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1368813917306498		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.1368813917306498 | validation: 0.1774567884941358]
	TIME [epoch: 11.6 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13774530219735948		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.13774530219735948 | validation: 0.17722118474973456]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13458871146005638		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.13458871146005638 | validation: 0.16893924588227088]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384401249910212		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.1384401249910212 | validation: 0.16748657859860874]
	TIME [epoch: 11.6 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13304902515758982		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.13304902515758982 | validation: 0.17559086245231995]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13320100925884287		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.13320100925884287 | validation: 0.18121970861033518]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13585732081792734		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.13585732081792734 | validation: 0.16972601456331332]
	TIME [epoch: 11.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325317421296208		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.1325317421296208 | validation: 0.1681116467621972]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13504642977014106		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.13504642977014106 | validation: 0.17588237245146524]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13207260659718412		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.13207260659718412 | validation: 0.16720483037930717]
	TIME [epoch: 11.6 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325177309382214		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.1325177309382214 | validation: 0.18013132265777831]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12773923558497352		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.12773923558497352 | validation: 0.17173002776057772]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1320665038678555		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.1320665038678555 | validation: 0.16894682157928514]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131869821485484		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.131869821485484 | validation: 0.173164156298122]
	TIME [epoch: 11.6 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13112228413747654		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.13112228413747654 | validation: 0.18087689461033155]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289826658768271		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.1289826658768271 | validation: 0.16638184787125418]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12576696970089882		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.12576696970089882 | validation: 0.17302862398814242]
	TIME [epoch: 11.6 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13456433050731323		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.13456433050731323 | validation: 0.18478768334940818]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327845419959269		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.1327845419959269 | validation: 0.17199528122921734]
	TIME [epoch: 11.6 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403926875237279		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.1403926875237279 | validation: 0.17670555368015378]
	TIME [epoch: 11.6 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13727174198662434		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.13727174198662434 | validation: 0.17513377248522669]
	TIME [epoch: 11.6 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13645801555273468		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.13645801555273468 | validation: 0.18740768087291856]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14156326590955695		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.14156326590955695 | validation: 0.17482927747082067]
	TIME [epoch: 11.6 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13540575076404893		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.13540575076404893 | validation: 0.19156482747274545]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13557495843052464		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.13557495843052464 | validation: 0.17816990299911944]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13589232566257434		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.13589232566257434 | validation: 0.1879248250490121]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12947179525915964		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.12947179525915964 | validation: 0.17580961942438897]
	TIME [epoch: 11.6 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13113391432927887		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.13113391432927887 | validation: 0.1785499266520265]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13104727208713263		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.13104727208713263 | validation: 0.16337253612692068]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13048763826306678		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.13048763826306678 | validation: 0.16356189025713108]
	TIME [epoch: 11.6 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289432384776509		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.1289432384776509 | validation: 0.1673524358713363]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298210895822027		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.1298210895822027 | validation: 0.16424867453942138]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332244244632781		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.1332244244632781 | validation: 0.16976246427464778]
	TIME [epoch: 11.6 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308393432296317		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.1308393432296317 | validation: 0.16246245996240802]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12865847124196225		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.12865847124196225 | validation: 0.168252619873211]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127727327136281		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.127727327136281 | validation: 0.16018075518937913]
	TIME [epoch: 11.6 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13003316317396832		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.13003316317396832 | validation: 0.15869334199847301]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280130632845117		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.1280130632845117 | validation: 0.1728505626942574]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12871092843576962		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.12871092843576962 | validation: 0.1641387867261441]
	TIME [epoch: 11.6 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13113641175376498		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.13113641175376498 | validation: 0.1651566487118489]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13138696856159177		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.13138696856159177 | validation: 0.16732986557167415]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286979951761236		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.1286979951761236 | validation: 0.16513386134690408]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12902547376272		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.12902547376272 | validation: 0.1591048775772689]
	TIME [epoch: 11.6 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13402479117585886		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.13402479117585886 | validation: 0.17494730413738332]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13879121110327178		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.13879121110327178 | validation: 0.19036154572443115]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14100833795823733		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.14100833795823733 | validation: 0.18276836451757597]
	TIME [epoch: 11.6 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13400805213644848		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.13400805213644848 | validation: 0.16335901229329858]
	TIME [epoch: 11.6 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13328354886517096		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.13328354886517096 | validation: 0.16972613860534871]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12830256000320323		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.12830256000320323 | validation: 0.1700789987021522]
	TIME [epoch: 11.6 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13288883623869474		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.13288883623869474 | validation: 0.16867338751206204]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13582522815413772		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.13582522815413772 | validation: 0.1764394920601908]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344558993130332		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.1344558993130332 | validation: 0.17635601920433225]
	TIME [epoch: 11.6 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13547960392875608		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.13547960392875608 | validation: 0.1768676619304253]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13272065803345548		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.13272065803345548 | validation: 0.17771613331044223]
	TIME [epoch: 11.6 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360175511410952		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.1360175511410952 | validation: 0.18538232283736336]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13277956312579106		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.13277956312579106 | validation: 0.17802825827649668]
	TIME [epoch: 11.6 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297478655832254		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.1297478655832254 | validation: 0.17320628137996857]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13019695087419494		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.13019695087419494 | validation: 0.1774310396753747]
	TIME [epoch: 11.6 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13352303955062733		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.13352303955062733 | validation: 0.1758948881901413]
	TIME [epoch: 11.6 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12868191933646805		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.12868191933646805 | validation: 0.16353320217749365]
	TIME [epoch: 11.6 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13104698410194138		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.13104698410194138 | validation: 0.166319976716199]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286552601077712		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.1286552601077712 | validation: 0.17284537041993464]
	TIME [epoch: 11.6 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13164365506102418		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.13164365506102418 | validation: 0.17291717786270097]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13291105716184665		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.13291105716184665 | validation: 0.16902358473031492]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12995732492040574		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.12995732492040574 | validation: 0.17064994116398452]
	TIME [epoch: 11.6 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13114037041164484		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.13114037041164484 | validation: 0.18170562582311683]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13276747001356176		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.13276747001356176 | validation: 0.1731142410201114]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312473249827595		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.1312473249827595 | validation: 0.18134432799151753]
	TIME [epoch: 11.6 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13191360689471945		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.13191360689471945 | validation: 0.1675890411537637]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13141689514851063		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.13141689514851063 | validation: 0.17115108214981292]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13064833530251813		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.13064833530251813 | validation: 0.168455224530853]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286319320209393		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.1286319320209393 | validation: 0.16701646438453652]
	TIME [epoch: 11.6 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12753092275837963		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.12753092275837963 | validation: 0.16317476442727447]
	TIME [epoch: 11.6 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12994151391012942		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.12994151391012942 | validation: 0.1776807868529611]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12734777127419625		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.12734777127419625 | validation: 0.1674761136577154]
	TIME [epoch: 11.6 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13034491182433386		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.13034491182433386 | validation: 0.16563568152687638]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13252862554019107		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.13252862554019107 | validation: 0.16939018748169984]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12717532850866706		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.12717532850866706 | validation: 0.16471118105737237]
	TIME [epoch: 11.6 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1330034657200642		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.1330034657200642 | validation: 0.17659418580071554]
	TIME [epoch: 11.6 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1347495347264419		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.1347495347264419 | validation: 0.1669060341413042]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13472679850732572		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.13472679850732572 | validation: 0.16928275714655908]
	TIME [epoch: 11.6 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13142424017443274		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.13142424017443274 | validation: 0.16821565174271033]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12763580694578838		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.12763580694578838 | validation: 0.16662204203043893]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13134834257222		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.13134834257222 | validation: 0.16305770812610473]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13109044022061714		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.13109044022061714 | validation: 0.16165890860751134]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13192300256002248		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.13192300256002248 | validation: 0.17480156100193678]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277443832548036		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.1277443832548036 | validation: 0.1713432985582265]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12929892631200385		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.12929892631200385 | validation: 0.17167399644307693]
	TIME [epoch: 11.6 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12532380518641656		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.12532380518641656 | validation: 0.17599628446137972]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13095558234790727		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.13095558234790727 | validation: 0.1661389759505371]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12633101829943444		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.12633101829943444 | validation: 0.176196599650423]
	TIME [epoch: 11.6 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13776945149769218		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.13776945149769218 | validation: 0.16567986513097835]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350267861378167		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.1350267861378167 | validation: 0.16342956268027223]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13265765128717433		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.13265765128717433 | validation: 0.1651167728435058]
	TIME [epoch: 11.6 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12907344130480308		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.12907344130480308 | validation: 0.16703096405341156]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13105058759164132		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.13105058759164132 | validation: 0.17296853805530993]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310320669182885		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.1310320669182885 | validation: 0.16014184601597273]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12931938879606608		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.12931938879606608 | validation: 0.1619232739581529]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300495090286683		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.1300495090286683 | validation: 0.16366835653769696]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12709875095086173		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.12709875095086173 | validation: 0.1644378025976549]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297256314407646		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.1297256314407646 | validation: 0.1538481171508834]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1560.pth
	Model improved!!!
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13173029419677268		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.13173029419677268 | validation: 0.16417729506583748]
	TIME [epoch: 11.6 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13020781253060187		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.13020781253060187 | validation: 0.16058081452303163]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12973480897228992		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.12973480897228992 | validation: 0.17511950216049316]
	TIME [epoch: 11.6 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277402762144763		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.1277402762144763 | validation: 0.16586986887621286]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13456864075128164		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.13456864075128164 | validation: 0.17136817915847355]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12813660856088033		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.12813660856088033 | validation: 0.17735622381311494]
	TIME [epoch: 11.6 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13007644021843634		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.13007644021843634 | validation: 0.17194031058896325]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13088731202572126		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.13088731202572126 | validation: 0.16942473793354473]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12681821054514522		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.12681821054514522 | validation: 0.18213778645015502]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296426070380344		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.1296426070380344 | validation: 0.17473000081687018]
	TIME [epoch: 11.6 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13586767181282813		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.13586767181282813 | validation: 0.1739788774457111]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13397285041512458		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.13397285041512458 | validation: 0.1748459869558316]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363008985276546		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.1363008985276546 | validation: 0.17379998953052167]
	TIME [epoch: 11.6 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13045167778064834		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.13045167778064834 | validation: 0.17213265709536985]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13283448436529166		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.13283448436529166 | validation: 0.1698496491783856]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278353553426582		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.1278353553426582 | validation: 0.17055918906953807]
	TIME [epoch: 11.6 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13011122276206283		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.13011122276206283 | validation: 0.16322395816728438]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1306223907098431		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.1306223907098431 | validation: 0.17605396840423498]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12492506405742479		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.12492506405742479 | validation: 0.1704316580600127]
	TIME [epoch: 11.6 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13200639849822166		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.13200639849822166 | validation: 0.16809948909811664]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12566665805968597		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.12566665805968597 | validation: 0.15803364858280763]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257229655715795		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.1257229655715795 | validation: 0.1659640787449574]
	TIME [epoch: 11.6 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12856729046717089		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.12856729046717089 | validation: 0.16602577408233124]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279221665133776		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.1279221665133776 | validation: 0.16894755471481626]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282864397748815		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.1282864397748815 | validation: 0.16374716514907448]
	TIME [epoch: 11.6 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12919077800992934		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.12919077800992934 | validation: 0.16368766807315177]
	TIME [epoch: 11.6 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12937170405593942		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.12937170405593942 | validation: 0.1657641238779933]
	TIME [epoch: 11.6 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289084573288287		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.1289084573288287 | validation: 0.16273588913617368]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12853769208519714		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.12853769208519714 | validation: 0.16387796941973695]
	TIME [epoch: 11.6 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12678103346737432		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.12678103346737432 | validation: 0.16984756588794198]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268108280309998		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.1268108280309998 | validation: 0.15931188275060423]
	TIME [epoch: 11.6 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12957664349230522		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.12957664349230522 | validation: 0.17460838362640962]
	TIME [epoch: 11.6 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13013397606143542		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.13013397606143542 | validation: 0.1594884732758146]
	TIME [epoch: 11.6 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259650764535207		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.1259650764535207 | validation: 0.16838877126146032]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12935297979372667		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.12935297979372667 | validation: 0.1570193268268502]
	TIME [epoch: 11.6 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12342446846759905		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.12342446846759905 | validation: 0.1771510092531278]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12970363674459368		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.12970363674459368 | validation: 0.17883996907964897]
	TIME [epoch: 11.6 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12817523504056205		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.12817523504056205 | validation: 0.1666243780947186]
	TIME [epoch: 11.6 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12968244880346308		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.12968244880346308 | validation: 0.17428039092582828]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346800520333319		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.1346800520333319 | validation: 0.17774450349351995]
	TIME [epoch: 11.6 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13148684149699535		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.13148684149699535 | validation: 0.16122432347376178]
	TIME [epoch: 11.6 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298591298865701		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.1298591298865701 | validation: 0.16758637534276402]
	TIME [epoch: 11.6 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13110583715044993		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.13110583715044993 | validation: 0.17686298681659074]
	TIME [epoch: 11.6 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265954558914446		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.1265954558914446 | validation: 0.16529590155686943]
	TIME [epoch: 11.6 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12875506135760045		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.12875506135760045 | validation: 0.16964343617814842]
	TIME [epoch: 11.6 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308912506893777		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.1308912506893777 | validation: 0.16745293705319939]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12963867590543407		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.12963867590543407 | validation: 0.16907487512479705]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12828789028761745		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.12828789028761745 | validation: 0.16981591953188094]
	TIME [epoch: 11.6 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336048008240947		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.1336048008240947 | validation: 0.16830266308979802]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13141639073693118		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.13141639073693118 | validation: 0.1770258667023484]
	TIME [epoch: 11.6 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301458303451684		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.1301458303451684 | validation: 0.16958805854595863]
	TIME [epoch: 11.6 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13510173606383907		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.13510173606383907 | validation: 0.17203990890059473]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259203825120065		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.1259203825120065 | validation: 0.17366341589564635]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12956911914229985		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.12956911914229985 | validation: 0.17034553270757094]
	TIME [epoch: 11.6 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287969016893084		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.1287969016893084 | validation: 0.1619013600280271]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13050244189425142		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.13050244189425142 | validation: 0.17222961845846402]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12876821747626402		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.12876821747626402 | validation: 0.16798582041241564]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12961362028642975		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.12961362028642975 | validation: 0.17098590295621008]
	TIME [epoch: 11.6 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12914918238799467		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.12914918238799467 | validation: 0.1703366590356839]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12470259518752849		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.12470259518752849 | validation: 0.1693804408585369]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12948502171348408		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.12948502171348408 | validation: 0.1727677194768249]
	TIME [epoch: 11.6 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12798537122876438		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.12798537122876438 | validation: 0.1770987746786062]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271933459107534		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.1271933459107534 | validation: 0.17255947808854835]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13075236362719758		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.13075236362719758 | validation: 0.17168958881587162]
	TIME [epoch: 11.6 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13142024354478976		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.13142024354478976 | validation: 0.17410866767364147]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12943773428514935		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.12943773428514935 | validation: 0.17537778257186573]
	TIME [epoch: 11.6 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13112185217503802		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.13112185217503802 | validation: 0.1802990437533972]
	TIME [epoch: 11.6 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13095487998544467		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.13095487998544467 | validation: 0.1735591622399744]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12985988500042503		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.12985988500042503 | validation: 0.16943704266573537]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12864757948697558		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.12864757948697558 | validation: 0.1675379365880864]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12856120293374204		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.12856120293374204 | validation: 0.17050483165713531]
	TIME [epoch: 11.6 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1311373213599657		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.1311373213599657 | validation: 0.16798930093030925]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13180680765889125		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.13180680765889125 | validation: 0.18179990198410254]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13139624320016866		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.13139624320016866 | validation: 0.18111263253134335]
	TIME [epoch: 11.6 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13447096954841217		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.13447096954841217 | validation: 0.18322579155470414]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13592443234506507		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.13592443234506507 | validation: 0.16916988077192863]
	TIME [epoch: 11.6 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12864304156480286		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.12864304156480286 | validation: 0.17773938373116063]
	TIME [epoch: 11.6 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13011823267807537		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.13011823267807537 | validation: 0.16783186037355743]
	TIME [epoch: 11.6 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12629882700887216		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.12629882700887216 | validation: 0.1714175827409132]
	TIME [epoch: 11.6 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276638136750937		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.1276638136750937 | validation: 0.16976347477723983]
	TIME [epoch: 11.6 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12362909222465623		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.12362909222465623 | validation: 0.17471307066343036]
	TIME [epoch: 11.6 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12747242485521743		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.12747242485521743 | validation: 0.17446395365395004]
	TIME [epoch: 11.6 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282812049579744		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.1282812049579744 | validation: 0.17340196235698876]
	TIME [epoch: 11.6 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13061546325845477		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.13061546325845477 | validation: 0.17154818300821434]
	TIME [epoch: 11.6 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12636628300333158		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.12636628300333158 | validation: 0.18075610107328313]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279401071173558		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.1279401071173558 | validation: 0.17132607580555864]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255545782643183		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.1255545782643183 | validation: 0.17848426609440488]
	TIME [epoch: 11.6 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262625402970757		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.1262625402970757 | validation: 0.16820118008295776]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12642422190190516		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.12642422190190516 | validation: 0.16621287870355503]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13249975147008725		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.13249975147008725 | validation: 0.18324676144738095]
	TIME [epoch: 11.6 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13012389404530428		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.13012389404530428 | validation: 0.17778387062528406]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13308688957166187		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.13308688957166187 | validation: 0.1797491903731413]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12489050943807548		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.12489050943807548 | validation: 0.1747232867625278]
	TIME [epoch: 11.6 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13026185242408042		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.13026185242408042 | validation: 0.1714973900034537]
	TIME [epoch: 11.6 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12934550560974942		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.12934550560974942 | validation: 0.17079660759622348]
	TIME [epoch: 11.6 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12202364017544298		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.12202364017544298 | validation: 0.1705770214795605]
	TIME [epoch: 11.6 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303336236290919		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.1303336236290919 | validation: 0.16565178797930644]
	TIME [epoch: 11.6 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12473247234113789		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.12473247234113789 | validation: 0.16625046085487963]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12941258477502093		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.12941258477502093 | validation: 0.1674412350865434]
	TIME [epoch: 11.6 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12929501052114692		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.12929501052114692 | validation: 0.1693901540324954]
	TIME [epoch: 11.6 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12818355170076023		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.12818355170076023 | validation: 0.16893337385952037]
	TIME [epoch: 11.6 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12704709504779443		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.12704709504779443 | validation: 0.16043434098086912]
	TIME [epoch: 11.6 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12691887278128905		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.12691887278128905 | validation: 0.17107694714932856]
	TIME [epoch: 11.6 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12978406300026638		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.12978406300026638 | validation: 0.17558904720307694]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12729532721115994		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.12729532721115994 | validation: 0.16073086200028505]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12748456628522067		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.12748456628522067 | validation: 0.17003740172464482]
	TIME [epoch: 11.6 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13035818825702095		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.13035818825702095 | validation: 0.17181626119453128]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13066968811193194		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.13066968811193194 | validation: 0.1648620312159313]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12747200998075758		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.12747200998075758 | validation: 0.17232161146853944]
	TIME [epoch: 11.6 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12677977052940523		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.12677977052940523 | validation: 0.16481225092930502]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13333634861350785		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.13333634861350785 | validation: 0.1694261341266449]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12902926273086962		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.12902926273086962 | validation: 0.1689119732106183]
	TIME [epoch: 11.6 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292950480148029		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.1292950480148029 | validation: 0.17836695027873312]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13497828780287247		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.13497828780287247 | validation: 0.16219139596263582]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12817535929649337		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.12817535929649337 | validation: 0.1680139448537639]
	TIME [epoch: 11.6 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12644421630225933		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.12644421630225933 | validation: 0.1726787632943003]
	TIME [epoch: 11.6 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259869663163765		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.1259869663163765 | validation: 0.17019142205227927]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12591621999971886		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.12591621999971886 | validation: 0.17720741470095291]
	TIME [epoch: 11.6 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12524884299765005		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.12524884299765005 | validation: 0.16532366983870714]
	TIME [epoch: 11.6 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12812583681134565		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.12812583681134565 | validation: 0.16687522611536118]
	TIME [epoch: 11.6 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12450157451141106		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.12450157451141106 | validation: 0.1684540812057903]
	TIME [epoch: 11.6 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303223475030322		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.1303223475030322 | validation: 0.17390664343665807]
	TIME [epoch: 11.6 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12731443176633214		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.12731443176633214 | validation: 0.1702978229134351]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12523108280053058		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.12523108280053058 | validation: 0.17680142832551596]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329213803815832		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.1329213803815832 | validation: 0.16845530670395747]
	TIME [epoch: 11.6 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12733490648555834		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.12733490648555834 | validation: 0.1643615694949292]
	TIME [epoch: 11.6 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12327651714192722		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.12327651714192722 | validation: 0.17067470324557316]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12332382134551542		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.12332382134551542 | validation: 0.16357568000356795]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12155147371689934		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.12155147371689934 | validation: 0.17720736882458152]
	TIME [epoch: 11.6 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251413094964622		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.1251413094964622 | validation: 0.17483139331742167]
	TIME [epoch: 11.6 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625984389180278		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.12625984389180278 | validation: 0.1602563463689668]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253562544653053		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.1253562544653053 | validation: 0.15874415916633455]
	TIME [epoch: 11.6 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12903517007385348		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.12903517007385348 | validation: 0.1679075800350557]
	TIME [epoch: 11.6 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12767912350021673		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.12767912350021673 | validation: 0.16327754642372955]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12936832504351356		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.12936832504351356 | validation: 0.176571888393256]
	TIME [epoch: 11.6 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127804355636676		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.127804355636676 | validation: 0.16975351630085947]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12527866858787612		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.12527866858787612 | validation: 0.16598546693744368]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12751256711683884		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.12751256711683884 | validation: 0.17236487113468435]
	TIME [epoch: 11.6 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12914208602967903		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.12914208602967903 | validation: 0.17143322865588467]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12575582714216937		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.12575582714216937 | validation: 0.16539458649178684]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12755365252912199		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.12755365252912199 | validation: 0.1743953296912022]
	TIME [epoch: 11.6 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293244883727252		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.1293244883727252 | validation: 0.16657776399711247]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13095927421231873		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.13095927421231873 | validation: 0.17066357807394625]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269280668185193		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.1269280668185193 | validation: 0.17590961739695474]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12927515809886933		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.12927515809886933 | validation: 0.16609192509986392]
	TIME [epoch: 11.6 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12587332692209777		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.12587332692209777 | validation: 0.1695590672612785]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1218408350027878		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.1218408350027878 | validation: 0.1693921470666335]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12462133363855481		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.12462133363855481 | validation: 0.16804982624729828]
	TIME [epoch: 11.6 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256017933000409		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.1256017933000409 | validation: 0.1708465522189701]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12528052548429577		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.12528052548429577 | validation: 0.17621837187133174]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12398731797024388		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.12398731797024388 | validation: 0.16222339147316361]
	TIME [epoch: 11.6 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12392742811969576		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.12392742811969576 | validation: 0.15916639657945497]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12525262222657912		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.12525262222657912 | validation: 0.17289620552468113]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12819895398443787		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.12819895398443787 | validation: 0.16532502818854952]
	TIME [epoch: 11.6 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12846868040794718		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.12846868040794718 | validation: 0.16751388264834088]
	TIME [epoch: 11.6 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272285116630269		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.1272285116630269 | validation: 0.1600268667241445]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251708092708002		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.1251708092708002 | validation: 0.1642876654701555]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126389364156917		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.126389364156917 | validation: 0.16381336689565454]
	TIME [epoch: 11.6 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12679782902502396		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.12679782902502396 | validation: 0.16956866753525693]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273694817405467		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.1273694817405467 | validation: 0.1619056902812602]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12718991523348513		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.12718991523348513 | validation: 0.17096873599922022]
	TIME [epoch: 11.6 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12679311146500055		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.12679311146500055 | validation: 0.17083048902590217]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12578835555770462		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.12578835555770462 | validation: 0.16213771084298903]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12628191731079436		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.12628191731079436 | validation: 0.16685649444486048]
	TIME [epoch: 11.6 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279581935316094		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.1279581935316094 | validation: 0.17023215706418143]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12961864326865202		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.12961864326865202 | validation: 0.16685870332786898]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12654329808088535		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.12654329808088535 | validation: 0.1679605069672262]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12730265807994443		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.12730265807994443 | validation: 0.1673860113471832]
	TIME [epoch: 11.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12498828398030391		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.12498828398030391 | validation: 0.1597130444802014]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12415049751648008		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.12415049751648008 | validation: 0.17182906988688715]
	TIME [epoch: 11.6 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12436367743959564		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.12436367743959564 | validation: 0.16250809692489596]
	TIME [epoch: 11.6 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282976857107975		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.1282976857107975 | validation: 0.16852584438074913]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273906412334961		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.1273906412334961 | validation: 0.1736450627310197]
	TIME [epoch: 11.6 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129653247963129		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.129653247963129 | validation: 0.1561765704351553]
	TIME [epoch: 11.6 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12343438142813834		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.12343438142813834 | validation: 0.16898718171653423]
	TIME [epoch: 11.6 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12608684500314996		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.12608684500314996 | validation: 0.17027007460252158]
	TIME [epoch: 11.6 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291323535615816		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.1291323535615816 | validation: 0.17343222086088736]
	TIME [epoch: 11.6 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13039951717699602		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.13039951717699602 | validation: 0.17348575712647374]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12933015868796824		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.12933015868796824 | validation: 0.16472685433100293]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13264280346191737		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.13264280346191737 | validation: 0.16486189813650806]
	TIME [epoch: 11.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12965626466287145		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.12965626466287145 | validation: 0.1651419333277305]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12569621003697104		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.12569621003697104 | validation: 0.1638526414199726]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12343876257386513		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.12343876257386513 | validation: 0.17088955827678554]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1244663602636205		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.1244663602636205 | validation: 0.1615066234701667]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13011602372877207		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.13011602372877207 | validation: 0.16556821169691177]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125279940509468		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.125279940509468 | validation: 0.16063332737801653]
	TIME [epoch: 11.6 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12753086701927557		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.12753086701927557 | validation: 0.17568640368540067]
	TIME [epoch: 11.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13075069958378988		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.13075069958378988 | validation: 0.1743159496676373]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12457376063878463		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.12457376063878463 | validation: 0.16530212295074428]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12268902968000214		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.12268902968000214 | validation: 0.16001121486147868]
	TIME [epoch: 11.6 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12583026545890333		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.12583026545890333 | validation: 0.17208968151529466]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294335853894755		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.1294335853894755 | validation: 0.16817416632509205]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12676795293696116		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.12676795293696116 | validation: 0.16509540373075277]
	TIME [epoch: 11.6 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12067876077466001		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.12067876077466001 | validation: 0.17084604219785426]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12371518746863304		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.12371518746863304 | validation: 0.16067234892516258]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12470200611602719		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.12470200611602719 | validation: 0.16848438035139437]
	TIME [epoch: 11.6 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12791203870513612		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.12791203870513612 | validation: 0.1592521153823632]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12662042841767923		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.12662042841767923 | validation: 0.1627665229236994]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257427547496962		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.1257427547496962 | validation: 0.16573872152552938]
	TIME [epoch: 11.6 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12818793566443556		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.12818793566443556 | validation: 0.16274103924681316]
	TIME [epoch: 11.6 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12861087563039428		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.12861087563039428 | validation: 0.15861407959356094]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13032071545683277		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.13032071545683277 | validation: 0.17005925677617292]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12646927656088802		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.12646927656088802 | validation: 0.16151310127393528]
	TIME [epoch: 11.6 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12771238698866372		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.12771238698866372 | validation: 0.16505644051131185]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12403333962298545		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.12403333962298545 | validation: 0.15546867523393318]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12942889322017465		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.12942889322017465 | validation: 0.17643919960879856]
	TIME [epoch: 11.6 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12843366798286912		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.12843366798286912 | validation: 0.1611349926839493]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12665987449036611		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.12665987449036611 | validation: 0.15672062109776247]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300392694804566		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.1300392694804566 | validation: 0.17476729313457134]
	TIME [epoch: 11.6 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12349952018598678		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.12349952018598678 | validation: 0.16396971883809802]
	TIME [epoch: 11.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261400045448057		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.1261400045448057 | validation: 0.1629381974847698]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259802297212711		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.1259802297212711 | validation: 0.17322496838099624]
	TIME [epoch: 11.6 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264534752253272		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.1264534752253272 | validation: 0.16762715890319776]
	TIME [epoch: 11.6 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290749348463415		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.1290749348463415 | validation: 0.1676334749961025]
	TIME [epoch: 11.6 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289190970348191		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.1289190970348191 | validation: 0.16970484784761902]
	TIME [epoch: 11.6 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294831689043296		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.1294831689043296 | validation: 0.16694067495416584]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12549011425647896		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.12549011425647896 | validation: 0.17164422098246795]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276483096288354		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.1276483096288354 | validation: 0.16224289107996037]
	TIME [epoch: 11.6 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12704603810553655		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.12704603810553655 | validation: 0.16708988812442083]
	TIME [epoch: 11.6 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12606865930706268		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.12606865930706268 | validation: 0.16225811360905723]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12721518637449397		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.12721518637449397 | validation: 0.17266194674182067]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12979982285178449		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.12979982285178449 | validation: 0.17015479264774108]
	TIME [epoch: 11.6 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12539837276946353		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.12539837276946353 | validation: 0.17157182328847362]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12262054822870957		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.12262054822870957 | validation: 0.15850228744970216]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12377353381358216		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.12377353381358216 | validation: 0.1615420312689683]
	TIME [epoch: 11.6 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12448518540249146		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.12448518540249146 | validation: 0.17601840633588092]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13117368029577411		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.13117368029577411 | validation: 0.16856824284073846]
	TIME [epoch: 11.6 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12914010493575873		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.12914010493575873 | validation: 0.17070274936828483]
	TIME [epoch: 11.6 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12879486054510697		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.12879486054510697 | validation: 0.15850620836812407]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12929595009294162		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.12929595009294162 | validation: 0.16655959852915034]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12992021213568888		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.12992021213568888 | validation: 0.16671440002797652]
	TIME [epoch: 11.6 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291221854853316		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.1291221854853316 | validation: 0.1698324757622402]
	TIME [epoch: 11.6 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13036673059689824		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.13036673059689824 | validation: 0.1690184838249323]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13117347215398936		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.13117347215398936 | validation: 0.16659740771329326]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12930912290193042		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.12930912290193042 | validation: 0.16153773555875112]
	TIME [epoch: 11.6 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12783415518608596		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.12783415518608596 | validation: 0.16912403952475596]
	TIME [epoch: 11.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290472818447902		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.1290472818447902 | validation: 0.1723991589963652]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13376131599295168		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.13376131599295168 | validation: 0.16804421083282375]
	TIME [epoch: 11.6 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304378235356768		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.1304378235356768 | validation: 0.17383273325664392]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1285607753837082		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.1285607753837082 | validation: 0.1678373250420323]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308649096255268		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.1308649096255268 | validation: 0.1711642929073058]
	TIME [epoch: 11.6 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12829571532893208		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.12829571532893208 | validation: 0.16210875837541075]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13621123467029903		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.13621123467029903 | validation: 0.16989948190646423]
	TIME [epoch: 11.6 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315238381183157		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.1315238381183157 | validation: 0.1642357724906804]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327167727011586		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.1327167727011586 | validation: 0.16675244074930973]
	TIME [epoch: 11.6 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1245321133498662		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.1245321133498662 | validation: 0.16133146458028727]
	TIME [epoch: 11.6 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1313763608593993		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.1313763608593993 | validation: 0.16865741811199592]
	TIME [epoch: 11.6 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12604957240302725		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.12604957240302725 | validation: 0.1551255584849805]
	TIME [epoch: 11.6 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12614691845202097		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.12614691845202097 | validation: 0.17241242653011982]
	TIME [epoch: 11.6 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12617560388890492		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.12617560388890492 | validation: 0.1672354497215389]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12373274832439923		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.12373274832439923 | validation: 0.16170189354959752]
	TIME [epoch: 11.6 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12278838468980033		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.12278838468980033 | validation: 0.16458032328745703]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260270240719488		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.1260270240719488 | validation: 0.16053465598902583]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12725221085765634		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.12725221085765634 | validation: 0.1646358080746515]
	TIME [epoch: 11.6 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12774764787478038		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.12774764787478038 | validation: 0.16267716407609414]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12606289617466848		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.12606289617466848 | validation: 0.16337735383211385]
	TIME [epoch: 11.6 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12454880711016279		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.12454880711016279 | validation: 0.15477261550445567]
	TIME [epoch: 11.6 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12449332439630015		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.12449332439630015 | validation: 0.16776825769917358]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12646641068000813		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.12646641068000813 | validation: 0.16533661103998806]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12622119337776672		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.12622119337776672 | validation: 0.16082098451194957]
	TIME [epoch: 11.6 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278438000988626		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.1278438000988626 | validation: 0.1670113644829155]
	TIME [epoch: 11.6 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280320815256965		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.1280320815256965 | validation: 0.15982572756452587]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12296648525734513		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.12296648525734513 | validation: 0.15862694958881224]
	TIME [epoch: 11.6 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1237662679910406		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.1237662679910406 | validation: 0.1605690731223443]
	TIME [epoch: 11.6 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12521960515765568		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.12521960515765568 | validation: 0.16238956349365882]
	TIME [epoch: 11.6 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12200222624709238		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.12200222624709238 | validation: 0.15897130613242183]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12656971390247357		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.12656971390247357 | validation: 0.15891616437551526]
	TIME [epoch: 11.6 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1243327316575467		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.1243327316575467 | validation: 0.16646151243277132]
	TIME [epoch: 11.6 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12339436905139528		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.12339436905139528 | validation: 0.17080534332604203]
	TIME [epoch: 11.6 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271838816225955		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.1271838816225955 | validation: 0.16076915349720028]
	TIME [epoch: 11.6 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12305074245202546		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.12305074245202546 | validation: 0.1626915506886573]
	TIME [epoch: 11.6 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13032303092409347		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.13032303092409347 | validation: 0.1641524005250256]
	TIME [epoch: 11.6 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12731320426467518		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.12731320426467518 | validation: 0.1696216858875237]
	TIME [epoch: 11.6 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12342355906729328		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.12342355906729328 | validation: 0.16796500910299592]
	TIME [epoch: 11.6 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12714201662182326		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.12714201662182326 | validation: 0.15669977179594957]
	TIME [epoch: 11.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12780663294451738		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.12780663294451738 | validation: 0.17401268165732858]
	TIME [epoch: 11.6 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12706847718251763		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.12706847718251763 | validation: 0.15738468560885174]
	TIME [epoch: 11.6 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12295391230787255		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.12295391230787255 | validation: 0.16689728501001977]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12591621088980148		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.12591621088980148 | validation: 0.1686565926194499]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12722328106922068		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.12722328106922068 | validation: 0.17439349003680865]
	TIME [epoch: 11.6 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12606185022808408		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.12606185022808408 | validation: 0.16642302581804047]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12480381144040885		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.12480381144040885 | validation: 0.15853945450950235]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12443520775487701		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.12443520775487701 | validation: 0.16755400867162087]
	TIME [epoch: 11.6 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12579618789782648		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.12579618789782648 | validation: 0.16361395256411945]
	TIME [epoch: 11.6 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12667777581458423		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.12667777581458423 | validation: 0.16325215133123824]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12729768469489525		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.12729768469489525 | validation: 0.16285530142553944]
	TIME [epoch: 11.6 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12307792538099702		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.12307792538099702 | validation: 0.1779020744548029]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12658165218414946		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.12658165218414946 | validation: 0.16557844367611374]
	TIME [epoch: 11.6 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12885330513107268		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.12885330513107268 | validation: 0.16877021986349305]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12237981056204636		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.12237981056204636 | validation: 0.17407680198083156]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.123042823821252		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.123042823821252 | validation: 0.16924273122248118]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1244798505075988		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.1244798505075988 | validation: 0.15890020692860288]
	TIME [epoch: 11.6 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12753316430384168		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.12753316430384168 | validation: 0.16336327812076712]
	TIME [epoch: 11.6 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12727460236718824		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.12727460236718824 | validation: 0.17276259732213173]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289562357269876		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.1289562357269876 | validation: 0.17821702681192364]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12870069629449699		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.12870069629449699 | validation: 0.16458248264774042]
	TIME [epoch: 11.6 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13007289161949964		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.13007289161949964 | validation: 0.1779937442365541]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13089259510595427		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.13089259510595427 | validation: 0.16892547142072073]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266952923364451		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.1266952923364451 | validation: 0.1709784112690075]
	TIME [epoch: 11.6 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280337733807788		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.1280337733807788 | validation: 0.16527059578186154]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12933373366854967		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.12933373366854967 | validation: 0.17309221206736136]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12990264448512662		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.12990264448512662 | validation: 0.1661034049706516]
	TIME [epoch: 11.6 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1311858495199885		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.1311858495199885 | validation: 0.17012617310267536]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13019942514512187		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.13019942514512187 | validation: 0.17068691249093434]
	TIME [epoch: 11.6 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308722808173159		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.1308722808173159 | validation: 0.16593838704714156]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13256314399519636		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.13256314399519636 | validation: 0.17671377896046203]
	TIME [epoch: 11.6 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12576081845963394		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.12576081845963394 | validation: 0.1650289887142551]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13161146953609434		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.13161146953609434 | validation: 0.1632724577053019]
	TIME [epoch: 11.6 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13019892292155977		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.13019892292155977 | validation: 0.167321425624528]
	TIME [epoch: 11.6 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12700425285051645		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.12700425285051645 | validation: 0.17552384251952954]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13033153756165916		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.13033153756165916 | validation: 0.16992106655872083]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12794054555862963		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.12794054555862963 | validation: 0.17707431598664136]
	TIME [epoch: 11.6 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336943607825825		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.1336943607825825 | validation: 0.1634286843391677]
	TIME [epoch: 11.6 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12955905480496507		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.12955905480496507 | validation: 0.16254781576585337]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13081807000904921		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.13081807000904921 | validation: 0.1679105169201835]
	TIME [epoch: 11.6 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12925598963158752		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.12925598963158752 | validation: 0.16504804417925611]
	TIME [epoch: 11.6 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12813256179495625		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.12813256179495625 | validation: 0.1649690232969465]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12877089383779147		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.12877089383779147 | validation: 0.16540411823421436]
	TIME [epoch: 11.6 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12944918292862487		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.12944918292862487 | validation: 0.154282153033525]
	TIME [epoch: 11.6 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12572199753402297		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.12572199753402297 | validation: 0.16245130520632423]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12839946593734036		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.12839946593734036 | validation: 0.1641630204501574]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12680937019258143		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.12680937019258143 | validation: 0.1626435683357665]
	TIME [epoch: 11.6 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255723884847725		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.1255723884847725 | validation: 0.1566956827400667]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12556012782962284		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.12556012782962284 | validation: 0.1569207100684704]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12580622844334255		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.12580622844334255 | validation: 0.16421846062040252]
	TIME [epoch: 11.6 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276942703453201		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.1276942703453201 | validation: 0.16305875287390642]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12210046035318199		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.12210046035318199 | validation: 0.16040575180426686]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12251509995082623		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.12251509995082623 | validation: 0.16533988497241864]
	TIME [epoch: 11.6 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12434374798867776		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.12434374798867776 | validation: 0.15518786970785775]
	TIME [epoch: 11.6 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12092188124965689		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.12092188124965689 | validation: 0.1689408704261023]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12791313784930927		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.12791313784930927 | validation: 0.16867731674999262]
	TIME [epoch: 11.6 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12669291861648405		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.12669291861648405 | validation: 0.16768184652440568]
	TIME [epoch: 11.6 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12962505168580385		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.12962505168580385 | validation: 0.16494087269023702]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12911119051574346		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.12911119051574346 | validation: 0.1608596371519075]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12285852782032972		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.12285852782032972 | validation: 0.1628946467792688]
	TIME [epoch: 11.6 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12876251876271755		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.12876251876271755 | validation: 0.15915586540040802]
	TIME [epoch: 11.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12619894723118427		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.12619894723118427 | validation: 0.16941880994874578]
	TIME [epoch: 11.6 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290178633873643		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.1290178633873643 | validation: 0.15958920206193]
	TIME [epoch: 11.6 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12687930348372808		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.12687930348372808 | validation: 0.16460357564612102]
	TIME [epoch: 11.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12558041877950657		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.12558041877950657 | validation: 0.17164537543378358]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12998685734264276		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.12998685734264276 | validation: 0.15930660749110753]
	TIME [epoch: 11.6 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12964659536176415		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.12964659536176415 | validation: 0.16314958414606825]
	TIME [epoch: 11.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302135920185255		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.1302135920185255 | validation: 0.16603899495088115]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13093519267870835		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.13093519267870835 | validation: 0.16319809690406703]
	TIME [epoch: 11.6 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12673648359302264		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.12673648359302264 | validation: 0.1634016503217361]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12610428402658194		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.12610428402658194 | validation: 0.1673908644712387]
	TIME [epoch: 11.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12993510308898046		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.12993510308898046 | validation: 0.1597990968695083]
	TIME [epoch: 11.6 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12640867286279747		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.12640867286279747 | validation: 0.16532101697013762]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12952441639677767		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.12952441639677767 | validation: 0.16486120737611956]
	TIME [epoch: 11.6 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12635148284579975		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.12635148284579975 | validation: 0.1750612601469025]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12761614171164318		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.12761614171164318 | validation: 0.15885822442007308]
	TIME [epoch: 11.6 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12534114538330834		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.12534114538330834 | validation: 0.16631741818511522]
	TIME [epoch: 11.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12815932828471582		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.12815932828471582 | validation: 0.16599848346264395]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12700411015120477		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.12700411015120477 | validation: 0.16143461841051085]
	TIME [epoch: 11.6 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12510843408896585		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.12510843408896585 | validation: 0.17380636479512632]
	TIME [epoch: 11.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267650052530571		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.1267650052530571 | validation: 0.17019156684135647]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12474644215386332		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.12474644215386332 | validation: 0.16981588711720644]
	TIME [epoch: 11.6 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292195160635109		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.1292195160635109 | validation: 0.16333430412052358]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12607074735797968		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.12607074735797968 | validation: 0.17206164889391232]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270883999582177		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.1270883999582177 | validation: 0.16720012893114994]
	TIME [epoch: 11.6 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255790435739763		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.1255790435739763 | validation: 0.17374115373873852]
	TIME [epoch: 11.6 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12571782755263652		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.12571782755263652 | validation: 0.16820808999857773]
	TIME [epoch: 11.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12768022660469355		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.12768022660469355 | validation: 0.1690806341438546]
	TIME [epoch: 11.6 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12476241411583242		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.12476241411583242 | validation: 0.16525509154739243]
	TIME [epoch: 11.6 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12416798457674913		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.12416798457674913 | validation: 0.15710278977832126]
	TIME [epoch: 11.6 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13105261726160716		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.13105261726160716 | validation: 0.161224439381401]
	TIME [epoch: 11.6 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12721057628680324		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.12721057628680324 | validation: 0.1627636901889074]
	TIME [epoch: 11.6 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125536565697402		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.125536565697402 | validation: 0.16627807298640274]
	TIME [epoch: 11.5 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12859707639418563		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.12859707639418563 | validation: 0.1648256824881534]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12647695440285314		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.12647695440285314 | validation: 0.16106869211028335]
	TIME [epoch: 11.6 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12734423700641892		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.12734423700641892 | validation: 0.1702982049775631]
	TIME [epoch: 11.6 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283921458983081		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.1283921458983081 | validation: 0.16134678423788337]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12493586643931971		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.12493586643931971 | validation: 0.1637744875475885]
	TIME [epoch: 11.6 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12569307409585617		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.12569307409585617 | validation: 0.1670528975291825]
	TIME [epoch: 11.6 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297919000916925		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.1297919000916925 | validation: 0.17058698232524777]
	TIME [epoch: 11.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1258885724248921		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.1258885724248921 | validation: 0.16691192223645512]
	TIME [epoch: 11.6 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12718000111835318		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.12718000111835318 | validation: 0.17484947971899792]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12718817720527892		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.12718817720527892 | validation: 0.16295126703578255]
	TIME [epoch: 11.6 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12443033106653767		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.12443033106653767 | validation: 0.17228325456397833]
	TIME [epoch: 11.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268233295346028		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.1268233295346028 | validation: 0.17016313068611588]
	TIME [epoch: 11.6 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12596679197313115		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.12596679197313115 | validation: 0.16832962530145906]
	TIME [epoch: 11.5 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12741220624108418		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.12741220624108418 | validation: 0.16517716622544285]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12867553024448944		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.12867553024448944 | validation: 0.16463957042694807]
	TIME [epoch: 11.6 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12907010582483658		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.12907010582483658 | validation: 0.17222366359925204]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238934442683128		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.1238934442683128 | validation: 0.15892948562923803]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12996984614736173		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.12996984614736173 | validation: 0.16848350345286014]
	TIME [epoch: 11.6 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260925828804834		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.1260925828804834 | validation: 0.17031368148858064]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124581212857824		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.124581212857824 | validation: 0.1717034062861226]
	TIME [epoch: 11.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12436371970479956		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.12436371970479956 | validation: 0.16985003556505063]
	TIME [epoch: 11.6 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126255799361549		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.126255799361549 | validation: 0.16845468806577782]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12576091403331177		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.12576091403331177 | validation: 0.15940412398993806]
	TIME [epoch: 11.5 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12655959501123198		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.12655959501123198 | validation: 0.17035284052447858]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12503058664967298		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.12503058664967298 | validation: 0.16678910182357334]
	TIME [epoch: 11.6 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12285439213824767		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.12285439213824767 | validation: 0.15633975487182517]
	TIME [epoch: 11.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12701944739555898		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.12701944739555898 | validation: 0.16882066777046326]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12536764655506136		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.12536764655506136 | validation: 0.16512792855876868]
	TIME [epoch: 11.6 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1243228842419955		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.1243228842419955 | validation: 0.1596043671588836]
	TIME [epoch: 11.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12912648803397034		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.12912648803397034 | validation: 0.16261830624051535]
	TIME [epoch: 11.6 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12574686910085928		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.12574686910085928 | validation: 0.16180583310207047]
	TIME [epoch: 11.6 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277551377836017		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.1277551377836017 | validation: 0.16711514393393237]
	TIME [epoch: 11.5 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12474194293516029		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.12474194293516029 | validation: 0.16578339276625953]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12477495939806413		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.12477495939806413 | validation: 0.15973581509745227]
	TIME [epoch: 11.6 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12486835890236654		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.12486835890236654 | validation: 0.16566458913303833]
	TIME [epoch: 11.6 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12396809951533816		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.12396809951533816 | validation: 0.16333226556787966]
	TIME [epoch: 11.6 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12794761172835134		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.12794761172835134 | validation: 0.16688873085001463]
	TIME [epoch: 11.6 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12300118789691207		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.12300118789691207 | validation: 0.17124472052468784]
	TIME [epoch: 11.6 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12818112910492113		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.12818112910492113 | validation: 0.15578833803363892]
	TIME [epoch: 11.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12433925096828165		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.12433925096828165 | validation: 0.17406713616162114]
	TIME [epoch: 11.6 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12555361063718018		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.12555361063718018 | validation: 0.16591888499404936]
	TIME [epoch: 11.6 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12448600550878099		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.12448600550878099 | validation: 0.1649953320990835]
	TIME [epoch: 11.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12621382325095054		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.12621382325095054 | validation: 0.1611799480901346]
	TIME [epoch: 11.6 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252899851767631		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.1252899851767631 | validation: 0.1529157294076412]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1972.pth
	Model improved!!!
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12563345709256032		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.12563345709256032 | validation: 0.16075797862096305]
	TIME [epoch: 11.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12200182171933764		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.12200182171933764 | validation: 0.1648359055834947]
	TIME [epoch: 11.6 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12003829935532018		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.12003829935532018 | validation: 0.1620338083587735]
	TIME [epoch: 11.6 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268798167482523		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.1268798167482523 | validation: 0.1590754570713778]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12583529161285267		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.12583529161285267 | validation: 0.1765740302292017]
	TIME [epoch: 11.6 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326995903252149		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.1326995903252149 | validation: 0.17218359697473318]
	TIME [epoch: 11.6 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254011276142688		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.1254011276142688 | validation: 0.16802268814459467]
	TIME [epoch: 11.6 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12682919682355775		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.12682919682355775 | validation: 0.15936507893952756]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256389606746653		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.1256389606746653 | validation: 0.15938413199270446]
	TIME [epoch: 11.6 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127524074858679		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.127524074858679 | validation: 0.16388816566036574]
	TIME [epoch: 11.6 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269769365683245		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.1269769365683245 | validation: 0.16431566734859132]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12382372676596434		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.12382372676596434 | validation: 0.16289693238966016]
	TIME [epoch: 11.6 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12677205636601122		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.12677205636601122 | validation: 0.16442608591443653]
	TIME [epoch: 11.6 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12280825804555505		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.12280825804555505 | validation: 0.17008824767667388]
	TIME [epoch: 11.6 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12561911225161285		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.12561911225161285 | validation: 0.17184408368820897]
	TIME [epoch: 11.6 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12905284931978522		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.12905284931978522 | validation: 0.1578592311903373]
	TIME [epoch: 11.6 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12103018766249395		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.12103018766249395 | validation: 0.16014953969331638]
	TIME [epoch: 11.6 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12685351511350357		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.12685351511350357 | validation: 0.15919771138534408]
	TIME [epoch: 11.6 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12458589271228479		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.12458589271228479 | validation: 0.16251072618993384]
	TIME [epoch: 11.6 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1233523794912685		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.1233523794912685 | validation: 0.16831703803444253]
	TIME [epoch: 11.6 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12725096749179074		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.12725096749179074 | validation: 0.16971507095567007]
	TIME [epoch: 11.6 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12572911755200156		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.12572911755200156 | validation: 0.1562064010602881]
	TIME [epoch: 11.6 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12432867168438302		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.12432867168438302 | validation: 0.1639296805693253]
	TIME [epoch: 11.6 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265040640960553		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.1265040640960553 | validation: 0.160623497436462]
	TIME [epoch: 11.6 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1218768954670137		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.1218768954670137 | validation: 0.15858215353109167]
	TIME [epoch: 11.6 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12693936460770142		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.12693936460770142 | validation: 0.1592933110191353]
	TIME [epoch: 11.6 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12400466369442975		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.12400466369442975 | validation: 0.1498501394022112]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240310_003030/states/model_tr_study3_1999.pth
	Model improved!!!
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12522713077783462		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.12522713077783462 | validation: 0.15774701125103618]
	TIME [epoch: 11.6 sec]
Finished training in 23338.402 seconds.
