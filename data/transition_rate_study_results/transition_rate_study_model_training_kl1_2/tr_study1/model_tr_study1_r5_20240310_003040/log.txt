Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r5', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 736946283

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.598882247555284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.598882247555284 | validation: 9.923646742080173]
	TIME [epoch: 92.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.819743495565042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.819743495565042 | validation: 6.329711957392747]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.090098978530108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.090098978530108 | validation: 6.065745545836606]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.904069718925664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.904069718925664 | validation: 6.301024345497949]
	TIME [epoch: 5.74 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.958755766155576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.958755766155576 | validation: 5.94937952652774]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.825443214522547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.825443214522547 | validation: 5.9666108094184755]
	TIME [epoch: 5.78 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.768815721861701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.768815721861701 | validation: 6.059263441791982]
	TIME [epoch: 5.74 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.777435190145534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.777435190145534 | validation: 5.965988057347517]
	TIME [epoch: 5.74 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.759190691945753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.759190691945753 | validation: 6.0530433286671235]
	TIME [epoch: 5.73 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.630622077445957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.630622077445957 | validation: 6.000624843357153]
	TIME [epoch: 5.74 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.587499848991995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.587499848991995 | validation: 6.053654049531881]
	TIME [epoch: 5.74 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.528213455314443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.528213455314443 | validation: 6.552573035755156]
	TIME [epoch: 5.78 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.760900215082615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.760900215082615 | validation: 6.04179814770868]
	TIME [epoch: 5.75 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.82860913918848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.82860913918848 | validation: 5.376365288096499]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.861598128902561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.861598128902561 | validation: 5.8646620064535755]
	TIME [epoch: 5.75 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.025896034825051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.025896034825051 | validation: 5.175061224208835]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.592241617515913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.592241617515913 | validation: 5.400819527767374]
	TIME [epoch: 5.74 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.429021622048501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.429021622048501 | validation: 5.338065200806133]
	TIME [epoch: 5.77 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.344847181175738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.344847181175738 | validation: 5.932518921709548]
	TIME [epoch: 5.76 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.458907868602623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.458907868602623 | validation: 5.005355422198011]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.028441360067487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.028441360067487 | validation: 4.830433501104795]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.387188313901881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.387188313901881 | validation: 4.952405443009467]
	TIME [epoch: 5.73 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.742266928317592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.742266928317592 | validation: 7.765491650890381]
	TIME [epoch: 5.73 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.867245057694216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.867245057694216 | validation: 4.6797970807130564]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.66906731176299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.66906731176299 | validation: 4.557340790160001]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464732004994548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.464732004994548 | validation: 4.516473350330689]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.605976712913354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.605976712913354 | validation: 4.479576081114575]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45975882077714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.45975882077714 | validation: 4.214801307647043]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3004036526565015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3004036526565015 | validation: 5.601431198583748]
	TIME [epoch: 5.75 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472330009885133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.472330009885133 | validation: 4.035050326321417]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.124024601897981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.124024601897981 | validation: 4.022377725748731]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.850193780978923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.850193780978923 | validation: 4.173432369759337]
	TIME [epoch: 5.76 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3037393299420925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3037393299420925 | validation: 3.7521305873511457]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.84328093052169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.84328093052169 | validation: 3.7937876360049696]
	TIME [epoch: 5.77 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9224485863146024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9224485863146024 | validation: 4.795732692897148]
	TIME [epoch: 5.73 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8824308129078355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8824308129078355 | validation: 3.6821150392629782]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6013988612060825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6013988612060825 | validation: 3.5252373502343586]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.441995111157447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.441995111157447 | validation: 3.6684343459293833]
	TIME [epoch: 5.75 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2838231298017457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2838231298017457 | validation: 3.5350345377345582]
	TIME [epoch: 5.74 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1874006487585422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1874006487585422 | validation: 2.9720662338354886]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3394475538859925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3394475538859925 | validation: 2.795961723088412]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1731529665957563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1731529665957563 | validation: 3.493427079378041]
	TIME [epoch: 5.78 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0943368007947165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0943368007947165 | validation: 2.6109443289129604]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.896236282770152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.896236282770152 | validation: 3.187407149744146]
	TIME [epoch: 5.76 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.869728295326304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.869728295326304 | validation: 2.4793376839549253]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5422855485555704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5422855485555704 | validation: 2.905335986231671]
	TIME [epoch: 5.76 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7135145008364976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7135145008364976 | validation: 3.2601648464973505]
	TIME [epoch: 5.74 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.598200555776527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.598200555776527 | validation: 2.2051627167290655]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.804936923591768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.804936923591768 | validation: 2.0619233098966907]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.384640943438039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.384640943438039 | validation: 2.2084511058184844]
	TIME [epoch: 5.74 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083966551365352		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.083966551365352 | validation: 2.8068868237387368]
	TIME [epoch: 5.73 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.440339604959743		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.440339604959743 | validation: 1.9530979721991435]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.109340407971635		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.109340407971635 | validation: 2.578860288284884]
	TIME [epoch: 5.74 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4000800524320236		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.4000800524320236 | validation: 2.094395674306112]
	TIME [epoch: 5.77 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.089689818300418		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.089689818300418 | validation: 1.9425112972808916]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4707043884570776		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.4707043884570776 | validation: 2.189188368683833]
	TIME [epoch: 5.75 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.104729693220062		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.104729693220062 | validation: 1.6360967106881594]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1093741809831443		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.1093741809831443 | validation: 1.652026436843305]
	TIME [epoch: 5.74 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9043876011015364		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.9043876011015364 | validation: 1.6914262815846934]
	TIME [epoch: 5.75 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8597779400637107		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.8597779400637107 | validation: 1.908255491396672]
	TIME [epoch: 5.78 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.799888645548596		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.799888645548596 | validation: 2.6695313893228088]
	TIME [epoch: 5.74 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.016149753582226		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.016149753582226 | validation: 1.6113064825738581]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.868181574637954		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.868181574637954 | validation: 2.0447613894079972]
	TIME [epoch: 5.74 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.961608131921683		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.961608131921683 | validation: 1.6965083157697352]
	TIME [epoch: 5.75 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8915988462083702		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.8915988462083702 | validation: 1.597509987313839]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.587724764645807		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.587724764645807 | validation: 2.0360833751292153]
	TIME [epoch: 5.78 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.202992636850399		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.202992636850399 | validation: 1.7712754846302894]
	TIME [epoch: 5.75 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8188441651641876		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.8188441651641876 | validation: 7.0372919045942375]
	TIME [epoch: 5.75 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8766963138456045		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.8766963138456045 | validation: 2.4429751164420352]
	TIME [epoch: 5.75 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.123979901071027		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.123979901071027 | validation: 1.8875845725086187]
	TIME [epoch: 5.75 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.778266933788057		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.778266933788057 | validation: 1.554556999774232]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7930368252297786		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.7930368252297786 | validation: 1.5566476287072717]
	TIME [epoch: 5.79 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8395998735505468		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.8395998735505468 | validation: 1.5964459471582024]
	TIME [epoch: 5.75 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.648971057993297		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.648971057993297 | validation: 1.332508501925638]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.637713903272086		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.637713903272086 | validation: 1.3644378272712137]
	TIME [epoch: 5.77 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8047855612177344		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.8047855612177344 | validation: 1.7180883105377547]
	TIME [epoch: 5.75 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6907744860959495		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.6907744860959495 | validation: 1.3205992055658835]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4924291340278903		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.4924291340278903 | validation: 1.316498934308947]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728909181537741		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.728909181537741 | validation: 1.5112947638048186]
	TIME [epoch: 5.75 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5888656724093255		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.5888656724093255 | validation: 1.645183335550921]
	TIME [epoch: 5.75 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5925581765565924		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.5925581765565924 | validation: 1.706409651103433]
	TIME [epoch: 5.75 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6272170864622015		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.6272170864622015 | validation: 1.696792922212748]
	TIME [epoch: 5.74 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9810504041357198		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.9810504041357198 | validation: 1.515596296865618]
	TIME [epoch: 5.78 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.576335270744547		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.576335270744547 | validation: 1.5463717023277412]
	TIME [epoch: 5.76 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.657835150015285		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.657835150015285 | validation: 1.42226099778736]
	TIME [epoch: 5.74 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.708826180754891		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.708826180754891 | validation: 1.9047519930924228]
	TIME [epoch: 5.75 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9564873433095036		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.9564873433095036 | validation: 1.8061164693074199]
	TIME [epoch: 5.74 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.838843761743858		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.838843761743858 | validation: 1.3517979993859428]
	TIME [epoch: 5.75 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.468618286298362		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.468618286298362 | validation: 1.7706805646407122]
	TIME [epoch: 5.78 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7185662636804517		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.7185662636804517 | validation: 1.7148152792491542]
	TIME [epoch: 5.75 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.67840707802775		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.67840707802775 | validation: 1.5727496864704842]
	TIME [epoch: 5.75 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.678828838430779		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.678828838430779 | validation: 1.6543964289755662]
	TIME [epoch: 5.75 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.734977330577527		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.734977330577527 | validation: 2.0089055436704903]
	TIME [epoch: 5.75 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6790862874440804		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.6790862874440804 | validation: 1.2558593817849397]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6515305928877708		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.6515305928877708 | validation: 1.3789641082980917]
	TIME [epoch: 5.79 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7410404465476563		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.7410404465476563 | validation: 1.671082768727543]
	TIME [epoch: 5.75 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.024394131886679		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.024394131886679 | validation: 2.0163848100318553]
	TIME [epoch: 5.74 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8218086198763508		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.8218086198763508 | validation: 1.6438791342464025]
	TIME [epoch: 5.75 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.671624567618788		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.671624567618788 | validation: 1.3407131452827343]
	TIME [epoch: 5.73 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.705734099193371		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.705734099193371 | validation: 1.452232484770517]
	TIME [epoch: 5.75 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4789597198115085		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.4789597198115085 | validation: 1.4002445459223873]
	TIME [epoch: 5.78 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6758108102200393		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.6758108102200393 | validation: 1.5052132791594934]
	TIME [epoch: 5.75 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.538852852754447		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.538852852754447 | validation: 1.613872825401872]
	TIME [epoch: 5.73 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5688015043065926		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.5688015043065926 | validation: 1.6472543814490275]
	TIME [epoch: 5.75 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5714339548127585		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.5714339548127585 | validation: 1.4598449960705875]
	TIME [epoch: 5.75 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4477772011227326		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.4477772011227326 | validation: 1.300417054892705]
	TIME [epoch: 5.75 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0414283442494936		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.0414283442494936 | validation: 1.1988020969365152]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6378609215332705		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.6378609215332705 | validation: 1.6579429867308608]
	TIME [epoch: 5.75 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5702163546482222		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.5702163546482222 | validation: 1.4386788591632524]
	TIME [epoch: 5.73 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4978417040636307		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.4978417040636307 | validation: 1.4610259676772015]
	TIME [epoch: 5.74 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6172201096455305		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.6172201096455305 | validation: 1.6513267847505346]
	TIME [epoch: 5.73 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5536299413820573		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.5536299413820573 | validation: 1.8657468857511144]
	TIME [epoch: 5.75 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7385065510083133		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.7385065510083133 | validation: 1.3371744658075813]
	TIME [epoch: 5.77 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4900207038517002		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.4900207038517002 | validation: 2.6285490741409068]
	TIME [epoch: 5.75 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8278744048400353		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.8278744048400353 | validation: 1.716404626979637]
	TIME [epoch: 5.73 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6218521442142098		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.6218521442142098 | validation: 1.4936172731152795]
	TIME [epoch: 5.75 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4491767400861737		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.4491767400861737 | validation: 1.541262345348442]
	TIME [epoch: 5.73 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5581160434742665		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.5581160434742665 | validation: 1.6625457754855157]
	TIME [epoch: 5.75 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7449127656668275		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.7449127656668275 | validation: 1.5385733519242901]
	TIME [epoch: 5.77 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4927459785846695		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.4927459785846695 | validation: 1.2685105777087753]
	TIME [epoch: 5.75 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7114797190356976		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.7114797190356976 | validation: 1.603875029806802]
	TIME [epoch: 5.72 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.622109754430268		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.622109754430268 | validation: 1.4419353875668293]
	TIME [epoch: 5.74 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6401136975050745		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.6401136975050745 | validation: 1.2557321537285737]
	TIME [epoch: 5.73 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6259270560880563		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.6259270560880563 | validation: 1.5739203275593736]
	TIME [epoch: 5.74 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5870829109025837		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.5870829109025837 | validation: 1.294402250474643]
	TIME [epoch: 5.79 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4250891884968875		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.4250891884968875 | validation: 1.5242399382065162]
	TIME [epoch: 5.74 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6064199781059385		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.6064199781059385 | validation: 1.6714641332907547]
	TIME [epoch: 5.74 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6294953344644552		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.6294953344644552 | validation: 1.268375709722589]
	TIME [epoch: 5.73 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4081343402489581		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.4081343402489581 | validation: 1.1626145787737792]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3195253599286263		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.3195253599286263 | validation: 1.3718870429671817]
	TIME [epoch: 5.74 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3808096993273913		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.3808096993273913 | validation: 1.646524714702294]
	TIME [epoch: 5.78 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6607968281062835		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.6607968281062835 | validation: 1.260152105105596]
	TIME [epoch: 5.75 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.542567851324993		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.542567851324993 | validation: 1.3878894134063529]
	TIME [epoch: 5.74 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4631224440149653		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.4631224440149653 | validation: 1.4589743207368266]
	TIME [epoch: 5.73 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6280335248876978		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.6280335248876978 | validation: 1.7820205572347612]
	TIME [epoch: 5.75 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5866588347681225		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.5866588347681225 | validation: 1.2859955417663655]
	TIME [epoch: 5.74 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3829338602807815		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.3829338602807815 | validation: 1.3280683015934938]
	TIME [epoch: 5.79 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4411904274541318		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.4411904274541318 | validation: 1.2943320032251293]
	TIME [epoch: 5.75 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5003748320346926		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.5003748320346926 | validation: 2.0748758882006246]
	TIME [epoch: 5.75 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7962486279328016		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.7962486279328016 | validation: 1.4058360653392874]
	TIME [epoch: 5.73 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3735450360727834		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.3735450360727834 | validation: 1.121317463453256]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4410804941022684		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.4410804941022684 | validation: 1.5056834918655961]
	TIME [epoch: 5.75 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3803892593205498		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.3803892593205498 | validation: 1.396355273205926]
	TIME [epoch: 5.78 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3481740678448428		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.3481740678448428 | validation: 1.2590999766410205]
	TIME [epoch: 5.75 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240919741773457		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.240919741773457 | validation: 1.530256625857441]
	TIME [epoch: 5.74 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3723358174958151		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.3723358174958151 | validation: 1.5699029432180716]
	TIME [epoch: 5.74 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.387716814174911		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.387716814174911 | validation: 1.0941912284172366]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.351010306031979		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.351010306031979 | validation: 1.0803980132759614]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.442846286641313		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.442846286641313 | validation: 1.0761709454055275]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.471204462177963		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.471204462177963 | validation: 1.5068936176983898]
	TIME [epoch: 5.75 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.389491479857557		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.389491479857557 | validation: 1.3510590422640032]
	TIME [epoch: 5.73 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3064237586252578		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.3064237586252578 | validation: 1.4172778393792629]
	TIME [epoch: 5.73 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6548312698873353		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.6548312698873353 | validation: 1.4736743353436554]
	TIME [epoch: 5.73 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4192810899846309		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.4192810899846309 | validation: 1.3065472360740313]
	TIME [epoch: 5.76 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2703875649066227		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.2703875649066227 | validation: 1.379529851833064]
	TIME [epoch: 5.75 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4776092803328793		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.4776092803328793 | validation: 1.4296489106552903]
	TIME [epoch: 5.74 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4126902900792675		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.4126902900792675 | validation: 1.2407943307791522]
	TIME [epoch: 5.74 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.269635559843781		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.269635559843781 | validation: 1.7961515354589415]
	TIME [epoch: 5.74 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4666215965390323		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.4666215965390323 | validation: 0.9974257457092952]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2376258612624784		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.2376258612624784 | validation: 1.157749817449442]
	TIME [epoch: 5.76 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2804582736905834		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.2804582736905834 | validation: 1.0770832026061528]
	TIME [epoch: 5.75 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2448416511744105		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.2448416511744105 | validation: 1.0731766084942327]
	TIME [epoch: 5.74 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4787443317780389		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.4787443317780389 | validation: 1.049923519968903]
	TIME [epoch: 5.73 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3268994546584367		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.3268994546584367 | validation: 1.8329451293459453]
	TIME [epoch: 5.73 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3207440367200405		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.3207440367200405 | validation: 0.940809320947886]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2507370756991842		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.2507370756991842 | validation: 1.2037519492311453]
	TIME [epoch: 5.77 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.368940641960566		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.368940641960566 | validation: 1.5550825777890083]
	TIME [epoch: 5.74 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5521371885310091		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.5521371885310091 | validation: 1.1643613209794836]
	TIME [epoch: 5.73 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3235468487883424		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.3235468487883424 | validation: 1.2118053343812683]
	TIME [epoch: 5.73 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.303074793999667		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.303074793999667 | validation: 1.34264727722563]
	TIME [epoch: 5.73 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3077733571470924		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.3077733571470924 | validation: 1.4351140913776157]
	TIME [epoch: 5.73 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2889396622574552		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.2889396622574552 | validation: 1.238949930971912]
	TIME [epoch: 5.77 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2994848018004928		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.2994848018004928 | validation: 1.189241699453626]
	TIME [epoch: 5.74 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4645258401786747		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.4645258401786747 | validation: 1.117604379782376]
	TIME [epoch: 5.73 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2581932730156253		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.2581932730156253 | validation: 1.366946207508329]
	TIME [epoch: 5.73 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3277986901617016		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.3277986901617016 | validation: 1.1562974493933982]
	TIME [epoch: 5.73 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1586461571881999		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.1586461571881999 | validation: 1.106479315298563]
	TIME [epoch: 5.73 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.455563315382472		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.455563315382472 | validation: 1.0888880141734674]
	TIME [epoch: 5.76 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3672679382232016		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.3672679382232016 | validation: 1.228284316129333]
	TIME [epoch: 5.75 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5181826490048271		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.5181826490048271 | validation: 1.1157698115016692]
	TIME [epoch: 5.73 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2931370004283134		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.2931370004283134 | validation: 1.3536920149036331]
	TIME [epoch: 5.73 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3425116005004163		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.3425116005004163 | validation: 1.12859454100163]
	TIME [epoch: 5.74 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2080089525446318		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.2080089525446318 | validation: 1.147418840836054]
	TIME [epoch: 5.73 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2736337975998997		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.2736337975998997 | validation: 1.2442435930926035]
	TIME [epoch: 5.77 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.273790311457328		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.273790311457328 | validation: 0.9789923416490629]
	TIME [epoch: 5.75 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3002527116839306		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.3002527116839306 | validation: 1.230209285403689]
	TIME [epoch: 5.73 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3321292535666431		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.3321292535666431 | validation: 1.1402041792848931]
	TIME [epoch: 5.73 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2757411828272474		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.2757411828272474 | validation: 1.0585730427086564]
	TIME [epoch: 5.73 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2200482625921778		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.2200482625921778 | validation: 1.1973612645926102]
	TIME [epoch: 5.73 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2041121566750062		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.2041121566750062 | validation: 1.181697420892043]
	TIME [epoch: 5.76 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.273156244930913		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.273156244930913 | validation: 1.2347926231962492]
	TIME [epoch: 5.75 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2176911711695608		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.2176911711695608 | validation: 1.2202613529855848]
	TIME [epoch: 5.73 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1593619769308725		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.1593619769308725 | validation: 1.944407182780782]
	TIME [epoch: 5.73 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.528155324554611		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.528155324554611 | validation: 1.234959120598596]
	TIME [epoch: 5.73 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2696119687100689		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.2696119687100689 | validation: 1.123052314558723]
	TIME [epoch: 5.73 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1546981765107867		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.1546981765107867 | validation: 0.9704376561288791]
	TIME [epoch: 5.76 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1616685674044636		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.1616685674044636 | validation: 1.031844588224787]
	TIME [epoch: 5.75 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2120500857262588		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.2120500857262588 | validation: 0.9990446226783155]
	TIME [epoch: 5.73 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0909025893841058		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.0909025893841058 | validation: 1.1402554117313297]
	TIME [epoch: 5.73 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1608057895482617		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.1608057895482617 | validation: 1.1611837773203797]
	TIME [epoch: 5.73 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.274800691455971		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.274800691455971 | validation: 0.9601824092281104]
	TIME [epoch: 5.73 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1746592321207046		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.1746592321207046 | validation: 1.4086510797885794]
	TIME [epoch: 5.76 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.342755506654449		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.342755506654449 | validation: 1.6804565090012185]
	TIME [epoch: 5.75 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2609521702685407		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.2609521702685407 | validation: 1.14811148473616]
	TIME [epoch: 5.74 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3177617260789678		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.3177617260789678 | validation: 0.9894261548934763]
	TIME [epoch: 5.73 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2458769938924923		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.2458769938924923 | validation: 1.0266704316942512]
	TIME [epoch: 5.73 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1602263966919137		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.1602263966919137 | validation: 1.0750527751150187]
	TIME [epoch: 5.73 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1601787781944601		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.1601787781944601 | validation: 1.0432798937304992]
	TIME [epoch: 5.77 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1229126128361275		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.1229126128361275 | validation: 1.1446056213385114]
	TIME [epoch: 5.75 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056548306563113		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.056548306563113 | validation: 1.1932039743409335]
	TIME [epoch: 5.73 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1349372431960798		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.1349372431960798 | validation: 1.1693674439703852]
	TIME [epoch: 5.73 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1727169905533965		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.1727169905533965 | validation: 1.0262634441789305]
	TIME [epoch: 5.73 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0656893124780809		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.0656893124780809 | validation: 0.9654525220057971]
	TIME [epoch: 5.74 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3480225050420815		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.3480225050420815 | validation: 1.1479791273606343]
	TIME [epoch: 5.76 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0577213509914403		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.0577213509914403 | validation: 0.9167881913497979]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.074373642732884		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.074373642732884 | validation: 1.2218790264673367]
	TIME [epoch: 5.74 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.085539115946017		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.085539115946017 | validation: 1.199750113130342]
	TIME [epoch: 5.73 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0618696831886718		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.0618696831886718 | validation: 1.007448988777186]
	TIME [epoch: 5.74 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2445251937790065		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.2445251937790065 | validation: 1.016130127055367]
	TIME [epoch: 5.73 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1327823581736014		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.1327823581736014 | validation: 1.27581107935034]
	TIME [epoch: 5.77 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1756408206136093		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.1756408206136093 | validation: 1.09777758843404]
	TIME [epoch: 5.75 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1610453298269747		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.1610453298269747 | validation: 1.0286990345728029]
	TIME [epoch: 5.74 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0741831281192793		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.0741831281192793 | validation: 0.9825643281200709]
	TIME [epoch: 5.73 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0816751536927507		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.0816751536927507 | validation: 1.0138205862619727]
	TIME [epoch: 5.73 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1553564568010621		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.1553564568010621 | validation: 1.2804419745836526]
	TIME [epoch: 5.73 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1928652844202805		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.1928652844202805 | validation: 1.2025249731003713]
	TIME [epoch: 5.77 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2024451643520186		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.2024451643520186 | validation: 1.314739338212599]
	TIME [epoch: 5.75 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2026329072092825		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.2026329072092825 | validation: 1.215123117654826]
	TIME [epoch: 5.74 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2410216057114707		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.2410216057114707 | validation: 1.0430917577832506]
	TIME [epoch: 5.74 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0153664007758103		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.0153664007758103 | validation: 2.0434214663794603]
	TIME [epoch: 5.73 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2844232140543292		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.2844232140543292 | validation: 1.3464853646613955]
	TIME [epoch: 5.73 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1220447872427184		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.1220447872427184 | validation: 0.9591020416711383]
	TIME [epoch: 5.77 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.109337214938421		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.109337214938421 | validation: 1.0369364744782668]
	TIME [epoch: 5.75 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0513760504335452		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.0513760504335452 | validation: 1.2313029245243043]
	TIME [epoch: 5.73 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.143268231279502		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.143268231279502 | validation: 1.027345999057448]
	TIME [epoch: 5.74 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0687726965738846		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.0687726965738846 | validation: 0.9933494932402632]
	TIME [epoch: 5.74 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.004559379882759		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.004559379882759 | validation: 0.967922536635231]
	TIME [epoch: 5.73 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0475581665514972		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.0475581665514972 | validation: 0.8377884843906909]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0185660267871581		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.0185660267871581 | validation: 0.9115986627195979]
	TIME [epoch: 5.76 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0077975460879756		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.0077975460879756 | validation: 1.0525286270485663]
	TIME [epoch: 5.74 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1041581594515126		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.1041581594515126 | validation: 1.048524832647242]
	TIME [epoch: 5.73 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0454390552788648		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.0454390552788648 | validation: 1.174188467460888]
	TIME [epoch: 5.74 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2070873500896107		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.2070873500896107 | validation: 0.9027254296681904]
	TIME [epoch: 5.73 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9875898037663489		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.9875898037663489 | validation: 1.677724245287123]
	TIME [epoch: 5.77 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.267600343182719		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.267600343182719 | validation: 1.0086274059430256]
	TIME [epoch: 5.74 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9299181373541305		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.9299181373541305 | validation: 1.317702242057799]
	TIME [epoch: 5.73 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1027413100525605		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.1027413100525605 | validation: 0.8938144391608336]
	TIME [epoch: 5.75 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0178505549910444		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.0178505549910444 | validation: 1.0228526716149011]
	TIME [epoch: 5.75 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0581461536401964		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.0581461536401964 | validation: 0.8182334988716757]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.012077957501012		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.012077957501012 | validation: 1.0138912317936175]
	TIME [epoch: 5.77 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0822952047704488		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.0822952047704488 | validation: 0.9446797237974351]
	TIME [epoch: 5.74 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.079853834799628		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.079853834799628 | validation: 0.8866820471173246]
	TIME [epoch: 5.73 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9263300460079075		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.9263300460079075 | validation: 0.8634002090327161]
	TIME [epoch: 5.73 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0510904638657883		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.0510904638657883 | validation: 0.8033544070418183]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9328482210607116		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.9328482210607116 | validation: 0.8810022316319075]
	TIME [epoch: 5.74 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639507228154406		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.0639507228154406 | validation: 0.8867345193498389]
	TIME [epoch: 5.77 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9019020532589266		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.9019020532589266 | validation: 0.9393454964287478]
	TIME [epoch: 5.74 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.993923444881755		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.993923444881755 | validation: 0.9084398112292544]
	TIME [epoch: 5.75 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9670965030037586		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.9670965030037586 | validation: 0.7762950138531514]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9912488106726149		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.9912488106726149 | validation: 0.8052313189762168]
	TIME [epoch: 5.73 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.036876460396235		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.036876460396235 | validation: 0.8513642059050065]
	TIME [epoch: 5.73 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9258526366934356		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.9258526366934356 | validation: 0.7792648848511536]
	TIME [epoch: 5.77 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9302011240546302		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.9302011240546302 | validation: 0.7375474597388114]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8173662972855642		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.8173662972855642 | validation: 0.6754801875717056]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8179494664377086		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.8179494664377086 | validation: 0.8350443117504861]
	TIME [epoch: 5.73 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9042986144490135		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.9042986144490135 | validation: 0.9981985987768576]
	TIME [epoch: 5.75 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8445669196577487		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.8445669196577487 | validation: 0.6958235589738936]
	TIME [epoch: 5.76 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8827874909372847		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.8827874909372847 | validation: 0.8934049307739054]
	TIME [epoch: 5.76 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8440180975506384		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.8440180975506384 | validation: 0.6462133781164633]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8854419041330472		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.8854419041330472 | validation: 0.9593227992525977]
	TIME [epoch: 5.74 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032027564530904		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.032027564530904 | validation: 0.8895537246637599]
	TIME [epoch: 5.73 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1851150466058022		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.1851150466058022 | validation: 1.2025812152172437]
	TIME [epoch: 5.74 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9771866782591493		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.9771866782591493 | validation: 0.913622458387662]
	TIME [epoch: 5.75 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.89513166764401		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.89513166764401 | validation: 0.9039894087581063]
	TIME [epoch: 5.77 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8425547785085098		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.8425547785085098 | validation: 0.9151675488155072]
	TIME [epoch: 5.74 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8886096239013421		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.8886096239013421 | validation: 0.7786285439345377]
	TIME [epoch: 5.74 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0045484412239205		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.0045484412239205 | validation: 1.054635934807765]
	TIME [epoch: 5.74 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9129497818705476		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.9129497818705476 | validation: 0.7235220477288826]
	TIME [epoch: 5.74 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7946713982497847		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.7946713982497847 | validation: 0.7121192969370328]
	TIME [epoch: 5.75 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7725187226734814		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.7725187226734814 | validation: 1.2157268545737645]
	TIME [epoch: 5.77 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3814207935418694		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.3814207935418694 | validation: 1.4272213857331326]
	TIME [epoch: 5.74 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.049350668502037		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.049350668502037 | validation: 0.8908168855100769]
	TIME [epoch: 5.74 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8070928989774642		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.8070928989774642 | validation: 0.7638057835940208]
	TIME [epoch: 5.74 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8822271161167666		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.8822271161167666 | validation: 0.7999561428101055]
	TIME [epoch: 5.74 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8244245260462655		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.8244245260462655 | validation: 0.6985296491894638]
	TIME [epoch: 5.75 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9303597606188824		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.9303597606188824 | validation: 0.9409977668396219]
	TIME [epoch: 5.77 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8820857766001021		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.8820857766001021 | validation: 0.8301336449329005]
	TIME [epoch: 5.74 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9507655078725422		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.9507655078725422 | validation: 0.8764688131239138]
	TIME [epoch: 5.74 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8462316093705776		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.8462316093705776 | validation: 0.8247652033668911]
	TIME [epoch: 5.74 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8435233029155425		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.8435233029155425 | validation: 0.6415906558934745]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7405785317768838		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.7405785317768838 | validation: 0.8898440522335233]
	TIME [epoch: 5.75 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9240480713076258		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.9240480713076258 | validation: 1.0543115631334505]
	TIME [epoch: 5.76 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8048378909507924		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.8048378909507924 | validation: 0.8167286103493612]
	TIME [epoch: 5.74 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.927198694242076		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.927198694242076 | validation: 0.8283017012026346]
	TIME [epoch: 5.73 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8101018367283166		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.8101018367283166 | validation: 0.6230965284133642]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7858496844346445		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.7858496844346445 | validation: 0.6683530698297512]
	TIME [epoch: 5.74 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9111874073507571		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.9111874073507571 | validation: 0.6748472774125202]
	TIME [epoch: 5.77 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.762138279595839		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.762138279595839 | validation: 1.3433533423913644]
	TIME [epoch: 5.75 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2430377196391045		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.2430377196391045 | validation: 1.1627164333343323]
	TIME [epoch: 5.74 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1594829867249934		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.1594829867249934 | validation: 0.8113911568824846]
	TIME [epoch: 5.73 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7811814964456782		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.7811814964456782 | validation: 1.1730579146497142]
	TIME [epoch: 5.75 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0962290251252185		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.0962290251252185 | validation: 0.627262754112413]
	TIME [epoch: 5.74 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836678059358052		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.6836678059358052 | validation: 0.8491962808437004]
	TIME [epoch: 5.77 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7863154794467269		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.7863154794467269 | validation: 0.5592942698113946]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7263587238541803		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.7263587238541803 | validation: 0.6678097002548896]
	TIME [epoch: 5.74 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7089630337650262		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.7089630337650262 | validation: 1.2068137781578125]
	TIME [epoch: 5.73 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9051624494139525		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.9051624494139525 | validation: 0.887189695032217]
	TIME [epoch: 5.73 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9054769901684054		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.9054769901684054 | validation: 0.8123771420161995]
	TIME [epoch: 5.74 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8534305845550321		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.8534305845550321 | validation: 0.642222704766283]
	TIME [epoch: 5.76 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7150924303535776		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.7150924303535776 | validation: 0.6762136290613421]
	TIME [epoch: 5.74 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332069183740852		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.7332069183740852 | validation: 0.9082382462814225]
	TIME [epoch: 5.73 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7985256630184319		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.7985256630184319 | validation: 0.946195995282233]
	TIME [epoch: 5.73 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.110410673802132		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.110410673802132 | validation: 1.057475927098994]
	TIME [epoch: 5.73 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8351842388284465		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.8351842388284465 | validation: 0.6618853052970206]
	TIME [epoch: 5.73 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7393897877386413		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.7393897877386413 | validation: 0.7787028071423313]
	TIME [epoch: 5.76 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.692020545154991		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.692020545154991 | validation: 0.6946663650244105]
	TIME [epoch: 5.75 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7549385391494996		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7549385391494996 | validation: 0.7529812345322747]
	TIME [epoch: 5.73 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7491119228467155		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.7491119228467155 | validation: 0.9975500517103347]
	TIME [epoch: 5.73 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8559755101567379		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.8559755101567379 | validation: 0.9355766848169063]
	TIME [epoch: 5.74 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8135740207078337		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.8135740207078337 | validation: 0.6815521509357008]
	TIME [epoch: 5.72 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7855171676561518		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.7855171676561518 | validation: 0.73322462227936]
	TIME [epoch: 5.76 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7814939530921464		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.7814939530921464 | validation: 0.7092186562487622]
	TIME [epoch: 5.76 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9718950759606402		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.9718950759606402 | validation: 0.6911653672805607]
	TIME [epoch: 5.73 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7403766638190564		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.7403766638190564 | validation: 0.7706413833138024]
	TIME [epoch: 5.75 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7773897706957211		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.7773897706957211 | validation: 0.6170098863683758]
	TIME [epoch: 5.73 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014826617668297		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.7014826617668297 | validation: 0.6486941008350189]
	TIME [epoch: 5.75 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7558707402768485		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.7558707402768485 | validation: 0.6348972693708032]
	TIME [epoch: 5.76 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7490177073660358		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.7490177073660358 | validation: 0.8388711055956687]
	TIME [epoch: 5.75 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206345996186444		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.7206345996186444 | validation: 1.440420362873694]
	TIME [epoch: 5.73 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.010245771148919		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.010245771148919 | validation: 0.588844121768821]
	TIME [epoch: 5.73 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7979019561611707		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.7979019561611707 | validation: 0.7026857663006046]
	TIME [epoch: 5.73 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7137316897142589		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.7137316897142589 | validation: 0.6906463052499318]
	TIME [epoch: 5.73 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.708541642035691		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.708541642035691 | validation: 0.6674834398440231]
	TIME [epoch: 5.76 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8753693467138287		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.8753693467138287 | validation: 0.6770809713161005]
	TIME [epoch: 5.75 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7469078198792427		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.7469078198792427 | validation: 1.0122384989747888]
	TIME [epoch: 5.73 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0309596976681628		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.0309596976681628 | validation: 0.7419738905719987]
	TIME [epoch: 5.73 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9598526990060134		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.9598526990060134 | validation: 0.9021329043798823]
	TIME [epoch: 5.73 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8625122818585615		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.8625122818585615 | validation: 0.8309016698565881]
	TIME [epoch: 5.73 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7585203072511807		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.7585203072511807 | validation: 0.6098148664260183]
	TIME [epoch: 5.76 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7424296688367895		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.7424296688367895 | validation: 0.7002646864951038]
	TIME [epoch: 5.75 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.676520492981499		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.676520492981499 | validation: 0.5855965290798093]
	TIME [epoch: 5.73 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390641650158441		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.6390641650158441 | validation: 0.5230660770807879]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6941239654190163		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.6941239654190163 | validation: 0.5344980640488864]
	TIME [epoch: 5.73 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6185603507980425		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.6185603507980425 | validation: 0.4714099821005901]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5711577589380981		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.5711577589380981 | validation: 0.5227224806526377]
	TIME [epoch: 5.77 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.606021902990791		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.606021902990791 | validation: 0.5807369845623095]
	TIME [epoch: 5.74 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5747799470170543		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5747799470170543 | validation: 0.9351434397248133]
	TIME [epoch: 5.74 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9544801737764561		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.9544801737764561 | validation: 0.7568332699194579]
	TIME [epoch: 5.74 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.650981890364395		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.650981890364395 | validation: 0.44573750716784405]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7110356621708973		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.7110356621708973 | validation: 0.8727237756987672]
	TIME [epoch: 5.73 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6509564563234634		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.6509564563234634 | validation: 0.4469883431738339]
	TIME [epoch: 5.77 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7402239989276307		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.7402239989276307 | validation: 0.5909574396926554]
	TIME [epoch: 5.76 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6361220772198528		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.6361220772198528 | validation: 0.8017483648802036]
	TIME [epoch: 5.73 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6707332739063498		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.6707332739063498 | validation: 0.5208264628367179]
	TIME [epoch: 5.73 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5743169775545933		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5743169775545933 | validation: 0.48607305672751294]
	TIME [epoch: 5.73 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5541192453455904		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.5541192453455904 | validation: 0.522773596116893]
	TIME [epoch: 5.73 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5814942385025423		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.5814942385025423 | validation: 0.4797498177070547]
	TIME [epoch: 5.77 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6004051294808768		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.6004051294808768 | validation: 0.6815330393688439]
	TIME [epoch: 5.74 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.587633616150506		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.587633616150506 | validation: 0.7907231816971203]
	TIME [epoch: 5.73 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6947261987930116		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.6947261987930116 | validation: 0.4826385975754326]
	TIME [epoch: 5.73 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.603227015221117		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.603227015221117 | validation: 0.4932020362286948]
	TIME [epoch: 5.73 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5137589559954053		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.5137589559954053 | validation: 0.7030541911440571]
	TIME [epoch: 5.73 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5808032536281101		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.5808032536281101 | validation: 0.5691116755479197]
	TIME [epoch: 5.77 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.557769154337397		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.557769154337397 | validation: 0.6666081548877371]
	TIME [epoch: 5.74 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7816572972296238		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.7816572972296238 | validation: 0.8779876287441198]
	TIME [epoch: 5.73 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899850938456519		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.6899850938456519 | validation: 0.44167677805076966]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6310976437632121		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.6310976437632121 | validation: 0.44430632192732206]
	TIME [epoch: 5.75 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8852857525949172		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.8852857525949172 | validation: 0.5124623521916174]
	TIME [epoch: 5.73 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5894836783778878		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.5894836783778878 | validation: 0.49113121634944146]
	TIME [epoch: 5.77 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228351697252854		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.6228351697252854 | validation: 0.5109032970210343]
	TIME [epoch: 5.76 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5453465510288082		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.5453465510288082 | validation: 0.8005563173004591]
	TIME [epoch: 5.73 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6580841894073691		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.6580841894073691 | validation: 0.45092337613368044]
	TIME [epoch: 5.73 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301802772957203		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.5301802772957203 | validation: 0.557613195320378]
	TIME [epoch: 5.74 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.552719263970846		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.552719263970846 | validation: 0.3438897989615177]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5578996821800827		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.5578996821800827 | validation: 0.3914474607411987]
	TIME [epoch: 5.78 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.560348701770829		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.560348701770829 | validation: 0.5539645746452618]
	TIME [epoch: 5.73 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5775118388747146		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.5775118388747146 | validation: 0.47763798528250845]
	TIME [epoch: 5.74 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5746959403042466		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.5746959403042466 | validation: 0.42078082681990553]
	TIME [epoch: 5.73 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4433978141739907		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.4433978141739907 | validation: 0.33333682274220605]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3863588978800869		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.3863588978800869 | validation: 0.47419255628406315]
	TIME [epoch: 5.74 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5506185616729506		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5506185616729506 | validation: 0.6504081477528627]
	TIME [epoch: 5.77 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6181135967815431		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.6181135967815431 | validation: 0.660319728308578]
	TIME [epoch: 5.75 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7444617959505894		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.7444617959505894 | validation: 0.76213607604854]
	TIME [epoch: 5.73 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5376237424769887		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.5376237424769887 | validation: 0.4171412213087662]
	TIME [epoch: 5.73 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4625107092582158		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.4625107092582158 | validation: 0.4635105610551099]
	TIME [epoch: 5.73 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5079754556006895		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.5079754556006895 | validation: 0.45096099131060097]
	TIME [epoch: 5.73 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42467211913425185		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.42467211913425185 | validation: 0.4395049430564998]
	TIME [epoch: 5.77 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5983828008987775		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.5983828008987775 | validation: 0.5051393810105305]
	TIME [epoch: 5.74 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5626431631340438		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.5626431631340438 | validation: 0.4416649436606433]
	TIME [epoch: 5.72 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49252558952644426		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.49252558952644426 | validation: 0.3021116590327058]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4411963960387685		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.4411963960387685 | validation: 0.42994751168121]
	TIME [epoch: 5.74 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5148764354262652		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.5148764354262652 | validation: 0.37687192725009044]
	TIME [epoch: 5.74 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.514181260691778		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.514181260691778 | validation: 0.4088701657760099]
	TIME [epoch: 5.78 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5448314843984732		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.5448314843984732 | validation: 0.5282648752425344]
	TIME [epoch: 5.74 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6028228351020258		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.6028228351020258 | validation: 0.3802020643430541]
	TIME [epoch: 5.73 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3953790364024676		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.3953790364024676 | validation: 0.9937376464887754]
	TIME [epoch: 5.74 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5770297534129151		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.5770297534129151 | validation: 0.4464427301336923]
	TIME [epoch: 5.73 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.623314638871643		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.623314638871643 | validation: 0.6523959283285466]
	TIME [epoch: 5.76 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7302436293932648		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.7302436293932648 | validation: 0.5652255437711645]
	TIME [epoch: 5.78 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5843373748450429		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.5843373748450429 | validation: 0.3767896239358828]
	TIME [epoch: 5.73 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4217030125014382		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.4217030125014382 | validation: 0.7378533421584212]
	TIME [epoch: 5.74 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49791813048405625		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.49791813048405625 | validation: 0.4869514956595808]
	TIME [epoch: 5.73 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5026338870817376		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.5026338870817376 | validation: 0.5474393196377814]
	TIME [epoch: 5.75 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48746416174632523		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.48746416174632523 | validation: 0.8926407724377601]
	TIME [epoch: 5.76 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8212912610715322		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.8212912610715322 | validation: 0.5094472326168579]
	TIME [epoch: 5.78 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4728190531192589		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.4728190531192589 | validation: 0.3503178580569052]
	TIME [epoch: 5.75 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.072046343823575		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.072046343823575 | validation: 0.3928863984567258]
	TIME [epoch: 5.74 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.512271585083806		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.512271585083806 | validation: 0.29736542191303617]
	TIME [epoch: 6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3937580350455493		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.3937580350455493 | validation: 0.3882892064754151]
	TIME [epoch: 5.75 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43060880846001925		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.43060880846001925 | validation: 0.3848343668877915]
	TIME [epoch: 5.76 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3981095229659213		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.3981095229659213 | validation: 0.2709750113663135]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_411.pth
	Model improved!!!
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37800825772800417		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.37800825772800417 | validation: 0.5035099991100783]
	TIME [epoch: 5.76 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48391459806806225		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.48391459806806225 | validation: 0.4099297348353869]
	TIME [epoch: 5.75 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4230949858368596		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.4230949858368596 | validation: 0.228780267570932]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4309676574083729		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.4309676574083729 | validation: 0.446447049625984]
	TIME [epoch: 5.74 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35867894569775477		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.35867894569775477 | validation: 0.3058195168877078]
	TIME [epoch: 5.78 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41438474125897357		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.41438474125897357 | validation: 0.31883753433581385]
	TIME [epoch: 5.76 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3705146733500909		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.3705146733500909 | validation: 0.2907355785165161]
	TIME [epoch: 5.74 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4031409737928192		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.4031409737928192 | validation: 0.2903391694706088]
	TIME [epoch: 5.74 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5383478328998599		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.5383478328998599 | validation: 0.4796727760197061]
	TIME [epoch: 5.75 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5294013904697388		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.5294013904697388 | validation: 0.39455908620302405]
	TIME [epoch: 5.75 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35277583051794503		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.35277583051794503 | validation: 0.3057255813091282]
	TIME [epoch: 5.78 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40831401114213106		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.40831401114213106 | validation: 0.3409846495423821]
	TIME [epoch: 5.77 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40834271347943807		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.40834271347943807 | validation: 0.6141905380430457]
	TIME [epoch: 5.76 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42049148040193135		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.42049148040193135 | validation: 0.5482368006604749]
	TIME [epoch: 5.75 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48633958482424994		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.48633958482424994 | validation: 0.49468663647739475]
	TIME [epoch: 5.75 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5405167896886783		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.5405167896886783 | validation: 0.4257595412944992]
	TIME [epoch: 5.75 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.521338011400895		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.521338011400895 | validation: 0.47498125873350605]
	TIME [epoch: 5.78 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6001114457077543		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.6001114457077543 | validation: 0.7011690709860963]
	TIME [epoch: 5.77 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.612951974475853		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.612951974475853 | validation: 0.39856967748144856]
	TIME [epoch: 5.75 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38012207142034443		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.38012207142034443 | validation: 0.3033825879745166]
	TIME [epoch: 5.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.401196259489528		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.401196259489528 | validation: 0.2751993515881373]
	TIME [epoch: 5.76 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5975626079163427		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.5975626079163427 | validation: 0.2394277253948595]
	TIME [epoch: 5.75 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34479781497572515		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.34479781497572515 | validation: 0.43998220751384914]
	TIME [epoch: 5.78 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4011782952647424		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.4011782952647424 | validation: 0.3359479665497289]
	TIME [epoch: 5.77 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42243610160349265		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.42243610160349265 | validation: 0.3463767177403301]
	TIME [epoch: 5.74 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4701550662486912		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.4701550662486912 | validation: 0.47880315080612645]
	TIME [epoch: 5.74 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49877853492017665		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.49877853492017665 | validation: 0.38412406382764036]
	TIME [epoch: 5.73 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.487292124065748		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.487292124065748 | validation: 0.41659964918848225]
	TIME [epoch: 5.75 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44058886665627195		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.44058886665627195 | validation: 0.3073219771138881]
	TIME [epoch: 5.78 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36018199996893197		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.36018199996893197 | validation: 0.30487558711921314]
	TIME [epoch: 5.77 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43287978063670196		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.43287978063670196 | validation: 0.3126126171007822]
	TIME [epoch: 5.75 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3745328604381999		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.3745328604381999 | validation: 0.4854829996998481]
	TIME [epoch: 5.74 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49740354094995204		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.49740354094995204 | validation: 0.46337282739219754]
	TIME [epoch: 5.75 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189675121912829		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5189675121912829 | validation: 0.26270950765638934]
	TIME [epoch: 5.76 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4284773798118704		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.4284773798118704 | validation: 0.5716925624231867]
	TIME [epoch: 5.78 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44255647232724427		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.44255647232724427 | validation: 0.4751064612135965]
	TIME [epoch: 5.76 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39502252595257226		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.39502252595257226 | validation: 0.3293469102128867]
	TIME [epoch: 5.73 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42633406512218774		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.42633406512218774 | validation: 0.3968175229346202]
	TIME [epoch: 5.75 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49024345977680134		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.49024345977680134 | validation: 0.36809150238121807]
	TIME [epoch: 5.75 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4766902375467379		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.4766902375467379 | validation: 0.7084220850607684]
	TIME [epoch: 5.73 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4661722451721213		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.4661722451721213 | validation: 0.3672578190891681]
	TIME [epoch: 5.76 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45370317070961586		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.45370317070961586 | validation: 0.3875335427870708]
	TIME [epoch: 5.75 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347230569375657		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.347230569375657 | validation: 0.2937791522236928]
	TIME [epoch: 5.73 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43554843839229657		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.43554843839229657 | validation: 0.625760383948593]
	TIME [epoch: 5.73 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47652085192815774		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.47652085192815774 | validation: 0.47656440873339195]
	TIME [epoch: 5.73 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.515870755252573		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.515870755252573 | validation: 0.4677588976212566]
	TIME [epoch: 5.74 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39510824859496135		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.39510824859496135 | validation: 0.3880150529339816]
	TIME [epoch: 5.77 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46159626514805474		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.46159626514805474 | validation: 0.26549597340215647]
	TIME [epoch: 5.75 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373187502287313		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.373187502287313 | validation: 0.24981564813943416]
	TIME [epoch: 5.74 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36246761814275097		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.36246761814275097 | validation: 0.40421960960012854]
	TIME [epoch: 5.74 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38137083578803144		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.38137083578803144 | validation: 0.37701748237835775]
	TIME [epoch: 5.73 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6042620764075521		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.6042620764075521 | validation: 0.5467810573186483]
	TIME [epoch: 5.74 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4810566008104541		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.4810566008104541 | validation: 0.4514302089530696]
	TIME [epoch: 5.77 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4822329813511631		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.4822329813511631 | validation: 0.27402786524315836]
	TIME [epoch: 5.75 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37045494886969405		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.37045494886969405 | validation: 0.5907442745378011]
	TIME [epoch: 5.74 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46147267017218796		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.46147267017218796 | validation: 0.2876609148920878]
	TIME [epoch: 5.74 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301560193876507		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.3301560193876507 | validation: 0.29896866792123133]
	TIME [epoch: 5.73 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36357247166154305		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.36357247166154305 | validation: 0.24240204716583322]
	TIME [epoch: 5.74 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30088482881824086		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.30088482881824086 | validation: 0.3046150344119107]
	TIME [epoch: 5.76 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33929448160216225		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.33929448160216225 | validation: 0.3769490429690343]
	TIME [epoch: 5.75 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3236657232961013		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.3236657232961013 | validation: 0.2662926048323445]
	TIME [epoch: 5.73 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3471971794638267		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.3471971794638267 | validation: 0.3260343385937201]
	TIME [epoch: 5.74 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33465139754662143		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.33465139754662143 | validation: 0.29657233422165524]
	TIME [epoch: 5.73 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.443600614134369		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.443600614134369 | validation: 0.3026769987664793]
	TIME [epoch: 5.73 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31601172599347865		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.31601172599347865 | validation: 0.32231757868811206]
	TIME [epoch: 5.76 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2886300785112818		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.2886300785112818 | validation: 0.2501978172769128]
	TIME [epoch: 5.75 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32287713518382644		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.32287713518382644 | validation: 0.25811482488444004]
	TIME [epoch: 5.74 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33211184958893153		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.33211184958893153 | validation: 0.2902202095659412]
	TIME [epoch: 5.74 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34827848748041895		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.34827848748041895 | validation: 0.21103219924858202]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_480.pth
	Model improved!!!
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638711180863929		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.4638711180863929 | validation: 0.38924532896186165]
	TIME [epoch: 5.73 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4420003928233028		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.4420003928233028 | validation: 0.3357392943144106]
	TIME [epoch: 5.77 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2888492704840462		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.2888492704840462 | validation: 0.27051845220597837]
	TIME [epoch: 5.75 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3096213890244908		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.3096213890244908 | validation: 0.3724671726158607]
	TIME [epoch: 5.74 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352653904337901		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.3352653904337901 | validation: 0.22151471801199316]
	TIME [epoch: 5.73 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31471179680701267		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.31471179680701267 | validation: 0.3664923687847758]
	TIME [epoch: 5.74 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33348892309925704		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.33348892309925704 | validation: 0.22362851962424082]
	TIME [epoch: 5.74 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32282952528584996		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.32282952528584996 | validation: 0.35530995614035304]
	TIME [epoch: 5.77 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49180522411852867		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.49180522411852867 | validation: 0.5555231634626326]
	TIME [epoch: 5.76 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42015045456732564		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.42015045456732564 | validation: 0.2880148404755169]
	TIME [epoch: 5.73 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3174474486545796		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.3174474486545796 | validation: 0.25115967421084223]
	TIME [epoch: 5.73 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29994216435729393		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.29994216435729393 | validation: 0.2192186415986786]
	TIME [epoch: 5.73 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889702833480593		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.3889702833480593 | validation: 0.2738040317436684]
	TIME [epoch: 5.73 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35964180079937125		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.35964180079937125 | validation: 0.6024409932966962]
	TIME [epoch: 5.78 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4164487397879999		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.4164487397879999 | validation: 0.3023628364729056]
	TIME [epoch: 5.75 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3394562310880447		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.3394562310880447 | validation: 0.36566809260318933]
	TIME [epoch: 5.74 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2992105529900539		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.2992105529900539 | validation: 0.32567912840050484]
	TIME [epoch: 5.74 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5161501293721557		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.5161501293721557 | validation: 0.5973661889095888]
	TIME [epoch: 5.73 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43131843889830385		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.43131843889830385 | validation: 0.34668221597396526]
	TIME [epoch: 5.73 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3506594064839023		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.3506594064839023 | validation: 0.30738971158630907]
	TIME [epoch: 5.77 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4015980450373776		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.4015980450373776 | validation: 0.2382921068970581]
	TIME [epoch: 5.75 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31250875003891065		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.31250875003891065 | validation: 0.24345008006378446]
	TIME [epoch: 5.74 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.286274127899867		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.286274127899867 | validation: 0.2383358457467803]
	TIME [epoch: 5.74 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33532104381946065		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.33532104381946065 | validation: 0.2984317066555307]
	TIME [epoch: 5.74 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3094845204201159		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.3094845204201159 | validation: 0.19621919995523357]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3606667612707478		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.3606667612707478 | validation: 0.33338659722737696]
	TIME [epoch: 5.79 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36870351668272466		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.36870351668272466 | validation: 0.5155198590758253]
	TIME [epoch: 5.75 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35703416895070983		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.35703416895070983 | validation: 0.5217779086463497]
	TIME [epoch: 5.75 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44365941318019686		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.44365941318019686 | validation: 0.43219683432654393]
	TIME [epoch: 5.72 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3250623386286323		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.3250623386286323 | validation: 0.24247971166350138]
	TIME [epoch: 5.73 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3005058400186469		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.3005058400186469 | validation: 0.5508335989887144]
	TIME [epoch: 5.73 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4307870684007397		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.4307870684007397 | validation: 0.5181884334532757]
	TIME [epoch: 5.79 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44683074024379765		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.44683074024379765 | validation: 0.2004757320223122]
	TIME [epoch: 5.75 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33675891394129187		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.33675891394129187 | validation: 0.23056891396533113]
	TIME [epoch: 5.75 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2751158128452459		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.2751158128452459 | validation: 0.32711807002486204]
	TIME [epoch: 5.75 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28660992581854083		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.28660992581854083 | validation: 0.30546995921579306]
	TIME [epoch: 5.75 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3546913648664026		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.3546913648664026 | validation: 0.2853730660102621]
	TIME [epoch: 5.75 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3124017407632922		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.3124017407632922 | validation: 0.2642366108192412]
	TIME [epoch: 5.78 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3254302013038046		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.3254302013038046 | validation: 0.2573793873988549]
	TIME [epoch: 5.75 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32437129153895916		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.32437129153895916 | validation: 0.2180029646606776]
	TIME [epoch: 5.75 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3825114137039243		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.3825114137039243 | validation: 0.2777079607668284]
	TIME [epoch: 5.73 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3269210907024017		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.3269210907024017 | validation: 0.3670742560628561]
	TIME [epoch: 5.75 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.386726498082405		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.386726498082405 | validation: 0.2047209001595045]
	TIME [epoch: 5.73 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3134640676604686		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.3134640676604686 | validation: 0.23905955018023292]
	TIME [epoch: 5.78 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.329593962227758		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.329593962227758 | validation: 0.2658644312316199]
	TIME [epoch: 5.75 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34249506557608933		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.34249506557608933 | validation: 0.3167368782523069]
	TIME [epoch: 5.75 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31662178850593836		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.31662178850593836 | validation: 0.2728194069440149]
	TIME [epoch: 5.73 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3007640079247043		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.3007640079247043 | validation: 0.27886317185866405]
	TIME [epoch: 5.75 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3036893877764677		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.3036893877764677 | validation: 0.4108772256603347]
	TIME [epoch: 5.74 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37701821712588574		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.37701821712588574 | validation: 0.21046537408344188]
	TIME [epoch: 5.77 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27191674492570383		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.27191674492570383 | validation: 0.3764808540345784]
	TIME [epoch: 5.75 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36408954908903557		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.36408954908903557 | validation: 0.33180056658869506]
	TIME [epoch: 5.73 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46243671113412627		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.46243671113412627 | validation: 0.23893074337906325]
	TIME [epoch: 5.74 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2938762921821481		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.2938762921821481 | validation: 0.3142181774909876]
	TIME [epoch: 5.73 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2829585726310734		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.2829585726310734 | validation: 0.35363467575206725]
	TIME [epoch: 5.74 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2894657935863343		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.2894657935863343 | validation: 0.21831428024382216]
	TIME [epoch: 5.77 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3084586069960302		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.3084586069960302 | validation: 0.2528439026748789]
	TIME [epoch: 5.74 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3015643156650165		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.3015643156650165 | validation: 0.24937363615831437]
	TIME [epoch: 5.73 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2738900325660684		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.2738900325660684 | validation: 0.2850032413761]
	TIME [epoch: 5.74 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3286972386755591		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.3286972386755591 | validation: 0.26863405812061325]
	TIME [epoch: 5.73 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33117645431528075		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.33117645431528075 | validation: 0.32644036359419665]
	TIME [epoch: 5.74 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31755759372872583		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.31755759372872583 | validation: 0.515781548126828]
	TIME [epoch: 5.77 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4374895617708951		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.4374895617708951 | validation: 0.2423229671060036]
	TIME [epoch: 5.74 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32706101915528774		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.32706101915528774 | validation: 0.20056786242373867]
	TIME [epoch: 5.73 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2890798129945617		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.2890798129945617 | validation: 0.2405948060761025]
	TIME [epoch: 5.73 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2710635206338675		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.2710635206338675 | validation: 0.2870348528915862]
	TIME [epoch: 5.73 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29670626101858966		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.29670626101858966 | validation: 0.3181942424581993]
	TIME [epoch: 5.73 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3052300079695406		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.3052300079695406 | validation: 0.44718228795475673]
	TIME [epoch: 5.76 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3754582102602722		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.3754582102602722 | validation: 0.268777458171131]
	TIME [epoch: 5.74 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.302222933149745		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.302222933149745 | validation: 0.283880401356672]
	TIME [epoch: 5.73 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.318795758165877		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.318795758165877 | validation: 0.22155804784087632]
	TIME [epoch: 5.73 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41577299846352783		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.41577299846352783 | validation: 0.686584276083149]
	TIME [epoch: 5.73 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657867819020998		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.6657867819020998 | validation: 0.35755616388170874]
	TIME [epoch: 5.74 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4056806833391695		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.4056806833391695 | validation: 0.25144452326111016]
	TIME [epoch: 5.79 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3196023950966107		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.3196023950966107 | validation: 0.34282155818110915]
	TIME [epoch: 5.75 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3303049281893316		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.3303049281893316 | validation: 0.25667893558344196]
	TIME [epoch: 5.73 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29977676585424823		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.29977676585424823 | validation: 0.2744288555653107]
	TIME [epoch: 5.74 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29418007595170664		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.29418007595170664 | validation: 0.20185579181250762]
	TIME [epoch: 5.74 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29434940200753434		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.29434940200753434 | validation: 0.25157593364628567]
	TIME [epoch: 5.75 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031908495045146		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.3031908495045146 | validation: 0.44589925575007827]
	TIME [epoch: 5.78 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3234554059044582		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.3234554059044582 | validation: 0.22624168784957577]
	TIME [epoch: 5.75 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32473302215086997		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.32473302215086997 | validation: 0.28148595671104626]
	TIME [epoch: 5.74 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3970920594640425		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.3970920594640425 | validation: 0.3492789966760641]
	TIME [epoch: 5.73 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3947179392914768		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.3947179392914768 | validation: 0.4615517674361446]
	TIME [epoch: 5.73 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3775701597619112		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.3775701597619112 | validation: 0.2920095319996679]
	TIME [epoch: 5.73 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976498082972236		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.3976498082972236 | validation: 0.23125955005915014]
	TIME [epoch: 5.77 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3132997078731644		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.3132997078731644 | validation: 0.2569589154592039]
	TIME [epoch: 5.75 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27355114100707745		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.27355114100707745 | validation: 0.23779340423564774]
	TIME [epoch: 5.73 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3452042660404689		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.3452042660404689 | validation: 0.2518188399795055]
	TIME [epoch: 5.73 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4123945200025488		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.4123945200025488 | validation: 0.3175288195016028]
	TIME [epoch: 5.73 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3428479046550075		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.3428479046550075 | validation: 0.2604610294456616]
	TIME [epoch: 5.73 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35479274441079645		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.35479274441079645 | validation: 0.4753313899062996]
	TIME [epoch: 5.79 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33991555994911504		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.33991555994911504 | validation: 0.24343526088959724]
	TIME [epoch: 5.75 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3048455601451218		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.3048455601451218 | validation: 0.2797928079525331]
	TIME [epoch: 5.75 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2843055482326897		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.2843055482326897 | validation: 0.5167903163159431]
	TIME [epoch: 5.75 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43553742301193704		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.43553742301193704 | validation: 0.2707025491543314]
	TIME [epoch: 5.75 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27457083368638635		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.27457083368638635 | validation: 0.20053104536362695]
	TIME [epoch: 5.73 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25585117079069164		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.25585117079069164 | validation: 0.22999678869671347]
	TIME [epoch: 5.78 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2918539276288608		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.2918539276288608 | validation: 0.23855890663960475]
	TIME [epoch: 5.75 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34470060587127743		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.34470060587127743 | validation: 0.29972755770182236]
	TIME [epoch: 5.75 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36704500551719904		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.36704500551719904 | validation: 0.2026681826941613]
	TIME [epoch: 5.73 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31087774491086967		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.31087774491086967 | validation: 0.3062280223732291]
	TIME [epoch: 5.75 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3438020015031722		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.3438020015031722 | validation: 0.36709320316948973]
	TIME [epoch: 5.73 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32669963405982955		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.32669963405982955 | validation: 0.18510331203689234]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_584.pth
	Model improved!!!
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039480235334313		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.3039480235334313 | validation: 0.7872844217468097]
	TIME [epoch: 5.74 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46484807662289546		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.46484807662289546 | validation: 0.3182159848546259]
	TIME [epoch: 5.74 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321707032968793		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.3321707032968793 | validation: 0.21210432577864788]
	TIME [epoch: 5.74 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22900765289543099		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.22900765289543099 | validation: 0.22758131868340886]
	TIME [epoch: 5.74 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923234551836944		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.2923234551836944 | validation: 0.29381612105170696]
	TIME [epoch: 5.74 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2742780480804873		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.2742780480804873 | validation: 0.40298284851603966]
	TIME [epoch: 5.78 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27930224324844566		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.27930224324844566 | validation: 0.2489275259695306]
	TIME [epoch: 5.75 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31419007930496723		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.31419007930496723 | validation: 0.21768037244331923]
	TIME [epoch: 5.74 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3282537260149257		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.3282537260149257 | validation: 0.27885887210207216]
	TIME [epoch: 5.74 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2744443445357162		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.2744443445357162 | validation: 0.2891556816313498]
	TIME [epoch: 5.74 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24380549563547316		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.24380549563547316 | validation: 0.19601017164378526]
	TIME [epoch: 5.74 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2306034650012757		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.2306034650012757 | validation: 0.24567898972789792]
	TIME [epoch: 5.78 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3129656002160708		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.3129656002160708 | validation: 0.2278058012143792]
	TIME [epoch: 5.75 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22359053333199636		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.22359053333199636 | validation: 0.20899600746238556]
	TIME [epoch: 5.74 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2901284875775856		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.2901284875775856 | validation: 0.24152710535042077]
	TIME [epoch: 5.74 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2513640126758465		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2513640126758465 | validation: 0.18172324719768987]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584233939013546		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.2584233939013546 | validation: 0.26362631627341204]
	TIME [epoch: 5.75 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897775846908237		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2897775846908237 | validation: 0.23551631044785395]
	TIME [epoch: 5.78 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512471624080083		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.2512471624080083 | validation: 0.19746150796158055]
	TIME [epoch: 5.75 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.290556440255283		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.290556440255283 | validation: 0.21639322013837542]
	TIME [epoch: 5.74 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24357351713912134		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.24357351713912134 | validation: 0.24494914724445735]
	TIME [epoch: 5.74 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2599744881690426		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.2599744881690426 | validation: 0.2221022647126158]
	TIME [epoch: 5.75 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26247912985603916		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.26247912985603916 | validation: 0.2555155912935384]
	TIME [epoch: 5.75 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2867096950455851		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.2867096950455851 | validation: 0.3214571974693376]
	TIME [epoch: 5.79 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3147614538654165		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.3147614538654165 | validation: 0.3364792030535115]
	TIME [epoch: 5.75 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3202381861099651		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.3202381861099651 | validation: 0.2506206432048356]
	TIME [epoch: 5.75 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2620069484107914		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.2620069484107914 | validation: 0.17645732243665244]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_611.pth
	Model improved!!!
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26514258968417537		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.26514258968417537 | validation: 0.25062567176971173]
	TIME [epoch: 5.73 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23598060060616716		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.23598060060616716 | validation: 0.21119093036651515]
	TIME [epoch: 5.73 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22292500788149663		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.22292500788149663 | validation: 0.22080851223531475]
	TIME [epoch: 5.77 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24784333237562078		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.24784333237562078 | validation: 0.24034610836269032]
	TIME [epoch: 5.73 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29583265924680424		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.29583265924680424 | validation: 0.31930300464090483]
	TIME [epoch: 5.74 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29320824316837146		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.29320824316837146 | validation: 0.3009903232000805]
	TIME [epoch: 5.74 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651194190645483		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.2651194190645483 | validation: 0.20828844578072442]
	TIME [epoch: 5.74 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33958545838677745		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.33958545838677745 | validation: 0.1607699110168587]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_619.pth
	Model improved!!!
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23030044114656342		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.23030044114656342 | validation: 0.14405475495166328]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_620.pth
	Model improved!!!
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20762356011656546		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.20762356011656546 | validation: 0.2055244007667187]
	TIME [epoch: 5.74 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21774364115382525		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.21774364115382525 | validation: 0.25487986692444636]
	TIME [epoch: 5.73 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2525675644816111		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.2525675644816111 | validation: 0.18865516951673056]
	TIME [epoch: 6.01 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20804022883729958		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.20804022883729958 | validation: 0.24677481936888623]
	TIME [epoch: 5.73 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878721535375534		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.2878721535375534 | validation: 0.21569556689307645]
	TIME [epoch: 5.74 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23095223045323557		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.23095223045323557 | validation: 0.16635233041594144]
	TIME [epoch: 5.77 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22549402001384802		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.22549402001384802 | validation: 0.38903692395920986]
	TIME [epoch: 5.74 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34195740086272003		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.34195740086272003 | validation: 0.2266292368574262]
	TIME [epoch: 5.74 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21653704336618318		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.21653704336618318 | validation: 0.21662952634999919]
	TIME [epoch: 5.74 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21419147052577098		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.21419147052577098 | validation: 0.28841016866004066]
	TIME [epoch: 5.74 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822521257994365		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.2822521257994365 | validation: 0.21182402084039006]
	TIME [epoch: 5.75 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21975472190614917		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.21975472190614917 | validation: 0.15831834637165196]
	TIME [epoch: 5.76 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3446314528046348		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.3446314528046348 | validation: 0.23442104439386546]
	TIME [epoch: 5.74 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.311086410517658		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.311086410517658 | validation: 0.31591531926088323]
	TIME [epoch: 5.74 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27525346469253803		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.27525346469253803 | validation: 0.24863434250719374]
	TIME [epoch: 5.73 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22578667967293928		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.22578667967293928 | validation: 0.2593439717331926]
	TIME [epoch: 5.73 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26429151502597237		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.26429151502597237 | validation: 0.1630259792190684]
	TIME [epoch: 5.75 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19787409397592906		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.19787409397592906 | validation: 0.17713814834533437]
	TIME [epoch: 5.76 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24277174743691898		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.24277174743691898 | validation: 0.3136152243655716]
	TIME [epoch: 5.74 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26969721815574654		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.26969721815574654 | validation: 0.1811108385292384]
	TIME [epoch: 5.74 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2551350267142407		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.2551350267142407 | validation: 0.22795840818522753]
	TIME [epoch: 5.73 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2799264134432944		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.2799264134432944 | validation: 0.21015164160707947]
	TIME [epoch: 5.74 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2467444034330183		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.2467444034330183 | validation: 0.2287588450401726]
	TIME [epoch: 5.75 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24401260786231121		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.24401260786231121 | validation: 0.17882790756866246]
	TIME [epoch: 5.77 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22938219598876824		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.22938219598876824 | validation: 0.2833543301705533]
	TIME [epoch: 5.74 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24619380482500075		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.24619380482500075 | validation: 0.1915950618727478]
	TIME [epoch: 5.74 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24272130006400003		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.24272130006400003 | validation: 0.22751172365172811]
	TIME [epoch: 5.74 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21447872619131164		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.21447872619131164 | validation: 0.1949080513441415]
	TIME [epoch: 5.74 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933765087815633		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.2933765087815633 | validation: 0.20330488205796443]
	TIME [epoch: 5.75 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24690508619917023		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.24690508619917023 | validation: 0.2989042175653277]
	TIME [epoch: 5.77 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28829912048781975		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.28829912048781975 | validation: 0.2472625561155986]
	TIME [epoch: 5.74 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2257399192497333		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.2257399192497333 | validation: 0.18741705900495728]
	TIME [epoch: 5.74 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2573443437400846		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.2573443437400846 | validation: 0.20779999929699913]
	TIME [epoch: 5.74 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2654104121721779		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.2654104121721779 | validation: 0.26602767587688697]
	TIME [epoch: 5.74 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26791808782433646		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.26791808782433646 | validation: 0.239276129888834]
	TIME [epoch: 5.75 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592365699188661		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.2592365699188661 | validation: 0.17852877050336902]
	TIME [epoch: 5.77 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2119835466171676		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.2119835466171676 | validation: 0.25982022101642327]
	TIME [epoch: 5.74 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20915714703927374		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.20915714703927374 | validation: 0.19641061077642247]
	TIME [epoch: 5.74 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24405455417829736		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.24405455417829736 | validation: 0.20785656615413678]
	TIME [epoch: 5.74 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21069801363110052		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.21069801363110052 | validation: 0.20032526374914925]
	TIME [epoch: 5.74 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.290685207946384		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.290685207946384 | validation: 0.24676107125618987]
	TIME [epoch: 5.75 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28940237405767694		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.28940237405767694 | validation: 0.20219881407379003]
	TIME [epoch: 5.77 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24741747163061242		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.24741747163061242 | validation: 0.1868780292359235]
	TIME [epoch: 5.74 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21977346988799934		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.21977346988799934 | validation: 0.25159467697252846]
	TIME [epoch: 5.74 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26358084374173435		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.26358084374173435 | validation: 0.18104802464105638]
	TIME [epoch: 5.74 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2108471342510268		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.2108471342510268 | validation: 0.19008067788842312]
	TIME [epoch: 5.74 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23860542338547308		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.23860542338547308 | validation: 0.19068341860340587]
	TIME [epoch: 5.75 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22196169340247607		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.22196169340247607 | validation: 0.343703863328986]
	TIME [epoch: 5.77 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26158333799669425		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.26158333799669425 | validation: 0.1668197515068735]
	TIME [epoch: 5.74 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20971957990249476		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.20971957990249476 | validation: 0.1615604101493222]
	TIME [epoch: 5.74 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20834402892400844		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.20834402892400844 | validation: 0.21326237319822944]
	TIME [epoch: 5.74 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23228511326342635		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.23228511326342635 | validation: 0.23214219428084876]
	TIME [epoch: 5.74 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24680655507005128		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.24680655507005128 | validation: 0.21070353085701266]
	TIME [epoch: 5.75 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23304088236329162		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.23304088236329162 | validation: 0.1941594440478536]
	TIME [epoch: 5.77 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2682320886391288		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.2682320886391288 | validation: 0.21242806713956083]
	TIME [epoch: 5.74 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25585215381632304		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.25585215381632304 | validation: 0.15044115388972756]
	TIME [epoch: 5.74 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22652935368395266		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.22652935368395266 | validation: 0.2544701335869339]
	TIME [epoch: 5.74 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2490466814931791		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.2490466814931791 | validation: 0.34019443675516237]
	TIME [epoch: 5.74 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2580790747767486		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.2580790747767486 | validation: 0.17178094452764026]
	TIME [epoch: 5.75 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19433357300920268		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.19433357300920268 | validation: 0.23230248101042164]
	TIME [epoch: 5.77 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20623254407402566		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.20623254407402566 | validation: 0.14768519404573144]
	TIME [epoch: 5.74 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2092551641564517		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.2092551641564517 | validation: 0.19040242812861985]
	TIME [epoch: 5.74 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28626333165022033		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.28626333165022033 | validation: 0.2378362652301602]
	TIME [epoch: 5.74 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28594982348083703		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.28594982348083703 | validation: 0.19297293717016126]
	TIME [epoch: 5.74 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22047570400427657		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.22047570400427657 | validation: 0.18583095300041116]
	TIME [epoch: 5.75 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2504998041528441		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.2504998041528441 | validation: 0.13707414892274075]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_686.pth
	Model improved!!!
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088976551293493		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.2088976551293493 | validation: 0.3118769679245466]
	TIME [epoch: 5.74 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2487733896146619		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.2487733896146619 | validation: 0.133779234692525]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18157740590084656		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.18157740590084656 | validation: 0.16170856678874287]
	TIME [epoch: 5.75 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19256039972588013		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.19256039972588013 | validation: 0.1916871417375706]
	TIME [epoch: 5.75 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22687347032433564		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.22687347032433564 | validation: 0.19873748459806626]
	TIME [epoch: 5.78 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2048058697694712		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.2048058697694712 | validation: 0.1901116125552766]
	TIME [epoch: 5.76 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28419979443142707		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.28419979443142707 | validation: 0.1936523750748204]
	TIME [epoch: 5.75 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19139907855878296		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.19139907855878296 | validation: 0.16559164133419949]
	TIME [epoch: 5.75 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21052672600527272		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.21052672600527272 | validation: 0.21354762473824573]
	TIME [epoch: 5.75 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20161288000029964		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.20161288000029964 | validation: 0.1795961974737355]
	TIME [epoch: 5.75 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2054561379305604		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.2054561379305604 | validation: 0.16537642083678278]
	TIME [epoch: 5.78 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19575717199691878		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.19575717199691878 | validation: 0.20318797376584144]
	TIME [epoch: 5.76 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24119183547156253		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.24119183547156253 | validation: 0.29797815515315973]
	TIME [epoch: 5.75 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24527311932358498		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.24527311932358498 | validation: 0.220112550473662]
	TIME [epoch: 5.75 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2513809761534971		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.2513809761534971 | validation: 0.2862946174172997]
	TIME [epoch: 5.75 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25083103546315394		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.25083103546315394 | validation: 0.23299771162873895]
	TIME [epoch: 5.75 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3334616954993416		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.3334616954993416 | validation: 0.3749085126713738]
	TIME [epoch: 5.77 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586104407161355		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.2586104407161355 | validation: 0.2649060086109591]
	TIME [epoch: 5.76 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20470355644208446		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.20470355644208446 | validation: 0.20169345225223687]
	TIME [epoch: 5.74 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19053753450874572		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.19053753450874572 | validation: 0.14795428093181154]
	TIME [epoch: 5.74 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20543855114497794		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.20543855114497794 | validation: 0.22282710854365084]
	TIME [epoch: 5.74 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544185061130204		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.2544185061130204 | validation: 0.1577853126510655]
	TIME [epoch: 5.74 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854015792729983		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.1854015792729983 | validation: 0.1946914513027059]
	TIME [epoch: 5.78 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20129280568647243		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.20129280568647243 | validation: 0.267315667233081]
	TIME [epoch: 5.76 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2489667429921309		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.2489667429921309 | validation: 0.22307705219932927]
	TIME [epoch: 5.75 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19174027883583145		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.19174027883583145 | validation: 0.20236126420903042]
	TIME [epoch: 5.75 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22131268923063444		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.22131268923063444 | validation: 0.21230298681523838]
	TIME [epoch: 5.74 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2036077235751099		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.2036077235751099 | validation: 0.19807688537989315]
	TIME [epoch: 5.74 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21420968186210507		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.21420968186210507 | validation: 0.21624035154931498]
	TIME [epoch: 5.78 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23068815191233463		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.23068815191233463 | validation: 0.23606583378406154]
	TIME [epoch: 5.76 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19462827462245835		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.19462827462245835 | validation: 0.17578347407182804]
	TIME [epoch: 5.75 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17453937167797678		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.17453937167797678 | validation: 0.1918226769217467]
	TIME [epoch: 5.74 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1989647851721221		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.1989647851721221 | validation: 0.276205558851974]
	TIME [epoch: 5.75 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2431240900708404		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.2431240900708404 | validation: 0.1557267323655438]
	TIME [epoch: 5.76 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20064577354866128		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.20064577354866128 | validation: 0.16580974111762664]
	TIME [epoch: 5.81 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2530874124552774		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.2530874124552774 | validation: 0.21150887869550025]
	TIME [epoch: 5.79 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22096867146911592		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.22096867146911592 | validation: 0.17538907319374833]
	TIME [epoch: 5.77 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.228604828899188		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.228604828899188 | validation: 0.1669702679809323]
	TIME [epoch: 5.76 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19893982830604062		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.19893982830604062 | validation: 0.1627425756940726]
	TIME [epoch: 5.75 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848271120428748		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.2848271120428748 | validation: 0.15189283494853323]
	TIME [epoch: 5.76 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19288085780781306		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.19288085780781306 | validation: 0.13873906897939398]
	TIME [epoch: 5.79 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17928556481992458		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.17928556481992458 | validation: 0.14854807863957373]
	TIME [epoch: 5.75 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20827610674969688		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.20827610674969688 | validation: 0.19250835304654668]
	TIME [epoch: 5.75 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2326487028407647		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.2326487028407647 | validation: 0.19410672896477937]
	TIME [epoch: 5.76 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2228045527851518		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.2228045527851518 | validation: 0.18440061482088788]
	TIME [epoch: 5.76 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19283912029420566		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.19283912029420566 | validation: 0.1456413889380119]
	TIME [epoch: 5.76 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2086301587767675		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.2086301587767675 | validation: 0.19831134606355896]
	TIME [epoch: 5.79 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18665248216233593		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.18665248216233593 | validation: 0.1564260830736298]
	TIME [epoch: 5.77 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22400192942505032		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.22400192942505032 | validation: 0.2640367181261474]
	TIME [epoch: 5.77 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2608609162069129		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.2608609162069129 | validation: 0.17468853342671545]
	TIME [epoch: 5.76 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17936913492056478		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.17936913492056478 | validation: 0.18738294428381516]
	TIME [epoch: 5.76 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20931584413591173		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.20931584413591173 | validation: 0.1971985210769664]
	TIME [epoch: 5.76 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19016767828686712		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.19016767828686712 | validation: 0.18947571210839229]
	TIME [epoch: 5.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909945404751864		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.1909945404751864 | validation: 0.20664113906149775]
	TIME [epoch: 5.76 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22443147580874828		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.22443147580874828 | validation: 0.16674915976045918]
	TIME [epoch: 5.75 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21053999229586795		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.21053999229586795 | validation: 0.37454711452421297]
	TIME [epoch: 5.75 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2736178665290565		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.2736178665290565 | validation: 0.23755340913957212]
	TIME [epoch: 5.75 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19592504866309657		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.19592504866309657 | validation: 0.17655923773272122]
	TIME [epoch: 5.75 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19077882090501203		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.19077882090501203 | validation: 0.19756514349090742]
	TIME [epoch: 5.79 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20620397239596358		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.20620397239596358 | validation: 0.23738487974528633]
	TIME [epoch: 5.76 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22251405719759854		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.22251405719759854 | validation: 0.2971470649302217]
	TIME [epoch: 5.75 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23892099289124957		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.23892099289124957 | validation: 0.19296613071626761]
	TIME [epoch: 5.76 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2191689244003282		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.2191689244003282 | validation: 0.23867909464194342]
	TIME [epoch: 5.75 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21475767570462728		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.21475767570462728 | validation: 0.1345632850745789]
	TIME [epoch: 5.75 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21268422261513592		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.21268422261513592 | validation: 0.130949994562014]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_751.pth
	Model improved!!!
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16430609691824177		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.16430609691824177 | validation: 0.20066190500256775]
	TIME [epoch: 5.76 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17655944953364744		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.17655944953364744 | validation: 0.1611410703541889]
	TIME [epoch: 5.75 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18540174138617774		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.18540174138617774 | validation: 0.15422913897244794]
	TIME [epoch: 5.75 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2132010140696708		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.2132010140696708 | validation: 0.12871769127730912]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_755.pth
	Model improved!!!
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1645673399132292		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.1645673399132292 | validation: 0.15591260882338726]
	TIME [epoch: 5.75 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19674235348243024		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.19674235348243024 | validation: 0.1607067794857196]
	TIME [epoch: 5.78 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20015470211160977		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.20015470211160977 | validation: 0.1944639765136931]
	TIME [epoch: 5.76 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18061179137499453		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.18061179137499453 | validation: 0.17102621228811796]
	TIME [epoch: 5.75 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24317784766620698		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.24317784766620698 | validation: 0.17753327832402263]
	TIME [epoch: 5.75 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1986684149348985		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.1986684149348985 | validation: 0.18615105854035854]
	TIME [epoch: 5.75 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24562239777583658		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.24562239777583658 | validation: 0.14603580058722315]
	TIME [epoch: 5.75 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15948376983287624		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.15948376983287624 | validation: 0.14737321857206861]
	TIME [epoch: 5.79 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20609626074549425		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.20609626074549425 | validation: 0.21013791364554152]
	TIME [epoch: 5.75 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20583191317468985		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.20583191317468985 | validation: 0.3368044381231872]
	TIME [epoch: 5.75 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2367473250623281		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.2367473250623281 | validation: 0.17625948963756763]
	TIME [epoch: 5.75 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19023854971133622		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.19023854971133622 | validation: 0.20451123555079542]
	TIME [epoch: 5.75 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1857031938662378		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.1857031938662378 | validation: 0.21835831835972022]
	TIME [epoch: 5.75 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19744564883330556		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.19744564883330556 | validation: 0.20757739208057208]
	TIME [epoch: 5.78 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16463042193893568		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.16463042193893568 | validation: 0.12169269069060307]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_770.pth
	Model improved!!!
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17859785330097064		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.17859785330097064 | validation: 0.2009156573939653]
	TIME [epoch: 5.74 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1845832577795132		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.1845832577795132 | validation: 0.16759846896288516]
	TIME [epoch: 5.73 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17372183624449286		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.17372183624449286 | validation: 0.15635400408585032]
	TIME [epoch: 5.75 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22942324614206683		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.22942324614206683 | validation: 0.16290730577811446]
	TIME [epoch: 5.76 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19913702553415585		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.19913702553415585 | validation: 0.17710926635418592]
	TIME [epoch: 5.79 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17143580326235242		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.17143580326235242 | validation: 0.22046520765876326]
	TIME [epoch: 5.76 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18432678616574016		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.18432678616574016 | validation: 0.21488760159363182]
	TIME [epoch: 5.73 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20089801859904127		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.20089801859904127 | validation: 0.13413646377614927]
	TIME [epoch: 5.74 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17328593722208738		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.17328593722208738 | validation: 0.21369297839066634]
	TIME [epoch: 5.74 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23176343492061374		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.23176343492061374 | validation: 0.14095998525904355]
	TIME [epoch: 5.74 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16561938865789683		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.16561938865789683 | validation: 0.16865055083647618]
	TIME [epoch: 5.79 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18369403870742776		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.18369403870742776 | validation: 0.2327990489710755]
	TIME [epoch: 5.75 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1883427901635846		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.1883427901635846 | validation: 0.21783325316235286]
	TIME [epoch: 5.74 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2119783732338209		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.2119783732338209 | validation: 0.1756548960531343]
	TIME [epoch: 5.75 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16527560725096047		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.16527560725096047 | validation: 0.13527648357279254]
	TIME [epoch: 5.73 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1584766234647845		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.1584766234647845 | validation: 0.15047184800609528]
	TIME [epoch: 5.73 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16779215807899298		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.16779215807899298 | validation: 0.15987394334725527]
	TIME [epoch: 5.79 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19085810198879788		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.19085810198879788 | validation: 0.17005446610492944]
	TIME [epoch: 5.76 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1628426516654907		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.1628426516654907 | validation: 0.20600471341228604]
	TIME [epoch: 5.75 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2066017075209923		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.2066017075209923 | validation: 0.17942706799657807]
	TIME [epoch: 5.75 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1661923258328518		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.1661923258328518 | validation: 0.17818349615189838]
	TIME [epoch: 5.75 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17743844770086328		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.17743844770086328 | validation: 0.13066839615922543]
	TIME [epoch: 5.75 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.174496025059076		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.174496025059076 | validation: 0.16503666420471105]
	TIME [epoch: 5.78 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1803011401131913		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.1803011401131913 | validation: 0.14168124787782535]
	TIME [epoch: 5.75 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15506345528377635		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.15506345528377635 | validation: 0.17207890715809407]
	TIME [epoch: 5.75 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1741662783395357		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.1741662783395357 | validation: 0.1696639112379419]
	TIME [epoch: 5.75 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16614582998232758		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.16614582998232758 | validation: 0.1758488832999718]
	TIME [epoch: 5.75 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15769412781349063		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.15769412781349063 | validation: 0.13211316212888263]
	TIME [epoch: 5.76 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18853842130188847		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.18853842130188847 | validation: 0.16452888100230348]
	TIME [epoch: 5.76 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1798872139255078		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.1798872139255078 | validation: 0.13536482865192376]
	TIME [epoch: 5.73 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16149489428299887		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.16149489428299887 | validation: 0.19557797725069698]
	TIME [epoch: 5.73 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17894961765116818		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.17894961765116818 | validation: 0.22663142981337475]
	TIME [epoch: 5.73 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19804964795651447		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.19804964795651447 | validation: 0.21319044089133357]
	TIME [epoch: 5.73 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16722231223090323		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.16722231223090323 | validation: 0.1324178645580601]
	TIME [epoch: 5.74 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18815646897116378		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.18815646897116378 | validation: 0.13089568710873548]
	TIME [epoch: 5.76 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17776702401577332		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.17776702401577332 | validation: 0.2179320582323566]
	TIME [epoch: 5.74 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106838355306307		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.2106838355306307 | validation: 0.23721295883577476]
	TIME [epoch: 5.74 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17768968519733241		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.17768968519733241 | validation: 0.20458645515918814]
	TIME [epoch: 5.74 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079640172062113		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.2079640172062113 | validation: 0.1214949967394905]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_809.pth
	Model improved!!!
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14620703624092654		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.14620703624092654 | validation: 0.13210191821002049]
	TIME [epoch: 5.75 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14867015520331436		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.14867015520331436 | validation: 0.20643915993138712]
	TIME [epoch: 5.77 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2154057041174786		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.2154057041174786 | validation: 0.15859385963977904]
	TIME [epoch: 5.75 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15804036416735734		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.15804036416735734 | validation: 0.16595922712546768]
	TIME [epoch: 5.74 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16907717208978434		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.16907717208978434 | validation: 0.14811245495273315]
	TIME [epoch: 5.74 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19247707977542353		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.19247707977542353 | validation: 0.14592754244573797]
	TIME [epoch: 5.73 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18093820953827428		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.18093820953827428 | validation: 0.24359260513268624]
	TIME [epoch: 5.75 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1914622433084454		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.1914622433084454 | validation: 0.182957303144735]
	TIME [epoch: 5.77 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162676644213855		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.162676644213855 | validation: 0.2158858129444607]
	TIME [epoch: 5.74 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19306360498848285		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.19306360498848285 | validation: 0.19621677111166755]
	TIME [epoch: 5.74 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19685860222167545		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.19685860222167545 | validation: 0.15690247253971715]
	TIME [epoch: 5.75 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20171361881352082		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.20171361881352082 | validation: 0.2823921584526683]
	TIME [epoch: 5.74 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1852575564439264		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.1852575564439264 | validation: 0.1342757494573755]
	TIME [epoch: 5.74 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18187725168121924		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.18187725168121924 | validation: 0.21256043743405592]
	TIME [epoch: 5.77 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17403806479662243		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.17403806479662243 | validation: 0.1708312586503022]
	TIME [epoch: 5.74 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18262601605981327		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.18262601605981327 | validation: 0.21397294500826278]
	TIME [epoch: 5.73 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18512674936799006		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.18512674936799006 | validation: 0.13059097598360797]
	TIME [epoch: 5.74 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16262022563287185		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.16262022563287185 | validation: 0.15974712696832213]
	TIME [epoch: 5.74 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19290297492584624		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.19290297492584624 | validation: 0.1721804826436933]
	TIME [epoch: 5.75 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1584316284900924		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.1584316284900924 | validation: 0.1501512568658394]
	TIME [epoch: 5.78 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15471283279118614		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.15471283279118614 | validation: 0.15870144478239873]
	TIME [epoch: 5.74 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.154134146972709		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.154134146972709 | validation: 0.187709675469866]
	TIME [epoch: 5.74 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15437890486676795		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.15437890486676795 | validation: 0.13457719931337045]
	TIME [epoch: 5.74 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17561990542598552		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.17561990542598552 | validation: 0.16839025103771732]
	TIME [epoch: 5.74 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1698361552256235		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.1698361552256235 | validation: 0.18878286378984035]
	TIME [epoch: 5.75 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21516086521323777		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.21516086521323777 | validation: 0.21517459451327345]
	TIME [epoch: 5.78 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17708623572726812		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.17708623572726812 | validation: 0.18380843335483169]
	TIME [epoch: 5.74 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17793188431206763		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.17793188431206763 | validation: 0.14336404996734273]
	TIME [epoch: 5.74 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17714302150630606		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.17714302150630606 | validation: 0.16960541603295048]
	TIME [epoch: 5.74 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17296407600851715		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.17296407600851715 | validation: 0.14533380648669758]
	TIME [epoch: 5.75 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15803769385588332		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.15803769385588332 | validation: 0.13216237612193366]
	TIME [epoch: 5.75 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14354300675695983		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.14354300675695983 | validation: 0.1399882242419306]
	TIME [epoch: 5.77 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16309124119225824		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.16309124119225824 | validation: 0.15583656910204924]
	TIME [epoch: 5.74 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14819809276337717		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.14819809276337717 | validation: 0.2037485410631832]
	TIME [epoch: 5.75 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1724452512061866		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.1724452512061866 | validation: 0.17570777235511365]
	TIME [epoch: 5.75 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1825502398386678		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.1825502398386678 | validation: 0.14425613070620702]
	TIME [epoch: 5.75 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15393648067722462		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.15393648067722462 | validation: 0.14880869710141523]
	TIME [epoch: 5.76 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16604127386845174		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.16604127386845174 | validation: 0.15566675022227572]
	TIME [epoch: 5.78 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15310161776228676		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.15310161776228676 | validation: 0.19805094412758054]
	TIME [epoch: 5.75 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18019654190443335		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.18019654190443335 | validation: 0.20696279715696747]
	TIME [epoch: 5.75 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16426944560426363		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.16426944560426363 | validation: 0.17245038472012986]
	TIME [epoch: 5.75 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1599115141215547		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.1599115141215547 | validation: 0.13805308270961897]
	TIME [epoch: 5.75 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1501025900857995		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.1501025900857995 | validation: 0.13237942929926]
	TIME [epoch: 5.77 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15909582484848842		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.15909582484848842 | validation: 0.13240746851314453]
	TIME [epoch: 5.78 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16887855554080014		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.16887855554080014 | validation: 0.1358681235408676]
	TIME [epoch: 5.74 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15833990354165134		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.15833990354165134 | validation: 0.11408773414842831]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_855.pth
	Model improved!!!
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15931773827294451		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.15931773827294451 | validation: 0.15608532388689222]
	TIME [epoch: 5.75 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1579631340548663		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.1579631340548663 | validation: 0.1316979130479814]
	TIME [epoch: 5.75 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16521121327733546		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.16521121327733546 | validation: 0.1520443531063986]
	TIME [epoch: 5.78 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.170468822918607		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.170468822918607 | validation: 0.15488526761934238]
	TIME [epoch: 5.75 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15637284628624654		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.15637284628624654 | validation: 0.15114182629619077]
	TIME [epoch: 5.74 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16056674440072657		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.16056674440072657 | validation: 0.1381237200218375]
	TIME [epoch: 5.73 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15192215982997556		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.15192215982997556 | validation: 0.14753630672150622]
	TIME [epoch: 5.75 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16546218504492147		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.16546218504492147 | validation: 0.14893794856159312]
	TIME [epoch: 5.74 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13800428616380297		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.13800428616380297 | validation: 0.15498569491361114]
	TIME [epoch: 5.78 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14323678883399965		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.14323678883399965 | validation: 0.1322633101403134]
	TIME [epoch: 5.76 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14937344623028992		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.14937344623028992 | validation: 0.1848132039581386]
	TIME [epoch: 5.75 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16094150879779284		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.16094150879779284 | validation: 0.11407361472788295]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_867.pth
	Model improved!!!
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14862264058169672		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.14862264058169672 | validation: 0.11893056842754753]
	TIME [epoch: 5.74 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15910162809538783		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.15910162809538783 | validation: 0.15100235693317401]
	TIME [epoch: 5.73 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391640779690241		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.1391640779690241 | validation: 0.1445977668298955]
	TIME [epoch: 5.77 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15823304990578432		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.15823304990578432 | validation: 0.1502079976503571]
	TIME [epoch: 5.75 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15577057732214594		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.15577057732214594 | validation: 0.13233766267290328]
	TIME [epoch: 5.74 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302209135356744		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.1302209135356744 | validation: 0.137608392661066]
	TIME [epoch: 5.73 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15504665778767182		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.15504665778767182 | validation: 0.1180702143782672]
	TIME [epoch: 5.74 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14593074149659757		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.14593074149659757 | validation: 0.19678712088532177]
	TIME [epoch: 5.73 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17197354038613452		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.17197354038613452 | validation: 0.13229957553783023]
	TIME [epoch: 5.77 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17161278992589588		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.17161278992589588 | validation: 0.16144565465620525]
	TIME [epoch: 5.74 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14704282004443772		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.14704282004443772 | validation: 0.14255085411440102]
	TIME [epoch: 5.74 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14946400631253237		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.14946400631253237 | validation: 0.15368763418128395]
	TIME [epoch: 5.75 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14701308187186252		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.14701308187186252 | validation: 0.15501860140950197]
	TIME [epoch: 5.74 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14467464100860505		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.14467464100860505 | validation: 0.13429423534975105]
	TIME [epoch: 5.73 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14340512967638427		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.14340512967638427 | validation: 0.1367508527816112]
	TIME [epoch: 5.78 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1469042162648263		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.1469042162648263 | validation: 0.1677190760823396]
	TIME [epoch: 5.75 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17391486740135076		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.17391486740135076 | validation: 0.16124693457074757]
	TIME [epoch: 5.74 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16471502972760932		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.16471502972760932 | validation: 0.14999316009189959]
	TIME [epoch: 5.74 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516394668744782		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.1516394668744782 | validation: 0.14953112462471838]
	TIME [epoch: 5.74 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15786703367052896		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.15786703367052896 | validation: 0.18773722532909642]
	TIME [epoch: 5.74 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1565946036476637		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.1565946036476637 | validation: 0.15341114171080952]
	TIME [epoch: 5.78 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14055143975475337		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.14055143975475337 | validation: 0.11346768767316402]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_889.pth
	Model improved!!!
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12875744238893444		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.12875744238893444 | validation: 0.1368239427298594]
	TIME [epoch: 5.73 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468495926922589		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.1468495926922589 | validation: 0.1319495025668544]
	TIME [epoch: 5.73 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477254929855026		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.1477254929855026 | validation: 0.1712333966818869]
	TIME [epoch: 5.75 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1671450627667708		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.1671450627667708 | validation: 0.1628671682673864]
	TIME [epoch: 5.74 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1472276396986589		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.1472276396986589 | validation: 0.1458623382965556]
	TIME [epoch: 5.77 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13272653978013346		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.13272653978013346 | validation: 0.1265416824104665]
	TIME [epoch: 5.74 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13181183897545537		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.13181183897545537 | validation: 0.1412755743249401]
	TIME [epoch: 5.73 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14733508376168847		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.14733508376168847 | validation: 0.13094380900162889]
	TIME [epoch: 5.75 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14652990600115695		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.14652990600115695 | validation: 0.15067512272028719]
	TIME [epoch: 5.74 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1491162749015355		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.1491162749015355 | validation: 0.11971223242028478]
	TIME [epoch: 5.73 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1358162655150475		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.1358162655150475 | validation: 0.12974037520895096]
	TIME [epoch: 5.78 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354079963488417		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.1354079963488417 | validation: 0.15024942844398745]
	TIME [epoch: 5.75 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15494682933471904		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.15494682933471904 | validation: 0.1520384294282859]
	TIME [epoch: 5.74 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17288354901366354		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.17288354901366354 | validation: 0.2216293146118239]
	TIME [epoch: 5.74 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23351274963639995		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.23351274963639995 | validation: 0.19429201521821518]
	TIME [epoch: 5.74 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16569746226563234		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.16569746226563234 | validation: 0.1594419984789163]
	TIME [epoch: 5.74 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15236930617071723		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.15236930617071723 | validation: 0.1708726378686465]
	TIME [epoch: 5.78 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1602215326552531		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.1602215326552531 | validation: 0.15797906285796603]
	TIME [epoch: 5.76 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14952229532934996		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.14952229532934996 | validation: 0.16016576215723288]
	TIME [epoch: 5.73 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15699916156538124		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.15699916156538124 | validation: 0.12835525163295167]
	TIME [epoch: 5.73 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13118803510368984		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.13118803510368984 | validation: 0.11903858455300252]
	TIME [epoch: 5.74 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321715028639287		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.1321715028639287 | validation: 0.12264509870288505]
	TIME [epoch: 5.74 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12977312902889232		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.12977312902889232 | validation: 0.13095691083932443]
	TIME [epoch: 5.77 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14056437124372156		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.14056437124372156 | validation: 0.11956966256172034]
	TIME [epoch: 5.75 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.171546731794539		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.171546731794539 | validation: 0.16848014738308373]
	TIME [epoch: 5.74 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14399016792944952		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.14399016792944952 | validation: 0.11383014777676623]
	TIME [epoch: 5.73 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341358912192567		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.1341358912192567 | validation: 0.14523039627990392]
	TIME [epoch: 5.74 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371956231194848		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.1371956231194848 | validation: 0.13291507309312325]
	TIME [epoch: 5.73 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14247089302407218		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.14247089302407218 | validation: 0.1497210699970131]
	TIME [epoch: 5.78 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20933428444377697		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.20933428444377697 | validation: 0.17791587939898537]
	TIME [epoch: 5.75 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590895354714363		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.2590895354714363 | validation: 0.13564798912329942]
	TIME [epoch: 5.74 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13579430258546205		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.13579430258546205 | validation: 0.19123902490044462]
	TIME [epoch: 5.74 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17133848924393005		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.17133848924393005 | validation: 0.1594746690692708]
	TIME [epoch: 5.73 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558980814858582		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.1558980814858582 | validation: 0.12729617884974564]
	TIME [epoch: 5.74 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428052529345841		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.1428052529345841 | validation: 0.13950683051856375]
	TIME [epoch: 5.78 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13815083364687517		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.13815083364687517 | validation: 0.17747620422324087]
	TIME [epoch: 5.75 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15079269053234667		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.15079269053234667 | validation: 0.14164268179543538]
	TIME [epoch: 5.74 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13709556703965764		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.13709556703965764 | validation: 0.12122970289445675]
	TIME [epoch: 5.74 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14558458528931428		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.14558458528931428 | validation: 0.11666235382741044]
	TIME [epoch: 5.74 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14402026663345716		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.14402026663345716 | validation: 0.13081574311482488]
	TIME [epoch: 5.73 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13650699743055178		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.13650699743055178 | validation: 0.11763955864959195]
	TIME [epoch: 5.78 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543821661519815		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.1543821661519815 | validation: 0.14367000573471814]
	TIME [epoch: 5.75 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17079870004207928		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.17079870004207928 | validation: 0.12083706415197931]
	TIME [epoch: 5.73 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13724310368713727		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.13724310368713727 | validation: 0.15639740867251786]
	TIME [epoch: 5.73 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14060392206349698		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.14060392206349698 | validation: 0.10520559753445721]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_934.pth
	Model improved!!!
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14322906794889498		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.14322906794889498 | validation: 0.1386838113867584]
	TIME [epoch: 5.75 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12940883921599453		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.12940883921599453 | validation: 0.1280272001020936]
	TIME [epoch: 5.78 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262194825491073		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.1262194825491073 | validation: 0.15186729460884005]
	TIME [epoch: 5.75 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16837818011455624		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.16837818011455624 | validation: 0.21159586853952006]
	TIME [epoch: 5.76 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17466801084476544		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.17466801084476544 | validation: 0.19538325897405442]
	TIME [epoch: 5.76 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13844895445256003		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.13844895445256003 | validation: 0.1458252834304179]
	TIME [epoch: 5.76 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14881579891063937		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.14881579891063937 | validation: 0.12451000523593607]
	TIME [epoch: 5.76 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17038595139634471		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.17038595139634471 | validation: 0.12287115941604894]
	TIME [epoch: 5.79 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13566282198936314		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.13566282198936314 | validation: 0.15657559751676098]
	TIME [epoch: 5.76 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13443037010575576		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.13443037010575576 | validation: 0.123376671861087]
	TIME [epoch: 5.76 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14420602614087324		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.14420602614087324 | validation: 0.1294449775334769]
	TIME [epoch: 5.76 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13598756083406424		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.13598756083406424 | validation: 0.18449947354053847]
	TIME [epoch: 5.76 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15052505901542376		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.15052505901542376 | validation: 0.20326978129805412]
	TIME [epoch: 5.76 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518581043603888		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.1518581043603888 | validation: 0.19875704042967168]
	TIME [epoch: 5.79 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18278105170790396		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.18278105170790396 | validation: 0.16031992903254272]
	TIME [epoch: 5.76 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1499640866428268		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.1499640866428268 | validation: 0.17916190322023526]
	TIME [epoch: 5.76 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257175937580217		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.1257175937580217 | validation: 0.13966765245370522]
	TIME [epoch: 5.76 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300512597272703		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.1300512597272703 | validation: 0.1408149362937867]
	TIME [epoch: 5.76 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1528342388569325		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.1528342388569325 | validation: 0.18855424312742508]
	TIME [epoch: 5.76 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16086084817889945		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.16086084817889945 | validation: 0.15897013081132963]
	TIME [epoch: 5.79 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17507936465983429		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.17507936465983429 | validation: 0.21238060847741572]
	TIME [epoch: 5.76 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16038963157256825		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.16038963157256825 | validation: 0.1558308579242599]
	TIME [epoch: 5.75 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400705928023692		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.1400705928023692 | validation: 0.16182854733597718]
	TIME [epoch: 5.75 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461222860718851		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.1461222860718851 | validation: 0.1477298908711652]
	TIME [epoch: 5.76 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15496542129703		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.15496542129703 | validation: 0.15965878438616687]
	TIME [epoch: 5.77 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14981761604466937		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.14981761604466937 | validation: 0.15295827022229727]
	TIME [epoch: 5.78 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460980340884122		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.1460980340884122 | validation: 0.11872887395780676]
	TIME [epoch: 5.76 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379069740143032		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.1379069740143032 | validation: 0.14233613988513807]
	TIME [epoch: 5.76 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14349580871327244		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.14349580871327244 | validation: 0.15575008653245245]
	TIME [epoch: 5.76 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13463656092069345		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.13463656092069345 | validation: 0.13890122415046705]
	TIME [epoch: 5.75 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13102380632499763		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.13102380632499763 | validation: 0.17053003964255622]
	TIME [epoch: 5.77 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1666404197600581		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.1666404197600581 | validation: 0.14689744338666008]
	TIME [epoch: 5.78 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1359327099341481		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.1359327099341481 | validation: 0.16206307501819958]
	TIME [epoch: 5.76 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14911021911151326		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.14911021911151326 | validation: 0.1305633144864489]
	TIME [epoch: 5.76 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13358201235584444		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.13358201235584444 | validation: 0.12041055419457554]
	TIME [epoch: 5.75 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14037040627487923		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.14037040627487923 | validation: 0.12866524255560782]
	TIME [epoch: 5.76 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13295116281089445		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.13295116281089445 | validation: 0.12020192079112513]
	TIME [epoch: 5.77 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14314844714416639		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.14314844714416639 | validation: 0.14924575187938846]
	TIME [epoch: 5.78 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13027735167581325		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.13027735167581325 | validation: 0.14150804544433318]
	TIME [epoch: 5.76 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14634125058513392		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.14634125058513392 | validation: 0.15941741850180796]
	TIME [epoch: 5.76 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15569333219418158		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.15569333219418158 | validation: 0.12668158355475354]
	TIME [epoch: 5.76 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12293257024548271		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.12293257024548271 | validation: 0.16133927628484215]
	TIME [epoch: 5.76 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15657470625260458		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.15657470625260458 | validation: 0.1387329130953056]
	TIME [epoch: 5.77 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207171127809607		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.1207171127809607 | validation: 0.1450455773407215]
	TIME [epoch: 5.78 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360625829915019		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.1360625829915019 | validation: 0.13367050703440994]
	TIME [epoch: 5.76 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13185033850490746		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.13185033850490746 | validation: 0.12942839945066326]
	TIME [epoch: 5.75 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13910269101475936		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.13910269101475936 | validation: 0.1271711251546001]
	TIME [epoch: 5.76 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13361563455880032		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.13361563455880032 | validation: 0.13185496222200224]
	TIME [epoch: 5.76 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13427535027897367		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.13427535027897367 | validation: 0.17409212243753885]
	TIME [epoch: 5.77 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13146665565581286		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.13146665565581286 | validation: 0.13256229421070878]
	TIME [epoch: 5.78 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15848373913139713		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.15848373913139713 | validation: 0.1615825664607828]
	TIME [epoch: 5.76 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13512950649920574		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.13512950649920574 | validation: 0.13496314909067558]
	TIME [epoch: 5.76 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12355757028416553		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.12355757028416553 | validation: 0.14716223157928088]
	TIME [epoch: 5.75 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12029941479609657		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.12029941479609657 | validation: 0.11849357979732855]
	TIME [epoch: 5.76 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13649954351115706		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.13649954351115706 | validation: 0.1954123434097346]
	TIME [epoch: 5.77 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14230568133156443		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.14230568133156443 | validation: 0.1456537486640769]
	TIME [epoch: 5.78 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12087988980873413		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.12087988980873413 | validation: 0.12497206205897733]
	TIME [epoch: 5.76 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13358994372132266		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.13358994372132266 | validation: 0.16878205701170224]
	TIME [epoch: 5.75 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12419738200909204		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.12419738200909204 | validation: 0.12860017477607652]
	TIME [epoch: 5.75 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12571570673957272		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.12571570673957272 | validation: 0.16401634720051167]
	TIME [epoch: 5.75 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321841615693372		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.1321841615693372 | validation: 0.13328712649867877]
	TIME [epoch: 5.77 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12263308875557341		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.12263308875557341 | validation: 0.14377224241659048]
	TIME [epoch: 5.78 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12756520639888688		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.12756520639888688 | validation: 0.1510034378265726]
	TIME [epoch: 5.76 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496779261509515		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.1496779261509515 | validation: 0.1978648229310176]
	TIME [epoch: 5.75 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14875060176566307		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.14875060176566307 | validation: 0.14976682365270422]
	TIME [epoch: 5.76 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16305828616920692		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.16305828616920692 | validation: 0.14212796747686876]
	TIME [epoch: 5.75 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406116646662573		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.1406116646662573 | validation: 0.14668221846204493]
	TIME [epoch: 5.78 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15252295173726427		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.15252295173726427 | validation: 0.1524708485650567]
	TIME [epoch: 5.77 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13436943832426612		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.13436943832426612 | validation: 0.14865698991303863]
	TIME [epoch: 5.75 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1456456648272954		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.1456456648272954 | validation: 0.16794675029202297]
	TIME [epoch: 5.76 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13717588885682588		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.13717588885682588 | validation: 0.16720613060795791]
	TIME [epoch: 5.76 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14030769796828424		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.14030769796828424 | validation: 0.13673500421163265]
	TIME [epoch: 5.76 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14683788207820847		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.14683788207820847 | validation: 0.15133089164758043]
	TIME [epoch: 5.78 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14251840518244122		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.14251840518244122 | validation: 0.12322720623767314]
	TIME [epoch: 5.77 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251870325801625		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.1251870325801625 | validation: 0.11835909892068362]
	TIME [epoch: 5.75 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12410212910178503		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.12410212910178503 | validation: 0.1357129858886819]
	TIME [epoch: 5.75 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13051097894927802		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.13051097894927802 | validation: 0.13138073123361133]
	TIME [epoch: 5.75 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15967881570290793		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.15967881570290793 | validation: 0.12842433175091691]
	TIME [epoch: 5.76 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14569924830922032		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.14569924830922032 | validation: 0.12911211493476202]
	TIME [epoch: 5.78 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1440812911148012		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.1440812911148012 | validation: 0.14205773866803992]
	TIME [epoch: 5.77 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13573132450966297		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.13573132450966297 | validation: 0.11824430291632053]
	TIME [epoch: 5.75 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12168165064038226		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.12168165064038226 | validation: 0.14971317611982252]
	TIME [epoch: 5.75 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12630378447150986		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.12630378447150986 | validation: 0.1655666039588062]
	TIME [epoch: 5.75 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13091450669418558		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.13091450669418558 | validation: 0.14487595541507056]
	TIME [epoch: 5.75 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13268519413935018		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.13268519413935018 | validation: 0.16381262074223635]
	TIME [epoch: 5.78 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348747263897496		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.1348747263897496 | validation: 0.14756893712617505]
	TIME [epoch: 5.77 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12543691511095126		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.12543691511095126 | validation: 0.13489519394264146]
	TIME [epoch: 5.76 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13616759589703112		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.13616759589703112 | validation: 0.18539076085879613]
	TIME [epoch: 5.75 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13639103609162187		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.13639103609162187 | validation: 0.11921957777004771]
	TIME [epoch: 5.75 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12814817268284076		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.12814817268284076 | validation: 0.12981176694686616]
	TIME [epoch: 5.75 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12913623061556873		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.12913623061556873 | validation: 0.1302292858697557]
	TIME [epoch: 5.78 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14561960190386608		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.14561960190386608 | validation: 0.16425413796967028]
	TIME [epoch: 5.77 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14757275472054582		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.14757275472054582 | validation: 0.15602996667135638]
	TIME [epoch: 5.75 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144639441419195		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.144639441419195 | validation: 0.1443197928575964]
	TIME [epoch: 5.75 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13862782206658783		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.13862782206658783 | validation: 0.1633716204088055]
	TIME [epoch: 5.75 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15278694091501388		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.15278694091501388 | validation: 0.16828614793927904]
	TIME [epoch: 5.75 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144078181787958		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.144078181787958 | validation: 0.14207120490047082]
	TIME [epoch: 5.78 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11827474401806548		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.11827474401806548 | validation: 0.11928846127508404]
	TIME [epoch: 5.76 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11931804996261755		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.11931804996261755 | validation: 0.1141792321215757]
	TIME [epoch: 5.75 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12598104053179618		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.12598104053179618 | validation: 0.12720876759229263]
	TIME [epoch: 5.75 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13601765764631465		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.13601765764631465 | validation: 0.14383749256070907]
	TIME [epoch: 5.75 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13668529782737132		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.13668529782737132 | validation: 0.173429077294157]
	TIME [epoch: 5.75 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14405445799270442		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.14405445799270442 | validation: 0.1469709062898605]
	TIME [epoch: 5.78 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13425664280814284		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.13425664280814284 | validation: 0.16316338887391024]
	TIME [epoch: 5.77 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13844556133429933		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.13844556133429933 | validation: 0.1595079931150478]
	TIME [epoch: 5.75 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12516439583571543		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.12516439583571543 | validation: 0.11281542821879288]
	TIME [epoch: 5.75 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11935277284126186		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.11935277284126186 | validation: 0.1407799600013534]
	TIME [epoch: 5.75 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14494216037599772		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.14494216037599772 | validation: 0.13497964638767207]
	TIME [epoch: 5.75 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14557234330662516		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.14557234330662516 | validation: 0.1405051135657083]
	TIME [epoch: 5.79 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14428588365299477		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.14428588365299477 | validation: 0.1714692355536511]
	TIME [epoch: 5.76 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514738039164833		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.1514738039164833 | validation: 0.14272899845232687]
	TIME [epoch: 5.75 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13852332240769322		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.13852332240769322 | validation: 0.15211827495509514]
	TIME [epoch: 5.75 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638844279251523		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.1638844279251523 | validation: 0.19788711477250537]
	TIME [epoch: 5.75 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15787231845638183		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.15787231845638183 | validation: 0.18492311568509595]
	TIME [epoch: 5.75 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612838425454683		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.1612838425454683 | validation: 0.15350061429276163]
	TIME [epoch: 5.78 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15526784658120368		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.15526784658120368 | validation: 0.1634724575355287]
	TIME [epoch: 5.76 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15182447806517022		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.15182447806517022 | validation: 0.16438955131629604]
	TIME [epoch: 5.75 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14153438617634198		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.14153438617634198 | validation: 0.16699102625831497]
	TIME [epoch: 5.75 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334882044927527		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.1334882044927527 | validation: 0.14013834196580655]
	TIME [epoch: 5.75 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205264071698751		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.1205264071698751 | validation: 0.12491186611856762]
	TIME [epoch: 5.75 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12571714822296726		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.12571714822296726 | validation: 0.1318643880952353]
	TIME [epoch: 5.78 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12903854047140131		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.12903854047140131 | validation: 0.1269383115701826]
	TIME [epoch: 5.76 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13143222264642435		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.13143222264642435 | validation: 0.11272939336582413]
	TIME [epoch: 5.75 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13803803169605158		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.13803803169605158 | validation: 0.11297335995498906]
	TIME [epoch: 5.75 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12758369109451823		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.12758369109451823 | validation: 0.16202486934015958]
	TIME [epoch: 5.75 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16199284463743044		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.16199284463743044 | validation: 0.1424579026911222]
	TIME [epoch: 5.75 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14417375432569324		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.14417375432569324 | validation: 0.13663889645227664]
	TIME [epoch: 5.79 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11883354920077666		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.11883354920077666 | validation: 0.11243748070672877]
	TIME [epoch: 5.76 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12988096830122187		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.12988096830122187 | validation: 0.1358840845597281]
	TIME [epoch: 5.75 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12187171716110998		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.12187171716110998 | validation: 0.1333740938064682]
	TIME [epoch: 5.75 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294238473562303		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.1294238473562303 | validation: 0.1423721838961147]
	TIME [epoch: 5.75 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1193616989432984		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.1193616989432984 | validation: 0.1344278269922597]
	TIME [epoch: 5.75 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1248481728849363		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.1248481728849363 | validation: 0.13735405741503093]
	TIME [epoch: 5.79 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12028403695222503		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.12028403695222503 | validation: 0.13128457280787778]
	TIME [epoch: 5.76 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12381188985658474		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.12381188985658474 | validation: 0.13515413225526382]
	TIME [epoch: 5.75 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12495476375185166		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.12495476375185166 | validation: 0.1476554013093646]
	TIME [epoch: 5.75 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276074995181677		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.1276074995181677 | validation: 0.14469018430578343]
	TIME [epoch: 5.75 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13464237725635375		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.13464237725635375 | validation: 0.13863777226243312]
	TIME [epoch: 5.75 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11942483316840269		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.11942483316840269 | validation: 0.14766538197530396]
	TIME [epoch: 5.78 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11975277877363366		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.11975277877363366 | validation: 0.12740995647499595]
	TIME [epoch: 5.76 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.122033970348493		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.122033970348493 | validation: 0.11455805451276935]
	TIME [epoch: 5.75 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314218748490827		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.1314218748490827 | validation: 0.12199128501121971]
	TIME [epoch: 5.75 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11977958385341737		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.11977958385341737 | validation: 0.16386148593355518]
	TIME [epoch: 5.75 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14035401436213293		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.14035401436213293 | validation: 0.13307817903472588]
	TIME [epoch: 5.75 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343228811890591		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.1343228811890591 | validation: 0.13109101176874555]
	TIME [epoch: 5.79 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296722883564336		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.1296722883564336 | validation: 0.14428464818612913]
	TIME [epoch: 5.76 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12894645283415673		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.12894645283415673 | validation: 0.16108471553720335]
	TIME [epoch: 5.75 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14729597728595906		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.14729597728595906 | validation: 0.14502135816346587]
	TIME [epoch: 5.75 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12493437181088414		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.12493437181088414 | validation: 0.15194645394645867]
	TIME [epoch: 5.75 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11925138835962044		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.11925138835962044 | validation: 0.1435789755779714]
	TIME [epoch: 5.75 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12950574583888963		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.12950574583888963 | validation: 0.15744118658175515]
	TIME [epoch: 5.78 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433291158169912		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.1433291158169912 | validation: 0.14666581460482386]
	TIME [epoch: 5.76 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12327175236573701		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.12327175236573701 | validation: 0.15941688465274392]
	TIME [epoch: 5.75 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12290066447151632		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.12290066447151632 | validation: 0.16447006642474718]
	TIME [epoch: 5.75 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13412967793064695		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.13412967793064695 | validation: 0.15103707899167643]
	TIME [epoch: 5.75 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12957104800350028		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.12957104800350028 | validation: 0.14156361481631155]
	TIME [epoch: 5.75 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13202026028858474		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.13202026028858474 | validation: 0.15576353655062022]
	TIME [epoch: 5.78 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12241729911322627		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.12241729911322627 | validation: 0.14027291314147472]
	TIME [epoch: 5.75 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326823408294884		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.1326823408294884 | validation: 0.1724495775478807]
	TIME [epoch: 5.75 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13143287804138493		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.13143287804138493 | validation: 0.12433170992333267]
	TIME [epoch: 5.75 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11338657891654888		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.11338657891654888 | validation: 0.13243673427465014]
	TIME [epoch: 5.75 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10987601112158069		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.10987601112158069 | validation: 0.1391249767896195]
	TIME [epoch: 5.75 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12133423768689854		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.12133423768689854 | validation: 0.15264978973767232]
	TIME [epoch: 5.78 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11602363926406112		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.11602363926406112 | validation: 0.1289048583000937]
	TIME [epoch: 5.75 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12329935656282211		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.12329935656282211 | validation: 0.12589308379798206]
	TIME [epoch: 5.75 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1232526593567095		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.1232526593567095 | validation: 0.1221825394119864]
	TIME [epoch: 5.75 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11529632436386		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.11529632436386 | validation: 0.1229875648750943]
	TIME [epoch: 5.75 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11747871581619711		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.11747871581619711 | validation: 0.14186570815013963]
	TIME [epoch: 5.75 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.121845404172685		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.121845404172685 | validation: 0.14017272376713316]
	TIME [epoch: 5.78 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11941224624463526		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.11941224624463526 | validation: 0.15620987256654534]
	TIME [epoch: 5.75 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12799199606521605		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.12799199606521605 | validation: 0.17157116136091616]
	TIME [epoch: 5.75 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1324428960425858		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.1324428960425858 | validation: 0.13181328296157682]
	TIME [epoch: 5.75 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300892379639851		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.1300892379639851 | validation: 0.16466883300932764]
	TIME [epoch: 5.75 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13932645471370694		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.13932645471370694 | validation: 0.1652201787568174]
	TIME [epoch: 5.75 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13796441689366049		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.13796441689366049 | validation: 0.19259708455538654]
	TIME [epoch: 5.78 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14426448513393955		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.14426448513393955 | validation: 0.18570993585674836]
	TIME [epoch: 5.75 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1397188448643427		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.1397188448643427 | validation: 0.19470599981206582]
	TIME [epoch: 5.75 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12488947110770278		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.12488947110770278 | validation: 0.16030994930282508]
	TIME [epoch: 5.75 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1404373284883673		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.1404373284883673 | validation: 0.19127701527639063]
	TIME [epoch: 5.75 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17539640470311144		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.17539640470311144 | validation: 0.1575371468308515]
	TIME [epoch: 5.75 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15508169157412516		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.15508169157412516 | validation: 0.1638449545200519]
	TIME [epoch: 5.78 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13160292497904708		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.13160292497904708 | validation: 0.14492445264665998]
	TIME [epoch: 5.75 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11666719358138444		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.11666719358138444 | validation: 0.1221028628985804]
	TIME [epoch: 5.75 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12380193608773499		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.12380193608773499 | validation: 0.12891526313942941]
	TIME [epoch: 5.75 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11602916544009156		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.11602916544009156 | validation: 0.1470028951677651]
	TIME [epoch: 5.75 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12180904193917122		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.12180904193917122 | validation: 0.15080905686994028]
	TIME [epoch: 5.75 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12577788793663267		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.12577788793663267 | validation: 0.176826828668445]
	TIME [epoch: 5.78 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438830237030241		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.1438830237030241 | validation: 0.20605488552359724]
	TIME [epoch: 5.75 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13191356234440338		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.13191356234440338 | validation: 0.1625830711055869]
	TIME [epoch: 5.75 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13190552912584264		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.13190552912584264 | validation: 0.22234998738316072]
	TIME [epoch: 5.75 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550589409790598		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.1550589409790598 | validation: 0.20324949704053893]
	TIME [epoch: 5.75 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14541843341164756		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.14541843341164756 | validation: 0.14710745509667436]
	TIME [epoch: 5.75 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11717787274320318		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.11717787274320318 | validation: 0.14565831860354156]
	TIME [epoch: 5.78 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12962708923189203		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.12962708923189203 | validation: 0.15026968800971754]
	TIME [epoch: 5.75 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12283173835663452		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.12283173835663452 | validation: 0.13973418549894942]
	TIME [epoch: 5.75 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11836731070358855		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.11836731070358855 | validation: 0.12805269811370834]
	TIME [epoch: 5.75 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12632691270273455		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.12632691270273455 | validation: 0.14608180498589396]
	TIME [epoch: 5.75 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12787091727156527		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.12787091727156527 | validation: 0.15814469585302227]
	TIME [epoch: 5.75 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13316830173188907		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.13316830173188907 | validation: 0.13480912188561736]
	TIME [epoch: 5.78 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12630855452906226		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.12630855452906226 | validation: 0.14760491163866354]
	TIME [epoch: 5.75 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12036563029557532		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.12036563029557532 | validation: 0.1274334117422667]
	TIME [epoch: 5.75 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12069951434848739		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.12069951434848739 | validation: 0.11978585988283151]
	TIME [epoch: 5.75 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12492262639927276		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.12492262639927276 | validation: 0.11519718565844736]
	TIME [epoch: 5.75 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11111345892672714		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.11111345892672714 | validation: 0.11593401791411534]
	TIME [epoch: 5.76 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12861464051480984		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.12861464051480984 | validation: 0.14302268424856845]
	TIME [epoch: 5.77 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12116861018678657		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.12116861018678657 | validation: 0.12173815820037481]
	TIME [epoch: 5.75 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1179861237112785		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.1179861237112785 | validation: 0.11939460365806152]
	TIME [epoch: 5.75 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11105430250049061		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.11105430250049061 | validation: 0.1294207426287747]
	TIME [epoch: 5.75 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11749868993589799		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.11749868993589799 | validation: 0.14579909275352765]
	TIME [epoch: 5.73 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12900589880970073		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.12900589880970073 | validation: 0.14530466070119474]
	TIME [epoch: 5.76 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13130736659793826		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.13130736659793826 | validation: 0.12670687511764112]
	TIME [epoch: 5.78 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11607065117414295		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.11607065117414295 | validation: 0.11353915940273339]
	TIME [epoch: 5.74 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11604782634950327		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.11604782634950327 | validation: 0.12288454651165]
	TIME [epoch: 5.75 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11112559840427157		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.11112559840427157 | validation: 0.10365452846517435]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_1148.pth
	Model improved!!!
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11318354800521739		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.11318354800521739 | validation: 0.12436804252593192]
	TIME [epoch: 5.75 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11378018045146517		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.11378018045146517 | validation: 0.12103430979512159]
	TIME [epoch: 5.76 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10794214676134235		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.10794214676134235 | validation: 0.11508424833744829]
	TIME [epoch: 5.77 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1151898413107674		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.1151898413107674 | validation: 0.1152870626974482]
	TIME [epoch: 5.75 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11166943274536421		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.11166943274536421 | validation: 0.1306313410866584]
	TIME [epoch: 5.73 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11530614674180566		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.11530614674180566 | validation: 0.10762014237952873]
	TIME [epoch: 5.73 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11685732464164854		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.11685732464164854 | validation: 0.11939601879573512]
	TIME [epoch: 5.73 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1075185878411275		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.1075185878411275 | validation: 0.13091629706253166]
	TIME [epoch: 5.76 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12186183954574188		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.12186183954574188 | validation: 0.1231229377429907]
	TIME [epoch: 5.76 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11246097490860986		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.11246097490860986 | validation: 0.11133778503820009]
	TIME [epoch: 5.75 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11192056529341914		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.11192056529341914 | validation: 0.11282560432093028]
	TIME [epoch: 5.73 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11030344198319995		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.11030344198319995 | validation: 0.11526212778838389]
	TIME [epoch: 5.73 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11620563023663318		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.11620563023663318 | validation: 0.10941495816554962]
	TIME [epoch: 5.73 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11675194822986179		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.11675194822986179 | validation: 0.12581853425004447]
	TIME [epoch: 5.76 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12705285855726192		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.12705285855726192 | validation: 0.11524019801495061]
	TIME [epoch: 5.76 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1157243668269675		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.1157243668269675 | validation: 0.10542225844806796]
	TIME [epoch: 5.74 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11760328090029729		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.11760328090029729 | validation: 0.1059939778906065]
	TIME [epoch: 5.73 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1213689686028673		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.1213689686028673 | validation: 0.11544587849646064]
	TIME [epoch: 5.73 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1166228243431822		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.1166228243431822 | validation: 0.11804364003810576]
	TIME [epoch: 5.73 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11895543595238521		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.11895543595238521 | validation: 0.123049493640181]
	TIME [epoch: 5.75 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11059830314825284		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.11059830314825284 | validation: 0.1365912213432315]
	TIME [epoch: 5.75 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11345077158406668		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.11345077158406668 | validation: 0.11643361935810585]
	TIME [epoch: 5.74 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1097397448353838		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.1097397448353838 | validation: 0.10929167373252416]
	TIME [epoch: 5.73 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11747190953155356		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.11747190953155356 | validation: 0.11834244864117999]
	TIME [epoch: 5.75 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.119417709397121		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.119417709397121 | validation: 0.10765224024623347]
	TIME [epoch: 5.73 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11727160439484718		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.11727160439484718 | validation: 0.10609715766566569]
	TIME [epoch: 5.77 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11161657188787098		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.11161657188787098 | validation: 0.11856962409878176]
	TIME [epoch: 5.74 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11391330109923405		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.11391330109923405 | validation: 0.12186945257321817]
	TIME [epoch: 5.74 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11163387606125028		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.11163387606125028 | validation: 0.11781676392145267]
	TIME [epoch: 5.74 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091779186795873		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.1091779186795873 | validation: 0.10751328535588255]
	TIME [epoch: 5.75 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11657280293371441		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.11657280293371441 | validation: 0.14690400971587367]
	TIME [epoch: 5.73 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12402640593622388		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.12402640593622388 | validation: 0.12602406237186936]
	TIME [epoch: 5.76 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11614064321850717		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.11614064321850717 | validation: 0.13245560531448486]
	TIME [epoch: 5.76 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14334358505095798		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.14334358505095798 | validation: 0.11780519402613311]
	TIME [epoch: 5.73 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11084049861107736		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.11084049861107736 | validation: 0.11666740952191909]
	TIME [epoch: 5.74 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10709932031612057		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.10709932031612057 | validation: 0.11902876905520657]
	TIME [epoch: 5.74 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11468693398798956		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.11468693398798956 | validation: 0.12274570997212747]
	TIME [epoch: 5.74 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1115146673091149		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.1115146673091149 | validation: 0.12691040802792]
	TIME [epoch: 5.76 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11332351872300898		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.11332351872300898 | validation: 0.12216714560571346]
	TIME [epoch: 5.74 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11434236927252464		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.11434236927252464 | validation: 0.11849519079017615]
	TIME [epoch: 5.73 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10662573466348588		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.10662573466348588 | validation: 0.11989092513392001]
	TIME [epoch: 5.73 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1090413919194475		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.1090413919194475 | validation: 0.10775029118063156]
	TIME [epoch: 5.74 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1022424868830286		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.1022424868830286 | validation: 0.115196366360409]
	TIME [epoch: 5.73 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13490897941619548		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.13490897941619548 | validation: 0.10496407348750601]
	TIME [epoch: 5.78 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11010806891893768		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.11010806891893768 | validation: 0.10593374533279047]
	TIME [epoch: 5.74 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10749692594285519		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.10749692594285519 | validation: 0.11582740762590273]
	TIME [epoch: 5.74 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10812901106899525		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.10812901106899525 | validation: 0.10842535833717148]
	TIME [epoch: 5.75 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10392007597086911		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.10392007597086911 | validation: 0.1058756905467428]
	TIME [epoch: 5.75 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11121915587598241		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.11121915587598241 | validation: 0.10912625107220766]
	TIME [epoch: 5.75 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10982441071111987		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.10982441071111987 | validation: 0.12983004133168757]
	TIME [epoch: 5.77 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11582777788506396		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.11582777788506396 | validation: 0.117480787261833]
	TIME [epoch: 5.76 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10611243645196342		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.10611243645196342 | validation: 0.1129868679056053]
	TIME [epoch: 5.75 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11019593081978861		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.11019593081978861 | validation: 0.11565796181516536]
	TIME [epoch: 5.75 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11593223016306141		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.11593223016306141 | validation: 0.12352851545286488]
	TIME [epoch: 5.75 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1168579544128973		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.1168579544128973 | validation: 0.15142467851497984]
	TIME [epoch: 5.75 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11475754543471611		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.11475754543471611 | validation: 0.12527545616740837]
	TIME [epoch: 5.77 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1175257142840484		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.1175257142840484 | validation: 0.13432744761319132]
	TIME [epoch: 5.76 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11022300347904906		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.11022300347904906 | validation: 0.11336928630747249]
	TIME [epoch: 5.75 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10878630461766457		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.10878630461766457 | validation: 0.1066905141300209]
	TIME [epoch: 5.75 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077852061709717		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.1077852061709717 | validation: 0.11589906963297138]
	TIME [epoch: 5.74 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11119754955183664		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.11119754955183664 | validation: 0.10320901388832425]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_1209.pth
	Model improved!!!
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11450827193102855		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.11450827193102855 | validation: 0.12799752638333395]
	TIME [epoch: 5.78 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12389421894241523		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.12389421894241523 | validation: 0.11882980383157314]
	TIME [epoch: 5.75 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1113236642192295		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.1113236642192295 | validation: 0.10392560393581513]
	TIME [epoch: 5.75 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11535384230962425		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.11535384230962425 | validation: 0.11407398104739136]
	TIME [epoch: 5.75 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1146628685627277		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.1146628685627277 | validation: 0.11699268503439202]
	TIME [epoch: 5.73 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1208301339565652		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.1208301339565652 | validation: 0.1061789196863946]
	TIME [epoch: 5.75 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13087799406209719		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.13087799406209719 | validation: 0.1307614559212797]
	TIME [epoch: 5.78 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12803549702448958		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.12803549702448958 | validation: 0.1081278908370097]
	TIME [epoch: 5.75 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10861160034492559		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.10861160034492559 | validation: 0.11479124225950042]
	TIME [epoch: 5.75 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10765979241232052		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.10765979241232052 | validation: 0.11048139574961799]
	TIME [epoch: 5.75 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11417957243302487		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.11417957243302487 | validation: 0.12667697481476345]
	TIME [epoch: 5.75 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11875538884682263		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.11875538884682263 | validation: 0.13696497242320949]
	TIME [epoch: 5.74 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12604063618468414		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.12604063618468414 | validation: 0.13077724964874726]
	TIME [epoch: 5.78 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11142036889143767		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.11142036889143767 | validation: 0.11269891580195625]
	TIME [epoch: 5.75 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1107039732348253		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.1107039732348253 | validation: 0.12885317025829046]
	TIME [epoch: 5.73 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11847963477707263		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.11847963477707263 | validation: 0.10906928949069687]
	TIME [epoch: 5.73 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1076451948826241		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.1076451948826241 | validation: 0.10214832954159465]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_1226.pth
	Model improved!!!
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11126978739042397		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.11126978739042397 | validation: 0.10296246331841953]
	TIME [epoch: 5.75 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1076031008924146		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.1076031008924146 | validation: 0.11056130371078177]
	TIME [epoch: 5.77 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11596256107405604		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.11596256107405604 | validation: 0.11210117939932653]
	TIME [epoch: 5.74 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10756211376792596		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.10756211376792596 | validation: 0.12617182914290548]
	TIME [epoch: 5.73 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1095082742393228		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.1095082742393228 | validation: 0.1252327069301724]
	TIME [epoch: 5.73 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11112734527903753		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.11112734527903753 | validation: 0.12562676792755836]
	TIME [epoch: 5.74 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1187368039176851		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.1187368039176851 | validation: 0.12714190835489242]
	TIME [epoch: 5.73 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11998059023196939		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.11998059023196939 | validation: 0.12027720471787445]
	TIME [epoch: 5.78 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11662830196679551		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.11662830196679551 | validation: 0.1214134831501162]
	TIME [epoch: 5.73 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1138369090524361		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.1138369090524361 | validation: 0.1252660795042516]
	TIME [epoch: 5.73 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1220544006734758		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.1220544006734758 | validation: 0.12059918305524242]
	TIME [epoch: 5.73 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11625044664519307		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.11625044664519307 | validation: 0.12359844758293598]
	TIME [epoch: 5.74 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11042172196548583		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.11042172196548583 | validation: 0.12820773694792792]
	TIME [epoch: 5.73 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11974574739252242		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.11974574739252242 | validation: 0.14920245763640547]
	TIME [epoch: 5.78 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12720595684748315		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.12720595684748315 | validation: 0.14369635352773044]
	TIME [epoch: 5.73 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11597262092339636		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.11597262092339636 | validation: 0.13390861228711656]
	TIME [epoch: 5.74 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11401773142599178		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.11401773142599178 | validation: 0.13847794679060077]
	TIME [epoch: 5.74 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11133232336156836		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.11133232336156836 | validation: 0.13534409696656233]
	TIME [epoch: 5.73 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13314077594678758		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.13314077594678758 | validation: 0.14068679503320802]
	TIME [epoch: 5.73 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13496961146367428		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.13496961146367428 | validation: 0.13836080738384687]
	TIME [epoch: 5.76 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14138180007778672		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.14138180007778672 | validation: 0.13190657846981826]
	TIME [epoch: 5.73 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12273040204475201		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.12273040204475201 | validation: 0.13292881900781076]
	TIME [epoch: 5.73 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11963428348434627		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.11963428348434627 | validation: 0.12072050617340666]
	TIME [epoch: 5.73 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11925046534744303		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.11925046534744303 | validation: 0.12741239649006253]
	TIME [epoch: 5.73 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11638711119271464		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.11638711119271464 | validation: 0.12203315034710105]
	TIME [epoch: 5.73 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11455001877351587		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.11455001877351587 | validation: 0.13033322573708328]
	TIME [epoch: 5.76 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1090001649260513		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.1090001649260513 | validation: 0.13071561643190852]
	TIME [epoch: 5.73 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11057850172812335		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.11057850172812335 | validation: 0.11130498801516253]
	TIME [epoch: 5.73 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11242663895487316		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.11242663895487316 | validation: 0.11854250281838397]
	TIME [epoch: 5.73 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12222931195318518		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.12222931195318518 | validation: 0.14384279720474347]
	TIME [epoch: 5.74 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11741957532753959		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.11741957532753959 | validation: 0.1263998299425817]
	TIME [epoch: 5.73 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11059301870243293		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.11059301870243293 | validation: 0.11381483142240885]
	TIME [epoch: 5.77 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1116303556048504		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.1116303556048504 | validation: 0.11422647822100325]
	TIME [epoch: 5.74 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10671898418782703		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.10671898418782703 | validation: 0.1321748065276142]
	TIME [epoch: 5.75 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11026697226775019		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.11026697226775019 | validation: 0.11377146899423346]
	TIME [epoch: 5.73 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10578042149600227		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.10578042149600227 | validation: 0.12328015216391552]
	TIME [epoch: 5.74 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11031818413463629		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.11031818413463629 | validation: 0.1325938120911889]
	TIME [epoch: 5.75 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10647418080964988		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.10647418080964988 | validation: 0.11621311161573385]
	TIME [epoch: 5.77 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11210166788403794		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.11210166788403794 | validation: 0.1074699137989639]
	TIME [epoch: 5.73 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10639608673306446		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.10639608673306446 | validation: 0.11945436170536837]
	TIME [epoch: 5.74 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10302328003061592		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.10302328003061592 | validation: 0.10764835849358044]
	TIME [epoch: 5.73 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11077513359892871		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.11077513359892871 | validation: 0.10857343787302075]
	TIME [epoch: 5.74 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10718044084278025		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.10718044084278025 | validation: 0.1106525163590822]
	TIME [epoch: 5.73 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1046816673503186		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.1046816673503186 | validation: 0.11289980553540531]
	TIME [epoch: 5.78 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11034874979494866		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.11034874979494866 | validation: 0.11391202500518346]
	TIME [epoch: 5.73 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11397526254499205		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.11397526254499205 | validation: 0.13373178183857298]
	TIME [epoch: 5.73 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11477146153970876		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.11477146153970876 | validation: 0.11661945278207615]
	TIME [epoch: 5.73 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10611011744886681		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.10611011744886681 | validation: 0.10801695883448087]
	TIME [epoch: 5.73 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10933942494399417		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.10933942494399417 | validation: 0.10912088371638821]
	TIME [epoch: 5.73 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11179928849653581		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.11179928849653581 | validation: 0.10976980161570353]
	TIME [epoch: 5.76 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1152450435699981		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.1152450435699981 | validation: 0.09787611862163845]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_1277.pth
	Model improved!!!
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11401379997339971		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.11401379997339971 | validation: 0.10591817715932844]
	TIME [epoch: 5.73 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11829021731451808		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.11829021731451808 | validation: 0.11647996385953598]
	TIME [epoch: 5.73 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11341072726361202		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.11341072726361202 | validation: 0.09870816032382136]
	TIME [epoch: 5.73 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10564832385677231		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.10564832385677231 | validation: 0.11727502174379542]
	TIME [epoch: 5.74 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1084808160049293		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.1084808160049293 | validation: 0.11327868074046407]
	TIME [epoch: 5.77 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1117870287519107		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.1117870287519107 | validation: 0.11952683841203522]
	TIME [epoch: 5.73 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11396278544497504		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.11396278544497504 | validation: 0.12372692046624385]
	TIME [epoch: 5.74 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11843216943320824		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.11843216943320824 | validation: 0.11466877770115787]
	TIME [epoch: 5.73 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11610700693816266		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.11610700693816266 | validation: 0.1337541957811294]
	TIME [epoch: 5.74 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11759070180767997		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.11759070180767997 | validation: 0.12038968656272715]
	TIME [epoch: 5.74 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294374287780708		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.11294374287780708 | validation: 0.1300663947903367]
	TIME [epoch: 5.76 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11343751697833789		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.11343751697833789 | validation: 0.1274235893221662]
	TIME [epoch: 5.74 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.107622712726383		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.107622712726383 | validation: 0.11263563481979728]
	TIME [epoch: 5.74 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1069806591927994		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.1069806591927994 | validation: 0.1035696257263763]
	TIME [epoch: 5.74 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10612322827674417		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.10612322827674417 | validation: 0.11707416012109928]
	TIME [epoch: 5.73 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10876879248812567		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.10876879248812567 | validation: 0.11251824451525146]
	TIME [epoch: 5.74 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11283017471978601		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.11283017471978601 | validation: 0.10970706875933786]
	TIME [epoch: 5.76 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11012375425818315		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.11012375425818315 | validation: 0.10521459785882727]
	TIME [epoch: 5.74 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10976811581833738		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.10976811581833738 | validation: 0.11619235818995315]
	TIME [epoch: 5.74 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11052023042790382		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.11052023042790382 | validation: 0.1233558105148375]
	TIME [epoch: 5.72 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10860742640381275		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.10860742640381275 | validation: 0.10000296115312772]
	TIME [epoch: 5.74 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10154650528489713		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.10154650528489713 | validation: 0.11525796767251421]
	TIME [epoch: 5.74 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10880032500085947		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.10880032500085947 | validation: 0.12129500221300343]
	TIME [epoch: 5.77 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11600723388861771		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.11600723388861771 | validation: 0.11595682954080547]
	TIME [epoch: 5.74 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1066009278474629		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.1066009278474629 | validation: 0.11492300496783467]
	TIME [epoch: 5.74 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10840992487753139		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.10840992487753139 | validation: 0.12179686183537229]
	TIME [epoch: 5.74 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10588342447696175		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.10588342447696175 | validation: 0.11602760187711972]
	TIME [epoch: 5.74 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10695165150722473		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.10695165150722473 | validation: 0.12294697267704541]
	TIME [epoch: 5.75 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10185693637936721		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.10185693637936721 | validation: 0.13432597229105697]
	TIME [epoch: 5.75 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1190296058706527		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.1190296058706527 | validation: 0.13474391377945283]
	TIME [epoch: 5.73 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11951098044968735		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.11951098044968735 | validation: 0.11594718488706461]
	TIME [epoch: 5.74 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11149118808435063		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.11149118808435063 | validation: 0.11011124394825238]
	TIME [epoch: 5.74 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11040762196075703		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.11040762196075703 | validation: 0.11785329728920658]
	TIME [epoch: 5.74 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11388427342019107		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.11388427342019107 | validation: 0.1114153811216717]
	TIME [epoch: 5.75 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10605720549154463		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.10605720549154463 | validation: 0.10884132827437781]
	TIME [epoch: 5.77 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1043936616690481		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.1043936616690481 | validation: 0.12017789247044239]
	TIME [epoch: 5.73 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10424937353063964		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.10424937353063964 | validation: 0.10737848479641705]
	TIME [epoch: 5.73 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10730386371227821		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.10730386371227821 | validation: 0.10765509049179851]
	TIME [epoch: 5.75 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10281231076082778		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.10281231076082778 | validation: 0.10827039383207553]
	TIME [epoch: 5.73 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1045386113243662		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.1045386113243662 | validation: 0.11318925009562852]
	TIME [epoch: 5.76 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10165082136622666		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.10165082136622666 | validation: 0.12106825444099711]
	TIME [epoch: 5.75 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10784273565878137		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.10784273565878137 | validation: 0.11015618759591003]
	TIME [epoch: 5.74 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1058776989813954		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.1058776989813954 | validation: 0.10985957352188665]
	TIME [epoch: 5.73 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11048167124293913		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.11048167124293913 | validation: 0.10846974139949225]
	TIME [epoch: 5.73 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10310368499098192		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.10310368499098192 | validation: 0.10774201331705267]
	TIME [epoch: 5.73 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11213398350773128		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.11213398350773128 | validation: 0.11350992274965949]
	TIME [epoch: 5.74 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1146693657194996		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.1146693657194996 | validation: 0.12225671900411994]
	TIME [epoch: 5.75 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11414866452323313		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.11414866452323313 | validation: 0.11917327074833715]
	TIME [epoch: 5.75 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1066548051473229		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.1066548051473229 | validation: 0.12679641332033467]
	TIME [epoch: 5.73 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10463690137713587		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.10463690137713587 | validation: 0.10478669842785161]
	TIME [epoch: 5.75 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10496739324585679		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.10496739324585679 | validation: 0.11643272010831916]
	TIME [epoch: 5.73 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1145992529412172		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.1145992529412172 | validation: 0.11194703330884559]
	TIME [epoch: 5.74 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10812258824747578		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.10812258824747578 | validation: 0.1105708815467835]
	TIME [epoch: 5.77 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10572613939080763		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.10572613939080763 | validation: 0.10658121645395595]
	TIME [epoch: 5.74 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10229742460436793		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.10229742460436793 | validation: 0.1143072055939877]
	TIME [epoch: 5.72 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11076341861829381		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.11076341861829381 | validation: 0.11233233670011583]
	TIME [epoch: 5.74 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10866963580428735		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.10866963580428735 | validation: 0.10231796165756693]
	TIME [epoch: 5.74 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10126686236445444		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.10126686236445444 | validation: 0.1058131147581209]
	TIME [epoch: 5.75 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10369487011225649		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.10369487011225649 | validation: 0.12029417554925452]
	TIME [epoch: 5.76 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10653572838978648		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.10653572838978648 | validation: 0.11002194138729161]
	TIME [epoch: 5.74 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10713242412583776		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.10713242412583776 | validation: 0.11324207266834972]
	TIME [epoch: 5.74 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10894642156886734		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.10894642156886734 | validation: 0.12556047511304688]
	TIME [epoch: 5.74 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11458254492811762		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.11458254492811762 | validation: 0.13559042355923073]
	TIME [epoch: 5.75 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11869840695182893		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.11869840695182893 | validation: 0.12307359449420133]
	TIME [epoch: 5.75 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11210693948694042		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.11210693948694042 | validation: 0.10361445347095302]
	TIME [epoch: 5.77 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10159550753379079		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.10159550753379079 | validation: 0.09919344092357485]
	TIME [epoch: 5.75 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10664401210417429		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.10664401210417429 | validation: 0.10080862165253046]
	TIME [epoch: 5.73 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10862141227894058		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.10862141227894058 | validation: 0.12099279884087782]
	TIME [epoch: 5.74 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11841687709733809		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.11841687709733809 | validation: 0.12142005125336745]
	TIME [epoch: 5.74 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11190237476400504		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.11190237476400504 | validation: 0.10885237652399159]
	TIME [epoch: 5.74 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10810814477314418		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.10810814477314418 | validation: 0.10901506101940928]
	TIME [epoch: 5.75 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10646655287226664		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.10646655287226664 | validation: 0.1081208035208062]
	TIME [epoch: 5.74 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10352433379223373		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.10352433379223373 | validation: 0.10562995910039892]
	TIME [epoch: 5.73 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1048777027887641		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.1048777027887641 | validation: 0.11680928218694137]
	TIME [epoch: 5.73 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.114254430918175		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.114254430918175 | validation: 0.1075231461235751]
	TIME [epoch: 5.73 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10626518911297808		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.10626518911297808 | validation: 0.11727458724621238]
	TIME [epoch: 5.75 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037062483350594		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.1037062483350594 | validation: 0.1085233638876176]
	TIME [epoch: 5.75 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10571406656304443		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.10571406656304443 | validation: 0.10641129665023233]
	TIME [epoch: 5.74 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10003902975279064		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.10003902975279064 | validation: 0.10812068712347361]
	TIME [epoch: 5.73 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10408795844814624		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.10408795844814624 | validation: 0.10373445691324698]
	TIME [epoch: 5.73 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10435179385931385		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.10435179385931385 | validation: 0.10574244377825584]
	TIME [epoch: 5.73 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10649023572784813		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.10649023572784813 | validation: 0.10126873223218287]
	TIME [epoch: 5.75 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11060816974058069		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.11060816974058069 | validation: 0.11534022552103594]
	TIME [epoch: 5.75 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10559952436954223		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.10559952436954223 | validation: 0.1237077976583555]
	TIME [epoch: 5.72 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11102220491759378		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.11102220491759378 | validation: 0.12534301892430755]
	TIME [epoch: 5.74 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10737809325712018		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.10737809325712018 | validation: 0.11583748802158146]
	TIME [epoch: 5.73 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1078819938963114		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.1078819938963114 | validation: 0.11207545796158618]
	TIME [epoch: 5.72 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11024624433818382		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.11024624433818382 | validation: 0.10389305801382072]
	TIME [epoch: 5.76 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10441064172058609		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.10441064172058609 | validation: 0.10679876175136371]
	TIME [epoch: 5.74 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10918381289581361		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.10918381289581361 | validation: 0.11910970920500535]
	TIME [epoch: 5.75 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10706025847464408		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.10706025847464408 | validation: 0.13031381194235234]
	TIME [epoch: 5.73 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10294197031138239		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.10294197031138239 | validation: 0.12396044481012286]
	TIME [epoch: 5.75 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10707646268061254		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.10707646268061254 | validation: 0.11883732376468546]
	TIME [epoch: 5.73 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10188778873438242		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.10188778873438242 | validation: 0.11276818287130044]
	TIME [epoch: 5.75 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10375050631914548		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.10375050631914548 | validation: 0.12814118507452635]
	TIME [epoch: 5.75 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065391542637291		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.1065391542637291 | validation: 0.12172664519747635]
	TIME [epoch: 5.72 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10230650716058817		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.10230650716058817 | validation: 0.113134218471698]
	TIME [epoch: 5.74 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038658848326821		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.1038658848326821 | validation: 0.12081480797985322]
	TIME [epoch: 5.73 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10804818004989279		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.10804818004989279 | validation: 0.12876584538844396]
	TIME [epoch: 5.73 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11226988796454349		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.11226988796454349 | validation: 0.1239669381273254]
	TIME [epoch: 5.77 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10649490483250836		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.10649490483250836 | validation: 0.13874638198667705]
	TIME [epoch: 5.75 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1073681834983621		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.1073681834983621 | validation: 0.13746406012880016]
	TIME [epoch: 5.73 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11878470888004848		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.11878470888004848 | validation: 0.14720260090697626]
	TIME [epoch: 5.73 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11637268239089894		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.11637268239089894 | validation: 0.1211292714273419]
	TIME [epoch: 5.74 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11080114141767586		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.11080114141767586 | validation: 0.12789023011011977]
	TIME [epoch: 5.74 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10915962936218421		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.10915962936218421 | validation: 0.1370747153423727]
	TIME [epoch: 5.75 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11524771431006246		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.11524771431006246 | validation: 0.1356311357738125]
	TIME [epoch: 5.74 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11193942789163218		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.11193942789163218 | validation: 0.13820285408048605]
	TIME [epoch: 5.74 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11119720661422709		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.11119720661422709 | validation: 0.12770089151444214]
	TIME [epoch: 5.72 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10948846820318321		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.10948846820318321 | validation: 0.12150486771812494]
	TIME [epoch: 5.73 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11604214587192609		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.11604214587192609 | validation: 0.11821346878792036]
	TIME [epoch: 5.72 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11184404108323642		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.11184404108323642 | validation: 0.11898863794586738]
	TIME [epoch: 5.76 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11690178735533743		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.11690178735533743 | validation: 0.11866559076401771]
	TIME [epoch: 5.75 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10655536178056815		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.10655536178056815 | validation: 0.11598939600115431]
	TIME [epoch: 5.74 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11626117319442314		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.11626117319442314 | validation: 0.1271214543522917]
	TIME [epoch: 5.74 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10287366183700043		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.10287366183700043 | validation: 0.12070692570745657]
	TIME [epoch: 5.74 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10464320183420223		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.10464320183420223 | validation: 0.12554704091655483]
	TIME [epoch: 5.74 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10409602578747565		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.10409602578747565 | validation: 0.13784800990078988]
	TIME [epoch: 5.77 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10909291895917753		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.10909291895917753 | validation: 0.1223083738607361]
	TIME [epoch: 5.75 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10558650637240108		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.10558650637240108 | validation: 0.1279274123973138]
	TIME [epoch: 5.74 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10391605407855802		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.10391605407855802 | validation: 0.1245112409737743]
	TIME [epoch: 5.75 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10338331596517808		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.10338331596517808 | validation: 0.11990864136301937]
	TIME [epoch: 5.74 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10122445473323449		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.10122445473323449 | validation: 0.10603949633078533]
	TIME [epoch: 5.73 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10051271795714371		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.10051271795714371 | validation: 0.11589695446506484]
	TIME [epoch: 5.75 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10360853214484474		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.10360853214484474 | validation: 0.12026739289860494]
	TIME [epoch: 5.75 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10105600444710915		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.10105600444710915 | validation: 0.1106670785856436]
	TIME [epoch: 5.73 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10263181112716992		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.10263181112716992 | validation: 0.10784639601089929]
	TIME [epoch: 5.73 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10334190709185201		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.10334190709185201 | validation: 0.10182275066371198]
	TIME [epoch: 5.73 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10395810489142747		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.10395810489142747 | validation: 0.12006652603558685]
	TIME [epoch: 5.73 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10352488563932974		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.10352488563932974 | validation: 0.11590192819317227]
	TIME [epoch: 5.76 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09713977442191389		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.09713977442191389 | validation: 0.10979422970430036]
	TIME [epoch: 5.75 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10576526560119276		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.10576526560119276 | validation: 0.12407848201893637]
	TIME [epoch: 5.74 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10520928951345963		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.10520928951345963 | validation: 0.1139142566985133]
	TIME [epoch: 5.73 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10409055256948434		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.10409055256948434 | validation: 0.10588814564273794]
	TIME [epoch: 5.73 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10877100854253255		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.10877100854253255 | validation: 0.09992607152063603]
	TIME [epoch: 5.72 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10782427198722153		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.10782427198722153 | validation: 0.11304963547533707]
	TIME [epoch: 5.77 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062917508410317		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.1062917508410317 | validation: 0.10594342650877735]
	TIME [epoch: 5.75 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10774160290576146		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.10774160290576146 | validation: 0.12053163380583233]
	TIME [epoch: 5.74 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10572897581177744		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.10572897581177744 | validation: 0.13447403156467372]
	TIME [epoch: 5.73 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11064002320158126		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.11064002320158126 | validation: 0.11330174636241093]
	TIME [epoch: 5.73 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09475545845004392		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.09475545845004392 | validation: 0.12085426732723453]
	TIME [epoch: 5.73 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1059867757715655		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.1059867757715655 | validation: 0.1198552738174043]
	TIME [epoch: 5.77 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10224302651753839		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.10224302651753839 | validation: 0.10596804084577835]
	TIME [epoch: 5.75 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10194097936088452		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.10194097936088452 | validation: 0.09382588864402326]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_1421.pth
	Model improved!!!
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10325895587890271		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.10325895587890271 | validation: 0.10017286870227628]
	TIME [epoch: 5.73 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10565604600183134		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.10565604600183134 | validation: 0.11615238720804223]
	TIME [epoch: 5.73 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10164823446110978		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.10164823446110978 | validation: 0.12048333531764822]
	TIME [epoch: 5.73 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10031954527903536		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.10031954527903536 | validation: 0.10691606417584788]
	TIME [epoch: 5.77 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09923781732057102		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.09923781732057102 | validation: 0.1013343786687728]
	TIME [epoch: 5.75 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10256617747935302		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.10256617747935302 | validation: 0.10440128747455207]
	TIME [epoch: 5.73 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10069456040386923		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.10069456040386923 | validation: 0.10574655836474442]
	TIME [epoch: 5.73 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10353798883084848		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.10353798883084848 | validation: 0.11484463942527144]
	TIME [epoch: 5.72 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10499527348619435		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.10499527348619435 | validation: 0.12317217035424072]
	TIME [epoch: 5.73 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10484114728209476		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.10484114728209476 | validation: 0.11615413858069853]
	TIME [epoch: 5.77 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10252519827715786		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.10252519827715786 | validation: 0.10073986221948507]
	TIME [epoch: 5.74 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10479238590737139		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.10479238590737139 | validation: 0.1141719525219725]
	TIME [epoch: 5.74 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10878848825989153		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.10878848825989153 | validation: 0.1211250494374957]
	TIME [epoch: 5.73 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1100722602044816		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.1100722602044816 | validation: 0.11670293038838994]
	TIME [epoch: 5.73 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167865200981958		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.10167865200981958 | validation: 0.11593542943951735]
	TIME [epoch: 5.74 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291283452593693		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.10291283452593693 | validation: 0.11671612906949314]
	TIME [epoch: 5.77 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10434326618175448		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.10434326618175448 | validation: 0.11705854928462456]
	TIME [epoch: 5.75 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1012319876068534		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.1012319876068534 | validation: 0.11356516159758988]
	TIME [epoch: 5.73 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10185506375355215		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.10185506375355215 | validation: 0.11269661249675149]
	TIME [epoch: 5.73 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09972224563971165		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.09972224563971165 | validation: 0.11171674422081203]
	TIME [epoch: 5.74 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09989786426789746		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.09989786426789746 | validation: 0.12103075100420652]
	TIME [epoch: 5.73 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10823369432522552		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.10823369432522552 | validation: 0.10630558110686203]
	TIME [epoch: 5.77 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1024085316573945		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.1024085316573945 | validation: 0.11473510466292983]
	TIME [epoch: 5.74 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09795189058283216		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.09795189058283216 | validation: 0.12942545359435678]
	TIME [epoch: 5.74 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10258504184352735		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.10258504184352735 | validation: 0.11615453230926295]
	TIME [epoch: 5.73 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10555670386460916		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.10555670386460916 | validation: 0.10994028915923855]
	TIME [epoch: 5.73 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1030021228748013		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.1030021228748013 | validation: 0.12205401802549741]
	TIME [epoch: 5.73 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11090520112548327		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.11090520112548327 | validation: 0.1314815996458893]
	TIME [epoch: 5.77 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10156337748468777		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.10156337748468777 | validation: 0.11710672230338773]
	TIME [epoch: 5.74 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1035377817327063		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.1035377817327063 | validation: 0.11783494200695394]
	TIME [epoch: 5.73 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09801950822536769		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.09801950822536769 | validation: 0.1090761685868582]
	TIME [epoch: 5.73 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070196311446967		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.1070196311446967 | validation: 0.1089690715215217]
	TIME [epoch: 5.73 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11122437661923334		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.11122437661923334 | validation: 0.10400791796764047]
	TIME [epoch: 5.74 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1133918096101762		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.1133918096101762 | validation: 0.1006374384073861]
	TIME [epoch: 5.76 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10402665923375844		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.10402665923375844 | validation: 0.09642208649142507]
	TIME [epoch: 5.75 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11156730162271819		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.11156730162271819 | validation: 0.10440764162394463]
	TIME [epoch: 5.73 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10644500490536479		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.10644500490536479 | validation: 0.1138265360387984]
	TIME [epoch: 5.73 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1085425083737974		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.1085425083737974 | validation: 0.11042146427465582]
	TIME [epoch: 5.73 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1059104354651173		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.1059104354651173 | validation: 0.11637729258622209]
	TIME [epoch: 5.74 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10803263463125884		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.10803263463125884 | validation: 0.11105295465987908]
	TIME [epoch: 5.76 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10314930854796646		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.10314930854796646 | validation: 0.11334078227716711]
	TIME [epoch: 5.74 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10156581343164668		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.10156581343164668 | validation: 0.1120783662706218]
	TIME [epoch: 5.73 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10517823429302903		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.10517823429302903 | validation: 0.11896636533213206]
	TIME [epoch: 5.73 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10725614033153844		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.10725614033153844 | validation: 0.11451796700901472]
	TIME [epoch: 5.73 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11212095626672479		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.11212095626672479 | validation: 0.12163195726702697]
	TIME [epoch: 5.74 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11086587591914672		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.11086587591914672 | validation: 0.11850436473090449]
	TIME [epoch: 5.78 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038116521841404		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.11038116521841404 | validation: 0.10231603469202664]
	TIME [epoch: 5.73 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10777473264494042		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.10777473264494042 | validation: 0.0916026174473801]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_1469.pth
	Model improved!!!
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10566073033438095		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.10566073033438095 | validation: 0.10365229985353402]
	TIME [epoch: 5.74 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11348338222241997		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.11348338222241997 | validation: 0.09827997591162507]
	TIME [epoch: 5.73 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114921575132301		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.1114921575132301 | validation: 0.10807869451532096]
	TIME [epoch: 5.73 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1013032553198051		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.1013032553198051 | validation: 0.10563018917115176]
	TIME [epoch: 5.76 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10592691183292333		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.10592691183292333 | validation: 0.0991490753754804]
	TIME [epoch: 5.74 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10613623582690243		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.10613623582690243 | validation: 0.10904920184324592]
	TIME [epoch: 5.73 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10697927741052182		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.10697927741052182 | validation: 0.113013081398582]
	TIME [epoch: 5.74 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10791595808220125		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.10791595808220125 | validation: 0.10633980897471837]
	TIME [epoch: 5.74 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11142812086790539		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.11142812086790539 | validation: 0.10556817342727552]
	TIME [epoch: 5.74 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060264477459418		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.1060264477459418 | validation: 0.10441779029616459]
	TIME [epoch: 5.77 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1092957710635139		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.1092957710635139 | validation: 0.11052784649782392]
	TIME [epoch: 5.75 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10539842997381642		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.10539842997381642 | validation: 0.10088275097095437]
	TIME [epoch: 5.73 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11187131532460749		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.11187131532460749 | validation: 0.1077394293650976]
	TIME [epoch: 5.73 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10427839255625101		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.10427839255625101 | validation: 0.09834407719458474]
	TIME [epoch: 5.73 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103775120036044		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.103775120036044 | validation: 0.10818946763977355]
	TIME [epoch: 5.74 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10685298577022337		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.10685298577022337 | validation: 0.1112511300816253]
	TIME [epoch: 5.76 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10860338493408585		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.10860338493408585 | validation: 0.10466104997159287]
	TIME [epoch: 5.74 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10645887533782408		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.10645887533782408 | validation: 0.10534992181557598]
	TIME [epoch: 5.73 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10232582843866807		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.10232582843866807 | validation: 0.12440746711101054]
	TIME [epoch: 5.73 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10761386439674975		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.10761386439674975 | validation: 0.11400378075555277]
	TIME [epoch: 5.73 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.111483545890222		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.111483545890222 | validation: 0.13024499712093157]
	TIME [epoch: 5.73 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11072533929033519		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.11072533929033519 | validation: 0.12496742419057638]
	TIME [epoch: 5.77 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10121058093115269		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.10121058093115269 | validation: 0.11642536176175511]
	TIME [epoch: 5.73 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10449016880226827		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.10449016880226827 | validation: 0.12712997612630486]
	TIME [epoch: 5.74 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10660856707763998		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.10660856707763998 | validation: 0.12473847435895924]
	TIME [epoch: 5.74 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10239584674696324		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.10239584674696324 | validation: 0.12848758263529533]
	TIME [epoch: 5.73 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10428442078366372		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.10428442078366372 | validation: 0.12159109675730971]
	TIME [epoch: 5.74 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291671231328965		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.10291671231328965 | validation: 0.1147132478446245]
	TIME [epoch: 5.76 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10059725331658056		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.10059725331658056 | validation: 0.12352510761574499]
	TIME [epoch: 5.73 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09990766485446759		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.09990766485446759 | validation: 0.12619718592857326]
	TIME [epoch: 5.75 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10339468013599784		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.10339468013599784 | validation: 0.12561831396813422]
	TIME [epoch: 5.73 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10000752149277009		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.10000752149277009 | validation: 0.11111667470848322]
	TIME [epoch: 5.73 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10268991452084839		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.10268991452084839 | validation: 0.11865407240643247]
	TIME [epoch: 5.74 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10329627785540482		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.10329627785540482 | validation: 0.1181419437058516]
	TIME [epoch: 5.76 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09710029803200376		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.09710029803200376 | validation: 0.12156302418249543]
	TIME [epoch: 5.73 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10164479746029476		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.10164479746029476 | validation: 0.11006553181506014]
	TIME [epoch: 5.73 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10713013426834095		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.10713013426834095 | validation: 0.11637570269535318]
	TIME [epoch: 5.73 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10454472715758487		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.10454472715758487 | validation: 0.11807684287880216]
	TIME [epoch: 5.73 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10379630501063823		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.10379630501063823 | validation: 0.11575384219043759]
	TIME [epoch: 5.74 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10250083667638013		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.10250083667638013 | validation: 0.12335126699414083]
	TIME [epoch: 5.76 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10125306076868607		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.10125306076868607 | validation: 0.11351322008892269]
	TIME [epoch: 5.73 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10224157765497524		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.10224157765497524 | validation: 0.10758662208786714]
	TIME [epoch: 5.73 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10405793879333175		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.10405793879333175 | validation: 0.10909206924200908]
	TIME [epoch: 5.72 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1045588964229047		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.1045588964229047 | validation: 0.11611620558575787]
	TIME [epoch: 5.73 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10350327304341646		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.10350327304341646 | validation: 0.11151581574937237]
	TIME [epoch: 5.74 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1093166104663558		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.1093166104663558 | validation: 0.10763515286966431]
	TIME [epoch: 5.75 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10758142284501868		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.10758142284501868 | validation: 0.11070169640662442]
	TIME [epoch: 5.73 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103333298190641		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.103333298190641 | validation: 0.11000888976397018]
	TIME [epoch: 5.73 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10638440126671236		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.10638440126671236 | validation: 0.10727077804957133]
	TIME [epoch: 5.73 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1021409095720544		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.1021409095720544 | validation: 0.1050997478758064]
	TIME [epoch: 5.73 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10272715774702268		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.10272715774702268 | validation: 0.10743031049243036]
	TIME [epoch: 5.75 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573231280294917		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.10573231280294917 | validation: 0.12333364652122365]
	TIME [epoch: 5.76 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10191828534329561		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.10191828534329561 | validation: 0.10476973794664378]
	TIME [epoch: 5.74 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09915379400519586		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.09915379400519586 | validation: 0.10922630683849327]
	TIME [epoch: 5.73 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10470947167072711		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.10470947167072711 | validation: 0.10671497256906069]
	TIME [epoch: 5.73 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10508583913161645		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.10508583913161645 | validation: 0.10125820244925629]
	TIME [epoch: 5.73 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10772785615237995		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.10772785615237995 | validation: 0.10605824680434654]
	TIME [epoch: 5.75 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10862040894465831		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.10862040894465831 | validation: 0.1027869348993423]
	TIME [epoch: 5.75 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10562575102603801		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.10562575102603801 | validation: 0.10524177032330907]
	TIME [epoch: 5.73 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10516755415840205		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.10516755415840205 | validation: 0.10364210761608696]
	TIME [epoch: 5.73 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10394790018390224		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.10394790018390224 | validation: 0.11556564589673869]
	TIME [epoch: 5.74 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10359536405927805		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.10359536405927805 | validation: 0.10819810622074981]
	TIME [epoch: 5.73 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10298366387142488		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.10298366387142488 | validation: 0.11749191280426466]
	TIME [epoch: 5.74 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1010109328085482		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.1010109328085482 | validation: 0.10735583583631556]
	TIME [epoch: 5.76 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10133952471472679		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.10133952471472679 | validation: 0.1144887164043157]
	TIME [epoch: 5.73 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10054821791937801		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.10054821791937801 | validation: 0.11470018344078727]
	TIME [epoch: 5.73 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10227277916377157		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.10227277916377157 | validation: 0.10739601367384388]
	TIME [epoch: 5.73 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10469048980164612		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.10469048980164612 | validation: 0.10314115920681144]
	TIME [epoch: 5.73 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10198801853779045		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.10198801853779045 | validation: 0.10498174639239687]
	TIME [epoch: 5.75 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993338943395266		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.09993338943395266 | validation: 0.09955046213287283]
	TIME [epoch: 5.76 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0955248691677443		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.0955248691677443 | validation: 0.10562279381344525]
	TIME [epoch: 5.73 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09978088655148241		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.09978088655148241 | validation: 0.11048065756208543]
	TIME [epoch: 5.74 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09979378757652409		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.09979378757652409 | validation: 0.10344753140454054]
	TIME [epoch: 5.73 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09972325871990825		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.09972325871990825 | validation: 0.1072582153663928]
	TIME [epoch: 5.74 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10690216341402389		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.10690216341402389 | validation: 0.10387342582946409]
	TIME [epoch: 5.75 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09495238568328437		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.09495238568328437 | validation: 0.10208984727352158]
	TIME [epoch: 5.77 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09770507623577099		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.09770507623577099 | validation: 0.10466600598893716]
	TIME [epoch: 5.74 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09827509270390068		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.09827509270390068 | validation: 0.10819614627677832]
	TIME [epoch: 5.74 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10091994207711391		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.10091994207711391 | validation: 0.10882005213003758]
	TIME [epoch: 5.74 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10364398538486055		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.10364398538486055 | validation: 0.10935791832903323]
	TIME [epoch: 5.75 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10180530224972968		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.10180530224972968 | validation: 0.1131272638128252]
	TIME [epoch: 5.76 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10469435647908162		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.10469435647908162 | validation: 0.11919804297810949]
	TIME [epoch: 5.75 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10149086130832453		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.10149086130832453 | validation: 0.11383680045608856]
	TIME [epoch: 5.74 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10084177583412332		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.10084177583412332 | validation: 0.1069356267838886]
	TIME [epoch: 5.74 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09804068549365469		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.09804068549365469 | validation: 0.10726155458046922]
	TIME [epoch: 5.74 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1012105871465095		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.1012105871465095 | validation: 0.11210814450524254]
	TIME [epoch: 5.73 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10213877977720277		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.10213877977720277 | validation: 0.112773224051492]
	TIME [epoch: 5.76 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10635960186645141		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.10635960186645141 | validation: 0.10483021977020107]
	TIME [epoch: 5.75 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10077138385435254		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.10077138385435254 | validation: 0.10237550585117974]
	TIME [epoch: 5.73 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1055630748063212		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.1055630748063212 | validation: 0.10336379736243734]
	TIME [epoch: 5.73 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10392526851655923		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.10392526851655923 | validation: 0.0976220854733291]
	TIME [epoch: 5.73 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10515376663738363		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.10515376663738363 | validation: 0.1043235055783262]
	TIME [epoch: 5.73 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10672677054604011		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.10672677054604011 | validation: 0.11429372172966268]
	TIME [epoch: 5.76 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10024538296562266		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.10024538296562266 | validation: 0.11634969326363705]
	TIME [epoch: 5.75 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09884494047640996		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.09884494047640996 | validation: 0.10477100719479011]
	TIME [epoch: 5.73 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10608626106906373		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.10608626106906373 | validation: 0.11174206334097354]
	TIME [epoch: 5.73 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10611882730894637		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.10611882730894637 | validation: 0.10789176132343052]
	TIME [epoch: 5.74 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10432702049950096		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.10432702049950096 | validation: 0.11217182835921573]
	TIME [epoch: 5.74 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10397678925288187		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.10397678925288187 | validation: 0.1122406062150742]
	TIME [epoch: 5.77 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10397068284253946		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.10397068284253946 | validation: 0.11209208710377457]
	TIME [epoch: 5.75 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10107777133762876		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.10107777133762876 | validation: 0.11377555841229699]
	TIME [epoch: 5.74 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10095184109050202		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.10095184109050202 | validation: 0.1030639153305993]
	TIME [epoch: 5.74 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10053602792696069		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.10053602792696069 | validation: 0.11979204069752672]
	TIME [epoch: 5.74 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10056932610680096		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.10056932610680096 | validation: 0.10667921718354496]
	TIME [epoch: 5.75 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09647150223591325		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.09647150223591325 | validation: 0.11381506864415748]
	TIME [epoch: 5.76 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10262648285066248		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.10262648285066248 | validation: 0.12406038956355174]
	TIME [epoch: 5.75 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10055045854546281		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.10055045854546281 | validation: 0.1105023794910257]
	TIME [epoch: 5.73 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10000036473815167		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.10000036473815167 | validation: 0.10724179554450068]
	TIME [epoch: 5.74 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10036065704733677		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.10036065704733677 | validation: 0.10063582572758352]
	TIME [epoch: 5.74 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10423159489368497		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.10423159489368497 | validation: 0.10969684041535571]
	TIME [epoch: 5.73 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09892070068937997		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.09892070068937997 | validation: 0.10807739458430331]
	TIME [epoch: 5.77 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10019026345717666		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.10019026345717666 | validation: 0.11201737402493173]
	TIME [epoch: 5.74 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1004531078487055		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.1004531078487055 | validation: 0.10711709229914189]
	TIME [epoch: 5.74 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10509545604876655		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.10509545604876655 | validation: 0.10389499075396001]
	TIME [epoch: 5.73 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10632548953819268		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.10632548953819268 | validation: 0.11516184453481682]
	TIME [epoch: 5.73 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10455136295921		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.10455136295921 | validation: 0.1093472397884635]
	TIME [epoch: 5.75 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09995641507656461		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.09995641507656461 | validation: 0.10638562569538497]
	TIME [epoch: 5.75 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10201873524665439		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.10201873524665439 | validation: 0.11520323573700107]
	TIME [epoch: 5.74 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10006766788997765		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.10006766788997765 | validation: 0.10148522035202948]
	TIME [epoch: 5.73 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10057505248148893		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.10057505248148893 | validation: 0.10598425512170742]
	TIME [epoch: 5.73 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10245058934936702		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.10245058934936702 | validation: 0.11081864557914084]
	TIME [epoch: 5.73 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10140577878426188		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.10140577878426188 | validation: 0.11129070392364955]
	TIME [epoch: 5.73 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0989873147042544		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.0989873147042544 | validation: 0.10177349761577738]
	TIME [epoch: 5.76 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10307628463693		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.10307628463693 | validation: 0.10972175426449374]
	TIME [epoch: 5.76 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10342705854630377		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.10342705854630377 | validation: 0.10617412491346667]
	TIME [epoch: 5.74 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09842400354120436		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.09842400354120436 | validation: 0.1098470553176236]
	TIME [epoch: 5.75 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10216754047507048		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.10216754047507048 | validation: 0.11172371547867865]
	TIME [epoch: 5.73 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09986565145589578		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.09986565145589578 | validation: 0.10279770747508357]
	TIME [epoch: 5.75 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10017535280587131		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.10017535280587131 | validation: 0.09837458333886512]
	TIME [epoch: 5.77 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10067496479454759		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.10067496479454759 | validation: 0.10254071547377513]
	TIME [epoch: 5.75 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1006318743735481		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.1006318743735481 | validation: 0.10885473950917618]
	TIME [epoch: 5.74 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10245468228789968		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.10245468228789968 | validation: 0.09890710372830722]
	TIME [epoch: 5.74 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09991708639827734		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.09991708639827734 | validation: 0.09943571788109214]
	TIME [epoch: 5.74 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10085116584825202		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.10085116584825202 | validation: 0.1099611555839991]
	TIME [epoch: 5.75 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10079480873221472		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.10079480873221472 | validation: 0.11167069989628901]
	TIME [epoch: 5.76 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10282144915644756		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.10282144915644756 | validation: 0.11604005845908391]
	TIME [epoch: 5.75 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10469505420914343		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.10469505420914343 | validation: 0.11484259128139022]
	TIME [epoch: 5.74 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09956845156344916		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.09956845156344916 | validation: 0.11326175663468385]
	TIME [epoch: 5.73 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10104244434365203		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.10104244434365203 | validation: 0.09787214076423113]
	TIME [epoch: 5.74 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10035586215862172		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.10035586215862172 | validation: 0.1279224335695416]
	TIME [epoch: 5.75 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1052841229793404		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.1052841229793404 | validation: 0.11217641337430496]
	TIME [epoch: 5.78 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200572707006603		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.10200572707006603 | validation: 0.11107384859811831]
	TIME [epoch: 5.75 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10611334324192528		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.10611334324192528 | validation: 0.10214805572634345]
	TIME [epoch: 5.74 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10381178978474118		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.10381178978474118 | validation: 0.10049313422656067]
	TIME [epoch: 5.73 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10273651848046554		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.10273651848046554 | validation: 0.10971149650523365]
	TIME [epoch: 5.74 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1086480918633527		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.1086480918633527 | validation: 0.10815490573539797]
	TIME [epoch: 5.74 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10714669529391188		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.10714669529391188 | validation: 0.11185738964181653]
	TIME [epoch: 5.78 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10657582042275655		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.10657582042275655 | validation: 0.10835292872489792]
	TIME [epoch: 5.74 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10892218344141671		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.10892218344141671 | validation: 0.11696346781109739]
	TIME [epoch: 5.72 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1082772954930461		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.1082772954930461 | validation: 0.10996129838665451]
	TIME [epoch: 5.73 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10090966129505093		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.10090966129505093 | validation: 0.09949533834488455]
	TIME [epoch: 5.73 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1007245851397902		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.1007245851397902 | validation: 0.10659821256760799]
	TIME [epoch: 5.74 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10197806730887485		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.10197806730887485 | validation: 0.10912731158338083]
	TIME [epoch: 5.77 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10318239469817851		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.10318239469817851 | validation: 0.10001384948992197]
	TIME [epoch: 5.74 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10209878017470603		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.10209878017470603 | validation: 0.1010827471684982]
	TIME [epoch: 5.74 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10339889686559212		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.10339889686559212 | validation: 0.09841094709903853]
	TIME [epoch: 5.74 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10376534136919718		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.10376534136919718 | validation: 0.10698293514520196]
	TIME [epoch: 5.74 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10586971728806649		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.10586971728806649 | validation: 0.10671534003782657]
	TIME [epoch: 5.72 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10207849264455728		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.10207849264455728 | validation: 0.1111635554501478]
	TIME [epoch: 5.77 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10522747095994638		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.10522747095994638 | validation: 0.10872170970739158]
	TIME [epoch: 5.75 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.099745897624457		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.099745897624457 | validation: 0.10389709956401859]
	TIME [epoch: 5.74 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10332593136902289		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.10332593136902289 | validation: 0.10273476938086656]
	TIME [epoch: 5.73 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09982538045988185		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.09982538045988185 | validation: 0.10347308943808432]
	TIME [epoch: 5.74 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09975798452491966		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.09975798452491966 | validation: 0.10137749832999504]
	TIME [epoch: 5.73 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1052782833907736		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.1052782833907736 | validation: 0.10604460850784253]
	TIME [epoch: 5.76 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10671825174991406		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.10671825174991406 | validation: 0.1029463185901898]
	TIME [epoch: 5.74 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09931486656148286		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.09931486656148286 | validation: 0.09717337130916605]
	TIME [epoch: 5.73 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10263877801659985		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.10263877801659985 | validation: 0.1244944993040182]
	TIME [epoch: 5.73 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10686255861756339		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.10686255861756339 | validation: 0.11932031386730675]
	TIME [epoch: 5.73 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10776339432365419		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.10776339432365419 | validation: 0.12327161614715085]
	TIME [epoch: 5.74 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10915671438399063		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.10915671438399063 | validation: 0.12765809248219298]
	TIME [epoch: 5.77 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1086635867315116		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.1086635867315116 | validation: 0.11845350216522146]
	TIME [epoch: 5.75 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10334488004815834		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.10334488004815834 | validation: 0.10848224921956917]
	TIME [epoch: 5.74 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10964965302481915		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.10964965302481915 | validation: 0.1123637442101163]
	TIME [epoch: 5.74 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10500488674562747		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.10500488674562747 | validation: 0.11362071525534605]
	TIME [epoch: 5.74 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10488168197035161		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.10488168197035161 | validation: 0.0974463699052896]
	TIME [epoch: 5.72 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10483828708034215		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.10483828708034215 | validation: 0.09770447706987426]
	TIME [epoch: 5.77 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1045787178752611		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.1045787178752611 | validation: 0.11084854556989823]
	TIME [epoch: 5.74 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10603695302415098		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.10603695302415098 | validation: 0.11446962590177737]
	TIME [epoch: 5.73 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1073685076317348		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.1073685076317348 | validation: 0.10848263532683379]
	TIME [epoch: 5.73 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10546319928848683		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.10546319928848683 | validation: 0.10288392211759564]
	TIME [epoch: 5.73 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09906383091216543		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.09906383091216543 | validation: 0.10875269753578405]
	TIME [epoch: 5.74 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10212633393189886		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.10212633393189886 | validation: 0.1037926308164732]
	TIME [epoch: 5.78 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10220749514587046		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.10220749514587046 | validation: 0.1020734808383568]
	TIME [epoch: 5.75 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10062849651914853		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.10062849651914853 | validation: 0.10673247839706825]
	TIME [epoch: 5.74 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09872922638534602		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.09872922638534602 | validation: 0.113579444647568]
	TIME [epoch: 5.73 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10527958955998705		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.10527958955998705 | validation: 0.1045035245970574]
	TIME [epoch: 5.74 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10336593088335207		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.10336593088335207 | validation: 0.10727538282625723]
	TIME [epoch: 5.73 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10005731753743824		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.10005731753743824 | validation: 0.10998396432162616]
	TIME [epoch: 5.78 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10408944298291758		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.10408944298291758 | validation: 0.09478162293395681]
	TIME [epoch: 5.74 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10347940231138372		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.10347940231138372 | validation: 0.10457020109248363]
	TIME [epoch: 5.73 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10233484498831942		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.10233484498831942 | validation: 0.10388566513531063]
	TIME [epoch: 5.73 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10002383090706402		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.10002383090706402 | validation: 0.10921490751874213]
	TIME [epoch: 5.74 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10148649331015835		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.10148649331015835 | validation: 0.10493805115478068]
	TIME [epoch: 5.73 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10000061216775046		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.10000061216775046 | validation: 0.10697777978182693]
	TIME [epoch: 5.77 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10055032455299806		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.10055032455299806 | validation: 0.10837697934336354]
	TIME [epoch: 5.73 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09859995632432299		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.09859995632432299 | validation: 0.10283181591210838]
	TIME [epoch: 5.73 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.101614144328629		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.101614144328629 | validation: 0.10625682147106828]
	TIME [epoch: 5.73 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10078639092971836		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.10078639092971836 | validation: 0.10739822518119091]
	TIME [epoch: 5.73 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10025903615963172		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.10025903615963172 | validation: 0.09146211191747203]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240310_003040/states/model_tr_study1_1669.pth
	Model improved!!!
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0971048862970949		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.0971048862970949 | validation: 0.11343211876538721]
	TIME [epoch: 5.77 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09972825433757426		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.09972825433757426 | validation: 0.10182510645522776]
	TIME [epoch: 5.73 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09855759160632743		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.09855759160632743 | validation: 0.09513379646933773]
	TIME [epoch: 5.73 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10190552644391952		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.10190552644391952 | validation: 0.09626189852045337]
	TIME [epoch: 5.73 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10496048005355826		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.10496048005355826 | validation: 0.09777481726318107]
	TIME [epoch: 5.73 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09920779211231888		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.09920779211231888 | validation: 0.10806821955175966]
	TIME [epoch: 5.73 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10510258790865437		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.10510258790865437 | validation: 0.10406420031522978]
	TIME [epoch: 5.77 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10247931538262192		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.10247931538262192 | validation: 0.0957350951089514]
	TIME [epoch: 5.73 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10366006527213079		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.10366006527213079 | validation: 0.09686887924162864]
	TIME [epoch: 5.73 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10270759346638973		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.10270759346638973 | validation: 0.10295453405294096]
	TIME [epoch: 5.73 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10239959157462557		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.10239959157462557 | validation: 0.09669130913644043]
	TIME [epoch: 5.73 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10256971147106064		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.10256971147106064 | validation: 0.09819938984267516]
	TIME [epoch: 5.73 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09783245956576962		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.09783245956576962 | validation: 0.09375733376421706]
	TIME [epoch: 5.76 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10205223244619423		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.10205223244619423 | validation: 0.09713032432658308]
	TIME [epoch: 5.73 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1058642742635985		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.1058642742635985 | validation: 0.10122213045635123]
	TIME [epoch: 5.72 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10762247072507779		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.10762247072507779 | validation: 0.10209997676411792]
	TIME [epoch: 5.73 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10504173778871592		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.10504173778871592 | validation: 0.10174071758584362]
	TIME [epoch: 5.73 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10315749890499604		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.10315749890499604 | validation: 0.10255025053948748]
	TIME [epoch: 5.74 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10388102787577214		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.10388102787577214 | validation: 0.10571054122166391]
	TIME [epoch: 5.77 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10034381152381343		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.10034381152381343 | validation: 0.09475018531457163]
	TIME [epoch: 5.73 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09803602573426604		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.09803602573426604 | validation: 0.10159802597714288]
	TIME [epoch: 5.73 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10160005189423794		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.10160005189423794 | validation: 0.09987874481489219]
	TIME [epoch: 5.73 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09935409145307442		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.09935409145307442 | validation: 0.10231388777288941]
	TIME [epoch: 5.73 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09755947591812791		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.09755947591812791 | validation: 0.10026472170079202]
	TIME [epoch: 5.74 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09837661247358932		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.09837661247358932 | validation: 0.09821460897820565]
	TIME [epoch: 5.77 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09695935185937099		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.09695935185937099 | validation: 0.10525481230368662]
	TIME [epoch: 5.73 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10229155319089463		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.10229155319089463 | validation: 0.11103662261957215]
	TIME [epoch: 5.72 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10110208411183748		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.10110208411183748 | validation: 0.10985767678519105]
	TIME [epoch: 5.73 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10104783167615572		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.10104783167615572 | validation: 0.10780752227595285]
	TIME [epoch: 5.74 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1017377077666628		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.1017377077666628 | validation: 0.11023353579889737]
	TIME [epoch: 5.74 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10362998906219034		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.10362998906219034 | validation: 0.10643372956863704]
	TIME [epoch: 5.75 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1040163074513029		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.1040163074513029 | validation: 0.11486856706375516]
	TIME [epoch: 5.73 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10276038362475051		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.10276038362475051 | validation: 0.10501377552395436]
	TIME [epoch: 5.73 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10020052033449207		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.10020052033449207 | validation: 0.10487974236134218]
	TIME [epoch: 5.73 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10020749539198154		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.10020749539198154 | validation: 0.10333001808648859]
	TIME [epoch: 5.74 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09786341503850833		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.09786341503850833 | validation: 0.10339511305213163]
	TIME [epoch: 5.74 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10355464168910641		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.10355464168910641 | validation: 0.10834155484669587]
	TIME [epoch: 5.76 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09486847850922835		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.09486847850922835 | validation: 0.11829297870308436]
	TIME [epoch: 5.75 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10614252427804809		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.10614252427804809 | validation: 0.11340203235473845]
	TIME [epoch: 5.73 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10210782066456264		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.10210782066456264 | validation: 0.11889893877164834]
	TIME [epoch: 5.74 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10232404968894335		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.10232404968894335 | validation: 0.11227233246310596]
	TIME [epoch: 5.74 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09810652504133714		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.09810652504133714 | validation: 0.10280745569639958]
	TIME [epoch: 5.75 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09984163486618029		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.09984163486618029 | validation: 0.10877506697438633]
	TIME [epoch: 5.77 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1017763763152074		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.1017763763152074 | validation: 0.10871433435094512]
	TIME [epoch: 5.74 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10263489955734226		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.10263489955734226 | validation: 0.1021032724266244]
	TIME [epoch: 5.74 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10204229696388875		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.10204229696388875 | validation: 0.10516424572782875]
	TIME [epoch: 5.73 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09884853290461743		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.09884853290461743 | validation: 0.11062655955964362]
	TIME [epoch: 5.73 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09774452053928007		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.09774452053928007 | validation: 0.1018582082100695]
	TIME [epoch: 5.74 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10101193805082237		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.10101193805082237 | validation: 0.111190508939307]
	TIME [epoch: 5.77 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09794490722767159		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.09794490722767159 | validation: 0.11036651419617488]
	TIME [epoch: 5.73 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09655542489268819		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.09655542489268819 | validation: 0.10816140864044627]
	TIME [epoch: 5.73 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10070373452509916		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.10070373452509916 | validation: 0.11009576396934335]
	TIME [epoch: 5.74 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09848105674956681		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.09848105674956681 | validation: 0.09688495077581082]
	TIME [epoch: 5.74 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1013420904797738		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.1013420904797738 | validation: 0.10740387646220312]
	TIME [epoch: 5.76 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933053626656843		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.09933053626656843 | validation: 0.09898609138450173]
	TIME [epoch: 5.76 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10293794111212348		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.10293794111212348 | validation: 0.10709260342554351]
	TIME [epoch: 5.75 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993335672818603		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.09993335672818603 | validation: 0.11192554215751244]
	TIME [epoch: 5.74 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09977714530860463		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.09977714530860463 | validation: 0.10900476187639443]
	TIME [epoch: 5.73 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09783660293648723		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.09783660293648723 | validation: 0.10944356258060355]
	TIME [epoch: 5.73 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09970162525265025		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.09970162525265025 | validation: 0.10483091551197352]
	TIME [epoch: 5.75 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0971931765954584		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.0971931765954584 | validation: 0.11553102033005462]
	TIME [epoch: 5.75 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09739035882916736		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.09739035882916736 | validation: 0.10565058805690702]
	TIME [epoch: 5.74 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09869347195162033		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.09869347195162033 | validation: 0.11005548856875659]
	TIME [epoch: 5.74 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10019757544305642		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.10019757544305642 | validation: 0.10758294321565359]
	TIME [epoch: 5.73 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09892762996642288		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.09892762996642288 | validation: 0.10834799622814803]
	TIME [epoch: 5.74 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10260256696478301		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.10260256696478301 | validation: 0.10696426750476601]
	TIME [epoch: 5.77 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10105354190974553		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.10105354190974553 | validation: 0.1158348106607103]
	TIME [epoch: 5.74 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002037334566339		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.1002037334566339 | validation: 0.11161933765566456]
	TIME [epoch: 5.74 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09797428424838824		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.09797428424838824 | validation: 0.10014792300478949]
	TIME [epoch: 5.75 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09977988579852641		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.09977988579852641 | validation: 0.12015330200580572]
	TIME [epoch: 5.73 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0972930482344159		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.0972930482344159 | validation: 0.11119031996987999]
	TIME [epoch: 5.74 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10210131717285573		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.10210131717285573 | validation: 0.10696040522678883]
	TIME [epoch: 5.76 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0991521825405847		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.0991521825405847 | validation: 0.11038238450266341]
	TIME [epoch: 5.76 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10129432192455497		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.10129432192455497 | validation: 0.1130014126077441]
	TIME [epoch: 5.74 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10187601251893202		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.10187601251893202 | validation: 0.1040765473058671]
	TIME [epoch: 5.75 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10139156385568444		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.10139156385568444 | validation: 0.11069401340127835]
	TIME [epoch: 5.74 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10424698043111798		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.10424698043111798 | validation: 0.1130294944794311]
	TIME [epoch: 5.73 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10025577544048259		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.10025577544048259 | validation: 0.10941470196097086]
	TIME [epoch: 5.76 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09861521436361138		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.09861521436361138 | validation: 0.10146015445715327]
	TIME [epoch: 5.74 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10496629200260549		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.10496629200260549 | validation: 0.10738545904180984]
	TIME [epoch: 5.73 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10114935555696597		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.10114935555696597 | validation: 0.10401090530269504]
	TIME [epoch: 5.73 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09779950073206065		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.09779950073206065 | validation: 0.10554429164692307]
	TIME [epoch: 5.73 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09898165682235605		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.09898165682235605 | validation: 0.10445211768331192]
	TIME [epoch: 5.73 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10240633060098649		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.10240633060098649 | validation: 0.11372939768475135]
	TIME [epoch: 5.77 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09488260640016269		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.09488260640016269 | validation: 0.11300173981995572]
	TIME [epoch: 5.75 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10032637417326817		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.10032637417326817 | validation: 0.10655628809011028]
	TIME [epoch: 5.73 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09803380850813949		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.09803380850813949 | validation: 0.11083045080886468]
	TIME [epoch: 5.73 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10064610548448033		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.10064610548448033 | validation: 0.11578877002379777]
	TIME [epoch: 5.73 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993826450187636		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.0993826450187636 | validation: 0.10819210701872173]
	TIME [epoch: 5.74 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1019968651018795		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.1019968651018795 | validation: 0.09887456636003851]
	TIME [epoch: 5.77 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09910349068269689		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.09910349068269689 | validation: 0.11537819394445943]
	TIME [epoch: 5.74 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10261066100466806		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.10261066100466806 | validation: 0.1186368346818502]
	TIME [epoch: 5.73 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10111061451499377		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.10111061451499377 | validation: 0.11707889232333477]
	TIME [epoch: 5.73 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10079767300251363		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.10079767300251363 | validation: 0.10758168056188827]
	TIME [epoch: 5.73 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10491381454875187		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.10491381454875187 | validation: 0.10347189234179567]
	TIME [epoch: 5.73 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09664223443593238		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.09664223443593238 | validation: 0.10269776356925152]
	TIME [epoch: 5.76 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10269026932343144		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.10269026932343144 | validation: 0.10077429139572272]
	TIME [epoch: 5.74 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10038586858172362		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.10038586858172362 | validation: 0.11526317011818683]
	TIME [epoch: 5.73 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10031996260615532		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.10031996260615532 | validation: 0.10720800119494034]
	TIME [epoch: 5.73 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09844727363701941		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.09844727363701941 | validation: 0.10489253717874532]
	TIME [epoch: 5.73 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10001347691164934		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.10001347691164934 | validation: 0.1146932908376941]
	TIME [epoch: 5.73 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993319346264793		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.0993319346264793 | validation: 0.10892283859162596]
	TIME [epoch: 5.76 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10004983422889237		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.10004983422889237 | validation: 0.11820124765665993]
	TIME [epoch: 5.75 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10292002020357617		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.10292002020357617 | validation: 0.1090133057149156]
	TIME [epoch: 5.73 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09953233336899088		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.09953233336899088 | validation: 0.10622892968271139]
	TIME [epoch: 5.73 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09799620993511726		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.09799620993511726 | validation: 0.10459724664698293]
	TIME [epoch: 5.73 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10003828924150984		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.10003828924150984 | validation: 0.11425598741182698]
	TIME [epoch: 5.73 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09772228545640194		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.09772228545640194 | validation: 0.10513545823233739]
	TIME [epoch: 5.78 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10102025869878813		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.10102025869878813 | validation: 0.11186728141801075]
	TIME [epoch: 5.75 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09618587661565396		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.09618587661565396 | validation: 0.10917435594298709]
	TIME [epoch: 5.73 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09950376217875517		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.09950376217875517 | validation: 0.10509951087201884]
	TIME [epoch: 5.74 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09668856447485555		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.09668856447485555 | validation: 0.10512341044507383]
	TIME [epoch: 5.73 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09874072259436213		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.09874072259436213 | validation: 0.11221066978172967]
	TIME [epoch: 5.73 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0996417297540942		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.0996417297540942 | validation: 0.10207498543471903]
	TIME [epoch: 5.78 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09692796268629604		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.09692796268629604 | validation: 0.10930145627617582]
	TIME [epoch: 5.75 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09908116488044746		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.09908116488044746 | validation: 0.10458805098439701]
	TIME [epoch: 5.74 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09870250575728087		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.09870250575728087 | validation: 0.10000470044771341]
	TIME [epoch: 5.74 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09996016841284873		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.09996016841284873 | validation: 0.09436981071984278]
	TIME [epoch: 5.73 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09941626083169042		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.09941626083169042 | validation: 0.11147666614937371]
	TIME [epoch: 5.74 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10203593205424129		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.10203593205424129 | validation: 0.10279274397958997]
	TIME [epoch: 5.77 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10095490448146366		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.10095490448146366 | validation: 0.09807817326285806]
	TIME [epoch: 5.74 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09804175700154323		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.09804175700154323 | validation: 0.09858885267835799]
	TIME [epoch: 5.75 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002197162140499		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.1002197162140499 | validation: 0.09866780557126355]
	TIME [epoch: 5.73 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10058361527407801		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.10058361527407801 | validation: 0.09384429527873187]
	TIME [epoch: 5.73 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10027033690864166		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.10027033690864166 | validation: 0.09807381705655932]
	TIME [epoch: 5.73 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09574801581196474		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.09574801581196474 | validation: 0.09646233542386894]
	TIME [epoch: 5.77 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890212587226649		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.09890212587226649 | validation: 0.10424801528121494]
	TIME [epoch: 5.74 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09772302063559463		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.09772302063559463 | validation: 0.10232837887231411]
	TIME [epoch: 5.74 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09923634354284398		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.09923634354284398 | validation: 0.10618297999113858]
	TIME [epoch: 5.74 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10213815945843042		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.10213815945843042 | validation: 0.10428533024480764]
	TIME [epoch: 5.73 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09972788450470663		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.09972788450470663 | validation: 0.09859681550070476]
	TIME [epoch: 5.73 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09484353115707311		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.09484353115707311 | validation: 0.11198586753135527]
	TIME [epoch: 5.77 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09955725903434842		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.09955725903434842 | validation: 0.10934074800426802]
	TIME [epoch: 5.74 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09914649109604862		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.09914649109604862 | validation: 0.10066851518922476]
	TIME [epoch: 5.73 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09894824753735713		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.09894824753735713 | validation: 0.1042000887650822]
	TIME [epoch: 5.73 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10128501691149791		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.10128501691149791 | validation: 0.0962598234139741]
	TIME [epoch: 5.74 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10118907971065787		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.10118907971065787 | validation: 0.1058780794340379]
	TIME [epoch: 5.74 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10107190193800679		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.10107190193800679 | validation: 0.09873898416197249]
	TIME [epoch: 5.78 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09880547029491116		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.09880547029491116 | validation: 0.10512125665745745]
	TIME [epoch: 5.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10151715767475508		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.10151715767475508 | validation: 0.10297447048452857]
	TIME [epoch: 5.73 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10088622884220444		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.10088622884220444 | validation: 0.11103953659234715]
	TIME [epoch: 5.73 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10033916424818054		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.10033916424818054 | validation: 0.11054883180915209]
	TIME [epoch: 5.75 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10296600872339387		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.10296600872339387 | validation: 0.10596049468590407]
	TIME [epoch: 5.73 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0980959956503147		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.0980959956503147 | validation: 0.11129632415917964]
	TIME [epoch: 5.77 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10039265628438226		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.10039265628438226 | validation: 0.10371831540521412]
	TIME [epoch: 5.75 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10020184141623287		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.10020184141623287 | validation: 0.10617952696130788]
	TIME [epoch: 5.73 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09977372161349107		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.09977372161349107 | validation: 0.10490165795319734]
	TIME [epoch: 5.74 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09790733964309964		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.09790733964309964 | validation: 0.10425720295358375]
	TIME [epoch: 5.75 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10059781235519806		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.10059781235519806 | validation: 0.10465386823340943]
	TIME [epoch: 5.75 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09850071081522521		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.09850071081522521 | validation: 0.09992335201836201]
	TIME [epoch: 5.78 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10108588007554661		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.10108588007554661 | validation: 0.09953658000205753]
	TIME [epoch: 5.74 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09716083544456501		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.09716083544456501 | validation: 0.10677798826022476]
	TIME [epoch: 5.73 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09953766022935867		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.09953766022935867 | validation: 0.0994890520334788]
	TIME [epoch: 5.74 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09734649753335162		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.09734649753335162 | validation: 0.10293843101570144]
	TIME [epoch: 5.73 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09493278656765317		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.09493278656765317 | validation: 0.10433451135245957]
	TIME [epoch: 5.73 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09756885901056704		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.09756885901056704 | validation: 0.11218611228542004]
	TIME [epoch: 5.77 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993627200147606		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.0993627200147606 | validation: 0.10999996903184865]
	TIME [epoch: 5.75 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09740203742423721		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.09740203742423721 | validation: 0.09943129705103505]
	TIME [epoch: 5.73 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.098379906251016		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.098379906251016 | validation: 0.10289010740135435]
	TIME [epoch: 5.74 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10139622133495615		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.10139622133495615 | validation: 0.10201834572300167]
	TIME [epoch: 5.74 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09829660771766646		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.09829660771766646 | validation: 0.10593770852566857]
	TIME [epoch: 5.74 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09825525988541553		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.09825525988541553 | validation: 0.10642703134178501]
	TIME [epoch: 5.77 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09998753921839379		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.09998753921839379 | validation: 0.10517241063298877]
	TIME [epoch: 5.74 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10063138803753732		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.10063138803753732 | validation: 0.113255754665792]
	TIME [epoch: 5.74 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10184137808849796		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.10184137808849796 | validation: 0.10286484148111733]
	TIME [epoch: 5.74 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573376277166352		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.10573376277166352 | validation: 0.10502774019339196]
	TIME [epoch: 5.74 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10316781673465812		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.10316781673465812 | validation: 0.11016784282808806]
	TIME [epoch: 5.75 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10016309799415786		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.10016309799415786 | validation: 0.10584946342797912]
	TIME [epoch: 5.76 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10151692305164198		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.10151692305164198 | validation: 0.10913062132642981]
	TIME [epoch: 5.75 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09954806354365514		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.09954806354365514 | validation: 0.1066631705205933]
	TIME [epoch: 5.75 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09903475116270441		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.09903475116270441 | validation: 0.10272801264444098]
	TIME [epoch: 5.74 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967653344197872		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.0967653344197872 | validation: 0.11566858996557113]
	TIME [epoch: 5.75 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10079399432752939		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.10079399432752939 | validation: 0.11015321231351452]
	TIME [epoch: 5.73 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10014374551240286		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.10014374551240286 | validation: 0.10918537964955109]
	TIME [epoch: 5.78 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10261556568271907		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.10261556568271907 | validation: 0.10256524098617671]
	TIME [epoch: 5.73 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09938049951198707		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.09938049951198707 | validation: 0.11309071800543319]
	TIME [epoch: 5.75 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10229239390779295		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.10229239390779295 | validation: 0.098714070736428]
	TIME [epoch: 5.72 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10082942403802701		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.10082942403802701 | validation: 0.09909132480341282]
	TIME [epoch: 5.75 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09789636491186131		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.09789636491186131 | validation: 0.10685348056729936]
	TIME [epoch: 5.73 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09905797913823558		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.09905797913823558 | validation: 0.1078581820293077]
	TIME [epoch: 5.78 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10210386934693137		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.10210386934693137 | validation: 0.10255183816864101]
	TIME [epoch: 5.73 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10087321462210395		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.10087321462210395 | validation: 0.10887178181973207]
	TIME [epoch: 5.75 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10047421609181245		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.10047421609181245 | validation: 0.1030489468809018]
	TIME [epoch: 5.74 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09659708697961877		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.09659708697961877 | validation: 0.10715216846492333]
	TIME [epoch: 5.75 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09887643056628641		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.09887643056628641 | validation: 0.1040429715248655]
	TIME [epoch: 5.74 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09725402722638933		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.09725402722638933 | validation: 0.1061651902799504]
	TIME [epoch: 5.78 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09940899393756635		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.09940899393756635 | validation: 0.10854259514750801]
	TIME [epoch: 5.73 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10179598675025353		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.10179598675025353 | validation: 0.10357978433285638]
	TIME [epoch: 5.74 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09705199124554853		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.09705199124554853 | validation: 0.10734932263150551]
	TIME [epoch: 5.74 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10195940625724594		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.10195940625724594 | validation: 0.10695836111250451]
	TIME [epoch: 5.74 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0997107975779758		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.0997107975779758 | validation: 0.1079725794095598]
	TIME [epoch: 5.74 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1008160466644735		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.1008160466644735 | validation: 0.11274392774176725]
	TIME [epoch: 5.76 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09628050278322947		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.09628050278322947 | validation: 0.10402659119256852]
	TIME [epoch: 5.73 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0994724174915173		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.0994724174915173 | validation: 0.1070497333554487]
	TIME [epoch: 5.72 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09732252021873977		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.09732252021873977 | validation: 0.10790099214131264]
	TIME [epoch: 5.74 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0998772444652139		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.0998772444652139 | validation: 0.11251884484746215]
	TIME [epoch: 5.74 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09980920200593693		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.09980920200593693 | validation: 0.0953246598861105]
	TIME [epoch: 5.75 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09805700277131638		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.09805700277131638 | validation: 0.11447844879799308]
	TIME [epoch: 5.75 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0992218442653206		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.0992218442653206 | validation: 0.10574306721387984]
	TIME [epoch: 5.73 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09817304052543653		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.09817304052543653 | validation: 0.10920574057012336]
	TIME [epoch: 5.73 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10139929597537645		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.10139929597537645 | validation: 0.11429913079690301]
	TIME [epoch: 5.75 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933762338526254		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.09933762338526254 | validation: 0.10918865073737057]
	TIME [epoch: 5.73 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10036154604973924		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.10036154604973924 | validation: 0.11027835057882827]
	TIME [epoch: 5.76 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09700277613069828		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.09700277613069828 | validation: 0.10831349642674255]
	TIME [epoch: 5.76 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10030470247431822		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.10030470247431822 | validation: 0.10832969169090916]
	TIME [epoch: 5.73 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1000835005963228		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.1000835005963228 | validation: 0.1078999951071199]
	TIME [epoch: 5.73 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10049692786850098		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.10049692786850098 | validation: 0.11071933259238355]
	TIME [epoch: 5.74 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0989412586343551		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.0989412586343551 | validation: 0.1141155315018197]
	TIME [epoch: 5.73 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10251006446481661		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.10251006446481661 | validation: 0.1015449352692975]
	TIME [epoch: 5.76 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09549139671284218		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.09549139671284218 | validation: 0.11319822554501517]
	TIME [epoch: 5.77 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09844789722510267		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.09844789722510267 | validation: 0.12355915206899894]
	TIME [epoch: 5.72 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10175543381952924		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.10175543381952924 | validation: 0.10669916587078823]
	TIME [epoch: 5.75 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0973453292694088		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.0973453292694088 | validation: 0.1111972820007517]
	TIME [epoch: 5.73 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.096417862087374		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.096417862087374 | validation: 0.10520785123534238]
	TIME [epoch: 5.73 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0936233890988482		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.0936233890988482 | validation: 0.10653212486335206]
	TIME [epoch: 5.74 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1018640089866521		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.1018640089866521 | validation: 0.10390492302988712]
	TIME [epoch: 5.76 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09996154967580496		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.09996154967580496 | validation: 0.11011017564478494]
	TIME [epoch: 5.75 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10004839795638995		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.10004839795638995 | validation: 0.11412052814725243]
	TIME [epoch: 5.72 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09916594270751557		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.09916594270751557 | validation: 0.10936186933894376]
	TIME [epoch: 5.75 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09353653503909104		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.09353653503909104 | validation: 0.1057263935182825]
	TIME [epoch: 5.74 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09847339044707877		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.09847339044707877 | validation: 0.10284451910126699]
	TIME [epoch: 5.76 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09615341316808343		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.09615341316808343 | validation: 0.09818242700744603]
	TIME [epoch: 5.76 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09994862073141242		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.09994862073141242 | validation: 0.1079321307161037]
	TIME [epoch: 5.75 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09473978436610359		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.09473978436610359 | validation: 0.11133807871511295]
	TIME [epoch: 5.75 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09962179021132378		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.09962179021132378 | validation: 0.10651853505368272]
	TIME [epoch: 5.75 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200559262240413		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.10200559262240413 | validation: 0.10457370447309003]
	TIME [epoch: 5.72 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09874063803351235		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.09874063803351235 | validation: 0.10939850843510009]
	TIME [epoch: 5.74 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09806366203623544		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.09806366203623544 | validation: 0.09627707904989403]
	TIME [epoch: 5.76 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09802255722140227		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.09802255722140227 | validation: 0.10806957662073906]
	TIME [epoch: 5.74 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0989160959190471		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.0989160959190471 | validation: 0.10751586368086362]
	TIME [epoch: 5.73 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09929901573314748		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.09929901573314748 | validation: 0.11502815934654617]
	TIME [epoch: 5.74 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10280296737709357		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.10280296737709357 | validation: 0.10864632279340347]
	TIME [epoch: 5.73 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014369084746653		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.1014369084746653 | validation: 0.10717926719530567]
	TIME [epoch: 5.77 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09563254712289124		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.09563254712289124 | validation: 0.11595855060680091]
	TIME [epoch: 5.74 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09974277263072197		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.09974277263072197 | validation: 0.10082850563730947]
	TIME [epoch: 5.73 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.096180232367404		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.096180232367404 | validation: 0.10296933135794252]
	TIME [epoch: 5.73 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10261271410509719		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.10261271410509719 | validation: 0.10891850408603646]
	TIME [epoch: 5.74 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09489965544744067		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.09489965544744067 | validation: 0.09654212784881659]
	TIME [epoch: 5.75 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09838467755982086		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.09838467755982086 | validation: 0.11175659480134392]
	TIME [epoch: 5.76 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09805740300028815		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.09805740300028815 | validation: 0.10255749329811821]
	TIME [epoch: 5.74 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09598601927432657		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.09598601927432657 | validation: 0.1067280885203855]
	TIME [epoch: 5.73 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09770342058379908		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.09770342058379908 | validation: 0.10845723290130911]
	TIME [epoch: 5.73 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10036398583610012		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.10036398583610012 | validation: 0.10147475833510386]
	TIME [epoch: 5.73 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09584810663426427		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.09584810663426427 | validation: 0.10656300118107646]
	TIME [epoch: 5.75 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10002660804269638		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.10002660804269638 | validation: 0.10559796144483823]
	TIME [epoch: 5.77 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1021601669935687		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.1021601669935687 | validation: 0.11941100523274484]
	TIME [epoch: 5.76 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10314163724296369		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.10314163724296369 | validation: 0.10488273676380282]
	TIME [epoch: 5.72 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09588522169818363		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.09588522169818363 | validation: 0.1130363632119421]
	TIME [epoch: 5.73 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09907359731032697		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.09907359731032697 | validation: 0.10521969139105881]
	TIME [epoch: 5.74 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.098369739820556		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.098369739820556 | validation: 0.1084184423010295]
	TIME [epoch: 5.74 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10369919281514471		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.10369919281514471 | validation: 0.10668250865882818]
	TIME [epoch: 5.75 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09693028742098508		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.09693028742098508 | validation: 0.10329027234403874]
	TIME [epoch: 5.76 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09908562023936693		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.09908562023936693 | validation: 0.11261074147298934]
	TIME [epoch: 5.73 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09924612097291818		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.09924612097291818 | validation: 0.1012802071132741]
	TIME [epoch: 5.73 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09875543969483717		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.09875543969483717 | validation: 0.1144823723581618]
	TIME [epoch: 5.73 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09709614185076448		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.09709614185076448 | validation: 0.10258057721753762]
	TIME [epoch: 5.74 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09663334289463654		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.09663334289463654 | validation: 0.10897121625328214]
	TIME [epoch: 5.77 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1026280098477308		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.1026280098477308 | validation: 0.10722819460660267]
	TIME [epoch: 5.75 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09928455284823867		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.09928455284823867 | validation: 0.10827297436055477]
	TIME [epoch: 5.73 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009643427763435		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.1009643427763435 | validation: 0.1159575752897272]
	TIME [epoch: 5.73 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09363623482196087		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.09363623482196087 | validation: 0.1064234223499697]
	TIME [epoch: 5.75 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0986596348002993		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.0986596348002993 | validation: 0.10828186898868981]
	TIME [epoch: 5.73 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09945907913848095		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.09945907913848095 | validation: 0.11292178151041984]
	TIME [epoch: 5.78 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10018979063372653		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.10018979063372653 | validation: 0.10332390529008506]
	TIME [epoch: 5.76 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993298824664919		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.0993298824664919 | validation: 0.10829358385015507]
	TIME [epoch: 5.73 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09573063787142087		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.09573063787142087 | validation: 0.09979020359538464]
	TIME [epoch: 5.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09520680409943243		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.09520680409943243 | validation: 0.10982648034585105]
	TIME [epoch: 5.74 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09714523056930538		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.09714523056930538 | validation: 0.10234713453454011]
	TIME [epoch: 5.73 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10009524100378012		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.10009524100378012 | validation: 0.10753356191734253]
	TIME [epoch: 5.77 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0989586735584426		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.0989586735584426 | validation: 0.09963911451969484]
	TIME [epoch: 5.74 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09983397823858542		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.09983397823858542 | validation: 0.10447596193493933]
	TIME [epoch: 5.74 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09662843169875313		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.09662843169875313 | validation: 0.10383466801773071]
	TIME [epoch: 5.74 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.099896731266771		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.099896731266771 | validation: 0.10485207060337631]
	TIME [epoch: 5.74 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09408384082324343		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.09408384082324343 | validation: 0.10833755215448214]
	TIME [epoch: 5.74 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09662672002234808		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.09662672002234808 | validation: 0.09240345903060433]
	TIME [epoch: 5.77 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09555443788398106		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.09555443788398106 | validation: 0.10514509914079971]
	TIME [epoch: 5.74 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09594896445750131		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.09594896445750131 | validation: 0.11373183637646885]
	TIME [epoch: 5.73 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0982649440076052		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.0982649440076052 | validation: 0.10873710339186801]
	TIME [epoch: 5.73 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993398786452312		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.09993398786452312 | validation: 0.1121888205238069]
	TIME [epoch: 5.73 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09574393141811602		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.09574393141811602 | validation: 0.11003633350793916]
	TIME [epoch: 5.74 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0995203494123501		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.0995203494123501 | validation: 0.10457189124236216]
	TIME [epoch: 5.77 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10013963798819778		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.10013963798819778 | validation: 0.11241855352050471]
	TIME [epoch: 5.75 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09898873809451447		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.09898873809451447 | validation: 0.10511660477235041]
	TIME [epoch: 5.74 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09606650367017248		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.09606650367017248 | validation: 0.10474395536359676]
	TIME [epoch: 5.74 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09811884604966885		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.09811884604966885 | validation: 0.10616211639044965]
	TIME [epoch: 5.73 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09963271848464886		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.09963271848464886 | validation: 0.1005938306926107]
	TIME [epoch: 5.74 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09644654659378919		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.09644654659378919 | validation: 0.10042899987477563]
	TIME [epoch: 5.78 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09918135091248541		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.09918135091248541 | validation: 0.10341189322156645]
	TIME [epoch: 5.75 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0955241752980325		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.0955241752980325 | validation: 0.10660640517395127]
	TIME [epoch: 5.74 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09738312836126653		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.09738312836126653 | validation: 0.09481245376425128]
	TIME [epoch: 5.73 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10059276095576251		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.10059276095576251 | validation: 0.10004544294000656]
	TIME [epoch: 5.73 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09612451428483779		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.09612451428483779 | validation: 0.1010226987847403]
	TIME [epoch: 5.74 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09816665888078596		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.09816665888078596 | validation: 0.10086231159294204]
	TIME [epoch: 5.76 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10060955438461595		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.10060955438461595 | validation: 0.10912850993123324]
	TIME [epoch: 5.74 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452005074485427		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.09452005074485427 | validation: 0.10370835066933015]
	TIME [epoch: 5.73 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09594606402170071		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.09594606402170071 | validation: 0.10272376015901767]
	TIME [epoch: 5.73 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10153109088342283		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.10153109088342283 | validation: 0.10353584393639306]
	TIME [epoch: 5.74 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09740288915424206		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.09740288915424206 | validation: 0.10789361056007245]
	TIME [epoch: 5.73 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09879891756968026		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.09879891756968026 | validation: 0.10878346852836346]
	TIME [epoch: 5.78 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09919675757032594		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.09919675757032594 | validation: 0.11199582234252858]
	TIME [epoch: 5.73 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09777762720496058		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.09777762720496058 | validation: 0.09504618571211954]
	TIME [epoch: 5.73 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09888564808841985		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.09888564808841985 | validation: 0.11009075165395217]
	TIME [epoch: 5.74 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09797408670884693		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.09797408670884693 | validation: 0.10364401554783487]
	TIME [epoch: 5.74 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09781781726341743		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.09781781726341743 | validation: 0.10961463354583013]
	TIME [epoch: 5.74 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10047867242622624		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.10047867242622624 | validation: 0.10931437549482834]
	TIME [epoch: 5.77 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09974108266139517		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.09974108266139517 | validation: 0.10357928233766767]
	TIME [epoch: 5.74 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933335124957669		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.09933335124957669 | validation: 0.1043024567781221]
	TIME [epoch: 5.73 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09764363043184607		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.09764363043184607 | validation: 0.11220558014478713]
	TIME [epoch: 5.74 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890703303049961		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.09890703303049961 | validation: 0.0995032809894218]
	TIME [epoch: 5.73 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09502702927586298		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.09502702927586298 | validation: 0.10301180866584188]
	TIME [epoch: 5.73 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09648187090427503		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.09648187090427503 | validation: 0.10128163323644324]
	TIME [epoch: 5.76 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09706892158988363		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.09706892158988363 | validation: 0.10956469085735354]
	TIME [epoch: 5.75 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09857737546919637		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.09857737546919637 | validation: 0.10235547692823194]
	TIME [epoch: 5.74 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09688240064199184		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.09688240064199184 | validation: 0.10471008933512838]
	TIME [epoch: 5.73 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09773528241145474		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.09773528241145474 | validation: 0.10336704359145675]
	TIME [epoch: 5.74 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09983824653019048		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.09983824653019048 | validation: 0.10753302059067087]
	TIME [epoch: 5.73 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0994730415549552		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.0994730415549552 | validation: 0.09875903325899589]
	TIME [epoch: 5.76 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09809995680929465		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.09809995680929465 | validation: 0.10772616566792585]
	TIME [epoch: 5.73 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09728824179699685		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.09728824179699685 | validation: 0.1005320036534494]
	TIME [epoch: 5.73 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10060595329729012		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.10060595329729012 | validation: 0.09457347917918259]
	TIME [epoch: 5.73 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09758051952176534		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.09758051952176534 | validation: 0.10942637217750234]
	TIME [epoch: 5.73 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1016028381446944		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.1016028381446944 | validation: 0.104089773362594]
	TIME [epoch: 5.73 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0946748445673117		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.0946748445673117 | validation: 0.1024235282789623]
	TIME [epoch: 5.75 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10099970854232096		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.10099970854232096 | validation: 0.10168062809692131]
	TIME [epoch: 5.72 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0965492679813278		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.0965492679813278 | validation: 0.11076398153017566]
	TIME [epoch: 5.74 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09972956764237073		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.09972956764237073 | validation: 0.10780340430972808]
	TIME [epoch: 5.73 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10000940660383667		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.10000940660383667 | validation: 0.09731275289728472]
	TIME [epoch: 5.73 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09586986793762045		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.09586986793762045 | validation: 0.09682523160285314]
	TIME [epoch: 5.73 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09951451426227712		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.09951451426227712 | validation: 0.10276772660055698]
	TIME [epoch: 5.75 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09851139530499048		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.09851139530499048 | validation: 0.10972502944926524]
	TIME [epoch: 5.74 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0982966628685982		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.0982966628685982 | validation: 0.09893771355370799]
	TIME [epoch: 5.74 sec]
Finished training in 11803.227 seconds.
