Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r3', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3760815079

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.795771090678581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.795771090678581 | validation: 9.14919952297663]
	TIME [epoch: 92.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.531039831355166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.531039831355166 | validation: 6.1450185531851345]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.095844723334345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.095844723334345 | validation: 5.331696196966229]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4682251246880345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4682251246880345 | validation: 7.256215171090144]
	TIME [epoch: 5.76 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.265161107971108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.265161107971108 | validation: 5.065395275839297]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.438726257229945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.438726257229945 | validation: 5.071031652862396]
	TIME [epoch: 5.75 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.191739705137236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.191739705137236 | validation: 5.479443681284233]
	TIME [epoch: 5.73 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.400008970278258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.400008970278258 | validation: 4.755966140427279]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.244663416744432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.244663416744432 | validation: 5.074105641782321]
	TIME [epoch: 5.75 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.099132832717901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.099132832717901 | validation: 5.480873490952734]
	TIME [epoch: 5.75 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2592453427117585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2592453427117585 | validation: 4.832470331132406]
	TIME [epoch: 5.79 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.953953432731055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.953953432731055 | validation: 4.861406341670358]
	TIME [epoch: 5.75 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.996468452690888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.996468452690888 | validation: 4.854936808427404]
	TIME [epoch: 5.75 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.116360374737454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.116360374737454 | validation: 5.165754751176171]
	TIME [epoch: 5.74 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.911399790403149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.911399790403149 | validation: 4.80056609428947]
	TIME [epoch: 5.74 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.883134317749377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.883134317749377 | validation: 4.926900961169994]
	TIME [epoch: 5.73 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7013405035994795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7013405035994795 | validation: 4.963487153968597]
	TIME [epoch: 5.74 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.662508617508209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.662508617508209 | validation: 4.491668713433366]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8123682926111115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8123682926111115 | validation: 4.577282200487271]
	TIME [epoch: 5.75 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46380202614607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.46380202614607 | validation: 4.3782237031987705]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.39772771113616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.39772771113616 | validation: 4.100268329904745]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.42122991942697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.42122991942697 | validation: 4.002134071523544]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.055555874001919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.055555874001919 | validation: 4.39383965830036]
	TIME [epoch: 5.75 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.116537275468359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.116537275468359 | validation: 3.579678885020742]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.106301319773166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.106301319773166 | validation: 3.5401171846619883]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6144570471584165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6144570471584165 | validation: 4.1781785848744555]
	TIME [epoch: 5.74 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1844159293559136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1844159293559136 | validation: 3.284631501524351]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.65824764919891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.65824764919891 | validation: 3.3444179395529]
	TIME [epoch: 5.74 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3274192350143474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3274192350143474 | validation: 3.566203883133229]
	TIME [epoch: 5.74 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6659265186674252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6659265186674252 | validation: 3.0663349862764666]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.276770519341019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.276770519341019 | validation: 3.006011009735216]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0693471451186953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0693471451186953 | validation: 2.788956294378786]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8982929627166096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8982929627166096 | validation: 2.5150611703167107]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2428285093065887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2428285093065887 | validation: 2.3023952547676703]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9254830257059767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9254830257059767 | validation: 2.443932602794461]
	TIME [epoch: 5.74 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.421298566908653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.421298566908653 | validation: 3.549722557355882]
	TIME [epoch: 5.74 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.827309728145461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.827309728145461 | validation: 2.303868429373988]
	TIME [epoch: 5.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250016404649872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.250016404649872 | validation: 2.74131315056991]
	TIME [epoch: 5.74 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.817286237393926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.817286237393926 | validation: 2.088945371536617]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3507203919655604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3507203919655604 | validation: 1.72930667405427]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2194093337879193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2194093337879193 | validation: 2.334430674530736]
	TIME [epoch: 5.75 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2534454076112826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2534454076112826 | validation: 1.956838423921994]
	TIME [epoch: 5.74 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.342692854474961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.342692854474961 | validation: 1.975351647837488]
	TIME [epoch: 5.76 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.023481631558175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.023481631558175 | validation: 1.5167095794666015]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0609008034783685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0609008034783685 | validation: 1.7750925163511835]
	TIME [epoch: 5.75 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9245395346478589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9245395346478589 | validation: 1.4385733959455127]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.553753926484466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.553753926484466 | validation: 1.368297136752623]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0111653859515117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0111653859515117 | validation: 1.7231876918275766]
	TIME [epoch: 5.74 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.970065041102509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.970065041102509 | validation: 1.5527766084315533]
	TIME [epoch: 5.74 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8140158810466176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8140158810466176 | validation: 1.3300644759103422]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8142087318415498		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.8142087318415498 | validation: 2.8082738924281707]
	TIME [epoch: 5.75 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.161329610258022		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.161329610258022 | validation: 1.283636465199514]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7341370717020184		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.7341370717020184 | validation: 1.2240643085861114]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0029013747539643		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.0029013747539643 | validation: 1.4059439271160146]
	TIME [epoch: 5.75 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6569460938421772		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.6569460938421772 | validation: 1.5182915394886767]
	TIME [epoch: 5.75 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7226630639782523		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.7226630639782523 | validation: 1.6814465757555694]
	TIME [epoch: 5.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6833875918746553		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.6833875918746553 | validation: 1.594758928790626]
	TIME [epoch: 5.76 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7803449305196477		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.7803449305196477 | validation: 1.414745668664675]
	TIME [epoch: 5.75 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7462260706794104		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.7462260706794104 | validation: 2.524258712028482]
	TIME [epoch: 5.75 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9001102458005144		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.9001102458005144 | validation: 1.7082003494150055]
	TIME [epoch: 5.75 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7492357090947224		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.7492357090947224 | validation: 1.8081924734637982]
	TIME [epoch: 5.75 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6785722640857244		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.6785722640857244 | validation: 1.80850371195463]
	TIME [epoch: 5.77 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6712906708019195		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.6712906708019195 | validation: 1.4001839338450552]
	TIME [epoch: 5.79 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5796858202364916		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.5796858202364916 | validation: 1.1771351175903855]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.627462398919672		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.627462398919672 | validation: 1.4569826001673623]
	TIME [epoch: 5.75 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4633783379454401		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.4633783379454401 | validation: 2.4121343426959596]
	TIME [epoch: 5.75 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.83408349941726		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.83408349941726 | validation: 2.270845792717071]
	TIME [epoch: 5.75 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6332935098171621		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.6332935098171621 | validation: 1.5284703149873664]
	TIME [epoch: 5.75 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.887188431932373		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.887188431932373 | validation: 2.3473814265014297]
	TIME [epoch: 5.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8110366750368792		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.8110366750368792 | validation: 1.3229004064317804]
	TIME [epoch: 5.76 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5018761610029516		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.5018761610029516 | validation: 0.9896156436053762]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4774916387772004		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.4774916387772004 | validation: 1.4979305737663573]
	TIME [epoch: 5.75 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5662439736946658		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.5662439736946658 | validation: 2.2682474103359156]
	TIME [epoch: 5.75 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8408330926059473		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.8408330926059473 | validation: 1.227702080512147]
	TIME [epoch: 5.75 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5487504943949297		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.5487504943949297 | validation: 1.0855054932606254]
	TIME [epoch: 5.78 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.375083043202757		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.375083043202757 | validation: 1.2558516143618004]
	TIME [epoch: 5.76 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7164086879323857		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.7164086879323857 | validation: 1.2078664227217248]
	TIME [epoch: 5.75 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5442966363602872		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.5442966363602872 | validation: 1.3754486954384242]
	TIME [epoch: 5.75 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4943942536406796		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.4943942536406796 | validation: 1.4253208520060345]
	TIME [epoch: 5.75 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6920626997833803		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.6920626997833803 | validation: 1.1250406318536068]
	TIME [epoch: 5.76 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6793987840895803		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.6793987840895803 | validation: 1.5026914002056224]
	TIME [epoch: 5.76 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5613388656268365		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.5613388656268365 | validation: 1.227715096539885]
	TIME [epoch: 5.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5569152948861031		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.5569152948861031 | validation: 1.2565899997803929]
	TIME [epoch: 5.75 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4621841435630307		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.4621841435630307 | validation: 1.7574917129467695]
	TIME [epoch: 5.75 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6443952070391312		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.6443952070391312 | validation: 1.154404348549434]
	TIME [epoch: 5.75 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321036741299909		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.321036741299909 | validation: 5.689185096721815]
	TIME [epoch: 5.75 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1994102067697425		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.1994102067697425 | validation: 1.3852363336181999]
	TIME [epoch: 5.75 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4905986179732413		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.4905986179732413 | validation: 1.1403487884694894]
	TIME [epoch: 5.79 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.356120504076708		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.356120504076708 | validation: 1.1847363004165692]
	TIME [epoch: 5.78 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5551555958203136		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.5551555958203136 | validation: 1.8639254628139934]
	TIME [epoch: 5.76 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.544264403766939		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.544264403766939 | validation: 1.2473654480549325]
	TIME [epoch: 5.75 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.421707816743882		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.421707816743882 | validation: 1.6736266658511354]
	TIME [epoch: 5.76 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5700512498272392		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.5700512498272392 | validation: 1.2280962166028597]
	TIME [epoch: 5.75 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5266391825367973		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.5266391825367973 | validation: 1.1031114670205282]
	TIME [epoch: 5.75 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3699438885112236		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.3699438885112236 | validation: 1.1652899478287102]
	TIME [epoch: 5.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3012588408376284		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.3012588408376284 | validation: 1.0217776034330361]
	TIME [epoch: 5.75 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3570320406104952		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.3570320406104952 | validation: 1.0074832839848082]
	TIME [epoch: 5.75 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3503147043074404		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.3503147043074404 | validation: 1.2064764439015616]
	TIME [epoch: 5.75 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4187362902265759		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.4187362902265759 | validation: 1.2796186005370813]
	TIME [epoch: 5.76 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5838916481026308		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.5838916481026308 | validation: 0.9531723791252695]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2786294678978087		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.2786294678978087 | validation: 0.9671448017729185]
	TIME [epoch: 5.79 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3162078806367434		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.3162078806367434 | validation: 0.8850434711120392]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2050450029488806		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.2050450029488806 | validation: 1.3230590827556414]
	TIME [epoch: 5.76 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4544586848582621		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.4544586848582621 | validation: 1.1383618523004204]
	TIME [epoch: 5.75 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2611479510437142		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.2611479510437142 | validation: 1.0565580324086807]
	TIME [epoch: 5.75 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3568700771197755		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.3568700771197755 | validation: 0.8980529560412797]
	TIME [epoch: 5.75 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4134383670616248		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.4134383670616248 | validation: 1.0194526789144163]
	TIME [epoch: 5.76 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2997158917463563		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.2997158917463563 | validation: 1.3679748573285513]
	TIME [epoch: 5.79 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.500436375089622		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.500436375089622 | validation: 0.842525692404731]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4495487647228322		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.4495487647228322 | validation: 1.1383669004548211]
	TIME [epoch: 5.75 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3577283640983975		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.3577283640983975 | validation: 1.5077462021571983]
	TIME [epoch: 5.76 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3637221290383919		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.3637221290383919 | validation: 1.296019263943838]
	TIME [epoch: 5.75 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3057049648720427		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.3057049648720427 | validation: 1.111660360235208]
	TIME [epoch: 5.75 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2874916598574626		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.2874916598574626 | validation: 1.1818723915396934]
	TIME [epoch: 5.79 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1774487508227998		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.1774487508227998 | validation: 1.06807762842668]
	TIME [epoch: 5.76 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3007785527062334		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.3007785527062334 | validation: 0.9727677863840418]
	TIME [epoch: 5.75 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2805824951942277		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.2805824951942277 | validation: 1.0396439101590766]
	TIME [epoch: 5.75 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4056119605187734		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.4056119605187734 | validation: 1.0880217753384387]
	TIME [epoch: 5.75 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3726947639737328		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.3726947639737328 | validation: 1.0031019891193045]
	TIME [epoch: 5.75 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2817105116122867		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.2817105116122867 | validation: 1.2711570740704776]
	TIME [epoch: 5.77 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.237747971357505		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.237747971357505 | validation: 0.9648051140662822]
	TIME [epoch: 5.79 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2597814941019585		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.2597814941019585 | validation: 1.2201242409038668]
	TIME [epoch: 5.76 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2381219297250072		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.2381219297250072 | validation: 1.0464726331481862]
	TIME [epoch: 5.75 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3876941780210754		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.3876941780210754 | validation: 1.0699404199712987]
	TIME [epoch: 5.75 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.413771985856239		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.413771985856239 | validation: 1.1436931147506335]
	TIME [epoch: 5.75 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3853974592234806		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.3853974592234806 | validation: 0.8894822802474165]
	TIME [epoch: 5.75 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.393382602294995		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.393382602294995 | validation: 1.0550175655904435]
	TIME [epoch: 5.79 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3345969689791042		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.3345969689791042 | validation: 1.5554495620426116]
	TIME [epoch: 5.76 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3196494156613077		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.3196494156613077 | validation: 0.9387969706635041]
	TIME [epoch: 5.75 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1679767599021529		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.1679767599021529 | validation: 1.0942005549884568]
	TIME [epoch: 5.75 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1526783774955067		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.1526783774955067 | validation: 0.9152278982787959]
	TIME [epoch: 5.75 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3013859479500114		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.3013859479500114 | validation: 0.9102145594141549]
	TIME [epoch: 5.75 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.157549908223547		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.157549908223547 | validation: 0.8510848911224163]
	TIME [epoch: 5.77 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1546130570023474		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.1546130570023474 | validation: 1.0723061860415435]
	TIME [epoch: 5.79 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2194448790215906		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.2194448790215906 | validation: 0.7673812842543949]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4021077086055387		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.4021077086055387 | validation: 1.0379350929019113]
	TIME [epoch: 5.75 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.319037089735768		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.319037089735768 | validation: 1.427168057355459]
	TIME [epoch: 5.75 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5353227900239124		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.5353227900239124 | validation: 0.9043293724546316]
	TIME [epoch: 5.75 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1759473161435114		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.1759473161435114 | validation: 0.9333144015672705]
	TIME [epoch: 5.75 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1435233335625552		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.1435233335625552 | validation: 0.8940696837298976]
	TIME [epoch: 5.79 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2636220781273344		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.2636220781273344 | validation: 0.9426767129020212]
	TIME [epoch: 5.76 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4036466873102813		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.4036466873102813 | validation: 1.1324157440691474]
	TIME [epoch: 5.75 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3819011486117767		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.3819011486117767 | validation: 1.0451551656380786]
	TIME [epoch: 5.75 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3581870270822198		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.3581870270822198 | validation: 1.3095744718948328]
	TIME [epoch: 5.75 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3860930709819899		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.3860930709819899 | validation: 1.1260945024403985]
	TIME [epoch: 5.75 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3805011999825214		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.3805011999825214 | validation: 0.9914461297352256]
	TIME [epoch: 5.76 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4468219301799792		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.4468219301799792 | validation: 1.0346344533957004]
	TIME [epoch: 5.78 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2994793154240916		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.2994793154240916 | validation: 1.0622399635109114]
	TIME [epoch: 5.75 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235098849467664		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.235098849467664 | validation: 0.9638393177581633]
	TIME [epoch: 5.75 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3085099970686185		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.3085099970686185 | validation: 0.8094094368347218]
	TIME [epoch: 5.75 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1544493807152474		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.1544493807152474 | validation: 1.0263116496287996]
	TIME [epoch: 5.75 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7095675800982462		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.7095675800982462 | validation: 1.63670876360902]
	TIME [epoch: 5.75 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.270216941199302		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.270216941199302 | validation: 0.8732654938754418]
	TIME [epoch: 5.79 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2532270330090367		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.2532270330090367 | validation: 1.3294536341451728]
	TIME [epoch: 5.76 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1801631261753522		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.1801631261753522 | validation: 0.8101372074500534]
	TIME [epoch: 5.75 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.114942456097295		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.114942456097295 | validation: 1.0039745604254688]
	TIME [epoch: 5.75 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2092062994705786		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.2092062994705786 | validation: 0.7444812508527632]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.077903055211244		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.077903055211244 | validation: 1.0976862630133903]
	TIME [epoch: 5.75 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.180466149379666		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.180466149379666 | validation: 1.1002689652756634]
	TIME [epoch: 5.78 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1998265165497397		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.1998265165497397 | validation: 0.8139747841302222]
	TIME [epoch: 5.76 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1033172208617756		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.1033172208617756 | validation: 0.9848327007443368]
	TIME [epoch: 5.75 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1100452456141974		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.1100452456141974 | validation: 0.7289916914794512]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2080245790663515		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.2080245790663515 | validation: 0.8733135544278142]
	TIME [epoch: 5.76 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0842091933562683		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.0842091933562683 | validation: 0.7532137304601347]
	TIME [epoch: 5.75 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0502212784289877		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.0502212784289877 | validation: 0.9696126989436645]
	TIME [epoch: 5.75 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2327360851471687		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.2327360851471687 | validation: 0.8272138896674259]
	TIME [epoch: 5.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1683495322518809		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.1683495322518809 | validation: 0.9312317694236788]
	TIME [epoch: 5.75 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1071065362539918		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.1071065362539918 | validation: 0.7716168354516936]
	TIME [epoch: 5.75 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1467604770801068		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.1467604770801068 | validation: 1.0380028538532362]
	TIME [epoch: 5.75 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2617379728554816		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.2617379728554816 | validation: 0.9638960659044474]
	TIME [epoch: 5.75 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3601156314670215		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.3601156314670215 | validation: 0.8990690347496917]
	TIME [epoch: 5.75 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1298105753484493		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.1298105753484493 | validation: 1.104227557380819]
	TIME [epoch: 5.78 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1452285538203384		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.1452285538203384 | validation: 0.9666280225701789]
	TIME [epoch: 5.77 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2611631178645837		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.2611631178645837 | validation: 0.7534334481924299]
	TIME [epoch: 5.75 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.317603886545093		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.317603886545093 | validation: 1.6765411480144616]
	TIME [epoch: 5.75 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.393526623882537		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.393526623882537 | validation: 1.564113352143062]
	TIME [epoch: 5.75 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.271255444800564		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.271255444800564 | validation: 0.8207870576194983]
	TIME [epoch: 5.75 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.333701294797922		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.333701294797922 | validation: 0.901725140250109]
	TIME [epoch: 5.75 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1611157229642477		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.1611157229642477 | validation: 0.6824726280137547]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9716228243738649		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.9716228243738649 | validation: 1.003977915372816]
	TIME [epoch: 5.75 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0919349281071646		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.0919349281071646 | validation: 0.6411417041218905]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.128896093815667		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.128896093815667 | validation: 0.8322105967366532]
	TIME [epoch: 5.75 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1852182292963682		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.1852182292963682 | validation: 0.758185581509185]
	TIME [epoch: 5.75 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9358083480619656		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9358083480619656 | validation: 0.666661455130526]
	TIME [epoch: 5.75 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9721696818983657		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.9721696818983657 | validation: 0.9004094727622507]
	TIME [epoch: 5.78 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9690180683948122		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.9690180683948122 | validation: 1.30301676203056]
	TIME [epoch: 5.75 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2679815191268313		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.2679815191268313 | validation: 0.7649472543081806]
	TIME [epoch: 5.74 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0379202076690275		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.0379202076690275 | validation: 0.6383273593211816]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.852483574438361		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.852483574438361 | validation: 0.6184818784516977]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8990841462064225		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.8990841462064225 | validation: 0.7011072949796333]
	TIME [epoch: 5.73 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9236952641851182		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.9236952641851182 | validation: 0.9614099627356106]
	TIME [epoch: 5.77 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0641244838921686		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.0641244838921686 | validation: 0.6819652612675509]
	TIME [epoch: 5.76 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1151575216270413		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.1151575216270413 | validation: 0.9870721375052652]
	TIME [epoch: 5.74 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1319950095694493		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.1319950095694493 | validation: 0.6734324882873541]
	TIME [epoch: 5.73 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1518454147350523		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.1518454147350523 | validation: 0.5801802814551053]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9231660270369436		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.9231660270369436 | validation: 0.8529550177441502]
	TIME [epoch: 5.74 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0202857289200153		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.0202857289200153 | validation: 0.591657495303056]
	TIME [epoch: 5.73 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8687719601288042		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.8687719601288042 | validation: 0.6131757876956465]
	TIME [epoch: 5.77 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9850451427562785		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.9850451427562785 | validation: 0.8581286310282715]
	TIME [epoch: 5.74 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0833252320543942		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.0833252320543942 | validation: 0.7561359433966658]
	TIME [epoch: 5.73 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9124273858877758		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.9124273858877758 | validation: 0.9676730838826352]
	TIME [epoch: 5.74 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.168156982791698		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.168156982791698 | validation: 0.5511225183898154]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9836340532715547		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.9836340532715547 | validation: 0.6484906888905886]
	TIME [epoch: 5.76 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8678181978456644		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.8678181978456644 | validation: 0.5631035635992907]
	TIME [epoch: 5.79 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8038685753455496		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.8038685753455496 | validation: 0.6988326590534003]
	TIME [epoch: 5.77 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8913128316125613		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.8913128316125613 | validation: 0.5560551397115997]
	TIME [epoch: 5.76 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8526976858327504		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.8526976858327504 | validation: 0.5942706737906126]
	TIME [epoch: 5.75 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8516537372530215		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.8516537372530215 | validation: 0.5341748403146255]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8615226882347319		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.8615226882347319 | validation: 0.5054160545693251]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9008851428645849		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.9008851428645849 | validation: 0.5006263740444313]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8783917175112077		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.8783917175112077 | validation: 0.7141102337596869]
	TIME [epoch: 5.78 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0606903432941641		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.0606903432941641 | validation: 0.5684627262484285]
	TIME [epoch: 5.75 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9332592648304759		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.9332592648304759 | validation: 0.9255050987903698]
	TIME [epoch: 5.75 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9248148297330364		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.9248148297330364 | validation: 0.5680144541668062]
	TIME [epoch: 5.75 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8388432128858581		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.8388432128858581 | validation: 0.6203060822159262]
	TIME [epoch: 5.75 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8940414487845172		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.8940414487845172 | validation: 0.8016159481299582]
	TIME [epoch: 5.75 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8702791751284802		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.8702791751284802 | validation: 0.6716724761785065]
	TIME [epoch: 5.79 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9540738716712297		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.9540738716712297 | validation: 0.4634632391929808]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8245934353893072		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.8245934353893072 | validation: 1.3557570865817337]
	TIME [epoch: 5.75 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1455840443397902		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.1455840443397902 | validation: 1.0338776662946914]
	TIME [epoch: 5.75 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8114813368992719		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.8114813368992719 | validation: 0.628256869169593]
	TIME [epoch: 5.75 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8687728622492923		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.8687728622492923 | validation: 0.5024067933338349]
	TIME [epoch: 5.75 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.779778063648967		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.779778063648967 | validation: 0.45247591783084884]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8967200830022031		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.8967200830022031 | validation: 0.6355159829141422]
	TIME [epoch: 5.77 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7834122601891967		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.7834122601891967 | validation: 0.6282847533182397]
	TIME [epoch: 5.75 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198553234777616		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.7198553234777616 | validation: 0.7850686881793832]
	TIME [epoch: 5.75 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8477914315620366		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.8477914315620366 | validation: 0.6452970702314375]
	TIME [epoch: 5.75 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.821389772920726		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.821389772920726 | validation: 0.45775433910325264]
	TIME [epoch: 5.75 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8088740127821954		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8088740127821954 | validation: 0.5005102917971944]
	TIME [epoch: 5.75 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7629407024486334		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.7629407024486334 | validation: 0.4996960537982967]
	TIME [epoch: 5.79 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7881965322659151		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.7881965322659151 | validation: 0.6699940021797993]
	TIME [epoch: 5.75 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.847623267255017		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.847623267255017 | validation: 0.8046507836963437]
	TIME [epoch: 5.75 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8101127962918178		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.8101127962918178 | validation: 0.5045699681157789]
	TIME [epoch: 5.75 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8376092746517614		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8376092746517614 | validation: 0.5717317812018419]
	TIME [epoch: 5.76 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0943898465220951		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.0943898465220951 | validation: 0.5737062823515037]
	TIME [epoch: 5.75 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8049261312238736		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.8049261312238736 | validation: 0.6554840988644034]
	TIME [epoch: 5.79 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.889258020666186		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.889258020666186 | validation: 0.7977119521485372]
	TIME [epoch: 5.77 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.834721308685518		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.834721308685518 | validation: 0.756199283264612]
	TIME [epoch: 5.75 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7904164646253089		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.7904164646253089 | validation: 0.49232562412982717]
	TIME [epoch: 5.75 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8551159681082927		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.8551159681082927 | validation: 0.4823149004207851]
	TIME [epoch: 5.75 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222397112865142		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.7222397112865142 | validation: 0.5317332522088151]
	TIME [epoch: 5.75 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.885029045114898		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.885029045114898 | validation: 0.9454838986135596]
	TIME [epoch: 5.75 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0206505003319113		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.0206505003319113 | validation: 0.6207214507819103]
	TIME [epoch: 5.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289724000478239		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.7289724000478239 | validation: 0.7654274437491025]
	TIME [epoch: 5.75 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.004279040556178		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.004279040556178 | validation: 0.5570111117639338]
	TIME [epoch: 5.75 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.799618688972318		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.799618688972318 | validation: 0.5658474823448598]
	TIME [epoch: 5.75 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8426025851304944		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.8426025851304944 | validation: 0.7542243972077363]
	TIME [epoch: 5.75 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0810336364444972		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.0810336364444972 | validation: 0.4879313737360208]
	TIME [epoch: 5.75 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6767482582545397		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.6767482582545397 | validation: 0.46182818397869185]
	TIME [epoch: 5.78 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9541932710163706		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.9541932710163706 | validation: 0.5751089621162087]
	TIME [epoch: 5.76 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7856386955551131		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.7856386955551131 | validation: 0.6175500803109875]
	TIME [epoch: 5.75 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.899615278804719		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.899615278804719 | validation: 0.4578840825884143]
	TIME [epoch: 5.75 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2006033597426098		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.2006033597426098 | validation: 0.5939377184573672]
	TIME [epoch: 5.75 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7684217181647091		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.7684217181647091 | validation: 0.46639609148535327]
	TIME [epoch: 5.76 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9747084462073611		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.9747084462073611 | validation: 0.6851354348925929]
	TIME [epoch: 5.75 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9253111442371539		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.9253111442371539 | validation: 0.43206468741924225]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6335698831232967		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6335698831232967 | validation: 0.3999390512492795]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7059956755922667		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.7059956755922667 | validation: 0.4653295111765498]
	TIME [epoch: 5.75 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6262074664281524		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.6262074664281524 | validation: 0.8538290506074779]
	TIME [epoch: 5.74 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7858016140896791		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.7858016140896791 | validation: 0.45182686726589555]
	TIME [epoch: 5.75 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283319858117604		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.6283319858117604 | validation: 0.388238206618974]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7399568467917799		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.7399568467917799 | validation: 2.7627672541808357]
	TIME [epoch: 5.79 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3578869637829676		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.3578869637829676 | validation: 0.5383545143350963]
	TIME [epoch: 5.74 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6316487911311505		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.6316487911311505 | validation: 0.377574097303175]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6296509326914654		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.6296509326914654 | validation: 0.4948476833383486]
	TIME [epoch: 5.74 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.65032819232822		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.65032819232822 | validation: 0.3744704263119924]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5805598228520803		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.5805598228520803 | validation: 0.42483181419447313]
	TIME [epoch: 5.74 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7490426255909142		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7490426255909142 | validation: 0.6452153365573551]
	TIME [epoch: 5.77 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699243218611153		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.699243218611153 | validation: 0.4918390585157312]
	TIME [epoch: 5.75 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7471821397452787		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.7471821397452787 | validation: 0.41777647161933806]
	TIME [epoch: 5.73 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8181908400238392		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.8181908400238392 | validation: 0.7348047401479488]
	TIME [epoch: 5.73 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8547904319343786		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.8547904319343786 | validation: 0.41506024050877904]
	TIME [epoch: 5.74 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6661418106808906		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6661418106808906 | validation: 0.356170460837789]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5652321323036569		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.5652321323036569 | validation: 0.40499362344593354]
	TIME [epoch: 5.75 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.551545443391538		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.551545443391538 | validation: 0.5092999823742411]
	TIME [epoch: 5.77 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6922056790829896		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.6922056790829896 | validation: 0.6375804310080236]
	TIME [epoch: 5.74 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6346630311455133		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.6346630311455133 | validation: 0.4370038820485578]
	TIME [epoch: 5.73 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8576624538314636		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.8576624538314636 | validation: 0.4092215744755177]
	TIME [epoch: 5.73 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7345343238829191		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.7345343238829191 | validation: 0.6500859542850509]
	TIME [epoch: 5.73 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7433368175047699		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.7433368175047699 | validation: 0.6714981226318891]
	TIME [epoch: 5.73 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7489614616241268		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.7489614616241268 | validation: 0.4178135065676407]
	TIME [epoch: 5.78 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6682917883405308		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.6682917883405308 | validation: 0.4119419389656617]
	TIME [epoch: 5.74 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8819946282835882		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.8819946282835882 | validation: 0.47998388221309995]
	TIME [epoch: 5.74 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6078358633996325		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.6078358633996325 | validation: 0.42996630488801674]
	TIME [epoch: 5.73 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8047029704885661		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.8047029704885661 | validation: 0.4158186042893292]
	TIME [epoch: 5.74 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6449697461980707		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.6449697461980707 | validation: 0.32524890075087953]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6209841117518029		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6209841117518029 | validation: 0.5912455797808331]
	TIME [epoch: 5.75 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301801938177585		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.6301801938177585 | validation: 0.3530738711071208]
	TIME [epoch: 5.76 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5647943102639742		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.5647943102639742 | validation: 0.47729683228703484]
	TIME [epoch: 5.73 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6395866230865455		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.6395866230865455 | validation: 0.4107789204665415]
	TIME [epoch: 5.73 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5667341723863882		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.5667341723863882 | validation: 0.47512712966085574]
	TIME [epoch: 5.73 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851600442861414		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.6851600442861414 | validation: 0.37358270960318385]
	TIME [epoch: 5.74 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5054533809154617		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.5054533809154617 | validation: 0.5034805039887924]
	TIME [epoch: 5.74 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7580363938573691		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.7580363938573691 | validation: 0.9789641764319931]
	TIME [epoch: 5.78 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7342606854095141		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.7342606854095141 | validation: 0.5440213881568977]
	TIME [epoch: 5.74 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7904889881708348		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.7904889881708348 | validation: 0.4778310986237266]
	TIME [epoch: 5.73 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.667506992604809		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.667506992604809 | validation: 0.40958086976054703]
	TIME [epoch: 5.73 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983385149967963		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.6983385149967963 | validation: 0.361364250626917]
	TIME [epoch: 5.74 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6775304680777889		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.6775304680777889 | validation: 0.4295666820152772]
	TIME [epoch: 5.73 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5591622444408522		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.5591622444408522 | validation: 0.5965111181144749]
	TIME [epoch: 5.75 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7821278054037253		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.7821278054037253 | validation: 0.5299931887265396]
	TIME [epoch: 5.76 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5395269938256799		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.5395269938256799 | validation: 0.520614626863052]
	TIME [epoch: 5.74 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6649460984606855		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.6649460984606855 | validation: 0.5477210622261651]
	TIME [epoch: 5.73 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5940814395715384		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.5940814395715384 | validation: 0.5682201071778991]
	TIME [epoch: 5.73 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247680049214201		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.7247680049214201 | validation: 0.5563660185406955]
	TIME [epoch: 5.73 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.539621791355018		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.539621791355018 | validation: 0.5227190741514841]
	TIME [epoch: 5.73 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5558212421814172		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.5558212421814172 | validation: 0.3514642551837238]
	TIME [epoch: 5.77 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.566204817144168		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.566204817144168 | validation: 0.3512429425558925]
	TIME [epoch: 5.74 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312099498890668		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.6312099498890668 | validation: 0.7955619272529826]
	TIME [epoch: 5.73 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0058051217654636		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.0058051217654636 | validation: 0.31452707955833803]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7373029516518776		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.7373029516518776 | validation: 0.4784879368271103]
	TIME [epoch: 5.74 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5690262792024496		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5690262792024496 | validation: 0.3668026073960046]
	TIME [epoch: 5.74 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4976076281419362		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.4976076281419362 | validation: 0.4401278829760756]
	TIME [epoch: 5.75 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6087616209207536		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.6087616209207536 | validation: 0.5275325739647797]
	TIME [epoch: 5.78 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467977396627779		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.5467977396627779 | validation: 0.28041018988669986]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.452159733857132		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.452159733857132 | validation: 0.35871518716801704]
	TIME [epoch: 5.75 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501454775734798		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.501454775734798 | validation: 0.5361962492718371]
	TIME [epoch: 5.74 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5856011094576276		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5856011094576276 | validation: 0.46085687331761177]
	TIME [epoch: 5.73 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6106312562434807		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.6106312562434807 | validation: 0.2611633294698108]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41820308087189717		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.41820308087189717 | validation: 0.2960497576389286]
	TIME [epoch: 5.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4956940679335214		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.4956940679335214 | validation: 0.3254287990290526]
	TIME [epoch: 5.75 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5115062093889314		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.5115062093889314 | validation: 0.399342679185039]
	TIME [epoch: 5.73 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5944789219316222		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.5944789219316222 | validation: 0.5534148942984737]
	TIME [epoch: 5.75 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5812401606196581		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.5812401606196581 | validation: 0.3381323225415415]
	TIME [epoch: 5.75 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48335477984518277		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.48335477984518277 | validation: 0.41899859408348095]
	TIME [epoch: 5.74 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6041047423581426		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.6041047423581426 | validation: 0.42952492711659346]
	TIME [epoch: 5.78 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49953981670308045		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.49953981670308045 | validation: 0.3884865202130877]
	TIME [epoch: 5.77 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5134052964919145		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.5134052964919145 | validation: 0.32869180894647954]
	TIME [epoch: 5.75 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4795558810750874		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.4795558810750874 | validation: 0.3412629043346584]
	TIME [epoch: 5.74 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5389437356826605		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.5389437356826605 | validation: 0.7394585634808254]
	TIME [epoch: 5.75 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5521022959165159		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5521022959165159 | validation: 0.3507685579435288]
	TIME [epoch: 5.73 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46092702661801543		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.46092702661801543 | validation: 0.6255685038400836]
	TIME [epoch: 5.75 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5208428902217263		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.5208428902217263 | validation: 0.6492502250680456]
	TIME [epoch: 5.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5052927248870807		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.5052927248870807 | validation: 0.29614030834656085]
	TIME [epoch: 5.75 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46000661868223636		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.46000661868223636 | validation: 0.40494573524182215]
	TIME [epoch: 5.75 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.558752339549698		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.558752339549698 | validation: 0.26621858857204717]
	TIME [epoch: 5.74 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6321009338628372		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.6321009338628372 | validation: 0.38261843802094675]
	TIME [epoch: 5.75 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6193862092461598		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.6193862092461598 | validation: 0.5868353272782335]
	TIME [epoch: 5.75 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7177869162790479		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.7177869162790479 | validation: 0.632115112026036]
	TIME [epoch: 5.78 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49677372115025253		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.49677372115025253 | validation: 0.4404919013857833]
	TIME [epoch: 5.75 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48666472920654835		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.48666472920654835 | validation: 0.34556028362051466]
	TIME [epoch: 5.75 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.508833185097572		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.508833185097572 | validation: 0.40376386934277214]
	TIME [epoch: 5.75 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5048611844791518		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.5048611844791518 | validation: 0.39377527768312304]
	TIME [epoch: 5.75 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48678680200291		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.48678680200291 | validation: 0.2936702953696306]
	TIME [epoch: 5.75 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7180970975531661		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.7180970975531661 | validation: 0.41154323989804353]
	TIME [epoch: 5.75 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7086766478670509		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.7086766478670509 | validation: 0.4792916667548924]
	TIME [epoch: 5.79 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3950183172531138		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.3950183172531138 | validation: 0.674948664314596]
	TIME [epoch: 5.75 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5657878121629989		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.5657878121629989 | validation: 0.2664546994082515]
	TIME [epoch: 5.75 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39490484276354143		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.39490484276354143 | validation: 0.41864163234540824]
	TIME [epoch: 5.75 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5018618174424315		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5018618174424315 | validation: 0.36180882968558065]
	TIME [epoch: 5.75 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.58797535469701		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.58797535469701 | validation: 0.37627574667730995]
	TIME [epoch: 5.75 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4290982298431192		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.4290982298431192 | validation: 0.3136186602083458]
	TIME [epoch: 5.78 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.433983791995983		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.433983791995983 | validation: 0.40926625365575214]
	TIME [epoch: 5.76 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4148937852183873		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.4148937852183873 | validation: 0.22797935855994822]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_354.pth
	Model improved!!!
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3529975699580062		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.3529975699580062 | validation: 0.4943507361866014]
	TIME [epoch: 5.75 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46753160966822754		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.46753160966822754 | validation: 0.2563124115073913]
	TIME [epoch: 5.74 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38555993806236344		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.38555993806236344 | validation: 0.29898017713064556]
	TIME [epoch: 5.75 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34722029817347333		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.34722029817347333 | validation: 0.290877042020921]
	TIME [epoch: 5.75 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4351806110093958		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.4351806110093958 | validation: 0.31197322119928145]
	TIME [epoch: 5.79 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4183709223928893		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.4183709223928893 | validation: 0.22539230971365976]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42810693909348807		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.42810693909348807 | validation: 0.6033656063530232]
	TIME [epoch: 5.75 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5604516411881363		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.5604516411881363 | validation: 0.26951467052500394]
	TIME [epoch: 5.74 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393291813255933		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.393291813255933 | validation: 0.2532189021156463]
	TIME [epoch: 5.75 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4072449346035536		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.4072449346035536 | validation: 0.24026358014737775]
	TIME [epoch: 5.75 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667967164705828		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.3667967164705828 | validation: 0.33425039645079624]
	TIME [epoch: 5.78 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.454108158227298		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.454108158227298 | validation: 0.22216460512733324]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31769793529363477		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.31769793529363477 | validation: 0.28227868259934435]
	TIME [epoch: 5.75 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.483965181534001		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.483965181534001 | validation: 0.4296542816529522]
	TIME [epoch: 5.75 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.380888705928864		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.380888705928864 | validation: 0.28906445121167423]
	TIME [epoch: 5.74 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3758686277269492		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.3758686277269492 | validation: 0.4268981640261757]
	TIME [epoch: 5.75 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36759174190408705		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.36759174190408705 | validation: 0.2577114359641406]
	TIME [epoch: 5.76 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39186706817839906		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.39186706817839906 | validation: 0.3332269651422422]
	TIME [epoch: 5.78 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6224377518396028		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.6224377518396028 | validation: 0.3890481064240017]
	TIME [epoch: 5.75 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40769641313805033		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.40769641313805033 | validation: 0.32505583698347607]
	TIME [epoch: 5.74 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38578410658999684		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.38578410658999684 | validation: 0.302845191771882]
	TIME [epoch: 5.75 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41157878974769735		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.41157878974769735 | validation: 0.48422262851430703]
	TIME [epoch: 5.75 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4312985361624908		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.4312985361624908 | validation: 0.31365323786885957]
	TIME [epoch: 5.74 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44934347969557237		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.44934347969557237 | validation: 0.2763012657927191]
	TIME [epoch: 5.79 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39704292123672		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.39704292123672 | validation: 0.24511213800252507]
	TIME [epoch: 5.75 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4223169522931699		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.4223169522931699 | validation: 0.3043757542548363]
	TIME [epoch: 5.75 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3994438946278953		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.3994438946278953 | validation: 0.4573637402354828]
	TIME [epoch: 5.75 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269806675635857		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.5269806675635857 | validation: 0.5134992848076592]
	TIME [epoch: 5.74 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.505646451949465		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.505646451949465 | validation: 0.28776306988294237]
	TIME [epoch: 5.75 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35802162355727396		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.35802162355727396 | validation: 0.3138633544967834]
	TIME [epoch: 5.75 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4898004439476418		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.4898004439476418 | validation: 0.26370665377888286]
	TIME [epoch: 5.78 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3818399505477004		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.3818399505477004 | validation: 0.780487445781518]
	TIME [epoch: 5.75 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5852216949805017		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.5852216949805017 | validation: 0.3675553010424858]
	TIME [epoch: 5.74 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4164286648907459		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.4164286648907459 | validation: 0.2897798919765337]
	TIME [epoch: 5.74 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33438635272639916		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.33438635272639916 | validation: 0.3018804342444357]
	TIME [epoch: 5.74 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35007325920561627		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.35007325920561627 | validation: 0.27361697942472907]
	TIME [epoch: 5.75 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3443036548326637		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.3443036548326637 | validation: 0.23404765924446166]
	TIME [epoch: 5.78 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3523330840791574		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.3523330840791574 | validation: 0.2903987124620203]
	TIME [epoch: 5.75 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35713372034579294		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.35713372034579294 | validation: 0.876343085921019]
	TIME [epoch: 5.74 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6184488580459547		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.6184488580459547 | validation: 0.24957635214858506]
	TIME [epoch: 5.75 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3813339949565527		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.3813339949565527 | validation: 0.49073546028356396]
	TIME [epoch: 5.75 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4446066363536326		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.4446066363536326 | validation: 0.17889738525252447]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2982053359237917		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.2982053359237917 | validation: 0.24675774788626087]
	TIME [epoch: 5.76 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31161518910737307		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.31161518910737307 | validation: 0.24064633067216284]
	TIME [epoch: 5.77 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3404512701579235		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.3404512701579235 | validation: 0.285456261261304]
	TIME [epoch: 5.75 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812442955540328		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.6812442955540328 | validation: 0.5810410339294019]
	TIME [epoch: 5.74 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49986211832605354		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.49986211832605354 | validation: 0.3160433088954897]
	TIME [epoch: 5.74 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30822857731723236		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.30822857731723236 | validation: 0.3083723640893287]
	TIME [epoch: 5.74 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35823666339993254		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.35823666339993254 | validation: 0.4939292213599171]
	TIME [epoch: 5.74 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48014940314144516		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.48014940314144516 | validation: 0.41167060594953186]
	TIME [epoch: 5.79 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4011964110086318		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.4011964110086318 | validation: 0.3630244451369724]
	TIME [epoch: 5.75 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736328393491861		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.3736328393491861 | validation: 0.18165729914942724]
	TIME [epoch: 5.75 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4082259600735283		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.4082259600735283 | validation: 0.4449412545419604]
	TIME [epoch: 5.74 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5958937653704119		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.5958937653704119 | validation: 0.43512672690881177]
	TIME [epoch: 5.74 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38968205248430815		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.38968205248430815 | validation: 0.30620264477367565]
	TIME [epoch: 5.75 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3024647091146163		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.3024647091146163 | validation: 0.44676691340408414]
	TIME [epoch: 5.75 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3783022849535275		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.3783022849535275 | validation: 0.32832302022799775]
	TIME [epoch: 5.78 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3136671200527744		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.3136671200527744 | validation: 0.590540565977195]
	TIME [epoch: 5.75 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44942073248597497		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.44942073248597497 | validation: 0.2890253881018506]
	TIME [epoch: 5.74 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4134298923745373		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.4134298923745373 | validation: 0.2674583246945793]
	TIME [epoch: 5.74 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3455819672788707		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.3455819672788707 | validation: 0.3236408248171573]
	TIME [epoch: 5.74 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41861420701409274		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.41861420701409274 | validation: 0.18590922686431058]
	TIME [epoch: 5.75 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2753131079604909		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.2753131079604909 | validation: 0.2730612971924433]
	TIME [epoch: 5.78 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30048509111389804		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.30048509111389804 | validation: 0.28849398890310696]
	TIME [epoch: 5.75 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4473822586551257		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.4473822586551257 | validation: 0.3954856119686875]
	TIME [epoch: 5.75 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4849759669350136		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.4849759669350136 | validation: 0.41455485198560676]
	TIME [epoch: 5.74 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4095325205428256		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.4095325205428256 | validation: 0.3205616956051322]
	TIME [epoch: 5.74 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33317866789659767		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.33317866789659767 | validation: 0.1882859693513416]
	TIME [epoch: 5.74 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3185090152610526		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.3185090152610526 | validation: 0.39806821797215874]
	TIME [epoch: 5.75 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4421742507412459		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.4421742507412459 | validation: 0.35552876078842405]
	TIME [epoch: 5.78 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30842096021084775		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.30842096021084775 | validation: 0.40506313015052714]
	TIME [epoch: 5.74 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4307786742594438		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.4307786742594438 | validation: 0.2609433063757134]
	TIME [epoch: 5.74 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2830928057025878		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.2830928057025878 | validation: 0.4439267467427901]
	TIME [epoch: 5.74 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3776803667913757		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.3776803667913757 | validation: 0.2312146376859543]
	TIME [epoch: 5.74 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.262490072127413		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.262490072127413 | validation: 0.21789559110622986]
	TIME [epoch: 5.75 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36801779661525846		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.36801779661525846 | validation: 0.25593501360208654]
	TIME [epoch: 5.78 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33400288811349965		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.33400288811349965 | validation: 0.2655125590392373]
	TIME [epoch: 5.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4746710031634329		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.4746710031634329 | validation: 0.41408267047564085]
	TIME [epoch: 5.74 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46287620934156115		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.46287620934156115 | validation: 0.20575695752442436]
	TIME [epoch: 5.74 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3014622104913963		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.3014622104913963 | validation: 0.3756979285963956]
	TIME [epoch: 5.74 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6225565093180976		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.6225565093180976 | validation: 0.49661249952974845]
	TIME [epoch: 5.74 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31912957233694306		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.31912957233694306 | validation: 0.38215380912378266]
	TIME [epoch: 5.76 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3441593473833179		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.3441593473833179 | validation: 0.26129030152953747]
	TIME [epoch: 5.78 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30019482291693245		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.30019482291693245 | validation: 0.23558360227132638]
	TIME [epoch: 5.74 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2951257398958068		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.2951257398958068 | validation: 0.22714146655125433]
	TIME [epoch: 5.74 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2623016384189413		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.2623016384189413 | validation: 0.19779436890040658]
	TIME [epoch: 5.74 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27791662445687393		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.27791662445687393 | validation: 0.37877938772831554]
	TIME [epoch: 5.74 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49092789266374404		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.49092789266374404 | validation: 0.3127800185418563]
	TIME [epoch: 5.74 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31915706027678314		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.31915706027678314 | validation: 0.35088795145379253]
	TIME [epoch: 5.78 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3586122002941152		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.3586122002941152 | validation: 0.2598536137774226]
	TIME [epoch: 5.75 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27684476233523103		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.27684476233523103 | validation: 0.21446938172124708]
	TIME [epoch: 5.74 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041515157838797		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.3041515157838797 | validation: 0.26612280339559397]
	TIME [epoch: 5.74 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5492661638104301		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.5492661638104301 | validation: 0.3467076882741955]
	TIME [epoch: 5.74 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3634465798648765		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.3634465798648765 | validation: 0.20000966602557516]
	TIME [epoch: 5.74 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26650038289429034		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.26650038289429034 | validation: 0.2645491932456336]
	TIME [epoch: 5.76 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32107171538521084		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.32107171538521084 | validation: 0.2849021304707268]
	TIME [epoch: 5.77 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34360949685564407		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.34360949685564407 | validation: 0.3065395382510423]
	TIME [epoch: 5.75 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3880419324364179		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3880419324364179 | validation: 0.30052939345683805]
	TIME [epoch: 5.74 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3511645669269466		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.3511645669269466 | validation: 0.29723135591305316]
	TIME [epoch: 5.75 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27504735033729544		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.27504735033729544 | validation: 0.23221484513908291]
	TIME [epoch: 5.74 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.277500481599356		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.277500481599356 | validation: 0.2993147816483194]
	TIME [epoch: 5.74 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26942596082967196		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.26942596082967196 | validation: 0.20018204066187684]
	TIME [epoch: 5.78 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31520670902722614		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.31520670902722614 | validation: 0.4957816369381598]
	TIME [epoch: 5.75 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3911040471108959		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.3911040471108959 | validation: 0.2374633115328533]
	TIME [epoch: 5.75 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2781573545211764		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.2781573545211764 | validation: 0.20914660726848508]
	TIME [epoch: 5.74 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3319539603878934		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.3319539603878934 | validation: 0.21860872717006355]
	TIME [epoch: 5.74 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3231583855409338		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.3231583855409338 | validation: 0.3305727977370633]
	TIME [epoch: 5.74 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.312298403856914		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.312298403856914 | validation: 0.24239840466449714]
	TIME [epoch: 5.76 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3386593347604691		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.3386593347604691 | validation: 0.34368771311834645]
	TIME [epoch: 5.77 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3144608404000048		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.3144608404000048 | validation: 0.2968302821622059]
	TIME [epoch: 5.75 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28147679657849783		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.28147679657849783 | validation: 0.1724859855975242]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2245596826896193		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.2245596826896193 | validation: 0.3980112710896465]
	TIME [epoch: 5.75 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34113813123556797		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.34113813123556797 | validation: 0.32728583604844685]
	TIME [epoch: 5.75 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35245072587328746		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.35245072587328746 | validation: 0.2154665927787791]
	TIME [epoch: 5.74 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038705942511591		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.3038705942511591 | validation: 0.23737485291039873]
	TIME [epoch: 5.79 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35265766587045433		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.35265766587045433 | validation: 0.36238439114539334]
	TIME [epoch: 5.75 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3357457234347015		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.3357457234347015 | validation: 0.3655009136626556]
	TIME [epoch: 5.75 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.543011527647862		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.543011527647862 | validation: 0.22114796610120777]
	TIME [epoch: 5.75 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362166897546628		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.3362166897546628 | validation: 0.31769851926463294]
	TIME [epoch: 5.74 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3519422899244763		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.3519422899244763 | validation: 0.38895549107360616]
	TIME [epoch: 5.76 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4263777510356315		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.4263777510356315 | validation: 0.3377372751311706]
	TIME [epoch: 5.76 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2918912546272274		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2918912546272274 | validation: 0.25927762895332174]
	TIME [epoch: 5.78 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3021723929953071		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.3021723929953071 | validation: 0.16423059240492324]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_477.pth
	Model improved!!!
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3707959513534354		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.3707959513534354 | validation: 0.25970610943729877]
	TIME [epoch: 5.75 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702808680227494		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.3702808680227494 | validation: 0.25315396821885294]
	TIME [epoch: 5.75 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29053595335417226		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.29053595335417226 | validation: 0.23458529755428678]
	TIME [epoch: 5.74 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545002746404281		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.2545002746404281 | validation: 0.20748100837524575]
	TIME [epoch: 5.75 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2640192168621316		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.2640192168621316 | validation: 0.5157443520440868]
	TIME [epoch: 5.79 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36926977992000115		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.36926977992000115 | validation: 0.22506483676766362]
	TIME [epoch: 5.75 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3271845556648379		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.3271845556648379 | validation: 0.2711128089200937]
	TIME [epoch: 5.74 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28444397831070234		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.28444397831070234 | validation: 0.17823079702903066]
	TIME [epoch: 5.75 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30844237556199106		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.30844237556199106 | validation: 0.34680552936068465]
	TIME [epoch: 5.74 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33421966133235026		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.33421966133235026 | validation: 0.1819394708565183]
	TIME [epoch: 5.74 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2307088653632493		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.2307088653632493 | validation: 0.16040756376356327]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_488.pth
	Model improved!!!
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24496476129797534		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.24496476129797534 | validation: 0.35637355230416373]
	TIME [epoch: 5.76 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2922053493672296		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.2922053493672296 | validation: 0.23853838875787867]
	TIME [epoch: 5.75 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23855275758261862		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.23855275758261862 | validation: 0.16534161616114396]
	TIME [epoch: 5.74 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2610736497741498		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.2610736497741498 | validation: 0.3091995436351767]
	TIME [epoch: 5.75 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44534428044058244		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.44534428044058244 | validation: 0.17352832541206917]
	TIME [epoch: 5.74 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28499895034890704		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.28499895034890704 | validation: 0.2999985603869805]
	TIME [epoch: 5.75 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2953088829427403		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.2953088829427403 | validation: 0.19031327344933963]
	TIME [epoch: 5.79 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23533664539008053		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.23533664539008053 | validation: 0.18642185090631522]
	TIME [epoch: 5.75 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2503231228157846		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.2503231228157846 | validation: 0.23490461927759484]
	TIME [epoch: 5.75 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27554951188124654		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.27554951188124654 | validation: 0.15107371000035283]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22622799627836798		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.22622799627836798 | validation: 0.40285255990636126]
	TIME [epoch: 5.74 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4298546837567927		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.4298546837567927 | validation: 0.2832288356577131]
	TIME [epoch: 5.74 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34775322531277847		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.34775322531277847 | validation: 0.2342924627541116]
	TIME [epoch: 5.78 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22066242902144473		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.22066242902144473 | validation: 0.25842820275146433]
	TIME [epoch: 5.74 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31739863211489217		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.31739863211489217 | validation: 0.21979834515135652]
	TIME [epoch: 5.75 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25781867176563694		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.25781867176563694 | validation: 0.3439550212674138]
	TIME [epoch: 5.74 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3649274358880496		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.3649274358880496 | validation: 0.45374138699577815]
	TIME [epoch: 5.74 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35547174508829427		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.35547174508829427 | validation: 0.3313328661469517]
	TIME [epoch: 5.74 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30992497160043836		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.30992497160043836 | validation: 0.28241288872583087]
	TIME [epoch: 5.75 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2685669728965892		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.2685669728965892 | validation: 0.20999191777240167]
	TIME [epoch: 5.78 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3885734044313768		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.3885734044313768 | validation: 0.13724232841899558]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_509.pth
	Model improved!!!
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2420394635299265		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.2420394635299265 | validation: 0.22795549809104493]
	TIME [epoch: 5.74 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22307062791196436		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.22307062791196436 | validation: 0.1497734465095499]
	TIME [epoch: 5.74 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2803357318504165		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.2803357318504165 | validation: 0.20768549458720598]
	TIME [epoch: 5.74 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23713771874915465		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.23713771874915465 | validation: 0.21099680225856915]
	TIME [epoch: 5.74 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3330097035302966		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.3330097035302966 | validation: 0.24723720566765361]
	TIME [epoch: 5.78 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32763159913814355		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.32763159913814355 | validation: 0.16971780171879386]
	TIME [epoch: 5.75 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21598263291918923		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.21598263291918923 | validation: 0.17528360547072308]
	TIME [epoch: 5.74 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22616067106761525		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.22616067106761525 | validation: 0.14819611629308482]
	TIME [epoch: 5.74 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3357946326760751		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.3357946326760751 | validation: 0.38224461748441785]
	TIME [epoch: 5.74 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3659262040988208		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.3659262040988208 | validation: 0.3109950103207509]
	TIME [epoch: 5.74 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3204464893738259		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.3204464893738259 | validation: 0.16895360823530248]
	TIME [epoch: 5.74 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22260936233288364		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.22260936233288364 | validation: 0.13048476161264555]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2193504108232664		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.2193504108232664 | validation: 0.24787328637399655]
	TIME [epoch: 5.75 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2635036030745511		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.2635036030745511 | validation: 0.23155504539231364]
	TIME [epoch: 5.74 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2959774874607867		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.2959774874607867 | validation: 0.19912308994987332]
	TIME [epoch: 5.74 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31173214010812395		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.31173214010812395 | validation: 0.3175531115944683]
	TIME [epoch: 5.74 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26407967608726557		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.26407967608726557 | validation: 0.2832005711819786]
	TIME [epoch: 5.74 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28860221713848555		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.28860221713848555 | validation: 0.15346316038907717]
	TIME [epoch: 5.78 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20644685337153346		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.20644685337153346 | validation: 0.3349969836128733]
	TIME [epoch: 5.74 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2531057881574512		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.2531057881574512 | validation: 0.2944145295274121]
	TIME [epoch: 5.74 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24399309859432802		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.24399309859432802 | validation: 0.22341585088979457]
	TIME [epoch: 5.74 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2753624747628481		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.2753624747628481 | validation: 0.24744187255411831]
	TIME [epoch: 5.74 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28855692353816453		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.28855692353816453 | validation: 0.2416269835202138]
	TIME [epoch: 5.74 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26503650877625806		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.26503650877625806 | validation: 0.23312188872694656]
	TIME [epoch: 5.75 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.227829461644177		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.227829461644177 | validation: 0.1835229398708995]
	TIME [epoch: 5.77 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28345168916826036		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.28345168916826036 | validation: 0.33879277314549394]
	TIME [epoch: 5.74 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3222031960719198		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.3222031960719198 | validation: 0.236519383092503]
	TIME [epoch: 5.74 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28514138344994283		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.28514138344994283 | validation: 0.23110996921371063]
	TIME [epoch: 5.74 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21125821844299278		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.21125821844299278 | validation: 0.2616328063166661]
	TIME [epoch: 5.74 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2201799546390583		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.2201799546390583 | validation: 0.22206924144752024]
	TIME [epoch: 5.74 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22558117679230644		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.22558117679230644 | validation: 0.15422482913400617]
	TIME [epoch: 5.78 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2684263855972803		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.2684263855972803 | validation: 0.2884882515866372]
	TIME [epoch: 5.75 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21760501213338038		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.21760501213338038 | validation: 0.5239912882324285]
	TIME [epoch: 5.74 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3258689227886669		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.3258689227886669 | validation: 0.2606562406157195]
	TIME [epoch: 5.74 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3130826344122684		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.3130826344122684 | validation: 0.22961158682716853]
	TIME [epoch: 5.74 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2540300449185784		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.2540300449185784 | validation: 0.2711281931130782]
	TIME [epoch: 5.74 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627270673656489		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.2627270673656489 | validation: 0.21671924158159386]
	TIME [epoch: 5.75 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22852890464761125		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.22852890464761125 | validation: 0.3379640266512429]
	TIME [epoch: 5.77 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28522886815848847		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.28522886815848847 | validation: 0.2823137550542487]
	TIME [epoch: 5.74 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18298824249811216		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.18298824249811216 | validation: 0.27614603726713804]
	TIME [epoch: 5.74 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21219381743556992		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.21219381743556992 | validation: 0.16051520407309386]
	TIME [epoch: 5.74 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17230670655511923		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.17230670655511923 | validation: 0.18541604261248984]
	TIME [epoch: 5.74 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21216929995033534		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.21216929995033534 | validation: 0.2068561354103831]
	TIME [epoch: 5.74 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22884735735420836		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.22884735735420836 | validation: 0.18157922820913647]
	TIME [epoch: 5.78 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285666831415802		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.285666831415802 | validation: 0.22697228963661645]
	TIME [epoch: 5.75 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2713068463382101		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.2713068463382101 | validation: 0.1779381254415424]
	TIME [epoch: 5.74 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20461770319320882		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.20461770319320882 | validation: 0.15849395338257707]
	TIME [epoch: 5.74 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25753445368799566		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.25753445368799566 | validation: 0.15495758561464476]
	TIME [epoch: 5.73 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17313098851220035		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.17313098851220035 | validation: 0.1368937685081643]
	TIME [epoch: 5.74 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26414539816840704		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.26414539816840704 | validation: 0.19465338269727994]
	TIME [epoch: 5.75 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24104431247657382		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.24104431247657382 | validation: 0.10180790697146026]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23642477621105956		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.23642477621105956 | validation: 0.21793715660820834]
	TIME [epoch: 5.75 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2411088782348079		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.2411088782348079 | validation: 0.11992760212894293]
	TIME [epoch: 5.74 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2038628459749673		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.2038628459749673 | validation: 0.22093366778911325]
	TIME [epoch: 5.74 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26077169153361085		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.26077169153361085 | validation: 0.12131852313119641]
	TIME [epoch: 5.74 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25879450502989904		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.25879450502989904 | validation: 0.19790320886647222]
	TIME [epoch: 5.74 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21791425887569094		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.21791425887569094 | validation: 0.16677574033739503]
	TIME [epoch: 5.78 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19276141289445836		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.19276141289445836 | validation: 0.12461325623789458]
	TIME [epoch: 5.75 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14874350421862376		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.14874350421862376 | validation: 0.12537967289285537]
	TIME [epoch: 5.74 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15515520967183377		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.15515520967183377 | validation: 0.11942271590368064]
	TIME [epoch: 5.74 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106042018967164		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.2106042018967164 | validation: 0.12227936142441259]
	TIME [epoch: 5.74 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19236863997119094		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.19236863997119094 | validation: 0.2552996736311831]
	TIME [epoch: 5.74 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2644261019059353		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.2644261019059353 | validation: 0.17473950688535667]
	TIME [epoch: 5.76 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659588611179329		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.1659588611179329 | validation: 0.1896290623519742]
	TIME [epoch: 5.78 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23179102745668848		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.23179102745668848 | validation: 0.1267686203960521]
	TIME [epoch: 5.74 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16407345872941992		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.16407345872941992 | validation: 0.121595063902517]
	TIME [epoch: 5.74 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19409680752633926		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.19409680752633926 | validation: 0.1271665113353928]
	TIME [epoch: 5.74 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512615435438356		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.2512615435438356 | validation: 0.20051222094131618]
	TIME [epoch: 5.73 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21505776404036855		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.21505776404036855 | validation: 0.26788024633546953]
	TIME [epoch: 5.74 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20234515622605562		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.20234515622605562 | validation: 0.17680374684643815]
	TIME [epoch: 5.78 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18739329925272333		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.18739329925272333 | validation: 0.14128545575618998]
	TIME [epoch: 5.75 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16318979725892527		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.16318979725892527 | validation: 0.12634950447667784]
	TIME [epoch: 5.74 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2302038240897792		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.2302038240897792 | validation: 0.20711153542506489]
	TIME [epoch: 5.74 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2637863639174604		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.2637863639174604 | validation: 0.21294488202315287]
	TIME [epoch: 5.75 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23107095935193223		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.23107095935193223 | validation: 0.2222273096826884]
	TIME [epoch: 5.75 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21416404877732526		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.21416404877732526 | validation: 0.15562327946357074]
	TIME [epoch: 5.75 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17897548568242988		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.17897548568242988 | validation: 0.13149770615342038]
	TIME [epoch: 5.77 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630265417759611		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.1630265417759611 | validation: 0.13008727294392972]
	TIME [epoch: 5.73 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19043661344065896		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.19043661344065896 | validation: 0.12531946896750382]
	TIME [epoch: 5.74 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1651488981178471		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.1651488981178471 | validation: 0.13406761410804374]
	TIME [epoch: 5.74 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20352880540103385		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.20352880540103385 | validation: 0.17442823216085912]
	TIME [epoch: 5.74 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18393400025344106		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.18393400025344106 | validation: 0.2439976058794218]
	TIME [epoch: 5.75 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19096003320020755		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.19096003320020755 | validation: 0.170654805521946]
	TIME [epoch: 5.77 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14549923838498272		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.14549923838498272 | validation: 0.16213564918727894]
	TIME [epoch: 5.75 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16977850673360997		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.16977850673360997 | validation: 0.21113827215400569]
	TIME [epoch: 5.75 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18252605750352557		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.18252605750352557 | validation: 0.12347120363856216]
	TIME [epoch: 5.74 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14083606586785352		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.14083606586785352 | validation: 0.13166517840941175]
	TIME [epoch: 5.73 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15045468180873553		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.15045468180873553 | validation: 0.11765966078542477]
	TIME [epoch: 5.73 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20867685092580954		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.20867685092580954 | validation: 0.13402352756496252]
	TIME [epoch: 5.75 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429999624202066		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.1429999624202066 | validation: 0.10736946280002947]
	TIME [epoch: 5.77 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603120432759893		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.1603120432759893 | validation: 0.14432314080786604]
	TIME [epoch: 5.75 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15099142959656991		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.15099142959656991 | validation: 0.117583745207296]
	TIME [epoch: 5.74 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14145379042424358		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.14145379042424358 | validation: 0.10202091309796671]
	TIME [epoch: 5.74 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15914911864543066		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.15914911864543066 | validation: 0.14166599984948838]
	TIME [epoch: 5.74 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19780919709124875		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.19780919709124875 | validation: 0.25426536466172855]
	TIME [epoch: 5.73 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19221739371396207		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.19221739371396207 | validation: 0.1579242346711167]
	TIME [epoch: 5.77 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17751381142780587		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.17751381142780587 | validation: 0.19169742557742822]
	TIME [epoch: 5.74 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16009059669845668		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.16009059669845668 | validation: 0.16389926296919063]
	TIME [epoch: 5.74 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16961296037403717		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.16961296037403717 | validation: 0.132712315165001]
	TIME [epoch: 5.74 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17811347871459282		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.17811347871459282 | validation: 0.17817061314585686]
	TIME [epoch: 5.74 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1623062397480055		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.1623062397480055 | validation: 0.15503136935216727]
	TIME [epoch: 5.74 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544630016552815		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.1544630016552815 | validation: 0.1985330738914643]
	TIME [epoch: 5.76 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19746184671869635		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.19746184671869635 | validation: 0.11792803174013797]
	TIME [epoch: 5.77 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14820304681094926		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.14820304681094926 | validation: 0.24161766002108784]
	TIME [epoch: 5.75 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666367329805347		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.2666367329805347 | validation: 0.125506641553012]
	TIME [epoch: 5.74 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.172945264049504		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.172945264049504 | validation: 0.13912521335126432]
	TIME [epoch: 5.74 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22016899777682108		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.22016899777682108 | validation: 0.1930960437099391]
	TIME [epoch: 5.73 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17143728341538816		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.17143728341538816 | validation: 0.1879387461092663]
	TIME [epoch: 5.74 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18333250053723835		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.18333250053723835 | validation: 0.13081124127823657]
	TIME [epoch: 5.78 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1954644853481276		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.1954644853481276 | validation: 0.12127762823092875]
	TIME [epoch: 5.74 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21137582979892222		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.21137582979892222 | validation: 0.15734297961237415]
	TIME [epoch: 5.74 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15245142959340757		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.15245142959340757 | validation: 0.15799461914284738]
	TIME [epoch: 5.74 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376493336021975		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.1376493336021975 | validation: 0.1340936105431236]
	TIME [epoch: 5.74 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.170487962565747		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.170487962565747 | validation: 0.22702134771225418]
	TIME [epoch: 5.74 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17523065272376814		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.17523065272376814 | validation: 0.20818051238748012]
	TIME [epoch: 5.76 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18565575861471753		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.18565575861471753 | validation: 0.14779086834421787]
	TIME [epoch: 5.78 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16938607540586956		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.16938607540586956 | validation: 0.12148245046538375]
	TIME [epoch: 5.74 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19466439473289018		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.19466439473289018 | validation: 0.25873384602081706]
	TIME [epoch: 5.74 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1743547860894227		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.1743547860894227 | validation: 0.214262105029727]
	TIME [epoch: 5.74 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17114191870185735		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.17114191870185735 | validation: 0.12422462549925818]
	TIME [epoch: 5.73 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12448478156899842		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.12448478156899842 | validation: 0.18995328621372515]
	TIME [epoch: 5.74 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17709763439601778		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.17709763439601778 | validation: 0.19688064821569107]
	TIME [epoch: 5.79 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13781924878062274		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.13781924878062274 | validation: 0.17461661831121128]
	TIME [epoch: 5.75 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1715062787577664		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.1715062787577664 | validation: 0.23497214488247284]
	TIME [epoch: 5.74 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14949546968350752		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.14949546968350752 | validation: 0.19205166711892058]
	TIME [epoch: 5.74 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16649894221780503		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.16649894221780503 | validation: 0.15095224729244847]
	TIME [epoch: 5.74 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22084674330903153		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.22084674330903153 | validation: 0.14094442808341134]
	TIME [epoch: 5.73 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16076263439558386		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.16076263439558386 | validation: 0.1785887972277259]
	TIME [epoch: 5.75 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14205713262655606		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.14205713262655606 | validation: 0.1515228147809062]
	TIME [epoch: 5.77 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459410488408848		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.1459410488408848 | validation: 0.11567805159955771]
	TIME [epoch: 5.74 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16166419888903982		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.16166419888903982 | validation: 0.3531594583771938]
	TIME [epoch: 5.74 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24501093123819465		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.24501093123819465 | validation: 0.2795353462587518]
	TIME [epoch: 5.74 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17653114713188567		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.17653114713188567 | validation: 0.16466553128349737]
	TIME [epoch: 5.74 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16144409298763007		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.16144409298763007 | validation: 0.13445255557484775]
	TIME [epoch: 5.74 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1416981799302179		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.1416981799302179 | validation: 0.11510642716432454]
	TIME [epoch: 5.79 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20052352749588173		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.20052352749588173 | validation: 0.26389414289271357]
	TIME [epoch: 5.75 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16035261737858816		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.16035261737858816 | validation: 0.11817568233352768]
	TIME [epoch: 5.74 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268059766514885		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.1268059766514885 | validation: 0.1297442189358326]
	TIME [epoch: 5.74 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255616895693958		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.1255616895693958 | validation: 0.12027163989792815]
	TIME [epoch: 5.74 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16150229495987933		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.16150229495987933 | validation: 0.17923059271431405]
	TIME [epoch: 5.73 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2097239003645161		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.2097239003645161 | validation: 0.09726922811178414]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_650.pth
	Model improved!!!
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129286299190554		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.129286299190554 | validation: 0.11450104401240023]
	TIME [epoch: 5.78 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1494914437159847		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.1494914437159847 | validation: 0.11967877450304722]
	TIME [epoch: 5.74 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18668166885066484		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.18668166885066484 | validation: 0.10343841405122596]
	TIME [epoch: 5.74 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1680294392965846		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.1680294392965846 | validation: 0.12808039836666954]
	TIME [epoch: 5.74 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15119984737900713		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.15119984737900713 | validation: 0.0982139807676769]
	TIME [epoch: 5.74 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14995969454202301		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.14995969454202301 | validation: 0.21749189319453116]
	TIME [epoch: 5.74 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18557204307455843		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.18557204307455843 | validation: 0.19928568534997268]
	TIME [epoch: 5.78 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18087319620234643		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.18087319620234643 | validation: 0.2135947428307604]
	TIME [epoch: 5.74 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1802839043750291		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.1802839043750291 | validation: 0.2217545745780117]
	TIME [epoch: 5.74 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1719913825534346		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.1719913825534346 | validation: 0.25157026640382407]
	TIME [epoch: 5.75 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19670434812629947		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.19670434812629947 | validation: 0.27943582003001594]
	TIME [epoch: 5.74 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21986893786004186		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.21986893786004186 | validation: 0.2529043907497479]
	TIME [epoch: 5.74 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15733056231043652		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.15733056231043652 | validation: 0.2788738507790798]
	TIME [epoch: 5.77 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1805601201053077		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.1805601201053077 | validation: 0.20317636977066728]
	TIME [epoch: 5.75 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15182377677398656		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.15182377677398656 | validation: 0.17038323467789035]
	TIME [epoch: 5.74 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12649057324763685		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.12649057324763685 | validation: 0.15118235701220686]
	TIME [epoch: 5.74 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14918373327086193		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.14918373327086193 | validation: 0.18570873028184104]
	TIME [epoch: 5.73 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588796305036517		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.1588796305036517 | validation: 0.21405119773911857]
	TIME [epoch: 5.74 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15297888475896093		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.15297888475896093 | validation: 0.20964869939889103]
	TIME [epoch: 5.74 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18090961005358627		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.18090961005358627 | validation: 0.1921590505342714]
	TIME [epoch: 5.79 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18621628281376978		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.18621628281376978 | validation: 0.13767678598350538]
	TIME [epoch: 5.75 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20966969924305842		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.20966969924305842 | validation: 0.14791728771432194]
	TIME [epoch: 5.74 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13733404926468704		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.13733404926468704 | validation: 0.12980492475056862]
	TIME [epoch: 5.74 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435568539915439		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.1435568539915439 | validation: 0.11882991095175839]
	TIME [epoch: 5.74 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17729453388848593		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.17729453388848593 | validation: 0.16500151842570326]
	TIME [epoch: 5.74 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17555453575365684		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.17555453575365684 | validation: 0.1402300776469308]
	TIME [epoch: 5.77 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16037435845742568		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.16037435845742568 | validation: 0.10693334557743443]
	TIME [epoch: 5.75 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11970807155828106		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.11970807155828106 | validation: 0.17598462021032027]
	TIME [epoch: 5.74 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23099562309407412		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.23099562309407412 | validation: 0.2672360271285997]
	TIME [epoch: 5.74 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23904953993515354		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.23904953993515354 | validation: 0.19092161041152445]
	TIME [epoch: 5.74 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26670933683894044		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.26670933683894044 | validation: 0.14955972774195905]
	TIME [epoch: 5.74 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26144081621028425		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.26144081621028425 | validation: 0.21073133556183662]
	TIME [epoch: 5.75 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20496143420478435		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.20496143420478435 | validation: 0.12103255508867601]
	TIME [epoch: 5.78 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16553507203850437		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.16553507203850437 | validation: 0.10620295268861268]
	TIME [epoch: 5.74 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1455213347197205		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.1455213347197205 | validation: 0.13955702231762554]
	TIME [epoch: 5.74 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14121273268298548		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.14121273268298548 | validation: 0.16356245998056892]
	TIME [epoch: 5.73 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279799963971799		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.1279799963971799 | validation: 0.1506237819578509]
	TIME [epoch: 5.73 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12483502647811981		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.12483502647811981 | validation: 0.12398774743731972]
	TIME [epoch: 5.74 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14213413709290257		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.14213413709290257 | validation: 0.12783284709754358]
	TIME [epoch: 5.76 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16149214997013353		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.16149214997013353 | validation: 0.08719866410476008]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_690.pth
	Model improved!!!
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13731015030475222		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.13731015030475222 | validation: 0.1716547062065579]
	TIME [epoch: 5.75 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15164089341858927		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.15164089341858927 | validation: 0.1946789118979158]
	TIME [epoch: 5.75 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335973713112244		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.1335973713112244 | validation: 0.1353729419653279]
	TIME [epoch: 5.75 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13070155358700772		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.13070155358700772 | validation: 0.1298286499489142]
	TIME [epoch: 5.75 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14219545203730177		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.14219545203730177 | validation: 0.1801302718115122]
	TIME [epoch: 5.74 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1330341164220949		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.1330341164220949 | validation: 0.21646763347943282]
	TIME [epoch: 5.79 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.172126417446604		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.172126417446604 | validation: 0.09786718478758306]
	TIME [epoch: 5.75 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12175136732605886		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.12175136732605886 | validation: 0.12741379566999733]
	TIME [epoch: 5.74 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18480817471845662		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.18480817471845662 | validation: 0.13687332909836553]
	TIME [epoch: 5.75 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14843149151500082		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.14843149151500082 | validation: 0.13137882000210924]
	TIME [epoch: 5.75 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15697073888713564		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.15697073888713564 | validation: 0.13069046766948877]
	TIME [epoch: 5.75 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15285232553597863		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.15285232553597863 | validation: 0.10611665168005774]
	TIME [epoch: 5.78 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14568181778179515		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.14568181778179515 | validation: 0.1569046511202109]
	TIME [epoch: 5.76 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14973562343543992		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.14973562343543992 | validation: 0.18397222182424228]
	TIME [epoch: 5.75 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13521706150578527		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.13521706150578527 | validation: 0.13171121815079884]
	TIME [epoch: 5.74 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15802996968798638		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.15802996968798638 | validation: 0.18732778728176414]
	TIME [epoch: 5.75 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125735203584087		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.125735203584087 | validation: 0.12417129937430808]
	TIME [epoch: 5.75 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15790503898551606		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.15790503898551606 | validation: 0.1319149369563994]
	TIME [epoch: 5.75 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11266047746745804		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.11266047746745804 | validation: 0.1698029132359039]
	TIME [epoch: 5.79 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635037838763938		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.1635037838763938 | validation: 0.3988188237796503]
	TIME [epoch: 5.75 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25434671820200677		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.25434671820200677 | validation: 0.27937983428167346]
	TIME [epoch: 5.75 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1758810537998836		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.1758810537998836 | validation: 0.2846992961601515]
	TIME [epoch: 5.74 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18148088272509383		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.18148088272509383 | validation: 0.21525645857976186]
	TIME [epoch: 5.75 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14736433187479436		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.14736433187479436 | validation: 0.24343561708880593]
	TIME [epoch: 5.74 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23319276684650217		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.23319276684650217 | validation: 0.2920082379436128]
	TIME [epoch: 5.78 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.189768708439221		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.189768708439221 | validation: 0.15713482853318383]
	TIME [epoch: 5.76 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19637261894531693		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.19637261894531693 | validation: 0.2139001184929405]
	TIME [epoch: 5.74 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.189870539941122		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.189870539941122 | validation: 0.1933612032803921]
	TIME [epoch: 5.74 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13244022778397332		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.13244022778397332 | validation: 0.23446503373962008]
	TIME [epoch: 5.74 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15806456144246503		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.15806456144246503 | validation: 0.17658323526643444]
	TIME [epoch: 5.75 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12626688221446253		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.12626688221446253 | validation: 0.19193990310038608]
	TIME [epoch: 5.75 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17033049496309322		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.17033049496309322 | validation: 0.24007384208024526]
	TIME [epoch: 5.79 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1574873892842977		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.1574873892842977 | validation: 0.14802431349974593]
	TIME [epoch: 5.75 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19865476493512757		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.19865476493512757 | validation: 0.13830837377306004]
	TIME [epoch: 5.75 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13921677061292348		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.13921677061292348 | validation: 0.15107678717450235]
	TIME [epoch: 5.75 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13150693456865764		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.13150693456865764 | validation: 0.08816301037647048]
	TIME [epoch: 5.74 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11913145475260575		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.11913145475260575 | validation: 0.11917836307354204]
	TIME [epoch: 5.74 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13192641849524037		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.13192641849524037 | validation: 0.1620018478691381]
	TIME [epoch: 5.77 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17143589104846652		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.17143589104846652 | validation: 0.12487329582214045]
	TIME [epoch: 5.76 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15172082862017378		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.15172082862017378 | validation: 0.12502561331449258]
	TIME [epoch: 5.75 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312809184546952		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.1312809184546952 | validation: 0.08944412616289128]
	TIME [epoch: 5.75 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1102222106025405		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.1102222106025405 | validation: 0.08880930859549035]
	TIME [epoch: 5.75 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357448700480396		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.1357448700480396 | validation: 0.11108684709558045]
	TIME [epoch: 5.75 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16068973466109315		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.16068973466109315 | validation: 0.13067111762678174]
	TIME [epoch: 5.75 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1881872320333559		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.1881872320333559 | validation: 0.16988745265605878]
	TIME [epoch: 5.79 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20092066984356302		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.20092066984356302 | validation: 0.12427801674477212]
	TIME [epoch: 5.75 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19675525276170203		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.19675525276170203 | validation: 0.1689783119708325]
	TIME [epoch: 5.75 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17337737962265742		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.17337737962265742 | validation: 0.10028795058139915]
	TIME [epoch: 5.74 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12910507240398164		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.12910507240398164 | validation: 0.08894594692343581]
	TIME [epoch: 5.75 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12850364687779292		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.12850364687779292 | validation: 0.09042112497773346]
	TIME [epoch: 5.75 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143976837331597		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.143976837331597 | validation: 0.09215552964153371]
	TIME [epoch: 5.78 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12422940992590328		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.12422940992590328 | validation: 0.10677016714438876]
	TIME [epoch: 5.76 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1475998629871624		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.1475998629871624 | validation: 0.1021020573211445]
	TIME [epoch: 5.75 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15591712268787958		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.15591712268787958 | validation: 0.11828106405137703]
	TIME [epoch: 5.75 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357828264735218		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.1357828264735218 | validation: 0.24722071054426958]
	TIME [epoch: 5.75 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20064577017440322		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.20064577017440322 | validation: 0.22591338140763179]
	TIME [epoch: 5.75 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461946681746955		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.1461946681746955 | validation: 0.13428377976113998]
	TIME [epoch: 5.75 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14522282419570554		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.14522282419570554 | validation: 0.15286779940481598]
	TIME [epoch: 5.79 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11348815446696167		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.11348815446696167 | validation: 0.19094396511049005]
	TIME [epoch: 5.75 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13899099385971392		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.13899099385971392 | validation: 0.1824967736106553]
	TIME [epoch: 5.75 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1158842165942558		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.1158842165942558 | validation: 0.15284090253614285]
	TIME [epoch: 5.75 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14737903408758807		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.14737903408758807 | validation: 0.19425153194838524]
	TIME [epoch: 5.75 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15392361927196047		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.15392361927196047 | validation: 0.17279172015774108]
	TIME [epoch: 5.75 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11861480429479594		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.11861480429479594 | validation: 0.12473324549878789]
	TIME [epoch: 5.78 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13717450839300685		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.13717450839300685 | validation: 0.2543052005491759]
	TIME [epoch: 5.76 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1600998503576307		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.1600998503576307 | validation: 0.2094736737845642]
	TIME [epoch: 5.75 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16947475408800203		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.16947475408800203 | validation: 0.22636473089541853]
	TIME [epoch: 5.75 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14012086712167993		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.14012086712167993 | validation: 0.23226293290489772]
	TIME [epoch: 5.75 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13077102190807685		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.13077102190807685 | validation: 0.14551363152738875]
	TIME [epoch: 5.75 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16147628476267606		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.16147628476267606 | validation: 0.21386984148665517]
	TIME [epoch: 5.75 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479543140004781		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.1479543140004781 | validation: 0.20505545341088408]
	TIME [epoch: 5.79 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128143284282481		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.128143284282481 | validation: 0.18604489262414695]
	TIME [epoch: 5.75 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11586463451696415		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.11586463451696415 | validation: 0.14737207140841085]
	TIME [epoch: 5.75 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10022203829000774		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.10022203829000774 | validation: 0.11522063840559346]
	TIME [epoch: 5.75 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10624020854600226		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.10624020854600226 | validation: 0.11988155945410459]
	TIME [epoch: 5.75 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10830592835104126		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.10830592835104126 | validation: 0.13712187759940556]
	TIME [epoch: 5.75 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09629516129656189		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.09629516129656189 | validation: 0.1375080312450662]
	TIME [epoch: 5.78 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1823680387991614		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.1823680387991614 | validation: 0.336442571664534]
	TIME [epoch: 5.76 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17354733855798696		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.17354733855798696 | validation: 0.19891066781969158]
	TIME [epoch: 5.75 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16301904437030235		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.16301904437030235 | validation: 0.10782504906982354]
	TIME [epoch: 5.75 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14248507295316679		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.14248507295316679 | validation: 0.12914648864693112]
	TIME [epoch: 5.75 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11873692796424792		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.11873692796424792 | validation: 0.1297670494818783]
	TIME [epoch: 5.75 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12290720513884357		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.12290720513884357 | validation: 0.10481727354467094]
	TIME [epoch: 5.75 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10725481095125375		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.10725481095125375 | validation: 0.12026179116018988]
	TIME [epoch: 5.79 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14189912953535322		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.14189912953535322 | validation: 0.17576312794794127]
	TIME [epoch: 5.75 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12715770900543905		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.12715770900543905 | validation: 0.0703050203336292]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_776.pth
	Model improved!!!
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09249361114462491		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.09249361114462491 | validation: 0.07038101319801968]
	TIME [epoch: 5.75 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14722110072524625		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.14722110072524625 | validation: 0.3808050341018708]
	TIME [epoch: 5.74 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28441995589032376		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.28441995589032376 | validation: 0.11222504466406445]
	TIME [epoch: 5.74 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12101565591268473		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.12101565591268473 | validation: 0.0909947046571783]
	TIME [epoch: 5.78 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14015150087968248		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.14015150087968248 | validation: 0.2151794749800996]
	TIME [epoch: 5.75 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16196037515483425		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.16196037515483425 | validation: 0.1272165403688852]
	TIME [epoch: 5.75 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1134173189145496		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.1134173189145496 | validation: 0.12947760524772814]
	TIME [epoch: 5.75 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10171636308523996		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.10171636308523996 | validation: 0.1356202831103677]
	TIME [epoch: 5.74 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09965256497728209		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.09965256497728209 | validation: 0.13528900190736765]
	TIME [epoch: 5.74 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12389695327177758		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.12389695327177758 | validation: 0.11421914486579737]
	TIME [epoch: 5.76 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1192376622712012		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.1192376622712012 | validation: 0.09406592578140317]
	TIME [epoch: 5.78 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14011786980144025		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.14011786980144025 | validation: 0.13925459145814018]
	TIME [epoch: 5.75 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1214367496252575		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.1214367496252575 | validation: 0.12521288711398737]
	TIME [epoch: 5.74 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12131628668858606		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.12131628668858606 | validation: 0.1365939457836142]
	TIME [epoch: 5.74 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11826190895389338		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.11826190895389338 | validation: 0.11157519327319378]
	TIME [epoch: 5.74 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12735423538784355		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.12735423538784355 | validation: 0.1045463325042961]
	TIME [epoch: 5.74 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577706513118667		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.1577706513118667 | validation: 0.13803364876440116]
	TIME [epoch: 5.78 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254103121288155		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.1254103121288155 | validation: 0.11220352188053447]
	TIME [epoch: 5.75 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09927802316017464		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.09927802316017464 | validation: 0.08817470013594375]
	TIME [epoch: 5.74 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09759660500675048		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.09759660500675048 | validation: 0.1176799892965096]
	TIME [epoch: 5.75 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14180291805201659		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.14180291805201659 | validation: 0.17126303640571344]
	TIME [epoch: 5.74 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16066133169217622		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.16066133169217622 | validation: 0.1697142860732304]
	TIME [epoch: 5.75 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396091304990655		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.1396091304990655 | validation: 0.13249455482420947]
	TIME [epoch: 5.76 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13185723082379242		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.13185723082379242 | validation: 0.16387654474724778]
	TIME [epoch: 5.77 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11644898903410181		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.11644898903410181 | validation: 0.187968841194669]
	TIME [epoch: 5.75 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13120105826052292		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.13120105826052292 | validation: 0.13661661464529337]
	TIME [epoch: 5.74 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12155473244995368		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.12155473244995368 | validation: 0.11893340777032037]
	TIME [epoch: 5.75 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1112845618841347		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.1112845618841347 | validation: 0.16314852320413142]
	TIME [epoch: 5.75 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12060644593341466		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.12060644593341466 | validation: 0.11953898868608391]
	TIME [epoch: 5.75 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10690907024600566		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.10690907024600566 | validation: 0.17664685891950796]
	TIME [epoch: 5.79 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12188217364909809		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.12188217364909809 | validation: 0.15737798462389482]
	TIME [epoch: 5.75 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13735305456538002		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.13735305456538002 | validation: 0.10290794582904159]
	TIME [epoch: 5.75 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10185997890199218		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.10185997890199218 | validation: 0.1102253758356002]
	TIME [epoch: 5.74 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11200278029535908		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.11200278029535908 | validation: 0.10884456778635841]
	TIME [epoch: 5.74 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11780122268099827		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.11780122268099827 | validation: 0.0900507092270528]
	TIME [epoch: 5.74 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10246785865987444		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.10246785865987444 | validation: 0.08159293302036331]
	TIME [epoch: 5.76 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10390585261553856		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.10390585261553856 | validation: 0.09258111998335988]
	TIME [epoch: 5.78 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09353369914473494		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.09353369914473494 | validation: 0.09658367825722657]
	TIME [epoch: 5.75 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342187282651931		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.1342187282651931 | validation: 0.17214576906555976]
	TIME [epoch: 5.75 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11441228160499194		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.11441228160499194 | validation: 0.11369926678816945]
	TIME [epoch: 5.75 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10874919709500747		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.10874919709500747 | validation: 0.15237447721604316]
	TIME [epoch: 5.74 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13198870609408		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.13198870609408 | validation: 0.20056247197803423]
	TIME [epoch: 5.74 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24673800852207062		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.24673800852207062 | validation: 0.18563531827656576]
	TIME [epoch: 5.79 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13265732354725043		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.13265732354725043 | validation: 0.11462882806179031]
	TIME [epoch: 5.75 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09389610913393448		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.09389610913393448 | validation: 0.0925451717816441]
	TIME [epoch: 5.75 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10592651677488828		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.10592651677488828 | validation: 0.11184879943766954]
	TIME [epoch: 5.75 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1128446256603676		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.1128446256603676 | validation: 0.16285212951219358]
	TIME [epoch: 5.75 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1186907514783109		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.1186907514783109 | validation: 0.08168289390958933]
	TIME [epoch: 5.75 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10648873829956024		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.10648873829956024 | validation: 0.09784221705031106]
	TIME [epoch: 5.76 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09396179731156891		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.09396179731156891 | validation: 0.09491701143114308]
	TIME [epoch: 5.78 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10035073277599858		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.10035073277599858 | validation: 0.13148258752939054]
	TIME [epoch: 5.75 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261814055396152		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.1261814055396152 | validation: 0.15282714142955878]
	TIME [epoch: 5.75 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10963415474686591		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.10963415474686591 | validation: 0.17684794502970838]
	TIME [epoch: 5.74 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12413554951680196		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.12413554951680196 | validation: 0.12742717915197013]
	TIME [epoch: 5.75 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08358410893813722		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.08358410893813722 | validation: 0.08598586110375649]
	TIME [epoch: 5.75 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09442359823424587		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.09442359823424587 | validation: 0.0990270018653504]
	TIME [epoch: 5.79 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09991435414098816		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.09991435414098816 | validation: 0.10583103079315392]
	TIME [epoch: 5.75 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11999437340954296		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.11999437340954296 | validation: 0.12598538718650956]
	TIME [epoch: 5.75 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11113163172867851		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.11113163172867851 | validation: 0.1328198469907581]
	TIME [epoch: 5.75 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12508356259535874		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.12508356259535874 | validation: 0.12838848244753462]
	TIME [epoch: 5.75 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12204804161678556		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.12204804161678556 | validation: 0.12583267437056658]
	TIME [epoch: 5.75 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0965710326990873		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.0965710326990873 | validation: 0.1533181894531394]
	TIME [epoch: 5.76 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10727275022438319		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.10727275022438319 | validation: 0.08414147255427462]
	TIME [epoch: 5.78 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09545466598106289		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.09545466598106289 | validation: 0.12109141761787498]
	TIME [epoch: 5.75 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12424551947143447		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.12424551947143447 | validation: 0.12309627728456782]
	TIME [epoch: 5.75 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10998310533169328		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.10998310533169328 | validation: 0.10992892700798568]
	TIME [epoch: 5.75 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11214154070189462		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.11214154070189462 | validation: 0.07527657035167958]
	TIME [epoch: 5.75 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08315819550945897		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.08315819550945897 | validation: 0.1594858667996559]
	TIME [epoch: 5.75 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1889818357538107		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.1889818357538107 | validation: 0.11299229303030092]
	TIME [epoch: 5.79 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11480142929151103		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.11480142929151103 | validation: 0.09835708653060579]
	TIME [epoch: 5.75 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13347767197228472		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.13347767197228472 | validation: 0.08584459353183352]
	TIME [epoch: 5.75 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12735099025205154		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.12735099025205154 | validation: 0.08467414416380951]
	TIME [epoch: 5.75 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10233686337714426		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.10233686337714426 | validation: 0.08698709791342807]
	TIME [epoch: 5.75 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09889831707439646		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.09889831707439646 | validation: 0.08913556054201738]
	TIME [epoch: 5.75 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09457258116064876		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.09457258116064876 | validation: 0.08910573229549158]
	TIME [epoch: 5.76 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11803243961255758		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.11803243961255758 | validation: 0.10655183152459095]
	TIME [epoch: 5.78 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09372832022557712		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.09372832022557712 | validation: 0.09148420467485362]
	TIME [epoch: 5.75 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09078075694260143		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.09078075694260143 | validation: 0.1255804428217823]
	TIME [epoch: 5.75 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12281150000309872		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.12281150000309872 | validation: 0.11348411501739786]
	TIME [epoch: 5.75 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08948129367417011		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.08948129367417011 | validation: 0.09425159113758422]
	TIME [epoch: 5.76 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12081747875961743		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.12081747875961743 | validation: 0.10971946571824007]
	TIME [epoch: 5.75 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10675477676879672		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.10675477676879672 | validation: 0.13446324449237693]
	TIME [epoch: 5.79 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13569337042209137		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.13569337042209137 | validation: 0.08408965951878627]
	TIME [epoch: 5.75 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10330935954848425		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.10330935954848425 | validation: 0.07584031067983386]
	TIME [epoch: 5.74 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08368268213608326		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.08368268213608326 | validation: 0.0697823863228214]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_861.pth
	Model improved!!!
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08385345073870423		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.08385345073870423 | validation: 0.09060117025320845]
	TIME [epoch: 5.75 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1311169371929517		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.1311169371929517 | validation: 0.18520102904186783]
	TIME [epoch: 5.75 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12699811543272035		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.12699811543272035 | validation: 0.1097503224015881]
	TIME [epoch: 5.79 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10287251893497225		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.10287251893497225 | validation: 0.11580825077488471]
	TIME [epoch: 5.77 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08892565642708694		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.08892565642708694 | validation: 0.1305828308101776]
	TIME [epoch: 5.76 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062671463140133		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.1062671463140133 | validation: 0.10907055146844112]
	TIME [epoch: 5.75 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12928404992850429		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.12928404992850429 | validation: 0.13734347072111217]
	TIME [epoch: 5.75 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0932599631294827		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.0932599631294827 | validation: 0.12868764634779403]
	TIME [epoch: 5.75 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10296701566410543		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.10296701566410543 | validation: 0.11899324352277227]
	TIME [epoch: 5.75 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08650459124774924		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.08650459124774924 | validation: 0.08868412757222256]
	TIME [epoch: 5.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09714017323818176		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.09714017323818176 | validation: 0.11629705419540201]
	TIME [epoch: 5.75 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10395701089962588		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.10395701089962588 | validation: 0.10985493986397528]
	TIME [epoch: 5.76 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10647751389163351		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.10647751389163351 | validation: 0.10879507891553632]
	TIME [epoch: 5.75 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09756599129128098		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.09756599129128098 | validation: 0.1158049505188551]
	TIME [epoch: 5.76 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09843883642462405		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.09843883642462405 | validation: 0.08890024458900078]
	TIME [epoch: 5.75 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09088339393997832		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.09088339393997832 | validation: 0.11309077627633876]
	TIME [epoch: 5.79 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11135012645407191		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.11135012645407191 | validation: 0.201732838240657]
	TIME [epoch: 5.78 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355787779375637		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.1355787779375637 | validation: 0.0949294148141382]
	TIME [epoch: 5.76 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12488313126317994		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.12488313126317994 | validation: 0.12344648355103106]
	TIME [epoch: 5.76 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10641672947517097		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.10641672947517097 | validation: 0.10169833176712505]
	TIME [epoch: 5.75 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10418182930929612		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.10418182930929612 | validation: 0.08882462494242147]
	TIME [epoch: 5.75 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08568438164524644		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.08568438164524644 | validation: 0.1260448803080317]
	TIME [epoch: 5.76 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10265204433525191		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.10265204433525191 | validation: 0.12431486499241437]
	TIME [epoch: 5.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09528112039474074		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.09528112039474074 | validation: 0.10917082092352214]
	TIME [epoch: 5.76 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08857750182335		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.08857750182335 | validation: 0.15210559720510747]
	TIME [epoch: 5.76 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10180616968014308		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.10180616968014308 | validation: 0.16418315798326538]
	TIME [epoch: 5.76 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11952373824897106		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.11952373824897106 | validation: 0.16958041814735345]
	TIME [epoch: 5.76 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10557559846015363		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.10557559846015363 | validation: 0.13114455030524766]
	TIME [epoch: 5.75 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10633862762354701		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.10633862762354701 | validation: 0.16165058037589694]
	TIME [epoch: 5.79 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1170161818874401		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.1170161818874401 | validation: 0.1174614204478816]
	TIME [epoch: 5.77 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356924840873926		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.09356924840873926 | validation: 0.13551150676683577]
	TIME [epoch: 5.76 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09553111179796846		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.09553111179796846 | validation: 0.08968718305559394]
	TIME [epoch: 5.76 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08604873205767374		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.08604873205767374 | validation: 0.10380308830924616]
	TIME [epoch: 5.76 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0958620427191765		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.0958620427191765 | validation: 0.09163967757210913]
	TIME [epoch: 5.76 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08911231292122909		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.08911231292122909 | validation: 0.10243105910104969]
	TIME [epoch: 5.76 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0905407546710524		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.0905407546710524 | validation: 0.09180204872000403]
	TIME [epoch: 5.8 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10463583306763682		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.10463583306763682 | validation: 0.09061890299239896]
	TIME [epoch: 5.76 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07890437465420205		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.07890437465420205 | validation: 0.08912560765155828]
	TIME [epoch: 5.75 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09210652044018325		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.09210652044018325 | validation: 0.11867467443437205]
	TIME [epoch: 5.76 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09548715991557591		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.09548715991557591 | validation: 0.06694825119776089]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_901.pth
	Model improved!!!
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07600266766151607		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.07600266766151607 | validation: 0.07865626550700165]
	TIME [epoch: 5.76 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08110386074194043		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.08110386074194043 | validation: 0.10559592662413687]
	TIME [epoch: 5.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09870541519297987		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.09870541519297987 | validation: 0.11167775902602813]
	TIME [epoch: 5.76 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08204006844647098		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.08204006844647098 | validation: 0.08463587023461099]
	TIME [epoch: 5.75 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09695494792541354		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.09695494792541354 | validation: 0.096093665780134]
	TIME [epoch: 5.75 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07917965765971492		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.07917965765971492 | validation: 0.11835511484837458]
	TIME [epoch: 5.75 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09759452550006542		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.09759452550006542 | validation: 0.103267229167835]
	TIME [epoch: 5.75 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10837727576498267		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.10837727576498267 | validation: 0.11577948656059463]
	TIME [epoch: 5.77 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11144572012029565		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.11144572012029565 | validation: 0.09117037683774895]
	TIME [epoch: 5.78 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11052406796667189		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.11052406796667189 | validation: 0.07787670498204317]
	TIME [epoch: 5.76 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11877429560475566		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.11877429560475566 | validation: 0.09467522285198043]
	TIME [epoch: 5.75 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0990024599677341		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.0990024599677341 | validation: 0.1022891945657891]
	TIME [epoch: 5.75 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10056768655130287		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.10056768655130287 | validation: 0.09060168525633676]
	TIME [epoch: 5.75 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09692908183110129		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.09692908183110129 | validation: 0.07894384143417671]
	TIME [epoch: 5.75 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08517856644135348		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.08517856644135348 | validation: 0.07871790964855398]
	TIME [epoch: 5.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09994093567596866		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.09994093567596866 | validation: 0.07896005159923196]
	TIME [epoch: 5.76 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1064644561615018		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.1064644561615018 | validation: 0.07797431595556044]
	TIME [epoch: 5.75 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12379854122372604		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.12379854122372604 | validation: 0.12015627578286207]
	TIME [epoch: 5.75 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09554278146967074		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.09554278146967074 | validation: 0.08768823807790982]
	TIME [epoch: 5.75 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08880467589477303		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.08880467589477303 | validation: 0.08022712502467323]
	TIME [epoch: 5.75 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11258830166143598		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.11258830166143598 | validation: 0.1265769068453224]
	TIME [epoch: 5.76 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13880553456039474		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.13880553456039474 | validation: 0.09748534153044021]
	TIME [epoch: 5.78 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10732768285160083		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.10732768285160083 | validation: 0.12194158499784015]
	TIME [epoch: 5.75 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09297525786160143		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.09297525786160143 | validation: 0.09183060324463674]
	TIME [epoch: 5.75 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09491357058985544		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.09491357058985544 | validation: 0.08915558308084728]
	TIME [epoch: 5.75 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07798636022719987		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.07798636022719987 | validation: 0.11034563146355372]
	TIME [epoch: 5.75 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08509604477029781		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.08509604477029781 | validation: 0.09204598464399062]
	TIME [epoch: 5.76 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832780914139554		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.0832780914139554 | validation: 0.10205165909604907]
	TIME [epoch: 5.79 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07292682000499282		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.07292682000499282 | validation: 0.07934657905128792]
	TIME [epoch: 5.76 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08659446387131275		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.08659446387131275 | validation: 0.09484972208880973]
	TIME [epoch: 5.76 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0725887081499708		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.0725887081499708 | validation: 0.08754893609784664]
	TIME [epoch: 5.75 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0897613652847933		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.0897613652847933 | validation: 0.10585000216548769]
	TIME [epoch: 5.75 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09606264042432276		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.09606264042432276 | validation: 0.12228202486589186]
	TIME [epoch: 5.75 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11576588070480426		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.11576588070480426 | validation: 0.10148769295265854]
	TIME [epoch: 5.76 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11486881329655532		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.11486881329655532 | validation: 0.09764810226764788]
	TIME [epoch: 5.79 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11799935653000357		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.11799935653000357 | validation: 0.11695155666991307]
	TIME [epoch: 5.76 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09262224628248228		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.09262224628248228 | validation: 0.12053403867265691]
	TIME [epoch: 5.75 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08497702882370042		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.08497702882370042 | validation: 0.09700469684815202]
	TIME [epoch: 5.75 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07901484026309663		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.07901484026309663 | validation: 0.08863297999400455]
	TIME [epoch: 5.76 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08277693205757977		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.08277693205757977 | validation: 0.11686952484120663]
	TIME [epoch: 5.75 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1175411779263308		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.1175411779263308 | validation: 0.09584141348362452]
	TIME [epoch: 5.79 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09057454001263607		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.09057454001263607 | validation: 0.10481854005549439]
	TIME [epoch: 5.76 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09741567042769844		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.09741567042769844 | validation: 0.1102765407402223]
	TIME [epoch: 5.75 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0991616949253014		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.0991616949253014 | validation: 0.11378809821626014]
	TIME [epoch: 5.75 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11944357647126538		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.11944357647126538 | validation: 0.08075473664483063]
	TIME [epoch: 5.75 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08791025809204024		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.08791025809204024 | validation: 0.09638382008627414]
	TIME [epoch: 5.75 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09492677575205535		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.09492677575205535 | validation: 0.08041436833990863]
	TIME [epoch: 5.77 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1043628486684769		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.1043628486684769 | validation: 0.0725079816797074]
	TIME [epoch: 5.78 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08091163336039953		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.08091163336039953 | validation: 0.10279085223912832]
	TIME [epoch: 5.75 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0904702806653581		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.0904702806653581 | validation: 0.07064076020269065]
	TIME [epoch: 5.75 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08288255470778544		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.08288255470778544 | validation: 0.07500086716282554]
	TIME [epoch: 5.75 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07427964493551636		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.07427964493551636 | validation: 0.07390396677844643]
	TIME [epoch: 5.75 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08946373488017421		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.08946373488017421 | validation: 0.08090529008199568]
	TIME [epoch: 5.75 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07237454565602022		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.07237454565602022 | validation: 0.10404041598264532]
	TIME [epoch: 5.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09773612423536435		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.09773612423536435 | validation: 0.13341765468201394]
	TIME [epoch: 5.76 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09249736526518704		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.09249736526518704 | validation: 0.14678985875093667]
	TIME [epoch: 5.75 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10414207050588065		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.10414207050588065 | validation: 0.15837136418309572]
	TIME [epoch: 5.75 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12392212142229617		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.12392212142229617 | validation: 0.12111970630062197]
	TIME [epoch: 5.75 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10172642840935683		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.10172642840935683 | validation: 0.10701767645294857]
	TIME [epoch: 5.75 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07818072347681765		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.07818072347681765 | validation: 0.11523200419118171]
	TIME [epoch: 5.78 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10027094447459373		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.10027094447459373 | validation: 0.10921241624393078]
	TIME [epoch: 5.76 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09882487271703513		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.09882487271703513 | validation: 0.13521739287261764]
	TIME [epoch: 5.75 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09909794477490967		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.09909794477490967 | validation: 0.11821486905531917]
	TIME [epoch: 5.75 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0941586125578468		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.0941586125578468 | validation: 0.1193283608590944]
	TIME [epoch: 5.75 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08562367834923447		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.08562367834923447 | validation: 0.11378653858473764]
	TIME [epoch: 5.75 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09887549115108224		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.09887549115108224 | validation: 0.16530952773610547]
	TIME [epoch: 5.75 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11960698092889567		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.11960698092889567 | validation: 0.16396895571504844]
	TIME [epoch: 5.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12070569732468028		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.12070569732468028 | validation: 0.14508389124526794]
	TIME [epoch: 5.75 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09067120183270877		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.09067120183270877 | validation: 0.14303363891950555]
	TIME [epoch: 5.75 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10907372468455993		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.10907372468455993 | validation: 0.12159604954564587]
	TIME [epoch: 5.75 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09394130709228155		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.09394130709228155 | validation: 0.15662727390190945]
	TIME [epoch: 5.75 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1135834518100774		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.1135834518100774 | validation: 0.12768294736147262]
	TIME [epoch: 5.75 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09660539365051751		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.09660539365051751 | validation: 0.1708347074055631]
	TIME [epoch: 5.78 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10864088710028993		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.10864088710028993 | validation: 0.15103916939816525]
	TIME [epoch: 5.77 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10243621703905305		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.10243621703905305 | validation: 0.14015574311094117]
	TIME [epoch: 5.75 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10051141319080738		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.10051141319080738 | validation: 0.12258884256779931]
	TIME [epoch: 5.76 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10036557573673528		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.10036557573673528 | validation: 0.132708760007299]
	TIME [epoch: 5.75 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09796244421163781		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.09796244421163781 | validation: 0.09768914919277558]
	TIME [epoch: 5.75 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07943953353885845		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.07943953353885845 | validation: 0.09737004992293675]
	TIME [epoch: 5.75 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0800587357957756		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.0800587357957756 | validation: 0.08449361495561293]
	TIME [epoch: 5.79 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08024361204088244		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.08024361204088244 | validation: 0.09193703499591935]
	TIME [epoch: 5.75 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08236606528300947		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.08236606528300947 | validation: 0.09737276087388316]
	TIME [epoch: 5.75 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10519556526775262		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.10519556526775262 | validation: 0.07870702376163932]
	TIME [epoch: 5.75 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09026230635423901		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.09026230635423901 | validation: 0.08381814697312354]
	TIME [epoch: 5.75 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07826416002138022		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.07826416002138022 | validation: 0.10848642038520481]
	TIME [epoch: 5.75 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08685727528453926		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.08685727528453926 | validation: 0.11904238566356296]
	TIME [epoch: 5.78 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08198941331206164		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.08198941331206164 | validation: 0.09032836311479493]
	TIME [epoch: 5.77 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07352894879655203		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.07352894879655203 | validation: 0.09435405903956536]
	TIME [epoch: 5.75 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07957975635531771		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.07957975635531771 | validation: 0.08803810007722249]
	TIME [epoch: 5.75 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07542033896777761		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.07542033896777761 | validation: 0.0909540400538808]
	TIME [epoch: 5.75 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07476012398306517		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.07476012398306517 | validation: 0.09599396046957427]
	TIME [epoch: 5.75 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07460741033449024		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.07460741033449024 | validation: 0.08079136229998754]
	TIME [epoch: 5.75 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07023078438113173		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.07023078438113173 | validation: 0.10687943141121214]
	TIME [epoch: 5.79 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11661857507066153		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.11661857507066153 | validation: 0.12139476781708129]
	TIME [epoch: 5.75 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10035341465164259		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.10035341465164259 | validation: 0.09317014193345954]
	TIME [epoch: 5.75 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07751502113414699		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.07751502113414699 | validation: 0.0745533904693471]
	TIME [epoch: 5.75 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07317256826415369		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.07317256826415369 | validation: 0.08178669845632847]
	TIME [epoch: 5.75 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07216751807908638		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.07216751807908638 | validation: 0.08783844764369704]
	TIME [epoch: 5.75 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09577110868015147		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.09577110868015147 | validation: 0.1148903518143412]
	TIME [epoch: 5.78 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09098780237898993		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.09098780237898993 | validation: 0.07394032511504219]
	TIME [epoch: 5.77 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0703552760784803		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.0703552760784803 | validation: 0.07816141549144684]
	TIME [epoch: 5.75 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07689936885628065		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.07689936885628065 | validation: 0.08010510540574624]
	TIME [epoch: 5.74 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08715136499229029		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.08715136499229029 | validation: 0.07279112734050937]
	TIME [epoch: 5.75 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07268827404711918		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.07268827404711918 | validation: 0.07403802300879274]
	TIME [epoch: 5.75 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09584206943153128		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.09584206943153128 | validation: 0.12644628835581986]
	TIME [epoch: 5.75 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291084465877263		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.10291084465877263 | validation: 0.09552130173638801]
	TIME [epoch: 5.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11703268799023622		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.11703268799023622 | validation: 0.09646143127397629]
	TIME [epoch: 5.75 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10465820361085941		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.10465820361085941 | validation: 0.06805745512801074]
	TIME [epoch: 5.75 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09304913601926161		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.09304913601926161 | validation: 0.06472780896376704]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_1010.pth
	Model improved!!!
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08514271169589478		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.08514271169589478 | validation: 0.08014723131296828]
	TIME [epoch: 5.75 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07613302534842839		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.07613302534842839 | validation: 0.07303587164642503]
	TIME [epoch: 5.74 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08386763941859397		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.08386763941859397 | validation: 0.07480473729333867]
	TIME [epoch: 5.78 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872841977184172		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.07872841977184172 | validation: 0.07370768670250717]
	TIME [epoch: 5.75 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08285934313330257		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.08285934313330257 | validation: 0.08667438280974679]
	TIME [epoch: 5.75 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08964258973649432		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.08964258973649432 | validation: 0.08886668875766927]
	TIME [epoch: 5.75 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07989302968318765		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.07989302968318765 | validation: 0.10029344431709594]
	TIME [epoch: 5.75 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08188008224630888		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.08188008224630888 | validation: 0.10238156647550437]
	TIME [epoch: 5.75 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0751927009374088		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.0751927009374088 | validation: 0.08736708803516478]
	TIME [epoch: 5.76 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07065993055029811		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.07065993055029811 | validation: 0.08785678550343808]
	TIME [epoch: 5.78 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07962170523327762		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.07962170523327762 | validation: 0.09329111502597486]
	TIME [epoch: 5.75 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0811403089065008		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.0811403089065008 | validation: 0.07201177196016474]
	TIME [epoch: 5.74 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08670981044750252		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.08670981044750252 | validation: 0.07763075697926237]
	TIME [epoch: 5.74 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09257200410848362		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.09257200410848362 | validation: 0.10315850610000986]
	TIME [epoch: 5.74 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09319735609914523		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.09319735609914523 | validation: 0.0803361584536589]
	TIME [epoch: 5.75 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0732324088333142		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.0732324088333142 | validation: 0.07137300136237984]
	TIME [epoch: 5.79 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07839695093785173		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.07839695093785173 | validation: 0.07372968904132604]
	TIME [epoch: 5.75 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08695973078377255		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.08695973078377255 | validation: 0.10144411740016007]
	TIME [epoch: 5.75 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09262629877524722		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.09262629877524722 | validation: 0.07568846715456869]
	TIME [epoch: 5.75 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09081653026971476		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.09081653026971476 | validation: 0.07416688541736347]
	TIME [epoch: 5.75 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08082628424043925		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.08082628424043925 | validation: 0.0661053797847788]
	TIME [epoch: 5.74 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07313688989799208		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.07313688989799208 | validation: 0.08032972759104448]
	TIME [epoch: 5.76 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07475559283061332		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.07475559283061332 | validation: 0.0913265862882667]
	TIME [epoch: 5.77 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08413748173681626		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.08413748173681626 | validation: 0.0837203785664763]
	TIME [epoch: 5.75 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08158351106634597		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.08158351106634597 | validation: 0.08072164369087378]
	TIME [epoch: 5.75 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08560168672031679		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.08560168672031679 | validation: 0.07651258783003953]
	TIME [epoch: 5.75 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08063986080714257		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.08063986080714257 | validation: 0.06479785210680873]
	TIME [epoch: 5.75 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08021946306011157		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.08021946306011157 | validation: 0.06547822229904078]
	TIME [epoch: 5.74 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0843851884389251		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.0843851884389251 | validation: 0.0659211238088017]
	TIME [epoch: 5.79 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09475504353740172		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.09475504353740172 | validation: 0.10797052829184413]
	TIME [epoch: 5.75 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10360002154740686		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.10360002154740686 | validation: 0.06442900124041159]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_1041.pth
	Model improved!!!
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09052666298549555		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.09052666298549555 | validation: 0.0769457837461547]
	TIME [epoch: 5.74 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08268716350086273		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.08268716350086273 | validation: 0.06472255385680428]
	TIME [epoch: 5.74 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08857615194828217		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.08857615194828217 | validation: 0.07627484352105603]
	TIME [epoch: 5.74 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08698321159702899		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.08698321159702899 | validation: 0.06373334184544156]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_1045.pth
	Model improved!!!
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08419704947946657		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.08419704947946657 | validation: 0.08611993498937594]
	TIME [epoch: 5.78 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0918601888016237		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.0918601888016237 | validation: 0.07631705249796815]
	TIME [epoch: 5.75 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.094030043596177		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.094030043596177 | validation: 0.08055945026164593]
	TIME [epoch: 5.75 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802185004803215		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.07802185004803215 | validation: 0.07822094440578055]
	TIME [epoch: 5.75 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08142616654546465		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.08142616654546465 | validation: 0.06822987540101307]
	TIME [epoch: 5.75 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08333913841973659		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.08333913841973659 | validation: 0.07758441441791472]
	TIME [epoch: 5.75 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07466831263922576		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.07466831263922576 | validation: 0.09184291550935736]
	TIME [epoch: 5.79 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07978876446989755		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.07978876446989755 | validation: 0.06235628037754071]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_1053.pth
	Model improved!!!
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08446869080040348		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.08446869080040348 | validation: 0.09043584896372096]
	TIME [epoch: 5.74 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08220387263232694		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.08220387263232694 | validation: 0.07656754347071491]
	TIME [epoch: 5.74 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08543429304500239		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.08543429304500239 | validation: 0.07995420117537949]
	TIME [epoch: 5.74 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07635668430747161		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.07635668430747161 | validation: 0.07267432577784098]
	TIME [epoch: 5.74 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08630799693961623		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.08630799693961623 | validation: 0.08867262212861374]
	TIME [epoch: 5.78 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0912113928112578		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.0912113928112578 | validation: 0.06479794461164941]
	TIME [epoch: 5.76 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09228981893518479		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.09228981893518479 | validation: 0.061322193527439235]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_1060.pth
	Model improved!!!
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0895549555119918		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.0895549555119918 | validation: 0.07333180140003984]
	TIME [epoch: 5.74 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0946402169111661		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.0946402169111661 | validation: 0.07397209124103402]
	TIME [epoch: 5.74 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11190860203613855		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.11190860203613855 | validation: 0.08299698714591255]
	TIME [epoch: 5.74 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07783391052105917		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.07783391052105917 | validation: 0.08741173187163691]
	TIME [epoch: 5.75 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07354297682256088		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.07354297682256088 | validation: 0.07782249313634147]
	TIME [epoch: 5.77 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0773644514163762		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.0773644514163762 | validation: 0.08618679635771918]
	TIME [epoch: 5.74 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08407126001655227		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.08407126001655227 | validation: 0.09520439953686108]
	TIME [epoch: 5.74 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0835676965746909		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.0835676965746909 | validation: 0.07659929133643617]
	TIME [epoch: 5.74 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08596457527803056		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.08596457527803056 | validation: 0.07806558732719664]
	TIME [epoch: 5.74 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07458364502321915		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.07458364502321915 | validation: 0.07049622415590462]
	TIME [epoch: 5.74 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07126371122596306		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.07126371122596306 | validation: 0.09963740975830349]
	TIME [epoch: 5.78 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09244634162607768		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.09244634162607768 | validation: 0.07886555020892312]
	TIME [epoch: 5.75 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07650364155753762		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.07650364155753762 | validation: 0.08747137311456951]
	TIME [epoch: 5.74 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08427597831854258		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.08427597831854258 | validation: 0.08844311797564787]
	TIME [epoch: 5.74 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10480189768465287		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.10480189768465287 | validation: 0.08586785566282053]
	TIME [epoch: 5.74 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271483935247643		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.1271483935247643 | validation: 0.08735190466080776]
	TIME [epoch: 5.74 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10495293825156637		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.10495293825156637 | validation: 0.0782661597097341]
	TIME [epoch: 5.75 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07981199348629439		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.07981199348629439 | validation: 0.08556283326177791]
	TIME [epoch: 5.77 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07834854940639513		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.07834854940639513 | validation: 0.09834912947891875]
	TIME [epoch: 5.74 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0684438093564938		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.0684438093564938 | validation: 0.07422231197460737]
	TIME [epoch: 5.74 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06664346857482287		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.06664346857482287 | validation: 0.07860575676263407]
	TIME [epoch: 5.74 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06669472976976554		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.06669472976976554 | validation: 0.08358476283816078]
	TIME [epoch: 5.74 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07537688293776733		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.07537688293776733 | validation: 0.07053090103431686]
	TIME [epoch: 5.74 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06842966065554186		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.06842966065554186 | validation: 0.06919469538217347]
	TIME [epoch: 5.78 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06675780946176524		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.06675780946176524 | validation: 0.06640094084277824]
	TIME [epoch: 5.75 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06791733260782332		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.06791733260782332 | validation: 0.09463325146015382]
	TIME [epoch: 5.74 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08080796288722636		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.08080796288722636 | validation: 0.12129551278635888]
	TIME [epoch: 5.74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08304831174496502		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.08304831174496502 | validation: 0.1201831743009945]
	TIME [epoch: 5.74 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0924177064791961		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.0924177064791961 | validation: 0.08556858506735102]
	TIME [epoch: 5.74 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06712173886728139		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.06712173886728139 | validation: 0.0685652283632684]
	TIME [epoch: 5.75 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07124415725617769		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.07124415725617769 | validation: 0.0951616791056853]
	TIME [epoch: 5.77 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07219888823208442		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.07219888823208442 | validation: 0.08394455710604883]
	TIME [epoch: 5.74 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07752508589778628		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.07752508589778628 | validation: 0.1005929748138405]
	TIME [epoch: 5.74 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0770068159778252		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.0770068159778252 | validation: 0.10222719852082833]
	TIME [epoch: 5.74 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07401702895472126		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.07401702895472126 | validation: 0.07467759689141099]
	TIME [epoch: 5.74 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.064874485139076		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.064874485139076 | validation: 0.07788297047432491]
	TIME [epoch: 5.74 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08239897299107694		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.08239897299107694 | validation: 0.06417795978354117]
	TIME [epoch: 5.78 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08221443313553753		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.08221443313553753 | validation: 0.06556288369936744]
	TIME [epoch: 5.75 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07134671837132667		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.07134671837132667 | validation: 0.07468777426506981]
	TIME [epoch: 5.74 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07422532829750196		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.07422532829750196 | validation: 0.0774701579891037]
	TIME [epoch: 5.74 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0708948327152429		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.0708948327152429 | validation: 0.06745470342951176]
	TIME [epoch: 5.74 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07071723533316134		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.07071723533316134 | validation: 0.07978112653381954]
	TIME [epoch: 5.74 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09191657210169024		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.09191657210169024 | validation: 0.11046709317505152]
	TIME [epoch: 5.75 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10600713145674809		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.10600713145674809 | validation: 0.087611581008703]
	TIME [epoch: 5.77 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07596721378012036		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.07596721378012036 | validation: 0.08385905110417859]
	TIME [epoch: 5.74 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08078447388834022		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.08078447388834022 | validation: 0.10786138377414943]
	TIME [epoch: 5.74 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08314936728693062		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.08314936728693062 | validation: 0.09761398213636385]
	TIME [epoch: 5.74 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09843698012614716		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.09843698012614716 | validation: 0.11963257251593987]
	TIME [epoch: 5.74 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09375484954513534		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.09375484954513534 | validation: 0.09766412631731435]
	TIME [epoch: 5.74 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08482282711628478		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.08482282711628478 | validation: 0.12425617653664191]
	TIME [epoch: 5.78 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09947473334558359		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.09947473334558359 | validation: 0.11231151575073497]
	TIME [epoch: 5.74 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08078058222307373		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.08078058222307373 | validation: 0.1011947250100139]
	TIME [epoch: 5.74 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08463250087041906		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.08463250087041906 | validation: 0.10813790158398424]
	TIME [epoch: 5.74 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07619939945467832		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.07619939945467832 | validation: 0.09799583746806705]
	TIME [epoch: 5.74 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0772036190691846		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.0772036190691846 | validation: 0.11416057154167061]
	TIME [epoch: 5.74 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09038268568608701		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.09038268568608701 | validation: 0.08199957179123019]
	TIME [epoch: 5.75 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07785910892769524		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.07785910892769524 | validation: 0.08691180728428463]
	TIME [epoch: 5.77 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07122306914104923		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.07122306914104923 | validation: 0.09873363898965869]
	TIME [epoch: 5.74 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09929374277826111		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.09929374277826111 | validation: 0.12549826721474813]
	TIME [epoch: 5.74 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07526744828154337		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.07526744828154337 | validation: 0.09145656834627826]
	TIME [epoch: 5.74 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07103928556794323		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.07103928556794323 | validation: 0.10656806484757736]
	TIME [epoch: 5.74 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07965652309435936		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.07965652309435936 | validation: 0.09972489190668608]
	TIME [epoch: 5.74 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07223413571459589		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.07223413571459589 | validation: 0.09375449398067712]
	TIME [epoch: 5.78 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0769871780363229		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.0769871780363229 | validation: 0.10972420761642625]
	TIME [epoch: 5.75 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10814452096889371		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.10814452096889371 | validation: 0.10612982691955898]
	TIME [epoch: 5.74 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08125623147909816		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.08125623147909816 | validation: 0.07514194510450292]
	TIME [epoch: 5.74 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07615292798697024		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.07615292798697024 | validation: 0.06547775642912983]
	TIME [epoch: 5.74 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06952791089750104		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.06952791089750104 | validation: 0.07001921666326535]
	TIME [epoch: 5.74 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0641813114014065		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.0641813114014065 | validation: 0.09724684975875442]
	TIME [epoch: 5.75 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07690007890687198		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.07690007890687198 | validation: 0.06557167955736615]
	TIME [epoch: 5.77 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07675159795402166		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.07675159795402166 | validation: 0.0665186297053749]
	TIME [epoch: 5.74 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07850053587190381		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.07850053587190381 | validation: 0.08125752165884155]
	TIME [epoch: 5.74 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08422489363018876		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.08422489363018876 | validation: 0.07613632712972827]
	TIME [epoch: 5.74 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789361937457423		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.07789361937457423 | validation: 0.06476728403457821]
	TIME [epoch: 5.74 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07636798449667402		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.07636798449667402 | validation: 0.060682559001287356]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_1135.pth
	Model improved!!!
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802057572775911		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.07802057572775911 | validation: 0.07197035237889088]
	TIME [epoch: 5.79 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07781728840375862		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.07781728840375862 | validation: 0.07895748548305502]
	TIME [epoch: 5.74 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08710000866002905		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.08710000866002905 | validation: 0.06703019682841417]
	TIME [epoch: 5.74 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08043536301749649		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.08043536301749649 | validation: 0.07651240185832782]
	TIME [epoch: 5.74 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07162255803645913		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.07162255803645913 | validation: 0.06631940602008303]
	TIME [epoch: 5.74 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07465790283158477		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.07465790283158477 | validation: 0.07849403783907616]
	TIME [epoch: 5.74 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07181965786569423		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.07181965786569423 | validation: 0.06521199003310535]
	TIME [epoch: 5.77 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06620115364964853		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.06620115364964853 | validation: 0.06485322682342204]
	TIME [epoch: 5.76 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06944777097115899		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.06944777097115899 | validation: 0.08380821752808021]
	TIME [epoch: 5.74 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791541200367076		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.0791541200367076 | validation: 0.0725653367370223]
	TIME [epoch: 5.74 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08121000104620983		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.08121000104620983 | validation: 0.06152888129159895]
	TIME [epoch: 5.74 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08047129497228461		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.08047129497228461 | validation: 0.06573694068506857]
	TIME [epoch: 5.74 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07862705101855554		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.07862705101855554 | validation: 0.06550568581993942]
	TIME [epoch: 5.74 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06638729174550663		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.06638729174550663 | validation: 0.06832574107752003]
	TIME [epoch: 5.78 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07054439062613402		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.07054439062613402 | validation: 0.07183096358500062]
	TIME [epoch: 5.74 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06858608502131491		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.06858608502131491 | validation: 0.06087044350473043]
	TIME [epoch: 5.74 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07732815794130174		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.07732815794130174 | validation: 0.057711537178829965]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_1152.pth
	Model improved!!!
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.076338440457711		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.076338440457711 | validation: 0.05512266399190938]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_1153.pth
	Model improved!!!
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07946942466701662		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.07946942466701662 | validation: 0.06486401880146388]
	TIME [epoch: 6.01 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07215281554399454		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.07215281554399454 | validation: 0.05769038640873889]
	TIME [epoch: 5.79 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07479675879776157		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.07479675879776157 | validation: 0.06829089278127652]
	TIME [epoch: 5.75 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08270886727641641		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.08270886727641641 | validation: 0.06323658925392789]
	TIME [epoch: 5.74 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07881100840370159		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.07881100840370159 | validation: 0.06719040565235142]
	TIME [epoch: 5.74 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07526423286951213		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.07526423286951213 | validation: 0.06617082452402957]
	TIME [epoch: 5.74 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07843804265212567		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.07843804265212567 | validation: 0.06588289377870135]
	TIME [epoch: 5.74 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06388075877153188		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.06388075877153188 | validation: 0.0866985339847825]
	TIME [epoch: 5.76 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09019863116323273		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.09019863116323273 | validation: 0.10503192083316698]
	TIME [epoch: 5.78 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08265623924378852		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.08265623924378852 | validation: 0.0722006652683544]
	TIME [epoch: 5.75 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07128617960405474		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.07128617960405474 | validation: 0.08014632822589317]
	TIME [epoch: 5.74 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07632989702396395		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.07632989702396395 | validation: 0.08800301757627295]
	TIME [epoch: 5.74 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0726465726310487		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.0726465726310487 | validation: 0.07736991644754586]
	TIME [epoch: 5.74 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0737036163130934		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.0737036163130934 | validation: 0.08716845431045471]
	TIME [epoch: 5.74 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08377008850369635		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.08377008850369635 | validation: 0.07165842292340681]
	TIME [epoch: 5.78 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07067074624464326		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.07067074624464326 | validation: 0.0660365929703465]
	TIME [epoch: 5.75 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06336521436020205		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.06336521436020205 | validation: 0.07308951049134713]
	TIME [epoch: 5.74 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0695037874431503		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.0695037874431503 | validation: 0.07409081612432913]
	TIME [epoch: 5.75 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07210906165076247		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.07210906165076247 | validation: 0.08753080051408095]
	TIME [epoch: 5.74 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08297156069631631		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.08297156069631631 | validation: 0.08523931904458791]
	TIME [epoch: 5.74 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0661754844683275		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.0661754844683275 | validation: 0.0726391268520106]
	TIME [epoch: 5.75 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06957860040147053		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.06957860040147053 | validation: 0.07584245912746786]
	TIME [epoch: 5.78 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06735118640995869		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.06735118640995869 | validation: 0.07302165076148256]
	TIME [epoch: 5.75 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07499058962208122		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.07499058962208122 | validation: 0.09674599630124511]
	TIME [epoch: 5.74 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09533689345002727		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.09533689345002727 | validation: 0.0999407299803811]
	TIME [epoch: 5.74 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06926447988305165		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.06926447988305165 | validation: 0.07030339748331535]
	TIME [epoch: 5.74 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06395980245279496		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.06395980245279496 | validation: 0.07494925817665903]
	TIME [epoch: 5.74 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06906602097183612		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.06906602097183612 | validation: 0.08470895174245395]
	TIME [epoch: 5.78 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07312235349277536		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.07312235349277536 | validation: 0.07808488701260306]
	TIME [epoch: 5.75 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06923848450972832		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.06923848450972832 | validation: 0.07076016208755906]
	TIME [epoch: 5.74 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06572605263686845		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.06572605263686845 | validation: 0.07731053428434087]
	TIME [epoch: 5.74 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07117268099821707		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.07117268099821707 | validation: 0.08220249352707054]
	TIME [epoch: 5.74 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06734606584510332		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.06734606584510332 | validation: 0.0783403539748818]
	TIME [epoch: 5.74 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06736117185389143		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.06736117185389143 | validation: 0.08596861499866477]
	TIME [epoch: 5.75 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0737234959373716		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.0737234959373716 | validation: 0.09732185836864123]
	TIME [epoch: 5.77 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07696434442124363		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.07696434442124363 | validation: 0.09494539872416212]
	TIME [epoch: 5.74 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07626784617179987		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.07626784617179987 | validation: 0.07751170359028015]
	TIME [epoch: 5.73 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0729291395692531		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.0729291395692531 | validation: 0.08644626353412128]
	TIME [epoch: 5.74 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0699546404248079		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.0699546404248079 | validation: 0.0753516047024206]
	TIME [epoch: 5.75 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06668058115910824		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.06668058115910824 | validation: 0.08822621873582781]
	TIME [epoch: 5.74 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0695042239669616		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.0695042239669616 | validation: 0.06681084822360386]
	TIME [epoch: 5.79 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0645519406230774		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.0645519406230774 | validation: 0.07687415108249189]
	TIME [epoch: 5.74 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06819471159388842		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.06819471159388842 | validation: 0.0779762994739731]
	TIME [epoch: 5.74 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062107626342711206		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.062107626342711206 | validation: 0.07578808645347032]
	TIME [epoch: 5.75 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08732747478359106		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.08732747478359106 | validation: 0.070966553733137]
	TIME [epoch: 5.74 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0838857519061617		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.0838857519061617 | validation: 0.07400421634070427]
	TIME [epoch: 5.74 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07942005816383363		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.07942005816383363 | validation: 0.07257704345526016]
	TIME [epoch: 5.76 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06893872940521223		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.06893872940521223 | validation: 0.06683768435405599]
	TIME [epoch: 5.78 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07152849438938232		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.07152849438938232 | validation: 0.07668057021562856]
	TIME [epoch: 5.75 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07196051818576145		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.07196051818576145 | validation: 0.07215942803143867]
	TIME [epoch: 5.75 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06585203430958803		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.06585203430958803 | validation: 0.08105006329384025]
	TIME [epoch: 5.75 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08435535448352442		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.08435535448352442 | validation: 0.07858514019686175]
	TIME [epoch: 5.75 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06180979571546008		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.06180979571546008 | validation: 0.08531545693124853]
	TIME [epoch: 5.75 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06509902933481293		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.06509902933481293 | validation: 0.10002019552236271]
	TIME [epoch: 5.79 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0758420490127815		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.0758420490127815 | validation: 0.10033456626737522]
	TIME [epoch: 5.75 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07229446634672783		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.07229446634672783 | validation: 0.08398688133077518]
	TIME [epoch: 5.74 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06597489468380391		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.06597489468380391 | validation: 0.08452142501236055]
	TIME [epoch: 5.74 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06620341469324215		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.06620341469324215 | validation: 0.08886509478616442]
	TIME [epoch: 5.75 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07183518807244277		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.07183518807244277 | validation: 0.10045794776442422]
	TIME [epoch: 5.75 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08507758262211874		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.08507758262211874 | validation: 0.11515385457632682]
	TIME [epoch: 5.76 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07628517622325415		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.07628517622325415 | validation: 0.08042616444912014]
	TIME [epoch: 5.78 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07605327923145144		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.07605327923145144 | validation: 0.08817050739132234]
	TIME [epoch: 5.75 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07040310914065745		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.07040310914065745 | validation: 0.09048762523425798]
	TIME [epoch: 5.74 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641345843689091		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.06641345843689091 | validation: 0.07310447820783915]
	TIME [epoch: 5.74 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06844816917008613		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.06844816917008613 | validation: 0.09205289935124747]
	TIME [epoch: 5.74 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07002955953079434		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.07002955953079434 | validation: 0.07265665013011216]
	TIME [epoch: 5.75 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06853486052847464		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.06853486052847464 | validation: 0.0887102758116199]
	TIME [epoch: 5.79 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0897510513012957		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.0897510513012957 | validation: 0.10629297463750138]
	TIME [epoch: 5.75 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0790105922407264		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.0790105922407264 | validation: 0.0965745170748895]
	TIME [epoch: 5.75 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08441913430904037		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.08441913430904037 | validation: 0.0843748300347251]
	TIME [epoch: 5.75 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07078806253691097		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.07078806253691097 | validation: 0.09557140596913653]
	TIME [epoch: 5.75 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062228917393610195		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.062228917393610195 | validation: 0.07726809354980148]
	TIME [epoch: 5.74 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06217810866869069		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.06217810866869069 | validation: 0.07235089910084015]
	TIME [epoch: 5.75 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060763258968586274		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.060763258968586274 | validation: 0.06738772334289243]
	TIME [epoch: 5.77 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06100715447592135		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.06100715447592135 | validation: 0.07212406259978421]
	TIME [epoch: 5.75 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05762653424580837		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.05762653424580837 | validation: 0.07196240656941819]
	TIME [epoch: 5.75 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06445928991968275		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.06445928991968275 | validation: 0.06722396343637907]
	TIME [epoch: 5.75 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06083342599839401		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.06083342599839401 | validation: 0.06792455560226231]
	TIME [epoch: 5.75 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06322943838007086		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.06322943838007086 | validation: 0.06915515386770942]
	TIME [epoch: 5.75 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06848141065597102		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.06848141065597102 | validation: 0.08358545994407347]
	TIME [epoch: 5.79 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07893182092665307		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.07893182092665307 | validation: 0.08119189497484125]
	TIME [epoch: 5.75 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0681077541349435		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.0681077541349435 | validation: 0.08238617849573263]
	TIME [epoch: 5.74 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0695981584650571		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.0695981584650571 | validation: 0.08382612156296379]
	TIME [epoch: 5.74 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06565312179696323		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.06565312179696323 | validation: 0.0898869950363611]
	TIME [epoch: 5.74 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06413013641023226		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.06413013641023226 | validation: 0.07961171726537677]
	TIME [epoch: 5.74 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07753503630329592		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.07753503630329592 | validation: 0.09216921308594858]
	TIME [epoch: 5.75 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0747806807667503		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.0747806807667503 | validation: 0.0673894196548655]
	TIME [epoch: 5.78 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06370679286307945		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.06370679286307945 | validation: 0.08242496778550468]
	TIME [epoch: 5.75 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06532418922728482		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.06532418922728482 | validation: 0.07170556295002842]
	TIME [epoch: 5.74 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07125735127877816		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.07125735127877816 | validation: 0.09519273803116841]
	TIME [epoch: 5.75 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060416654677731274		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.060416654677731274 | validation: 0.07699237213064537]
	TIME [epoch: 5.74 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05994498142614737		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.05994498142614737 | validation: 0.0592109645003737]
	TIME [epoch: 5.74 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821148695584259		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.06821148695584259 | validation: 0.08547875650374531]
	TIME [epoch: 5.79 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0626189488037111		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.0626189488037111 | validation: 0.08041156068620023]
	TIME [epoch: 5.75 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06457708632572264		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.06457708632572264 | validation: 0.07898363296025976]
	TIME [epoch: 5.74 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06208786006428205		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.06208786006428205 | validation: 0.07221401238906597]
	TIME [epoch: 5.74 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06621256476412829		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.06621256476412829 | validation: 0.07089485431098153]
	TIME [epoch: 5.75 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06136123118315312		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.06136123118315312 | validation: 0.07186895613283936]
	TIME [epoch: 5.74 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06256507442528797		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.06256507442528797 | validation: 0.07781805505532177]
	TIME [epoch: 5.78 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06537896139799122		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.06537896139799122 | validation: 0.080435022648752]
	TIME [epoch: 5.75 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06521867300920704		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.06521867300920704 | validation: 0.07963463626614894]
	TIME [epoch: 5.75 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059775850762291916		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.059775850762291916 | validation: 0.07404617792866029]
	TIME [epoch: 5.74 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06763426631708408		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.06763426631708408 | validation: 0.07532213638259096]
	TIME [epoch: 5.74 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059943956266098816		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.059943956266098816 | validation: 0.07735050979219875]
	TIME [epoch: 5.74 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06882960863990702		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.06882960863990702 | validation: 0.09944784193478805]
	TIME [epoch: 5.74 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08462061207805213		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.08462061207805213 | validation: 0.11238805937379524]
	TIME [epoch: 5.78 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07722860289817976		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.07722860289817976 | validation: 0.10241157117867297]
	TIME [epoch: 5.74 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07479735713429143		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.07479735713429143 | validation: 0.0981759591286408]
	TIME [epoch: 5.75 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06677486357335151		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.06677486357335151 | validation: 0.08629271823117231]
	TIME [epoch: 5.74 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06594175988274707		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.06594175988274707 | validation: 0.09137519255388396]
	TIME [epoch: 5.75 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07473928102303845		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.07473928102303845 | validation: 0.0896579383156823]
	TIME [epoch: 5.74 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06475713919338809		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.06475713919338809 | validation: 0.08724558279269147]
	TIME [epoch: 5.78 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0634865911058751		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.0634865911058751 | validation: 0.09076903716150703]
	TIME [epoch: 5.76 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06679745011561913		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.06679745011561913 | validation: 0.08966327322706587]
	TIME [epoch: 5.75 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06234496729623312		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.06234496729623312 | validation: 0.0839929500961457]
	TIME [epoch: 5.74 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06850048466319407		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.06850048466319407 | validation: 0.08421612540702089]
	TIME [epoch: 5.74 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06326996210381389		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.06326996210381389 | validation: 0.07748253544494392]
	TIME [epoch: 5.74 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06494198183150682		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.06494198183150682 | validation: 0.08698988919432843]
	TIME [epoch: 5.74 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641209489887182		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.06641209489887182 | validation: 0.09176592309005958]
	TIME [epoch: 5.79 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0656297890730473		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.0656297890730473 | validation: 0.08817011849281396]
	TIME [epoch: 5.75 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05992580526988503		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.05992580526988503 | validation: 0.08919244862639626]
	TIME [epoch: 5.75 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0713496736490884		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.0713496736490884 | validation: 0.0747585239028366]
	TIME [epoch: 5.74 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06365616028564161		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.06365616028564161 | validation: 0.07499773549521856]
	TIME [epoch: 5.75 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0633983708551928		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.0633983708551928 | validation: 0.0663634465301845]
	TIME [epoch: 5.75 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060727728313015025		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.060727728313015025 | validation: 0.07651348783264303]
	TIME [epoch: 5.77 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06242176541428661		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.06242176541428661 | validation: 0.07092001621638899]
	TIME [epoch: 5.75 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06601370297613893		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.06601370297613893 | validation: 0.09074939857852009]
	TIME [epoch: 5.74 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07101005587640953		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.07101005587640953 | validation: 0.08734866227589556]
	TIME [epoch: 5.74 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07104916837267516		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.07104916837267516 | validation: 0.08278943857240335]
	TIME [epoch: 5.74 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06627679287519751		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.06627679287519751 | validation: 0.07360307403133969]
	TIME [epoch: 5.75 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06005062877239875		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.06005062877239875 | validation: 0.0663664671738404]
	TIME [epoch: 5.75 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060800391667821425		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.060800391667821425 | validation: 0.07987157980731953]
	TIME [epoch: 5.79 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06266343829062238		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.06266343829062238 | validation: 0.08355440153656792]
	TIME [epoch: 5.74 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07161557976282769		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.07161557976282769 | validation: 0.08587660710209093]
	TIME [epoch: 5.75 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07099588494707111		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.07099588494707111 | validation: 0.08292923110270885]
	TIME [epoch: 5.75 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06339388745778031		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.06339388745778031 | validation: 0.08660095085326894]
	TIME [epoch: 5.74 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06558065025727061		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.06558065025727061 | validation: 0.1044547006162039]
	TIME [epoch: 5.74 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0672950812999575		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.0672950812999575 | validation: 0.08863991670089526]
	TIME [epoch: 5.77 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06816017435126197		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.06816017435126197 | validation: 0.08696190530367769]
	TIME [epoch: 5.75 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06249358709571663		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.06249358709571663 | validation: 0.08688062293485496]
	TIME [epoch: 5.74 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06677457241500254		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.06677457241500254 | validation: 0.08988116607384859]
	TIME [epoch: 5.74 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06588696596714397		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.06588696596714397 | validation: 0.08389182419213075]
	TIME [epoch: 5.75 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06313864527619321		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.06313864527619321 | validation: 0.09918372159164437]
	TIME [epoch: 5.74 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07568652620309088		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.07568652620309088 | validation: 0.09486938027429791]
	TIME [epoch: 5.74 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07034799458486429		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.07034799458486429 | validation: 0.08828445931705506]
	TIME [epoch: 5.79 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06952528730426699		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.06952528730426699 | validation: 0.0881584427043586]
	TIME [epoch: 5.75 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06280503967833972		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.06280503967833972 | validation: 0.08792907438774737]
	TIME [epoch: 5.74 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06146661319896285		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.06146661319896285 | validation: 0.08362641592545274]
	TIME [epoch: 5.74 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05666961596871921		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.05666961596871921 | validation: 0.08912842122775412]
	TIME [epoch: 5.74 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06303113663260027		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.06303113663260027 | validation: 0.0811165106711033]
	TIME [epoch: 5.74 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06305913372183525		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.06305913372183525 | validation: 0.07930237760952792]
	TIME [epoch: 5.78 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061146013195496285		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.061146013195496285 | validation: 0.0860204729562443]
	TIME [epoch: 5.76 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059764097928910895		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.059764097928910895 | validation: 0.08035218127708733]
	TIME [epoch: 5.75 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05962683176789185		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.05962683176789185 | validation: 0.07693221293633695]
	TIME [epoch: 5.74 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06409908096494951		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.06409908096494951 | validation: 0.08105945084565454]
	TIME [epoch: 5.74 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06365002332634416		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.06365002332634416 | validation: 0.0891897554608413]
	TIME [epoch: 5.74 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06354881934866667		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.06354881934866667 | validation: 0.07957109897477538]
	TIME [epoch: 5.74 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06559994598957782		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.06559994598957782 | validation: 0.07758250310358576]
	TIME [epoch: 5.78 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06538953150031485		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.06538953150031485 | validation: 0.07598718361835916]
	TIME [epoch: 5.74 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06232408812997835		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.06232408812997835 | validation: 0.07338818368230218]
	TIME [epoch: 5.75 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06763600427681973		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.06763600427681973 | validation: 0.09281776230679892]
	TIME [epoch: 5.75 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06885777811807174		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.06885777811807174 | validation: 0.10022875310924809]
	TIME [epoch: 5.74 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0695352432828436		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.0695352432828436 | validation: 0.09397553337696561]
	TIME [epoch: 5.75 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0693944893422946		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.0693944893422946 | validation: 0.10395214080507384]
	TIME [epoch: 5.78 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07172031423638489		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.07172031423638489 | validation: 0.0988777777249582]
	TIME [epoch: 5.77 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08045559507829139		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.08045559507829139 | validation: 0.09850892236537426]
	TIME [epoch: 5.74 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641044309601232		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.06641044309601232 | validation: 0.08141470862392934]
	TIME [epoch: 5.74 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0665630944819289		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.0665630944819289 | validation: 0.08623880711655481]
	TIME [epoch: 5.74 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06791378251151502		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.06791378251151502 | validation: 0.0855772414810939]
	TIME [epoch: 5.75 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0658274020312924		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.0658274020312924 | validation: 0.07288154769176816]
	TIME [epoch: 5.74 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06340876786390238		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.06340876786390238 | validation: 0.08063814915989406]
	TIME [epoch: 5.8 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06469645335065823		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.06469645335065823 | validation: 0.07673829110770367]
	TIME [epoch: 5.75 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06542906313810605		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.06542906313810605 | validation: 0.07375866548098127]
	TIME [epoch: 5.74 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06177007054835455		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.06177007054835455 | validation: 0.06298308935582302]
	TIME [epoch: 5.74 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0655950798340715		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.0655950798340715 | validation: 0.07242762082381216]
	TIME [epoch: 5.74 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06593129876798791		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.06593129876798791 | validation: 0.06664085559413686]
	TIME [epoch: 5.74 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06292747267289407		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.06292747267289407 | validation: 0.06135500874593259]
	TIME [epoch: 5.78 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05835052498272966		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.05835052498272966 | validation: 0.07479039123420331]
	TIME [epoch: 5.77 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05699534931091082		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.05699534931091082 | validation: 0.07978231950833686]
	TIME [epoch: 5.75 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0602730866465986		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.0602730866465986 | validation: 0.08049924944071375]
	TIME [epoch: 5.75 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06481139896271475		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.06481139896271475 | validation: 0.07060712069589023]
	TIME [epoch: 5.74 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06898835376705967		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.06898835376705967 | validation: 0.072654362141924]
	TIME [epoch: 5.74 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07260810380177748		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.07260810380177748 | validation: 0.07784839783760827]
	TIME [epoch: 5.74 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925712619914612		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.06925712619914612 | validation: 0.07476504130230129]
	TIME [epoch: 5.79 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06591460234068576		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.06591460234068576 | validation: 0.06512593991153243]
	TIME [epoch: 5.74 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0648876658630768		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.0648876658630768 | validation: 0.06858063430576827]
	TIME [epoch: 5.75 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06640121079315639		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.06640121079315639 | validation: 0.07238154316240988]
	TIME [epoch: 5.75 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05839537821606911		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.05839537821606911 | validation: 0.08299559358994424]
	TIME [epoch: 5.74 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07542018081395131		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.07542018081395131 | validation: 0.08518788931142961]
	TIME [epoch: 5.75 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06319995926383565		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.06319995926383565 | validation: 0.07761531017247132]
	TIME [epoch: 5.78 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060766195460912456		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.060766195460912456 | validation: 0.06922380713276441]
	TIME [epoch: 5.75 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0622332551296389		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.0622332551296389 | validation: 0.08425234334852588]
	TIME [epoch: 5.74 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06805975766187855		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.06805975766187855 | validation: 0.07380406454006579]
	TIME [epoch: 5.74 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07134925047487292		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.07134925047487292 | validation: 0.08188083266288919]
	TIME [epoch: 5.73 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06163830459436137		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.06163830459436137 | validation: 0.07277434409792465]
	TIME [epoch: 5.74 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061243675149400094		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.061243675149400094 | validation: 0.06974722966030622]
	TIME [epoch: 5.75 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06398093323725326		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.06398093323725326 | validation: 0.07174872664837771]
	TIME [epoch: 5.78 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05917250703596321		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.05917250703596321 | validation: 0.08744747794323983]
	TIME [epoch: 5.74 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059759293336016615		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.059759293336016615 | validation: 0.06722169616793779]
	TIME [epoch: 5.75 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05953064805630763		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.05953064805630763 | validation: 0.07418237663429872]
	TIME [epoch: 5.74 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05949106790236609		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.05949106790236609 | validation: 0.07468510051570329]
	TIME [epoch: 5.74 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06853687910906445		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.06853687910906445 | validation: 0.08575729692849947]
	TIME [epoch: 5.73 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06712547012184551		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.06712547012184551 | validation: 0.07621223220105457]
	TIME [epoch: 5.78 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05697605516364744		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.05697605516364744 | validation: 0.06820959603890896]
	TIME [epoch: 5.74 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05796077875647261		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.05796077875647261 | validation: 0.08141403308130274]
	TIME [epoch: 5.74 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06580999674616805		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.06580999674616805 | validation: 0.07300926394421943]
	TIME [epoch: 5.74 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06464672911620578		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.06464672911620578 | validation: 0.06922239285544604]
	TIME [epoch: 5.74 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06417797369663344		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.06417797369663344 | validation: 0.07102851673739537]
	TIME [epoch: 5.75 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05923949612958417		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.05923949612958417 | validation: 0.07472174332734549]
	TIME [epoch: 5.75 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07276833524601212		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.07276833524601212 | validation: 0.08795636172802826]
	TIME [epoch: 5.78 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07013551643698517		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.07013551643698517 | validation: 0.08684393157865589]
	TIME [epoch: 5.75 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06922711358178854		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.06922711358178854 | validation: 0.06969250987990712]
	TIME [epoch: 5.75 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05936336862218887		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.05936336862218887 | validation: 0.0631616010449263]
	TIME [epoch: 5.75 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05880265817242465		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.05880265817242465 | validation: 0.0675203692902916]
	TIME [epoch: 5.75 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061782280436857163		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.061782280436857163 | validation: 0.07095946028594392]
	TIME [epoch: 5.75 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05906830221863753		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.05906830221863753 | validation: 0.07963245625465495]
	TIME [epoch: 5.79 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06177278811027982		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.06177278811027982 | validation: 0.08017551602164286]
	TIME [epoch: 5.75 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06836140585761576		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.06836140585761576 | validation: 0.08960651047586836]
	TIME [epoch: 5.75 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06349850439505769		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.06349850439505769 | validation: 0.08515758566465907]
	TIME [epoch: 5.75 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060476058173339044		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.060476058173339044 | validation: 0.09177416632462247]
	TIME [epoch: 5.75 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059953048490393256		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.059953048490393256 | validation: 0.08280520172630344]
	TIME [epoch: 5.75 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06272261830027294		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.06272261830027294 | validation: 0.08392334159499487]
	TIME [epoch: 5.76 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057729178175285986		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.057729178175285986 | validation: 0.0790270224547268]
	TIME [epoch: 5.78 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06205447727687724		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.06205447727687724 | validation: 0.08621265365827274]
	TIME [epoch: 5.75 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642676972354263		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.0642676972354263 | validation: 0.08318325132446124]
	TIME [epoch: 5.74 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059572287143644195		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.059572287143644195 | validation: 0.09359020802767005]
	TIME [epoch: 5.74 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06316733103187429		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.06316733103187429 | validation: 0.09593945716322327]
	TIME [epoch: 5.74 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07229431660524684		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.07229431660524684 | validation: 0.0887711192175688]
	TIME [epoch: 5.74 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06856189564963201		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.06856189564963201 | validation: 0.09734322281707197]
	TIME [epoch: 5.78 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06529328180519585		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.06529328180519585 | validation: 0.08599939874787961]
	TIME [epoch: 5.75 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06367273660652704		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.06367273660652704 | validation: 0.1032061978854323]
	TIME [epoch: 5.75 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06736887449208982		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.06736887449208982 | validation: 0.09812204396761644]
	TIME [epoch: 5.74 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06902410481508925		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.06902410481508925 | validation: 0.09909548267732515]
	TIME [epoch: 5.75 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06312409958144102		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.06312409958144102 | validation: 0.09901532242309002]
	TIME [epoch: 5.74 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0664023969727256		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.0664023969727256 | validation: 0.10393780058396647]
	TIME [epoch: 5.76 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07023358171078171		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.07023358171078171 | validation: 0.09489915639774152]
	TIME [epoch: 5.77 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06699251496683264		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.06699251496683264 | validation: 0.10355382418622291]
	TIME [epoch: 5.75 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06551834210483638		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.06551834210483638 | validation: 0.09843283059729054]
	TIME [epoch: 5.74 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06368103509685222		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.06368103509685222 | validation: 0.08979296747516738]
	TIME [epoch: 5.75 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05820383848081719		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.05820383848081719 | validation: 0.0890009879998082]
	TIME [epoch: 5.75 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06040836898175935		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.06040836898175935 | validation: 0.09688832844332561]
	TIME [epoch: 5.75 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07015098641542171		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.07015098641542171 | validation: 0.10473466424161294]
	TIME [epoch: 5.78 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06512745707831875		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.06512745707831875 | validation: 0.10314473696364054]
	TIME [epoch: 5.75 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07202895912107969		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.07202895912107969 | validation: 0.11095124892653059]
	TIME [epoch: 5.75 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06922389692010464		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.06922389692010464 | validation: 0.10701563962093516]
	TIME [epoch: 5.74 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07101473123065247		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.07101473123065247 | validation: 0.09568396044638629]
	TIME [epoch: 5.74 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07228321932537116		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.07228321932537116 | validation: 0.09892876564530183]
	TIME [epoch: 5.74 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0657507784671356		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.0657507784671356 | validation: 0.10432213650527655]
	TIME [epoch: 5.76 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06769627638944538		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.06769627638944538 | validation: 0.09205700172296101]
	TIME [epoch: 5.78 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06699175190155891		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.06699175190155891 | validation: 0.0913157987924735]
	TIME [epoch: 5.75 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07358393562426595		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.07358393562426595 | validation: 0.09576633059409304]
	TIME [epoch: 5.75 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06325865371338676		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.06325865371338676 | validation: 0.09084704772216572]
	TIME [epoch: 5.75 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061372227957212595		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.061372227957212595 | validation: 0.0938023412725554]
	TIME [epoch: 5.74 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06690688298467155		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.06690688298467155 | validation: 0.09030963468456188]
	TIME [epoch: 5.74 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0656495704413749		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.0656495704413749 | validation: 0.09078770977168925]
	TIME [epoch: 5.78 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05843765569957104		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.05843765569957104 | validation: 0.07995795753938195]
	TIME [epoch: 5.74 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061735922879758806		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.061735922879758806 | validation: 0.09348251799454296]
	TIME [epoch: 5.74 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0613792020089416		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.0613792020089416 | validation: 0.0944726774565391]
	TIME [epoch: 5.74 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0610297092659999		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.0610297092659999 | validation: 0.08478681801977582]
	TIME [epoch: 5.74 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06094496040570462		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.06094496040570462 | validation: 0.08833208769226097]
	TIME [epoch: 5.74 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062225765108155855		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.062225765108155855 | validation: 0.08199431663367687]
	TIME [epoch: 5.77 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06291390077027385		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.06291390077027385 | validation: 0.0908933483730063]
	TIME [epoch: 5.76 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06608386223737668		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.06608386223737668 | validation: 0.09200739619322462]
	TIME [epoch: 5.74 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0656538153688746		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.0656538153688746 | validation: 0.09444921809304]
	TIME [epoch: 5.73 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06796119720811436		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.06796119720811436 | validation: 0.10249513914868424]
	TIME [epoch: 5.73 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06298898794379228		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.06298898794379228 | validation: 0.08779547246135629]
	TIME [epoch: 5.74 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06440289757314935		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.06440289757314935 | validation: 0.0927112705657785]
	TIME [epoch: 5.74 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06944635808216934		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.06944635808216934 | validation: 0.0992043724308199]
	TIME [epoch: 5.79 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06897978600882292		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.06897978600882292 | validation: 0.09689261745832721]
	TIME [epoch: 5.75 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06333689557064201		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.06333689557064201 | validation: 0.08645876295668879]
	TIME [epoch: 5.74 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344894670459286		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.06344894670459286 | validation: 0.08565459507563962]
	TIME [epoch: 5.74 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06444015493074866		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.06444015493074866 | validation: 0.0873224122024558]
	TIME [epoch: 5.74 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06290730062520422		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.06290730062520422 | validation: 0.08970393267987621]
	TIME [epoch: 5.74 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05847637465856607		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.05847637465856607 | validation: 0.08654917720434695]
	TIME [epoch: 5.76 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05985780797833781		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.05985780797833781 | validation: 0.09582822602554472]
	TIME [epoch: 5.75 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06230602486000928		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.06230602486000928 | validation: 0.09150755661350055]
	TIME [epoch: 5.74 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060967911700578775		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.060967911700578775 | validation: 0.08178563886591893]
	TIME [epoch: 5.74 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0626097036087751		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.0626097036087751 | validation: 0.08512997655627341]
	TIME [epoch: 5.74 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058138754793805716		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.058138754793805716 | validation: 0.08456929613317446]
	TIME [epoch: 5.74 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06189504949010473		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.06189504949010473 | validation: 0.09043278694008883]
	TIME [epoch: 5.74 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061273209103474134		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.061273209103474134 | validation: 0.07546838928519478]
	TIME [epoch: 5.78 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06428315064979215		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.06428315064979215 | validation: 0.08820037224214562]
	TIME [epoch: 5.75 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0617490889188937		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.0617490889188937 | validation: 0.08940956275317014]
	TIME [epoch: 5.74 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06420270834225192		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.06420270834225192 | validation: 0.08840229975066534]
	TIME [epoch: 5.74 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06757267818915759		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.06757267818915759 | validation: 0.08216575467763938]
	TIME [epoch: 5.74 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06537569024243303		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.06537569024243303 | validation: 0.09152968349668666]
	TIME [epoch: 5.74 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642739461540798		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.0642739461540798 | validation: 0.0934589663991797]
	TIME [epoch: 5.77 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06292869917631666		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.06292869917631666 | validation: 0.10326888937542972]
	TIME [epoch: 5.75 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06317113739429021		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.06317113739429021 | validation: 0.0889590365917891]
	TIME [epoch: 5.75 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060699614108418565		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.060699614108418565 | validation: 0.09016504434957696]
	TIME [epoch: 5.74 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06000177564369302		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.06000177564369302 | validation: 0.08346154031304887]
	TIME [epoch: 5.74 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0598471353717202		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.0598471353717202 | validation: 0.08456397409786189]
	TIME [epoch: 5.75 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05827607249937802		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.05827607249937802 | validation: 0.08710595069714329]
	TIME [epoch: 5.74 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06100761392819221		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.06100761392819221 | validation: 0.08065135164379193]
	TIME [epoch: 5.78 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06271894176542409		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.06271894176542409 | validation: 0.0933231735585134]
	TIME [epoch: 5.74 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06177171900089353		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.06177171900089353 | validation: 0.08292081599124704]
	TIME [epoch: 5.73 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05952275611228997		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.05952275611228997 | validation: 0.09030509637792854]
	TIME [epoch: 5.74 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06010457323599879		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.06010457323599879 | validation: 0.09174663354267558]
	TIME [epoch: 5.74 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056854012344691826		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.056854012344691826 | validation: 0.08813830677443103]
	TIME [epoch: 5.74 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05987516300969582		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.05987516300969582 | validation: 0.08873300190869934]
	TIME [epoch: 5.77 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05956386949762274		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.05956386949762274 | validation: 0.08862864506651766]
	TIME [epoch: 5.75 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06465388430306468		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.06465388430306468 | validation: 0.08849414645725556]
	TIME [epoch: 5.75 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062392793574580795		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.062392793574580795 | validation: 0.07920524529759958]
	TIME [epoch: 5.74 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05530090464555175		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.05530090464555175 | validation: 0.07545313080040274]
	TIME [epoch: 5.74 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06264265556532736		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.06264265556532736 | validation: 0.07825871227983656]
	TIME [epoch: 5.74 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06692718548426069		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.06692718548426069 | validation: 0.08755001229909586]
	TIME [epoch: 5.74 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06574459597748974		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.06574459597748974 | validation: 0.07419405420597167]
	TIME [epoch: 5.79 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05689060638673231		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.05689060638673231 | validation: 0.07783859224265713]
	TIME [epoch: 5.74 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05817583465706897		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.05817583465706897 | validation: 0.07366770959152345]
	TIME [epoch: 5.75 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05957867875479152		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.05957867875479152 | validation: 0.07527873971494353]
	TIME [epoch: 5.74 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057563506431295854		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.057563506431295854 | validation: 0.07423900766712811]
	TIME [epoch: 5.74 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06359403806430738		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.06359403806430738 | validation: 0.06599686902127556]
	TIME [epoch: 5.74 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06670038716602518		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.06670038716602518 | validation: 0.07632863672497905]
	TIME [epoch: 5.76 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0631032124605792		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.0631032124605792 | validation: 0.07153363395347644]
	TIME [epoch: 5.75 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06011393799670234		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.06011393799670234 | validation: 0.07328297476015598]
	TIME [epoch: 5.75 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060752964684403735		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.060752964684403735 | validation: 0.077648366389551]
	TIME [epoch: 5.74 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05854220050864288		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.05854220050864288 | validation: 0.0760632115700669]
	TIME [epoch: 5.74 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057125404677727774		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.057125404677727774 | validation: 0.08085946467173179]
	TIME [epoch: 5.75 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05725436240940234		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.05725436240940234 | validation: 0.07523128166386572]
	TIME [epoch: 5.75 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056261573600299604		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.056261573600299604 | validation: 0.07817327795078542]
	TIME [epoch: 5.78 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056812413883667		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.056812413883667 | validation: 0.0919744045042473]
	TIME [epoch: 5.74 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0580870582204095		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.0580870582204095 | validation: 0.07957455257996796]
	TIME [epoch: 5.74 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278880163964208		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.06278880163964208 | validation: 0.08704518915769736]
	TIME [epoch: 5.74 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06479846873914254		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.06479846873914254 | validation: 0.078139876159091]
	TIME [epoch: 5.74 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05868202939141533		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.05868202939141533 | validation: 0.08061399131613282]
	TIME [epoch: 5.74 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06351512287977623		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.06351512287977623 | validation: 0.07389313082805865]
	TIME [epoch: 5.77 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06764178337146176		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.06764178337146176 | validation: 0.08943397682518986]
	TIME [epoch: 5.75 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06358778740837681		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.06358778740837681 | validation: 0.07242931983970798]
	TIME [epoch: 5.75 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057385513054011336		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.057385513054011336 | validation: 0.07881715513404808]
	TIME [epoch: 5.74 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058967740291790194		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.058967740291790194 | validation: 0.08365198969828168]
	TIME [epoch: 5.74 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468324414839699		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.06468324414839699 | validation: 0.06392077587910716]
	TIME [epoch: 5.74 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05685529478769965		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.05685529478769965 | validation: 0.07357656082870373]
	TIME [epoch: 5.74 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062168463591894874		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.062168463591894874 | validation: 0.07277291601656842]
	TIME [epoch: 5.78 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061687448117421086		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.061687448117421086 | validation: 0.07889711484964446]
	TIME [epoch: 5.75 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06268344168612253		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.06268344168612253 | validation: 0.07765481602004749]
	TIME [epoch: 5.74 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061876357144835845		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.061876357144835845 | validation: 0.07218899872358173]
	TIME [epoch: 5.74 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0575485407649607		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.0575485407649607 | validation: 0.07399618262407762]
	TIME [epoch: 5.74 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259551557430316		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.06259551557430316 | validation: 0.07456960324229922]
	TIME [epoch: 5.74 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.066225594392479		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.066225594392479 | validation: 0.07449859226486616]
	TIME [epoch: 5.78 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06541594405667608		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.06541594405667608 | validation: 0.0657100064357975]
	TIME [epoch: 5.74 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06012838647660099		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.06012838647660099 | validation: 0.08100882777961968]
	TIME [epoch: 5.74 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057528409502816055		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.057528409502816055 | validation: 0.08235443487688056]
	TIME [epoch: 5.74 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05910944376795686		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.05910944376795686 | validation: 0.07742816939158262]
	TIME [epoch: 5.73 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05445291590308163		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.05445291590308163 | validation: 0.07677516140546115]
	TIME [epoch: 5.73 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06314544563405534		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.06314544563405534 | validation: 0.07198938153108671]
	TIME [epoch: 5.75 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057692558844828684		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.057692558844828684 | validation: 0.08745711950493085]
	TIME [epoch: 5.77 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06227668068007111		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.06227668068007111 | validation: 0.08721871228712384]
	TIME [epoch: 5.75 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06548091684494017		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.06548091684494017 | validation: 0.07534727614326485]
	TIME [epoch: 5.73 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0609938675382016		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.0609938675382016 | validation: 0.08286632535051343]
	TIME [epoch: 5.75 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06014087482417122		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.06014087482417122 | validation: 0.08785938841004341]
	TIME [epoch: 5.74 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06547509572094538		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.06547509572094538 | validation: 0.07910998725432063]
	TIME [epoch: 5.74 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05923799947719357		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.05923799947719357 | validation: 0.07706563174392769]
	TIME [epoch: 5.77 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06286842845907174		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.06286842845907174 | validation: 0.07612894320999163]
	TIME [epoch: 5.74 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06101154881304872		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.06101154881304872 | validation: 0.07782054515842673]
	TIME [epoch: 5.74 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059956562652212844		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.059956562652212844 | validation: 0.07109959350460171]
	TIME [epoch: 5.74 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0542056732446949		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.0542056732446949 | validation: 0.068430369184514]
	TIME [epoch: 5.74 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06031813980824921		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.06031813980824921 | validation: 0.06990086189674358]
	TIME [epoch: 5.74 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060540827761215804		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.060540827761215804 | validation: 0.07186758937671134]
	TIME [epoch: 5.76 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05604362205578557		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.05604362205578557 | validation: 0.07488476894158104]
	TIME [epoch: 5.77 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05896238243781333		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.05896238243781333 | validation: 0.06939551882126505]
	TIME [epoch: 5.75 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05768035080886305		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.05768035080886305 | validation: 0.07950989430470082]
	TIME [epoch: 5.74 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05832907775922137		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.05832907775922137 | validation: 0.08340904762976387]
	TIME [epoch: 5.74 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055312798056150456		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.055312798056150456 | validation: 0.0750287922877748]
	TIME [epoch: 5.73 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0564831699123355		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.0564831699123355 | validation: 0.06976864179352708]
	TIME [epoch: 5.74 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06150790240684319		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.06150790240684319 | validation: 0.08168831001816844]
	TIME [epoch: 5.77 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057282013999929084		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.057282013999929084 | validation: 0.06416950732348248]
	TIME [epoch: 5.74 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05570715805869402		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.05570715805869402 | validation: 0.06209982786100512]
	TIME [epoch: 5.74 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056495586802285745		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.056495586802285745 | validation: 0.0697624653517138]
	TIME [epoch: 5.74 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06040410317960674		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.06040410317960674 | validation: 0.05827592472959533]
	TIME [epoch: 5.74 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056588712944184244		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.056588712944184244 | validation: 0.06836104070110702]
	TIME [epoch: 5.74 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060200381739114135		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.060200381739114135 | validation: 0.07538384488139248]
	TIME [epoch: 5.75 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054025415404322374		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.054025415404322374 | validation: 0.073909849652595]
	TIME [epoch: 5.77 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05982943264786075		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.05982943264786075 | validation: 0.061386127151400835]
	TIME [epoch: 5.74 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06145898687159457		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.06145898687159457 | validation: 0.060067631023834486]
	TIME [epoch: 5.74 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06072986238446766		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.06072986238446766 | validation: 0.07151818886521769]
	TIME [epoch: 5.74 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05613468463296264		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.05613468463296264 | validation: 0.06396861350860147]
	TIME [epoch: 5.74 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625092229932586		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.0625092229932586 | validation: 0.05610157705901238]
	TIME [epoch: 5.74 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055079819887312295		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.055079819887312295 | validation: 0.06955481909608506]
	TIME [epoch: 5.78 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058585666599780394		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.058585666599780394 | validation: 0.0699687020352399]
	TIME [epoch: 5.74 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05922652188073522		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.05922652188073522 | validation: 0.06391715438463781]
	TIME [epoch: 5.74 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05967494699282066		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.05967494699282066 | validation: 0.06554852084818308]
	TIME [epoch: 5.74 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06183663156836253		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.06183663156836253 | validation: 0.06609621480351979]
	TIME [epoch: 5.74 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05828976928172935		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.05828976928172935 | validation: 0.06881443489501392]
	TIME [epoch: 5.73 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05957774491390725		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.05957774491390725 | validation: 0.05829557994330497]
	TIME [epoch: 5.75 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06022044402203651		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.06022044402203651 | validation: 0.07266209486261399]
	TIME [epoch: 5.77 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05807437551848185		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.05807437551848185 | validation: 0.07271640545189635]
	TIME [epoch: 5.74 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060119285483303204		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.060119285483303204 | validation: 0.06595906311992071]
	TIME [epoch: 5.74 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06162545898762461		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.06162545898762461 | validation: 0.0673174978809269]
	TIME [epoch: 5.74 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05808519013190722		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.05808519013190722 | validation: 0.06984024999544375]
	TIME [epoch: 5.74 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0558099458504098		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.0558099458504098 | validation: 0.07062556143069686]
	TIME [epoch: 5.74 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060926225075079166		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.060926225075079166 | validation: 0.07657904260286083]
	TIME [epoch: 5.78 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0564207092803749		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.0564207092803749 | validation: 0.07931558091741284]
	TIME [epoch: 5.74 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784069979071932		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.05784069979071932 | validation: 0.06779639784755091]
	TIME [epoch: 5.74 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05551792218227884		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.05551792218227884 | validation: 0.07427389170516524]
	TIME [epoch: 5.73 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0584873303565156		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.0584873303565156 | validation: 0.07807853210281934]
	TIME [epoch: 5.75 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055806196989842086		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.055806196989842086 | validation: 0.06739343287332702]
	TIME [epoch: 5.74 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05488341963828349		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.05488341963828349 | validation: 0.06861847735496213]
	TIME [epoch: 5.77 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05702957011546443		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.05702957011546443 | validation: 0.06486049458692199]
	TIME [epoch: 5.75 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058116638678642585		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.058116638678642585 | validation: 0.06655364940073326]
	TIME [epoch: 5.74 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054014144482659635		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.054014144482659635 | validation: 0.08015918802436424]
	TIME [epoch: 5.74 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05787897874790227		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.05787897874790227 | validation: 0.07907101371846598]
	TIME [epoch: 5.74 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05691514567857094		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.05691514567857094 | validation: 0.07242739858359407]
	TIME [epoch: 5.74 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060833015604530166		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.060833015604530166 | validation: 0.07562987940506767]
	TIME [epoch: 5.74 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06026403012215469		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.06026403012215469 | validation: 0.06677900956230494]
	TIME [epoch: 5.77 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05538351914624441		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.05538351914624441 | validation: 0.07522213208535032]
	TIME [epoch: 5.74 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05592303605002482		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.05592303605002482 | validation: 0.07422773487485271]
	TIME [epoch: 5.74 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055766729611937016		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.055766729611937016 | validation: 0.08267239682224817]
	TIME [epoch: 5.74 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054804887984273395		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.054804887984273395 | validation: 0.07810540456859376]
	TIME [epoch: 5.74 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0577110053329265		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.0577110053329265 | validation: 0.07118112072782547]
	TIME [epoch: 5.74 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056029050472973484		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.056029050472973484 | validation: 0.07938019898358123]
	TIME [epoch: 5.77 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05497693084507159		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.05497693084507159 | validation: 0.08232798824381757]
	TIME [epoch: 5.76 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05954553524337499		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.05954553524337499 | validation: 0.09163237756644559]
	TIME [epoch: 5.74 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060487647171460525		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.060487647171460525 | validation: 0.08231091214651144]
	TIME [epoch: 5.74 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05997305575246243		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.05997305575246243 | validation: 0.07425133707303637]
	TIME [epoch: 5.73 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05887786780355088		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.05887786780355088 | validation: 0.07289910379501359]
	TIME [epoch: 5.74 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0560811539982984		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.0560811539982984 | validation: 0.08097386883140623]
	TIME [epoch: 5.74 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057798999125867175		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.057798999125867175 | validation: 0.07903472641333241]
	TIME [epoch: 5.78 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06332213935311416		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.06332213935311416 | validation: 0.07539190426206187]
	TIME [epoch: 5.75 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05521898515694325		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.05521898515694325 | validation: 0.07374767697585602]
	TIME [epoch: 5.74 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05706032355743843		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.05706032355743843 | validation: 0.0746735133610663]
	TIME [epoch: 5.74 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05632733317810277		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.05632733317810277 | validation: 0.07644104462269322]
	TIME [epoch: 5.74 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06043351468558636		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.06043351468558636 | validation: 0.07737994709025547]
	TIME [epoch: 5.73 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055485035965400824		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.055485035965400824 | validation: 0.07773683914959886]
	TIME [epoch: 5.77 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05974035373362118		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.05974035373362118 | validation: 0.0758713564593686]
	TIME [epoch: 5.76 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05994175659574499		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.05994175659574499 | validation: 0.06787282395128345]
	TIME [epoch: 5.74 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06008649353149099		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.06008649353149099 | validation: 0.07406435608554311]
	TIME [epoch: 5.74 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05818340011216072		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.05818340011216072 | validation: 0.0821177448798672]
	TIME [epoch: 5.74 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062190921098488824		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.062190921098488824 | validation: 0.08212910270073355]
	TIME [epoch: 5.74 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06066307739067138		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.06066307739067138 | validation: 0.07915592580846173]
	TIME [epoch: 5.74 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05947257656966517		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.05947257656966517 | validation: 0.08035110451876762]
	TIME [epoch: 5.77 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05817474984603644		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.05817474984603644 | validation: 0.06852197256037817]
	TIME [epoch: 5.73 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059257153210941826		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.059257153210941826 | validation: 0.07032760552562825]
	TIME [epoch: 5.73 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058638947557016964		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.058638947557016964 | validation: 0.06967955877180354]
	TIME [epoch: 5.74 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873894405149126		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.05873894405149126 | validation: 0.06721055287808207]
	TIME [epoch: 5.74 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05780189453967255		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.05780189453967255 | validation: 0.07131968020285571]
	TIME [epoch: 5.74 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058890018527550436		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.058890018527550436 | validation: 0.07278330824584942]
	TIME [epoch: 5.77 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603683470052412		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.05603683470052412 | validation: 0.06982995503005955]
	TIME [epoch: 5.76 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05575864855681982		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.05575864855681982 | validation: 0.07139876156334866]
	TIME [epoch: 5.75 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057712721340403374		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.057712721340403374 | validation: 0.07436936398542975]
	TIME [epoch: 5.74 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06104895861730737		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.06104895861730737 | validation: 0.07542186959420429]
	TIME [epoch: 5.73 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05533463239872908		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.05533463239872908 | validation: 0.06868726856341623]
	TIME [epoch: 5.73 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05537586205155007		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.05537586205155007 | validation: 0.07090285965947037]
	TIME [epoch: 5.74 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056441340933399003		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.056441340933399003 | validation: 0.07012582249755936]
	TIME [epoch: 5.78 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06191259855659009		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.06191259855659009 | validation: 0.07524144434519611]
	TIME [epoch: 5.75 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05881094615453026		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.05881094615453026 | validation: 0.07400601081438506]
	TIME [epoch: 5.74 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0613294514310416		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.0613294514310416 | validation: 0.07151456859757015]
	TIME [epoch: 5.74 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05985040205512314		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.05985040205512314 | validation: 0.08030916630425626]
	TIME [epoch: 5.74 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057490814477595534		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.057490814477595534 | validation: 0.08198130438558614]
	TIME [epoch: 5.74 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06225624919307668		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.06225624919307668 | validation: 0.07363999435992771]
	TIME [epoch: 5.77 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05808986333957962		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.05808986333957962 | validation: 0.07597057725348515]
	TIME [epoch: 5.75 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05596877653757013		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.05596877653757013 | validation: 0.06866801888970187]
	TIME [epoch: 5.74 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0588468792927077		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.0588468792927077 | validation: 0.07521251538489226]
	TIME [epoch: 5.74 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05907454292672389		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.05907454292672389 | validation: 0.07574053587962595]
	TIME [epoch: 5.74 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059076864908627416		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.059076864908627416 | validation: 0.07518935254383617]
	TIME [epoch: 5.74 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056459983348144255		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.056459983348144255 | validation: 0.07239820758615839]
	TIME [epoch: 5.76 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06080138157157934		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.06080138157157934 | validation: 0.06611910112867618]
	TIME [epoch: 5.77 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055327877251688924		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.055327877251688924 | validation: 0.06706166971252184]
	TIME [epoch: 5.75 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0575365033951426		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.0575365033951426 | validation: 0.06737594000722232]
	TIME [epoch: 5.75 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784822675950623		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.05784822675950623 | validation: 0.06963458249300716]
	TIME [epoch: 5.75 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060861976625271576		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.060861976625271576 | validation: 0.07029949534486518]
	TIME [epoch: 5.75 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05726268740569543		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.05726268740569543 | validation: 0.08043550251736999]
	TIME [epoch: 5.75 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06243526756353085		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.06243526756353085 | validation: 0.07247977500399966]
	TIME [epoch: 5.78 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05917444681836758		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.05917444681836758 | validation: 0.07230977644189529]
	TIME [epoch: 5.75 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05591440223948138		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.05591440223948138 | validation: 0.07075437006590989]
	TIME [epoch: 5.74 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05599833634850611		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.05599833634850611 | validation: 0.060574146094362624]
	TIME [epoch: 5.74 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054347619796271354		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.054347619796271354 | validation: 0.06885173084375752]
	TIME [epoch: 5.74 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0544136252861107		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.0544136252861107 | validation: 0.08330567837350791]
	TIME [epoch: 5.74 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053242065615975415		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.053242065615975415 | validation: 0.07687682322078525]
	TIME [epoch: 5.76 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05440337709597252		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.05440337709597252 | validation: 0.05987006810751921]
	TIME [epoch: 5.77 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0531043646035234		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.0531043646035234 | validation: 0.07109419535997738]
	TIME [epoch: 5.75 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05853474565076221		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.05853474565076221 | validation: 0.06551795479381746]
	TIME [epoch: 5.74 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05943789094571133		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.05943789094571133 | validation: 0.06798652460670832]
	TIME [epoch: 5.74 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056911331901831355		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.056911331901831355 | validation: 0.06682218238277915]
	TIME [epoch: 5.74 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05943354041904046		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.05943354041904046 | validation: 0.07389849214812848]
	TIME [epoch: 5.74 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05711590505523695		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.05711590505523695 | validation: 0.07128225214442795]
	TIME [epoch: 5.77 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05686365837211741		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.05686365837211741 | validation: 0.0748864622286838]
	TIME [epoch: 5.74 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0564096701791437		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.0564096701791437 | validation: 0.06511071348928649]
	TIME [epoch: 5.74 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059549393515631974		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.059549393515631974 | validation: 0.07130008856457144]
	TIME [epoch: 5.74 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057032602957784354		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.057032602957784354 | validation: 0.0759668395675075]
	TIME [epoch: 5.74 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05643392956079568		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.05643392956079568 | validation: 0.07341035580593137]
	TIME [epoch: 5.74 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06154486137451984		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.06154486137451984 | validation: 0.08165839687323494]
	TIME [epoch: 5.76 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05612023333795414		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.05612023333795414 | validation: 0.07418209086181551]
	TIME [epoch: 5.77 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05351951984277749		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.05351951984277749 | validation: 0.07528373365666398]
	TIME [epoch: 5.75 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05995058076106191		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.05995058076106191 | validation: 0.07246521711894133]
	TIME [epoch: 5.74 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05981962894828632		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.05981962894828632 | validation: 0.07230300594392967]
	TIME [epoch: 5.74 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057507105569697445		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.057507105569697445 | validation: 0.06688906577269883]
	TIME [epoch: 5.74 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05735355613095772		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.05735355613095772 | validation: 0.0667794560423589]
	TIME [epoch: 5.74 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058504381463337446		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.058504381463337446 | validation: 0.07570286081155318]
	TIME [epoch: 5.78 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05529641193383457		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.05529641193383457 | validation: 0.0703548207719199]
	TIME [epoch: 5.75 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055949975986667656		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.055949975986667656 | validation: 0.06421689602428611]
	TIME [epoch: 5.75 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056664070368732375		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.056664070368732375 | validation: 0.0688675613437995]
	TIME [epoch: 5.74 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056278931280987335		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.056278931280987335 | validation: 0.0691031796555565]
	TIME [epoch: 5.74 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057331244417497006		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.057331244417497006 | validation: 0.060765260845370705]
	TIME [epoch: 5.74 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05483243828819756		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.05483243828819756 | validation: 0.0691275406228981]
	TIME [epoch: 5.75 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05747224801916264		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.05747224801916264 | validation: 0.07492332822826563]
	TIME [epoch: 5.77 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642034290002135		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.0642034290002135 | validation: 0.06659133565350171]
	TIME [epoch: 5.74 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06057963128980771		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.06057963128980771 | validation: 0.07349312517885452]
	TIME [epoch: 5.75 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05977288459494072		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.05977288459494072 | validation: 0.07097560112593597]
	TIME [epoch: 5.74 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05810967746994427		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.05810967746994427 | validation: 0.06276451561236038]
	TIME [epoch: 5.75 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05770551085794375		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.05770551085794375 | validation: 0.06224698733654591]
	TIME [epoch: 5.75 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05758431057890734		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.05758431057890734 | validation: 0.060914063546169954]
	TIME [epoch: 5.78 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054426079413064314		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.054426079413064314 | validation: 0.06665448399038124]
	TIME [epoch: 5.74 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05630148090878448		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.05630148090878448 | validation: 0.06809923016487562]
	TIME [epoch: 5.74 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05672235230442878		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.05672235230442878 | validation: 0.07639652256083712]
	TIME [epoch: 5.74 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05831072842920126		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.05831072842920126 | validation: 0.07463809287795342]
	TIME [epoch: 5.74 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055924128420584515		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.055924128420584515 | validation: 0.06661466336269209]
	TIME [epoch: 5.74 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05503885401587097		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.05503885401587097 | validation: 0.07643434844925126]
	TIME [epoch: 5.77 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05916142720480811		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.05916142720480811 | validation: 0.06146826682422167]
	TIME [epoch: 5.76 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05861483141443768		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.05861483141443768 | validation: 0.06812629677738027]
	TIME [epoch: 5.74 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05289578129315674		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.05289578129315674 | validation: 0.06481510982649842]
	TIME [epoch: 5.74 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05527198214710833		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.05527198214710833 | validation: 0.06358157242495452]
	TIME [epoch: 5.74 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05635339143729304		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.05635339143729304 | validation: 0.0736339898882291]
	TIME [epoch: 5.74 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565442907658405		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.05565442907658405 | validation: 0.07752113934353622]
	TIME [epoch: 5.74 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05923905794053992		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.05923905794053992 | validation: 0.0737702167109276]
	TIME [epoch: 5.78 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05997122042200508		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.05997122042200508 | validation: 0.0714957062588625]
	TIME [epoch: 5.73 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06120643472879191		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.06120643472879191 | validation: 0.0654745210900948]
	TIME [epoch: 5.74 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0608786642412281		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.0608786642412281 | validation: 0.05882308376889963]
	TIME [epoch: 5.75 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05889128801718462		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.05889128801718462 | validation: 0.0696020183456574]
	TIME [epoch: 5.75 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0544370817617331		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.0544370817617331 | validation: 0.07426173971891945]
	TIME [epoch: 5.74 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056789805353172615		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.056789805353172615 | validation: 0.07713419459744668]
	TIME [epoch: 5.77 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05559013586587418		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.05559013586587418 | validation: 0.0684227490524806]
	TIME [epoch: 5.76 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05662773289502186		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.05662773289502186 | validation: 0.07153266838041444]
	TIME [epoch: 5.75 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055911985832291844		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.055911985832291844 | validation: 0.06477339198360929]
	TIME [epoch: 5.75 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056716334458682		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.056716334458682 | validation: 0.07405654908660063]
	TIME [epoch: 5.74 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05974805286083751		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.05974805286083751 | validation: 0.06962157591396094]
	TIME [epoch: 5.74 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057244111395733766		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.057244111395733766 | validation: 0.06952684265693085]
	TIME [epoch: 5.74 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05676387656052535		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.05676387656052535 | validation: 0.07504992738911966]
	TIME [epoch: 5.78 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05431156493773733		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.05431156493773733 | validation: 0.07230167672503603]
	TIME [epoch: 5.73 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05544753283358409		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.05544753283358409 | validation: 0.06612828331224539]
	TIME [epoch: 5.74 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05506828024785197		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.05506828024785197 | validation: 0.06742741865009604]
	TIME [epoch: 5.74 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05923825498747165		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.05923825498747165 | validation: 0.0697669972610248]
	TIME [epoch: 5.73 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056467252372347766		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.056467252372347766 | validation: 0.06429174075512328]
	TIME [epoch: 5.74 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05560653039743092		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.05560653039743092 | validation: 0.06958810371770302]
	TIME [epoch: 5.76 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05179776803784644		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.05179776803784644 | validation: 0.07816314363915039]
	TIME [epoch: 5.75 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05585169773570273		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.05585169773570273 | validation: 0.07785546545452107]
	TIME [epoch: 5.74 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05225977412405884		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.05225977412405884 | validation: 0.07257947572710997]
	TIME [epoch: 5.74 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055985586262186825		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.055985586262186825 | validation: 0.0765880855654892]
	TIME [epoch: 5.74 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0562645472953595		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.0562645472953595 | validation: 0.06630254371055339]
	TIME [epoch: 5.74 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05447460924750344		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.05447460924750344 | validation: 0.06462083484338087]
	TIME [epoch: 5.74 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05590497128206874		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.05590497128206874 | validation: 0.07938379086423855]
	TIME [epoch: 5.78 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05387355048897566		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.05387355048897566 | validation: 0.07617864915223262]
	TIME [epoch: 5.74 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05295362171723378		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.05295362171723378 | validation: 0.06795728063382385]
	TIME [epoch: 5.73 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05578409817723354		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.05578409817723354 | validation: 0.06529043439863179]
	TIME [epoch: 5.73 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05756957652325478		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.05756957652325478 | validation: 0.07772300348145816]
	TIME [epoch: 5.73 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05893260577608715		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.05893260577608715 | validation: 0.06587048445198883]
	TIME [epoch: 5.74 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052771350299959226		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.052771350299959226 | validation: 0.07788344337794266]
	TIME [epoch: 5.77 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05360432602219131		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.05360432602219131 | validation: 0.06870078634246161]
	TIME [epoch: 5.76 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054633657059503425		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.054633657059503425 | validation: 0.07009058887642372]
	TIME [epoch: 5.74 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05352326833827217		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.05352326833827217 | validation: 0.07061747820477185]
	TIME [epoch: 5.73 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054295442498251224		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.054295442498251224 | validation: 0.0633278333526088]
	TIME [epoch: 5.74 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053184634091298456		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.053184634091298456 | validation: 0.06491027905068433]
	TIME [epoch: 5.74 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053857151947159766		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.053857151947159766 | validation: 0.06511331582089847]
	TIME [epoch: 5.74 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050420134637680095		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.050420134637680095 | validation: 0.061997247458994965]
	TIME [epoch: 5.77 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05529468860328099		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.05529468860328099 | validation: 0.07154184741730299]
	TIME [epoch: 5.73 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05250770095915258		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.05250770095915258 | validation: 0.06668351950584031]
	TIME [epoch: 5.73 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0554570860465801		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.0554570860465801 | validation: 0.07837364548787988]
	TIME [epoch: 5.74 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0568529886960613		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.0568529886960613 | validation: 0.06884190140655021]
	TIME [epoch: 5.74 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05494642912483902		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.05494642912483902 | validation: 0.07734945200026644]
	TIME [epoch: 5.74 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058348966656402726		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.058348966656402726 | validation: 0.0694526547695417]
	TIME [epoch: 5.77 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05532509063669007		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.05532509063669007 | validation: 0.06770784327813226]
	TIME [epoch: 5.75 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05280806463498479		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.05280806463498479 | validation: 0.06279253714540586]
	TIME [epoch: 5.74 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055109536747897266		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.055109536747897266 | validation: 0.06293516208479773]
	TIME [epoch: 5.74 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05357426826911056		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.05357426826911056 | validation: 0.06858501857336621]
	TIME [epoch: 5.73 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05263848824173695		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.05263848824173695 | validation: 0.07258432781398068]
	TIME [epoch: 5.73 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056449194159787816		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.056449194159787816 | validation: 0.07328039702012691]
	TIME [epoch: 5.74 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055377256574342344		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.055377256574342344 | validation: 0.06741656079068982]
	TIME [epoch: 5.76 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05399881230112197		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.05399881230112197 | validation: 0.0651152507943734]
	TIME [epoch: 5.74 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05623731538676947		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.05623731538676947 | validation: 0.0756828824604687]
	TIME [epoch: 5.74 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05924423198600733		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.05924423198600733 | validation: 0.07605463564981356]
	TIME [epoch: 5.74 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05502179201059621		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.05502179201059621 | validation: 0.07851790025770221]
	TIME [epoch: 5.73 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05125481636159293		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.05125481636159293 | validation: 0.059885008052128284]
	TIME [epoch: 5.74 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055299336788342035		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.055299336788342035 | validation: 0.07386264171681332]
	TIME [epoch: 5.78 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05377102988611841		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.05377102988611841 | validation: 0.06877738087472769]
	TIME [epoch: 5.74 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05540757363868745		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.05540757363868745 | validation: 0.06738587810784542]
	TIME [epoch: 5.73 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05865038210027281		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.05865038210027281 | validation: 0.0641243480471771]
	TIME [epoch: 5.73 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056171651292115515		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.056171651292115515 | validation: 0.06243922134550619]
	TIME [epoch: 5.73 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05351369504793783		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.05351369504793783 | validation: 0.06929749142175348]
	TIME [epoch: 5.73 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058143640605115086		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.058143640605115086 | validation: 0.07052127232399931]
	TIME [epoch: 5.75 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058547780613449944		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.058547780613449944 | validation: 0.0746335186212886]
	TIME [epoch: 5.77 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05492722709923804		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.05492722709923804 | validation: 0.07871288256070517]
	TIME [epoch: 5.74 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055164962933575507		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.055164962933575507 | validation: 0.07899356764315196]
	TIME [epoch: 5.74 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058157348586055785		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.058157348586055785 | validation: 0.07577348395435025]
	TIME [epoch: 5.74 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06107324792518273		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.06107324792518273 | validation: 0.07166642373984308]
	TIME [epoch: 5.74 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05722673995551132		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.05722673995551132 | validation: 0.07084928521612054]
	TIME [epoch: 5.75 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059429621699930046		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.059429621699930046 | validation: 0.06885651586219382]
	TIME [epoch: 5.78 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057231250112647236		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.057231250112647236 | validation: 0.07066422581435379]
	TIME [epoch: 5.75 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052143609684028216		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.052143609684028216 | validation: 0.06974871025805614]
	TIME [epoch: 5.74 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058740325834846355		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.058740325834846355 | validation: 0.07147550816550224]
	TIME [epoch: 5.74 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0567606518104664		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.0567606518104664 | validation: 0.07521261935362825]
	TIME [epoch: 5.74 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05776681129215268		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.05776681129215268 | validation: 0.07534422032723166]
	TIME [epoch: 5.74 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05391281938029546		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.05391281938029546 | validation: 0.07621286490317271]
	TIME [epoch: 5.75 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05950751572395079		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.05950751572395079 | validation: 0.07226113115345945]
	TIME [epoch: 5.77 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05618415249173172		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.05618415249173172 | validation: 0.06758078622542509]
	TIME [epoch: 5.74 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054557061662353065		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.054557061662353065 | validation: 0.06899192028148793]
	TIME [epoch: 5.74 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05430467376493088		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.05430467376493088 | validation: 0.07368612649803014]
	TIME [epoch: 5.73 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05679822515592667		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.05679822515592667 | validation: 0.07909261873631962]
	TIME [epoch: 5.73 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0583692773645693		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.0583692773645693 | validation: 0.0750020650491351]
	TIME [epoch: 5.74 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05578380217147383		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.05578380217147383 | validation: 0.0728013117045265]
	TIME [epoch: 5.77 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05553971472080145		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.05553971472080145 | validation: 0.05833679870181679]
	TIME [epoch: 5.75 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057906837229798815		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.057906837229798815 | validation: 0.07062164831271185]
	TIME [epoch: 5.74 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056199878311784794		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.056199878311784794 | validation: 0.07434683743223848]
	TIME [epoch: 5.74 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057179574108947875		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.057179574108947875 | validation: 0.07332089866028117]
	TIME [epoch: 5.74 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05203371869439187		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.05203371869439187 | validation: 0.06851311889476945]
	TIME [epoch: 5.74 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05228086324607792		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.05228086324607792 | validation: 0.07788933775046833]
	TIME [epoch: 5.74 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056270459103387786		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.056270459103387786 | validation: 0.06547540073306482]
	TIME [epoch: 5.76 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05747249050334248		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.05747249050334248 | validation: 0.06771826085180242]
	TIME [epoch: 5.73 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05632942494024765		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.05632942494024765 | validation: 0.06426125784548399]
	TIME [epoch: 5.73 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05614087473031799		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.05614087473031799 | validation: 0.06499649352939482]
	TIME [epoch: 5.74 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056553920565599776		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.056553920565599776 | validation: 0.06356730555195285]
	TIME [epoch: 5.74 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05964786525564107		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.05964786525564107 | validation: 0.06925257944457569]
	TIME [epoch: 5.74 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05496728083714676		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.05496728083714676 | validation: 0.06976142726218484]
	TIME [epoch: 5.78 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056542607181684815		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.056542607181684815 | validation: 0.0689957128785382]
	TIME [epoch: 5.74 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05827976274808429		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.05827976274808429 | validation: 0.0674452596050078]
	TIME [epoch: 5.74 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05704631946405293		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.05704631946405293 | validation: 0.07045775240090184]
	TIME [epoch: 5.73 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05883507926608446		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.05883507926608446 | validation: 0.07156659595971405]
	TIME [epoch: 5.73 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052419579963362675		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.052419579963362675 | validation: 0.05989248873725646]
	TIME [epoch: 5.73 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05627300287735912		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.05627300287735912 | validation: 0.07265573844262266]
	TIME [epoch: 5.76 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05432031690714792		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.05432031690714792 | validation: 0.06684701492617519]
	TIME [epoch: 5.75 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05351116114267429		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.05351116114267429 | validation: 0.06887043419870773]
	TIME [epoch: 5.74 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05767254868736975		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.05767254868736975 | validation: 0.06967952524624457]
	TIME [epoch: 5.74 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05963112234844357		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.05963112234844357 | validation: 0.06628999498884895]
	TIME [epoch: 5.73 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05204187245257356		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.05204187245257356 | validation: 0.06561887752208528]
	TIME [epoch: 5.74 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05471062330220622		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.05471062330220622 | validation: 0.061591141756318656]
	TIME [epoch: 5.74 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054377217326930426		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.054377217326930426 | validation: 0.06541729118245172]
	TIME [epoch: 5.78 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05482310686976663		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.05482310686976663 | validation: 0.07118191465865906]
	TIME [epoch: 5.74 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06083361781042211		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.06083361781042211 | validation: 0.0638468935161731]
	TIME [epoch: 5.73 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05743562177760836		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.05743562177760836 | validation: 0.07098378068344376]
	TIME [epoch: 5.73 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058284731241224345		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.058284731241224345 | validation: 0.06728602307440477]
	TIME [epoch: 5.73 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05441316231126034		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.05441316231126034 | validation: 0.07044484029199215]
	TIME [epoch: 5.74 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054766566045242576		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.054766566045242576 | validation: 0.06389724262860698]
	TIME [epoch: 5.77 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05762167926456843		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.05762167926456843 | validation: 0.06817998272410199]
	TIME [epoch: 5.75 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055972604841100934		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.055972604841100934 | validation: 0.06416645659575178]
	TIME [epoch: 5.74 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05763853099387386		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.05763853099387386 | validation: 0.06933942567131551]
	TIME [epoch: 5.74 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05645800031361458		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.05645800031361458 | validation: 0.06681974256194695]
	TIME [epoch: 5.74 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05802877519381702		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.05802877519381702 | validation: 0.07224304785175713]
	TIME [epoch: 5.73 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058968677886171536		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.058968677886171536 | validation: 0.07369568248939037]
	TIME [epoch: 5.73 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06044886881144068		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.06044886881144068 | validation: 0.07321129363078895]
	TIME [epoch: 5.77 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05684463791128407		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.05684463791128407 | validation: 0.07639600727179788]
	TIME [epoch: 5.74 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057874735794454124		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.057874735794454124 | validation: 0.0782289212616905]
	TIME [epoch: 5.74 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05803603879961976		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.05803603879961976 | validation: 0.06357625520498104]
	TIME [epoch: 5.74 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05833904670996987		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.05833904670996987 | validation: 0.07348400112994445]
	TIME [epoch: 5.73 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06012153898440353		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.06012153898440353 | validation: 0.059205138758034764]
	TIME [epoch: 5.74 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05578855132502178		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.05578855132502178 | validation: 0.061272578853375566]
	TIME [epoch: 5.77 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0586643072425669		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.0586643072425669 | validation: 0.0703332312835918]
	TIME [epoch: 5.75 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06120701605183505		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.06120701605183505 | validation: 0.0680655903117115]
	TIME [epoch: 5.74 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05771921885546266		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.05771921885546266 | validation: 0.06261981077703746]
	TIME [epoch: 5.73 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05560802652199684		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.05560802652199684 | validation: 0.05788358665792767]
	TIME [epoch: 5.74 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05775920716089848		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.05775920716089848 | validation: 0.06351374538169031]
	TIME [epoch: 5.75 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05896839650602502		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.05896839650602502 | validation: 0.07235397468502938]
	TIME [epoch: 5.75 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0543527981096891		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.0543527981096891 | validation: 0.06687819022294397]
	TIME [epoch: 5.79 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051735656271834574		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.051735656271834574 | validation: 0.07683418262116459]
	TIME [epoch: 5.74 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058203658545468745		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.058203658545468745 | validation: 0.07561773383150273]
	TIME [epoch: 5.74 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05607263835261851		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.05607263835261851 | validation: 0.07491923397839605]
	TIME [epoch: 5.74 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05410854050462669		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.05410854050462669 | validation: 0.06538023221040402]
	TIME [epoch: 5.73 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05460663894874707		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.05460663894874707 | validation: 0.06310619290659697]
	TIME [epoch: 5.73 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057991295895453446		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.057991295895453446 | validation: 0.07133144099404715]
	TIME [epoch: 5.76 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055424675993744184		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.055424675993744184 | validation: 0.07269647038263127]
	TIME [epoch: 5.74 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058951230301326304		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.058951230301326304 | validation: 0.06482574101224942]
	TIME [epoch: 5.74 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05626342068023586		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.05626342068023586 | validation: 0.06806911602576869]
	TIME [epoch: 5.74 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05612875184953918		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.05612875184953918 | validation: 0.058985092609153515]
	TIME [epoch: 5.74 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055712168316665645		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.055712168316665645 | validation: 0.06390888401240408]
	TIME [epoch: 5.74 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057908623859182315		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.057908623859182315 | validation: 0.07580385551962396]
	TIME [epoch: 5.75 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05653971711938997		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.05653971711938997 | validation: 0.06524243979472899]
	TIME [epoch: 5.77 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05810953657651167		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.05810953657651167 | validation: 0.058376876048128995]
	TIME [epoch: 5.73 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05560555996991832		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.05560555996991832 | validation: 0.07016084670318408]
	TIME [epoch: 5.73 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05643587090894031		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.05643587090894031 | validation: 0.06934705671656789]
	TIME [epoch: 5.73 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054338663560038955		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.054338663560038955 | validation: 0.07027552587897526]
	TIME [epoch: 5.73 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05774107835933885		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.05774107835933885 | validation: 0.06455375568408776]
	TIME [epoch: 5.73 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0548112289745896		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.0548112289745896 | validation: 0.06863035320554516]
	TIME [epoch: 5.78 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054540065966307096		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.054540065966307096 | validation: 0.06392857541130079]
	TIME [epoch: 5.74 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0538950331513874		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.0538950331513874 | validation: 0.0668877282063646]
	TIME [epoch: 5.73 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05705005917054286		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.05705005917054286 | validation: 0.06919585702884876]
	TIME [epoch: 5.74 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055590038738840566		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.055590038738840566 | validation: 0.0659826140677448]
	TIME [epoch: 5.74 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05030089718319575		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.05030089718319575 | validation: 0.07074996422809346]
	TIME [epoch: 5.74 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05324650961842969		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.05324650961842969 | validation: 0.06933428253521189]
	TIME [epoch: 5.74 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05347149365328424		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.05347149365328424 | validation: 0.055691139496187196]
	TIME [epoch: 5.76 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05166480393623235		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.05166480393623235 | validation: 0.06578281669594274]
	TIME [epoch: 5.74 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06037447909905933		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.06037447909905933 | validation: 0.077621279132898]
	TIME [epoch: 5.73 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054357258279790585		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.054357258279790585 | validation: 0.0759031297925759]
	TIME [epoch: 5.74 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055437869872150124		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.055437869872150124 | validation: 0.0693328643075689]
	TIME [epoch: 5.74 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05564546255708137		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.05564546255708137 | validation: 0.07251584228037293]
	TIME [epoch: 5.74 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05423941446460584		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.05423941446460584 | validation: 0.07917299206080039]
	TIME [epoch: 5.77 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05828374088967379		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.05828374088967379 | validation: 0.06670091416215791]
	TIME [epoch: 5.74 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054017403330552674		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.054017403330552674 | validation: 0.07390739540220546]
	TIME [epoch: 5.74 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05461234476888636		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.05461234476888636 | validation: 0.06283021516459082]
	TIME [epoch: 5.74 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05735959684829171		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.05735959684829171 | validation: 0.07231232770609843]
	TIME [epoch: 5.73 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0568140599406155		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.0568140599406155 | validation: 0.061928476798802354]
	TIME [epoch: 5.73 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05494051172610432		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.05494051172610432 | validation: 0.08338824682384878]
	TIME [epoch: 5.74 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054692266448689165		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.054692266448689165 | validation: 0.06019563842323471]
	TIME [epoch: 5.77 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055704231180061424		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.055704231180061424 | validation: 0.06020489311925332]
	TIME [epoch: 5.74 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05321706368423948		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.05321706368423948 | validation: 0.0669832323971871]
	TIME [epoch: 5.73 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0587980456986725		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.0587980456986725 | validation: 0.06627234157670646]
	TIME [epoch: 5.74 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05425070106384214		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.05425070106384214 | validation: 0.05949926948703389]
	TIME [epoch: 5.74 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053868045359092794		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.053868045359092794 | validation: 0.06342909915010106]
	TIME [epoch: 5.74 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05222628971389152		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.05222628971389152 | validation: 0.07196101936763934]
	TIME [epoch: 5.77 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056875643288005984		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.056875643288005984 | validation: 0.07144741359703476]
	TIME [epoch: 5.74 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056213526856050106		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.056213526856050106 | validation: 0.06059715922113181]
	TIME [epoch: 5.73 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05677474140442594		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.05677474140442594 | validation: 0.07268172005721596]
	TIME [epoch: 5.74 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05697124350942149		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.05697124350942149 | validation: 0.06945513813122565]
	TIME [epoch: 5.74 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565578833066863		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.05565578833066863 | validation: 0.06403926547925062]
	TIME [epoch: 5.74 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05637299698077895		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.05637299698077895 | validation: 0.07207228924544197]
	TIME [epoch: 5.75 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05689408226865203		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.05689408226865203 | validation: 0.07179988850825937]
	TIME [epoch: 5.77 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0530056518573163		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.0530056518573163 | validation: 0.06172836118265586]
	TIME [epoch: 5.74 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05655100084357715		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.05655100084357715 | validation: 0.05754551784132834]
	TIME [epoch: 5.74 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05556271246583993		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.05556271246583993 | validation: 0.072604577122733]
	TIME [epoch: 5.73 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05801805111565406		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.05801805111565406 | validation: 0.06580881559440097]
	TIME [epoch: 5.74 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058761550319464916		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.058761550319464916 | validation: 0.06895976734850252]
	TIME [epoch: 5.74 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056820142580176446		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.056820142580176446 | validation: 0.06340649667775085]
	TIME [epoch: 5.78 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056754283873366715		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.056754283873366715 | validation: 0.06751819152144602]
	TIME [epoch: 5.75 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060158926302671084		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.060158926302671084 | validation: 0.068261563225054]
	TIME [epoch: 5.74 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059338240621165474		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.059338240621165474 | validation: 0.07415431729298226]
	TIME [epoch: 5.74 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057352169413976375		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.057352169413976375 | validation: 0.07239634032573068]
	TIME [epoch: 5.74 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0584826170690115		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.0584826170690115 | validation: 0.06858585687666008]
	TIME [epoch: 5.74 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05656585721933301		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.05656585721933301 | validation: 0.07772460321507359]
	TIME [epoch: 5.77 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05655217460918807		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.05655217460918807 | validation: 0.06904499923631263]
	TIME [epoch: 5.75 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06022142327896697		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.06022142327896697 | validation: 0.0718851091945318]
	TIME [epoch: 5.74 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060713404045564315		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.060713404045564315 | validation: 0.06576037151128143]
	TIME [epoch: 5.74 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05818812768609044		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.05818812768609044 | validation: 0.07176999161366825]
	TIME [epoch: 5.74 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05914852641476524		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.05914852641476524 | validation: 0.06768472886050259]
	TIME [epoch: 5.74 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061587045404276286		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.061587045404276286 | validation: 0.0710410174623819]
	TIME [epoch: 5.74 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056268382789778394		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.056268382789778394 | validation: 0.07297441095379906]
	TIME [epoch: 5.78 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05866224563710921		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.05866224563710921 | validation: 0.07074007847121791]
	TIME [epoch: 5.75 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059847199834353416		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.059847199834353416 | validation: 0.0710055844309081]
	TIME [epoch: 5.74 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05673160666956162		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.05673160666956162 | validation: 0.06986831758157003]
	TIME [epoch: 5.74 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05414766670617883		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.05414766670617883 | validation: 0.07051640649900069]
	TIME [epoch: 5.74 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05523538937691261		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.05523538937691261 | validation: 0.07378516687189306]
	TIME [epoch: 5.74 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056262189035097526		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.056262189035097526 | validation: 0.06114122639480018]
	TIME [epoch: 5.77 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05207145505033662		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.05207145505033662 | validation: 0.06837120721526084]
	TIME [epoch: 5.76 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05657992407662985		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.05657992407662985 | validation: 0.0616592318437732]
	TIME [epoch: 5.74 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05633284523249247		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.05633284523249247 | validation: 0.06563030876830057]
	TIME [epoch: 5.74 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05546264295787169		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.05546264295787169 | validation: 0.06726453114764346]
	TIME [epoch: 5.74 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05783625877346316		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.05783625877346316 | validation: 0.06182749004954955]
	TIME [epoch: 5.74 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05726028005020235		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.05726028005020235 | validation: 0.06587308179987933]
	TIME [epoch: 5.74 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057144863420400954		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.057144863420400954 | validation: 0.060587042864841914]
	TIME [epoch: 5.78 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05929387697822028		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.05929387697822028 | validation: 0.057310323133675775]
	TIME [epoch: 5.74 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05632360755416557		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.05632360755416557 | validation: 0.0682161868185478]
	TIME [epoch: 5.74 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054138100385914725		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.054138100385914725 | validation: 0.06921309341715876]
	TIME [epoch: 5.74 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05835029313716784		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.05835029313716784 | validation: 0.06877774196494395]
	TIME [epoch: 5.74 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05651590856845874		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.05651590856845874 | validation: 0.07052096928886746]
	TIME [epoch: 5.74 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056254223846942536		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.056254223846942536 | validation: 0.07252120319185737]
	TIME [epoch: 5.77 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059957329386438246		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.059957329386438246 | validation: 0.0662553326760605]
	TIME [epoch: 5.75 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05735778895896741		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.05735778895896741 | validation: 0.08283854413277851]
	TIME [epoch: 5.74 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060416660432133916		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.060416660432133916 | validation: 0.06538008390731861]
	TIME [epoch: 5.74 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05893827174741113		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.05893827174741113 | validation: 0.06574480840357534]
	TIME [epoch: 5.74 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05875624378111539		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.05875624378111539 | validation: 0.0599320150724203]
	TIME [epoch: 5.74 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058502642158440414		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.058502642158440414 | validation: 0.06401667046387086]
	TIME [epoch: 5.74 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05514672911920371		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.05514672911920371 | validation: 0.0706702589212878]
	TIME [epoch: 5.78 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05574719469388332		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.05574719469388332 | validation: 0.0628821485708132]
	TIME [epoch: 5.75 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05659361488849675		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.05659361488849675 | validation: 0.0689199148802015]
	TIME [epoch: 5.74 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0549961609331819		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.0549961609331819 | validation: 0.0597421497568582]
	TIME [epoch: 5.74 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0552315399651409		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.0552315399651409 | validation: 0.06585600648634297]
	TIME [epoch: 5.74 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05552427334187976		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.05552427334187976 | validation: 0.060834554916112386]
	TIME [epoch: 5.74 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05903604040740348		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.05903604040740348 | validation: 0.06450832353945221]
	TIME [epoch: 5.78 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05911911124447507		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.05911911124447507 | validation: 0.06614930221498502]
	TIME [epoch: 5.75 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0560795540378671		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.0560795540378671 | validation: 0.06445531814771462]
	TIME [epoch: 5.74 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05754730199234376		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.05754730199234376 | validation: 0.05957747305238645]
	TIME [epoch: 5.74 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05737513816652817		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.05737513816652817 | validation: 0.0620019452232585]
	TIME [epoch: 5.74 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0560793677938839		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.0560793677938839 | validation: 0.06212566848239234]
	TIME [epoch: 5.74 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05744146646840748		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.05744146646840748 | validation: 0.057967953614813265]
	TIME [epoch: 5.75 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05857170926184854		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.05857170926184854 | validation: 0.06381984604098336]
	TIME [epoch: 5.77 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056184625005937225		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.056184625005937225 | validation: 0.05841276657208781]
	TIME [epoch: 5.74 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05643828839612699		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.05643828839612699 | validation: 0.0691680343280997]
	TIME [epoch: 5.74 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057801575744574535		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.057801575744574535 | validation: 0.06596933216521746]
	TIME [epoch: 5.74 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057423391035487284		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.057423391035487284 | validation: 0.059314156933899284]
	TIME [epoch: 5.74 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05949119884528713		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.05949119884528713 | validation: 0.06537212151459193]
	TIME [epoch: 5.74 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053707967781556926		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.053707967781556926 | validation: 0.06386717680121659]
	TIME [epoch: 5.78 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0549577640294322		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.0549577640294322 | validation: 0.06364507381653142]
	TIME [epoch: 5.75 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0552400574534712		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.0552400574534712 | validation: 0.07085399857036238]
	TIME [epoch: 5.74 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05468357080390626		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.05468357080390626 | validation: 0.06022406386198538]
	TIME [epoch: 5.74 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057677050326403176		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.057677050326403176 | validation: 0.05259356616620285]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240310_003040/states/model_tr_study1_1923.pth
	Model improved!!!
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05429201039289483		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.05429201039289483 | validation: 0.06451876194254913]
	TIME [epoch: 5.74 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05724450018771973		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.05724450018771973 | validation: 0.06116146963270557]
	TIME [epoch: 5.75 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05420475679188051		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.05420475679188051 | validation: 0.06488328296867464]
	TIME [epoch: 5.77 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05427767379307706		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.05427767379307706 | validation: 0.06005085410091392]
	TIME [epoch: 5.75 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05570482044908996		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.05570482044908996 | validation: 0.068703541816489]
	TIME [epoch: 5.74 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05913027509537408		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.05913027509537408 | validation: 0.06042545103445047]
	TIME [epoch: 5.74 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05888989317978323		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.05888989317978323 | validation: 0.0735612965976368]
	TIME [epoch: 5.74 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05745703196394995		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.05745703196394995 | validation: 0.06527708969896737]
	TIME [epoch: 5.74 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05430008704033859		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.05430008704033859 | validation: 0.06070599301539158]
	TIME [epoch: 5.78 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05523991620471722		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.05523991620471722 | validation: 0.0786591726726623]
	TIME [epoch: 5.74 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565084358936945		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.05565084358936945 | validation: 0.06398433481261352]
	TIME [epoch: 5.73 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054006309775447216		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.054006309775447216 | validation: 0.07038112398457645]
	TIME [epoch: 5.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056178983415010236		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.056178983415010236 | validation: 0.07247718415453078]
	TIME [epoch: 5.73 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053615581099638945		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.053615581099638945 | validation: 0.07092566972897787]
	TIME [epoch: 5.74 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05363695314337316		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.05363695314337316 | validation: 0.059611782629660735]
	TIME [epoch: 5.77 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05670849167840581		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.05670849167840581 | validation: 0.0673199702122705]
	TIME [epoch: 5.76 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055671668146630986		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.055671668146630986 | validation: 0.06619193849281904]
	TIME [epoch: 5.75 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053655725360583245		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.053655725360583245 | validation: 0.0743839157183897]
	TIME [epoch: 5.74 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05549627525405807		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.05549627525405807 | validation: 0.06302254719303887]
	TIME [epoch: 5.75 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056471843297278744		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.056471843297278744 | validation: 0.06487809772813422]
	TIME [epoch: 5.75 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05026064246019393		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.05026064246019393 | validation: 0.060575235850454004]
	TIME [epoch: 5.74 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055753055465464475		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.055753055465464475 | validation: 0.060681914002838004]
	TIME [epoch: 5.77 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056961236289469024		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.056961236289469024 | validation: 0.06968374804662962]
	TIME [epoch: 5.74 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05670730313741429		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.05670730313741429 | validation: 0.06882861255148304]
	TIME [epoch: 5.73 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05239694376183441		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.05239694376183441 | validation: 0.05824375290044717]
	TIME [epoch: 5.74 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05901498272969749		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.05901498272969749 | validation: 0.06763414010372118]
	TIME [epoch: 5.74 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05425867271400844		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.05425867271400844 | validation: 0.06286549818799968]
	TIME [epoch: 5.74 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0573282505647398		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.0573282505647398 | validation: 0.06180399466739617]
	TIME [epoch: 5.76 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05474682984204042		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.05474682984204042 | validation: 0.06670161939803713]
	TIME [epoch: 5.76 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054350612894315656		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.054350612894315656 | validation: 0.059578890494835446]
	TIME [epoch: 5.75 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051971929993762024		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.051971929993762024 | validation: 0.05923777406593834]
	TIME [epoch: 5.74 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055557873583827626		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.055557873583827626 | validation: 0.0640109804538413]
	TIME [epoch: 5.73 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054644301289972386		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.054644301289972386 | validation: 0.061631354695397204]
	TIME [epoch: 5.73 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05657060851188533		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.05657060851188533 | validation: 0.0632720486160557]
	TIME [epoch: 5.74 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05415647525275587		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.05415647525275587 | validation: 0.06610352513487337]
	TIME [epoch: 5.78 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05799039816734852		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.05799039816734852 | validation: 0.06483483147868728]
	TIME [epoch: 5.74 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05569025517211541		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.05569025517211541 | validation: 0.06826708511674301]
	TIME [epoch: 5.74 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05828521879893587		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.05828521879893587 | validation: 0.07027328638956223]
	TIME [epoch: 5.74 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05688096739544512		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.05688096739544512 | validation: 0.07257945934392562]
	TIME [epoch: 5.74 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055602676382178584		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.055602676382178584 | validation: 0.06634994532553756]
	TIME [epoch: 5.74 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056116399462761105		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.056116399462761105 | validation: 0.07064014584391576]
	TIME [epoch: 5.77 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05515463420526947		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.05515463420526947 | validation: 0.0670272375692778]
	TIME [epoch: 5.74 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05432964558085071		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.05432964558085071 | validation: 0.06813205824720316]
	TIME [epoch: 5.73 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055135150077299085		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.055135150077299085 | validation: 0.06616248138950075]
	TIME [epoch: 5.73 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052947625186342676		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.052947625186342676 | validation: 0.055763395520106035]
	TIME [epoch: 5.74 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053902537417462294		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.053902537417462294 | validation: 0.06367806662434602]
	TIME [epoch: 5.74 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05726419383604551		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.05726419383604551 | validation: 0.05566812087063751]
	TIME [epoch: 5.75 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05667813596961624		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.05667813596961624 | validation: 0.058452905810420036]
	TIME [epoch: 5.77 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05480840428200512		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.05480840428200512 | validation: 0.06084490270684707]
	TIME [epoch: 5.74 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05600827622330185		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.05600827622330185 | validation: 0.06289799217364023]
	TIME [epoch: 5.74 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05639550795771535		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.05639550795771535 | validation: 0.07230175786433511]
	TIME [epoch: 5.74 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05596002602082538		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.05596002602082538 | validation: 0.06941858327019045]
	TIME [epoch: 5.74 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05674858141704951		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.05674858141704951 | validation: 0.06598702247450818]
	TIME [epoch: 5.73 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050659680994009706		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.050659680994009706 | validation: 0.06481186685173253]
	TIME [epoch: 5.77 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05605345402282522		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.05605345402282522 | validation: 0.06342473370038547]
	TIME [epoch: 5.74 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05233455698227764		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.05233455698227764 | validation: 0.0675660837310199]
	TIME [epoch: 5.73 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05324608935876854		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.05324608935876854 | validation: 0.06449849672223365]
	TIME [epoch: 5.74 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05529990780084526		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.05529990780084526 | validation: 0.06728184031632847]
	TIME [epoch: 5.74 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05321655595553765		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.05321655595553765 | validation: 0.06163108611034957]
	TIME [epoch: 5.73 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054379982834679215		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.054379982834679215 | validation: 0.06774241425188963]
	TIME [epoch: 5.75 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05252651797590033		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.05252651797590033 | validation: 0.06732372299276877]
	TIME [epoch: 5.77 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055869373892088695		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.055869373892088695 | validation: 0.06438103927087337]
	TIME [epoch: 5.74 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05824463089888214		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.05824463089888214 | validation: 0.062160754370552324]
	TIME [epoch: 5.73 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05511004330546171		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.05511004330546171 | validation: 0.06598027666940119]
	TIME [epoch: 5.73 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05489768420207737		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.05489768420207737 | validation: 0.06310861094130878]
	TIME [epoch: 5.73 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05483683786487262		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.05483683786487262 | validation: 0.06064949892115155]
	TIME [epoch: 5.74 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05254091388040626		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.05254091388040626 | validation: 0.06351543426149094]
	TIME [epoch: 5.78 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05175068259762582		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.05175068259762582 | validation: 0.06218516241597316]
	TIME [epoch: 5.75 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05569934604201206		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.05569934604201206 | validation: 0.0761236358890106]
	TIME [epoch: 5.75 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054001572166032415		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.054001572166032415 | validation: 0.07092361373521783]
	TIME [epoch: 5.75 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05639292663255744		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.05639292663255744 | validation: 0.05841751810869535]
	TIME [epoch: 5.75 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05683157490921743		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.05683157490921743 | validation: 0.0585019959450676]
	TIME [epoch: 5.74 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053844333671293716		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.053844333671293716 | validation: 0.05736996840524697]
	TIME [epoch: 5.76 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05590909752161362		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.05590909752161362 | validation: 0.06598285587775038]
	TIME [epoch: 5.77 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056231804198849725		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.056231804198849725 | validation: 0.06040536364214113]
	TIME [epoch: 5.74 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0565037470362757		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.0565037470362757 | validation: 0.06673256772629085]
	TIME [epoch: 5.74 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058393130850592743		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.058393130850592743 | validation: 0.058042612913879674]
	TIME [epoch: 5.74 sec]
Finished training in 11706.946 seconds.
