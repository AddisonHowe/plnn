Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r4', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2280710166

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.965944265465573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.965944265465573 | validation: 10.944818746655951]
	TIME [epoch: 91.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.207184982622064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.207184982622064 | validation: 10.666912825900491]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.648453778823272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.648453778823272 | validation: 9.196095680190366]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.783321824598382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.783321824598382 | validation: 10.409676383822239]
	TIME [epoch: 5.73 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.211316309529414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.211316309529414 | validation: 7.6775875283711255]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.612294540639644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.612294540639644 | validation: 7.063852425681173]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.808120157758237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.808120157758237 | validation: 5.9908989458248305]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.536442455963819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.536442455963819 | validation: 8.494292748701234]
	TIME [epoch: 5.72 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.042358746607141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.042358746607141 | validation: 5.774793584583232]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.725425136250965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.725425136250965 | validation: 5.677695438159949]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.578353795610264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.578353795610264 | validation: 5.330622785467865]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.475544547679131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.475544547679131 | validation: 5.181556715862937]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.167273281750003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.167273281750003 | validation: 5.0297405641440704]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0128214780648115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0128214780648115 | validation: 6.0124087389676655]
	TIME [epoch: 5.73 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.410325895887638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.410325895887638 | validation: 5.08614564312377]
	TIME [epoch: 5.73 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.90831097065394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.90831097065394 | validation: 4.5925344804171]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.933720402289893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.933720402289893 | validation: 4.572234064878401]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.703036165548484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.703036165548484 | validation: 4.707063946129534]
	TIME [epoch: 5.77 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.558954046236116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.558954046236116 | validation: 4.208653803830049]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.342709578875924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.342709578875924 | validation: 4.339018195359777]
	TIME [epoch: 5.74 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.523797688669962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.523797688669962 | validation: 4.340614430060892]
	TIME [epoch: 5.72 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.09536175795475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.09536175795475 | validation: 4.4512979464955]
	TIME [epoch: 5.73 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.060089525715988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.060089525715988 | validation: 3.8008215732559307]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.978650171605139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.978650171605139 | validation: 4.9152145572917965]
	TIME [epoch: 5.74 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6119098110137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6119098110137 | validation: 3.9426466948020558]
	TIME [epoch: 5.78 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9863109648655435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9863109648655435 | validation: 4.22161210829613]
	TIME [epoch: 5.73 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.096607970344628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.096607970344628 | validation: 4.285191080958596]
	TIME [epoch: 5.74 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.791931010886989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.791931010886989 | validation: 4.067894633948136]
	TIME [epoch: 5.73 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.815943382828671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.815943382828671 | validation: 3.226013019978717]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6136156178070302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6136156178070302 | validation: 3.370223293205672]
	TIME [epoch: 5.75 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3653051818593256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3653051818593256 | validation: 4.7656049947088945]
	TIME [epoch: 5.74 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.578336466985732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.578336466985732 | validation: 3.377249798249512]
	TIME [epoch: 5.76 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0457151948708456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0457151948708456 | validation: 3.1500571750463555]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1094140523914513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1094140523914513 | validation: 3.4749813042130304]
	TIME [epoch: 5.74 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.11356250088998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.11356250088998 | validation: 2.7182282588211284]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1343981644466536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1343981644466536 | validation: 3.240965190384246]
	TIME [epoch: 5.73 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9396539554114667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9396539554114667 | validation: 2.661516973778254]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80036771414287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.80036771414287 | validation: 2.458271788364828]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4573841865413897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4573841865413897 | validation: 2.981455587468314]
	TIME [epoch: 5.74 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.722526977607063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.722526977607063 | validation: 3.107067142413564]
	TIME [epoch: 5.72 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3749794058894294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3749794058894294 | validation: 2.9465367605703694]
	TIME [epoch: 5.72 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6785763476813673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6785763476813673 | validation: 2.324183714211368]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2970457430118425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2970457430118425 | validation: 2.0928282707488077]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.228034525344812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.228034525344812 | validation: 1.906952598414522]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1687887462084054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1687887462084054 | validation: 2.2327639163492097]
	TIME [epoch: 5.79 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2114084605436064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2114084605436064 | validation: 2.5217266059161925]
	TIME [epoch: 5.74 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4878022009743708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4878022009743708 | validation: 2.1894043300998822]
	TIME [epoch: 5.73 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0826032195635733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0826032195635733 | validation: 2.4682526392045574]
	TIME [epoch: 5.73 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3167134183143308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3167134183143308 | validation: 2.381177004042902]
	TIME [epoch: 5.73 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8398138343556791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8398138343556791 | validation: 2.1170104540545625]
	TIME [epoch: 5.73 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8663241380570714		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.8663241380570714 | validation: 2.2709388136457362]
	TIME [epoch: 5.77 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1723665443744604		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.1723665443744604 | validation: 1.572051807569705]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7447567338830199		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.7447567338830199 | validation: 2.2994869340832795]
	TIME [epoch: 5.73 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.871193684603419		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.871193684603419 | validation: 1.8054288473474218]
	TIME [epoch: 5.72 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.920254064596128		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.920254064596128 | validation: 2.057118587672347]
	TIME [epoch: 5.74 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7286139349168244		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.7286139349168244 | validation: 1.9050344345721106]
	TIME [epoch: 5.73 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8721273641821066		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.8721273641821066 | validation: 1.6149029906304626]
	TIME [epoch: 5.75 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9025705268441293		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.9025705268441293 | validation: 1.6754341914734858]
	TIME [epoch: 5.77 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.204776145409983		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.204776145409983 | validation: 1.7471726016754985]
	TIME [epoch: 5.74 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6990056388881019		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.6990056388881019 | validation: 2.1767883956731344]
	TIME [epoch: 5.74 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.624724326559907		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.624724326559907 | validation: 1.7782967455419734]
	TIME [epoch: 5.73 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.633557701728948		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.633557701728948 | validation: 2.2552487159857924]
	TIME [epoch: 5.74 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7688831967829302		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.7688831967829302 | validation: 1.605673632240443]
	TIME [epoch: 5.73 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5693637956373767		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.5693637956373767 | validation: 1.7541629014317155]
	TIME [epoch: 5.77 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.232952171967815		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.232952171967815 | validation: 2.721150475735916]
	TIME [epoch: 5.74 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9086573599904426		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.9086573599904426 | validation: 1.6488770377919884]
	TIME [epoch: 5.73 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6097585896598936		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.6097585896598936 | validation: 1.6516039186450922]
	TIME [epoch: 5.73 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7971159746259242		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.7971159746259242 | validation: 1.608662810714273]
	TIME [epoch: 5.74 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4582326248130606		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.4582326248130606 | validation: 2.4515328063787]
	TIME [epoch: 5.74 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.827417672934386		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.827417672934386 | validation: 1.4363309246752887]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7275968760543643		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.7275968760543643 | validation: 2.5668470842692432]
	TIME [epoch: 5.77 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7349657018779012		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.7349657018779012 | validation: 2.182613694210335]
	TIME [epoch: 5.74 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.754130086125942		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.754130086125942 | validation: 1.8108572435054142]
	TIME [epoch: 5.73 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.62307415355466		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.62307415355466 | validation: 2.286981422168936]
	TIME [epoch: 5.74 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7321401912888041		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.7321401912888041 | validation: 1.57902254683469]
	TIME [epoch: 5.74 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7572473494574699		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.7572473494574699 | validation: 1.7403845923016616]
	TIME [epoch: 5.74 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5139602475889191		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.5139602475889191 | validation: 1.8458079739530695]
	TIME [epoch: 5.78 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4020710879161165		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.4020710879161165 | validation: 2.299427867703682]
	TIME [epoch: 5.74 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9507914465624978		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.9507914465624978 | validation: 1.834392258389685]
	TIME [epoch: 5.73 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6830237266923969		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.6830237266923969 | validation: 1.373222296274346]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5681367502327928		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.5681367502327928 | validation: 1.5215946004592524]
	TIME [epoch: 5.75 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.56892917791266		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.56892917791266 | validation: 2.361252297308035]
	TIME [epoch: 5.73 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8909206532172562		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.8909206532172562 | validation: 1.6639015479952592]
	TIME [epoch: 5.76 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4789547653426711		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.4789547653426711 | validation: 1.9243701762493701]
	TIME [epoch: 5.75 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7844745110949614		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.7844745110949614 | validation: 1.9118775086016535]
	TIME [epoch: 5.74 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5029153871082468		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.5029153871082468 | validation: 1.6503152231917597]
	TIME [epoch: 5.73 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5720916488427301		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.5720916488427301 | validation: 1.462691330773102]
	TIME [epoch: 5.74 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4229888002923086		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.4229888002923086 | validation: 1.4941127695623926]
	TIME [epoch: 5.73 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4556031916291445		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.4556031916291445 | validation: 1.4373507949380357]
	TIME [epoch: 5.73 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.465330091160866		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.465330091160866 | validation: 2.2023720416961017]
	TIME [epoch: 5.77 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6996727966453182		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.6996727966453182 | validation: 1.4060012844704375]
	TIME [epoch: 5.74 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4448528060054173		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.4448528060054173 | validation: 1.5048971753488234]
	TIME [epoch: 5.74 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4333482826546273		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.4333482826546273 | validation: 2.180030702585079]
	TIME [epoch: 5.73 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5537636658508005		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.5537636658508005 | validation: 1.3896289814709086]
	TIME [epoch: 5.73 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.483828985265548		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.483828985265548 | validation: 1.2474261709461112]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5234799537157186		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.5234799537157186 | validation: 2.4478101972006945]
	TIME [epoch: 5.76 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5129717041005244		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.5129717041005244 | validation: 1.5304895463455506]
	TIME [epoch: 5.75 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5843003205474653		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.5843003205474653 | validation: 1.7962001410255093]
	TIME [epoch: 5.74 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.631572966530294		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.631572966530294 | validation: 1.7272824725796947]
	TIME [epoch: 5.73 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5347717716082072		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.5347717716082072 | validation: 1.6183451783692033]
	TIME [epoch: 5.73 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5970169273482344		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.5970169273482344 | validation: 1.905629424336484]
	TIME [epoch: 5.74 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4204437155726148		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.4204437155726148 | validation: 1.68493487322371]
	TIME [epoch: 5.73 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3538370804770679		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.3538370804770679 | validation: 1.7579880892668336]
	TIME [epoch: 5.77 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5186843753272914		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.5186843753272914 | validation: 1.791615953854963]
	TIME [epoch: 5.74 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.520228528546168		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.520228528546168 | validation: 1.5590666795366963]
	TIME [epoch: 5.74 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0815492589664553		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.0815492589664553 | validation: 3.5930574742408807]
	TIME [epoch: 5.73 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7085553314224167		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.7085553314224167 | validation: 1.3708173141299045]
	TIME [epoch: 5.73 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3330797713311837		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.3330797713311837 | validation: 1.3833664040318947]
	TIME [epoch: 5.73 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5607073270178005		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.5607073270178005 | validation: 1.552371649712265]
	TIME [epoch: 5.76 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4385804014981343		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.4385804014981343 | validation: 1.5612886315190337]
	TIME [epoch: 5.75 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6173441426954427		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.6173441426954427 | validation: 1.453953286875144]
	TIME [epoch: 5.73 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5683589243892935		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.5683589243892935 | validation: 1.9568086314693125]
	TIME [epoch: 5.73 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7094124451834527		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.7094124451834527 | validation: 1.5319446869596596]
	TIME [epoch: 5.74 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6423469616133073		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.6423469616133073 | validation: 1.626653445710285]
	TIME [epoch: 5.74 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5221713575093032		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.5221713575093032 | validation: 1.326094392631241]
	TIME [epoch: 5.73 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5116711808270356		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.5116711808270356 | validation: 2.666044281154455]
	TIME [epoch: 5.77 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6286814339691424		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.6286814339691424 | validation: 1.6795698822655252]
	TIME [epoch: 5.74 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.340838949479096		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.340838949479096 | validation: 1.5409047537373328]
	TIME [epoch: 5.74 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3099742618365058		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.3099742618365058 | validation: 1.4969241239866984]
	TIME [epoch: 5.73 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7581386990852965		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.7581386990852965 | validation: 1.427295721898883]
	TIME [epoch: 5.73 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.332242590671124		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.332242590671124 | validation: 1.7765774127859146]
	TIME [epoch: 5.74 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.378142658218721		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.378142658218721 | validation: 1.3900736182867892]
	TIME [epoch: 5.76 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4033060982617624		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.4033060982617624 | validation: 1.6558248299152407]
	TIME [epoch: 5.75 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.323556131172845		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.323556131172845 | validation: 1.6366354056602357]
	TIME [epoch: 5.74 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5847931956474246		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.5847931956474246 | validation: 2.5804872848309386]
	TIME [epoch: 5.74 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1243478884272124		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.1243478884272124 | validation: 1.793198163900904]
	TIME [epoch: 5.74 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3921696319929915		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.3921696319929915 | validation: 1.7169905004362158]
	TIME [epoch: 5.73 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3268466453809484		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.3268466453809484 | validation: 1.7111275718413204]
	TIME [epoch: 5.74 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4111091354554919		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.4111091354554919 | validation: 1.8043425432217166]
	TIME [epoch: 5.77 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2807178292470207		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.2807178292470207 | validation: 1.5281693217629997]
	TIME [epoch: 5.74 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4405460065325064		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.4405460065325064 | validation: 1.439664816880475]
	TIME [epoch: 5.74 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2888209702888807		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.2888209702888807 | validation: 1.510512678415239]
	TIME [epoch: 5.74 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3312253168158195		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.3312253168158195 | validation: 1.4184390262593456]
	TIME [epoch: 5.73 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5039579789933735		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.5039579789933735 | validation: 1.5083227416886433]
	TIME [epoch: 5.74 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6498301734677816		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.6498301734677816 | validation: 1.3773796172297086]
	TIME [epoch: 5.75 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5116964813346287		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.5116964813346287 | validation: 1.5879160044950535]
	TIME [epoch: 5.77 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4151212160940894		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.4151212160940894 | validation: 1.4380635500226224]
	TIME [epoch: 5.74 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3414241346888522		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.3414241346888522 | validation: 1.6832033320762947]
	TIME [epoch: 5.74 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4878257513902458		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.4878257513902458 | validation: 1.9489544744173268]
	TIME [epoch: 5.73 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5857528795898457		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.5857528795898457 | validation: 1.823612519646253]
	TIME [epoch: 5.73 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4330438786316946		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.4330438786316946 | validation: 1.5200397164418384]
	TIME [epoch: 5.74 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5175519605022214		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.5175519605022214 | validation: 1.388440465588079]
	TIME [epoch: 5.77 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4498555574635907		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.4498555574635907 | validation: 1.2714773152591474]
	TIME [epoch: 5.74 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3012542423859204		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.3012542423859204 | validation: 1.5873258245557669]
	TIME [epoch: 5.74 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3341701733667417		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.3341701733667417 | validation: 1.359775823548717]
	TIME [epoch: 5.74 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2682772301636145		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.2682772301636145 | validation: 1.4359230451626093]
	TIME [epoch: 5.74 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4242944913725761		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.4242944913725761 | validation: 1.4009062731206912]
	TIME [epoch: 5.74 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3731938208714123		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.3731938208714123 | validation: 1.3159198126675147]
	TIME [epoch: 5.76 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3471135520677402		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.3471135520677402 | validation: 1.5007776970508895]
	TIME [epoch: 5.77 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2826032074672424		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.2826032074672424 | validation: 1.6964313855363322]
	TIME [epoch: 5.75 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3998183113790164		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.3998183113790164 | validation: 1.4382154740515185]
	TIME [epoch: 5.74 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.403329487720968		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.403329487720968 | validation: 1.6155354029862015]
	TIME [epoch: 5.74 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3637854545266355		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.3637854545266355 | validation: 1.2993592054199699]
	TIME [epoch: 5.74 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2939990527112597		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.2939990527112597 | validation: 1.4626030038046187]
	TIME [epoch: 5.74 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4161532891664563		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.4161532891664563 | validation: 1.3017558987057094]
	TIME [epoch: 5.77 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3335105302543484		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.3335105302543484 | validation: 1.3446989086414285]
	TIME [epoch: 5.75 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3433529887493112		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.3433529887493112 | validation: 1.6346253385109974]
	TIME [epoch: 5.74 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6417860664176656		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.6417860664176656 | validation: 1.7949306517740602]
	TIME [epoch: 5.74 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3573228021143278		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.3573228021143278 | validation: 1.549421353949516]
	TIME [epoch: 5.74 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4719556577180921		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.4719556577180921 | validation: 1.4278548042887083]
	TIME [epoch: 5.74 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3800666154642107		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.3800666154642107 | validation: 1.47994978376744]
	TIME [epoch: 5.75 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3353296695404184		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.3353296695404184 | validation: 1.5410065614957507]
	TIME [epoch: 5.77 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2744778668645957		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.2744778668645957 | validation: 1.5229281385040088]
	TIME [epoch: 5.74 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2606288307209303		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.2606288307209303 | validation: 1.3862125019006397]
	TIME [epoch: 5.74 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.298519107039477		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.298519107039477 | validation: 1.351838205256051]
	TIME [epoch: 5.74 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2682624456742944		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.2682624456742944 | validation: 1.3520514613868313]
	TIME [epoch: 5.74 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3454411527297332		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.3454411527297332 | validation: 1.2058955372865099]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3304556576804019		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.3304556576804019 | validation: 1.2349325224501695]
	TIME [epoch: 5.78 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2141449218336102		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.2141449218336102 | validation: 1.3124516859711646]
	TIME [epoch: 5.74 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2323704073125232		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.2323704073125232 | validation: 1.8303790387908863]
	TIME [epoch: 5.74 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4969319620627188		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.4969319620627188 | validation: 1.515564472354304]
	TIME [epoch: 5.73 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.192758252806563		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.192758252806563 | validation: 1.2407730411654947]
	TIME [epoch: 5.73 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1793796536487835		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.1793796536487835 | validation: 1.352011304404847]
	TIME [epoch: 5.74 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.203731943277624		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.203731943277624 | validation: 1.524041591293213]
	TIME [epoch: 5.76 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7211878116090995		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.7211878116090995 | validation: 1.3994358170810188]
	TIME [epoch: 5.75 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2569358039870102		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.2569358039870102 | validation: 1.2672814289659633]
	TIME [epoch: 5.74 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3109833485991553		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.3109833485991553 | validation: 1.2355263370751763]
	TIME [epoch: 5.73 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2886316657151147		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.2886316657151147 | validation: 1.5426377737241164]
	TIME [epoch: 5.74 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.291763442460483		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.291763442460483 | validation: 1.4359513256317107]
	TIME [epoch: 5.74 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3464720888266797		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.3464720888266797 | validation: 1.7164039588850202]
	TIME [epoch: 5.73 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.520025516069285		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.520025516069285 | validation: 1.355059516450133]
	TIME [epoch: 5.77 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4044178827866345		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.4044178827866345 | validation: 1.2095018868392462]
	TIME [epoch: 5.74 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3379552175009781		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.3379552175009781 | validation: 1.2273734802492886]
	TIME [epoch: 5.74 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1372431021620626		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.1372431021620626 | validation: 1.5190020644834386]
	TIME [epoch: 5.73 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.273540904271627		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.273540904271627 | validation: 1.2121805982237033]
	TIME [epoch: 5.73 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2121743397550782		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.2121743397550782 | validation: 1.343723872768374]
	TIME [epoch: 5.74 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2373278751358923		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.2373278751358923 | validation: 1.33580726477306]
	TIME [epoch: 5.75 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2887970881608448		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.2887970881608448 | validation: 1.1343078647171634]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3040859461867031		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.3040859461867031 | validation: 1.3214982035236569]
	TIME [epoch: 5.75 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.296221923311174		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.296221923311174 | validation: 1.3526048326938047]
	TIME [epoch: 5.74 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3608552978096395		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.3608552978096395 | validation: 1.336908020481928]
	TIME [epoch: 5.74 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257248585258232		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.257248585258232 | validation: 1.3029460202023304]
	TIME [epoch: 5.74 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2547959298430527		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.2547959298430527 | validation: 1.642258840907465]
	TIME [epoch: 5.74 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3117329296020634		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.3117329296020634 | validation: 1.1316747508068772]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.192945771751359		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.192945771751359 | validation: 1.9094303021268328]
	TIME [epoch: 5.74 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3592293288783506		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.3592293288783506 | validation: 1.4924350230887757]
	TIME [epoch: 5.74 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4746737866575177		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.4746737866575177 | validation: 1.7634909932343106]
	TIME [epoch: 5.74 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4036356336175937		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.4036356336175937 | validation: 1.706740968945297]
	TIME [epoch: 5.74 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3679247279326603		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.3679247279326603 | validation: 1.2913786806366778]
	TIME [epoch: 5.74 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1945742854670818		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.1945742854670818 | validation: 1.4531605750997256]
	TIME [epoch: 5.76 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.219948451982462		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.219948451982462 | validation: 1.1163596819036183]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.201306896317127		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.201306896317127 | validation: 1.0987395238508149]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.30229964854187		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.30229964854187 | validation: 1.1726650683735327]
	TIME [epoch: 5.74 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2360819620107182		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.2360819620107182 | validation: 1.155363232156035]
	TIME [epoch: 5.74 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141024879984373		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.141024879984373 | validation: 1.6548392859247878]
	TIME [epoch: 5.74 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3280801564125515		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.3280801564125515 | validation: 1.0512456828417038]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4773586069958946		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.4773586069958946 | validation: 1.3843648060252496]
	TIME [epoch: 5.76 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2528833739278793		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.2528833739278793 | validation: 1.2516221964609382]
	TIME [epoch: 5.74 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2519937485657815		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.2519937485657815 | validation: 1.049912141692937]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1652693999590555		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.1652693999590555 | validation: 1.3442203801960744]
	TIME [epoch: 5.74 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.179387123012976		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.179387123012976 | validation: 1.247527998076816]
	TIME [epoch: 5.74 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3298607837448044		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.3298607837448044 | validation: 1.2744688280697858]
	TIME [epoch: 5.73 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1300944295632966		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.1300944295632966 | validation: 1.052843521475834]
	TIME [epoch: 5.77 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1122437841875334		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.1122437841875334 | validation: 1.6609706431232132]
	TIME [epoch: 5.74 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.206005202404611		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.206005202404611 | validation: 1.0670266687594445]
	TIME [epoch: 5.73 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0756233161473476		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.0756233161473476 | validation: 1.583023941856562]
	TIME [epoch: 5.73 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2395232398298943		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.2395232398298943 | validation: 1.2272359943367463]
	TIME [epoch: 5.73 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1798406506196464		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.1798406506196464 | validation: 1.4972905755609243]
	TIME [epoch: 5.73 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2723255847691055		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.2723255847691055 | validation: 1.1793764806369158]
	TIME [epoch: 5.76 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1109619440873184		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.1109619440873184 | validation: 1.2483345888819077]
	TIME [epoch: 5.75 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1442245293598174		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.1442245293598174 | validation: 1.3533265019138543]
	TIME [epoch: 5.73 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1264086297719573		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.1264086297719573 | validation: 0.98590832053223]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1585351513467572		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.1585351513467572 | validation: 1.082525067391321]
	TIME [epoch: 5.73 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1773485227801501		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.1773485227801501 | validation: 1.0434902802195134]
	TIME [epoch: 5.73 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.164362451589839		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.164362451589839 | validation: 1.0352841299579603]
	TIME [epoch: 5.73 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.152714572492267		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.152714572492267 | validation: 0.8702716086085209]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.175878562958699		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.175878562958699 | validation: 1.2722611145574996]
	TIME [epoch: 5.74 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.186103958243849		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.186103958243849 | validation: 1.0817664947569379]
	TIME [epoch: 5.73 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1237746678450304		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.1237746678450304 | validation: 1.0270079766095257]
	TIME [epoch: 5.74 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.14292980404685		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.14292980404685 | validation: 1.0629299554419631]
	TIME [epoch: 5.73 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1703895387788725		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.1703895387788725 | validation: 1.2980223934012083]
	TIME [epoch: 5.73 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1955996701421747		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.1955996701421747 | validation: 1.098532728573885]
	TIME [epoch: 5.76 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1133226106782967		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.1133226106782967 | validation: 1.1247276391110088]
	TIME [epoch: 5.75 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1412916804952373		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.1412916804952373 | validation: 1.581577064295387]
	TIME [epoch: 5.74 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1873294299754362		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.1873294299754362 | validation: 1.158293279164852]
	TIME [epoch: 5.74 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0693136656635631		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.0693136656635631 | validation: 1.0873391911982222]
	TIME [epoch: 5.73 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1805162748607412		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.1805162748607412 | validation: 1.40193008909026]
	TIME [epoch: 5.74 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1429026665916309		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.1429026665916309 | validation: 1.1726381700688941]
	TIME [epoch: 5.74 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0420081327826904		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.0420081327826904 | validation: 1.433536896219464]
	TIME [epoch: 5.77 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.176773729467893		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.176773729467893 | validation: 1.1180789481179423]
	TIME [epoch: 5.74 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1091210629158859		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.1091210629158859 | validation: 1.2364542556334368]
	TIME [epoch: 5.73 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3085503053741678		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.3085503053741678 | validation: 1.0441376420373076]
	TIME [epoch: 5.74 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2087790747700526		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.2087790747700526 | validation: 1.282825521245483]
	TIME [epoch: 5.73 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1618895768614408		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.1618895768614408 | validation: 1.0317289154149185]
	TIME [epoch: 5.73 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0376765438746263		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.0376765438746263 | validation: 1.0761882085247294]
	TIME [epoch: 5.76 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1053087713855403		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.1053087713855403 | validation: 0.9473326953928713]
	TIME [epoch: 5.75 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.037110847379778		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.037110847379778 | validation: 0.9741063908395023]
	TIME [epoch: 5.74 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0459810377213092		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.0459810377213092 | validation: 1.1051344599253745]
	TIME [epoch: 5.74 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.204193207346403		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.204193207346403 | validation: 1.0366325192042205]
	TIME [epoch: 5.73 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1235429210076902		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.1235429210076902 | validation: 1.0281323989791589]
	TIME [epoch: 5.74 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1094131086318035		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.1094131086318035 | validation: 1.1358369412785312]
	TIME [epoch: 5.74 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1306296805805474		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.1306296805805474 | validation: 1.072923900889946]
	TIME [epoch: 5.78 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021121005742568		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.021121005742568 | validation: 1.0419706250114964]
	TIME [epoch: 5.74 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0469173375038623		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.0469173375038623 | validation: 1.3110456411666842]
	TIME [epoch: 5.73 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1208614733626716		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.1208614733626716 | validation: 1.0732496748863383]
	TIME [epoch: 5.74 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0666157554725388		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.0666157554725388 | validation: 1.1703811025585398]
	TIME [epoch: 5.74 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0524561559237418		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.0524561559237418 | validation: 0.9630828512125663]
	TIME [epoch: 5.74 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0452135352183902		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.0452135352183902 | validation: 0.9369421387619034]
	TIME [epoch: 5.76 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0320032037894609		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.0320032037894609 | validation: 1.1429952264792202]
	TIME [epoch: 5.75 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0433039071219805		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.0433039071219805 | validation: 1.3104369188150964]
	TIME [epoch: 5.74 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2143191791700658		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.2143191791700658 | validation: 1.1720035705248553]
	TIME [epoch: 5.74 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0615194315521659		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.0615194315521659 | validation: 0.9536566456517985]
	TIME [epoch: 5.74 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1016368878908984		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.1016368878908984 | validation: 1.2885788879194064]
	TIME [epoch: 5.74 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1462359980927366		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.1462359980927366 | validation: 1.1382062286760815]
	TIME [epoch: 5.74 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.080405394567768		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.080405394567768 | validation: 1.082951101684137]
	TIME [epoch: 5.77 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9364478231474508		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.9364478231474508 | validation: 1.0519111283151557]
	TIME [epoch: 5.74 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1294155092832667		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.1294155092832667 | validation: 1.0817812365126416]
	TIME [epoch: 5.74 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9688434974599812		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.9688434974599812 | validation: 0.9308237362864616]
	TIME [epoch: 5.74 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9534784496882501		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.9534784496882501 | validation: 1.2268811717188337]
	TIME [epoch: 5.74 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0529504874627824		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.0529504874627824 | validation: 1.1660058633270294]
	TIME [epoch: 5.73 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.097453894242621		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.097453894242621 | validation: 1.421999302930343]
	TIME [epoch: 5.76 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.096328512958751		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.096328512958751 | validation: 1.0673414210881615]
	TIME [epoch: 5.75 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.000375071468838		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.000375071468838 | validation: 1.1464986852087131]
	TIME [epoch: 5.74 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9417332378620857		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.9417332378620857 | validation: 1.101098837452589]
	TIME [epoch: 5.74 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1572852906580005		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.1572852906580005 | validation: 1.1542355161204862]
	TIME [epoch: 5.73 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0271768640225842		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.0271768640225842 | validation: 1.1924049852013534]
	TIME [epoch: 5.74 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.890606449350427		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.890606449350427 | validation: 1.3178344703841833]
	TIME [epoch: 5.74 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9631453698102642		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.9631453698102642 | validation: 1.2990493003248726]
	TIME [epoch: 5.78 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9970525912490671		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.9970525912490671 | validation: 0.8712103996910454]
	TIME [epoch: 5.74 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9137208759427576		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.9137208759427576 | validation: 1.023161497148743]
	TIME [epoch: 5.74 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8995426049027093		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.8995426049027093 | validation: 0.9529171877053983]
	TIME [epoch: 5.74 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8275684280300405		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.8275684280300405 | validation: 1.2062275092846921]
	TIME [epoch: 5.74 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9362425805616071		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.9362425805616071 | validation: 1.0351186330391249]
	TIME [epoch: 5.74 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8938160068600732		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.8938160068600732 | validation: 1.1623547985639122]
	TIME [epoch: 5.76 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8315090720048198		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.8315090720048198 | validation: 0.9943652947194873]
	TIME [epoch: 5.75 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8692635849969169		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.8692635849969169 | validation: 1.002222651666809]
	TIME [epoch: 5.74 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8753331637655138		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.8753331637655138 | validation: 1.4199586234669073]
	TIME [epoch: 5.74 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9641038767601845		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.9641038767601845 | validation: 1.1600533035505556]
	TIME [epoch: 5.74 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02222816354057		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.02222816354057 | validation: 0.9823399901953883]
	TIME [epoch: 5.74 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.865935412673445		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.865935412673445 | validation: 1.1267496982608705]
	TIME [epoch: 5.74 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8616420539015219		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.8616420539015219 | validation: 1.4598073505115365]
	TIME [epoch: 5.78 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9109918327717599		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.9109918327717599 | validation: 0.8941722585287347]
	TIME [epoch: 5.74 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8544195471461213		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.8544195471461213 | validation: 1.2262915779390273]
	TIME [epoch: 5.74 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.892617991742587		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.892617991742587 | validation: 1.0049977739756408]
	TIME [epoch: 5.74 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8646352651486854		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.8646352651486854 | validation: 1.2061963086598655]
	TIME [epoch: 5.74 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7985528583718281		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.7985528583718281 | validation: 0.9134360897569579]
	TIME [epoch: 5.74 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7470540209120053		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.7470540209120053 | validation: 1.5379385619795647]
	TIME [epoch: 5.77 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9586162216700269		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.9586162216700269 | validation: 1.0075608448133477]
	TIME [epoch: 5.75 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.711999949886967		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.711999949886967 | validation: 1.0276526329507873]
	TIME [epoch: 5.74 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.818159996615473		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.818159996615473 | validation: 0.9955010127006514]
	TIME [epoch: 5.74 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7832741169880908		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.7832741169880908 | validation: 1.0236503445624208]
	TIME [epoch: 5.74 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9351016089496521		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.9351016089496521 | validation: 0.8286921890170453]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7884781873517142		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.7884781873517142 | validation: 0.8493241447961747]
	TIME [epoch: 5.74 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7630241401108864		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.7630241401108864 | validation: 0.8105177555876932]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7287523659336975		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.7287523659336975 | validation: 0.9154738071625482]
	TIME [epoch: 5.74 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7288765737014786		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.7288765737014786 | validation: 1.0592842286702446]
	TIME [epoch: 5.73 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963388171117934		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.6963388171117934 | validation: 0.7997581989394504]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6773989310019164		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.6773989310019164 | validation: 0.9867532444810205]
	TIME [epoch: 5.74 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7710033119952142		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.7710033119952142 | validation: 0.7289945056001096]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_309.pth
	Model improved!!!
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6236016871885466		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.6236016871885466 | validation: 0.851367341896818]
	TIME [epoch: 5.78 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6593798640385593		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.6593798640385593 | validation: 0.7360029823198866]
	TIME [epoch: 5.74 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7626362415400163		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.7626362415400163 | validation: 1.0398922774848471]
	TIME [epoch: 5.74 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7861986694806409		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.7861986694806409 | validation: 0.8739718099095546]
	TIME [epoch: 5.74 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7079846580851998		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.7079846580851998 | validation: 0.8081987620050894]
	TIME [epoch: 5.74 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6251573396408049		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.6251573396408049 | validation: 0.666324603159772]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6076938645653104		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.6076938645653104 | validation: 0.7290056823446932]
	TIME [epoch: 5.76 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6475856260871131		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.6475856260871131 | validation: 0.7782678556128286]
	TIME [epoch: 5.75 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7041481585645997		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.7041481585645997 | validation: 0.7404970227805356]
	TIME [epoch: 5.74 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7244363584411997		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.7244363584411997 | validation: 0.7640719240994599]
	TIME [epoch: 5.74 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864431057936531		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.6864431057936531 | validation: 0.874772672663532]
	TIME [epoch: 5.74 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6739202499075266		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6739202499075266 | validation: 0.8957001692213351]
	TIME [epoch: 5.74 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6509016874831028		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.6509016874831028 | validation: 0.9723019613166852]
	TIME [epoch: 5.74 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7138415382814852		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7138415382814852 | validation: 0.9530812654117231]
	TIME [epoch: 5.78 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7792713718881807		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.7792713718881807 | validation: 0.7416937048170678]
	TIME [epoch: 5.74 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.582741974462606		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.582741974462606 | validation: 0.9215709779790053]
	TIME [epoch: 5.74 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355630120883945		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.7355630120883945 | validation: 0.8738189695647631]
	TIME [epoch: 5.74 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6411353788714742		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.6411353788714742 | validation: 1.2669738939009456]
	TIME [epoch: 5.73 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6772305741626765		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.6772305741626765 | validation: 1.0290532451935193]
	TIME [epoch: 5.74 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6631058047335334		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6631058047335334 | validation: 0.8954805205627033]
	TIME [epoch: 5.76 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.641343747767038		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.641343747767038 | validation: 0.9552259876923844]
	TIME [epoch: 5.75 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.765771248281677		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.765771248281677 | validation: 1.6097972163427547]
	TIME [epoch: 5.74 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8854492195490901		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.8854492195490901 | validation: 0.9729671046662586]
	TIME [epoch: 5.74 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5960047054253363		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.5960047054253363 | validation: 0.9568943391476796]
	TIME [epoch: 5.74 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5257746257194782		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.5257746257194782 | validation: 0.7110721725107121]
	TIME [epoch: 5.74 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5265097881874805		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.5265097881874805 | validation: 1.058516702645755]
	TIME [epoch: 5.74 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6347356678662309		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.6347356678662309 | validation: 0.9071407293232145]
	TIME [epoch: 5.78 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6216178418755116		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.6216178418755116 | validation: 0.7746599305320779]
	TIME [epoch: 5.74 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5236683040095077		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.5236683040095077 | validation: 0.753108388908891]
	TIME [epoch: 5.74 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828133673168436		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.6828133673168436 | validation: 0.7845791007280367]
	TIME [epoch: 5.74 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5045110168216249		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.5045110168216249 | validation: 0.8736658385470202]
	TIME [epoch: 5.74 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5328238481228598		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.5328238481228598 | validation: 0.9347998672044381]
	TIME [epoch: 5.74 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6548244383838508		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.6548244383838508 | validation: 0.8628991686483708]
	TIME [epoch: 5.76 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5831570793870013		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.5831570793870013 | validation: 0.816782345489743]
	TIME [epoch: 5.75 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5876610312795467		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5876610312795467 | validation: 0.8831828805119635]
	TIME [epoch: 5.74 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5674696032774487		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.5674696032774487 | validation: 0.7183819767865314]
	TIME [epoch: 5.74 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5383192179417283		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.5383192179417283 | validation: 0.9305053567806766]
	TIME [epoch: 5.74 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.812022990550775		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.812022990550775 | validation: 0.7900545550282074]
	TIME [epoch: 5.73 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677594773551022		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.5677594773551022 | validation: 0.8194395976334695]
	TIME [epoch: 5.74 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4934913113402462		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.4934913113402462 | validation: 0.8891840427129617]
	TIME [epoch: 5.78 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5941282530297629		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5941282530297629 | validation: 0.6506229565292592]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5731904756466755		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.5731904756466755 | validation: 0.9822828655978991]
	TIME [epoch: 5.74 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451169096622881		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.5451169096622881 | validation: 1.0755832452545158]
	TIME [epoch: 5.74 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5834926795879685		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.5834926795879685 | validation: 0.9872955245462897]
	TIME [epoch: 5.74 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6451007798446241		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.6451007798446241 | validation: 0.8153278645147266]
	TIME [epoch: 5.74 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077608368024837		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5077608368024837 | validation: 0.8648697709012185]
	TIME [epoch: 5.76 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5847861803443816		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.5847861803443816 | validation: 0.91662740264289]
	TIME [epoch: 5.75 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5569353452944845		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.5569353452944845 | validation: 0.7658791979710766]
	TIME [epoch: 5.74 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228475544480399		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.6228475544480399 | validation: 1.3415464906278245]
	TIME [epoch: 5.73 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7594585405122382		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.7594585405122382 | validation: 0.7718942318433074]
	TIME [epoch: 5.74 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083216006813293		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.5083216006813293 | validation: 1.0595356194112173]
	TIME [epoch: 5.74 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5546897419415582		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.5546897419415582 | validation: 0.6782750146790433]
	TIME [epoch: 5.74 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4719434144526428		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.4719434144526428 | validation: 0.6737923025301962]
	TIME [epoch: 5.77 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4967107095126164		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.4967107095126164 | validation: 0.8877409246569714]
	TIME [epoch: 5.74 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46778154241809317		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.46778154241809317 | validation: 0.8400921463522771]
	TIME [epoch: 5.74 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4446704231647425		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.4446704231647425 | validation: 0.8207677299361962]
	TIME [epoch: 5.74 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6268735335125629		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.6268735335125629 | validation: 0.8643436868174468]
	TIME [epoch: 5.73 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6194547830475297		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.6194547830475297 | validation: 0.5835285224742252]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037929525877628		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5037929525877628 | validation: 0.6897215429555145]
	TIME [epoch: 5.77 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4925933679137755		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.4925933679137755 | validation: 0.6608325484656722]
	TIME [epoch: 5.74 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5000168195191865		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.5000168195191865 | validation: 0.872080458464457]
	TIME [epoch: 5.74 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43334499183265945		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.43334499183265945 | validation: 1.0319151337484782]
	TIME [epoch: 5.73 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.623711633490261		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.623711633490261 | validation: 0.5887808358030638]
	TIME [epoch: 5.73 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44941318666334473		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.44941318666334473 | validation: 0.6242420923976776]
	TIME [epoch: 5.73 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4963603763612425		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.4963603763612425 | validation: 0.7510279553723445]
	TIME [epoch: 5.75 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.538313301731175		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.538313301731175 | validation: 0.8644878184391253]
	TIME [epoch: 5.76 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43385135745731357		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.43385135745731357 | validation: 1.0588794132617176]
	TIME [epoch: 5.74 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4407437697928641		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.4407437697928641 | validation: 0.874900686632742]
	TIME [epoch: 5.74 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.556836275130223		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.556836275130223 | validation: 0.6250597741814998]
	TIME [epoch: 5.73 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42310644547123155		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.42310644547123155 | validation: 0.6621559624048101]
	TIME [epoch: 5.73 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.558306678520304		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.558306678520304 | validation: 0.5549405713739053]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45348629550232733		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.45348629550232733 | validation: 0.7699479109060574]
	TIME [epoch: 5.77 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4017375784362309		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.4017375784362309 | validation: 0.8503239417784657]
	TIME [epoch: 5.74 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5319220166869845		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.5319220166869845 | validation: 0.9910623288841521]
	TIME [epoch: 5.73 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4904055862080018		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.4904055862080018 | validation: 0.7514403070340393]
	TIME [epoch: 5.73 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727972672701411		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.4727972672701411 | validation: 0.7685780162218311]
	TIME [epoch: 5.73 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4970350929789548		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.4970350929789548 | validation: 0.7453460080174799]
	TIME [epoch: 5.73 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47344496843633066		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.47344496843633066 | validation: 0.8132119126472727]
	TIME [epoch: 5.75 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4901260606359248		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.4901260606359248 | validation: 0.7804856140171782]
	TIME [epoch: 5.76 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3924394879803489		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.3924394879803489 | validation: 0.775729368883913]
	TIME [epoch: 5.74 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3924630196506496		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.3924630196506496 | validation: 0.8116337979870397]
	TIME [epoch: 5.74 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5375869243470047		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.5375869243470047 | validation: 0.7373201582649074]
	TIME [epoch: 5.73 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45065181049709907		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.45065181049709907 | validation: 0.6460247462231579]
	TIME [epoch: 5.73 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4294733340392404		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.4294733340392404 | validation: 0.567062605411938]
	TIME [epoch: 5.74 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6796334661262541		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.6796334661262541 | validation: 0.6484164309424147]
	TIME [epoch: 5.77 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3815617101074616		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.3815617101074616 | validation: 0.5806505369717567]
	TIME [epoch: 5.74 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713845852165085		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.3713845852165085 | validation: 0.7715095403128577]
	TIME [epoch: 5.73 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38252867692302084		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.38252867692302084 | validation: 0.616703981818083]
	TIME [epoch: 5.73 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48841245795872973		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.48841245795872973 | validation: 0.7545357813878532]
	TIME [epoch: 5.74 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39650906044939316		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.39650906044939316 | validation: 0.659691011790849]
	TIME [epoch: 5.73 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6337222973388581		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.6337222973388581 | validation: 0.8095277085559818]
	TIME [epoch: 5.75 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42160914624889545		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.42160914624889545 | validation: 0.9554628723779685]
	TIME [epoch: 5.76 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.493221918595004		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.493221918595004 | validation: 0.6824282990887526]
	TIME [epoch: 5.74 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5768575510606601		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.5768575510606601 | validation: 0.7135100074125847]
	TIME [epoch: 5.73 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4349918071625272		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.4349918071625272 | validation: 0.9558120327233242]
	TIME [epoch: 5.73 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4321996385062065		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.4321996385062065 | validation: 0.7235232164238381]
	TIME [epoch: 5.73 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41188568080606025		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.41188568080606025 | validation: 0.6423706616051605]
	TIME [epoch: 5.74 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40202717218867057		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.40202717218867057 | validation: 0.633252354503577]
	TIME [epoch: 5.77 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40936958576529126		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.40936958576529126 | validation: 0.5797681597177631]
	TIME [epoch: 5.74 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4407784270956752		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.4407784270956752 | validation: 0.5377390590834247]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4724314223648368		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.4724314223648368 | validation: 0.6786986628832783]
	TIME [epoch: 5.74 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35270820947722914		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.35270820947722914 | validation: 0.6557140961743005]
	TIME [epoch: 5.74 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5260504002060268		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.5260504002060268 | validation: 0.4999277029322626]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38723751405539997		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.38723751405539997 | validation: 0.5159763803249402]
	TIME [epoch: 5.76 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3618660373548216		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.3618660373548216 | validation: 0.8566232806744515]
	TIME [epoch: 5.75 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4301442318994749		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.4301442318994749 | validation: 0.7949189399867789]
	TIME [epoch: 5.74 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5002491575631857		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.5002491575631857 | validation: 0.6037265843004961]
	TIME [epoch: 5.73 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49774072803303676		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.49774072803303676 | validation: 0.6100767398644168]
	TIME [epoch: 5.73 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.383108869532746		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.383108869532746 | validation: 0.5033499151524218]
	TIME [epoch: 5.73 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3816941044909436		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.3816941044909436 | validation: 0.4982583621952374]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34821646462130856		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.34821646462130856 | validation: 0.5985824829250587]
	TIME [epoch: 5.77 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40234480924558913		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.40234480924558913 | validation: 0.5604143281014116]
	TIME [epoch: 5.74 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40065615201593346		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.40065615201593346 | validation: 0.5272271539544756]
	TIME [epoch: 5.73 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43864335411333377		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.43864335411333377 | validation: 0.8250878294760454]
	TIME [epoch: 5.73 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41136251127189555		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.41136251127189555 | validation: 0.49124727577452293]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3055642827571698		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.3055642827571698 | validation: 0.6163748218665872]
	TIME [epoch: 5.74 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136433179697838		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.5136433179697838 | validation: 0.5131127826462847]
	TIME [epoch: 5.77 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805870832852582		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.3805870832852582 | validation: 0.46740075729830566]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_427.pth
	Model improved!!!
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3621501751558869		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.3621501751558869 | validation: 0.7365555896632678]
	TIME [epoch: 5.74 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36523748107572473		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.36523748107572473 | validation: 0.6287858777462211]
	TIME [epoch: 5.99 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3811974587580621		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.3811974587580621 | validation: 0.834323485680919]
	TIME [epoch: 5.73 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44736166777711134		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.44736166777711134 | validation: 0.6309030676379073]
	TIME [epoch: 5.74 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35350680882736973		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.35350680882736973 | validation: 0.6732015798284732]
	TIME [epoch: 5.75 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3896688743646356		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.3896688743646356 | validation: 0.6095665262422327]
	TIME [epoch: 5.76 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3676748235396501		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.3676748235396501 | validation: 0.5721447318869519]
	TIME [epoch: 5.74 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32688344682950743		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.32688344682950743 | validation: 0.583126037730706]
	TIME [epoch: 5.73 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3626217269365145		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.3626217269365145 | validation: 0.7250386366533936]
	TIME [epoch: 5.73 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3525674289057512		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.3525674289057512 | validation: 0.561675462521443]
	TIME [epoch: 5.74 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3786828096519048		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.3786828096519048 | validation: 0.46572606918945914]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_438.pth
	Model improved!!!
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3190535935884705		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.3190535935884705 | validation: 0.6794416275679387]
	TIME [epoch: 5.78 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3640605585909731		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.3640605585909731 | validation: 0.45344729929119454]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2749905693736251		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.2749905693736251 | validation: 0.5469557607257793]
	TIME [epoch: 5.74 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36590132948034876		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.36590132948034876 | validation: 0.7030216209366391]
	TIME [epoch: 5.74 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3227967850313842		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.3227967850313842 | validation: 0.6325585714119869]
	TIME [epoch: 5.73 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3875886825208664		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.3875886825208664 | validation: 1.279544852771274]
	TIME [epoch: 5.73 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6206984359895613		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.6206984359895613 | validation: 0.5055515172359912]
	TIME [epoch: 5.76 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389005002107625		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.389005002107625 | validation: 0.733365949200531]
	TIME [epoch: 5.75 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4504565440804437		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.4504565440804437 | validation: 0.4575517121337904]
	TIME [epoch: 5.74 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3914789166705922		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.3914789166705922 | validation: 0.43825890107321785]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_448.pth
	Model improved!!!
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3072922713484351		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.3072922713484351 | validation: 0.5113593772748074]
	TIME [epoch: 5.74 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3814692629175794		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.3814692629175794 | validation: 0.4186431076686505]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40814767841180455		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.40814767841180455 | validation: 0.5233025953807677]
	TIME [epoch: 5.75 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3244736752314166		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3244736752314166 | validation: 0.4264865505637861]
	TIME [epoch: 5.76 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.284835795641252		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.284835795641252 | validation: 0.47014291029512595]
	TIME [epoch: 5.73 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2688866189261191		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.2688866189261191 | validation: 0.6768975760509508]
	TIME [epoch: 5.73 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3337051589500368		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.3337051589500368 | validation: 0.38524967959619255]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331256169748784		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.331256169748784 | validation: 0.4784377446958324]
	TIME [epoch: 5.73 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30017601164244595		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.30017601164244595 | validation: 0.44587768928851335]
	TIME [epoch: 5.73 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2589511119454741		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.2589511119454741 | validation: 0.36837158064938996]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3006961457943063		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.3006961457943063 | validation: 0.6099013877460684]
	TIME [epoch: 5.74 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3455304878619743		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.3455304878619743 | validation: 0.47032095814425334]
	TIME [epoch: 5.73 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30411919713151614		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.30411919713151614 | validation: 0.4870256590082384]
	TIME [epoch: 5.73 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2819824463517612		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.2819824463517612 | validation: 0.6160705275124349]
	TIME [epoch: 5.73 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35542152143895883		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.35542152143895883 | validation: 0.43295567423639264]
	TIME [epoch: 5.73 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2629548530797856		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.2629548530797856 | validation: 0.5114434733288273]
	TIME [epoch: 5.74 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.349165637138105		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.349165637138105 | validation: 0.733264858621671]
	TIME [epoch: 5.76 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36320991200064334		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.36320991200064334 | validation: 0.5983110939303786]
	TIME [epoch: 5.73 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2868705298678795		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.2868705298678795 | validation: 0.4285742728593464]
	TIME [epoch: 5.73 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40997059137477154		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.40997059137477154 | validation: 0.5986258413580988]
	TIME [epoch: 5.73 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3259070516075768		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.3259070516075768 | validation: 0.5897212110633481]
	TIME [epoch: 5.73 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35354285816146686		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.35354285816146686 | validation: 0.5851575066873608]
	TIME [epoch: 5.73 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.325956816995804		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.325956816995804 | validation: 0.34726861312030394]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33791169923664754		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.33791169923664754 | validation: 0.4512275545098018]
	TIME [epoch: 5.74 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36009363850135157		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.36009363850135157 | validation: 0.6171474455634555]
	TIME [epoch: 5.73 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31790682188235714		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.31790682188235714 | validation: 0.5054166142454681]
	TIME [epoch: 5.73 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2691837724666266		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.2691837724666266 | validation: 0.4802007340879176]
	TIME [epoch: 5.73 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32123391043306593		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.32123391043306593 | validation: 0.5109152271280964]
	TIME [epoch: 5.73 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2883167105200047		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.2883167105200047 | validation: 0.6468307329252189]
	TIME [epoch: 5.76 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301698111794649		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.3301698111794649 | validation: 0.5458699077978943]
	TIME [epoch: 5.75 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.468797950880517		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.468797950880517 | validation: 0.7142457814277333]
	TIME [epoch: 5.74 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33065309895634815		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.33065309895634815 | validation: 0.47084325353019024]
	TIME [epoch: 5.73 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32040119976352344		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.32040119976352344 | validation: 0.6118261295805709]
	TIME [epoch: 5.73 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326110237476409		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.3326110237476409 | validation: 0.7803373665359072]
	TIME [epoch: 5.73 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4142006864788311		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.4142006864788311 | validation: 0.37632712782321043]
	TIME [epoch: 5.74 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2932871638933173		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.2932871638933173 | validation: 0.4888991344773237]
	TIME [epoch: 5.77 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32328026142489685		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.32328026142489685 | validation: 0.5712037285185952]
	TIME [epoch: 5.74 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34149842044360834		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.34149842044360834 | validation: 0.8410329264869728]
	TIME [epoch: 5.73 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44303159562559224		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.44303159562559224 | validation: 0.6899027521220235]
	TIME [epoch: 5.74 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601103389036625		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.3601103389036625 | validation: 0.41570350786678545]
	TIME [epoch: 5.74 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586660674343126		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.2586660674343126 | validation: 0.44147845997143237]
	TIME [epoch: 5.74 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2391104788725015		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.2391104788725015 | validation: 0.8048255508333199]
	TIME [epoch: 5.76 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3367634962204547		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.3367634962204547 | validation: 0.5040469533953801]
	TIME [epoch: 5.75 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33820436101973167		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.33820436101973167 | validation: 0.5159257762683574]
	TIME [epoch: 5.74 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28120307317628374		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.28120307317628374 | validation: 0.424083170571636]
	TIME [epoch: 5.74 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2709682552543261		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.2709682552543261 | validation: 0.4432320501658768]
	TIME [epoch: 5.73 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29968385230599853		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.29968385230599853 | validation: 0.5024960048061596]
	TIME [epoch: 5.74 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.276377546838541		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.276377546838541 | validation: 0.6697428484730458]
	TIME [epoch: 5.74 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2879922531189728		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.2879922531189728 | validation: 0.5088160728443749]
	TIME [epoch: 5.77 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24228141273148465		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.24228141273148465 | validation: 0.5411784754638268]
	TIME [epoch: 5.74 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2455469958401825		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.2455469958401825 | validation: 0.42190471850979094]
	TIME [epoch: 5.73 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22590157416836767		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.22590157416836767 | validation: 0.4908363508019328]
	TIME [epoch: 5.73 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28993689748238466		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.28993689748238466 | validation: 0.6645706735044965]
	TIME [epoch: 5.74 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2881346646544495		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.2881346646544495 | validation: 0.5249376706997596]
	TIME [epoch: 5.73 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2741925044264137		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.2741925044264137 | validation: 0.4957946531026447]
	TIME [epoch: 5.76 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25622778462322904		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.25622778462322904 | validation: 0.5692542238162206]
	TIME [epoch: 5.75 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2219149649961798		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.2219149649961798 | validation: 0.4945670251054121]
	TIME [epoch: 5.74 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23103998947858548		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.23103998947858548 | validation: 0.5105262835421434]
	TIME [epoch: 5.73 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21871681012397143		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.21871681012397143 | validation: 0.5079327971505904]
	TIME [epoch: 5.73 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23045301006726712		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.23045301006726712 | validation: 0.4594051077426616]
	TIME [epoch: 5.73 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2568513748097625		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.2568513748097625 | validation: 0.49712792786032467]
	TIME [epoch: 5.74 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24164224820144686		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.24164224820144686 | validation: 0.4640266413937721]
	TIME [epoch: 5.77 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23501747518011426		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.23501747518011426 | validation: 0.5501934703961615]
	TIME [epoch: 5.74 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24084820601369908		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.24084820601369908 | validation: 0.48259026579952563]
	TIME [epoch: 5.74 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2555061897156629		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.2555061897156629 | validation: 0.4273778302847035]
	TIME [epoch: 5.73 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2450681070614052		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.2450681070614052 | validation: 0.4397985197870527]
	TIME [epoch: 5.74 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24235277316204862		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.24235277316204862 | validation: 0.41626510988060506]
	TIME [epoch: 5.73 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2489148267704211		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.2489148267704211 | validation: 0.3985801417641166]
	TIME [epoch: 5.76 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28433842279537225		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.28433842279537225 | validation: 0.4505067614543256]
	TIME [epoch: 5.75 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34546054568152185		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.34546054568152185 | validation: 0.6059173601819817]
	TIME [epoch: 5.74 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29324658088696653		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.29324658088696653 | validation: 0.4827272082996465]
	TIME [epoch: 5.74 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27822004561148184		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.27822004561148184 | validation: 0.46190984884772185]
	TIME [epoch: 5.73 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2557664574522952		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.2557664574522952 | validation: 0.7248277867699179]
	TIME [epoch: 5.74 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3217215077628477		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.3217215077628477 | validation: 0.5948127966685408]
	TIME [epoch: 5.74 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3012933369563122		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.3012933369563122 | validation: 0.6618615812719273]
	TIME [epoch: 5.77 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30613961163444303		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.30613961163444303 | validation: 0.6639601452003976]
	TIME [epoch: 5.74 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3121350122464169		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.3121350122464169 | validation: 0.5163266925580045]
	TIME [epoch: 5.74 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24081793972456214		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.24081793972456214 | validation: 0.5451896087987261]
	TIME [epoch: 5.73 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103919315790036		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.3103919315790036 | validation: 0.5144930417186571]
	TIME [epoch: 5.74 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2941206097450634		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.2941206097450634 | validation: 0.614739689944702]
	TIME [epoch: 5.73 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26984806709233217		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.26984806709233217 | validation: 0.38394912454929514]
	TIME [epoch: 5.76 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26301420283405497		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.26301420283405497 | validation: 0.4242935992622689]
	TIME [epoch: 5.75 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316282779816626		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.3316282779816626 | validation: 0.48389554555688763]
	TIME [epoch: 5.74 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2194582224810989		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.2194582224810989 | validation: 0.396229499006534]
	TIME [epoch: 5.74 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2311452058170176		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.2311452058170176 | validation: 0.5079172333996962]
	TIME [epoch: 5.73 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29561173143892394		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.29561173143892394 | validation: 0.4076063685262683]
	TIME [epoch: 5.74 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24779351624584553		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.24779351624584553 | validation: 0.5034803199192796]
	TIME [epoch: 5.74 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.268887212757014		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.268887212757014 | validation: 0.47492112701364236]
	TIME [epoch: 5.77 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19961694948702657		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.19961694948702657 | validation: 0.6096119257691136]
	TIME [epoch: 5.74 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23744082845786368		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.23744082845786368 | validation: 0.46234584105477966]
	TIME [epoch: 5.73 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23799824351187962		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.23799824351187962 | validation: 0.5181987773196705]
	TIME [epoch: 5.73 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26734879399349215		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.26734879399349215 | validation: 0.4628545505258543]
	TIME [epoch: 5.74 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2343501609867648		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.2343501609867648 | validation: 0.38216253797113087]
	TIME [epoch: 5.73 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23043310102690706		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.23043310102690706 | validation: 0.4766206127777561]
	TIME [epoch: 5.76 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2606990475098032		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.2606990475098032 | validation: 0.436805035878675]
	TIME [epoch: 5.75 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20228434294438244		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.20228434294438244 | validation: 0.36250849763152376]
	TIME [epoch: 5.74 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21730631773530334		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.21730631773530334 | validation: 0.4280958864789694]
	TIME [epoch: 5.74 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21255091165188766		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.21255091165188766 | validation: 0.46981229269461994]
	TIME [epoch: 5.73 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20627922805964957		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.20627922805964957 | validation: 0.5820954410280763]
	TIME [epoch: 5.74 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28008896430541436		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.28008896430541436 | validation: 0.3914942211476666]
	TIME [epoch: 5.74 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22863047543344128		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.22863047543344128 | validation: 0.42450100663008417]
	TIME [epoch: 5.77 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22874976159615729		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.22874976159615729 | validation: 0.41946439980183486]
	TIME [epoch: 5.74 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2602728166979708		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.2602728166979708 | validation: 0.5522739006269513]
	TIME [epoch: 5.74 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.266252766686912		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.266252766686912 | validation: 0.42696484470536467]
	TIME [epoch: 5.74 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.273100590877579		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.273100590877579 | validation: 0.44676700808811987]
	TIME [epoch: 5.74 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18064007783692657		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.18064007783692657 | validation: 0.46253351642906526]
	TIME [epoch: 5.73 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20715429263041013		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.20715429263041013 | validation: 0.48778380231588814]
	TIME [epoch: 5.76 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2122568380887664		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.2122568380887664 | validation: 0.39971604871977384]
	TIME [epoch: 5.75 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24103436789300364		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.24103436789300364 | validation: 0.3809641245913993]
	TIME [epoch: 5.74 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20793481274742343		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.20793481274742343 | validation: 0.5341175391803681]
	TIME [epoch: 5.74 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2837175106414388		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.2837175106414388 | validation: 0.3726096926120125]
	TIME [epoch: 5.74 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18272676131801702		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.18272676131801702 | validation: 0.33760959248473044]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18390503856074014		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.18390503856074014 | validation: 0.3658470446380875]
	TIME [epoch: 5.74 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45240584540812284		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.45240584540812284 | validation: 0.47541699851465824]
	TIME [epoch: 5.77 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.200752327539244		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.200752327539244 | validation: 0.37132594052597023]
	TIME [epoch: 5.74 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2352435963753733		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.2352435963753733 | validation: 0.4145828492103141]
	TIME [epoch: 5.73 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1832195251314782		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.1832195251314782 | validation: 0.38691667785474276]
	TIME [epoch: 5.73 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21473469416344362		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.21473469416344362 | validation: 0.47955967533208255]
	TIME [epoch: 5.73 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24352387598361208		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.24352387598361208 | validation: 0.4590358614026071]
	TIME [epoch: 5.73 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21373838268413126		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.21373838268413126 | validation: 0.4410340693038493]
	TIME [epoch: 5.76 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1981215565541154		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.1981215565541154 | validation: 0.5545718786181186]
	TIME [epoch: 5.74 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545330982071552		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.2545330982071552 | validation: 0.44743809144351093]
	TIME [epoch: 5.73 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17335495928614036		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.17335495928614036 | validation: 0.5387126340621675]
	TIME [epoch: 5.73 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22034360686405816		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.22034360686405816 | validation: 0.4256608135463496]
	TIME [epoch: 5.73 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.212011150838653		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.212011150838653 | validation: 0.6218615650194744]
	TIME [epoch: 5.73 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2339787576429486		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.2339787576429486 | validation: 0.5818780367913869]
	TIME [epoch: 5.74 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2618547474601117		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.2618547474601117 | validation: 0.5323906192616464]
	TIME [epoch: 5.77 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26462486603542107		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.26462486603542107 | validation: 0.5072207020844048]
	TIME [epoch: 5.74 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1819016535922786		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.1819016535922786 | validation: 0.41043856220166264]
	TIME [epoch: 5.73 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20251553763714164		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.20251553763714164 | validation: 0.6708573172792115]
	TIME [epoch: 5.73 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25913265096715543		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.25913265096715543 | validation: 0.35626264107646466]
	TIME [epoch: 5.74 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20970089021598504		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.20970089021598504 | validation: 0.5062175064738983]
	TIME [epoch: 5.73 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22613231038697182		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.22613231038697182 | validation: 0.4714512959071593]
	TIME [epoch: 5.76 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2216367867994171		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.2216367867994171 | validation: 0.4380046255085565]
	TIME [epoch: 5.75 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645394611626153		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.2645394611626153 | validation: 0.5196698006426873]
	TIME [epoch: 5.74 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23757935234250158		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.23757935234250158 | validation: 0.3951378325903746]
	TIME [epoch: 5.73 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19698901197323412		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.19698901197323412 | validation: 0.4706183407100237]
	TIME [epoch: 5.73 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1960121248335965		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.1960121248335965 | validation: 0.44036527424555416]
	TIME [epoch: 5.73 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1933286477599187		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.1933286477599187 | validation: 0.4497071363273104]
	TIME [epoch: 5.73 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28762632231557		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.28762632231557 | validation: 0.458026110067015]
	TIME [epoch: 5.77 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23530026776984717		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.23530026776984717 | validation: 0.3648340173605742]
	TIME [epoch: 5.74 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23301699322905453		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.23301699322905453 | validation: 0.37010329421576826]
	TIME [epoch: 5.73 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674068978184315		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.2674068978184315 | validation: 0.3948430758403955]
	TIME [epoch: 5.73 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590336520071095		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.2590336520071095 | validation: 0.42347077480283896]
	TIME [epoch: 5.74 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2095133158063372		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.2095133158063372 | validation: 0.3447537530042388]
	TIME [epoch: 5.73 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23110960419124135		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.23110960419124135 | validation: 0.34831199466260004]
	TIME [epoch: 5.76 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3027825808474829		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.3027825808474829 | validation: 0.3282609159435031]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_595.pth
	Model improved!!!
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20680653617131514		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.20680653617131514 | validation: 0.3408105680180855]
	TIME [epoch: 5.74 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20205992621078828		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.20205992621078828 | validation: 0.5151789330039739]
	TIME [epoch: 5.74 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24165778359642454		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.24165778359642454 | validation: 0.4622569031850975]
	TIME [epoch: 5.73 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25773847470335337		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.25773847470335337 | validation: 0.3923679110521489]
	TIME [epoch: 5.74 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21048211364416383		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.21048211364416383 | validation: 0.576496285003442]
	TIME [epoch: 5.73 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27877733927545323		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.27877733927545323 | validation: 0.3269609270649734]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_601.pth
	Model improved!!!
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23246922445376014		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.23246922445376014 | validation: 0.4495160623054554]
	TIME [epoch: 5.74 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19290103386310814		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.19290103386310814 | validation: 0.3749396201332353]
	TIME [epoch: 5.73 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19759389471808178		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.19759389471808178 | validation: 0.3521707483880748]
	TIME [epoch: 5.73 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.177917275214231		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.177917275214231 | validation: 0.37590089850673397]
	TIME [epoch: 5.73 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2139050476248666		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.2139050476248666 | validation: 0.4830410780509841]
	TIME [epoch: 5.73 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2506240767324539		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.2506240767324539 | validation: 0.5692538409058691]
	TIME [epoch: 5.77 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2827086547160654		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.2827086547160654 | validation: 0.36484224870025]
	TIME [epoch: 5.74 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2124918637278368		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.2124918637278368 | validation: 0.3560452347646864]
	TIME [epoch: 5.73 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20725332917756173		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.20725332917756173 | validation: 0.34937900613694445]
	TIME [epoch: 5.73 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19637644317041672		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.19637644317041672 | validation: 0.3914106867741501]
	TIME [epoch: 5.73 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18637061598432128		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.18637061598432128 | validation: 0.31628304974115734]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_612.pth
	Model improved!!!
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16242788472721836		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.16242788472721836 | validation: 0.3889687880041445]
	TIME [epoch: 5.76 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23550886910259405		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.23550886910259405 | validation: 0.4521836585119809]
	TIME [epoch: 5.77 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17655341727072282		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.17655341727072282 | validation: 0.4026934058697303]
	TIME [epoch: 5.74 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19994934990568075		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.19994934990568075 | validation: 0.3195275965131554]
	TIME [epoch: 5.74 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16821635992690015		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.16821635992690015 | validation: 0.49558448599552085]
	TIME [epoch: 5.74 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2191275507769938		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.2191275507769938 | validation: 0.36633240107110354]
	TIME [epoch: 5.74 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17829094402171825		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.17829094402171825 | validation: 0.3461273036731901]
	TIME [epoch: 5.74 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21821002805697237		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.21821002805697237 | validation: 0.4555886192771334]
	TIME [epoch: 5.78 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18769357904924858		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.18769357904924858 | validation: 0.34003296814214895]
	TIME [epoch: 5.74 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2066056692258107		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.2066056692258107 | validation: 0.37484794818327843]
	TIME [epoch: 5.74 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23126039608055932		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.23126039608055932 | validation: 0.4466327562733774]
	TIME [epoch: 5.74 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20003137793433362		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.20003137793433362 | validation: 0.35224462972979903]
	TIME [epoch: 5.74 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23759937838148923		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.23759937838148923 | validation: 0.5738528902462445]
	TIME [epoch: 5.74 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3138250969596311		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.3138250969596311 | validation: 0.3948532187084135]
	TIME [epoch: 5.75 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21882397002195395		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.21882397002195395 | validation: 0.3433695484941828]
	TIME [epoch: 5.77 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20681306721327472		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.20681306721327472 | validation: 0.39390988049575515]
	TIME [epoch: 5.74 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19506698973463446		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.19506698973463446 | validation: 0.32103347591423137]
	TIME [epoch: 5.74 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18218738563175696		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.18218738563175696 | validation: 0.4205520349112817]
	TIME [epoch: 5.74 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21160081040906456		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.21160081040906456 | validation: 0.38231225982611294]
	TIME [epoch: 5.74 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1846439793572734		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.1846439793572734 | validation: 0.45375926766299857]
	TIME [epoch: 5.74 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16666778066430737		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.16666778066430737 | validation: 0.4514777254340713]
	TIME [epoch: 5.78 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22360726250317609		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.22360726250317609 | validation: 0.39758776518942845]
	TIME [epoch: 5.74 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20869684666879462		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.20869684666879462 | validation: 0.4974304921113466]
	TIME [epoch: 5.74 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21665966608039222		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.21665966608039222 | validation: 0.3049526171395301]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_636.pth
	Model improved!!!
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15575778898899217		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.15575778898899217 | validation: 0.42972541514776724]
	TIME [epoch: 5.74 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16483561380070139		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.16483561380070139 | validation: 0.5550252600044684]
	TIME [epoch: 5.74 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20385830760809742		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.20385830760809742 | validation: 0.5716122691536697]
	TIME [epoch: 5.76 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22414553045748442		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.22414553045748442 | validation: 0.39662678032811416]
	TIME [epoch: 5.75 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18115661345822986		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.18115661345822986 | validation: 0.401993392621376]
	TIME [epoch: 5.74 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23307920700484466		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.23307920700484466 | validation: 0.40416668697932945]
	TIME [epoch: 5.73 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18983333807874964		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.18983333807874964 | validation: 0.41058402547818473]
	TIME [epoch: 5.73 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15035137348231964		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.15035137348231964 | validation: 0.3494263178786517]
	TIME [epoch: 5.73 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16414308062970123		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.16414308062970123 | validation: 0.32673245886247904]
	TIME [epoch: 5.73 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1689418009241579		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.1689418009241579 | validation: 0.42377091387568955]
	TIME [epoch: 5.78 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16422166650472914		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.16422166650472914 | validation: 0.4688737468378804]
	TIME [epoch: 5.74 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16948660766815332		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.16948660766815332 | validation: 0.35177613907329347]
	TIME [epoch: 5.74 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.151142481138121		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.151142481138121 | validation: 0.5831214168147626]
	TIME [epoch: 5.73 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2011827185221669		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.2011827185221669 | validation: 0.4352916639739698]
	TIME [epoch: 5.73 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24230312958959838		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.24230312958959838 | validation: 0.40079733031860043]
	TIME [epoch: 5.74 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18802410883716442		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.18802410883716442 | validation: 0.3657720502450242]
	TIME [epoch: 5.76 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21539924196234383		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.21539924196234383 | validation: 0.33895438158420715]
	TIME [epoch: 5.75 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20116378637574997		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.20116378637574997 | validation: 0.37473607667241327]
	TIME [epoch: 5.74 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654216652231745		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.1654216652231745 | validation: 0.32119641344170563]
	TIME [epoch: 5.73 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20412787280467212		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.20412787280467212 | validation: 0.4114460472191877]
	TIME [epoch: 5.74 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21215997753448784		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.21215997753448784 | validation: 0.3976684302540743]
	TIME [epoch: 5.73 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17982118836439753		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.17982118836439753 | validation: 0.26645180968457594]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16660587597102772		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.16660587597102772 | validation: 0.2928492300994527]
	TIME [epoch: 5.78 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18226860911246145		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.18226860911246145 | validation: 0.3703838991025741]
	TIME [epoch: 5.74 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20563277640603536		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.20563277640603536 | validation: 0.3123186798473338]
	TIME [epoch: 5.73 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18928510210010496		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.18928510210010496 | validation: 0.2779318159764139]
	TIME [epoch: 5.74 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20352197475189432		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.20352197475189432 | validation: 0.30906874536064477]
	TIME [epoch: 5.73 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15191666240555243		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.15191666240555243 | validation: 0.36382928753457494]
	TIME [epoch: 5.73 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1803153519542724		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.1803153519542724 | validation: 0.36304560033361677]
	TIME [epoch: 5.76 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17672309671941622		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.17672309671941622 | validation: 0.3187788107633395]
	TIME [epoch: 5.75 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14268964944451074		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.14268964944451074 | validation: 0.32591037434397885]
	TIME [epoch: 5.74 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1884416954522431		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.1884416954522431 | validation: 0.30768247636835944]
	TIME [epoch: 5.73 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16191261747550245		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.16191261747550245 | validation: 0.3492338525373909]
	TIME [epoch: 5.73 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16365815072746953		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.16365815072746953 | validation: 0.3229499594251984]
	TIME [epoch: 5.73 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16920580631719054		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.16920580631719054 | validation: 0.4571770278245011]
	TIME [epoch: 5.73 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1661389170758892		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.1661389170758892 | validation: 0.38095087183703874]
	TIME [epoch: 5.77 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18300506172447692		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.18300506172447692 | validation: 0.3894125273493151]
	TIME [epoch: 5.73 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19150987940095954		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.19150987940095954 | validation: 0.3299904358864142]
	TIME [epoch: 5.73 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24208635353482122		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.24208635353482122 | validation: 0.3009148301945078]
	TIME [epoch: 5.73 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17696862365047328		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.17696862365047328 | validation: 0.42583375567766796]
	TIME [epoch: 5.73 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18520508674853156		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.18520508674853156 | validation: 0.36394505808343686]
	TIME [epoch: 5.73 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1678201554557816		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.1678201554557816 | validation: 0.4336834185310847]
	TIME [epoch: 5.76 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19375949014412203		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.19375949014412203 | validation: 0.35869679263710247]
	TIME [epoch: 5.75 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16515870134164218		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.16515870134164218 | validation: 0.3997841244208251]
	TIME [epoch: 5.74 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22744908624047672		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.22744908624047672 | validation: 0.5222028380349183]
	TIME [epoch: 5.73 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1681229988215		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.1681229988215 | validation: 0.39738669621413464]
	TIME [epoch: 5.73 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15741614802035417		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.15741614802035417 | validation: 0.5360140186380344]
	TIME [epoch: 5.73 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17596785857309458		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.17596785857309458 | validation: 0.3553184922763868]
	TIME [epoch: 5.73 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15361004448587376		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.15361004448587376 | validation: 0.3413289016278266]
	TIME [epoch: 5.78 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13805778248694162		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.13805778248694162 | validation: 0.43193884448778036]
	TIME [epoch: 5.74 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2599506324766425		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.2599506324766425 | validation: 0.43768702311883495]
	TIME [epoch: 5.73 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22614267774662483		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.22614267774662483 | validation: 0.35413481941266406]
	TIME [epoch: 5.73 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19685926963999958		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.19685926963999958 | validation: 0.4471710565289176]
	TIME [epoch: 5.73 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22562906057972226		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.22562906057972226 | validation: 0.4497101649422369]
	TIME [epoch: 5.74 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18200877365912357		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.18200877365912357 | validation: 0.2985538271389491]
	TIME [epoch: 5.76 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18329895638989213		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.18329895638989213 | validation: 0.3003415280058651]
	TIME [epoch: 5.75 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1674068620601385		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.1674068620601385 | validation: 0.37757518726006767]
	TIME [epoch: 5.74 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17650834170229357		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.17650834170229357 | validation: 0.3940909675706326]
	TIME [epoch: 5.73 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16928177774041034		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.16928177774041034 | validation: 0.35607030424356223]
	TIME [epoch: 5.74 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15484768754428138		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.15484768754428138 | validation: 0.3437888516533477]
	TIME [epoch: 5.73 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1813587263620353		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.1813587263620353 | validation: 0.4166759773018769]
	TIME [epoch: 5.74 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20926785810978082		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.20926785810978082 | validation: 0.3813826088801875]
	TIME [epoch: 5.78 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22552349373573932		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.22552349373573932 | validation: 0.31891023796570556]
	TIME [epoch: 5.74 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16731978899633665		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.16731978899633665 | validation: 0.3003797478368938]
	TIME [epoch: 5.74 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1480679962234315		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.1480679962234315 | validation: 0.29550199708815966]
	TIME [epoch: 5.74 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15393474588529305		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.15393474588529305 | validation: 0.3399548136880064]
	TIME [epoch: 5.74 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15116773509603643		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.15116773509603643 | validation: 0.35526441936990766]
	TIME [epoch: 5.74 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14380223370554115		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.14380223370554115 | validation: 0.3835377128161204]
	TIME [epoch: 5.76 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19861680319484848		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.19861680319484848 | validation: 0.3952817292748593]
	TIME [epoch: 5.75 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1560210300735563		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.1560210300735563 | validation: 0.342307454950839]
	TIME [epoch: 5.74 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1564223147310726		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.1564223147310726 | validation: 0.34914977580479095]
	TIME [epoch: 5.74 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15211910375320262		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.15211910375320262 | validation: 0.29811427472769536]
	TIME [epoch: 5.74 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133390798727663		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.133390798727663 | validation: 0.4103224267384258]
	TIME [epoch: 5.74 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17549156356365408		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.17549156356365408 | validation: 0.30213784056191956]
	TIME [epoch: 5.74 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17277122525249927		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.17277122525249927 | validation: 0.3425615739159694]
	TIME [epoch: 5.78 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20931080178782888		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.20931080178782888 | validation: 0.3679965051802219]
	TIME [epoch: 5.74 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16831380225107398		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.16831380225107398 | validation: 0.3623578042798419]
	TIME [epoch: 5.74 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1645295255460649		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.1645295255460649 | validation: 0.40895037171178616]
	TIME [epoch: 5.74 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1615789961333743		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.1615789961333743 | validation: 0.31571667349870247]
	TIME [epoch: 5.74 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15864495773732282		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.15864495773732282 | validation: 0.34933328603517255]
	TIME [epoch: 5.74 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16805110928667794		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.16805110928667794 | validation: 0.28812115774143143]
	TIME [epoch: 5.76 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15538505972223524		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.15538505972223524 | validation: 0.31734769525261347]
	TIME [epoch: 5.75 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1924927927123985		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.1924927927123985 | validation: 0.3949162009274923]
	TIME [epoch: 5.74 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518712879941835		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.1518712879941835 | validation: 0.321242226493374]
	TIME [epoch: 5.74 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1453650312139994		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.1453650312139994 | validation: 0.3449027833627649]
	TIME [epoch: 5.74 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14177255626449292		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.14177255626449292 | validation: 0.3311586125818354]
	TIME [epoch: 5.74 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14855219961625832		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.14855219961625832 | validation: 0.43404439427317726]
	TIME [epoch: 5.74 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20252505714680108		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.20252505714680108 | validation: 0.35061359375130174]
	TIME [epoch: 5.78 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400135004431896		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.1400135004431896 | validation: 0.29926750807458774]
	TIME [epoch: 5.74 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13786172625485135		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.13786172625485135 | validation: 0.42341360675291595]
	TIME [epoch: 5.75 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14671958960151685		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.14671958960151685 | validation: 0.3423640543622398]
	TIME [epoch: 5.75 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16607012794159903		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.16607012794159903 | validation: 0.5497411851391735]
	TIME [epoch: 5.77 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21000851931367673		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.21000851931367673 | validation: 0.3641144112212328]
	TIME [epoch: 5.76 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15832510674499406		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.15832510674499406 | validation: 0.3462052066394475]
	TIME [epoch: 5.78 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16266411588173543		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.16266411588173543 | validation: 0.37981555128593925]
	TIME [epoch: 5.76 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550585422783528		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.1550585422783528 | validation: 0.41921806350459423]
	TIME [epoch: 5.76 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1934729872158058		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.1934729872158058 | validation: 0.47213447767235195]
	TIME [epoch: 5.77 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1678545764178511		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.1678545764178511 | validation: 0.3933100187222439]
	TIME [epoch: 5.76 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20348536565392197		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.20348536565392197 | validation: 0.376524271203595]
	TIME [epoch: 5.75 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16715878522529412		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.16715878522529412 | validation: 0.4203830269562765]
	TIME [epoch: 5.76 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18852026443115133		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.18852026443115133 | validation: 0.4403001059474069]
	TIME [epoch: 5.78 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2039100444703899		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.2039100444703899 | validation: 0.4579851407786709]
	TIME [epoch: 5.75 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17255490529214595		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.17255490529214595 | validation: 0.45302655927400637]
	TIME [epoch: 5.75 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516340555637769		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.1516340555637769 | validation: 0.29504393620581676]
	TIME [epoch: 5.74 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.181989151088635		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.181989151088635 | validation: 0.3583364519484752]
	TIME [epoch: 5.75 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566178879104709		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.1566178879104709 | validation: 0.41268746593982214]
	TIME [epoch: 5.76 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16372482349266865		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.16372482349266865 | validation: 0.40462074449090696]
	TIME [epoch: 5.79 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1711414221555127		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.1711414221555127 | validation: 0.4058954300954356]
	TIME [epoch: 5.75 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14500880365867505		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.14500880365867505 | validation: 0.34892020999817747]
	TIME [epoch: 5.75 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139087705062174		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.139087705062174 | validation: 0.445625382615791]
	TIME [epoch: 5.74 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19568207234998705		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.19568207234998705 | validation: 0.36466060821630747]
	TIME [epoch: 5.74 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1890034508340475		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.1890034508340475 | validation: 0.41313597631265575]
	TIME [epoch: 5.74 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20328458951071415		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.20328458951071415 | validation: 0.3154461514449048]
	TIME [epoch: 5.75 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19392765319305882		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.19392765319305882 | validation: 0.28251672998783145]
	TIME [epoch: 5.77 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1798543867293041		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.1798543867293041 | validation: 0.302211321023692]
	TIME [epoch: 5.74 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20064496149451105		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.20064496149451105 | validation: 0.32398850581795857]
	TIME [epoch: 5.74 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318984380818616		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.1318984380818616 | validation: 0.31283567696910203]
	TIME [epoch: 5.74 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16374314129485773		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.16374314129485773 | validation: 0.45049788300001614]
	TIME [epoch: 5.74 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17420616858931776		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.17420616858931776 | validation: 0.34335896184187364]
	TIME [epoch: 5.74 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15205058929152243		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.15205058929152243 | validation: 0.2851549789682056]
	TIME [epoch: 5.78 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12311634429992555		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.12311634429992555 | validation: 0.44826328478933863]
	TIME [epoch: 5.75 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24675230500262382		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.24675230500262382 | validation: 0.4371701911051218]
	TIME [epoch: 5.74 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20328984880102424		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.20328984880102424 | validation: 0.409119603013487]
	TIME [epoch: 5.74 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16040535080982882		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.16040535080982882 | validation: 0.37499216686182985]
	TIME [epoch: 5.74 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15770992846280685		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.15770992846280685 | validation: 0.3753655824319236]
	TIME [epoch: 5.74 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19038735487441527		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.19038735487441527 | validation: 0.37952381746444397]
	TIME [epoch: 5.75 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14120600702820946		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.14120600702820946 | validation: 0.33938992223448194]
	TIME [epoch: 5.77 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15103737181244845		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.15103737181244845 | validation: 0.32282957694530906]
	TIME [epoch: 5.74 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283012197314225		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.1283012197314225 | validation: 0.33496588798848514]
	TIME [epoch: 5.74 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15121763889180223		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.15121763889180223 | validation: 0.33857755149125285]
	TIME [epoch: 5.74 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13113053231630037		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.13113053231630037 | validation: 0.3126586423796927]
	TIME [epoch: 5.74 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12261121133174391		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.12261121133174391 | validation: 0.30183192422066796]
	TIME [epoch: 5.74 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12910091848066102		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.12910091848066102 | validation: 0.28647125989072736]
	TIME [epoch: 5.78 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15780066802266288		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.15780066802266288 | validation: 0.36679588524333395]
	TIME [epoch: 5.75 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753223469053064		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.13753223469053064 | validation: 0.34426632173225996]
	TIME [epoch: 5.74 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16025918122103		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.16025918122103 | validation: 0.3191645749430624]
	TIME [epoch: 5.74 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14737791868625327		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.14737791868625327 | validation: 0.3340162146619939]
	TIME [epoch: 5.74 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452063058285988		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.1452063058285988 | validation: 0.4203973306155989]
	TIME [epoch: 5.74 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18922177811484675		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.18922177811484675 | validation: 0.329423194568771]
	TIME [epoch: 5.75 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14265704449808925		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.14265704449808925 | validation: 0.2824682656423312]
	TIME [epoch: 5.77 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17490088355846223		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.17490088355846223 | validation: 0.33228309260573113]
	TIME [epoch: 5.74 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18268875603323653		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.18268875603323653 | validation: 0.3190856006387182]
	TIME [epoch: 5.74 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14198065173701768		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.14198065173701768 | validation: 0.2836643074965303]
	TIME [epoch: 5.74 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14416050147023612		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.14416050147023612 | validation: 0.288668914588906]
	TIME [epoch: 5.74 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12518408168027106		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.12518408168027106 | validation: 0.28896656508520063]
	TIME [epoch: 5.74 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11538379574514449		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.11538379574514449 | validation: 0.34492260662876795]
	TIME [epoch: 5.78 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16649212709988256		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.16649212709988256 | validation: 0.41491201944274453]
	TIME [epoch: 5.75 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16426475780846794		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.16426475780846794 | validation: 0.3346538796659169]
	TIME [epoch: 5.75 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383826680913231		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.1383826680913231 | validation: 0.33783220962805227]
	TIME [epoch: 5.75 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15390635798605892		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.15390635798605892 | validation: 0.31100328817936057]
	TIME [epoch: 5.75 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15179724757047924		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.15179724757047924 | validation: 0.3439425942604281]
	TIME [epoch: 5.74 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452258318051091		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.1452258318051091 | validation: 0.3104203560391682]
	TIME [epoch: 5.75 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19102481319914943		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.19102481319914943 | validation: 0.3387053871908786]
	TIME [epoch: 5.77 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1770258872496501		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.1770258872496501 | validation: 0.3587236239887666]
	TIME [epoch: 5.74 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1564224534848242		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.1564224534848242 | validation: 0.34712234391754876]
	TIME [epoch: 5.74 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12961578832218684		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.12961578832218684 | validation: 0.3236832386975163]
	TIME [epoch: 5.74 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14345758404339093		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.14345758404339093 | validation: 0.3379473081898111]
	TIME [epoch: 5.74 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14157906845817841		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.14157906845817841 | validation: 0.3663287410491603]
	TIME [epoch: 5.74 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15036471111283192		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.15036471111283192 | validation: 0.361687655326466]
	TIME [epoch: 5.78 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14882472472054106		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.14882472472054106 | validation: 0.3236687547885252]
	TIME [epoch: 5.75 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1149908223739029		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.1149908223739029 | validation: 0.3396752560609126]
	TIME [epoch: 5.74 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14135010574116227		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.14135010574116227 | validation: 0.28805225798913664]
	TIME [epoch: 5.74 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14133067129879479		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.14133067129879479 | validation: 0.286909663049167]
	TIME [epoch: 5.74 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276470951340634		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.1276470951340634 | validation: 0.3295220714680271]
	TIME [epoch: 5.74 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20505594174518613		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.20505594174518613 | validation: 0.36625237820529877]
	TIME [epoch: 5.76 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16579228826274642		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.16579228826274642 | validation: 0.3669115244210385]
	TIME [epoch: 5.77 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16087744697793768		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.16087744697793768 | validation: 0.346698072405549]
	TIME [epoch: 5.75 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.161284143352559		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.161284143352559 | validation: 0.29495122907695676]
	TIME [epoch: 5.75 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15071083183682799		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.15071083183682799 | validation: 0.3208960354482956]
	TIME [epoch: 5.74 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14718941310285663		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.14718941310285663 | validation: 0.40575417733015956]
	TIME [epoch: 5.74 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14370996407621658		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.14370996407621658 | validation: 0.31507011506610605]
	TIME [epoch: 5.75 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15994068046119625		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.15994068046119625 | validation: 0.29638952083715736]
	TIME [epoch: 5.78 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13075621807894622		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.13075621807894622 | validation: 0.3491206201497776]
	TIME [epoch: 5.75 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13527931471261279		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.13527931471261279 | validation: 0.3127743181589676]
	TIME [epoch: 5.75 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327987447148605		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.1327987447148605 | validation: 0.31125135293191497]
	TIME [epoch: 5.75 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1440520414185419		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.1440520414185419 | validation: 0.3081546767324011]
	TIME [epoch: 5.75 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566763746924892		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.1566763746924892 | validation: 0.3515140804808394]
	TIME [epoch: 5.74 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14884570093926394		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.14884570093926394 | validation: 0.39805541438483716]
	TIME [epoch: 5.76 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612527469824768		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.1612527469824768 | validation: 0.3345389997226614]
	TIME [epoch: 5.77 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14749713122348015		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.14749713122348015 | validation: 0.42819145133273145]
	TIME [epoch: 5.75 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21884825261395824		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.21884825261395824 | validation: 0.3251697263150189]
	TIME [epoch: 5.75 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13689105459367273		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.13689105459367273 | validation: 0.3780379922588788]
	TIME [epoch: 5.74 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1352757781829076		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.1352757781829076 | validation: 0.29583061649208914]
	TIME [epoch: 5.74 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12208214267775502		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.12208214267775502 | validation: 0.348138050073359]
	TIME [epoch: 5.74 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.137352565549392		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.137352565549392 | validation: 0.3492073367051727]
	TIME [epoch: 5.78 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16278326173004726		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.16278326173004726 | validation: 0.5246468804120812]
	TIME [epoch: 5.75 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18462250854416534		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.18462250854416534 | validation: 0.40398853675659674]
	TIME [epoch: 5.74 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521367374265257		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.1521367374265257 | validation: 0.4206170754539732]
	TIME [epoch: 5.74 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14359055558050898		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.14359055558050898 | validation: 0.37908793362636695]
	TIME [epoch: 5.74 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12326782029541163		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.12326782029541163 | validation: 0.3671171822028967]
	TIME [epoch: 5.74 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13494481766396282		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.13494481766396282 | validation: 0.3825316632202907]
	TIME [epoch: 5.76 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16497320290406828		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.16497320290406828 | validation: 0.41373926646666176]
	TIME [epoch: 5.77 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16541537644295318		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.16541537644295318 | validation: 0.3248374767262638]
	TIME [epoch: 5.74 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11970454434230646		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.11970454434230646 | validation: 0.3255817750183149]
	TIME [epoch: 5.74 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13381621499818186		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.13381621499818186 | validation: 0.3741465222685727]
	TIME [epoch: 5.74 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12261506485799717		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.12261506485799717 | validation: 0.3592629196836569]
	TIME [epoch: 5.74 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12373260112722195		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.12373260112722195 | validation: 0.36513637527599907]
	TIME [epoch: 5.74 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1284239226033757		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.1284239226033757 | validation: 0.4356310028096941]
	TIME [epoch: 5.78 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448794185678437		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.1448794185678437 | validation: 0.3501389244543411]
	TIME [epoch: 5.75 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12020556989074187		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.12020556989074187 | validation: 0.3347075731367125]
	TIME [epoch: 5.74 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12911773223967782		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.12911773223967782 | validation: 0.3352527917167551]
	TIME [epoch: 5.74 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12011071354270492		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.12011071354270492 | validation: 0.3255591294056031]
	TIME [epoch: 5.74 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11483885794263508		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.11483885794263508 | validation: 0.3629035745371874]
	TIME [epoch: 5.74 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468582523415648		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.1468582523415648 | validation: 0.3347714965656461]
	TIME [epoch: 5.75 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13244039540013303		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.13244039540013303 | validation: 0.29361845726420777]
	TIME [epoch: 5.77 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131702021330525		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.131702021330525 | validation: 0.30680042953638065]
	TIME [epoch: 5.75 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12975812727466077		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.12975812727466077 | validation: 0.43974746016040156]
	TIME [epoch: 5.74 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15260998423727384		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.15260998423727384 | validation: 0.37389534128971363]
	TIME [epoch: 5.74 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1473026093042668		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.1473026093042668 | validation: 0.3210994833121638]
	TIME [epoch: 5.74 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15708814217788947		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.15708814217788947 | validation: 0.3834300529307315]
	TIME [epoch: 5.74 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1447517607373507		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.1447517607373507 | validation: 0.305569969025631]
	TIME [epoch: 5.78 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12129075900469871		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.12129075900469871 | validation: 0.3010392585803316]
	TIME [epoch: 5.74 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12887923960501063		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.12887923960501063 | validation: 0.304545522602792]
	TIME [epoch: 5.74 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11804607432939933		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.11804607432939933 | validation: 0.34365713549335114]
	TIME [epoch: 5.74 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13486055188848772		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.13486055188848772 | validation: 0.37038364278631564]
	TIME [epoch: 5.74 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13634025151221774		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.13634025151221774 | validation: 0.3147421676783547]
	TIME [epoch: 5.74 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322420552973782		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.1322420552973782 | validation: 0.28045375174502857]
	TIME [epoch: 5.77 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11910030975410296		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.11910030975410296 | validation: 0.34817803132123715]
	TIME [epoch: 5.76 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12866356241035853		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.12866356241035853 | validation: 0.34290516458453996]
	TIME [epoch: 5.74 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14049797583529652		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.14049797583529652 | validation: 0.4367545591650104]
	TIME [epoch: 5.74 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17011793345289491		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.17011793345289491 | validation: 0.3551304612628509]
	TIME [epoch: 5.74 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11977176495590781		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.11977176495590781 | validation: 0.36152069370187323]
	TIME [epoch: 5.74 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13122139553225967		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.13122139553225967 | validation: 0.3735735546599909]
	TIME [epoch: 5.74 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12343484721412987		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.12343484721412987 | validation: 0.3274824547785349]
	TIME [epoch: 5.78 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12476010163303194		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.12476010163303194 | validation: 0.3853912952325855]
	TIME [epoch: 5.75 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12306629737240415		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.12306629737240415 | validation: 0.3530710613430125]
	TIME [epoch: 5.74 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13029252085021922		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.13029252085021922 | validation: 0.37054567819553497]
	TIME [epoch: 5.74 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292889213565896		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.1292889213565896 | validation: 0.30776865651857116]
	TIME [epoch: 5.74 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464616462211795		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.1464616462211795 | validation: 0.3046857809133851]
	TIME [epoch: 5.74 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12450672046526051		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.12450672046526051 | validation: 0.31314559009252657]
	TIME [epoch: 5.77 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12536248688789173		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.12536248688789173 | validation: 0.30666324843404125]
	TIME [epoch: 5.75 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09968278121837794		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.09968278121837794 | validation: 0.3240944661695228]
	TIME [epoch: 5.74 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12269870546224969		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.12269870546224969 | validation: 0.34696700359438026]
	TIME [epoch: 5.74 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1206006272615843		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.1206006272615843 | validation: 0.35837584610493783]
	TIME [epoch: 5.74 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12565316667530754		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.12565316667530754 | validation: 0.3367537753195248]
	TIME [epoch: 5.74 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13039036632308537		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.13039036632308537 | validation: 0.3504096752403943]
	TIME [epoch: 5.74 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14396802145378088		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.14396802145378088 | validation: 0.3241457541732379]
	TIME [epoch: 5.78 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12754133928101066		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.12754133928101066 | validation: 0.37563416542566985]
	TIME [epoch: 5.74 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14743719396400165		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.14743719396400165 | validation: 0.33624915761265667]
	TIME [epoch: 5.74 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12887883292515903		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.12887883292515903 | validation: 0.3737983686006273]
	TIME [epoch: 5.74 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12446288893464885		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.12446288893464885 | validation: 0.2891562856564684]
	TIME [epoch: 5.74 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124893319211823		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.124893319211823 | validation: 0.33231688082953703]
	TIME [epoch: 5.74 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12425649762194385		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.12425649762194385 | validation: 0.3026578894090972]
	TIME [epoch: 5.77 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11859913900851056		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.11859913900851056 | validation: 0.35875885666022506]
	TIME [epoch: 5.75 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12367153051910312		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.12367153051910312 | validation: 0.3586999884847661]
	TIME [epoch: 5.74 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11930843507640672		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.11930843507640672 | validation: 0.3500194800006623]
	TIME [epoch: 5.74 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11534076046256078		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.11534076046256078 | validation: 0.3202130395357245]
	TIME [epoch: 5.74 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11851908510851489		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.11851908510851489 | validation: 0.3570154809869491]
	TIME [epoch: 5.75 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335927147262109		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.1335927147262109 | validation: 0.3645911319995511]
	TIME [epoch: 5.75 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12404965521000343		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.12404965521000343 | validation: 0.3293998707501477]
	TIME [epoch: 5.78 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12937615894368146		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.12937615894368146 | validation: 0.41463627279620147]
	TIME [epoch: 5.75 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14206026045204068		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.14206026045204068 | validation: 0.33960888115612087]
	TIME [epoch: 5.75 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12290949956769756		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.12290949956769756 | validation: 0.32501281365357215]
	TIME [epoch: 5.74 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13146920719074662		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.13146920719074662 | validation: 0.33898936943980884]
	TIME [epoch: 5.75 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13303373145081604		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.13303373145081604 | validation: 0.30106212627406964]
	TIME [epoch: 5.74 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15348223891873808		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.15348223891873808 | validation: 0.3119137103728693]
	TIME [epoch: 5.77 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353521807084443		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.1353521807084443 | validation: 0.2806298914352122]
	TIME [epoch: 5.76 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12681308187148313		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.12681308187148313 | validation: 0.28761531637252]
	TIME [epoch: 5.75 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11788403583290592		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.11788403583290592 | validation: 0.2836862436204596]
	TIME [epoch: 5.75 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12472753715595544		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.12472753715595544 | validation: 0.31729494316919915]
	TIME [epoch: 5.75 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11399607384414985		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.11399607384414985 | validation: 0.3013457871811855]
	TIME [epoch: 5.75 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.110592043935725		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.110592043935725 | validation: 0.30356788713892646]
	TIME [epoch: 5.75 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280808043614734		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.1280808043614734 | validation: 0.3275101058697489]
	TIME [epoch: 5.79 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12355201030707932		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.12355201030707932 | validation: 0.29921401811107984]
	TIME [epoch: 5.75 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10843328176400369		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.10843328176400369 | validation: 0.32706823184260003]
	TIME [epoch: 5.75 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11928781708332462		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.11928781708332462 | validation: 0.3494294853195409]
	TIME [epoch: 5.75 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12484613974489206		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.12484613974489206 | validation: 0.34160167980614986]
	TIME [epoch: 5.75 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12272337808697571		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.12272337808697571 | validation: 0.3002249333956777]
	TIME [epoch: 5.74 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12016198052209452		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.12016198052209452 | validation: 0.311326003567283]
	TIME [epoch: 5.77 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370526226577479		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.1370526226577479 | validation: 0.341488923275507]
	TIME [epoch: 5.76 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14089277925046467		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.14089277925046467 | validation: 0.40021400211808283]
	TIME [epoch: 5.75 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11958055076879925		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.11958055076879925 | validation: 0.37655880867793656]
	TIME [epoch: 5.75 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11603291752640937		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.11603291752640937 | validation: 0.37498206451893906]
	TIME [epoch: 5.75 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14073933992530616		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.14073933992530616 | validation: 0.38822378073760355]
	TIME [epoch: 5.75 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12360543253644092		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.12360543253644092 | validation: 0.36218910407217936]
	TIME [epoch: 5.75 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11317801759047624		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.11317801759047624 | validation: 0.3817356175491014]
	TIME [epoch: 5.78 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271228282227971		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.1271228282227971 | validation: 0.3413997276669727]
	TIME [epoch: 5.75 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12043789508098902		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.12043789508098902 | validation: 0.3568031165137151]
	TIME [epoch: 5.75 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303213507886306		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.1303213507886306 | validation: 0.34899296973677923]
	TIME [epoch: 5.75 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14109807599375726		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.14109807599375726 | validation: 0.3794176638792807]
	TIME [epoch: 5.75 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13201597280067598		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.13201597280067598 | validation: 0.3720950515183925]
	TIME [epoch: 5.74 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11597320456585336		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.11597320456585336 | validation: 0.3342899204777632]
	TIME [epoch: 5.77 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12705556157822445		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.12705556157822445 | validation: 0.34483588701950985]
	TIME [epoch: 5.76 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11573076513441488		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.11573076513441488 | validation: 0.32849977113629486]
	TIME [epoch: 5.75 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11740284140414035		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.11740284140414035 | validation: 0.3562795835759437]
	TIME [epoch: 5.75 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12807448025016185		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.12807448025016185 | validation: 0.33005016453232044]
	TIME [epoch: 5.75 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1156907515065432		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.1156907515065432 | validation: 0.35291150293189716]
	TIME [epoch: 5.74 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11902385691175793		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.11902385691175793 | validation: 0.3284033557499049]
	TIME [epoch: 5.75 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11281528358213369		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.11281528358213369 | validation: 0.33495908007243175]
	TIME [epoch: 5.78 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1165761126951602		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.1165761126951602 | validation: 0.38802779622601186]
	TIME [epoch: 5.75 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1161740201221334		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.1161740201221334 | validation: 0.3629669454980177]
	TIME [epoch: 5.75 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13162613467758727		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.13162613467758727 | validation: 0.3565006725524782]
	TIME [epoch: 5.75 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12214123729622506		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.12214123729622506 | validation: 0.37462221394671813]
	TIME [epoch: 5.75 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1185803528927169		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.1185803528927169 | validation: 0.39515681832209426]
	TIME [epoch: 5.75 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11501003222774042		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.11501003222774042 | validation: 0.3744417125426297]
	TIME [epoch: 5.78 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12013295200906499		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.12013295200906499 | validation: 0.3885637927079029]
	TIME [epoch: 5.76 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14075692214107266		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.14075692214107266 | validation: 0.3650996450172568]
	TIME [epoch: 5.75 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12554733891031905		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.12554733891031905 | validation: 0.3565735988253906]
	TIME [epoch: 5.75 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12007170993214174		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.12007170993214174 | validation: 0.31462456620175105]
	TIME [epoch: 5.75 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16151153626031728		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.16151153626031728 | validation: 0.3227992778603077]
	TIME [epoch: 5.75 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15312350222403254		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.15312350222403254 | validation: 0.3281150265295971]
	TIME [epoch: 5.75 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12971312822242206		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.12971312822242206 | validation: 0.36274470562925204]
	TIME [epoch: 5.78 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10818981741588489		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.10818981741588489 | validation: 0.3344216863200331]
	TIME [epoch: 5.75 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12445482175545339		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.12445482175545339 | validation: 0.35681358506864413]
	TIME [epoch: 5.75 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12438231817994708		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.12438231817994708 | validation: 0.3226657120045406]
	TIME [epoch: 5.75 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11910384088718244		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.11910384088718244 | validation: 0.3436238223912772]
	TIME [epoch: 5.75 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10890304052084492		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.10890304052084492 | validation: 0.31540071325140095]
	TIME [epoch: 5.75 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12059304858301445		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.12059304858301445 | validation: 0.3453685377413776]
	TIME [epoch: 5.78 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12313726841785844		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.12313726841785844 | validation: 0.31712548198608537]
	TIME [epoch: 5.75 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12358563561249239		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.12358563561249239 | validation: 0.29753560326125206]
	TIME [epoch: 5.75 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11248068301313761		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.11248068301313761 | validation: 0.3463438554135231]
	TIME [epoch: 5.75 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12405655955797742		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.12405655955797742 | validation: 0.27285472369881897]
	TIME [epoch: 5.75 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493241829281332		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.1493241829281332 | validation: 0.29719850031160955]
	TIME [epoch: 5.75 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13566750788731444		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.13566750788731444 | validation: 0.3188264676847557]
	TIME [epoch: 5.76 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12554641143625714		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.12554641143625714 | validation: 0.34229293203378014]
	TIME [epoch: 5.77 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110527500557481		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.1110527500557481 | validation: 0.34277941950055507]
	TIME [epoch: 5.75 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13016098965126044		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.13016098965126044 | validation: 0.3417386665439631]
	TIME [epoch: 5.75 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13050441268338828		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.13050441268338828 | validation: 0.3214284553114708]
	TIME [epoch: 5.74 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1113883186584741		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.1113883186584741 | validation: 0.3298622868897509]
	TIME [epoch: 5.74 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10314860854434707		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.10314860854434707 | validation: 0.30746179170737503]
	TIME [epoch: 5.74 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11702056562143336		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.11702056562143336 | validation: 0.3076851832750001]
	TIME [epoch: 5.78 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10631779340925503		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.10631779340925503 | validation: 0.33943488932328825]
	TIME [epoch: 5.75 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282711251410288		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.1282711251410288 | validation: 0.3396512218209344]
	TIME [epoch: 5.74 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11980701920706426		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.11980701920706426 | validation: 0.37925181325488583]
	TIME [epoch: 5.75 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11064955708728477		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.11064955708728477 | validation: 0.30617767908417787]
	TIME [epoch: 5.75 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11259072504842635		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.11259072504842635 | validation: 0.2887976541783134]
	TIME [epoch: 5.75 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1154511557919778		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.1154511557919778 | validation: 0.3369700478787952]
	TIME [epoch: 5.76 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10439361741573164		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.10439361741573164 | validation: 0.32485522518646404]
	TIME [epoch: 5.77 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10893863829430256		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.10893863829430256 | validation: 0.3082842432018706]
	TIME [epoch: 5.75 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10230011293047492		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.10230011293047492 | validation: 0.30156504733121947]
	TIME [epoch: 5.75 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10223401727924353		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.10223401727924353 | validation: 0.33792092259067447]
	TIME [epoch: 5.75 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1358484267862746		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.1358484267862746 | validation: 0.33184994341362173]
	TIME [epoch: 5.75 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110199895717131		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.1110199895717131 | validation: 0.33101148238716105]
	TIME [epoch: 5.75 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11373537999508682		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.11373537999508682 | validation: 0.3477145555719594]
	TIME [epoch: 5.78 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11529122803402507		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.11529122803402507 | validation: 0.312844871178189]
	TIME [epoch: 5.75 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10664784267396822		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.10664784267396822 | validation: 0.33926044826859225]
	TIME [epoch: 5.75 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11972517068354657		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.11972517068354657 | validation: 0.3261914995379065]
	TIME [epoch: 5.75 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10989409173191696		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.10989409173191696 | validation: 0.29946658021776645]
	TIME [epoch: 5.75 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11621518121566164		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.11621518121566164 | validation: 0.291832525694998]
	TIME [epoch: 5.75 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12526606796102893		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.12526606796102893 | validation: 0.29353114304987094]
	TIME [epoch: 5.76 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11339784628669362		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.11339784628669362 | validation: 0.2922009157206153]
	TIME [epoch: 5.78 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11233613686477403		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.11233613686477403 | validation: 0.2655151075365072]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_978.pth
	Model improved!!!
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11134902300716204		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.11134902300716204 | validation: 0.2932824602588552]
	TIME [epoch: 5.75 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11351599927542175		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.11351599927542175 | validation: 0.2872773101654042]
	TIME [epoch: 5.74 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12578462693123113		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.12578462693123113 | validation: 0.2988604336679549]
	TIME [epoch: 5.74 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10904236639459271		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.10904236639459271 | validation: 0.27533446163092395]
	TIME [epoch: 5.74 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11465552219173933		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.11465552219173933 | validation: 0.2975164253294217]
	TIME [epoch: 5.78 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11745808458820647		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.11745808458820647 | validation: 0.2769663609377239]
	TIME [epoch: 5.74 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1141318827154729		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.1141318827154729 | validation: 0.2870973345858213]
	TIME [epoch: 5.75 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11519836266591613		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.11519836266591613 | validation: 0.3007234321663572]
	TIME [epoch: 5.74 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11700047842977074		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.11700047842977074 | validation: 0.2689468138881618]
	TIME [epoch: 5.75 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11574731652244799		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.11574731652244799 | validation: 0.2916796052021364]
	TIME [epoch: 5.74 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11292637971296438		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.11292637971296438 | validation: 0.32536571311745704]
	TIME [epoch: 5.77 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10453679239146782		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.10453679239146782 | validation: 0.303712386407879]
	TIME [epoch: 5.76 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11657816282415905		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.11657816282415905 | validation: 0.30197184828978596]
	TIME [epoch: 5.75 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13112019563924127		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.13112019563924127 | validation: 0.35402219492561154]
	TIME [epoch: 5.74 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14384539295321785		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.14384539295321785 | validation: 0.3314647385287686]
	TIME [epoch: 5.74 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10296565400568802		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.10296565400568802 | validation: 0.2890879649062702]
	TIME [epoch: 5.74 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10608841780989761		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.10608841780989761 | validation: 0.27853883953690306]
	TIME [epoch: 5.75 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11939431609723423		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.11939431609723423 | validation: 0.2605695612141187]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_996.pth
	Model improved!!!
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12267145979093816		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.12267145979093816 | validation: 0.2981784796754736]
	TIME [epoch: 5.75 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11555155323786015		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.11555155323786015 | validation: 0.3329164103115362]
	TIME [epoch: 5.75 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10780842136927898		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.10780842136927898 | validation: 0.28255300500624936]
	TIME [epoch: 5.74 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0980314171908745		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.0980314171908745 | validation: 0.2919770283235362]
	TIME [epoch: 5.74 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10857008898281265		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.10857008898281265 | validation: 0.3629033004263437]
	TIME [epoch: 5.74 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12396085849480351		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.12396085849480351 | validation: 0.3141374415145621]
	TIME [epoch: 5.77 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11953930805805366		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.11953930805805366 | validation: 0.33610215228277823]
	TIME [epoch: 5.76 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11581222674831644		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.11581222674831644 | validation: 0.27778335606281684]
	TIME [epoch: 5.74 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1151675071688077		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.1151675071688077 | validation: 0.2774397517406787]
	TIME [epoch: 5.74 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0988661846134079		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.0988661846134079 | validation: 0.3035024520334815]
	TIME [epoch: 5.74 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11723938116629253		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.11723938116629253 | validation: 0.33977599499030675]
	TIME [epoch: 5.74 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11341482469995796		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.11341482469995796 | validation: 0.31610595353541726]
	TIME [epoch: 5.74 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11215792697567051		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.11215792697567051 | validation: 0.30947721125954764]
	TIME [epoch: 5.78 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11527228025558142		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.11527228025558142 | validation: 0.31685687142350144]
	TIME [epoch: 5.74 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11165416923979103		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.11165416923979103 | validation: 0.314667146426957]
	TIME [epoch: 5.74 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10316335616204635		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.10316335616204635 | validation: 0.3188994664525897]
	TIME [epoch: 5.74 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10888638446037438		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.10888638446037438 | validation: 0.3350339509699208]
	TIME [epoch: 5.74 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12530481544886957		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.12530481544886957 | validation: 0.35842104840524824]
	TIME [epoch: 5.74 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12333167553827211		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.12333167553827211 | validation: 0.29430835230573227]
	TIME [epoch: 5.77 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11555090402370471		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.11555090402370471 | validation: 0.27602013055516406]
	TIME [epoch: 5.75 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11514467165829492		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.11514467165829492 | validation: 0.2862095769907524]
	TIME [epoch: 5.75 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09857906253978924		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.09857906253978924 | validation: 0.31936013545424347]
	TIME [epoch: 5.74 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11876544253886315		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.11876544253886315 | validation: 0.3124700158591247]
	TIME [epoch: 5.74 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11855242051003965		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.11855242051003965 | validation: 0.2936788436434711]
	TIME [epoch: 5.74 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12232769347729076		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.12232769347729076 | validation: 0.3009313961594583]
	TIME [epoch: 5.75 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11683819782939148		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.11683819782939148 | validation: 0.33307330103098026]
	TIME [epoch: 5.78 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11163254642913475		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.11163254642913475 | validation: 0.35015402258458544]
	TIME [epoch: 5.75 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10495957244995674		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.10495957244995674 | validation: 0.3245762224101462]
	TIME [epoch: 5.74 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11915034170015197		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.11915034170015197 | validation: 0.3443226104306102]
	TIME [epoch: 5.74 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10738900260981186		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.10738900260981186 | validation: 0.34064085653805537]
	TIME [epoch: 5.74 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10853598744417879		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.10853598744417879 | validation: 0.34461089123623306]
	TIME [epoch: 5.74 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10466138500801189		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.10466138500801189 | validation: 0.33116511405980126]
	TIME [epoch: 5.77 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10603291278641815		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.10603291278641815 | validation: 0.2833772989770846]
	TIME [epoch: 5.75 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10176901839605931		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.10176901839605931 | validation: 0.2969853552049621]
	TIME [epoch: 5.74 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10288806002546765		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.10288806002546765 | validation: 0.3037500920882061]
	TIME [epoch: 5.74 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10342156091960603		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.10342156091960603 | validation: 0.3206892391077139]
	TIME [epoch: 5.74 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11169782529984264		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.11169782529984264 | validation: 0.3337094953809359]
	TIME [epoch: 5.74 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10682617325567124		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.10682617325567124 | validation: 0.2812853598939998]
	TIME [epoch: 5.75 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10639359448513264		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.10639359448513264 | validation: 0.27920953108362995]
	TIME [epoch: 5.77 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11175045778897584		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.11175045778897584 | validation: 0.2852133789074705]
	TIME [epoch: 5.74 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1125443884557367		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.1125443884557367 | validation: 0.3074174463489072]
	TIME [epoch: 5.74 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10928829010993117		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.10928829010993117 | validation: 0.32260634616272127]
	TIME [epoch: 5.74 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10438509689154779		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.10438509689154779 | validation: 0.329764502620907]
	TIME [epoch: 5.74 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10061556501821006		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.10061556501821006 | validation: 0.359763309032005]
	TIME [epoch: 5.74 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1193370163940188		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.1193370163940188 | validation: 0.3662928282767793]
	TIME [epoch: 5.78 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1161096156210003		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.1161096156210003 | validation: 0.3367254297382944]
	TIME [epoch: 5.75 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038300230976504		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.11038300230976504 | validation: 0.37102395098900687]
	TIME [epoch: 5.74 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12344113841287416		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.12344113841287416 | validation: 0.3651446358158007]
	TIME [epoch: 5.74 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10491061358043471		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.10491061358043471 | validation: 0.32085082837041073]
	TIME [epoch: 5.74 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09462917615591707		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.09462917615591707 | validation: 0.3170637095612075]
	TIME [epoch: 5.74 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10329477788811602		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.10329477788811602 | validation: 0.3031295142814115]
	TIME [epoch: 5.75 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11072832457148783		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.11072832457148783 | validation: 0.28939671189418953]
	TIME [epoch: 5.77 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10400296869574738		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.10400296869574738 | validation: 0.29131931571753245]
	TIME [epoch: 5.74 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09957459768822893		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.09957459768822893 | validation: 0.2805848853420884]
	TIME [epoch: 5.74 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11349628428024049		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.11349628428024049 | validation: 0.30197938846863986]
	TIME [epoch: 5.74 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10595222995962053		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.10595222995962053 | validation: 0.2829801142954235]
	TIME [epoch: 5.74 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11562121584517959		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.11562121584517959 | validation: 0.32777391792702804]
	TIME [epoch: 5.74 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12658450455833126		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.12658450455833126 | validation: 0.276376214052314]
	TIME [epoch: 5.77 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10545839783137052		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.10545839783137052 | validation: 0.28811485939074716]
	TIME [epoch: 5.74 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10148084096508142		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.10148084096508142 | validation: 0.29646279094072664]
	TIME [epoch: 5.74 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0996205793772198		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.0996205793772198 | validation: 0.2922135998933077]
	TIME [epoch: 5.74 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0992515055432309		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.0992515055432309 | validation: 0.31122878764171]
	TIME [epoch: 5.74 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10149282326819692		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.10149282326819692 | validation: 0.3164431206177614]
	TIME [epoch: 5.74 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11167049504790708		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.11167049504790708 | validation: 0.31535200481644265]
	TIME [epoch: 5.75 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10448174975157229		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.10448174975157229 | validation: 0.3188230856429798]
	TIME [epoch: 5.77 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10246108928722972		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.10246108928722972 | validation: 0.3131861098563408]
	TIME [epoch: 5.74 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10817937380045015		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.10817937380045015 | validation: 0.31160076901175865]
	TIME [epoch: 5.74 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10152941459610469		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.10152941459610469 | validation: 0.30796597147290233]
	TIME [epoch: 5.74 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09908735826426601		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.09908735826426601 | validation: 0.32368157099863554]
	TIME [epoch: 5.74 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263488698617184		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.1263488698617184 | validation: 0.395288710736613]
	TIME [epoch: 5.74 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1177411831887362		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.1177411831887362 | validation: 0.3416726417929836]
	TIME [epoch: 5.77 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12093208509859599		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.12093208509859599 | validation: 0.3536434082791241]
	TIME [epoch: 5.74 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11172321756950418		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.11172321756950418 | validation: 0.32630277121762485]
	TIME [epoch: 5.74 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11104384005003275		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.11104384005003275 | validation: 0.32132442439694997]
	TIME [epoch: 5.74 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11890859671259987		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.11890859671259987 | validation: 0.3205028369438639]
	TIME [epoch: 5.74 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10605866631258704		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.10605866631258704 | validation: 0.292062767831954]
	TIME [epoch: 5.74 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10030115714249264		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.10030115714249264 | validation: 0.32483198097120325]
	TIME [epoch: 5.75 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10676421403331973		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.10676421403331973 | validation: 0.2897815013533242]
	TIME [epoch: 5.77 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10491521104616572		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.10491521104616572 | validation: 0.2955001543699518]
	TIME [epoch: 5.74 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09729628484198874		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.09729628484198874 | validation: 0.28121480232063795]
	TIME [epoch: 5.74 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10270373352371631		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.10270373352371631 | validation: 0.3065944956243148]
	TIME [epoch: 5.74 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10205116048988494		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.10205116048988494 | validation: 0.3026038776793973]
	TIME [epoch: 5.73 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10283002243900354		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.10283002243900354 | validation: 0.3410874870276456]
	TIME [epoch: 5.74 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0999128459904849		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.0999128459904849 | validation: 0.3059575965507355]
	TIME [epoch: 5.77 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10970194269985042		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.10970194269985042 | validation: 0.30774677931593725]
	TIME [epoch: 5.74 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09557641736510993		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.09557641736510993 | validation: 0.26435376972669067]
	TIME [epoch: 5.74 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10049988437432877		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.10049988437432877 | validation: 0.27811598593814235]
	TIME [epoch: 5.74 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10599619200542872		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.10599619200542872 | validation: 0.30780094561263355]
	TIME [epoch: 5.74 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11332067368564631		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.11332067368564631 | validation: 0.29205676003996106]
	TIME [epoch: 5.74 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11006991308995223		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.11006991308995223 | validation: 0.3081597957747228]
	TIME [epoch: 5.74 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10309609503989828		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.10309609503989828 | validation: 0.2895162100157609]
	TIME [epoch: 5.76 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11058391485147533		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.11058391485147533 | validation: 0.28624729090720324]
	TIME [epoch: 5.74 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10420106342695055		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.10420106342695055 | validation: 0.2980233693328757]
	TIME [epoch: 5.74 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10894139340643016		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.10894139340643016 | validation: 0.2981402081557768]
	TIME [epoch: 5.73 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.106310942640434		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.106310942640434 | validation: 0.31325346965278683]
	TIME [epoch: 5.73 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10107899531884677		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.10107899531884677 | validation: 0.2944734707768924]
	TIME [epoch: 5.74 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10178698254458755		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.10178698254458755 | validation: 0.2924365506222526]
	TIME [epoch: 5.77 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10322440120980592		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.10322440120980592 | validation: 0.2884672869781928]
	TIME [epoch: 5.74 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10096610888490541		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.10096610888490541 | validation: 0.276390130102012]
	TIME [epoch: 5.74 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09765860054508335		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.09765860054508335 | validation: 0.2982215422357241]
	TIME [epoch: 5.74 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10484527654754908		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.10484527654754908 | validation: 0.27541487608005055]
	TIME [epoch: 5.74 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10819461156627705		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.10819461156627705 | validation: 0.2787809599318501]
	TIME [epoch: 5.74 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11608779976905917		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.11608779976905917 | validation: 0.2600336714350479]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_1099.pth
	Model improved!!!
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10564292026671249		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.10564292026671249 | validation: 0.2968383713001361]
	TIME [epoch: 5.76 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291047245371165		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.10291047245371165 | validation: 0.3070013484037346]
	TIME [epoch: 5.74 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10740441477330612		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.10740441477330612 | validation: 0.30325241008816134]
	TIME [epoch: 5.74 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1018998723211773		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.1018998723211773 | validation: 0.28899973640859117]
	TIME [epoch: 5.74 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10922297232845252		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.10922297232845252 | validation: 0.3078884454853272]
	TIME [epoch: 5.74 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11433171457180377		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.11433171457180377 | validation: 0.32200928988190014]
	TIME [epoch: 5.74 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11398694666512581		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.11398694666512581 | validation: 0.33512133632834873]
	TIME [epoch: 5.77 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11858426296454992		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.11858426296454992 | validation: 0.3257410931260986]
	TIME [epoch: 5.74 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11471713346926907		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.11471713346926907 | validation: 0.31394406547213966]
	TIME [epoch: 5.74 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10015981336825981		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.10015981336825981 | validation: 0.2852028675074467]
	TIME [epoch: 5.74 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1050210653105545		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.1050210653105545 | validation: 0.2954562791081043]
	TIME [epoch: 5.74 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09850704881473787		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.09850704881473787 | validation: 0.28808273733177947]
	TIME [epoch: 5.73 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10342873926466438		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.10342873926466438 | validation: 0.27551617468912026]
	TIME [epoch: 5.76 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10897448166530982		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.10897448166530982 | validation: 0.2858556866339127]
	TIME [epoch: 5.75 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10244322116483207		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.10244322116483207 | validation: 0.29161352525443457]
	TIME [epoch: 5.74 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10890157084962993		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.10890157084962993 | validation: 0.34239620234035456]
	TIME [epoch: 5.74 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11772188580550015		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.11772188580550015 | validation: 0.29343639671580063]
	TIME [epoch: 5.74 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0974689687312422		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.0974689687312422 | validation: 0.309495403142891]
	TIME [epoch: 5.73 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09737989795608214		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.09737989795608214 | validation: 0.30147997418934636]
	TIME [epoch: 5.74 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10054548077647421		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.10054548077647421 | validation: 0.29512966195257245]
	TIME [epoch: 5.77 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11162121576402621		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.11162121576402621 | validation: 0.27991614771783196]
	TIME [epoch: 5.74 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11540137439987114		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.11540137439987114 | validation: 0.2736779032251146]
	TIME [epoch: 5.74 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1148189744107414		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.1148189744107414 | validation: 0.33583567000061537]
	TIME [epoch: 5.74 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12735189355316623		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.12735189355316623 | validation: 0.3047335373887081]
	TIME [epoch: 5.74 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103588373756168		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.103588373756168 | validation: 0.29742783124861205]
	TIME [epoch: 5.74 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1101757254334989		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.1101757254334989 | validation: 0.3203823474100104]
	TIME [epoch: 5.76 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1055986781556634		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.1055986781556634 | validation: 0.29620520195160693]
	TIME [epoch: 5.75 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1045303389616472		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.1045303389616472 | validation: 0.3131018181080169]
	TIME [epoch: 5.74 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10998909763063315		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.10998909763063315 | validation: 0.2832122113587565]
	TIME [epoch: 5.74 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11135288818011055		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.11135288818011055 | validation: 0.3024329420266127]
	TIME [epoch: 5.74 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10342996085041574		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.10342996085041574 | validation: 0.2978090651364319]
	TIME [epoch: 5.74 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10270317724468156		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.10270317724468156 | validation: 0.28230343413302045]
	TIME [epoch: 5.74 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09508786375714526		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.09508786375714526 | validation: 0.29630224814996703]
	TIME [epoch: 5.77 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09874215230196591		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.09874215230196591 | validation: 0.32362324445796153]
	TIME [epoch: 5.74 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10745514763714387		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.10745514763714387 | validation: 0.33437936183456257]
	TIME [epoch: 5.74 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10374032881648398		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.10374032881648398 | validation: 0.2975727009137561]
	TIME [epoch: 5.74 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10461056447116487		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.10461056447116487 | validation: 0.3181809741492056]
	TIME [epoch: 5.74 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10372577367235175		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.10372577367235175 | validation: 0.3261544350177642]
	TIME [epoch: 5.74 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09619349181244226		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.09619349181244226 | validation: 0.30000344124018546]
	TIME [epoch: 5.77 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10023080089707617		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.10023080089707617 | validation: 0.33789471906761565]
	TIME [epoch: 5.75 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10945629364643852		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.10945629364643852 | validation: 0.3250791606222597]
	TIME [epoch: 5.74 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10006738049171295		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.10006738049171295 | validation: 0.3086533690466466]
	TIME [epoch: 5.74 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0951463507432066		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.0951463507432066 | validation: 0.29366787727948424]
	TIME [epoch: 5.74 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10539880551361541		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.10539880551361541 | validation: 0.28889724214811796]
	TIME [epoch: 5.74 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09878302130860911		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.09878302130860911 | validation: 0.29152361006372013]
	TIME [epoch: 5.74 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10191392570426146		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.10191392570426146 | validation: 0.33050654494306503]
	TIME [epoch: 5.78 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10391817201470618		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.10391817201470618 | validation: 0.3211086122826758]
	TIME [epoch: 5.74 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10131044067143664		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.10131044067143664 | validation: 0.33057131451768795]
	TIME [epoch: 5.74 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11104389511753562		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.11104389511753562 | validation: 0.30968040286621334]
	TIME [epoch: 5.74 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09839752470629894		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.09839752470629894 | validation: 0.3000560540535499]
	TIME [epoch: 5.74 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09326354678107575		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.09326354678107575 | validation: 0.308505335961811]
	TIME [epoch: 5.74 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10178384699550716		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.10178384699550716 | validation: 0.32650861078147325]
	TIME [epoch: 5.76 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10317694211422535		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.10317694211422535 | validation: 0.32136584801662793]
	TIME [epoch: 5.75 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10716646520073454		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.10716646520073454 | validation: 0.29889593846185225]
	TIME [epoch: 5.74 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10285675992626632		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.10285675992626632 | validation: 0.28724891686028864]
	TIME [epoch: 5.74 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09435294165012412		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.09435294165012412 | validation: 0.3022341895196983]
	TIME [epoch: 5.74 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10139480061104668		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.10139480061104668 | validation: 0.3516488260147124]
	TIME [epoch: 5.74 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294049273819523		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.11294049273819523 | validation: 0.30949543488694337]
	TIME [epoch: 5.74 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10041421491582116		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.10041421491582116 | validation: 0.31823611189691653]
	TIME [epoch: 5.78 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10205142992594553		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.10205142992594553 | validation: 0.3325107153294733]
	TIME [epoch: 5.74 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10002177926477923		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.10002177926477923 | validation: 0.3098804783489091]
	TIME [epoch: 5.74 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10705196064385297		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.10705196064385297 | validation: 0.31979560274999386]
	TIME [epoch: 5.74 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.110055502619371		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.110055502619371 | validation: 0.30889969961651065]
	TIME [epoch: 5.74 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10332071954878294		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.10332071954878294 | validation: 0.2967839607339069]
	TIME [epoch: 5.74 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09902344697813714		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.09902344697813714 | validation: 0.3177838020803324]
	TIME [epoch: 5.76 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09432206132288841		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.09432206132288841 | validation: 0.3131023366295046]
	TIME [epoch: 5.75 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10096830464972145		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.10096830464972145 | validation: 0.30657137138002993]
	TIME [epoch: 5.74 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10256552064949076		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.10256552064949076 | validation: 0.32637822201513605]
	TIME [epoch: 5.74 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10623865597058701		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.10623865597058701 | validation: 0.3259051689467555]
	TIME [epoch: 5.74 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09886480407254702		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.09886480407254702 | validation: 0.31253024626651477]
	TIME [epoch: 5.74 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09928850176697988		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.09928850176697988 | validation: 0.3025813636847511]
	TIME [epoch: 5.74 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037648294803212		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.1037648294803212 | validation: 0.3153083527145507]
	TIME [epoch: 5.77 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10317350926438386		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.10317350926438386 | validation: 0.304257229675055]
	TIME [epoch: 5.74 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09564351031157134		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.09564351031157134 | validation: 0.30804005447685756]
	TIME [epoch: 5.74 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.095654240231088		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.095654240231088 | validation: 0.30441578391203883]
	TIME [epoch: 5.74 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09226126070897289		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.09226126070897289 | validation: 0.28599771794592227]
	TIME [epoch: 5.74 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09555164441970773		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.09555164441970773 | validation: 0.2952353617015411]
	TIME [epoch: 5.74 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10549964390681293		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.10549964390681293 | validation: 0.30441729907974874]
	TIME [epoch: 5.76 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09591760044009823		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.09591760044009823 | validation: 0.3353225539128619]
	TIME [epoch: 5.75 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10089497790912749		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.10089497790912749 | validation: 0.3087845201470407]
	TIME [epoch: 5.74 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11064911227110844		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.11064911227110844 | validation: 0.33366235679335915]
	TIME [epoch: 5.74 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10138831689399806		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.10138831689399806 | validation: 0.3014524275126783]
	TIME [epoch: 5.74 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10151100137750112		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.10151100137750112 | validation: 0.297747353219131]
	TIME [epoch: 5.74 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09589080239275181		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.09589080239275181 | validation: 0.3074143267583595]
	TIME [epoch: 5.75 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11231238164116862		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.11231238164116862 | validation: 0.33451599642860624]
	TIME [epoch: 5.77 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12563436794527874		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.12563436794527874 | validation: 0.32278400324175627]
	TIME [epoch: 5.74 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104221960695427		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.1104221960695427 | validation: 0.3200405370067005]
	TIME [epoch: 5.74 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09883595047795475		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.09883595047795475 | validation: 0.27654423116271454]
	TIME [epoch: 5.74 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09868240381311176		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.09868240381311176 | validation: 0.29022914788401255]
	TIME [epoch: 5.74 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09471583664200273		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.09471583664200273 | validation: 0.28807702497889964]
	TIME [epoch: 5.74 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09644129438108404		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.09644129438108404 | validation: 0.30366478497994054]
	TIME [epoch: 5.77 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09764892416906686		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.09764892416906686 | validation: 0.30650196429370635]
	TIME [epoch: 5.75 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09536289863790964		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.09536289863790964 | validation: 0.3092722160015442]
	TIME [epoch: 5.74 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09193174082946992		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.09193174082946992 | validation: 0.3061723425446252]
	TIME [epoch: 5.74 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09817954154014918		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.09817954154014918 | validation: 0.30348373718265315]
	TIME [epoch: 5.74 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09331859475159313		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.09331859475159313 | validation: 0.3180090791235069]
	TIME [epoch: 5.74 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1007050571754553		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.1007050571754553 | validation: 0.30595149953358053]
	TIME [epoch: 5.75 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0988680266020396		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.0988680266020396 | validation: 0.31771549613865563]
	TIME [epoch: 5.76 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09919996209748214		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.09919996209748214 | validation: 0.33806085127155294]
	TIME [epoch: 5.74 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10092850608674434		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.10092850608674434 | validation: 0.31944146583813815]
	TIME [epoch: 5.74 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10269453600867799		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.10269453600867799 | validation: 0.34089189570097606]
	TIME [epoch: 5.74 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11261681998151318		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.11261681998151318 | validation: 0.3267538737669009]
	TIME [epoch: 5.74 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10456776437142319		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.10456776437142319 | validation: 0.3279199163103014]
	TIME [epoch: 5.74 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1063521510745482		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.1063521510745482 | validation: 0.33802468649476697]
	TIME [epoch: 5.77 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09924565902857159		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.09924565902857159 | validation: 0.3177453149678154]
	TIME [epoch: 5.74 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062556770082376		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.1062556770082376 | validation: 0.33221265646455833]
	TIME [epoch: 5.74 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11425727651847419		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.11425727651847419 | validation: 0.31915902875282903]
	TIME [epoch: 5.74 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10974610008118968		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.10974610008118968 | validation: 0.2998698304767362]
	TIME [epoch: 5.74 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11646318523873948		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.11646318523873948 | validation: 0.2951397858094771]
	TIME [epoch: 5.74 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1051789502203799		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.1051789502203799 | validation: 0.33396245250966744]
	TIME [epoch: 5.75 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09569148570258697		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.09569148570258697 | validation: 0.3102017278045899]
	TIME [epoch: 5.76 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09774476349830011		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.09774476349830011 | validation: 0.2962079523952675]
	TIME [epoch: 5.74 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09221940806873048		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.09221940806873048 | validation: 0.29866331715916633]
	TIME [epoch: 5.74 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926230578364645		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.09926230578364645 | validation: 0.2875360621495976]
	TIME [epoch: 5.74 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09910202952205943		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.09910202952205943 | validation: 0.29587191676522906]
	TIME [epoch: 5.74 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10342647768272072		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.10342647768272072 | validation: 0.2983281041957874]
	TIME [epoch: 5.74 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10174956184463094		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.10174956184463094 | validation: 0.289791528538766]
	TIME [epoch: 5.77 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09761124958185821		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.09761124958185821 | validation: 0.3148936191292119]
	TIME [epoch: 5.74 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09382504713135802		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.09382504713135802 | validation: 0.3028184498421912]
	TIME [epoch: 5.74 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09882065983412686		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.09882065983412686 | validation: 0.31314813682265663]
	TIME [epoch: 5.74 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10071509353971826		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.10071509353971826 | validation: 0.3109077408591558]
	TIME [epoch: 5.74 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09445941687169526		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.09445941687169526 | validation: 0.3079719175798032]
	TIME [epoch: 5.74 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356819166281087		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.09356819166281087 | validation: 0.30741908261078565]
	TIME [epoch: 5.75 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09617618224166535		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.09617618224166535 | validation: 0.2974123412074772]
	TIME [epoch: 5.77 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08889828020172463		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.08889828020172463 | validation: 0.28826846456161653]
	TIME [epoch: 5.74 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09413906814077846		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.09413906814077846 | validation: 0.29078293447188347]
	TIME [epoch: 5.74 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10158674033893335		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.10158674033893335 | validation: 0.2890664792957289]
	TIME [epoch: 5.74 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09178178378192		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.09178178378192 | validation: 0.2980923872263117]
	TIME [epoch: 5.74 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09554684460622721		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.09554684460622721 | validation: 0.31134692686911664]
	TIME [epoch: 5.74 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.092500475498912		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.092500475498912 | validation: 0.3219590951771458]
	TIME [epoch: 5.77 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09244519869791161		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.09244519869791161 | validation: 0.3132711521659045]
	TIME [epoch: 5.74 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10156248723698541		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.10156248723698541 | validation: 0.34212082084500517]
	TIME [epoch: 5.74 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10365441564023557		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.10365441564023557 | validation: 0.3304348110119848]
	TIME [epoch: 5.74 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1128384101648328		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.1128384101648328 | validation: 0.32749514563747717]
	TIME [epoch: 5.74 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10623672812232067		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.10623672812232067 | validation: 0.3144064248358171]
	TIME [epoch: 5.74 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10153917604288029		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.10153917604288029 | validation: 0.29163037025976274]
	TIME [epoch: 5.75 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09582007579462426		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.09582007579462426 | validation: 0.3052715858356664]
	TIME [epoch: 5.77 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09605496165543526		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.09605496165543526 | validation: 0.30665772741792774]
	TIME [epoch: 5.74 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09391581125405658		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.09391581125405658 | validation: 0.31880613063470437]
	TIME [epoch: 5.74 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0958193213401975		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.0958193213401975 | validation: 0.2948291214922122]
	TIME [epoch: 5.74 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09718673763830998		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.09718673763830998 | validation: 0.29754122399578825]
	TIME [epoch: 5.74 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09419940859113402		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.09419940859113402 | validation: 0.2843469929480702]
	TIME [epoch: 5.74 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08973787476691455		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.08973787476691455 | validation: 0.27443989789795153]
	TIME [epoch: 5.78 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09518544876413718		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.09518544876413718 | validation: 0.30287081735363713]
	TIME [epoch: 5.75 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09757418108290197		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.09757418108290197 | validation: 0.30191852249811646]
	TIME [epoch: 5.74 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10269449135728184		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.10269449135728184 | validation: 0.3204254883947911]
	TIME [epoch: 5.74 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10766366100821873		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.10766366100821873 | validation: 0.3077661044541939]
	TIME [epoch: 5.74 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09312346138441537		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.09312346138441537 | validation: 0.2922571756192583]
	TIME [epoch: 5.74 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09478692218789429		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.09478692218789429 | validation: 0.2748651148879081]
	TIME [epoch: 5.75 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0971384350163709		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.0971384350163709 | validation: 0.2784088400618186]
	TIME [epoch: 5.77 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10077383395530858		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.10077383395530858 | validation: 0.28219757190000844]
	TIME [epoch: 5.74 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10640280000457517		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.10640280000457517 | validation: 0.274312076210589]
	TIME [epoch: 5.74 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1007809162298704		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.1007809162298704 | validation: 0.2793994054820174]
	TIME [epoch: 5.74 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1069586965009471		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.1069586965009471 | validation: 0.27560081192543245]
	TIME [epoch: 5.74 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09433936341458873		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.09433936341458873 | validation: 0.29772050173147513]
	TIME [epoch: 5.74 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09614249686030092		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.09614249686030092 | validation: 0.2968338146970084]
	TIME [epoch: 5.77 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09881258959615763		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.09881258959615763 | validation: 0.31246952787159177]
	TIME [epoch: 5.75 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10542550821928709		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.10542550821928709 | validation: 0.3116702195275591]
	TIME [epoch: 5.74 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10139712024103338		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.10139712024103338 | validation: 0.2936185035372616]
	TIME [epoch: 5.74 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1035199043222567		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.1035199043222567 | validation: 0.27709068168947837]
	TIME [epoch: 5.74 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10140525611826055		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.10140525611826055 | validation: 0.30815524045161086]
	TIME [epoch: 5.74 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09748749619567823		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.09748749619567823 | validation: 0.2841957535669453]
	TIME [epoch: 5.76 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09792137490445152		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.09792137490445152 | validation: 0.2806300590473086]
	TIME [epoch: 5.75 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0908323227832596		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.0908323227832596 | validation: 0.294232868053321]
	TIME [epoch: 5.74 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09407949743617042		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.09407949743617042 | validation: 0.3281826125075441]
	TIME [epoch: 5.74 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1025143427577987		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.1025143427577987 | validation: 0.3256146650571386]
	TIME [epoch: 5.74 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09937897977168411		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.09937897977168411 | validation: 0.3304296777439935]
	TIME [epoch: 5.74 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10184539023152146		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.10184539023152146 | validation: 0.3256979242329677]
	TIME [epoch: 5.74 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993437566515159		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.09993437566515159 | validation: 0.3175969458086764]
	TIME [epoch: 5.78 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09614903059597799		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.09614903059597799 | validation: 0.3227830597955316]
	TIME [epoch: 5.74 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0980897909528059		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.0980897909528059 | validation: 0.30379800506917615]
	TIME [epoch: 5.74 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09262065106467464		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.09262065106467464 | validation: 0.29939217699099957]
	TIME [epoch: 5.74 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09685771729427713		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.09685771729427713 | validation: 0.30125349588019584]
	TIME [epoch: 5.74 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09756399451114649		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.09756399451114649 | validation: 0.30162397607430463]
	TIME [epoch: 5.74 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09862305314298482		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.09862305314298482 | validation: 0.2965261231280198]
	TIME [epoch: 5.77 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10172424052034258		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.10172424052034258 | validation: 0.2944975886886268]
	TIME [epoch: 5.75 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0974435916680636		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.0974435916680636 | validation: 0.27603583581646624]
	TIME [epoch: 5.74 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09544008460459069		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.09544008460459069 | validation: 0.2971997323234308]
	TIME [epoch: 5.74 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09405511580802026		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.09405511580802026 | validation: 0.28228976795763744]
	TIME [epoch: 5.74 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09551074435414308		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.09551074435414308 | validation: 0.29377880282093116]
	TIME [epoch: 5.74 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10087420970444518		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.10087420970444518 | validation: 0.3009864991831955]
	TIME [epoch: 5.74 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09652876009561825		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.09652876009561825 | validation: 0.30675798390572534]
	TIME [epoch: 5.78 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10089061032820174		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.10089061032820174 | validation: 0.277015328035198]
	TIME [epoch: 5.74 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10180791509261307		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.10180791509261307 | validation: 0.28955761012711295]
	TIME [epoch: 5.74 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10942525334952141		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.10942525334952141 | validation: 0.31138644962504075]
	TIME [epoch: 5.74 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11099888838474731		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.11099888838474731 | validation: 0.328144605466416]
	TIME [epoch: 5.74 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10345163216224537		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.10345163216224537 | validation: 0.3108891984515769]
	TIME [epoch: 5.74 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10815791871483645		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.10815791871483645 | validation: 0.31793481626176545]
	TIME [epoch: 5.76 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11870924654955232		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.11870924654955232 | validation: 0.32540461752921507]
	TIME [epoch: 5.75 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11111690573836963		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.11111690573836963 | validation: 0.30615110417183444]
	TIME [epoch: 5.74 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09986068325724967		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.09986068325724967 | validation: 0.2955223599290634]
	TIME [epoch: 5.74 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09754075165965317		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.09754075165965317 | validation: 0.30888967239961046]
	TIME [epoch: 5.74 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09412592661689571		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.09412592661689571 | validation: 0.3052762172883013]
	TIME [epoch: 5.74 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09493288852370788		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.09493288852370788 | validation: 0.3068430676013513]
	TIME [epoch: 5.74 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09310036321510966		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.09310036321510966 | validation: 0.31297467555921743]
	TIME [epoch: 5.78 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09726383437041608		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.09726383437041608 | validation: 0.3046351707382794]
	TIME [epoch: 5.74 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09218958748055896		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.09218958748055896 | validation: 0.304030415210619]
	TIME [epoch: 5.74 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09367191904712979		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.09367191904712979 | validation: 0.3075885804636789]
	TIME [epoch: 5.74 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09907091449802952		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.09907091449802952 | validation: 0.29151292248552946]
	TIME [epoch: 5.74 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10412009916421577		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.10412009916421577 | validation: 0.30275292908111306]
	TIME [epoch: 5.74 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10078920572288054		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.10078920572288054 | validation: 0.27454700313904246]
	TIME [epoch: 5.77 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09715291599648584		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.09715291599648584 | validation: 0.27020539839056074]
	TIME [epoch: 5.75 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09964472704919299		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.09964472704919299 | validation: 0.277520148471373]
	TIME [epoch: 5.74 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09671995830144611		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.09671995830144611 | validation: 0.31066505168896824]
	TIME [epoch: 5.74 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09396449439172097		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.09396449439172097 | validation: 0.2871880516025601]
	TIME [epoch: 5.74 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09393682288734334		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.09393682288734334 | validation: 0.28614170298210445]
	TIME [epoch: 5.74 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09526950341888468		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.09526950341888468 | validation: 0.278978755928429]
	TIME [epoch: 5.74 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09494066999990959		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.09494066999990959 | validation: 0.27923016810295226]
	TIME [epoch: 5.77 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09468521345652767		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.09468521345652767 | validation: 0.28295045409002684]
	TIME [epoch: 5.74 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09519085403708892		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.09519085403708892 | validation: 0.2781778828815891]
	TIME [epoch: 5.74 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09641015091647856		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.09641015091647856 | validation: 0.270491996043389]
	TIME [epoch: 5.74 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09235511089704913		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.09235511089704913 | validation: 0.28323939532065273]
	TIME [epoch: 5.74 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0941708011803444		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.0941708011803444 | validation: 0.28285248612240466]
	TIME [epoch: 5.74 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0983321084269691		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.0983321084269691 | validation: 0.2788047382881394]
	TIME [epoch: 5.76 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09629736125302844		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.09629736125302844 | validation: 0.28008325846885246]
	TIME [epoch: 5.75 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09486612520942037		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.09486612520942037 | validation: 0.28709567902567096]
	TIME [epoch: 5.74 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0956379419656552		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.0956379419656552 | validation: 0.2846388758556252]
	TIME [epoch: 5.74 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0972249793459517		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.0972249793459517 | validation: 0.267164444755336]
	TIME [epoch: 5.74 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09679528901238896		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.09679528901238896 | validation: 0.2659373652176177]
	TIME [epoch: 5.74 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10030729564695158		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.10030729564695158 | validation: 0.2623048431666448]
	TIME [epoch: 5.74 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09567102381685783		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.09567102381685783 | validation: 0.2744614692737057]
	TIME [epoch: 5.78 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0960107638502523		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.0960107638502523 | validation: 0.2846874182772355]
	TIME [epoch: 5.74 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09422910701133996		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.09422910701133996 | validation: 0.2953533082857881]
	TIME [epoch: 5.74 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09680154727320314		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.09680154727320314 | validation: 0.30315588412539063]
	TIME [epoch: 5.74 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09848682302844654		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.09848682302844654 | validation: 0.30012144593486006]
	TIME [epoch: 5.74 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09845387639080941		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.09845387639080941 | validation: 0.29987836460985917]
	TIME [epoch: 5.74 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09703798084449113		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.09703798084449113 | validation: 0.3041265462077454]
	TIME [epoch: 5.77 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09394761295187506		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.09394761295187506 | validation: 0.300900085106158]
	TIME [epoch: 5.75 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09607707641264371		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.09607707641264371 | validation: 0.31174733406213917]
	TIME [epoch: 5.74 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.094293668788792		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.094293668788792 | validation: 0.2896664255786693]
	TIME [epoch: 5.74 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09391622944662598		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.09391622944662598 | validation: 0.29556274027038204]
	TIME [epoch: 5.74 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09285501360806164		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.09285501360806164 | validation: 0.28035326074939965]
	TIME [epoch: 5.74 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09545388257762497		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.09545388257762497 | validation: 0.2987937066390979]
	TIME [epoch: 5.75 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08917441621068038		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.08917441621068038 | validation: 0.30966427445585226]
	TIME [epoch: 5.77 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09089372551139929		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.09089372551139929 | validation: 0.3099361317055998]
	TIME [epoch: 5.74 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09598202784468847		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.09598202784468847 | validation: 0.3095066380684315]
	TIME [epoch: 5.74 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09689850701489876		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.09689850701489876 | validation: 0.293436161424229]
	TIME [epoch: 5.74 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09365941468545741		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.09365941468545741 | validation: 0.30462321259987496]
	TIME [epoch: 5.74 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09439790149524535		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.09439790149524535 | validation: 0.3078317067180932]
	TIME [epoch: 5.74 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0901538062748882		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.0901538062748882 | validation: 0.30269970905964555]
	TIME [epoch: 5.77 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09013071316022493		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.09013071316022493 | validation: 0.29574080012527015]
	TIME [epoch: 5.75 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09341268820167362		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.09341268820167362 | validation: 0.2911836188943826]
	TIME [epoch: 5.74 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09381427770323261		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.09381427770323261 | validation: 0.2865310619410017]
	TIME [epoch: 5.74 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09559993708538612		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.09559993708538612 | validation: 0.2961993924593419]
	TIME [epoch: 5.74 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09031935854752238		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.09031935854752238 | validation: 0.29827442037734136]
	TIME [epoch: 5.74 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0957728604834206		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.0957728604834206 | validation: 0.31762581619678243]
	TIME [epoch: 5.75 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09242013017500512		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.09242013017500512 | validation: 0.2893301426452112]
	TIME [epoch: 5.77 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09374019152879048		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.09374019152879048 | validation: 0.30144038561157355]
	TIME [epoch: 5.74 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09659186099241246		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.09659186099241246 | validation: 0.29641138247087123]
	TIME [epoch: 5.74 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09414241728470693		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.09414241728470693 | validation: 0.31484550778874004]
	TIME [epoch: 5.74 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09442920291107715		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.09442920291107715 | validation: 0.3078105789782985]
	TIME [epoch: 5.74 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09290193210378496		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.09290193210378496 | validation: 0.30852618478168325]
	TIME [epoch: 5.74 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09561278144411062		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.09561278144411062 | validation: 0.29036200269474527]
	TIME [epoch: 5.77 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09536714234522946		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.09536714234522946 | validation: 0.2916896749990678]
	TIME [epoch: 5.74 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09262094509116207		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.09262094509116207 | validation: 0.2890807526642971]
	TIME [epoch: 5.74 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09586985835083939		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.09586985835083939 | validation: 0.29022279823975716]
	TIME [epoch: 5.74 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09280642095657897		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.09280642095657897 | validation: 0.29236210149156316]
	TIME [epoch: 5.74 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08953312462419948		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.08953312462419948 | validation: 0.2842436342795382]
	TIME [epoch: 5.74 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09372869764320928		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.09372869764320928 | validation: 0.287650414779132]
	TIME [epoch: 5.75 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.095129105625512		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.095129105625512 | validation: 0.30495639100840427]
	TIME [epoch: 5.76 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09061967523508643		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.09061967523508643 | validation: 0.29575814088674446]
	TIME [epoch: 5.74 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0919424875866398		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.0919424875866398 | validation: 0.2953360278659594]
	TIME [epoch: 5.74 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09091798123653191		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.09091798123653191 | validation: 0.29808897948253166]
	TIME [epoch: 5.74 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09412027528846646		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.09412027528846646 | validation: 0.30436634979557525]
	TIME [epoch: 5.74 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1008995645308794		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.1008995645308794 | validation: 0.30582620007101907]
	TIME [epoch: 5.74 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1033347991720468		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.1033347991720468 | validation: 0.3003649923213014]
	TIME [epoch: 5.77 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09477387511890578		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.09477387511890578 | validation: 0.30180998583120994]
	TIME [epoch: 5.75 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09243753302132247		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.09243753302132247 | validation: 0.29075179618415825]
	TIME [epoch: 5.74 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09050147448209686		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.09050147448209686 | validation: 0.2912812815034579]
	TIME [epoch: 5.74 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09271578239255879		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.09271578239255879 | validation: 0.29307091684267145]
	TIME [epoch: 5.74 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10118559762249463		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.10118559762249463 | validation: 0.29399398997649623]
	TIME [epoch: 5.74 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09762412510379118		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.09762412510379118 | validation: 0.29627225523294415]
	TIME [epoch: 5.75 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09580717228601326		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.09580717228601326 | validation: 0.29232284264903674]
	TIME [epoch: 5.76 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09540677347806398		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.09540677347806398 | validation: 0.29622432116299174]
	TIME [epoch: 5.74 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10007690880457216		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.10007690880457216 | validation: 0.2933002295186136]
	TIME [epoch: 5.74 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09565766427174834		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.09565766427174834 | validation: 0.291955570181294]
	TIME [epoch: 5.74 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.091368522716824		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.091368522716824 | validation: 0.28111234057673856]
	TIME [epoch: 5.74 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09027381262901965		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.09027381262901965 | validation: 0.29131720030317754]
	TIME [epoch: 5.74 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09521395193713723		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.09521395193713723 | validation: 0.3144865900487666]
	TIME [epoch: 5.77 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09759885477411531		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.09759885477411531 | validation: 0.2947113367869792]
	TIME [epoch: 5.74 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967873365153244		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.0967873365153244 | validation: 0.2870124792812447]
	TIME [epoch: 5.74 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08949685989133092		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.08949685989133092 | validation: 0.2881314176021019]
	TIME [epoch: 5.74 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09171486528258065		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.09171486528258065 | validation: 0.2806381498558552]
	TIME [epoch: 5.74 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08840547831544006		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.08840547831544006 | validation: 0.2891845282670709]
	TIME [epoch: 5.74 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09026858109726418		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.09026858109726418 | validation: 0.29061403286189125]
	TIME [epoch: 5.75 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09367021351642153		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.09367021351642153 | validation: 0.2924885411772315]
	TIME [epoch: 5.76 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0885844217753538		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.0885844217753538 | validation: 0.2677499750067549]
	TIME [epoch: 5.74 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0905941988930093		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.0905941988930093 | validation: 0.27474680813526187]
	TIME [epoch: 5.74 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09146341735357313		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.09146341735357313 | validation: 0.2796411636060979]
	TIME [epoch: 5.74 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09363250801776501		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.09363250801776501 | validation: 0.28999745250437187]
	TIME [epoch: 5.74 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09736688946539346		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.09736688946539346 | validation: 0.3058094890269515]
	TIME [epoch: 5.74 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09522651564847354		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.09522651564847354 | validation: 0.27235686491313954]
	TIME [epoch: 5.77 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09006071204552026		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.09006071204552026 | validation: 0.28940090911190547]
	TIME [epoch: 5.74 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08820454085622745		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.08820454085622745 | validation: 0.2939018011958]
	TIME [epoch: 5.74 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0969212973979862		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.0969212973979862 | validation: 0.2935209680932886]
	TIME [epoch: 5.74 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09041829111305452		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.09041829111305452 | validation: 0.29517034407638454]
	TIME [epoch: 5.74 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08966548430093653		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.08966548430093653 | validation: 0.277752029956619]
	TIME [epoch: 5.74 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09630879211623093		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.09630879211623093 | validation: 0.29462214115132707]
	TIME [epoch: 5.76 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.094576500095869		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.094576500095869 | validation: 0.2946341812365175]
	TIME [epoch: 5.75 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0884727563638356		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.0884727563638356 | validation: 0.28860332492119556]
	TIME [epoch: 5.74 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09127074708637518		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.09127074708637518 | validation: 0.29180606091525507]
	TIME [epoch: 5.74 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08904022444276358		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.08904022444276358 | validation: 0.2774774194129997]
	TIME [epoch: 5.74 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08771531219353867		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.08771531219353867 | validation: 0.2856139925919984]
	TIME [epoch: 5.74 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08955541630987299		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.08955541630987299 | validation: 0.28082768112817635]
	TIME [epoch: 5.74 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09107941077424667		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.09107941077424667 | validation: 0.2809946579703479]
	TIME [epoch: 5.77 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09507211464308739		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.09507211464308739 | validation: 0.29114888012032003]
	TIME [epoch: 5.74 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09264544372220437		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.09264544372220437 | validation: 0.30424965804441945]
	TIME [epoch: 5.74 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0911762343844011		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.0911762343844011 | validation: 0.2994320337293584]
	TIME [epoch: 5.74 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08991054600159708		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.08991054600159708 | validation: 0.2941015343756335]
	TIME [epoch: 5.73 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0948141845495637		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.0948141845495637 | validation: 0.29549621325814807]
	TIME [epoch: 5.74 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0925786579634594		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.0925786579634594 | validation: 0.2991481774250687]
	TIME [epoch: 5.76 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08912414043168444		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.08912414043168444 | validation: 0.29528250525952554]
	TIME [epoch: 5.75 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09083503134596677		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.09083503134596677 | validation: 0.30246997512261964]
	TIME [epoch: 5.74 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09020532871794737		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.09020532871794737 | validation: 0.2856625722293872]
	TIME [epoch: 5.74 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09392768810224972		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.09392768810224972 | validation: 0.2705428130654293]
	TIME [epoch: 5.74 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09059694317716822		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.09059694317716822 | validation: 0.2567444088633765]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_1415.pth
	Model improved!!!
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09854951059407964		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.09854951059407964 | validation: 0.27485176041873177]
	TIME [epoch: 5.74 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967481485056298		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.0967481485056298 | validation: 0.2808736928585248]
	TIME [epoch: 5.77 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10155904990851661		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.10155904990851661 | validation: 0.27325614183276636]
	TIME [epoch: 5.74 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09503757555841318		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.09503757555841318 | validation: 0.25621858736911574]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_1419.pth
	Model improved!!!
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09455870855640838		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.09455870855640838 | validation: 0.26884839357782825]
	TIME [epoch: 5.74 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09339016258674829		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.09339016258674829 | validation: 0.27469166293851954]
	TIME [epoch: 5.73 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09121417911197852		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.09121417911197852 | validation: 0.28142925394566276]
	TIME [epoch: 5.74 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0947352684635596		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.0947352684635596 | validation: 0.28592215294605267]
	TIME [epoch: 5.77 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09604857290370059		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.09604857290370059 | validation: 0.28301061690366264]
	TIME [epoch: 5.74 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09080222802658884		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.09080222802658884 | validation: 0.28310155125285974]
	TIME [epoch: 5.74 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0950057659949812		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.0950057659949812 | validation: 0.2939041030188712]
	TIME [epoch: 5.74 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09227211274538559		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.09227211274538559 | validation: 0.2796148988869253]
	TIME [epoch: 5.74 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09463611549121931		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.09463611549121931 | validation: 0.2939962048533941]
	TIME [epoch: 5.74 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09407388367522602		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.09407388367522602 | validation: 0.2895440960048693]
	TIME [epoch: 5.75 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09271341685483868		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.09271341685483868 | validation: 0.27556406596936134]
	TIME [epoch: 5.77 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0953517790156007		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.0953517790156007 | validation: 0.2764350812280197]
	TIME [epoch: 5.74 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09502239277609936		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.09502239277609936 | validation: 0.27057899009312836]
	TIME [epoch: 5.74 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0961999884752256		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.0961999884752256 | validation: 0.27812474338194126]
	TIME [epoch: 5.73 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09894519569682748		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.09894519569682748 | validation: 0.26922941223047664]
	TIME [epoch: 5.73 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09480694007896473		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.09480694007896473 | validation: 0.26225199350957706]
	TIME [epoch: 5.73 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09367396209487172		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.09367396209487172 | validation: 0.2567412742277792]
	TIME [epoch: 5.77 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09401433445512099		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.09401433445512099 | validation: 0.25000467848320845]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240310_003040/states/model_tr_study1_1437.pth
	Model improved!!!
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0970584321491852		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.0970584321491852 | validation: 0.2710436935080686]
	TIME [epoch: 5.74 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09517038630860347		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.09517038630860347 | validation: 0.25825248669802947]
	TIME [epoch: 5.74 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09603158219769042		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.09603158219769042 | validation: 0.2733454157229946]
	TIME [epoch: 5.74 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089807086578717		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.089807086578717 | validation: 0.2738673964255839]
	TIME [epoch: 5.74 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09580775812187334		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.09580775812187334 | validation: 0.26015305479998757]
	TIME [epoch: 5.76 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0937339413724656		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.0937339413724656 | validation: 0.2607509908049155]
	TIME [epoch: 5.75 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09216161638547225		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.09216161638547225 | validation: 0.2761278082141636]
	TIME [epoch: 5.74 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09375086611280883		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.09375086611280883 | validation: 0.267765062589724]
	TIME [epoch: 5.74 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09634349934538933		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.09634349934538933 | validation: 0.25097370253661366]
	TIME [epoch: 5.74 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09415023669529389		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.09415023669529389 | validation: 0.2612683264200751]
	TIME [epoch: 5.74 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09094518902695158		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.09094518902695158 | validation: 0.26035339515111683]
	TIME [epoch: 5.74 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09055804868448605		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.09055804868448605 | validation: 0.26288148842016534]
	TIME [epoch: 5.78 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10045022435065479		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.10045022435065479 | validation: 0.26753520897956956]
	TIME [epoch: 5.74 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09245069269255568		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.09245069269255568 | validation: 0.26575842286554585]
	TIME [epoch: 5.74 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09357840829033579		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.09357840829033579 | validation: 0.27611353513322323]
	TIME [epoch: 5.74 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09435795863714008		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.09435795863714008 | validation: 0.28336777711819766]
	TIME [epoch: 5.74 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09318875730966308		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.09318875730966308 | validation: 0.2879742089929774]
	TIME [epoch: 5.74 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0919449091716511		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.0919449091716511 | validation: 0.285878119603027]
	TIME [epoch: 5.76 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09517179791563493		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.09517179791563493 | validation: 0.2852777269129539]
	TIME [epoch: 5.75 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0924112565588982		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.0924112565588982 | validation: 0.276611609960536]
	TIME [epoch: 5.74 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0927395039543817		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.0927395039543817 | validation: 0.29176107450522887]
	TIME [epoch: 5.74 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09147545312338155		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.09147545312338155 | validation: 0.2836249381694589]
	TIME [epoch: 5.74 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09618679594684995		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.09618679594684995 | validation: 0.2831677792275146]
	TIME [epoch: 5.74 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09418147509326624		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.09418147509326624 | validation: 0.2913790560316458]
	TIME [epoch: 5.74 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09172439568753943		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.09172439568753943 | validation: 0.29536275834064535]
	TIME [epoch: 5.78 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08584193985068128		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.08584193985068128 | validation: 0.26219773495982807]
	TIME [epoch: 5.74 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0914637353874031		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.0914637353874031 | validation: 0.27547510622745164]
	TIME [epoch: 5.74 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08940804255162564		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.08940804255162564 | validation: 0.2730639600953446]
	TIME [epoch: 5.74 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0916740594432865		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.0916740594432865 | validation: 0.28382042664981777]
	TIME [epoch: 5.74 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0922536835500554		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.0922536835500554 | validation: 0.2766773124885322]
	TIME [epoch: 5.74 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.097779005814588		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.097779005814588 | validation: 0.2998802492465515]
	TIME [epoch: 5.76 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09620776079946644		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.09620776079946644 | validation: 0.2838810467806771]
	TIME [epoch: 5.75 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909437903764618		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.0909437903764618 | validation: 0.2909145151742653]
	TIME [epoch: 5.74 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09099489356251238		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.09099489356251238 | validation: 0.2862137894945865]
	TIME [epoch: 5.74 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0889380451619296		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.0889380451619296 | validation: 0.28316655238016275]
	TIME [epoch: 5.74 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08884570556358437		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.08884570556358437 | validation: 0.2824554544293702]
	TIME [epoch: 5.74 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08983121946742079		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.08983121946742079 | validation: 0.2918142477855291]
	TIME [epoch: 5.74 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08948676510323385		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.08948676510323385 | validation: 0.28599186978690094]
	TIME [epoch: 5.78 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09080360695191741		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.09080360695191741 | validation: 0.2857539088769687]
	TIME [epoch: 5.74 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08910562958890841		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.08910562958890841 | validation: 0.2763437604338338]
	TIME [epoch: 5.74 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08684095862604092		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.08684095862604092 | validation: 0.27379968537447724]
	TIME [epoch: 5.74 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09043222958006561		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.09043222958006561 | validation: 0.285647524720716]
	TIME [epoch: 5.74 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08841064549328545		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.08841064549328545 | validation: 0.27178281475068816]
	TIME [epoch: 5.74 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0945818013899537		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.0945818013899537 | validation: 0.2821622787095217]
	TIME [epoch: 5.77 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08849239340852336		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.08849239340852336 | validation: 0.281576373752106]
	TIME [epoch: 5.75 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09012289020436504		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.09012289020436504 | validation: 0.28101194554812714]
	TIME [epoch: 5.75 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08858961254686462		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.08858961254686462 | validation: 0.2830412093697002]
	TIME [epoch: 5.75 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09381909940815344		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.09381909940815344 | validation: 0.2884828797948135]
	TIME [epoch: 5.75 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09666908669788704		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.09666908669788704 | validation: 0.29305012980267314]
	TIME [epoch: 5.75 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09676001480027223		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.09676001480027223 | validation: 0.3136838790710067]
	TIME [epoch: 5.76 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08944468092094993		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.08944468092094993 | validation: 0.2837903008549073]
	TIME [epoch: 5.77 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09125003187005089		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.09125003187005089 | validation: 0.291925628174271]
	TIME [epoch: 5.75 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09329041598499926		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.09329041598499926 | validation: 0.28583932666479744]
	TIME [epoch: 5.75 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0951539527441302		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.0951539527441302 | validation: 0.2912069520367246]
	TIME [epoch: 5.75 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09721260826068126		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.09721260826068126 | validation: 0.2863424447835471]
	TIME [epoch: 5.75 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08913169350142279		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.08913169350142279 | validation: 0.26324767536742477]
	TIME [epoch: 5.75 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09444730200105728		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.09444730200105728 | validation: 0.28404204653427556]
	TIME [epoch: 5.78 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09341431495862836		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.09341431495862836 | validation: 0.27191489633380006]
	TIME [epoch: 5.75 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09051128295048189		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.09051128295048189 | validation: 0.2909172218646763]
	TIME [epoch: 5.75 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09412407126129797		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.09412407126129797 | validation: 0.26464536015941653]
	TIME [epoch: 5.75 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09175626201397145		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.09175626201397145 | validation: 0.28605753925789007]
	TIME [epoch: 5.74 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09402367752963654		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.09402367752963654 | validation: 0.2741160623210566]
	TIME [epoch: 5.74 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08911850259353987		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.08911850259353987 | validation: 0.2673607710663145]
	TIME [epoch: 5.76 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09485148125717036		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.09485148125717036 | validation: 0.27720499463302783]
	TIME [epoch: 5.77 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09407796913025562		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.09407796913025562 | validation: 0.28148451292063154]
	TIME [epoch: 5.75 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09150946247150915		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.09150946247150915 | validation: 0.2800446513381166]
	TIME [epoch: 5.74 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09002239009915008		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.09002239009915008 | validation: 0.29333177529982474]
	TIME [epoch: 5.75 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08928933588699348		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.08928933588699348 | validation: 0.2933138618504378]
	TIME [epoch: 5.74 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09118669365663716		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.09118669365663716 | validation: 0.2807949879598584]
	TIME [epoch: 5.75 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09180013407902654		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.09180013407902654 | validation: 0.2859656194118877]
	TIME [epoch: 5.78 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09134383946621183		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.09134383946621183 | validation: 0.26974755215106494]
	TIME [epoch: 5.75 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09442528954939253		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.09442528954939253 | validation: 0.27526052903539777]
	TIME [epoch: 5.75 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0926506780749639		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.0926506780749639 | validation: 0.28064576475581604]
	TIME [epoch: 5.74 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08938312399361661		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.08938312399361661 | validation: 0.2916194603010773]
	TIME [epoch: 5.75 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09409893558451676		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.09409893558451676 | validation: 0.28580512636603816]
	TIME [epoch: 5.75 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09488255035900815		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.09488255035900815 | validation: 0.28416511863874316]
	TIME [epoch: 5.76 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09023447573125026		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.09023447573125026 | validation: 0.28282238553455746]
	TIME [epoch: 5.77 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09100883217283265		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.09100883217283265 | validation: 0.2848821756781797]
	TIME [epoch: 5.75 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0938325160470879		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.0938325160470879 | validation: 0.2843059005783098]
	TIME [epoch: 5.75 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944882266445922		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.0944882266445922 | validation: 0.28213305835368985]
	TIME [epoch: 5.75 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0941988993972663		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.0941988993972663 | validation: 0.2694698397333174]
	TIME [epoch: 5.75 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09300725698679234		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.09300725698679234 | validation: 0.2729244235872111]
	TIME [epoch: 5.75 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0923576293702383		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.0923576293702383 | validation: 0.2762982348246208]
	TIME [epoch: 5.78 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09119866548940404		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.09119866548940404 | validation: 0.2735855334098837]
	TIME [epoch: 5.75 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09394750214908924		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.09394750214908924 | validation: 0.2695656784118378]
	TIME [epoch: 5.75 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09509090989093952		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.09509090989093952 | validation: 0.26556477081452046]
	TIME [epoch: 5.75 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09165112292491873		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.09165112292491873 | validation: 0.2671819097947211]
	TIME [epoch: 5.75 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09089907054896541		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.09089907054896541 | validation: 0.2693877797344134]
	TIME [epoch: 5.74 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09101128264350511		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.09101128264350511 | validation: 0.2774670570331724]
	TIME [epoch: 5.76 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09044903661475995		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.09044903661475995 | validation: 0.2754836291940639]
	TIME [epoch: 5.77 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.091473178508502		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.091473178508502 | validation: 0.26789813947883945]
	TIME [epoch: 5.75 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09136348551070689		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.09136348551070689 | validation: 0.2820305463328227]
	TIME [epoch: 5.75 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09274156798799366		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.09274156798799366 | validation: 0.28030034977531165]
	TIME [epoch: 5.75 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0914639166073233		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.0914639166073233 | validation: 0.27238574281057903]
	TIME [epoch: 5.74 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08929431969658273		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.08929431969658273 | validation: 0.270605855670964]
	TIME [epoch: 5.75 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915341068300211		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.0915341068300211 | validation: 0.27619021445654585]
	TIME [epoch: 5.78 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08405174092822187		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.08405174092822187 | validation: 0.2798385245383575]
	TIME [epoch: 5.75 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0916598437852055		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.0916598437852055 | validation: 0.27378775062618255]
	TIME [epoch: 5.75 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0837748072669766		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.0837748072669766 | validation: 0.2874505527353319]
	TIME [epoch: 5.74 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08909058560451374		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.08909058560451374 | validation: 0.297673334130565]
	TIME [epoch: 5.74 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09245086602476196		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.09245086602476196 | validation: 0.3024805309177133]
	TIME [epoch: 5.74 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09395351152798626		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.09395351152798626 | validation: 0.29136561651672066]
	TIME [epoch: 5.77 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08885947113085943		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.08885947113085943 | validation: 0.3004674309916158]
	TIME [epoch: 5.76 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09474008139404881		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.09474008139404881 | validation: 0.3083231481594555]
	TIME [epoch: 5.75 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09094333646575499		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.09094333646575499 | validation: 0.30063626255224685]
	TIME [epoch: 5.75 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09306740733157973		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.09306740733157973 | validation: 0.29048306875630386]
	TIME [epoch: 5.75 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08960032320215053		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.08960032320215053 | validation: 0.2835291698733139]
	TIME [epoch: 5.75 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09036494131949908		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.09036494131949908 | validation: 0.29271518861899265]
	TIME [epoch: 5.75 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09447299780373757		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.09447299780373757 | validation: 0.2941466536309746]
	TIME [epoch: 5.78 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08678062292769101		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.08678062292769101 | validation: 0.28956188690007734]
	TIME [epoch: 5.75 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08911407216441328		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.08911407216441328 | validation: 0.2864633840554261]
	TIME [epoch: 5.75 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09546036663952072		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.09546036663952072 | validation: 0.28534086054510094]
	TIME [epoch: 5.75 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08684245835784433		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.08684245835784433 | validation: 0.2864182894842449]
	TIME [epoch: 5.75 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09123157923113356		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.09123157923113356 | validation: 0.3100569779398172]
	TIME [epoch: 5.75 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09754051783220238		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.09754051783220238 | validation: 0.296847775295433]
	TIME [epoch: 5.77 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09267656553690781		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.09267656553690781 | validation: 0.2948154712453561]
	TIME [epoch: 5.76 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09341933476283652		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.09341933476283652 | validation: 0.28394607352140455]
	TIME [epoch: 5.75 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08904515936168612		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.08904515936168612 | validation: 0.2791797436115066]
	TIME [epoch: 5.75 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08572698959299424		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.08572698959299424 | validation: 0.28747170831483126]
	TIME [epoch: 5.75 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08801521184705813		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.08801521184705813 | validation: 0.28148634160434555]
	TIME [epoch: 5.75 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09129996148088146		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.09129996148088146 | validation: 0.28120742462489384]
	TIME [epoch: 5.75 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08975852751895334		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.08975852751895334 | validation: 0.27540478511008304]
	TIME [epoch: 5.79 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08854517167885814		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.08854517167885814 | validation: 0.2781008644102543]
	TIME [epoch: 5.75 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09297107966851635		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.09297107966851635 | validation: 0.28918253042244796]
	TIME [epoch: 5.75 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0887894216152966		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.0887894216152966 | validation: 0.2731620715611055]
	TIME [epoch: 5.75 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09079424350792963		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.09079424350792963 | validation: 0.28211672457748466]
	TIME [epoch: 5.75 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09112515478276093		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.09112515478276093 | validation: 0.28747970796943534]
	TIME [epoch: 5.75 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0879979447837897		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.0879979447837897 | validation: 0.2919052455420473]
	TIME [epoch: 5.77 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09196907530121982		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.09196907530121982 | validation: 0.2752606164763098]
	TIME [epoch: 5.76 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09318845940272774		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.09318845940272774 | validation: 0.2831867662020897]
	TIME [epoch: 5.75 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08780758026297339		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.08780758026297339 | validation: 0.2926821459568045]
	TIME [epoch: 5.75 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09131639376968925		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.09131639376968925 | validation: 0.2881572209178732]
	TIME [epoch: 5.75 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08921561957365835		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.08921561957365835 | validation: 0.2924050776156107]
	TIME [epoch: 5.75 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08900932849888968		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.08900932849888968 | validation: 0.28247745767307214]
	TIME [epoch: 5.75 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0893867288992457		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.0893867288992457 | validation: 0.2851589128688108]
	TIME [epoch: 5.78 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08555667914001375		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.08555667914001375 | validation: 0.2843530446061199]
	TIME [epoch: 5.75 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08886750619963815		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.08886750619963815 | validation: 0.28983667793276363]
	TIME [epoch: 5.75 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08620533798194935		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.08620533798194935 | validation: 0.2870501175582961]
	TIME [epoch: 5.75 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0907384825446709		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.0907384825446709 | validation: 0.2906603914582276]
	TIME [epoch: 5.75 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09115135873719206		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.09115135873719206 | validation: 0.28924368606818013]
	TIME [epoch: 5.75 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08960972767541307		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.08960972767541307 | validation: 0.27968677772276423]
	TIME [epoch: 5.78 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09374533377648657		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.09374533377648657 | validation: 0.2777771681237036]
	TIME [epoch: 5.75 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09407750999318572		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.09407750999318572 | validation: 0.28900912300603254]
	TIME [epoch: 5.75 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09150860441637348		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.09150860441637348 | validation: 0.2867208917146575]
	TIME [epoch: 5.75 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09203055488339704		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.09203055488339704 | validation: 0.2899137339645276]
	TIME [epoch: 5.75 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09287334257667894		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.09287334257667894 | validation: 0.29530863614557623]
	TIME [epoch: 5.75 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09076981417142968		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.09076981417142968 | validation: 0.29087073770652466]
	TIME [epoch: 5.76 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08624957613966816		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.08624957613966816 | validation: 0.2949284623922367]
	TIME [epoch: 5.77 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08693025794058577		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.08693025794058577 | validation: 0.2938450084406224]
	TIME [epoch: 5.75 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08875090976017197		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.08875090976017197 | validation: 0.2833874866862113]
	TIME [epoch: 5.75 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0907700502701378		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.0907700502701378 | validation: 0.3046535751452834]
	TIME [epoch: 5.75 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08908552835927254		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.08908552835927254 | validation: 0.2989547763787911]
	TIME [epoch: 5.75 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09427145801475748		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.09427145801475748 | validation: 0.2890970095952756]
	TIME [epoch: 5.75 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09180270359488826		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.09180270359488826 | validation: 0.2857752051224822]
	TIME [epoch: 5.78 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08847098151315749		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.08847098151315749 | validation: 0.28205955061288956]
	TIME [epoch: 5.75 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08702734199903123		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.08702734199903123 | validation: 0.28928688772385025]
	TIME [epoch: 5.75 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08745843298654592		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.08745843298654592 | validation: 0.2752407476523054]
	TIME [epoch: 5.75 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08839886705142737		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.08839886705142737 | validation: 0.2922609623059365]
	TIME [epoch: 5.75 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0880012425524349		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.0880012425524349 | validation: 0.2842493129250127]
	TIME [epoch: 5.74 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08916800315031154		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.08916800315031154 | validation: 0.2855875341728583]
	TIME [epoch: 5.76 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09340281716982139		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.09340281716982139 | validation: 0.2723356915915956]
	TIME [epoch: 5.77 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09224395691529416		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.09224395691529416 | validation: 0.27187089909199297]
	TIME [epoch: 5.75 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09203130446893029		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.09203130446893029 | validation: 0.28932614811297813]
	TIME [epoch: 5.75 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09000680504214661		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.09000680504214661 | validation: 0.2885306921524379]
	TIME [epoch: 5.75 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08806854454402673		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.08806854454402673 | validation: 0.285497329279237]
	TIME [epoch: 5.75 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888838785859782		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.0888838785859782 | validation: 0.28401586477394525]
	TIME [epoch: 5.75 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08594183093255185		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.08594183093255185 | validation: 0.28771177236398704]
	TIME [epoch: 5.78 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09052861294474643		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.09052861294474643 | validation: 0.28147252187207433]
	TIME [epoch: 5.75 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09433140520308843		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.09433140520308843 | validation: 0.2883903075263244]
	TIME [epoch: 5.75 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09240165962466322		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.09240165962466322 | validation: 0.28407075495762]
	TIME [epoch: 5.75 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08493373146414754		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.08493373146414754 | validation: 0.27609098470313215]
	TIME [epoch: 5.75 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08896711520524775		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.08896711520524775 | validation: 0.2788806902213543]
	TIME [epoch: 5.75 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08652187014367518		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.08652187014367518 | validation: 0.2770281125258574]
	TIME [epoch: 5.76 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08907548685215172		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.08907548685215172 | validation: 0.2839171758858045]
	TIME [epoch: 5.77 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09149390583197282		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.09149390583197282 | validation: 0.2830195222453605]
	TIME [epoch: 5.75 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0875978557594456		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.0875978557594456 | validation: 0.2634491901493533]
	TIME [epoch: 5.75 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08559146937836448		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.08559146937836448 | validation: 0.27738050249912405]
	TIME [epoch: 5.74 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915775765530124		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.0915775765530124 | validation: 0.27580048464507595]
	TIME [epoch: 5.75 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0898356438579671		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.0898356438579671 | validation: 0.28184320835718857]
	TIME [epoch: 5.75 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08929223270716713		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.08929223270716713 | validation: 0.28304406749192096]
	TIME [epoch: 5.78 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09036854787908892		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.09036854787908892 | validation: 0.27779176000226474]
	TIME [epoch: 5.75 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0905052608625777		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.0905052608625777 | validation: 0.2757487413073135]
	TIME [epoch: 5.75 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08867564360669519		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.08867564360669519 | validation: 0.289784911889754]
	TIME [epoch: 5.75 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08920002501000902		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.08920002501000902 | validation: 0.26450884601619423]
	TIME [epoch: 5.75 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0886279205130058		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.0886279205130058 | validation: 0.28015977567516404]
	TIME [epoch: 5.75 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08820482248637546		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.08820482248637546 | validation: 0.2752969269641175]
	TIME [epoch: 5.77 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08984309210927965		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.08984309210927965 | validation: 0.2878688538089858]
	TIME [epoch: 5.76 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08827551173704473		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.08827551173704473 | validation: 0.28149550633469494]
	TIME [epoch: 5.75 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09078423342368107		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.09078423342368107 | validation: 0.2722828039788454]
	TIME [epoch: 5.75 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09160445378420931		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.09160445378420931 | validation: 0.28443167592983043]
	TIME [epoch: 5.75 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08844288608280201		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.08844288608280201 | validation: 0.27508938901577173]
	TIME [epoch: 5.75 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08945312058936894		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.08945312058936894 | validation: 0.28253066185825043]
	TIME [epoch: 5.75 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08709868264327242		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.08709868264327242 | validation: 0.2946437253860456]
	TIME [epoch: 5.78 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09024541342391648		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.09024541342391648 | validation: 0.2784719156321798]
	TIME [epoch: 5.75 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08973770467705308		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.08973770467705308 | validation: 0.2653083132996222]
	TIME [epoch: 5.75 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.087215551826885		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.087215551826885 | validation: 0.26958531890031734]
	TIME [epoch: 5.75 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08929128054707738		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.08929128054707738 | validation: 0.2800851666840509]
	TIME [epoch: 5.75 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0862633929270901		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.0862633929270901 | validation: 0.27609665202228756]
	TIME [epoch: 5.75 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09066251854209685		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.09066251854209685 | validation: 0.2798917857130668]
	TIME [epoch: 5.77 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09108176248321209		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.09108176248321209 | validation: 0.2737429145715724]
	TIME [epoch: 5.76 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188092478894781		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.09188092478894781 | validation: 0.28640839286946523]
	TIME [epoch: 5.75 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08742620452806843		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.08742620452806843 | validation: 0.2770233875854037]
	TIME [epoch: 5.75 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09040106814264198		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.09040106814264198 | validation: 0.26512591283817655]
	TIME [epoch: 5.75 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08843062138509354		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.08843062138509354 | validation: 0.2808991623254116]
	TIME [epoch: 5.75 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09214486392663641		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.09214486392663641 | validation: 0.27488487193238476]
	TIME [epoch: 5.75 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08957570753629954		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.08957570753629954 | validation: 0.2946543587596979]
	TIME [epoch: 5.78 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08471508314229619		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.08471508314229619 | validation: 0.28675161868977045]
	TIME [epoch: 5.75 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0925830118950987		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.0925830118950987 | validation: 0.2806752005864631]
	TIME [epoch: 5.75 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08363137052672864		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.08363137052672864 | validation: 0.2850114960968642]
	TIME [epoch: 5.75 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09182402229794431		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.09182402229794431 | validation: 0.2873915469693716]
	TIME [epoch: 5.75 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09050435866506881		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.09050435866506881 | validation: 0.28795628371870036]
	TIME [epoch: 5.75 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.088546690313996		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.088546690313996 | validation: 0.28504135272954767]
	TIME [epoch: 5.77 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08655841880613135		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.08655841880613135 | validation: 0.29130350320363985]
	TIME [epoch: 5.75 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08891884570041239		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.08891884570041239 | validation: 0.286631493070535]
	TIME [epoch: 5.75 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915446169366223		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.0915446169366223 | validation: 0.2863875773597545]
	TIME [epoch: 5.74 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08810881810671095		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.08810881810671095 | validation: 0.27766733635237756]
	TIME [epoch: 5.74 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09117308355645888		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.09117308355645888 | validation: 0.27784178716290225]
	TIME [epoch: 5.75 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0878440115540719		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.0878440115540719 | validation: 0.28436355491871856]
	TIME [epoch: 5.75 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09046136741101309		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.09046136741101309 | validation: 0.27280921937231645]
	TIME [epoch: 5.77 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09070167464544807		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.09070167464544807 | validation: 0.29582751726377987]
	TIME [epoch: 5.75 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09277461233005357		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.09277461233005357 | validation: 0.2858084416238271]
	TIME [epoch: 5.74 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08844304176236123		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.08844304176236123 | validation: 0.29640182962713485]
	TIME [epoch: 5.74 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08925717658463321		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.08925717658463321 | validation: 0.2841264715305265]
	TIME [epoch: 5.74 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08908192716823321		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.08908192716823321 | validation: 0.2895414484583327]
	TIME [epoch: 5.74 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09415157971298956		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.09415157971298956 | validation: 0.28530867535212134]
	TIME [epoch: 5.78 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08968158320785626		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.08968158320785626 | validation: 0.2828752926862378]
	TIME [epoch: 5.75 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08862936217801076		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.08862936217801076 | validation: 0.28954874799322583]
	TIME [epoch: 5.74 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09315207807518378		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.09315207807518378 | validation: 0.27883690699249025]
	TIME [epoch: 5.74 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08708093193631193		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.08708093193631193 | validation: 0.2844983595733507]
	TIME [epoch: 5.74 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08772600437520557		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.08772600437520557 | validation: 0.27512860443998366]
	TIME [epoch: 5.74 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08683250869004887		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.08683250869004887 | validation: 0.276190676640728]
	TIME [epoch: 5.75 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08922142656520851		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.08922142656520851 | validation: 0.27961565147905787]
	TIME [epoch: 5.77 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08681715896872058		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.08681715896872058 | validation: 0.2847396863085883]
	TIME [epoch: 5.75 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09245389972645869		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.09245389972645869 | validation: 0.27569889878076065]
	TIME [epoch: 5.74 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08889755245886302		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.08889755245886302 | validation: 0.29038548993731705]
	TIME [epoch: 5.74 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0926768398612732		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.0926768398612732 | validation: 0.2863286899322101]
	TIME [epoch: 5.74 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09285871873501937		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.09285871873501937 | validation: 0.2878407764071636]
	TIME [epoch: 5.75 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09263010616307578		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.09263010616307578 | validation: 0.27872464866830177]
	TIME [epoch: 5.78 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09139981479780912		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.09139981479780912 | validation: 0.26885454964730643]
	TIME [epoch: 5.75 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0874196621583918		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.0874196621583918 | validation: 0.2688148598595532]
	TIME [epoch: 5.75 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09218440015180615		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.09218440015180615 | validation: 0.26585810519668235]
	TIME [epoch: 5.74 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09119494290112092		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.09119494290112092 | validation: 0.2645811137576209]
	TIME [epoch: 5.74 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09039247636225543		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.09039247636225543 | validation: 0.26250929621518587]
	TIME [epoch: 5.74 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08890200429024468		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.08890200429024468 | validation: 0.2687327335735284]
	TIME [epoch: 5.76 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08926972212069663		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.08926972212069663 | validation: 0.26900254268247614]
	TIME [epoch: 5.77 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09072665957493785		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.09072665957493785 | validation: 0.26889776384215575]
	TIME [epoch: 5.75 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08980576655592913		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.08980576655592913 | validation: 0.2749235496489839]
	TIME [epoch: 5.74 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08974704590167251		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.08974704590167251 | validation: 0.27273060084462725]
	TIME [epoch: 5.75 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08940370384351431		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.08940370384351431 | validation: 0.29098028455817876]
	TIME [epoch: 5.75 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08838425486063392		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.08838425486063392 | validation: 0.26396292376883107]
	TIME [epoch: 5.75 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08908067052230927		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.08908067052230927 | validation: 0.2739657581985144]
	TIME [epoch: 5.78 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831962684254668		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.08831962684254668 | validation: 0.27327262556240933]
	TIME [epoch: 5.75 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09019720863102823		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.09019720863102823 | validation: 0.2770968600893508]
	TIME [epoch: 5.75 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09093810889551568		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.09093810889551568 | validation: 0.2724491998810867]
	TIME [epoch: 5.75 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08680733964410742		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.08680733964410742 | validation: 0.28615320488355805]
	TIME [epoch: 5.75 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09205416374880546		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.09205416374880546 | validation: 0.2646434689127698]
	TIME [epoch: 5.74 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0921692122265213		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.0921692122265213 | validation: 0.2681498463850929]
	TIME [epoch: 5.77 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08855561692157676		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.08855561692157676 | validation: 0.2790853837751254]
	TIME [epoch: 5.76 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09027577004616172		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.09027577004616172 | validation: 0.29209452432562666]
	TIME [epoch: 5.75 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08783657976247045		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.08783657976247045 | validation: 0.26553247970101407]
	TIME [epoch: 5.75 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08650286165368828		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.08650286165368828 | validation: 0.2725454339346207]
	TIME [epoch: 5.74 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08762102346814796		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.08762102346814796 | validation: 0.28313771175443847]
	TIME [epoch: 5.74 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09140343832927511		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.09140343832927511 | validation: 0.278212628253405]
	TIME [epoch: 5.74 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08680206652435958		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.08680206652435958 | validation: 0.2703801451052131]
	TIME [epoch: 5.78 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08951772926230718		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.08951772926230718 | validation: 0.2795183728062363]
	TIME [epoch: 5.75 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08789000261859879		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.08789000261859879 | validation: 0.2714833671793572]
	TIME [epoch: 5.74 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08720545241034686		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.08720545241034686 | validation: 0.27637716177740934]
	TIME [epoch: 5.74 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09045059425888016		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.09045059425888016 | validation: 0.2787920889830467]
	TIME [epoch: 5.74 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08968981208153812		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.08968981208153812 | validation: 0.288193121649482]
	TIME [epoch: 5.74 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08671174154132213		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.08671174154132213 | validation: 0.27236867264428827]
	TIME [epoch: 5.77 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08800274023172981		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.08800274023172981 | validation: 0.27583280607598254]
	TIME [epoch: 5.76 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08424731116423646		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.08424731116423646 | validation: 0.2768240879793699]
	TIME [epoch: 5.75 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09085739666248491		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.09085739666248491 | validation: 0.27812068440984894]
	TIME [epoch: 5.75 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08542177410027198		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.08542177410027198 | validation: 0.2831855642269669]
	TIME [epoch: 5.74 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08698149777224871		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.08698149777224871 | validation: 0.26540348055132723]
	TIME [epoch: 5.74 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09231570062717596		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.09231570062717596 | validation: 0.2809205146556504]
	TIME [epoch: 5.74 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08767052601862879		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.08767052601862879 | validation: 0.27463115254856474]
	TIME [epoch: 5.78 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08890317338187623		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.08890317338187623 | validation: 0.26080081412542183]
	TIME [epoch: 5.75 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08986882854097726		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.08986882854097726 | validation: 0.2847496868440245]
	TIME [epoch: 5.74 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08881607066581401		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.08881607066581401 | validation: 0.2814416080082252]
	TIME [epoch: 5.74 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08834739173350362		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.08834739173350362 | validation: 0.2800920646269336]
	TIME [epoch: 5.74 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08861899887234574		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.08861899887234574 | validation: 0.2902061628121275]
	TIME [epoch: 5.74 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08456985357834389		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.08456985357834389 | validation: 0.27458345820163405]
	TIME [epoch: 5.77 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0858152729270634		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.0858152729270634 | validation: 0.26898776267227237]
	TIME [epoch: 5.76 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09048912088895031		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.09048912088895031 | validation: 0.28254014509785513]
	TIME [epoch: 5.75 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0906897124094859		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.0906897124094859 | validation: 0.2741453782183682]
	TIME [epoch: 5.74 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883624344852162		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.0883624344852162 | validation: 0.2713240611127831]
	TIME [epoch: 5.74 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08531826530753017		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.08531826530753017 | validation: 0.2797916976961917]
	TIME [epoch: 5.75 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08577255931245566		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.08577255931245566 | validation: 0.27713444813812366]
	TIME [epoch: 5.74 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08557870633844687		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.08557870633844687 | validation: 0.28654379479889974]
	TIME [epoch: 5.78 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08928085909649511		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.08928085909649511 | validation: 0.2845122900594973]
	TIME [epoch: 5.75 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08424734364564754		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.08424734364564754 | validation: 0.28404932088388063]
	TIME [epoch: 5.74 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08743171200625541		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.08743171200625541 | validation: 0.278501828340228]
	TIME [epoch: 5.74 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09324559744522262		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.09324559744522262 | validation: 0.27480252269009486]
	TIME [epoch: 5.74 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09222124670675493		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.09222124670675493 | validation: 0.2901279537054316]
	TIME [epoch: 5.74 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08627354363724413		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.08627354363724413 | validation: 0.28352246478975135]
	TIME [epoch: 5.78 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909247347731755		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.0909247347731755 | validation: 0.2745288189280403]
	TIME [epoch: 5.75 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0869356920139737		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.0869356920139737 | validation: 0.28665576815824806]
	TIME [epoch: 5.74 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08447754340812644		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.08447754340812644 | validation: 0.282105632759889]
	TIME [epoch: 5.74 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08950248555952076		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.08950248555952076 | validation: 0.2910841435630787]
	TIME [epoch: 5.74 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08740504019162879		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.08740504019162879 | validation: 0.2865876481482115]
	TIME [epoch: 5.74 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08764714742032763		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.08764714742032763 | validation: 0.2854558635933832]
	TIME [epoch: 5.76 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08576346147739829		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.08576346147739829 | validation: 0.2853056207389751]
	TIME [epoch: 5.77 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08582559074455946		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.08582559074455946 | validation: 0.2787985789878114]
	TIME [epoch: 5.74 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09249705365264252		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.09249705365264252 | validation: 0.2753607034253322]
	TIME [epoch: 5.74 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08592546359611852		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.08592546359611852 | validation: 0.28750562454559936]
	TIME [epoch: 5.74 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08801918686570968		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.08801918686570968 | validation: 0.26721964134853865]
	TIME [epoch: 5.74 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08729928207998247		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.08729928207998247 | validation: 0.2749626305559969]
	TIME [epoch: 5.74 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08816161238684736		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.08816161238684736 | validation: 0.2790434616076055]
	TIME [epoch: 5.78 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0917313131722782		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.0917313131722782 | validation: 0.270220485752922]
	TIME [epoch: 5.75 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08955154194794598		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.08955154194794598 | validation: 0.26691137553607913]
	TIME [epoch: 5.74 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0876398209584424		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.0876398209584424 | validation: 0.2712623618820573]
	TIME [epoch: 5.74 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08544009911283684		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.08544009911283684 | validation: 0.26513169559253275]
	TIME [epoch: 5.74 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08685981010147034		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.08685981010147034 | validation: 0.27953208659879564]
	TIME [epoch: 5.74 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08806230638825549		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.08806230638825549 | validation: 0.2683327902087925]
	TIME [epoch: 5.75 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09060281836759145		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.09060281836759145 | validation: 0.2786965736483415]
	TIME [epoch: 5.77 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08821766085159033		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.08821766085159033 | validation: 0.26953041484165263]
	TIME [epoch: 5.75 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08959862644483665		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.08959862644483665 | validation: 0.26848784531137143]
	TIME [epoch: 5.74 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.086586288494981		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.086586288494981 | validation: 0.26496363562776076]
	TIME [epoch: 5.74 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08834330732867801		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.08834330732867801 | validation: 0.2663518234908683]
	TIME [epoch: 5.74 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08799380908551237		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.08799380908551237 | validation: 0.2706257252975686]
	TIME [epoch: 5.74 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08786650671351462		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.08786650671351462 | validation: 0.26775666227222467]
	TIME [epoch: 5.78 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08687743487213422		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.08687743487213422 | validation: 0.26156602209306834]
	TIME [epoch: 5.75 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08678692882398126		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.08678692882398126 | validation: 0.2698556899152877]
	TIME [epoch: 5.74 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08812058945546294		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.08812058945546294 | validation: 0.2748126354377207]
	TIME [epoch: 5.74 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0899698750887443		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.0899698750887443 | validation: 0.25980961216580867]
	TIME [epoch: 5.75 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09043200439254268		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.09043200439254268 | validation: 0.2759949818027879]
	TIME [epoch: 5.75 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09088059762156143		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.09088059762156143 | validation: 0.2699347660208063]
	TIME [epoch: 5.76 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09179780342240935		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.09179780342240935 | validation: 0.2656812179228568]
	TIME [epoch: 5.77 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0898525895020782		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.0898525895020782 | validation: 0.2719717392658197]
	TIME [epoch: 5.75 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08839986419345258		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.08839986419345258 | validation: 0.26484436909611836]
	TIME [epoch: 5.74 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09401094234966136		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.09401094234966136 | validation: 0.27047315742093464]
	TIME [epoch: 5.74 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08954911581351284		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.08954911581351284 | validation: 0.2703673259347443]
	TIME [epoch: 5.74 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08909806193862121		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.08909806193862121 | validation: 0.27237916084800673]
	TIME [epoch: 5.74 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08893311288548504		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.08893311288548504 | validation: 0.2643942741982579]
	TIME [epoch: 5.78 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08838826011722647		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.08838826011722647 | validation: 0.2655523803516522]
	TIME [epoch: 5.75 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09213882113142424		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.09213882113142424 | validation: 0.27108138391408765]
	TIME [epoch: 5.75 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08601435179227483		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.08601435179227483 | validation: 0.2523269439153659]
	TIME [epoch: 5.74 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08314955933093529		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.08314955933093529 | validation: 0.26404931275116555]
	TIME [epoch: 5.74 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08902935972944352		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.08902935972944352 | validation: 0.26861183049528004]
	TIME [epoch: 5.74 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08789037938051672		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.08789037938051672 | validation: 0.2742419328571176]
	TIME [epoch: 5.77 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08812508898941418		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.08812508898941418 | validation: 0.27578460621472084]
	TIME [epoch: 5.76 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08632846948923634		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.08632846948923634 | validation: 0.28702768917462157]
	TIME [epoch: 5.75 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924038997034607		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.08924038997034607 | validation: 0.2763099963576098]
	TIME [epoch: 5.74 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08921620217345752		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.08921620217345752 | validation: 0.2755383330317702]
	TIME [epoch: 5.74 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0849706908812834		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.0849706908812834 | validation: 0.27149409935550756]
	TIME [epoch: 5.74 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08763862985985373		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.08763862985985373 | validation: 0.2694644999454927]
	TIME [epoch: 5.74 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08657030567227991		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.08657030567227991 | validation: 0.2746163808123464]
	TIME [epoch: 5.78 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08727237296189237		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.08727237296189237 | validation: 0.2659554046012207]
	TIME [epoch: 5.75 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08808733025948559		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.08808733025948559 | validation: 0.27141357432307683]
	TIME [epoch: 5.74 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09195222205647424		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.09195222205647424 | validation: 0.27752311686140174]
	TIME [epoch: 5.74 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08935656431109688		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.08935656431109688 | validation: 0.2870403313075653]
	TIME [epoch: 5.74 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0901848899474675		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.0901848899474675 | validation: 0.2744855076451726]
	TIME [epoch: 5.74 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09109864852703435		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.09109864852703435 | validation: 0.27166211604416396]
	TIME [epoch: 5.77 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08882308992928088		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.08882308992928088 | validation: 0.2699521534630811]
	TIME [epoch: 5.76 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08805446174438321		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.08805446174438321 | validation: 0.2712217228855556]
	TIME [epoch: 5.75 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09065898164909003		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.09065898164909003 | validation: 0.27936545622431874]
	TIME [epoch: 5.74 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08342427560081853		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.08342427560081853 | validation: 0.27564883378156424]
	TIME [epoch: 5.74 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08979569291556648		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.08979569291556648 | validation: 0.27591240983777243]
	TIME [epoch: 5.74 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09017057983262651		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.09017057983262651 | validation: 0.2659269504410451]
	TIME [epoch: 5.74 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08664292236415143		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.08664292236415143 | validation: 0.27677106946271557]
	TIME [epoch: 5.78 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08850892384697376		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.08850892384697376 | validation: 0.2792050190496107]
	TIME [epoch: 5.75 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08623191180708703		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.08623191180708703 | validation: 0.2736572048934411]
	TIME [epoch: 5.74 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09158200986447326		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.09158200986447326 | validation: 0.27761027553783174]
	TIME [epoch: 5.74 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09060741828872393		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.09060741828872393 | validation: 0.2780289948856881]
	TIME [epoch: 5.74 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08901112780099171		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.08901112780099171 | validation: 0.28782779905798445]
	TIME [epoch: 5.74 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08757028032519154		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.08757028032519154 | validation: 0.2864924749094169]
	TIME [epoch: 5.77 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08883444095048487		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.08883444095048487 | validation: 0.2837924616299842]
	TIME [epoch: 5.75 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09088515991918104		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.09088515991918104 | validation: 0.2729099507621666]
	TIME [epoch: 5.74 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08774741716558544		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.08774741716558544 | validation: 0.2858678608822817]
	TIME [epoch: 5.74 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08260046412333111		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.08260046412333111 | validation: 0.2833932035926273]
	TIME [epoch: 5.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09015707185452501		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.09015707185452501 | validation: 0.2736192861160263]
	TIME [epoch: 5.74 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08855177887004366		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.08855177887004366 | validation: 0.2779810692179978]
	TIME [epoch: 5.75 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09172114333272938		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.09172114333272938 | validation: 0.2775069667995755]
	TIME [epoch: 5.77 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08966007490964759		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.08966007490964759 | validation: 0.28166121512342573]
	TIME [epoch: 5.74 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909443480913611		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.0909443480913611 | validation: 0.27968110609623675]
	TIME [epoch: 5.74 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08844049661504673		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.08844049661504673 | validation: 0.26705433178302396]
	TIME [epoch: 5.74 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08878078284718496		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.08878078284718496 | validation: 0.28825479963973133]
	TIME [epoch: 5.74 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08776506078293472		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.08776506078293472 | validation: 0.2775942500797536]
	TIME [epoch: 5.74 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08809401570992965		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.08809401570992965 | validation: 0.27801790159505696]
	TIME [epoch: 5.78 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08802964886881526		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.08802964886881526 | validation: 0.2706454695687506]
	TIME [epoch: 5.75 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08743859147735802		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.08743859147735802 | validation: 0.2751614361881892]
	TIME [epoch: 5.74 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08572676910657828		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.08572676910657828 | validation: 0.26933365069416304]
	TIME [epoch: 5.74 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08674860434576254		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.08674860434576254 | validation: 0.2832872063671109]
	TIME [epoch: 5.74 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08909358136374088		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.08909358136374088 | validation: 0.28029300228276]
	TIME [epoch: 5.74 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09039898033863508		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.09039898033863508 | validation: 0.29364621926412887]
	TIME [epoch: 5.75 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09203984108318639		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.09203984108318639 | validation: 0.2835519615467103]
	TIME [epoch: 5.77 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915658540424931		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.0915658540424931 | validation: 0.2808476167881104]
	TIME [epoch: 5.75 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08780137228082027		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.08780137228082027 | validation: 0.2788954797546623]
	TIME [epoch: 5.74 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08815806811455018		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.08815806811455018 | validation: 0.28445395185208566]
	TIME [epoch: 5.74 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08970885002741627		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.08970885002741627 | validation: 0.28743251382863866]
	TIME [epoch: 5.74 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08899155818268997		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.08899155818268997 | validation: 0.27783375476882816]
	TIME [epoch: 5.74 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0856813876228921		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.0856813876228921 | validation: 0.2721410617118698]
	TIME [epoch: 5.78 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09052079609010474		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.09052079609010474 | validation: 0.2759980205612124]
	TIME [epoch: 5.75 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08481536556494491		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.08481536556494491 | validation: 0.2737381750390616]
	TIME [epoch: 5.74 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08722974586562725		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.08722974586562725 | validation: 0.2829658054038106]
	TIME [epoch: 5.74 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08891008380360443		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.08891008380360443 | validation: 0.28344710006049817]
	TIME [epoch: 5.74 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08817385635542152		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.08817385635542152 | validation: 0.28792810467131236]
	TIME [epoch: 5.74 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09105974897545496		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.09105974897545496 | validation: 0.27819291313899536]
	TIME [epoch: 5.75 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0891093605828926		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.0891093605828926 | validation: 0.2849993536726491]
	TIME [epoch: 5.77 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08921132371410519		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.08921132371410519 | validation: 0.2838216918871215]
	TIME [epoch: 5.75 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09213434908689339		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.09213434908689339 | validation: 0.27296606061941214]
	TIME [epoch: 5.74 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08809219245601554		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.08809219245601554 | validation: 0.2888914898291704]
	TIME [epoch: 5.74 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09162010708534866		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.09162010708534866 | validation: 0.2796687173788394]
	TIME [epoch: 5.74 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08547692788616079		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.08547692788616079 | validation: 0.2807463421781874]
	TIME [epoch: 5.74 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08625471165037263		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.08625471165037263 | validation: 0.288992041104578]
	TIME [epoch: 5.77 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08973087649190675		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.08973087649190675 | validation: 0.277287782021754]
	TIME [epoch: 5.75 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08341858756284293		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.08341858756284293 | validation: 0.27139413091307957]
	TIME [epoch: 5.74 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08649841400332738		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.08649841400332738 | validation: 0.2731596077487279]
	TIME [epoch: 5.74 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08618514136988303		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.08618514136988303 | validation: 0.27538802034881393]
	TIME [epoch: 5.74 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08511664575493179		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.08511664575493179 | validation: 0.2795873162900476]
	TIME [epoch: 5.74 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08430008777905916		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.08430008777905916 | validation: 0.2824404950574552]
	TIME [epoch: 5.77 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08902027298745584		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.08902027298745584 | validation: 0.26507870949489354]
	TIME [epoch: 5.75 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08820088832071475		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.08820088832071475 | validation: 0.26756538639783173]
	TIME [epoch: 5.74 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08703716638950995		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.08703716638950995 | validation: 0.26530987809810824]
	TIME [epoch: 5.74 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831445202253252		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.08831445202253252 | validation: 0.270508480702908]
	TIME [epoch: 5.74 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08280903032097184		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.08280903032097184 | validation: 0.2817525804277062]
	TIME [epoch: 5.74 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08881183104142037		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.08881183104142037 | validation: 0.2807321114681446]
	TIME [epoch: 5.74 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08832549197372384		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.08832549197372384 | validation: 0.27379472100101526]
	TIME [epoch: 5.77 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08684701278813022		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.08684701278813022 | validation: 0.2611032566953712]
	TIME [epoch: 5.74 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08794344580788316		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.08794344580788316 | validation: 0.27879610391697873]
	TIME [epoch: 5.74 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08855879756469509		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.08855879756469509 | validation: 0.279434108331592]
	TIME [epoch: 5.74 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08710894848390395		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.08710894848390395 | validation: 0.26708630106626446]
	TIME [epoch: 5.74 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08422928776698402		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.08422928776698402 | validation: 0.2743739540066037]
	TIME [epoch: 5.74 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08979736036235203		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.08979736036235203 | validation: 0.280346686477516]
	TIME [epoch: 5.77 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08853378523584453		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.08853378523584453 | validation: 0.27044099015885986]
	TIME [epoch: 5.75 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08737008449826913		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.08737008449826913 | validation: 0.27920805465068826]
	TIME [epoch: 5.74 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08967448379374293		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.08967448379374293 | validation: 0.2835007186335848]
	TIME [epoch: 5.74 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08858360093419725		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.08858360093419725 | validation: 0.2792138112190876]
	TIME [epoch: 5.74 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08605751607438676		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.08605751607438676 | validation: 0.27848102697727856]
	TIME [epoch: 5.74 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08911528635911005		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.08911528635911005 | validation: 0.2707919692783532]
	TIME [epoch: 5.74 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08968069600770238		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.08968069600770238 | validation: 0.27597165676387747]
	TIME [epoch: 5.78 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08463626563029504		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.08463626563029504 | validation: 0.2744056039876608]
	TIME [epoch: 5.74 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0877003983126471		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.0877003983126471 | validation: 0.2808780852784761]
	TIME [epoch: 5.74 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08484790332402495		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.08484790332402495 | validation: 0.2718715486828699]
	TIME [epoch: 5.74 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09159772380997375		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.09159772380997375 | validation: 0.27433364580615344]
	TIME [epoch: 5.74 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08605686185119225		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.08605686185119225 | validation: 0.28697405907585377]
	TIME [epoch: 5.74 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08728448747936497		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.08728448747936497 | validation: 0.27929140568465416]
	TIME [epoch: 5.77 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08533590800465896		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.08533590800465896 | validation: 0.26565431830721503]
	TIME [epoch: 5.76 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08567456845901755		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.08567456845901755 | validation: 0.27247779847212933]
	TIME [epoch: 5.74 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883746008518877		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.0883746008518877 | validation: 0.27629303200246197]
	TIME [epoch: 5.74 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08526274889036083		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.08526274889036083 | validation: 0.2882065451485101]
	TIME [epoch: 5.74 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08795947937425332		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.08795947937425332 | validation: 0.2698448842740085]
	TIME [epoch: 5.74 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0898632703969379		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.0898632703969379 | validation: 0.2884585668753967]
	TIME [epoch: 5.74 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08930524731103814		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.08930524731103814 | validation: 0.2863302932986036]
	TIME [epoch: 5.78 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08839127202161753		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.08839127202161753 | validation: 0.27127754001083765]
	TIME [epoch: 5.74 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08826505139992225		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.08826505139992225 | validation: 0.26716659709906637]
	TIME [epoch: 5.74 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08537531908496329		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.08537531908496329 | validation: 0.27994009231009437]
	TIME [epoch: 5.74 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08847532057921534		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.08847532057921534 | validation: 0.2775875280074916]
	TIME [epoch: 5.74 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0857310769889566		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.0857310769889566 | validation: 0.2677656201142023]
	TIME [epoch: 5.74 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08521870964505529		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.08521870964505529 | validation: 0.2868540856694917]
	TIME [epoch: 5.77 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08509459289103047		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.08509459289103047 | validation: 0.26523684736768965]
	TIME [epoch: 5.75 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08666891473451414		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.08666891473451414 | validation: 0.2675058282311234]
	TIME [epoch: 5.74 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08599558636851136		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.08599558636851136 | validation: 0.276176349494286]
	TIME [epoch: 5.74 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08582360134039468		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.08582360134039468 | validation: 0.2696226014812992]
	TIME [epoch: 5.74 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08575500263880892		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.08575500263880892 | validation: 0.2755678705806787]
	TIME [epoch: 5.74 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0900477434095445		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.0900477434095445 | validation: 0.28048743014209465]
	TIME [epoch: 5.75 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08597169157080674		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.08597169157080674 | validation: 0.2746669492850036]
	TIME [epoch: 5.76 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08693999515856388		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.08693999515856388 | validation: 0.27438010948068076]
	TIME [epoch: 5.74 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08557595539801928		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.08557595539801928 | validation: 0.26975253726701226]
	TIME [epoch: 5.74 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08695225472063156		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.08695225472063156 | validation: 0.27163846748286485]
	TIME [epoch: 5.74 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08486052186918772		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.08486052186918772 | validation: 0.271806947222041]
	TIME [epoch: 5.74 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08642251560806663		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.08642251560806663 | validation: 0.26760819268710273]
	TIME [epoch: 5.74 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08850158514128728		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.08850158514128728 | validation: 0.268820182697139]
	TIME [epoch: 5.77 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08639516701786698		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.08639516701786698 | validation: 0.27443762907446917]
	TIME [epoch: 5.74 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08904097710068973		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.08904097710068973 | validation: 0.2695920115541663]
	TIME [epoch: 5.74 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08546426231564669		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.08546426231564669 | validation: 0.2773112626268977]
	TIME [epoch: 5.74 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08641819015470799		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.08641819015470799 | validation: 0.27367155197732823]
	TIME [epoch: 5.74 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08731188885020724		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.08731188885020724 | validation: 0.26701101269961725]
	TIME [epoch: 5.74 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09022837900293104		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.09022837900293104 | validation: 0.26926613429036184]
	TIME [epoch: 5.75 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0892497818960625		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.0892497818960625 | validation: 0.2693725797732462]
	TIME [epoch: 5.76 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08500115995483863		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.08500115995483863 | validation: 0.27895520219168074]
	TIME [epoch: 5.74 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08531376137600034		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.08531376137600034 | validation: 0.2722148651321992]
	TIME [epoch: 5.74 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09091964433567824		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.09091964433567824 | validation: 0.2716923656781219]
	TIME [epoch: 5.74 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08980696584819592		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.08980696584819592 | validation: 0.28263438760284787]
	TIME [epoch: 5.74 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08755342625871547		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.08755342625871547 | validation: 0.26922387629924305]
	TIME [epoch: 5.74 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08791790257756572		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.08791790257756572 | validation: 0.27615047225502376]
	TIME [epoch: 5.77 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08607891679730864		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.08607891679730864 | validation: 0.26951648969353376]
	TIME [epoch: 5.75 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08748836575163459		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.08748836575163459 | validation: 0.2656655217215987]
	TIME [epoch: 5.74 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08862104072249291		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.08862104072249291 | validation: 0.2664461145486817]
	TIME [epoch: 5.74 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08750545309876712		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.08750545309876712 | validation: 0.2817222008617859]
	TIME [epoch: 5.74 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08647153149821159		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.08647153149821159 | validation: 0.27059473087282776]
	TIME [epoch: 5.74 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09119579662084284		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.09119579662084284 | validation: 0.2706792957102211]
	TIME [epoch: 5.75 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08837814133562684		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.08837814133562684 | validation: 0.27691918650953135]
	TIME [epoch: 5.76 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0872341108934613		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.0872341108934613 | validation: 0.27356749963456245]
	TIME [epoch: 5.74 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888280876833515		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.0888280876833515 | validation: 0.28178640128246885]
	TIME [epoch: 5.74 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08843632635093777		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.08843632635093777 | validation: 0.26330614494323157]
	TIME [epoch: 5.74 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08312108036425969		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.08312108036425969 | validation: 0.27236764617484094]
	TIME [epoch: 5.74 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08687096932376004		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.08687096932376004 | validation: 0.2809666954328485]
	TIME [epoch: 5.74 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08865957086150773		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.08865957086150773 | validation: 0.27174369831655504]
	TIME [epoch: 5.77 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08770993824022891		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.08770993824022891 | validation: 0.2695855281976517]
	TIME [epoch: 5.74 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0885622026725359		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.0885622026725359 | validation: 0.26991309435864613]
	TIME [epoch: 5.74 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08814857028448123		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.08814857028448123 | validation: 0.2872477642418615]
	TIME [epoch: 5.74 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09005452409123216		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.09005452409123216 | validation: 0.2623317334827241]
	TIME [epoch: 5.74 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0876256714349766		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.0876256714349766 | validation: 0.27423751837795257]
	TIME [epoch: 5.74 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08906958047262149		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.08906958047262149 | validation: 0.2721539686885881]
	TIME [epoch: 5.76 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08699482596210839		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.08699482596210839 | validation: 0.2736860459215671]
	TIME [epoch: 5.75 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08972878247871571		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.08972878247871571 | validation: 0.27455684868961355]
	TIME [epoch: 5.74 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08789597363477428		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.08789597363477428 | validation: 0.27470444545823586]
	TIME [epoch: 5.74 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08409759632417108		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.08409759632417108 | validation: 0.26932570017539936]
	TIME [epoch: 5.74 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08656375573416666		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.08656375573416666 | validation: 0.269869270434235]
	TIME [epoch: 5.74 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08528209078614186		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.08528209078614186 | validation: 0.2727509345159995]
	TIME [epoch: 5.74 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08466640187770563		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.08466640187770563 | validation: 0.2757830103630955]
	TIME [epoch: 5.78 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08266001155756485		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.08266001155756485 | validation: 0.27866176292393535]
	TIME [epoch: 5.74 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08948866210713574		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.08948866210713574 | validation: 0.2781629859667752]
	TIME [epoch: 5.74 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09128724165642395		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.09128724165642395 | validation: 0.2697122938352544]
	TIME [epoch: 5.74 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08623106006339831		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.08623106006339831 | validation: 0.27502900026561183]
	TIME [epoch: 5.74 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08846241834064945		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.08846241834064945 | validation: 0.2814963425329711]
	TIME [epoch: 5.74 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08722610235442924		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.08722610235442924 | validation: 0.28454865432806337]
	TIME [epoch: 5.76 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08593483859142342		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.08593483859142342 | validation: 0.26088310350459476]
	TIME [epoch: 5.75 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09143397823327334		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.09143397823327334 | validation: 0.2831368846696221]
	TIME [epoch: 5.74 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08246846113763553		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.08246846113763553 | validation: 0.27738229979588114]
	TIME [epoch: 5.74 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08564877195326767		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.08564877195326767 | validation: 0.28446504445940696]
	TIME [epoch: 5.74 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08311092977615236		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.08311092977615236 | validation: 0.2779088858812337]
	TIME [epoch: 5.74 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08960526465002176		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.08960526465002176 | validation: 0.2808428090107277]
	TIME [epoch: 5.74 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08822311421403008		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.08822311421403008 | validation: 0.273664240902209]
	TIME [epoch: 5.77 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08522960473768668		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.08522960473768668 | validation: 0.27435783673621933]
	TIME [epoch: 5.74 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08667345719717245		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.08667345719717245 | validation: 0.28111216682676915]
	TIME [epoch: 5.74 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08653959028751752		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.08653959028751752 | validation: 0.2749065321318427]
	TIME [epoch: 5.74 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09117783814413066		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.09117783814413066 | validation: 0.2743330314536111]
	TIME [epoch: 5.74 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08496631443594703		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.08496631443594703 | validation: 0.27994968568317974]
	TIME [epoch: 5.74 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08849509551648578		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.08849509551648578 | validation: 0.287440129410771]
	TIME [epoch: 5.76 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08759365041992301		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.08759365041992301 | validation: 0.27577190988755784]
	TIME [epoch: 5.75 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08744437679850109		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.08744437679850109 | validation: 0.27447767410360024]
	TIME [epoch: 5.74 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08621495105715919		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.08621495105715919 | validation: 0.2855265442567377]
	TIME [epoch: 5.74 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08610515089645968		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.08610515089645968 | validation: 0.28236282754612146]
	TIME [epoch: 5.74 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08771303877382167		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.08771303877382167 | validation: 0.2762549587415509]
	TIME [epoch: 5.74 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08865441785172411		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.08865441785172411 | validation: 0.26818890468827666]
	TIME [epoch: 5.74 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08591058730345195		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.08591058730345195 | validation: 0.28078875870709885]
	TIME [epoch: 5.77 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08677006631773945		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.08677006631773945 | validation: 0.275347495365883]
	TIME [epoch: 5.74 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08581646750846939		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.08581646750846939 | validation: 0.2844311831132091]
	TIME [epoch: 5.74 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08755116714112422		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.08755116714112422 | validation: 0.27804472131404373]
	TIME [epoch: 5.74 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909810826277559		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.0909810826277559 | validation: 0.28652028784552186]
	TIME [epoch: 5.74 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08790253057106184		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.08790253057106184 | validation: 0.2839457589425624]
	TIME [epoch: 5.74 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08491105629910442		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.08491105629910442 | validation: 0.2826186890419132]
	TIME [epoch: 5.77 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08482726974146022		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.08482726974146022 | validation: 0.28019137820168555]
	TIME [epoch: 5.75 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08762162629387832		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.08762162629387832 | validation: 0.28186861649097184]
	TIME [epoch: 5.74 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08419405836421126		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.08419405836421126 | validation: 0.2752216270383249]
	TIME [epoch: 5.74 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08802472038587589		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.08802472038587589 | validation: 0.27799611599817164]
	TIME [epoch: 5.74 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0903937483118303		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.0903937483118303 | validation: 0.27666048482798833]
	TIME [epoch: 5.74 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09082817184089054		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.09082817184089054 | validation: 0.28703411653328786]
	TIME [epoch: 5.75 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08818103715974504		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.08818103715974504 | validation: 0.2872551439510074]
	TIME [epoch: 5.77 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08792680749246304		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.08792680749246304 | validation: 0.28846225900158756]
	TIME [epoch: 5.74 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08509680892039534		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.08509680892039534 | validation: 0.28371692873815363]
	TIME [epoch: 5.74 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08958567446204824		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.08958567446204824 | validation: 0.28266193333525397]
	TIME [epoch: 5.74 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0856093478349203		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.0856093478349203 | validation: 0.28788397943093974]
	TIME [epoch: 5.74 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09048421787417835		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.09048421787417835 | validation: 0.2719671225100986]
	TIME [epoch: 5.74 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08545774029376872		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.08545774029376872 | validation: 0.2777521470014562]
	TIME [epoch: 5.77 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08978610187587178		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.08978610187587178 | validation: 0.2722190629077176]
	TIME [epoch: 5.74 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08715229452645311		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.08715229452645311 | validation: 0.2840857196841823]
	TIME [epoch: 5.74 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08727111802006925		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.08727111802006925 | validation: 0.27540291502924186]
	TIME [epoch: 5.74 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08728222461999743		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.08728222461999743 | validation: 0.2788664380659167]
	TIME [epoch: 5.74 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0919513484456591		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.0919513484456591 | validation: 0.27973967452431353]
	TIME [epoch: 5.74 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08895784889091016		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.08895784889091016 | validation: 0.2797902224927828]
	TIME [epoch: 5.75 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08563710875879993		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.08563710875879993 | validation: 0.27971777318516244]
	TIME [epoch: 5.76 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09005513570690718		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.09005513570690718 | validation: 0.29071194039289394]
	TIME [epoch: 5.74 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08964275602356307		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.08964275602356307 | validation: 0.27544757337029496]
	TIME [epoch: 5.74 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09047269530169677		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.09047269530169677 | validation: 0.2692369833509652]
	TIME [epoch: 5.74 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08794054340246399		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.08794054340246399 | validation: 0.2813646128724508]
	TIME [epoch: 5.74 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08455668758669159		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.08455668758669159 | validation: 0.2780946049624922]
	TIME [epoch: 5.74 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0875890613216476		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.0875890613216476 | validation: 0.2841010411816567]
	TIME [epoch: 5.78 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08513488816836645		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.08513488816836645 | validation: 0.2865329933547532]
	TIME [epoch: 5.75 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08463311973513572		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.08463311973513572 | validation: 0.2856483710736301]
	TIME [epoch: 5.74 sec]
Finished training in 11758.555 seconds.
