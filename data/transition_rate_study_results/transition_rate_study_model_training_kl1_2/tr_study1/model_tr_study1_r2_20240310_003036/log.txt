Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r2', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4224207111

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.173480907668974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.173480907668974 | validation: 10.31775878172387]
	TIME [epoch: 82.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.66556096175704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.66556096175704 | validation: 9.090497291233689]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.595829193282288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.595829193282288 | validation: 8.873251528737754]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.708668574950439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.708668574950439 | validation: 9.042557292096967]
	TIME [epoch: 6.48 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.915742769152676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.915742769152676 | validation: 8.158414498844463]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.661761364510053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.661761364510053 | validation: 7.2288554626651464]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.154255708891386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.154255708891386 | validation: 7.886174764072309]
	TIME [epoch: 6.44 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.91100756175777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.91100756175777 | validation: 7.1480416278982375]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.581921845789745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.581921845789745 | validation: 6.833422819965183]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.260758107408009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.260758107408009 | validation: 6.518797004600183]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.205885098756043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.205885098756043 | validation: 6.507019009510934]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.33158928481897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.33158928481897 | validation: 6.544976210737368]
	TIME [epoch: 6.46 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.274991947153275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.274991947153275 | validation: 6.285229947666184]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.973097063525699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.973097063525699 | validation: 6.161307785995823]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.773746600751306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.773746600751306 | validation: 5.912425405873567]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6656342335778795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6656342335778795 | validation: 6.152579691945991]
	TIME [epoch: 6.46 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.650784313214174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.650784313214174 | validation: 6.224885163499298]
	TIME [epoch: 6.47 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.588703096771752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.588703096771752 | validation: 5.921253456396933]
	TIME [epoch: 6.46 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.487009048770745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.487009048770745 | validation: 6.351132396741466]
	TIME [epoch: 6.45 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.543091658379153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.543091658379153 | validation: 5.864842862489186]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.368850661446912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.368850661446912 | validation: 5.7535928927790065]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.424513229810197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.424513229810197 | validation: 6.067643377111099]
	TIME [epoch: 6.44 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6220534402208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6220534402208 | validation: 5.583403007590077]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.351527693393449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.351527693393449 | validation: 5.665244434661777]
	TIME [epoch: 6.48 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.283109864388121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.283109864388121 | validation: 5.655689472725585]
	TIME [epoch: 6.45 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.395547512271532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.395547512271532 | validation: 5.622571720519252]
	TIME [epoch: 6.44 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.118149822381766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.118149822381766 | validation: 5.514613509370353]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.990997834550463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.990997834550463 | validation: 4.963211129160961]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.845699735666056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.845699735666056 | validation: 5.082844617337673]
	TIME [epoch: 6.46 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9526616667319106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9526616667319106 | validation: 4.729475424880354]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.655214620437917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.655214620437917 | validation: 4.436684378047054]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.596660907101939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.596660907101939 | validation: 4.1913580055322575]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.54743130035642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.54743130035642 | validation: 4.050561248956148]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.03588679230926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.03588679230926 | validation: 3.9472884093912137]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9253470888288544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9253470888288544 | validation: 3.9247736899300993]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.163452062329449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.163452062329449 | validation: 3.5970640472008797]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8919695672412264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8919695672412264 | validation: 3.604972418411427]
	TIME [epoch: 6.49 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4649162841572205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4649162841572205 | validation: 3.486692654686246]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4472146197183964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4472146197183964 | validation: 3.709183817556589]
	TIME [epoch: 6.46 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.648956934441979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.648956934441979 | validation: 3.4922069410925007]
	TIME [epoch: 6.46 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5289076524401817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5289076524401817 | validation: 3.229334805202711]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3045777939522556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3045777939522556 | validation: 3.016220741633727]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.169988764411129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.169988764411129 | validation: 3.3961208533340943]
	TIME [epoch: 6.48 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.683393684159114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.683393684159114 | validation: 3.2661435639275305]
	TIME [epoch: 6.48 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4021702261475335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4021702261475335 | validation: 3.5701375697856292]
	TIME [epoch: 6.46 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.096969126102927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.096969126102927 | validation: 3.349230608048847]
	TIME [epoch: 6.45 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0682300740006134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0682300740006134 | validation: 2.6157349656567748]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1748702836577727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1748702836577727 | validation: 2.4728799539335653]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6908755195313603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6908755195313603 | validation: 2.6169098743941768]
	TIME [epoch: 6.46 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.987222640487408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.987222640487408 | validation: 3.1581573832415244]
	TIME [epoch: 6.46 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.87229256018704		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.87229256018704 | validation: 2.267769449830544]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.820243983018186		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.820243983018186 | validation: 2.5702760309839907]
	TIME [epoch: 6.45 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5891589215052697		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.5891589215052697 | validation: 3.4408520356249355]
	TIME [epoch: 6.46 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.784628456692839		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.784628456692839 | validation: 2.596593554846895]
	TIME [epoch: 6.44 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5655714389455797		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.5655714389455797 | validation: 3.07498081256896]
	TIME [epoch: 6.45 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6515109312441574		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.6515109312441574 | validation: 2.9109139879999963]
	TIME [epoch: 6.45 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6511909179352164		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.6511909179352164 | validation: 2.5203799894698995]
	TIME [epoch: 6.44 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.463850075318503		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.463850075318503 | validation: 3.3441082600000347]
	TIME [epoch: 6.46 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.848074180708133		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.848074180708133 | validation: 2.464487849004884]
	TIME [epoch: 6.44 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6323123247420552		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.6323123247420552 | validation: 2.2372046164427735]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5409149923302663		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.5409149923302663 | validation: 2.166844225240356]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4259812234740137		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.4259812234740137 | validation: 2.396350266520767]
	TIME [epoch: 6.44 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6300759056978142		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.6300759056978142 | validation: 2.145825899319654]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.51012027761908		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.51012027761908 | validation: 2.603357136367321]
	TIME [epoch: 6.45 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.389134164845633		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.389134164845633 | validation: 2.588929729991654]
	TIME [epoch: 6.45 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.433156165813423		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.433156165813423 | validation: 1.9759543728279239]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2314014530028485		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.2314014530028485 | validation: 1.9157724080741605]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.331141820784922		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.331141820784922 | validation: 3.1378454423255704]
	TIME [epoch: 6.44 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4077040851112486		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.4077040851112486 | validation: 2.0118063905712216]
	TIME [epoch: 6.44 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.146469674154827		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.146469674154827 | validation: 2.161836484923294]
	TIME [epoch: 6.44 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.140021962267971		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.140021962267971 | validation: 2.918678659675232]
	TIME [epoch: 6.46 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.605758200807518		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.605758200807518 | validation: 2.481375883812443]
	TIME [epoch: 6.46 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251305160241332		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.251305160241332 | validation: 1.7937965445405109]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.046603278079459		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.046603278079459 | validation: 2.109236610190045]
	TIME [epoch: 6.44 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1162558491557615		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.1162558491557615 | validation: 2.1842247935451815]
	TIME [epoch: 6.44 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2630504903442166		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.2630504903442166 | validation: 2.1658600704925663]
	TIME [epoch: 6.44 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.123738664979115		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.123738664979115 | validation: 1.7290853900815844]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275222932072271		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.275222932072271 | validation: 1.9365925219230389]
	TIME [epoch: 6.44 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9319406626392173		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.9319406626392173 | validation: 1.8197837269724115]
	TIME [epoch: 6.47 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2231130528300973		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.2231130528300973 | validation: 2.753042981878885]
	TIME [epoch: 6.44 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2840519998817816		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.2840519998817816 | validation: 1.7614494160906902]
	TIME [epoch: 6.44 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9416679199838707		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.9416679199838707 | validation: 2.2147751426831093]
	TIME [epoch: 6.44 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.140948701860463		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.140948701860463 | validation: 2.0653184498107726]
	TIME [epoch: 6.44 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.128707844769203		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.128707844769203 | validation: 2.01536576424608]
	TIME [epoch: 6.44 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4498472982981143		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.4498472982981143 | validation: 1.8968891103298375]
	TIME [epoch: 6.45 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.910696593360567		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.910696593360567 | validation: 2.0956959610771797]
	TIME [epoch: 6.47 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4688848070546134		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.4688848070546134 | validation: 2.3704133173744744]
	TIME [epoch: 6.45 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.03731446246134		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.03731446246134 | validation: 1.8364055644895825]
	TIME [epoch: 6.44 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9212366176798659		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.9212366176798659 | validation: 2.077605464090406]
	TIME [epoch: 6.44 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8845512206369202		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.8845512206369202 | validation: 2.4814730997234875]
	TIME [epoch: 6.44 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9692343779460235		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.9692343779460235 | validation: 1.6927592658712212]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9883138733800982		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.9883138733800982 | validation: 2.011279235421836]
	TIME [epoch: 6.44 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7150444787237185		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.7150444787237185 | validation: 1.7123332435420449]
	TIME [epoch: 6.47 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5263373327707248		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.5263373327707248 | validation: 1.5142285762800434]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9656200642203492		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.9656200642203492 | validation: 2.415163240039799]
	TIME [epoch: 6.45 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7948847325539588		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.7948847325539588 | validation: 2.164178884418215]
	TIME [epoch: 6.45 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.661476599763653		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.661476599763653 | validation: 2.065809203624624]
	TIME [epoch: 6.45 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8798587577114771		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.8798587577114771 | validation: 2.4644539166833583]
	TIME [epoch: 6.43 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8328654436651792		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.8328654436651792 | validation: 1.8357153291183412]
	TIME [epoch: 6.45 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5772615958452825		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.5772615958452825 | validation: 1.905353505285427]
	TIME [epoch: 6.48 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5308890106987643		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.5308890106987643 | validation: 1.5792084332591105]
	TIME [epoch: 6.45 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5950110438733636		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.5950110438733636 | validation: 1.6951358021071303]
	TIME [epoch: 6.45 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5454468034126247		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.5454468034126247 | validation: 1.4364117736474873]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5249016346876232		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.5249016346876232 | validation: 1.4345357226601056]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6059046473276064		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.6059046473276064 | validation: 1.7905526746713398]
	TIME [epoch: 6.44 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.56252269013026		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.56252269013026 | validation: 1.342006794101307]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.487630516492898		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.487630516492898 | validation: 1.8632078344129166]
	TIME [epoch: 6.47 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7264480760263448		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.7264480760263448 | validation: 2.1813927953877603]
	TIME [epoch: 6.44 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.612545187009831		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.612545187009831 | validation: 1.6532414808063567]
	TIME [epoch: 6.44 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4304358278519684		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.4304358278519684 | validation: 1.4751014696552387]
	TIME [epoch: 6.44 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5947056727968558		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.5947056727968558 | validation: 2.4034134014937347]
	TIME [epoch: 6.44 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7081951374540003		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.7081951374540003 | validation: 1.3477065014739105]
	TIME [epoch: 6.44 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4382539931216378		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.4382539931216378 | validation: 1.578027079765669]
	TIME [epoch: 6.44 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3868342033104726		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.3868342033104726 | validation: 1.5695030006004544]
	TIME [epoch: 6.47 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6019459642627343		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.6019459642627343 | validation: 1.436620221258512]
	TIME [epoch: 6.45 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4779571643797964		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.4779571643797964 | validation: 1.3952708949706394]
	TIME [epoch: 6.44 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1860897673654835		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.1860897673654835 | validation: 1.5592024805075833]
	TIME [epoch: 6.44 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.457898602470389		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.457898602470389 | validation: 2.219878279702946]
	TIME [epoch: 6.44 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5281810789461938		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.5281810789461938 | validation: 1.9636236497512938]
	TIME [epoch: 6.44 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.278535296283771		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.278535296283771 | validation: 1.1394546748055407]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3838286922103638		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.3838286922103638 | validation: 1.3217233582311247]
	TIME [epoch: 6.47 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2211975025227624		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.2211975025227624 | validation: 1.5982570168464116]
	TIME [epoch: 6.44 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3547635636128035		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.3547635636128035 | validation: 1.353803888102819]
	TIME [epoch: 6.44 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4623642301386728		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.4623642301386728 | validation: 2.350466255535235]
	TIME [epoch: 6.44 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5655212663981868		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.5655212663981868 | validation: 1.3896942849413183]
	TIME [epoch: 6.44 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2871356872381416		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.2871356872381416 | validation: 1.5358437630264468]
	TIME [epoch: 6.44 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5008960484917635		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.5008960484917635 | validation: 1.2947113440003764]
	TIME [epoch: 6.44 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3086896503115708		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.3086896503115708 | validation: 1.1402591273492841]
	TIME [epoch: 6.45 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2121907548963573		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.2121907548963573 | validation: 1.5350208342689633]
	TIME [epoch: 6.46 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4488314119892085		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.4488314119892085 | validation: 1.8406223944328814]
	TIME [epoch: 6.44 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2479493052544084		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.2479493052544084 | validation: 1.4627778642293623]
	TIME [epoch: 6.44 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3933359022408283		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.3933359022408283 | validation: 0.9943303250037095]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1508641249725926		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.1508641249725926 | validation: 1.7767584269649046]
	TIME [epoch: 6.44 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5025143104908307		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.5025143104908307 | validation: 1.372857931241848]
	TIME [epoch: 6.44 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1296180068789807		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.1296180068789807 | validation: 1.4612162995238782]
	TIME [epoch: 6.45 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2000489136837507		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.2000489136837507 | validation: 2.231356004594541]
	TIME [epoch: 6.45 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3935462411796942		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.3935462411796942 | validation: 1.3022592591129187]
	TIME [epoch: 6.44 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7015580330697855		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.7015580330697855 | validation: 1.665908231954013]
	TIME [epoch: 6.44 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3619100252143324		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.3619100252143324 | validation: 1.2960560218577712]
	TIME [epoch: 6.44 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.212155190519859		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.212155190519859 | validation: 1.2995846394131803]
	TIME [epoch: 6.44 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2015638204435648		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.2015638204435648 | validation: 1.2771436461496932]
	TIME [epoch: 6.44 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3139932939137886		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.3139932939137886 | validation: 1.4695055456869834]
	TIME [epoch: 6.44 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2737878147937804		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.2737878147937804 | validation: 1.087162594745374]
	TIME [epoch: 6.46 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1195150580042972		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.1195150580042972 | validation: 1.2030342687109357]
	TIME [epoch: 6.44 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.396251345141849		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.396251345141849 | validation: 1.0646449389222692]
	TIME [epoch: 6.44 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1308346938245035		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.1308346938245035 | validation: 1.6103440256329549]
	TIME [epoch: 6.44 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.49537589691842		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.49537589691842 | validation: 2.1246432000502087]
	TIME [epoch: 6.44 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3213815911006495		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.3213815911006495 | validation: 1.2987760543809526]
	TIME [epoch: 6.44 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1111942794217187		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.1111942794217187 | validation: 1.023683952242084]
	TIME [epoch: 6.44 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1177062886827265		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.1177062886827265 | validation: 1.6576215489632549]
	TIME [epoch: 6.47 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0686103155274405		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.0686103155274405 | validation: 1.2493281293791592]
	TIME [epoch: 6.44 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1432803306325452		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.1432803306325452 | validation: 0.9802729234425411]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2115782669207982		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.2115782669207982 | validation: 1.3158956800634098]
	TIME [epoch: 6.44 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3140336411792215		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.3140336411792215 | validation: 1.3941674523916674]
	TIME [epoch: 6.44 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1913974618920966		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.1913974618920966 | validation: 0.950387301088232]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1274928263155113		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.1274928263155113 | validation: 1.4917538912314117]
	TIME [epoch: 6.44 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.374761547544742		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.374761547544742 | validation: 1.4121117846520224]
	TIME [epoch: 6.47 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1070456097081907		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.1070456097081907 | validation: 1.6104392639959348]
	TIME [epoch: 6.44 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1332157336714954		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.1332157336714954 | validation: 1.7035768551352322]
	TIME [epoch: 6.44 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0520116023833164		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.0520116023833164 | validation: 1.645380015622235]
	TIME [epoch: 6.44 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9840493635699026		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.9840493635699026 | validation: 1.1761865916393817]
	TIME [epoch: 6.44 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1299541787931389		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.1299541787931389 | validation: 1.2556827712856735]
	TIME [epoch: 6.44 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2150386673734586		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.2150386673734586 | validation: 1.261770698914266]
	TIME [epoch: 6.44 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1179813441750617		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.1179813441750617 | validation: 1.4262410390571532]
	TIME [epoch: 6.47 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.12941665583887		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.12941665583887 | validation: 1.6451899838388568]
	TIME [epoch: 6.45 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.195083432357663		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.195083432357663 | validation: 1.0981726030188816]
	TIME [epoch: 6.44 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0662103581406859		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.0662103581406859 | validation: 1.1575085006828247]
	TIME [epoch: 6.44 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0625973005856015		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.0625973005856015 | validation: 1.2828485810574908]
	TIME [epoch: 6.44 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9836334523003597		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.9836334523003597 | validation: 1.4552713887592463]
	TIME [epoch: 6.44 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0298899862291098		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.0298899862291098 | validation: 1.0118178632488806]
	TIME [epoch: 6.44 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0133090387516506		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.0133090387516506 | validation: 0.9060579527563093]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9618644489696764		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.9618644489696764 | validation: 1.0420492937980925]
	TIME [epoch: 6.46 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.290323479881719		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.290323479881719 | validation: 1.1481979636139517]
	TIME [epoch: 6.45 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0590924343733208		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.0590924343733208 | validation: 1.1610890208194073]
	TIME [epoch: 6.45 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2213851970790663		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.2213851970790663 | validation: 1.2611106733211008]
	TIME [epoch: 6.45 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.01443057142855		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.01443057142855 | validation: 1.0794786174042126]
	TIME [epoch: 6.45 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0571762210764921		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.0571762210764921 | validation: 0.9124627196090507]
	TIME [epoch: 6.46 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0003039579293185		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.0003039579293185 | validation: 1.0724711022268125]
	TIME [epoch: 6.47 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.002719030854021		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.002719030854021 | validation: 1.5797605612143952]
	TIME [epoch: 6.48 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1425487910710261		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.1425487910710261 | validation: 1.0656408995873248]
	TIME [epoch: 6.45 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9025499592354778		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.9025499592354778 | validation: 1.2306188208253874]
	TIME [epoch: 6.46 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0123129760766212		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.0123129760766212 | validation: 1.2796100730393656]
	TIME [epoch: 6.45 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0429930746304572		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.0429930746304572 | validation: 1.1821788208166464]
	TIME [epoch: 6.44 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.045744886597367		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.045744886597367 | validation: 1.153801596653704]
	TIME [epoch: 6.45 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.075459310769495		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.075459310769495 | validation: 1.3336699105087586]
	TIME [epoch: 6.45 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031541028345861		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.031541028345861 | validation: 1.0447914119086745]
	TIME [epoch: 6.48 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9279449668303058		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.9279449668303058 | validation: 1.3560049872105373]
	TIME [epoch: 6.45 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0988474988335108		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.0988474988335108 | validation: 1.020284815121938]
	TIME [epoch: 6.45 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1916506385281422		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.1916506385281422 | validation: 1.3243441752800162]
	TIME [epoch: 6.45 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9208031505932371		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.9208031505932371 | validation: 1.3284371906125825]
	TIME [epoch: 6.44 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082081161587902		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.082081161587902 | validation: 1.2095551464593977]
	TIME [epoch: 6.45 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.01111514562716		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.01111514562716 | validation: 0.9712651605748874]
	TIME [epoch: 6.45 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9972840654192143		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.9972840654192143 | validation: 1.2770464937559558]
	TIME [epoch: 6.47 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9298634662763261		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.9298634662763261 | validation: 0.9393678093884229]
	TIME [epoch: 6.44 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9247793921813545		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.9247793921813545 | validation: 0.8707661039014062]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0159007174998416		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.0159007174998416 | validation: 1.0355966994219654]
	TIME [epoch: 6.45 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8995087079357493		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.8995087079357493 | validation: 1.2294750239303367]
	TIME [epoch: 6.45 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9451838967015482		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.9451838967015482 | validation: 1.0819472041309655]
	TIME [epoch: 6.45 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9283308088400546		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.9283308088400546 | validation: 1.312676455012413]
	TIME [epoch: 6.45 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0182024276028174		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.0182024276028174 | validation: 0.975964605190831]
	TIME [epoch: 6.47 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1910001583741732		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.1910001583741732 | validation: 0.9377535033093277]
	TIME [epoch: 6.45 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.796236138428033		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.796236138428033 | validation: 1.1925063652747592]
	TIME [epoch: 6.44 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9566950896217564		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.9566950896217564 | validation: 1.2677059098047059]
	TIME [epoch: 6.44 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9955290818793849		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.9955290818793849 | validation: 1.2345812726472805]
	TIME [epoch: 6.44 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.193032695675858		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.193032695675858 | validation: 0.9893637102707662]
	TIME [epoch: 6.45 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8767200182886108		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.8767200182886108 | validation: 1.1266583615907613]
	TIME [epoch: 6.45 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.788554580799514		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.788554580799514 | validation: 1.0191899669251825]
	TIME [epoch: 6.49 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0229033247407302		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.0229033247407302 | validation: 0.9387757571447836]
	TIME [epoch: 6.45 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8756851415597743		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.8756851415597743 | validation: 0.8484729471669041]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.938967408554341		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.938967408554341 | validation: 1.175318420092884]
	TIME [epoch: 6.44 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8555972238049411		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.8555972238049411 | validation: 1.10662648211832]
	TIME [epoch: 6.45 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9666006350519407		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.9666006350519407 | validation: 1.0144740363173923]
	TIME [epoch: 6.45 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.800723147479262		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.800723147479262 | validation: 0.8564381364202988]
	TIME [epoch: 6.45 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9894286572745697		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.9894286572745697 | validation: 1.2176393816158082]
	TIME [epoch: 6.48 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9889288035940385		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.9889288035940385 | validation: 1.032596635129826]
	TIME [epoch: 6.45 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.966907570183493		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.966907570183493 | validation: 0.7721656656605614]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8876068276332669		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.8876068276332669 | validation: 1.2555666249652173]
	TIME [epoch: 6.46 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0698818303562754		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.0698818303562754 | validation: 0.8365771702132255]
	TIME [epoch: 6.46 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9313884993819622		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.9313884993819622 | validation: 0.9534203588107899]
	TIME [epoch: 6.46 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9164305382439324		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.9164305382439324 | validation: 1.015219427090234]
	TIME [epoch: 6.46 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8012237574098295		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.8012237574098295 | validation: 0.9231738048562026]
	TIME [epoch: 6.48 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8560864964888502		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.8560864964888502 | validation: 1.507929670300754]
	TIME [epoch: 6.48 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7345360834922227		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.7345360834922227 | validation: 0.8808141859415644]
	TIME [epoch: 6.47 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0655004701504855		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.0655004701504855 | validation: 1.0525462514643875]
	TIME [epoch: 6.46 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8491177157523557		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.8491177157523557 | validation: 0.8820023637304022]
	TIME [epoch: 6.45 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.828567041908293		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.828567041908293 | validation: 1.560692086683219]
	TIME [epoch: 6.47 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9092361169375729		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.9092361169375729 | validation: 0.736608917011528]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7907308562474147		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.7907308562474147 | validation: 1.3193335922195961]
	TIME [epoch: 6.46 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8754105217126545		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8754105217126545 | validation: 1.0271820604912483]
	TIME [epoch: 6.46 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8050841730121368		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.8050841730121368 | validation: 0.7764310170732691]
	TIME [epoch: 6.45 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7634735018944403		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.7634735018944403 | validation: 0.8044075972569994]
	TIME [epoch: 6.45 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027070904060118		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.027070904060118 | validation: 1.1686888477708501]
	TIME [epoch: 6.45 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9265006906409841		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.9265006906409841 | validation: 0.8162722812547426]
	TIME [epoch: 6.45 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8696864595887743		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8696864595887743 | validation: 0.9293843472978033]
	TIME [epoch: 6.45 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.857425981773162		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.857425981773162 | validation: 1.0136296605157693]
	TIME [epoch: 6.46 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7853696584295928		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.7853696584295928 | validation: 1.1467004023669558]
	TIME [epoch: 6.46 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056381566141752		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.056381566141752 | validation: 1.16454272657616]
	TIME [epoch: 6.45 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8265728729993538		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.8265728729993538 | validation: 1.1091217874777692]
	TIME [epoch: 6.45 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9093082845514885		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.9093082845514885 | validation: 0.7850285160577382]
	TIME [epoch: 6.45 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7041667963374358		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.7041667963374358 | validation: 1.014089195755094]
	TIME [epoch: 6.45 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9399436171890829		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.9399436171890829 | validation: 1.1852795961837583]
	TIME [epoch: 6.45 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9001555089733053		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.9001555089733053 | validation: 1.072500661820412]
	TIME [epoch: 6.45 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9917069543089265		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.9917069543089265 | validation: 0.8800809477241148]
	TIME [epoch: 6.47 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8053722746944687		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.8053722746944687 | validation: 1.0753452385678892]
	TIME [epoch: 6.45 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7599265806814953		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.7599265806814953 | validation: 1.1509618094430099]
	TIME [epoch: 6.45 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.808979851442349		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.808979851442349 | validation: 1.0496680549005928]
	TIME [epoch: 6.45 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8720529859120912		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.8720529859120912 | validation: 1.0325586202568122]
	TIME [epoch: 6.45 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7494580457524218		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.7494580457524218 | validation: 0.7860276921993249]
	TIME [epoch: 6.45 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6483931562779917		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.6483931562779917 | validation: 1.2667976347713494]
	TIME [epoch: 6.45 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8522819635290161		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.8522819635290161 | validation: 0.9617752689587961]
	TIME [epoch: 6.47 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176031493079283		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.7176031493079283 | validation: 0.9047270362299866]
	TIME [epoch: 6.45 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.849912969350124		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.849912969350124 | validation: 1.1174342096514271]
	TIME [epoch: 6.45 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217991819816094		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7217991819816094 | validation: 1.149396998935174]
	TIME [epoch: 6.45 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9080609852716812		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.9080609852716812 | validation: 1.1931915925688175]
	TIME [epoch: 6.45 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206007031000201		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.7206007031000201 | validation: 0.7832281317918102]
	TIME [epoch: 6.45 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7487477920619192		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7487477920619192 | validation: 0.7256404112450672]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7611135438156882		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.7611135438156882 | validation: 0.7486888605993322]
	TIME [epoch: 6.47 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7483539973626998		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.7483539973626998 | validation: 0.9534281745701904]
	TIME [epoch: 6.45 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956925471130342		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.6956925471130342 | validation: 0.8341972897392609]
	TIME [epoch: 6.45 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281014766397677		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.6281014766397677 | validation: 0.9392987256044522]
	TIME [epoch: 6.45 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6504323400192038		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.6504323400192038 | validation: 1.0043954714872825]
	TIME [epoch: 6.45 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7640638579937068		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.7640638579937068 | validation: 1.5024265797900367]
	TIME [epoch: 6.45 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8280677594144685		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.8280677594144685 | validation: 1.1148434533303475]
	TIME [epoch: 6.45 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8547988751194038		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.8547988751194038 | validation: 1.5318334732276193]
	TIME [epoch: 6.47 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.833226810631479		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.833226810631479 | validation: 0.7011955248172955]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6683331301778224		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.6683331301778224 | validation: 1.2067698690659736]
	TIME [epoch: 6.45 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6806922807701636		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.6806922807701636 | validation: 1.381614454863518]
	TIME [epoch: 6.45 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.842215343689579		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.842215343689579 | validation: 1.0226329485082695]
	TIME [epoch: 6.45 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7827919515878791		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.7827919515878791 | validation: 1.0842058272059172]
	TIME [epoch: 6.44 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722365242064988		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.722365242064988 | validation: 1.1929794230163533]
	TIME [epoch: 6.45 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8105431086357893		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.8105431086357893 | validation: 0.8514660262350217]
	TIME [epoch: 6.46 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6629577468249636		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.6629577468249636 | validation: 0.7224693419816265]
	TIME [epoch: 6.46 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8457930753470175		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.8457930753470175 | validation: 1.372377662051755]
	TIME [epoch: 6.45 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007027320840759		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.7007027320840759 | validation: 0.6827281103067298]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6365561904377207		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.6365561904377207 | validation: 1.0559656126108272]
	TIME [epoch: 6.45 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8237275641190802		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.8237275641190802 | validation: 0.9198906491950197]
	TIME [epoch: 6.45 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8717469220192491		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.8717469220192491 | validation: 0.992263552851939]
	TIME [epoch: 6.45 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7350845722742587		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.7350845722742587 | validation: 0.6567703165403593]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390041895112881		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6390041895112881 | validation: 0.8276741495911503]
	TIME [epoch: 6.46 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.66003657024677		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.66003657024677 | validation: 0.881789604335569]
	TIME [epoch: 6.46 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.707446627656895		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.707446627656895 | validation: 0.772231938584915]
	TIME [epoch: 6.46 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7088416385905238		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7088416385905238 | validation: 1.2170151025751106]
	TIME [epoch: 6.46 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7370723899704005		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.7370723899704005 | validation: 0.7619867463518678]
	TIME [epoch: 6.46 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.651037212694547		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.651037212694547 | validation: 0.7254544446992225]
	TIME [epoch: 6.46 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7018562889787129		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.7018562889787129 | validation: 0.9812858818767417]
	TIME [epoch: 6.47 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390119162124928		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.6390119162124928 | validation: 0.7959850512666458]
	TIME [epoch: 6.48 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9046979431401694		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.9046979431401694 | validation: 1.2138370006849195]
	TIME [epoch: 6.46 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7267818866915986		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.7267818866915986 | validation: 0.6492458682233793]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5586495533654402		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.5586495533654402 | validation: 0.9589496786447015]
	TIME [epoch: 6.45 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.809434647402706		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.809434647402706 | validation: 1.2012779286518573]
	TIME [epoch: 6.46 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8457192325043205		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.8457192325043205 | validation: 1.047766682736623]
	TIME [epoch: 6.46 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7382427823831115		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.7382427823831115 | validation: 0.6172358868409102]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211799995446104		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.7211799995446104 | validation: 0.6502070249933043]
	TIME [epoch: 6.48 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8093574857677006		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.8093574857677006 | validation: 1.0244703588994077]
	TIME [epoch: 6.46 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.618049755139974		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.618049755139974 | validation: 0.7025398013701392]
	TIME [epoch: 6.45 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7855269880488318		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.7855269880488318 | validation: 0.7833513517894451]
	TIME [epoch: 6.45 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6510666441544415		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.6510666441544415 | validation: 0.8006384464795301]
	TIME [epoch: 6.47 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5973833767392585		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.5973833767392585 | validation: 0.742456048130138]
	TIME [epoch: 6.45 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6699693378313729		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.6699693378313729 | validation: 0.6634413099729392]
	TIME [epoch: 6.45 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7567552010936589		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.7567552010936589 | validation: 0.8220898707854442]
	TIME [epoch: 6.48 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.678363467496875		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.678363467496875 | validation: 1.0441007733874879]
	TIME [epoch: 6.47 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8216315175993896		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.8216315175993896 | validation: 0.9096712690115861]
	TIME [epoch: 6.47 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6930977143053081		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.6930977143053081 | validation: 0.8486286562354859]
	TIME [epoch: 6.45 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6673860217182659		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.6673860217182659 | validation: 0.9301577672637569]
	TIME [epoch: 6.47 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8461170600004486		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.8461170600004486 | validation: 0.8637753937182651]
	TIME [epoch: 6.46 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685541831453361		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.685541831453361 | validation: 0.7794240610802559]
	TIME [epoch: 6.46 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8146795636051839		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.8146795636051839 | validation: 1.1296437407411324]
	TIME [epoch: 6.49 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214527928116418		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.7214527928116418 | validation: 0.8436590228113414]
	TIME [epoch: 6.47 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990793378555858		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.6990793378555858 | validation: 0.9187213723263699]
	TIME [epoch: 6.45 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6145843677361269		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.6145843677361269 | validation: 0.7638596658934189]
	TIME [epoch: 6.47 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5701005077863519		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.5701005077863519 | validation: 0.9322125590275644]
	TIME [epoch: 6.46 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5932665136118163		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5932665136118163 | validation: 0.623825747124624]
	TIME [epoch: 6.46 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6057355392277397		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.6057355392277397 | validation: 0.819879065567461]
	TIME [epoch: 6.46 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7444311812040035		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.7444311812040035 | validation: 0.6881578558948626]
	TIME [epoch: 6.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.641936207352076		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.641936207352076 | validation: 0.620661939281866]
	TIME [epoch: 6.46 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5494165272851799		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.5494165272851799 | validation: 0.75798224037978]
	TIME [epoch: 6.47 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6095563545099407		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.6095563545099407 | validation: 0.6389676673854275]
	TIME [epoch: 6.45 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5207498648517636		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5207498648517636 | validation: 1.123400094522733]
	TIME [epoch: 6.47 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7099063495226111		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.7099063495226111 | validation: 0.5359332792358659]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840101758400815		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.6840101758400815 | validation: 0.8370592882332158]
	TIME [epoch: 6.46 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5372391339764422		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.5372391339764422 | validation: 0.6525997519788814]
	TIME [epoch: 6.48 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70661710769677		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.70661710769677 | validation: 0.8466402891631428]
	TIME [epoch: 6.46 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6271605341037757		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.6271605341037757 | validation: 0.7051639203113951]
	TIME [epoch: 6.45 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5702616246954526		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.5702616246954526 | validation: 0.6797383032456094]
	TIME [epoch: 6.46 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48149259952425705		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.48149259952425705 | validation: 0.6361165696992276]
	TIME [epoch: 6.44 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6049923148335524		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.6049923148335524 | validation: 0.7202379995431946]
	TIME [epoch: 6.46 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5752813740931255		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.5752813740931255 | validation: 0.6799682817842312]
	TIME [epoch: 6.45 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6142027201959448		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.6142027201959448 | validation: 1.406338047984575]
	TIME [epoch: 6.47 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7484378961349057		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.7484378961349057 | validation: 0.5965356839969526]
	TIME [epoch: 6.46 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5929541317254063		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.5929541317254063 | validation: 0.8087561815239787]
	TIME [epoch: 6.47 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5398052720107923		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5398052720107923 | validation: 1.0539542670730617]
	TIME [epoch: 6.44 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5550954556410701		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.5550954556410701 | validation: 0.5956444802663355]
	TIME [epoch: 6.46 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49519652463485136		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.49519652463485136 | validation: 0.7751605820646953]
	TIME [epoch: 6.45 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4937798510073309		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.4937798510073309 | validation: 0.8636952320688382]
	TIME [epoch: 6.45 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843995095199107		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.6843995095199107 | validation: 0.6815105717370129]
	TIME [epoch: 6.46 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6176706033206221		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.6176706033206221 | validation: 0.7895289583627292]
	TIME [epoch: 6.47 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.534975023096815		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.534975023096815 | validation: 1.1806498483796304]
	TIME [epoch: 6.46 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7065300143273234		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.7065300143273234 | validation: 0.6556913718272915]
	TIME [epoch: 6.46 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.53099227906309		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.53099227906309 | validation: 1.047062360487386]
	TIME [epoch: 6.46 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5729964657133573		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.5729964657133573 | validation: 0.6088706615190062]
	TIME [epoch: 6.46 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5851493251144916		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.5851493251144916 | validation: 0.7646929762375322]
	TIME [epoch: 6.45 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5160972034065157		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.5160972034065157 | validation: 0.8851103182601364]
	TIME [epoch: 6.46 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7002600517957743		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.7002600517957743 | validation: 0.5130170100872566]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5512109989586368		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5512109989586368 | validation: 0.7564009412662894]
	TIME [epoch: 6.46 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5389421626333155		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.5389421626333155 | validation: 0.878629997948116]
	TIME [epoch: 6.45 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7039326667283772		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.7039326667283772 | validation: 0.8783221978789121]
	TIME [epoch: 6.46 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5950869678952347		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5950869678952347 | validation: 0.6305378924414022]
	TIME [epoch: 6.45 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5430098201459498		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.5430098201459498 | validation: 0.6944928940024783]
	TIME [epoch: 6.45 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281619482821476		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.6281619482821476 | validation: 0.517707549004818]
	TIME [epoch: 6.46 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4449340895153609		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.4449340895153609 | validation: 0.8644869227670361]
	TIME [epoch: 6.49 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5624563719777551		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.5624563719777551 | validation: 0.6278204190249776]
	TIME [epoch: 6.46 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5064589577646393		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.5064589577646393 | validation: 0.78806309323731]
	TIME [epoch: 6.45 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7918221246622633		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.7918221246622633 | validation: 0.48071903809793826]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5281206946977364		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.5281206946977364 | validation: 0.7235864319909656]
	TIME [epoch: 6.44 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572086393232127		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.572086393232127 | validation: 0.6061303699559284]
	TIME [epoch: 6.45 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7511015190414364		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.7511015190414364 | validation: 0.7133708136362671]
	TIME [epoch: 6.44 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6294631464029788		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.6294631464029788 | validation: 1.0622607136449886]
	TIME [epoch: 6.48 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5340299338719219		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.5340299338719219 | validation: 0.4452363370112893]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_358.pth
	Model improved!!!
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42672444926420405		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.42672444926420405 | validation: 1.136007442038251]
	TIME [epoch: 6.46 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7917623163089345		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.7917623163089345 | validation: 0.7034527920316737]
	TIME [epoch: 6.45 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6492103499501245		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.6492103499501245 | validation: 0.7263077423026647]
	TIME [epoch: 6.45 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5027656691823392		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.5027656691823392 | validation: 0.671033125719149]
	TIME [epoch: 6.45 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5173816906125552		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.5173816906125552 | validation: 0.8815142449078361]
	TIME [epoch: 6.45 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5428919491916218		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.5428919491916218 | validation: 0.6225888539070311]
	TIME [epoch: 6.48 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.421556003894479		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.421556003894479 | validation: 1.0980480974276112]
	TIME [epoch: 6.46 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5981984445051551		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.5981984445051551 | validation: 0.4319300311068773]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43757363638329083		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.43757363638329083 | validation: 0.771598091867678]
	TIME [epoch: 6.45 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6921570884110582		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.6921570884110582 | validation: 0.5534348843249763]
	TIME [epoch: 6.45 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5505074174573326		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.5505074174573326 | validation: 0.46273206081137974]
	TIME [epoch: 6.45 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45648569421356855		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.45648569421356855 | validation: 0.9863877676800016]
	TIME [epoch: 6.45 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6092220191330147		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.6092220191330147 | validation: 0.7261526065090953]
	TIME [epoch: 6.48 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4846324222732657		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.4846324222732657 | validation: 0.6853210263817527]
	TIME [epoch: 6.45 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.56332989634142		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.56332989634142 | validation: 0.9379130833706427]
	TIME [epoch: 6.45 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516637111508241		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.516637111508241 | validation: 0.5312212282811826]
	TIME [epoch: 6.45 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4361336669250804		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.4361336669250804 | validation: 0.6479255563952236]
	TIME [epoch: 6.45 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5400542649699234		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.5400542649699234 | validation: 0.5745314232916158]
	TIME [epoch: 6.45 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46829427797041273		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.46829427797041273 | validation: 0.5262356914662351]
	TIME [epoch: 6.45 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47986980421302283		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.47986980421302283 | validation: 0.5035528294325132]
	TIME [epoch: 6.48 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5310807746849157		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.5310807746849157 | validation: 0.5006938537720679]
	TIME [epoch: 6.46 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4880732836494773		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.4880732836494773 | validation: 0.680168796557087]
	TIME [epoch: 6.45 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5144746397160975		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5144746397160975 | validation: 0.701862734975183]
	TIME [epoch: 6.45 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.489050742280312		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.489050742280312 | validation: 0.7097792119762774]
	TIME [epoch: 6.45 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5284358088972099		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.5284358088972099 | validation: 0.6899498166127157]
	TIME [epoch: 6.45 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4664180450330814		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.4664180450330814 | validation: 0.6418164763387262]
	TIME [epoch: 6.45 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4946351772185269		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.4946351772185269 | validation: 0.5255800817156062]
	TIME [epoch: 6.46 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4133242975163287		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.4133242975163287 | validation: 0.5064076049241926]
	TIME [epoch: 6.47 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48053619779028744		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.48053619779028744 | validation: 0.4832272851830392]
	TIME [epoch: 6.45 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45370896397614024		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.45370896397614024 | validation: 0.5234806781545391]
	TIME [epoch: 6.45 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5816436326452546		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.5816436326452546 | validation: 0.6423060748391641]
	TIME [epoch: 6.45 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4413439865262071		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.4413439865262071 | validation: 0.5591926304117012]
	TIME [epoch: 6.45 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.58198612623799		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.58198612623799 | validation: 0.8703089241312233]
	TIME [epoch: 6.45 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5145037130736717		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.5145037130736717 | validation: 0.5812075573507405]
	TIME [epoch: 6.46 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5779974626802016		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.5779974626802016 | validation: 0.7784954972657372]
	TIME [epoch: 6.47 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44103344271664235		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.44103344271664235 | validation: 0.5607633439095103]
	TIME [epoch: 6.45 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5687328064830905		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.5687328064830905 | validation: 0.656201623200258]
	TIME [epoch: 6.45 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4683749409555728		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.4683749409555728 | validation: 0.807488968374182]
	TIME [epoch: 6.45 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5481852551590072		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.5481852551590072 | validation: 0.6516535128172748]
	TIME [epoch: 6.45 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5332757229567775		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.5332757229567775 | validation: 0.49164997852319076]
	TIME [epoch: 6.45 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48278547106564296		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.48278547106564296 | validation: 1.095272187118755]
	TIME [epoch: 6.46 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5347439045909516		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.5347439045909516 | validation: 0.75857604173427]
	TIME [epoch: 6.47 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.471526317249495		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.471526317249495 | validation: 0.4365199128638996]
	TIME [epoch: 6.46 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42453888857917343		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.42453888857917343 | validation: 0.7733423450661028]
	TIME [epoch: 6.45 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48610420832588214		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.48610420832588214 | validation: 0.6199098774947603]
	TIME [epoch: 6.46 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.592917900367932		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.592917900367932 | validation: 0.7774243437535182]
	TIME [epoch: 6.45 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6500218337715156		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.6500218337715156 | validation: 0.6004132398015577]
	TIME [epoch: 6.45 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4485066520081119		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.4485066520081119 | validation: 0.49325631642042345]
	TIME [epoch: 6.45 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446009105531263		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.5446009105531263 | validation: 0.5555923828679384]
	TIME [epoch: 6.48 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4423284357049905		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.4423284357049905 | validation: 0.4763997110437555]
	TIME [epoch: 6.46 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43527224029441297		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.43527224029441297 | validation: 0.5928628656504471]
	TIME [epoch: 6.46 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024396884980511		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.5024396884980511 | validation: 0.46527019284271376]
	TIME [epoch: 6.45 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43867357058030304		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.43867357058030304 | validation: 0.5656435441625207]
	TIME [epoch: 6.45 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46588922808485117		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.46588922808485117 | validation: 0.6018679103138894]
	TIME [epoch: 6.45 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42168247680229504		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.42168247680229504 | validation: 0.3826401129890814]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_413.pth
	Model improved!!!
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43225860983416975		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.43225860983416975 | validation: 0.5010978147818199]
	TIME [epoch: 6.48 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4542246124440338		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.4542246124440338 | validation: 0.3965790299568366]
	TIME [epoch: 6.45 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5635498898913887		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.5635498898913887 | validation: 0.4359510916163309]
	TIME [epoch: 6.45 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4737326630565511		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.4737326630565511 | validation: 0.5147816787568933]
	TIME [epoch: 6.45 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5928977234497491		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.5928977234497491 | validation: 0.42245615100670636]
	TIME [epoch: 6.44 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4713385545829195		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.4713385545829195 | validation: 0.522346991549808]
	TIME [epoch: 6.45 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4250087307879517		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.4250087307879517 | validation: 0.5784251172464554]
	TIME [epoch: 6.45 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40796277104176637		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.40796277104176637 | validation: 0.6332439956456186]
	TIME [epoch: 6.48 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5197991708452726		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.5197991708452726 | validation: 0.5728691530193462]
	TIME [epoch: 6.46 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46565386719070023		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.46565386719070023 | validation: 0.7086307625115583]
	TIME [epoch: 6.45 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43248977654011783		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.43248977654011783 | validation: 0.506002714720112]
	TIME [epoch: 6.45 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4861539088901631		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.4861539088901631 | validation: 0.5314504539818472]
	TIME [epoch: 6.44 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4485343454253123		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.4485343454253123 | validation: 0.568691925368432]
	TIME [epoch: 6.45 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5217299607023622		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.5217299607023622 | validation: 0.47889002501391476]
	TIME [epoch: 6.45 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4189784016598472		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.4189784016598472 | validation: 0.5187863909801169]
	TIME [epoch: 6.46 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42507165949185355		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.42507165949185355 | validation: 0.5403684461377937]
	TIME [epoch: 6.47 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5320865391822989		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.5320865391822989 | validation: 0.6042125426991706]
	TIME [epoch: 6.45 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40904401926875694		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.40904401926875694 | validation: 0.4753011453756001]
	TIME [epoch: 6.45 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36205513361845076		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.36205513361845076 | validation: 0.5005693729764318]
	TIME [epoch: 6.45 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47408018004381103		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.47408018004381103 | validation: 0.9117097294584658]
	TIME [epoch: 6.45 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49231295430289984		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.49231295430289984 | validation: 0.44695280054304265]
	TIME [epoch: 6.45 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38560300983505486		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.38560300983505486 | validation: 0.40673147677925414]
	TIME [epoch: 6.46 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033882030844367		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.5033882030844367 | validation: 0.35076757249656726]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34792833267091616		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.34792833267091616 | validation: 0.5595100600184287]
	TIME [epoch: 6.45 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409895720124798		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.409895720124798 | validation: 0.6901118880598162]
	TIME [epoch: 6.45 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48661100342507835		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.48661100342507835 | validation: 0.478358241957553]
	TIME [epoch: 6.45 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40842324712439615		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.40842324712439615 | validation: 0.5853042096039742]
	TIME [epoch: 6.45 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44078559360229164		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.44078559360229164 | validation: 0.4972944754873441]
	TIME [epoch: 6.44 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4225667000240769		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.4225667000240769 | validation: 0.5948549341652852]
	TIME [epoch: 6.46 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4132807752462162		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.4132807752462162 | validation: 0.4341481304735072]
	TIME [epoch: 6.46 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4067145686579451		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.4067145686579451 | validation: 0.5867851401155079]
	TIME [epoch: 6.45 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4553068542585117		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.4553068542585117 | validation: 0.6931052895329322]
	TIME [epoch: 6.44 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3894132835450451		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.3894132835450451 | validation: 0.5249524364581459]
	TIME [epoch: 6.44 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3404619843073664		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.3404619843073664 | validation: 0.4184353992318161]
	TIME [epoch: 6.45 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46483162609355977		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.46483162609355977 | validation: 0.5226099395270313]
	TIME [epoch: 6.45 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.505497077226982		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.505497077226982 | validation: 0.379807910432787]
	TIME [epoch: 6.45 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45870068089066013		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.45870068089066013 | validation: 0.38697964608845087]
	TIME [epoch: 6.47 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3932158198443628		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.3932158198443628 | validation: 0.4637721691388849]
	TIME [epoch: 6.45 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3323951216418885		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3323951216418885 | validation: 0.5587766409786843]
	TIME [epoch: 6.45 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46464361886446354		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.46464361886446354 | validation: 0.35069370265736466]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45591757352645146		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.45591757352645146 | validation: 0.40497367465942047]
	TIME [epoch: 6.44 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3680852998585006		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.3680852998585006 | validation: 0.33004286245135306]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3904787818796716		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.3904787818796716 | validation: 0.5863033942626302]
	TIME [epoch: 6.45 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569083773769361		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.4569083773769361 | validation: 0.4934783898111866]
	TIME [epoch: 6.47 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4356865564462292		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.4356865564462292 | validation: 0.37996379660646606]
	TIME [epoch: 6.45 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3215961066010701		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.3215961066010701 | validation: 0.5176418219902728]
	TIME [epoch: 6.46 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35798506547148934		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.35798506547148934 | validation: 0.48018554393445867]
	TIME [epoch: 6.45 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31174547632121935		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.31174547632121935 | validation: 0.44444151376269936]
	TIME [epoch: 6.46 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46914038059118734		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.46914038059118734 | validation: 0.5952258803968958]
	TIME [epoch: 6.45 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933426843438428		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.3933426843438428 | validation: 0.402136795828923]
	TIME [epoch: 6.45 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36959409942841315		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.36959409942841315 | validation: 0.41251992176863006]
	TIME [epoch: 6.49 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4108810329597308		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.4108810329597308 | validation: 0.6087576242903054]
	TIME [epoch: 6.45 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37003269440378367		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.37003269440378367 | validation: 0.502201658030048]
	TIME [epoch: 6.45 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4255030622821353		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.4255030622821353 | validation: 0.8480349912707519]
	TIME [epoch: 6.45 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5425438529673089		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.5425438529673089 | validation: 0.39317262329535674]
	TIME [epoch: 6.45 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35047432183669697		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.35047432183669697 | validation: 0.36703609422570027]
	TIME [epoch: 6.45 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3672639305206337		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.3672639305206337 | validation: 0.4061016720277692]
	TIME [epoch: 6.45 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3598264510732728		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.3598264510732728 | validation: 0.36557376552711063]
	TIME [epoch: 6.48 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3081109216042246		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.3081109216042246 | validation: 0.44780042893496796]
	TIME [epoch: 6.46 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36012878888766553		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.36012878888766553 | validation: 0.425616522049428]
	TIME [epoch: 6.45 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33802043036640994		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.33802043036640994 | validation: 0.3999276957853043]
	TIME [epoch: 6.45 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5115333827760666		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.5115333827760666 | validation: 0.8960410146583179]
	TIME [epoch: 6.45 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4330437329178289		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.4330437329178289 | validation: 0.31850259458646674]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_476.pth
	Model improved!!!
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29061930210768977		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.29061930210768977 | validation: 0.7904515614611901]
	TIME [epoch: 6.45 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43081004324027294		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.43081004324027294 | validation: 0.2603715283893699]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37500573484534677		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.37500573484534677 | validation: 0.5174019114841292]
	TIME [epoch: 6.45 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.420692534144936		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.420692534144936 | validation: 0.42754085796337943]
	TIME [epoch: 6.45 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34662125266801486		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.34662125266801486 | validation: 0.39068975908914894]
	TIME [epoch: 6.45 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31369774077239093		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.31369774077239093 | validation: 0.28063068407823566]
	TIME [epoch: 6.45 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3519538339330203		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.3519538339330203 | validation: 0.5431782354083142]
	TIME [epoch: 6.45 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34142446704411455		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.34142446704411455 | validation: 0.5095992920706965]
	TIME [epoch: 6.45 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3865961066415422		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.3865961066415422 | validation: 0.5381175778053026]
	TIME [epoch: 6.46 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33509097479397165		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.33509097479397165 | validation: 0.5758675581077175]
	TIME [epoch: 6.47 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36373833493687097		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.36373833493687097 | validation: 0.6083973520023401]
	TIME [epoch: 6.45 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3254775072890632		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.3254775072890632 | validation: 0.2669311573801761]
	TIME [epoch: 6.45 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29873878938352555		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.29873878938352555 | validation: 0.4150164232616851]
	TIME [epoch: 6.45 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39724877992440905		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.39724877992440905 | validation: 0.38139103816680775]
	TIME [epoch: 6.45 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3280477997613981		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.3280477997613981 | validation: 0.27818987754059615]
	TIME [epoch: 6.45 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3536382259337286		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.3536382259337286 | validation: 0.34447628196984426]
	TIME [epoch: 6.47 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28683642306641277		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.28683642306641277 | validation: 0.3278090776100527]
	TIME [epoch: 6.47 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3313358052433465		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.3313358052433465 | validation: 0.500504013785891]
	TIME [epoch: 6.46 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4193422859010911		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.4193422859010911 | validation: 0.3160837548970978]
	TIME [epoch: 6.45 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694764928069241		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.3694764928069241 | validation: 0.3856856569369833]
	TIME [epoch: 6.45 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36312333054323565		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.36312333054323565 | validation: 0.48777187302645775]
	TIME [epoch: 6.45 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3340886518735009		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.3340886518735009 | validation: 0.31552729785263295]
	TIME [epoch: 6.45 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.283870912814729		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.283870912814729 | validation: 0.4942700468399427]
	TIME [epoch: 6.46 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.402587490930511		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.402587490930511 | validation: 0.42403920666593836]
	TIME [epoch: 6.48 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31183556607146556		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.31183556607146556 | validation: 0.46592308315545766]
	TIME [epoch: 6.45 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2631320724954689		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.2631320724954689 | validation: 0.29399999653378645]
	TIME [epoch: 6.44 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32806639508719404		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.32806639508719404 | validation: 0.35048176528750574]
	TIME [epoch: 6.44 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34017163193635547		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.34017163193635547 | validation: 0.32961140668684563]
	TIME [epoch: 6.44 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626617912706372		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.2626617912706372 | validation: 0.25454515193206106]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108195543980136		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.3108195543980136 | validation: 0.3700455997466777]
	TIME [epoch: 6.44 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32954567134064255		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.32954567134064255 | validation: 0.26898956358522336]
	TIME [epoch: 6.47 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36355829243194787		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.36355829243194787 | validation: 0.3208926686661585]
	TIME [epoch: 6.45 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2954824902861692		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.2954824902861692 | validation: 0.34629436644333583]
	TIME [epoch: 6.44 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2990153359488806		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.2990153359488806 | validation: 0.41506716561207513]
	TIME [epoch: 6.44 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2997703046761184		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.2997703046761184 | validation: 0.5055632859212957]
	TIME [epoch: 6.44 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26507068152040447		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.26507068152040447 | validation: 0.39175633328761167]
	TIME [epoch: 6.44 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33359360883910844		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.33359360883910844 | validation: 0.4079046620152046]
	TIME [epoch: 6.44 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33260505748690533		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.33260505748690533 | validation: 0.34136380970188124]
	TIME [epoch: 6.48 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32984253388070806		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.32984253388070806 | validation: 0.4913777692217207]
	TIME [epoch: 6.45 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3284200928158978		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.3284200928158978 | validation: 0.6145098805245207]
	TIME [epoch: 6.45 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32803728143509897		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.32803728143509897 | validation: 0.336098559645385]
	TIME [epoch: 6.45 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34846087090014405		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.34846087090014405 | validation: 0.2926861314563688]
	TIME [epoch: 6.44 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30227351184956525		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.30227351184956525 | validation: 0.27147300998250096]
	TIME [epoch: 6.45 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26816315627315296		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.26816315627315296 | validation: 0.4684530681413689]
	TIME [epoch: 6.45 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343156254199235		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.3343156254199235 | validation: 0.3234729769861405]
	TIME [epoch: 6.48 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38069247842212794		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.38069247842212794 | validation: 0.34467212751719756]
	TIME [epoch: 6.46 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34644593940283186		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.34644593940283186 | validation: 0.5006068434827585]
	TIME [epoch: 6.45 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3961555258547257		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.3961555258547257 | validation: 0.5551983981959184]
	TIME [epoch: 6.45 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3201856940597775		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.3201856940597775 | validation: 0.26415557777299453]
	TIME [epoch: 6.45 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25676732371948213		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.25676732371948213 | validation: 0.47152975724885066]
	TIME [epoch: 6.45 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3450965189193891		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.3450965189193891 | validation: 0.2375638785418037]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31106292271326597		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.31106292271326597 | validation: 0.36422754432755866]
	TIME [epoch: 6.47 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30499719763742067		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.30499719763742067 | validation: 0.4018212576298097]
	TIME [epoch: 6.45 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31502118520616373		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.31502118520616373 | validation: 0.38916789412195185]
	TIME [epoch: 6.45 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28634983605935416		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.28634983605935416 | validation: 0.28290609225350755]
	TIME [epoch: 6.45 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939163262567027		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.2939163262567027 | validation: 0.28748526004832203]
	TIME [epoch: 6.45 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.328660790938412		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.328660790938412 | validation: 0.2537396556882578]
	TIME [epoch: 6.45 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2699244763484487		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.2699244763484487 | validation: 0.2013207172340742]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_534.pth
	Model improved!!!
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2501468407356504		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.2501468407356504 | validation: 0.3276610975053218]
	TIME [epoch: 6.49 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25451973342116		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.25451973342116 | validation: 0.3605164942734253]
	TIME [epoch: 6.46 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3070069312025529		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.3070069312025529 | validation: 0.4408383599163257]
	TIME [epoch: 6.46 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29501176329895007		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.29501176329895007 | validation: 0.3909766727882629]
	TIME [epoch: 6.45 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3008161847023119		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.3008161847023119 | validation: 0.32774798061424437]
	TIME [epoch: 6.45 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2243384452919478		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.2243384452919478 | validation: 0.21066271362950162]
	TIME [epoch: 6.45 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32468956721253334		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.32468956721253334 | validation: 0.26484696557635024]
	TIME [epoch: 6.44 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44003710841309274		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.44003710841309274 | validation: 0.2252412251822584]
	TIME [epoch: 6.46 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31993103741496076		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.31993103741496076 | validation: 0.4502129578754973]
	TIME [epoch: 6.47 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2948485966818257		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.2948485966818257 | validation: 0.23989130962270508]
	TIME [epoch: 6.45 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624069658714916		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.2624069658714916 | validation: 0.30391324828597316]
	TIME [epoch: 6.45 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2887977034150392		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.2887977034150392 | validation: 0.25119717884230425]
	TIME [epoch: 6.45 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24947415701623812		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.24947415701623812 | validation: 0.3086756895651591]
	TIME [epoch: 6.45 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27303674191974714		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.27303674191974714 | validation: 0.24694571878891197]
	TIME [epoch: 6.45 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35739283026621915		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.35739283026621915 | validation: 0.34072347813260834]
	TIME [epoch: 6.45 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31488377314767046		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.31488377314767046 | validation: 0.35558715840347643]
	TIME [epoch: 6.48 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24548238809535317		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.24548238809535317 | validation: 0.2577608890876367]
	TIME [epoch: 6.45 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915289610214997		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.2915289610214997 | validation: 0.2289994065888707]
	TIME [epoch: 6.45 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27702152147029796		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.27702152147029796 | validation: 0.3021268936456977]
	TIME [epoch: 6.45 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898942941281796		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.2898942941281796 | validation: 0.5621673970478906]
	TIME [epoch: 6.45 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36301909270574517		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.36301909270574517 | validation: 0.30465115630505174]
	TIME [epoch: 6.45 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31576564330802215		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.31576564330802215 | validation: 0.2199249609271535]
	TIME [epoch: 6.45 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27597293973745046		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.27597293973745046 | validation: 0.3248168282645992]
	TIME [epoch: 6.49 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27491671185868216		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.27491671185868216 | validation: 0.2544207266999702]
	TIME [epoch: 6.46 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3087193084847716		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.3087193084847716 | validation: 0.17067866446970859]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2467381902192598		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.2467381902192598 | validation: 0.323775101262853]
	TIME [epoch: 6.45 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2811826601668025		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.2811826601668025 | validation: 0.3043889356725485]
	TIME [epoch: 6.45 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3034705037218902		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.3034705037218902 | validation: 0.22545247919092823]
	TIME [epoch: 6.44 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4009024239977803		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.4009024239977803 | validation: 0.678023300525561]
	TIME [epoch: 6.45 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4209598181729996		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.4209598181729996 | validation: 0.5164488772482256]
	TIME [epoch: 6.48 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3168608199369468		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.3168608199369468 | validation: 0.22415324545122345]
	TIME [epoch: 6.45 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32030309669676904		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.32030309669676904 | validation: 0.2031924284177614]
	TIME [epoch: 6.45 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25662207602265635		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.25662207602265635 | validation: 0.5024312725864897]
	TIME [epoch: 6.45 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30279964937068343		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.30279964937068343 | validation: 0.4771343264348885]
	TIME [epoch: 6.45 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32663942810163177		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.32663942810163177 | validation: 0.4468596873652497]
	TIME [epoch: 6.46 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923327529294634		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.2923327529294634 | validation: 0.24961882925009501]
	TIME [epoch: 6.45 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770328755275942		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.2770328755275942 | validation: 0.33556187885754]
	TIME [epoch: 6.48 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2936601648759657		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.2936601648759657 | validation: 0.34425119937341564]
	TIME [epoch: 6.46 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2591294135344816		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.2591294135344816 | validation: 0.2591122055330928]
	TIME [epoch: 6.45 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36278115096533753		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.36278115096533753 | validation: 0.24424928480601474]
	TIME [epoch: 6.45 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24400067707823428		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.24400067707823428 | validation: 0.2610342858318371]
	TIME [epoch: 6.45 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24710868308585854		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.24710868308585854 | validation: 0.2901080340184547]
	TIME [epoch: 6.45 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30204197894194185		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.30204197894194185 | validation: 0.4037492505810863]
	TIME [epoch: 6.45 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3015650383984577		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.3015650383984577 | validation: 0.24441573434319622]
	TIME [epoch: 6.49 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2526887896172383		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.2526887896172383 | validation: 0.46814996649351037]
	TIME [epoch: 6.47 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2795964578564171		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.2795964578564171 | validation: 0.39275007286436525]
	TIME [epoch: 6.46 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3107735429265895		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.3107735429265895 | validation: 0.26980758625550083]
	TIME [epoch: 6.46 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24863488012458657		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.24863488012458657 | validation: 0.22607298406846]
	TIME [epoch: 6.46 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2841444195408008		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.2841444195408008 | validation: 0.25913778893243167]
	TIME [epoch: 6.46 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.249015990224782		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.249015990224782 | validation: 0.32911604123935534]
	TIME [epoch: 6.46 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22105083939763534		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.22105083939763534 | validation: 0.23861966487737715]
	TIME [epoch: 6.48 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2639325924129581		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.2639325924129581 | validation: 0.27797743685799925]
	TIME [epoch: 6.48 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2775525377703348		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.2775525377703348 | validation: 0.3941194631589147]
	TIME [epoch: 6.46 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25816798492132714		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.25816798492132714 | validation: 0.4045042978375508]
	TIME [epoch: 6.46 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352728949347881		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.3352728949347881 | validation: 0.38933094848064087]
	TIME [epoch: 6.46 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3237875772981971		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.3237875772981971 | validation: 0.1886246610758425]
	TIME [epoch: 6.45 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21958705252944719		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.21958705252944719 | validation: 0.23635447300231577]
	TIME [epoch: 6.46 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2368697248670475		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.2368697248670475 | validation: 0.34364982034752006]
	TIME [epoch: 6.48 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2547582689846958		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.2547582689846958 | validation: 0.3998430186279028]
	TIME [epoch: 6.48 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22134167821107467		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.22134167821107467 | validation: 0.227902324620936]
	TIME [epoch: 6.46 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2430917917623903		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.2430917917623903 | validation: 0.2499796656265474]
	TIME [epoch: 6.46 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22005188702946607		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.22005188702946607 | validation: 0.2485356192474548]
	TIME [epoch: 6.46 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536259843617145		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.2536259843617145 | validation: 0.4081932604060681]
	TIME [epoch: 6.45 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31007396187438124		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.31007396187438124 | validation: 0.36882889784413564]
	TIME [epoch: 6.45 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22635659412096948		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.22635659412096948 | validation: 0.2619848929156362]
	TIME [epoch: 6.46 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2360979747016104		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2360979747016104 | validation: 0.22918659236246122]
	TIME [epoch: 6.49 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2513962353988893		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.2513962353988893 | validation: 0.292273653652312]
	TIME [epoch: 6.46 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28322724141991323		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.28322724141991323 | validation: 0.3336583280884271]
	TIME [epoch: 6.46 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2485527949154407		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.2485527949154407 | validation: 0.4028485527017571]
	TIME [epoch: 6.45 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24657325870435765		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.24657325870435765 | validation: 0.26152812927068014]
	TIME [epoch: 6.45 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3132707003802382		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.3132707003802382 | validation: 0.2924477220119051]
	TIME [epoch: 6.45 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.199483058533795		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.199483058533795 | validation: 0.2423252627294545]
	TIME [epoch: 6.46 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2484019457007731		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.2484019457007731 | validation: 0.26726262658840627]
	TIME [epoch: 6.49 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28433781475910647		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.28433781475910647 | validation: 0.430723706353952]
	TIME [epoch: 6.46 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24409369261225505		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.24409369261225505 | validation: 0.19103735408491973]
	TIME [epoch: 6.46 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2508345446302054		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.2508345446302054 | validation: 0.33825119166647566]
	TIME [epoch: 6.46 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24823264094454833		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.24823264094454833 | validation: 0.35803866931774436]
	TIME [epoch: 6.46 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.230224453388951		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.230224453388951 | validation: 0.2810586205136248]
	TIME [epoch: 6.46 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521404824541232		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.3521404824541232 | validation: 0.30204226526480643]
	TIME [epoch: 6.45 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31355286075139893		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.31355286075139893 | validation: 0.19255611569807976]
	TIME [epoch: 6.49 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18957431762972882		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.18957431762972882 | validation: 0.3844583010426332]
	TIME [epoch: 6.47 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23479292354618989		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.23479292354618989 | validation: 0.1955783845372499]
	TIME [epoch: 6.46 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19485135831063882		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.19485135831063882 | validation: 0.2212254026309956]
	TIME [epoch: 6.46 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24193937971516657		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.24193937971516657 | validation: 0.2909406622130543]
	TIME [epoch: 6.46 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18881673209421723		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.18881673209421723 | validation: 0.29091986895569427]
	TIME [epoch: 6.46 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254521557169047		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.254521557169047 | validation: 0.2779055996747151]
	TIME [epoch: 6.46 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2273305723096991		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.2273305723096991 | validation: 0.2804434653536303]
	TIME [epoch: 6.49 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20186083323273601		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.20186083323273601 | validation: 0.30510838401665596]
	TIME [epoch: 6.47 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23433208226405522		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.23433208226405522 | validation: 0.33046215630403736]
	TIME [epoch: 6.46 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2602632082165177		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.2602632082165177 | validation: 0.2671781128005013]
	TIME [epoch: 6.46 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24723988969989855		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.24723988969989855 | validation: 0.23251558549531118]
	TIME [epoch: 6.46 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22050856965054388		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.22050856965054388 | validation: 0.2753747289178291]
	TIME [epoch: 6.46 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2517282173244782		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.2517282173244782 | validation: 0.28068174598695267]
	TIME [epoch: 6.46 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23830214751102852		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.23830214751102852 | validation: 0.20474736379148437]
	TIME [epoch: 6.47 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33477519717851756		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.33477519717851756 | validation: 0.3135332939800075]
	TIME [epoch: 6.48 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23924286975337233		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.23924286975337233 | validation: 0.3931381239784282]
	TIME [epoch: 6.46 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25033989496968134		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.25033989496968134 | validation: 0.5114435851400958]
	TIME [epoch: 6.45 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39146253747842713		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.39146253747842713 | validation: 0.27319819322802047]
	TIME [epoch: 6.45 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23200744741071522		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.23200744741071522 | validation: 0.21706825943497993]
	TIME [epoch: 6.46 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2192383507375705		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.2192383507375705 | validation: 0.21226653691109754]
	TIME [epoch: 6.46 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20520054023273898		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.20520054023273898 | validation: 0.5605549054544917]
	TIME [epoch: 6.48 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31444441155432334		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.31444441155432334 | validation: 0.34361964395033157]
	TIME [epoch: 6.47 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32063232656816176		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.32063232656816176 | validation: 0.3123292103679407]
	TIME [epoch: 6.46 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2246871583466033		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.2246871583466033 | validation: 0.27568624608142356]
	TIME [epoch: 6.46 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18806861754355908		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.18806861754355908 | validation: 0.3607818052739371]
	TIME [epoch: 6.46 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25137012491906224		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.25137012491906224 | validation: 0.40810694629243466]
	TIME [epoch: 6.46 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24444981178621727		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.24444981178621727 | validation: 0.25871963959667893]
	TIME [epoch: 6.46 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2197365028047149		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.2197365028047149 | validation: 0.2625668842144371]
	TIME [epoch: 6.46 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.250249469115835		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.250249469115835 | validation: 0.28524195472716385]
	TIME [epoch: 6.49 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20551123235407703		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.20551123235407703 | validation: 0.26343776385996265]
	TIME [epoch: 6.46 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.195771716675509		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.195771716675509 | validation: 0.30447650079601163]
	TIME [epoch: 6.46 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22814026778773314		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.22814026778773314 | validation: 0.23262438441281078]
	TIME [epoch: 6.46 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18752333080394648		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.18752333080394648 | validation: 0.3680653087012105]
	TIME [epoch: 6.46 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2844573955283217		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.2844573955283217 | validation: 0.3681277278172715]
	TIME [epoch: 6.46 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26804741862298465		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.26804741862298465 | validation: 0.20361567296753807]
	TIME [epoch: 6.46 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19525054704105663		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.19525054704105663 | validation: 0.26804533349406784]
	TIME [epoch: 6.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1946241232655932		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.1946241232655932 | validation: 0.23971614323616444]
	TIME [epoch: 6.47 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18223297124854065		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.18223297124854065 | validation: 0.17694076943075873]
	TIME [epoch: 6.46 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1898669323910586		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.1898669323910586 | validation: 0.2071021757948837]
	TIME [epoch: 6.46 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28148672708634803		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.28148672708634803 | validation: 0.22475110144338153]
	TIME [epoch: 6.46 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21370713140323472		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.21370713140323472 | validation: 0.27007933262315165]
	TIME [epoch: 6.46 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20721219754903392		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.20721219754903392 | validation: 0.2032642799696376]
	TIME [epoch: 6.46 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17351750111878803		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.17351750111878803 | validation: 0.31573030097785776]
	TIME [epoch: 6.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19368672503778453		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.19368672503778453 | validation: 0.3062714555659947]
	TIME [epoch: 6.47 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20880971688443595		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.20880971688443595 | validation: 0.32925873326247984]
	TIME [epoch: 6.46 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24574834454263797		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.24574834454263797 | validation: 0.21479064620819288]
	TIME [epoch: 6.46 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1948531470503386		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.1948531470503386 | validation: 0.2376507777000375]
	TIME [epoch: 6.46 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23734924499954838		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.23734924499954838 | validation: 0.25599452761548736]
	TIME [epoch: 6.46 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18092649342540035		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.18092649342540035 | validation: 0.2323042080697715]
	TIME [epoch: 6.46 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15923701771018378		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.15923701771018378 | validation: 0.3351757366216072]
	TIME [epoch: 6.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1722816562170063		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.1722816562170063 | validation: 0.2568946368093491]
	TIME [epoch: 6.47 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2836289289930064		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.2836289289930064 | validation: 0.3128616186386554]
	TIME [epoch: 6.46 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21800344577278316		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.21800344577278316 | validation: 0.26992124420039765]
	TIME [epoch: 6.46 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21215083063733406		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.21215083063733406 | validation: 0.3065658319265757]
	TIME [epoch: 6.46 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2514594966657572		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.2514594966657572 | validation: 0.33102226979589433]
	TIME [epoch: 6.46 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20489900597449287		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.20489900597449287 | validation: 0.1728540785030934]
	TIME [epoch: 6.46 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1704154325617377		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.1704154325617377 | validation: 0.19935339699602708]
	TIME [epoch: 6.48 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16047434808588174		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.16047434808588174 | validation: 0.3334800223748534]
	TIME [epoch: 6.48 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1668760558081086		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.1668760558081086 | validation: 0.19719409961805245]
	TIME [epoch: 6.46 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17705237973173066		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.17705237973173066 | validation: 0.18680208857139924]
	TIME [epoch: 6.46 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17772007917327387		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.17772007917327387 | validation: 0.3863128032165053]
	TIME [epoch: 6.46 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23303286139177148		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.23303286139177148 | validation: 0.20943386114511423]
	TIME [epoch: 6.46 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18151748934713674		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.18151748934713674 | validation: 0.2005054636315402]
	TIME [epoch: 6.46 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16436310664492734		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.16436310664492734 | validation: 0.19968586073766745]
	TIME [epoch: 6.48 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15821861017677682		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.15821861017677682 | validation: 0.2801254608140449]
	TIME [epoch: 6.48 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1959204207243718		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.1959204207243718 | validation: 0.2528544697821654]
	TIME [epoch: 6.45 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19897505695700674		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.19897505695700674 | validation: 0.20115779301270864]
	TIME [epoch: 6.45 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17632357650188246		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.17632357650188246 | validation: 0.16161547010179292]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_682.pth
	Model improved!!!
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16259522346053923		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.16259522346053923 | validation: 0.2659415213376555]
	TIME [epoch: 6.45 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19857447645573922		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.19857447645573922 | validation: 0.2597275167245056]
	TIME [epoch: 6.44 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21535910971771344		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.21535910971771344 | validation: 0.24270542208588303]
	TIME [epoch: 6.46 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25109710363443205		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.25109710363443205 | validation: 0.2396739676419327]
	TIME [epoch: 6.47 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16472143499613381		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.16472143499613381 | validation: 0.1778057268145746]
	TIME [epoch: 6.45 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18358855262479393		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.18358855262479393 | validation: 0.18003998208974373]
	TIME [epoch: 6.44 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17924091390332642		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.17924091390332642 | validation: 0.19940130006099333]
	TIME [epoch: 6.45 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24066962020911029		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.24066962020911029 | validation: 0.23302858478391655]
	TIME [epoch: 6.45 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23099819827359694		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.23099819827359694 | validation: 0.2494675204183235]
	TIME [epoch: 6.45 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1972318338493858		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.1972318338493858 | validation: 0.24676938461976228]
	TIME [epoch: 6.46 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20226115676057965		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.20226115676057965 | validation: 0.21620927327131229]
	TIME [epoch: 6.49 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18639680278883197		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.18639680278883197 | validation: 0.17651932140931173]
	TIME [epoch: 6.47 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1932453074047115		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.1932453074047115 | validation: 0.26150559604982226]
	TIME [epoch: 6.46 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17791634829182532		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.17791634829182532 | validation: 0.2133015118418403]
	TIME [epoch: 6.46 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21725621807300233		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.21725621807300233 | validation: 0.24176187879215788]
	TIME [epoch: 6.46 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595201804960994		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.2595201804960994 | validation: 0.2387512084369702]
	TIME [epoch: 6.46 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25279439348676846		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.25279439348676846 | validation: 0.16151399302237748]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_699.pth
	Model improved!!!
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726968229544162		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.1726968229544162 | validation: 0.16812975410640982]
	TIME [epoch: 6.49 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18189390888403556		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.18189390888403556 | validation: 0.13396835590337758]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_701.pth
	Model improved!!!
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14008703188080518		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.14008703188080518 | validation: 0.12709533991912722]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_702.pth
	Model improved!!!
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15593561596033792		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.15593561596033792 | validation: 0.24451186098883715]
	TIME [epoch: 6.47 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1656370869316271		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.1656370869316271 | validation: 0.13195222738660867]
	TIME [epoch: 6.46 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14279951207783692		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.14279951207783692 | validation: 0.1862767047367309]
	TIME [epoch: 6.45 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19825531496305854		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.19825531496305854 | validation: 0.250169714628043]
	TIME [epoch: 6.46 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1436358899845018		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.1436358899845018 | validation: 0.23315958704096001]
	TIME [epoch: 6.51 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16754656327448492		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.16754656327448492 | validation: 0.14784161306786467]
	TIME [epoch: 6.47 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275376234653204		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.1275376234653204 | validation: 0.12197765612493922]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_709.pth
	Model improved!!!
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12298899041488709		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.12298899041488709 | validation: 0.1705382939034756]
	TIME [epoch: 6.46 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18058554286937514		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.18058554286937514 | validation: 0.30915159188532343]
	TIME [epoch: 6.46 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17805579275155387		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.17805579275155387 | validation: 0.16558413128128555]
	TIME [epoch: 6.46 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18495671002052466		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.18495671002052466 | validation: 0.2103329304693041]
	TIME [epoch: 6.46 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15527443697564272		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.15527443697564272 | validation: 0.2295217885304425]
	TIME [epoch: 6.49 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2506717679411648		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.2506717679411648 | validation: 0.16125640012216608]
	TIME [epoch: 6.46 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20496063911679546		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.20496063911679546 | validation: 0.17479102789065798]
	TIME [epoch: 6.46 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549996460054132		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.1549996460054132 | validation: 0.23220256229762995]
	TIME [epoch: 6.46 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1675775587683793		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.1675775587683793 | validation: 0.19082429662520553]
	TIME [epoch: 6.46 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21862619793889387		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.21862619793889387 | validation: 0.2437237692626758]
	TIME [epoch: 6.46 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18249585829226236		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.18249585829226236 | validation: 0.34574962017512256]
	TIME [epoch: 6.46 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2452189713710048		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.2452189713710048 | validation: 0.13725960629207037]
	TIME [epoch: 6.51 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15656138848894013		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.15656138848894013 | validation: 0.18950767972460925]
	TIME [epoch: 6.47 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15813755892323406		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.15813755892323406 | validation: 0.2691376505013771]
	TIME [epoch: 6.46 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1701102764071956		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.1701102764071956 | validation: 0.18510756529343436]
	TIME [epoch: 6.47 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1676894975791212		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.1676894975791212 | validation: 0.19336957411852504]
	TIME [epoch: 6.47 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14876623948395024		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.14876623948395024 | validation: 0.2808783764557316]
	TIME [epoch: 6.46 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20940540503083468		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.20940540503083468 | validation: 0.18568116026892306]
	TIME [epoch: 6.47 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1625796976213067		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1625796976213067 | validation: 0.24006559512908054]
	TIME [epoch: 6.51 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20824066331400015		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.20824066331400015 | validation: 0.16027879414366186]
	TIME [epoch: 6.46 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14321931341490335		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.14321931341490335 | validation: 0.12603156577044022]
	TIME [epoch: 6.47 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544169733514846		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.1544169733514846 | validation: 0.30942960105649664]
	TIME [epoch: 6.48 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18234787810459854		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.18234787810459854 | validation: 0.1356139949120916]
	TIME [epoch: 6.46 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19086571063510363		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.19086571063510363 | validation: 0.16801121294276222]
	TIME [epoch: 6.46 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287135591304123		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.1287135591304123 | validation: 0.15622779458141856]
	TIME [epoch: 6.46 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393164625636849		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.1393164625636849 | validation: 0.13490271296388942]
	TIME [epoch: 6.48 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15041312042515345		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.15041312042515345 | validation: 0.1857510500168156]
	TIME [epoch: 6.48 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19374052967849353		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.19374052967849353 | validation: 0.3922562200188125]
	TIME [epoch: 6.46 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19227911480075932		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.19227911480075932 | validation: 0.2620820557695165]
	TIME [epoch: 6.46 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19124594490508462		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.19124594490508462 | validation: 0.24383758947273343]
	TIME [epoch: 6.45 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22663381056452764		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.22663381056452764 | validation: 0.1755881623506809]
	TIME [epoch: 6.46 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20597432136289032		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.20597432136289032 | validation: 0.2285028809916048]
	TIME [epoch: 6.46 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23501265789288925		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.23501265789288925 | validation: 0.15659959546612448]
	TIME [epoch: 6.48 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14595023733274143		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.14595023733274143 | validation: 0.1470105259679829]
	TIME [epoch: 6.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18904300490217332		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.18904300490217332 | validation: 0.1579036660250398]
	TIME [epoch: 6.46 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19262742120438492		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.19262742120438492 | validation: 0.12176587863649882]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_745.pth
	Model improved!!!
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15675353782828946		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.15675353782828946 | validation: 0.16092668543991492]
	TIME [epoch: 6.47 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15426625453200693		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.15426625453200693 | validation: 0.1787261389922547]
	TIME [epoch: 6.47 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14373066824701827		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.14373066824701827 | validation: 0.18664060449984068]
	TIME [epoch: 6.46 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14690567880910643		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.14690567880910643 | validation: 0.26799567643257327]
	TIME [epoch: 6.53 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896240406071334		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.1896240406071334 | validation: 0.23430919533582553]
	TIME [epoch: 6.48 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16147496207049092		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.16147496207049092 | validation: 0.1117972043183261]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_751.pth
	Model improved!!!
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14607793714878387		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.14607793714878387 | validation: 0.16031127153928482]
	TIME [epoch: 6.46 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133024952022913		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.133024952022913 | validation: 0.22756384820719341]
	TIME [epoch: 6.47 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21882476136595685		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.21882476136595685 | validation: 0.12697399462918446]
	TIME [epoch: 6.46 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13345461341535939		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.13345461341535939 | validation: 0.15118706581722519]
	TIME [epoch: 6.47 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385412586806879		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.1385412586806879 | validation: 0.12477136795227659]
	TIME [epoch: 6.46 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156438500010264		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.156438500010264 | validation: 0.11933678630204737]
	TIME [epoch: 6.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1644661545992335		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.1644661545992335 | validation: 0.16219046868389275]
	TIME [epoch: 6.47 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13986326764337534		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.13986326764337534 | validation: 0.2203170500592968]
	TIME [epoch: 6.46 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1680631914164815		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.1680631914164815 | validation: 0.16059211197686454]
	TIME [epoch: 6.47 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.145198089451205		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.145198089451205 | validation: 0.13333973988408954]
	TIME [epoch: 6.47 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15016542424395496		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.15016542424395496 | validation: 0.1724427497554211]
	TIME [epoch: 6.47 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16894103483961664		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.16894103483961664 | validation: 0.1844856607548286]
	TIME [epoch: 6.48 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13635848352198127		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.13635848352198127 | validation: 0.12601902761807715]
	TIME [epoch: 6.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14365264205731196		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.14365264205731196 | validation: 0.1147247620381978]
	TIME [epoch: 6.48 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14974716015325124		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.14974716015325124 | validation: 0.15801768123721865]
	TIME [epoch: 6.46 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11868083532998527		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.11868083532998527 | validation: 0.10492902995056806]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_767.pth
	Model improved!!!
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12555687923891698		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.12555687923891698 | validation: 0.13485618275428532]
	TIME [epoch: 6.46 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16068787718214173		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.16068787718214173 | validation: 0.20225139150972282]
	TIME [epoch: 6.46 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15918945684626357		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.15918945684626357 | validation: 0.16824065484187123]
	TIME [epoch: 6.46 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14560401137430812		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.14560401137430812 | validation: 0.15437232013088298]
	TIME [epoch: 6.49 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536576324503088		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.1536576324503088 | validation: 0.15047427480842415]
	TIME [epoch: 6.47 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13187720748472737		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.13187720748472737 | validation: 0.16160402256017053]
	TIME [epoch: 6.46 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256027265438004		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.1256027265438004 | validation: 0.13988949446637688]
	TIME [epoch: 6.46 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17455766347996723		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.17455766347996723 | validation: 0.36432136215158195]
	TIME [epoch: 6.45 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28175109186450087		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.28175109186450087 | validation: 0.3800034307826009]
	TIME [epoch: 6.46 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17061078622792827		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.17061078622792827 | validation: 0.19638771948457026]
	TIME [epoch: 6.46 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1843998363391094		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.1843998363391094 | validation: 0.23640500002385995]
	TIME [epoch: 6.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14901860904797176		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.14901860904797176 | validation: 0.13380352942691132]
	TIME [epoch: 6.46 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12684444253301286		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.12684444253301286 | validation: 0.18729687790413593]
	TIME [epoch: 6.46 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12672336151675198		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.12672336151675198 | validation: 0.09877327474768627]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_781.pth
	Model improved!!!
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328883160358184		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.1328883160358184 | validation: 0.15537930665420402]
	TIME [epoch: 6.46 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300449651361293		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.1300449651361293 | validation: 0.13354019993275537]
	TIME [epoch: 6.46 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14561562494908492		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.14561562494908492 | validation: 0.218673714538616]
	TIME [epoch: 6.46 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2059199310633148		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.2059199310633148 | validation: 0.3018929846572344]
	TIME [epoch: 6.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14436150633213218		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.14436150633213218 | validation: 0.13713771974648883]
	TIME [epoch: 6.47 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12117222084753557		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.12117222084753557 | validation: 0.13952230081153438]
	TIME [epoch: 6.46 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15032534903197386		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.15032534903197386 | validation: 0.16875457912431535]
	TIME [epoch: 6.46 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12966470398761534		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.12966470398761534 | validation: 0.1733814509315609]
	TIME [epoch: 6.46 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1594779019902946		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.1594779019902946 | validation: 0.17221729107253098]
	TIME [epoch: 6.46 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1368973458086368		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.1368973458086368 | validation: 0.18081124584555283]
	TIME [epoch: 6.46 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10557184369676847		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.10557184369676847 | validation: 0.09967672060074019]
	TIME [epoch: 6.49 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12610207879439803		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.12610207879439803 | validation: 0.1417965611138646]
	TIME [epoch: 6.47 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346759652201755		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.1346759652201755 | validation: 0.2370936157141002]
	TIME [epoch: 6.46 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17518900048700192		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.17518900048700192 | validation: 0.20078950082906502]
	TIME [epoch: 6.46 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16394503693385154		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.16394503693385154 | validation: 0.24080811262119192]
	TIME [epoch: 6.46 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1569314483212086		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.1569314483212086 | validation: 0.14193202959287735]
	TIME [epoch: 6.46 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11489013980688584		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.11489013980688584 | validation: 0.11731763680551378]
	TIME [epoch: 6.46 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12823850999000408		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.12823850999000408 | validation: 0.13280679680164956]
	TIME [epoch: 6.48 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13063859026946922		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.13063859026946922 | validation: 0.14354719877904862]
	TIME [epoch: 6.48 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13099676140519118		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.13099676140519118 | validation: 0.12041116107419235]
	TIME [epoch: 6.46 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12417273046159276		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.12417273046159276 | validation: 0.15765883817632376]
	TIME [epoch: 6.46 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1501537877435336		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.1501537877435336 | validation: 0.2843129574037672]
	TIME [epoch: 6.46 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16430372713809707		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.16430372713809707 | validation: 0.18833140360143805]
	TIME [epoch: 6.46 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13385819965377388		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.13385819965377388 | validation: 0.1588967108319674]
	TIME [epoch: 6.46 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11405432621531073		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.11405432621531073 | validation: 0.09842371722540538]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_806.pth
	Model improved!!!
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1284198127381896		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.1284198127381896 | validation: 0.17559021802248403]
	TIME [epoch: 6.48 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19937754496569526		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.19937754496569526 | validation: 0.15960211066417446]
	TIME [epoch: 6.46 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13202261923074218		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.13202261923074218 | validation: 0.2452114711629067]
	TIME [epoch: 6.46 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532085990862116		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.1532085990862116 | validation: 0.18642169889778734]
	TIME [epoch: 6.46 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12254223047922319		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.12254223047922319 | validation: 0.19464691138894666]
	TIME [epoch: 6.46 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11211371300834143		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.11211371300834143 | validation: 0.1969787563941763]
	TIME [epoch: 6.46 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13080517153444354		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.13080517153444354 | validation: 0.12476626964234326]
	TIME [epoch: 6.48 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1246318455084548		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.1246318455084548 | validation: 0.1634090085808051]
	TIME [epoch: 6.48 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13744196253240865		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.13744196253240865 | validation: 0.14450963147398066]
	TIME [epoch: 6.46 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12917331866467363		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.12917331866467363 | validation: 0.3497035879751684]
	TIME [epoch: 6.46 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20311606996579368		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.20311606996579368 | validation: 0.12085662442856931]
	TIME [epoch: 6.46 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14217565092733536		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.14217565092733536 | validation: 0.25284277662479193]
	TIME [epoch: 6.46 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17339835220426345		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.17339835220426345 | validation: 0.10185764581266007]
	TIME [epoch: 6.46 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11030021719392986		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.11030021719392986 | validation: 0.16741493838605034]
	TIME [epoch: 6.46 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13089760693818323		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.13089760693818323 | validation: 0.1947428035447314]
	TIME [epoch: 6.49 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1071978255726008		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.1071978255726008 | validation: 0.16503843881397395]
	TIME [epoch: 6.46 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15206480559173594		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.15206480559173594 | validation: 0.13768281276525035]
	TIME [epoch: 6.46 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12480425267297432		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.12480425267297432 | validation: 0.12894409487542174]
	TIME [epoch: 6.46 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11113823546698354		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.11113823546698354 | validation: 0.15546853789327056]
	TIME [epoch: 6.46 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1017225405282419		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.1017225405282419 | validation: 0.15008721698168997]
	TIME [epoch: 6.46 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11596775422522768		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.11596775422522768 | validation: 0.15246869842676736]
	TIME [epoch: 6.46 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13059363284759973		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.13059363284759973 | validation: 0.1198515615664387]
	TIME [epoch: 6.49 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12026191582362844		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.12026191582362844 | validation: 0.13869951172647813]
	TIME [epoch: 6.46 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14083360927867156		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.14083360927867156 | validation: 0.1595499353734189]
	TIME [epoch: 6.46 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14689691835607716		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.14689691835607716 | validation: 0.19010962226523176]
	TIME [epoch: 6.46 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14573000028730135		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.14573000028730135 | validation: 0.15457317736713422]
	TIME [epoch: 6.46 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126376284802359		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.126376284802359 | validation: 0.19798860346049785]
	TIME [epoch: 6.46 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16569336913767066		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.16569336913767066 | validation: 0.1422712122115578]
	TIME [epoch: 6.46 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341684363670485		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.1341684363670485 | validation: 0.10382723962722913]
	TIME [epoch: 6.49 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11244153650994766		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.11244153650994766 | validation: 0.09282613459018826]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_836.pth
	Model improved!!!
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386180021635678		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.1386180021635678 | validation: 0.16293181738276846]
	TIME [epoch: 6.46 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13613765890343302		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.13613765890343302 | validation: 0.09575905518840064]
	TIME [epoch: 6.46 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1034256713835257		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.1034256713835257 | validation: 0.1547819011832221]
	TIME [epoch: 6.46 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15671379151390732		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.15671379151390732 | validation: 0.2560870529642842]
	TIME [epoch: 6.46 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17849939380432675		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.17849939380432675 | validation: 0.13814741233857178]
	TIME [epoch: 6.45 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12535052163050747		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.12535052163050747 | validation: 0.21398458182778726]
	TIME [epoch: 6.49 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15956797095935504		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.15956797095935504 | validation: 0.174658484458108]
	TIME [epoch: 6.47 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14634934258269586		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.14634934258269586 | validation: 0.16041893227676302]
	TIME [epoch: 6.46 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13705085233772368		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.13705085233772368 | validation: 0.13143876610116315]
	TIME [epoch: 6.46 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10977934666713085		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.10977934666713085 | validation: 0.16097085265927313]
	TIME [epoch: 6.46 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1589376612640881		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.1589376612640881 | validation: 0.11382430578664578]
	TIME [epoch: 6.46 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10753680881903484		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.10753680881903484 | validation: 0.1133986936014556]
	TIME [epoch: 6.46 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1490603438762214		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.1490603438762214 | validation: 0.15768069095557716]
	TIME [epoch: 6.49 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10940817369641744		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.10940817369641744 | validation: 0.15357569334578616]
	TIME [epoch: 6.47 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12676550452974675		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.12676550452974675 | validation: 0.09087479627022155]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_851.pth
	Model improved!!!
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10321663270997383		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.10321663270997383 | validation: 0.16281083328250945]
	TIME [epoch: 6.45 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11633842722502186		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.11633842722502186 | validation: 0.11018862593574204]
	TIME [epoch: 6.46 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12335030008242365		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.12335030008242365 | validation: 0.13330107120971904]
	TIME [epoch: 6.45 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09922057406113365		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.09922057406113365 | validation: 0.0918297719965804]
	TIME [epoch: 6.45 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09651356048436405		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.09651356048436405 | validation: 0.09378496132990741]
	TIME [epoch: 6.48 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10311248187623734		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.10311248187623734 | validation: 0.09061795532735563]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_857.pth
	Model improved!!!
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10546347460664393		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.10546347460664393 | validation: 0.18934937376878502]
	TIME [epoch: 6.45 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16525297828546065		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.16525297828546065 | validation: 0.14779358264809997]
	TIME [epoch: 6.44 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14897377856706584		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.14897377856706584 | validation: 0.12168912760840676]
	TIME [epoch: 6.45 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12705955676634423		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.12705955676634423 | validation: 0.14421366117932025]
	TIME [epoch: 6.45 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21268210940564714		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.21268210940564714 | validation: 0.19888819888053452]
	TIME [epoch: 6.44 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718576077606186		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.1718576077606186 | validation: 0.14013956026664243]
	TIME [epoch: 6.46 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14738691513478458		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.14738691513478458 | validation: 0.15347294179490922]
	TIME [epoch: 6.47 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11259736347112097		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.11259736347112097 | validation: 0.17848698989937933]
	TIME [epoch: 6.45 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10656144230814368		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.10656144230814368 | validation: 0.11756359680696353]
	TIME [epoch: 6.45 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17606370970152024		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.17606370970152024 | validation: 0.22044301118484855]
	TIME [epoch: 6.45 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21649461226621838		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.21649461226621838 | validation: 0.16922484094738113]
	TIME [epoch: 6.45 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343495280201863		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.1343495280201863 | validation: 0.1352562502069209]
	TIME [epoch: 6.45 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12698622262463138		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.12698622262463138 | validation: 0.10660663779546486]
	TIME [epoch: 6.47 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13695824234569848		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.13695824234569848 | validation: 0.11381183020778451]
	TIME [epoch: 6.48 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12152079940552571		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.12152079940552571 | validation: 0.14305197201330694]
	TIME [epoch: 6.46 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12898002571254277		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.12898002571254277 | validation: 0.1327888959351957]
	TIME [epoch: 6.46 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10557571115070344		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.10557571115070344 | validation: 0.09979946377789674]
	TIME [epoch: 6.46 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11866161770486437		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.11866161770486437 | validation: 0.09805789061369982]
	TIME [epoch: 6.45 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11489227437485906		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.11489227437485906 | validation: 0.1403873823240001]
	TIME [epoch: 6.46 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1149528508595715		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.1149528508595715 | validation: 0.16695585168739627]
	TIME [epoch: 6.46 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1043165277476556		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.1043165277476556 | validation: 0.17417547955414875]
	TIME [epoch: 6.49 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393624579751881		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.1393624579751881 | validation: 0.14851519461388865]
	TIME [epoch: 6.46 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15035533059411155		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.15035533059411155 | validation: 0.12574005557889756]
	TIME [epoch: 6.46 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1145205127027204		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.1145205127027204 | validation: 0.13930723220414062]
	TIME [epoch: 6.46 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10725681700818906		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.10725681700818906 | validation: 0.11833159256520943]
	TIME [epoch: 6.46 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11497085545342756		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.11497085545342756 | validation: 0.156866009073613]
	TIME [epoch: 6.46 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11959330607551616		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.11959330607551616 | validation: 0.14965170556718654]
	TIME [epoch: 6.46 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11269027813622788		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.11269027813622788 | validation: 0.12507555688501612]
	TIME [epoch: 6.49 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10572886004237025		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.10572886004237025 | validation: 0.10936458182671903]
	TIME [epoch: 6.46 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900293506916676		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.10900293506916676 | validation: 0.12117295735285051]
	TIME [epoch: 6.46 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11826720272628931		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.11826720272628931 | validation: 0.11488648258567309]
	TIME [epoch: 6.46 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09255416591628185		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.09255416591628185 | validation: 0.13475049249447577]
	TIME [epoch: 6.46 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09861297036292727		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.09861297036292727 | validation: 0.17352941538929884]
	TIME [epoch: 6.46 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1188240433597886		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.1188240433597886 | validation: 0.1523968086195864]
	TIME [epoch: 6.46 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11327734423709916		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.11327734423709916 | validation: 0.10597234821340776]
	TIME [epoch: 6.49 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10115643022494449		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.10115643022494449 | validation: 0.08596276778758523]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_893.pth
	Model improved!!!
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10991503186438306		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.10991503186438306 | validation: 0.1374405596589181]
	TIME [epoch: 6.46 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11385962107835057		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.11385962107835057 | validation: 0.14079667061178644]
	TIME [epoch: 6.45 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12816058697724517		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.12816058697724517 | validation: 0.08773913890060993]
	TIME [epoch: 6.46 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09241787403871908		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.09241787403871908 | validation: 0.10311044560655015]
	TIME [epoch: 6.46 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13116447585087965		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.13116447585087965 | validation: 0.15224094829365065]
	TIME [epoch: 6.46 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15414975628886154		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.15414975628886154 | validation: 0.2996064870612307]
	TIME [epoch: 6.48 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16202388086048664		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.16202388086048664 | validation: 0.1101374852012659]
	TIME [epoch: 6.46 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11526192631294617		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.11526192631294617 | validation: 0.12635852763426886]
	TIME [epoch: 6.46 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11710691621486505		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.11710691621486505 | validation: 0.13978030403461134]
	TIME [epoch: 6.46 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167010067341783		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.10167010067341783 | validation: 0.09169512192400363]
	TIME [epoch: 6.45 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08696688766991917		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.08696688766991917 | validation: 0.10348569710778996]
	TIME [epoch: 6.46 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104258723378221		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.1104258723378221 | validation: 0.10502932763094712]
	TIME [epoch: 6.46 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11208792096559327		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.11208792096559327 | validation: 0.11141388951444206]
	TIME [epoch: 6.48 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11636628674543181		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.11636628674543181 | validation: 0.16502161343855748]
	TIME [epoch: 6.46 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11540687537973214		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.11540687537973214 | validation: 0.13147682030611507]
	TIME [epoch: 6.46 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452722606699575		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.09452722606699575 | validation: 0.11348562472916963]
	TIME [epoch: 6.46 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12818863981641826		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.12818863981641826 | validation: 0.11636969907803532]
	TIME [epoch: 6.46 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12511571035179306		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.12511571035179306 | validation: 0.12462075473979749]
	TIME [epoch: 6.45 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10951785738320993		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.10951785738320993 | validation: 0.11952121986470965]
	TIME [epoch: 6.46 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13015066694607005		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.13015066694607005 | validation: 0.09381638942229023]
	TIME [epoch: 6.47 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09220705054527564		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.09220705054527564 | validation: 0.11340655258419848]
	TIME [epoch: 6.48 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12123827070342912		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.12123827070342912 | validation: 0.13235572711839308]
	TIME [epoch: 6.46 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09626878250626747		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.09626878250626747 | validation: 0.12559891304039206]
	TIME [epoch: 6.46 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10083831484278179		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.10083831484278179 | validation: 0.1094520169424984]
	TIME [epoch: 6.46 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12828997307528292		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.12828997307528292 | validation: 0.1416084374221166]
	TIME [epoch: 6.46 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09641886294561858		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.09641886294561858 | validation: 0.10247335348532291]
	TIME [epoch: 6.46 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09808582822087067		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.09808582822087067 | validation: 0.12564736192358442]
	TIME [epoch: 6.47 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09427641446935393		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.09427641446935393 | validation: 0.13630907259774852]
	TIME [epoch: 6.47 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08459440107118894		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.08459440107118894 | validation: 0.12877124701849313]
	TIME [epoch: 6.46 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0941305611079354		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.0941305611079354 | validation: 0.11850610826897441]
	TIME [epoch: 6.46 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09227340629003306		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.09227340629003306 | validation: 0.11516174893669416]
	TIME [epoch: 6.46 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09193196018022606		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.09193196018022606 | validation: 0.16442484718250827]
	TIME [epoch: 6.46 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13055696598285038		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.13055696598285038 | validation: 0.10518563432843489]
	TIME [epoch: 6.46 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12633834274980152		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.12633834274980152 | validation: 0.13066096074405947]
	TIME [epoch: 6.46 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10728958595821012		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.10728958595821012 | validation: 0.12552762551912752]
	TIME [epoch: 6.49 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08884473876436545		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.08884473876436545 | validation: 0.10751290446663035]
	TIME [epoch: 6.46 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10292548721256557		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.10292548721256557 | validation: 0.15041846982354487]
	TIME [epoch: 6.45 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09492652464089452		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.09492652464089452 | validation: 0.19099027553908263]
	TIME [epoch: 6.45 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11010386514678075		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.11010386514678075 | validation: 0.14443520935483503]
	TIME [epoch: 6.44 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11295287561450033		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.11295287561450033 | validation: 0.11231455108710581]
	TIME [epoch: 6.44 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0914024603724613		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.0914024603724613 | validation: 0.14358980143321418]
	TIME [epoch: 6.44 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0972363014855902		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.0972363014855902 | validation: 0.12215664468873755]
	TIME [epoch: 6.47 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09384722332971646		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.09384722332971646 | validation: 0.15574479141043035]
	TIME [epoch: 6.45 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10298754571770694		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.10298754571770694 | validation: 0.15656946871075372]
	TIME [epoch: 6.44 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11490007821543793		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.11490007821543793 | validation: 0.18315299142979985]
	TIME [epoch: 6.44 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10205258966280037		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.10205258966280037 | validation: 0.16355811958412048]
	TIME [epoch: 6.44 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1100955858272837		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.1100955858272837 | validation: 0.13883617516241262]
	TIME [epoch: 6.44 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10296007103115187		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.10296007103115187 | validation: 0.16837254685561376]
	TIME [epoch: 6.44 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13117150189896082		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.13117150189896082 | validation: 0.15899753207805598]
	TIME [epoch: 6.47 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10836895274057226		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.10836895274057226 | validation: 0.10891938438019823]
	TIME [epoch: 6.45 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09116742955995434		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.09116742955995434 | validation: 0.13318949387604934]
	TIME [epoch: 6.44 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09387362102931646		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.09387362102931646 | validation: 0.09319966256277504]
	TIME [epoch: 6.44 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10246003766014458		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.10246003766014458 | validation: 0.13401582083996702]
	TIME [epoch: 6.44 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12341894337641976		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.12341894337641976 | validation: 0.14171075792713644]
	TIME [epoch: 6.44 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11113647764705117		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.11113647764705117 | validation: 0.1284944069074291]
	TIME [epoch: 6.44 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062417259189081		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.1062417259189081 | validation: 0.14140556430447987]
	TIME [epoch: 6.47 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09353020213475362		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.09353020213475362 | validation: 0.23592856699665113]
	TIME [epoch: 6.45 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13512842963881505		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.13512842963881505 | validation: 0.17949853282629186]
	TIME [epoch: 6.44 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09603700349140903		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.09603700349140903 | validation: 0.1275394889422487]
	TIME [epoch: 6.44 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10168178825009949		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.10168178825009949 | validation: 0.15410682744716026]
	TIME [epoch: 6.45 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10649944729304604		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.10649944729304604 | validation: 0.09462705103880187]
	TIME [epoch: 6.45 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10259753507725906		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.10259753507725906 | validation: 0.09759476670476244]
	TIME [epoch: 6.45 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08723018940384014		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.08723018940384014 | validation: 0.10771427713185514]
	TIME [epoch: 6.47 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08167583878315107		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.08167583878315107 | validation: 0.17635556528129442]
	TIME [epoch: 6.47 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10921503667028111		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.10921503667028111 | validation: 0.14760277030471833]
	TIME [epoch: 6.46 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09195420804765336		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.09195420804765336 | validation: 0.11975167397243745]
	TIME [epoch: 6.46 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08171680784077447		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.08171680784077447 | validation: 0.10462177717730159]
	TIME [epoch: 6.46 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09279326312125895		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.09279326312125895 | validation: 0.17337641991093602]
	TIME [epoch: 6.46 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14886532699867053		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.14886532699867053 | validation: 0.13173047261093637]
	TIME [epoch: 6.46 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09656689999502868		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.09656689999502868 | validation: 0.09356272666281601]
	TIME [epoch: 6.47 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09635292500011086		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.09635292500011086 | validation: 0.12979950520998534]
	TIME [epoch: 6.47 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09593586015815586		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.09593586015815586 | validation: 0.12093158264203868]
	TIME [epoch: 6.46 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0992996638025439		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.0992996638025439 | validation: 0.12181262571859543]
	TIME [epoch: 6.46 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10233879010267985		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.10233879010267985 | validation: 0.10626070050598882]
	TIME [epoch: 6.46 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926840928243909		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.09926840928243909 | validation: 0.10359566712102047]
	TIME [epoch: 6.46 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08525376084692375		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.08525376084692375 | validation: 0.11117221325696551]
	TIME [epoch: 6.46 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0772513373328521		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.0772513373328521 | validation: 0.10047184322707295]
	TIME [epoch: 6.46 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0919261444904873		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.0919261444904873 | validation: 0.11412228397693501]
	TIME [epoch: 6.49 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060941988072482		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.1060941988072482 | validation: 0.12309174487790475]
	TIME [epoch: 6.46 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09217932870528098		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.09217932870528098 | validation: 0.10082575494643338]
	TIME [epoch: 6.46 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09238756475379785		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.09238756475379785 | validation: 0.09113116674922271]
	TIME [epoch: 6.45 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08720709776271147		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.08720709776271147 | validation: 0.08930096372934344]
	TIME [epoch: 6.46 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08154467053864103		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.08154467053864103 | validation: 0.16044172226010647]
	TIME [epoch: 6.46 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11777114037192495		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.11777114037192495 | validation: 0.13971372153442782]
	TIME [epoch: 6.46 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11427206529243866		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.11427206529243866 | validation: 0.14677891964969875]
	TIME [epoch: 6.49 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0958788510553095		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.0958788510553095 | validation: 0.1538886874164825]
	TIME [epoch: 6.46 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377712919233264		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.1377712919233264 | validation: 0.1710693909494644]
	TIME [epoch: 6.45 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12322765281937498		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.12322765281937498 | validation: 0.12918183738305533]
	TIME [epoch: 6.45 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11844530288804445		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.11844530288804445 | validation: 0.12033206621072502]
	TIME [epoch: 6.46 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0987458487543798		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.0987458487543798 | validation: 0.10633002440777442]
	TIME [epoch: 6.45 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0922745675375026		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.0922745675375026 | validation: 0.13742979437319328]
	TIME [epoch: 6.46 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09686212478094242		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.09686212478094242 | validation: 0.1274623333931439]
	TIME [epoch: 6.49 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11333904236099861		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.11333904236099861 | validation: 0.1285780815254355]
	TIME [epoch: 6.46 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09729566745397066		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.09729566745397066 | validation: 0.09647015806539268]
	TIME [epoch: 6.45 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09158487373062676		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.09158487373062676 | validation: 0.10877147106546488]
	TIME [epoch: 6.46 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11690116096072707		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.11690116096072707 | validation: 0.13726997492875648]
	TIME [epoch: 6.45 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10360768534078407		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.10360768534078407 | validation: 0.09549556452210892]
	TIME [epoch: 6.45 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09737113814851123		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.09737113814851123 | validation: 0.0998154740559032]
	TIME [epoch: 6.46 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10271847701991635		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.10271847701991635 | validation: 0.12136376974924082]
	TIME [epoch: 6.48 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12312383952647155		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.12312383952647155 | validation: 0.13139681220415966]
	TIME [epoch: 6.46 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11987491560380203		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.11987491560380203 | validation: 0.12001391139598883]
	TIME [epoch: 6.46 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09221376692092167		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.09221376692092167 | validation: 0.12204878625990297]
	TIME [epoch: 6.45 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08345064377133962		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.08345064377133962 | validation: 0.0890291612001457]
	TIME [epoch: 6.46 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09909745193801822		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.09909745193801822 | validation: 0.10236898937836525]
	TIME [epoch: 6.45 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1010174682476365		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.1010174682476365 | validation: 0.09991051066383012]
	TIME [epoch: 6.46 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1136738892767148		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.1136738892767148 | validation: 0.10205980366114395]
	TIME [epoch: 6.47 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10266200949661726		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.10266200949661726 | validation: 0.08750508542720692]
	TIME [epoch: 6.47 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10110015336759003		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.10110015336759003 | validation: 0.11064916777221712]
	TIME [epoch: 6.46 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10823825811669974		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.10823825811669974 | validation: 0.08666376760978882]
	TIME [epoch: 6.46 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08670204602399052		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.08670204602399052 | validation: 0.09862385855231781]
	TIME [epoch: 6.46 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104280353941419		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.1104280353941419 | validation: 0.08692346007087831]
	TIME [epoch: 6.45 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13916288255679965		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.13916288255679965 | validation: 0.1274543019900172]
	TIME [epoch: 6.45 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10141263887124512		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.10141263887124512 | validation: 0.10213617503533336]
	TIME [epoch: 6.47 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10122011910534759		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.10122011910534759 | validation: 0.06537960705383311]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_1007.pth
	Model improved!!!
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09688215005464587		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.09688215005464587 | validation: 0.12689480109774048]
	TIME [epoch: 6.46 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12753248054261096		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.12753248054261096 | validation: 0.1172229523483579]
	TIME [epoch: 6.46 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09842048799010199		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.09842048799010199 | validation: 0.1352528545870891]
	TIME [epoch: 6.47 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11242606723546397		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.11242606723546397 | validation: 0.09319427917862808]
	TIME [epoch: 6.46 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08671465242400647		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.08671465242400647 | validation: 0.06848479740482065]
	TIME [epoch: 6.46 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08369531926466355		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.08369531926466355 | validation: 0.08041633278127193]
	TIME [epoch: 6.47 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08992379148860324		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.08992379148860324 | validation: 0.09506321068079547]
	TIME [epoch: 6.48 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08962556276179043		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.08962556276179043 | validation: 0.09452343151828851]
	TIME [epoch: 6.46 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09175646299573723		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.09175646299573723 | validation: 0.08581225017242025]
	TIME [epoch: 6.46 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10704649327466056		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.10704649327466056 | validation: 0.09694285126337995]
	TIME [epoch: 6.47 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16335346707335882		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.16335346707335882 | validation: 0.15297448612962875]
	TIME [epoch: 6.46 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11518838633904593		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.11518838633904593 | validation: 0.08775293273240464]
	TIME [epoch: 6.46 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08309514766804157		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.08309514766804157 | validation: 0.09689652135231032]
	TIME [epoch: 6.48 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10720403546760496		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.10720403546760496 | validation: 0.0981497408032715]
	TIME [epoch: 6.49 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09569737335739734		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.09569737335739734 | validation: 0.11304784659139351]
	TIME [epoch: 6.46 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10648028816838519		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.10648028816838519 | validation: 0.14057684333809914]
	TIME [epoch: 6.46 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09574178742107645		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.09574178742107645 | validation: 0.09930122514065422]
	TIME [epoch: 6.46 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.087286787542877		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.087286787542877 | validation: 0.14429839375344808]
	TIME [epoch: 6.46 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.102519570206095		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.102519570206095 | validation: 0.07355248847981301]
	TIME [epoch: 6.46 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07483549209616498		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.07483549209616498 | validation: 0.10038914460530571]
	TIME [epoch: 6.46 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08504280315268396		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.08504280315268396 | validation: 0.09908076009582072]
	TIME [epoch: 6.49 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0774356811270357		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.0774356811270357 | validation: 0.07492291110274209]
	TIME [epoch: 6.46 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0821039947746705		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.0821039947746705 | validation: 0.07638636298314429]
	TIME [epoch: 6.46 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06997843360505812		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.06997843360505812 | validation: 0.09866108716096901]
	TIME [epoch: 6.46 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08923735892450776		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.08923735892450776 | validation: 0.10422669198458447]
	TIME [epoch: 6.46 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11017731662097188		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.11017731662097188 | validation: 0.0795568950019864]
	TIME [epoch: 6.46 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08422379202828986		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.08422379202828986 | validation: 0.0673493911019524]
	TIME [epoch: 6.47 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0870016470486687		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.0870016470486687 | validation: 0.08813295725097399]
	TIME [epoch: 6.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08517011923047703		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.08517011923047703 | validation: 0.07896977123930024]
	TIME [epoch: 6.47 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07699809411464884		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.07699809411464884 | validation: 0.10016580003873356]
	TIME [epoch: 6.46 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09103277506062035		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.09103277506062035 | validation: 0.11392595163725996]
	TIME [epoch: 6.47 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07550894080265415		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.07550894080265415 | validation: 0.09603272549661622]
	TIME [epoch: 6.46 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12112216921096006		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.12112216921096006 | validation: 0.09780368003957181]
	TIME [epoch: 6.46 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1127717353890443		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.1127717353890443 | validation: 0.11313417638257921]
	TIME [epoch: 6.46 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10073487337360332		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.10073487337360332 | validation: 0.09164823526470992]
	TIME [epoch: 6.51 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0805991331674963		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.0805991331674963 | validation: 0.08517387539844831]
	TIME [epoch: 6.47 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08520556875449176		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.08520556875449176 | validation: 0.10169315378703594]
	TIME [epoch: 6.47 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11376329330332591		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.11376329330332591 | validation: 0.09242812825670953]
	TIME [epoch: 6.47 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0840858845279566		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.0840858845279566 | validation: 0.0915258581692207]
	TIME [epoch: 6.46 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07729880726458072		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.07729880726458072 | validation: 0.1166452361504338]
	TIME [epoch: 6.46 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0871482599812632		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.0871482599812632 | validation: 0.10434980303830273]
	TIME [epoch: 6.46 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09053954156679674		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.09053954156679674 | validation: 0.12101387429797676]
	TIME [epoch: 6.49 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09897425374816302		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.09897425374816302 | validation: 0.10593042833707689]
	TIME [epoch: 6.47 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08294868194592209		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.08294868194592209 | validation: 0.0885226303699895]
	TIME [epoch: 6.47 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08203265354730946		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.08203265354730946 | validation: 0.10007644410128318]
	TIME [epoch: 6.46 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09314042839906321		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.09314042839906321 | validation: 0.09176949673181199]
	TIME [epoch: 6.46 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10236292227602407		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.10236292227602407 | validation: 0.12126745403030216]
	TIME [epoch: 6.46 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10902700824021722		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.10902700824021722 | validation: 0.08901422237879379]
	TIME [epoch: 6.46 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07417129917998518		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.07417129917998518 | validation: 0.08342123966063231]
	TIME [epoch: 6.48 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888587544941391		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.0888587544941391 | validation: 0.09471366333793774]
	TIME [epoch: 6.49 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10247665090541411		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.10247665090541411 | validation: 0.10872768959835354]
	TIME [epoch: 6.47 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10794210604873804		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.10794210604873804 | validation: 0.10933514988568327]
	TIME [epoch: 6.46 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09920863741444927		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.09920863741444927 | validation: 0.10913555526915582]
	TIME [epoch: 6.47 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09625558508448553		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.09625558508448553 | validation: 0.10684731276525575]
	TIME [epoch: 6.47 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08433599155332303		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.08433599155332303 | validation: 0.09360743324997978]
	TIME [epoch: 6.46 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08721978523700907		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.08721978523700907 | validation: 0.07198631495802171]
	TIME [epoch: 6.48 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791754542627306		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.0791754542627306 | validation: 0.13735953727760364]
	TIME [epoch: 6.49 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08465298856698594		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.08465298856698594 | validation: 0.10602461259397165]
	TIME [epoch: 6.47 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07239071626900996		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.07239071626900996 | validation: 0.08816558811320555]
	TIME [epoch: 6.46 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08145919550456807		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.08145919550456807 | validation: 0.06934177902663717]
	TIME [epoch: 6.47 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06877260316988024		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.06877260316988024 | validation: 0.0757482657080679]
	TIME [epoch: 6.46 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08106057849526137		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.08106057849526137 | validation: 0.14990631373096858]
	TIME [epoch: 6.47 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10500363149400355		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.10500363149400355 | validation: 0.12245399771474277]
	TIME [epoch: 6.47 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08955825621308554		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.08955825621308554 | validation: 0.09324265098005367]
	TIME [epoch: 6.51 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08753869679872298		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.08753869679872298 | validation: 0.0967426486546184]
	TIME [epoch: 6.47 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08231963048859688		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.08231963048859688 | validation: 0.09214770171957827]
	TIME [epoch: 6.47 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09197880208585696		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.09197880208585696 | validation: 0.0946165999364555]
	TIME [epoch: 6.47 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08146166600729426		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.08146166600729426 | validation: 0.07478774667871235]
	TIME [epoch: 6.47 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06875158571235956		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.06875158571235956 | validation: 0.07323126447308032]
	TIME [epoch: 6.47 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07738177901307897		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.07738177901307897 | validation: 0.09335149348703457]
	TIME [epoch: 6.47 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08364918182569471		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.08364918182569471 | validation: 0.08231791870751579]
	TIME [epoch: 6.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08269466839361558		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.08269466839361558 | validation: 0.08482338515997054]
	TIME [epoch: 6.47 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07252456482050978		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.07252456482050978 | validation: 0.07836197073723825]
	TIME [epoch: 6.47 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07311764101877251		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.07311764101877251 | validation: 0.08278187581652961]
	TIME [epoch: 6.47 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.079378157149274		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.079378157149274 | validation: 0.07436495315751379]
	TIME [epoch: 6.47 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07068622103914525		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.07068622103914525 | validation: 0.08450664673270485]
	TIME [epoch: 6.46 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08193046252121483		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.08193046252121483 | validation: 0.08082278658993311]
	TIME [epoch: 6.47 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09395125738595417		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.09395125738595417 | validation: 0.10793417117740933]
	TIME [epoch: 6.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10529590765283345		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.10529590765283345 | validation: 0.0881109436387162]
	TIME [epoch: 6.47 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08255452584236328		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.08255452584236328 | validation: 0.09607641722646325]
	TIME [epoch: 6.47 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07646316821882962		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.07646316821882962 | validation: 0.08238592408093068]
	TIME [epoch: 6.47 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0892062412783829		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.0892062412783829 | validation: 0.09387629010323345]
	TIME [epoch: 6.47 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08762120215893476		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.08762120215893476 | validation: 0.07958494851285018]
	TIME [epoch: 6.46 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127359024006195		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.08127359024006195 | validation: 0.0786084150296042]
	TIME [epoch: 6.46 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09571839675155489		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.09571839675155489 | validation: 0.09004359355060584]
	TIME [epoch: 6.51 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06964936440754906		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.06964936440754906 | validation: 0.09618410815710066]
	TIME [epoch: 6.47 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07606923270536727		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.07606923270536727 | validation: 0.09222852532785897]
	TIME [epoch: 6.47 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09958744300247188		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.09958744300247188 | validation: 0.08931042956056306]
	TIME [epoch: 6.47 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08908092418322264		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.08908092418322264 | validation: 0.08504294017928954]
	TIME [epoch: 6.47 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07207193025682937		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.07207193025682937 | validation: 0.07651444760151196]
	TIME [epoch: 6.47 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07607204601794208		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.07607204601794208 | validation: 0.09852029761638251]
	TIME [epoch: 6.47 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07881654243886516		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.07881654243886516 | validation: 0.07133998201334787]
	TIME [epoch: 6.51 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323923961881291		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.08323923961881291 | validation: 0.11605089700304624]
	TIME [epoch: 6.47 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08622583846562562		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.08622583846562562 | validation: 0.09800583040210152]
	TIME [epoch: 6.46 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08295856988842949		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.08295856988842949 | validation: 0.07686297885913725]
	TIME [epoch: 6.46 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08659383400426736		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.08659383400426736 | validation: 0.09903832663613432]
	TIME [epoch: 6.47 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08042508603674219		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.08042508603674219 | validation: 0.08511097326193187]
	TIME [epoch: 6.47 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10470612637634788		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.10470612637634788 | validation: 0.09723381770800962]
	TIME [epoch: 6.46 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07009912768385045		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.07009912768385045 | validation: 0.08068186358988282]
	TIME [epoch: 6.49 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08033674262985756		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.08033674262985756 | validation: 0.09813676054856536]
	TIME [epoch: 6.48 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08342976778336897		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.08342976778336897 | validation: 0.12141480371136566]
	TIME [epoch: 6.47 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09114068130109532		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.09114068130109532 | validation: 0.11121508865427661]
	TIME [epoch: 6.46 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07442440593000732		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.07442440593000732 | validation: 0.09342549872974054]
	TIME [epoch: 6.47 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07266049582657078		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.07266049582657078 | validation: 0.10378613127084517]
	TIME [epoch: 6.46 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08234281844661544		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.08234281844661544 | validation: 0.08518138756078195]
	TIME [epoch: 6.46 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08339676474727725		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.08339676474727725 | validation: 0.11495586408819698]
	TIME [epoch: 6.48 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09690972732954072		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.09690972732954072 | validation: 0.08948005475782043]
	TIME [epoch: 6.48 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07693714084780298		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.07693714084780298 | validation: 0.09223355184491752]
	TIME [epoch: 6.57 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08370109076347639		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.08370109076347639 | validation: 0.07849660471062664]
	TIME [epoch: 6.47 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07186833289986672		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.07186833289986672 | validation: 0.091549873053768]
	TIME [epoch: 6.46 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07076291928443237		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.07076291928443237 | validation: 0.10283856570811285]
	TIME [epoch: 6.45 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07981072673835035		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.07981072673835035 | validation: 0.09903475255785313]
	TIME [epoch: 6.46 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08424866666255598		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.08424866666255598 | validation: 0.09544290431370803]
	TIME [epoch: 6.46 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07273496578040338		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.07273496578040338 | validation: 0.1152580770403906]
	TIME [epoch: 6.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07571986680856088		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.07571986680856088 | validation: 0.11749254798937346]
	TIME [epoch: 6.47 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08742505736383371		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.08742505736383371 | validation: 0.12935793294445766]
	TIME [epoch: 6.46 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09372043987819509		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.09372043987819509 | validation: 0.092183416946955]
	TIME [epoch: 6.46 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0823425684765621		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.0823425684765621 | validation: 0.06831491911205387]
	TIME [epoch: 6.47 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07028724957603073		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.07028724957603073 | validation: 0.10198565472296495]
	TIME [epoch: 6.46 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08045475665167454		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.08045475665167454 | validation: 0.09150103328148088]
	TIME [epoch: 6.46 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08227259059296417		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.08227259059296417 | validation: 0.0956397271496859]
	TIME [epoch: 6.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07742197352313057		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.07742197352313057 | validation: 0.08726299889514501]
	TIME [epoch: 6.47 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08276950659638496		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.08276950659638496 | validation: 0.078950744337835]
	TIME [epoch: 6.45 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07548132947540438		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.07548132947540438 | validation: 0.08741437015316215]
	TIME [epoch: 6.45 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08163565485615765		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.08163565485615765 | validation: 0.08540355395851468]
	TIME [epoch: 6.46 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07297250700388691		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.07297250700388691 | validation: 0.09389655183549929]
	TIME [epoch: 6.46 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07046099826266305		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.07046099826266305 | validation: 0.09793714151968227]
	TIME [epoch: 6.45 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07530053508694978		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.07530053508694978 | validation: 0.10497171633195844]
	TIME [epoch: 6.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791555963337908		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.0791555963337908 | validation: 0.09733675648720173]
	TIME [epoch: 6.46 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07179805965729259		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.07179805965729259 | validation: 0.0894756184213885]
	TIME [epoch: 6.46 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08581179457571696		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.08581179457571696 | validation: 0.08154241213051869]
	TIME [epoch: 6.45 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06642490256256632		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.06642490256256632 | validation: 0.08611432983742137]
	TIME [epoch: 6.47 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07215372875082468		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.07215372875082468 | validation: 0.0836737307848787]
	TIME [epoch: 6.46 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340807288866228		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.08340807288866228 | validation: 0.08965922265518932]
	TIME [epoch: 6.45 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07642558755881457		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.07642558755881457 | validation: 0.09934250424696434]
	TIME [epoch: 6.49 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07264162192782429		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.07264162192782429 | validation: 0.09027025249134889]
	TIME [epoch: 6.47 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07570065002286874		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.07570065002286874 | validation: 0.12893391565533835]
	TIME [epoch: 6.46 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08596613095127381		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.08596613095127381 | validation: 0.16051260158235242]
	TIME [epoch: 6.46 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11235193736816386		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.11235193736816386 | validation: 0.16224195893225082]
	TIME [epoch: 6.46 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933398768627576		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.09933398768627576 | validation: 0.09644286574567501]
	TIME [epoch: 6.47 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07104121523067103		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.07104121523067103 | validation: 0.08865940139613669]
	TIME [epoch: 6.46 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08408926121526426		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.08408926121526426 | validation: 0.08137552092926555]
	TIME [epoch: 6.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07283230914552946		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.07283230914552946 | validation: 0.0814404369228794]
	TIME [epoch: 6.48 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0830139469040306		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.0830139469040306 | validation: 0.11190672715541322]
	TIME [epoch: 6.46 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09327812431164625		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.09327812431164625 | validation: 0.09175242054977684]
	TIME [epoch: 6.46 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0722374563028828		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.0722374563028828 | validation: 0.08545769521154656]
	TIME [epoch: 6.47 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07907719391126955		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.07907719391126955 | validation: 0.09787670329238353]
	TIME [epoch: 6.46 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07615628922496992		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.07615628922496992 | validation: 0.11319975868669666]
	TIME [epoch: 6.46 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07764842777294037		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.07764842777294037 | validation: 0.10811100689616147]
	TIME [epoch: 6.47 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07415274636568608		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.07415274636568608 | validation: 0.0868441951319512]
	TIME [epoch: 6.48 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06880816527954249		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.06880816527954249 | validation: 0.08145204734733064]
	TIME [epoch: 6.46 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06831595440432944		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.06831595440432944 | validation: 0.09253043231924156]
	TIME [epoch: 6.46 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07688300668331863		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.07688300668331863 | validation: 0.07880829905386885]
	TIME [epoch: 6.46 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017202116666418		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.07017202116666418 | validation: 0.07776473710886232]
	TIME [epoch: 6.46 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07869645749420903		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.07869645749420903 | validation: 0.08758527667260001]
	TIME [epoch: 6.46 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07637874820995393		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.07637874820995393 | validation: 0.07818725548539425]
	TIME [epoch: 6.48 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0957307423515261		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.0957307423515261 | validation: 0.07617513758511368]
	TIME [epoch: 6.48 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08246598691022346		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.08246598691022346 | validation: 0.07528306613119629]
	TIME [epoch: 6.46 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07071001947758836		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.07071001947758836 | validation: 0.08784571142757344]
	TIME [epoch: 6.46 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06915729280498381		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.06915729280498381 | validation: 0.08970371597740599]
	TIME [epoch: 6.46 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07048664865093161		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.07048664865093161 | validation: 0.09805032599218003]
	TIME [epoch: 6.46 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06983461632117886		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.06983461632117886 | validation: 0.1079773780097048]
	TIME [epoch: 6.46 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07882894728332303		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.07882894728332303 | validation: 0.1006401979446617]
	TIME [epoch: 6.48 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07613260971559804		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.07613260971559804 | validation: 0.12368385484358636]
	TIME [epoch: 6.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08467313352712202		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.08467313352712202 | validation: 0.10438669259302703]
	TIME [epoch: 6.46 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08358955806105106		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.08358955806105106 | validation: 0.10369202112382248]
	TIME [epoch: 6.46 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08060191150087676		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.08060191150087676 | validation: 0.10284371674231067]
	TIME [epoch: 6.46 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0691151031164531		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.0691151031164531 | validation: 0.10404854416459447]
	TIME [epoch: 6.46 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09296845646994076		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.09296845646994076 | validation: 0.08788029696947047]
	TIME [epoch: 6.45 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07340324139787446		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.07340324139787446 | validation: 0.09428565805600808]
	TIME [epoch: 6.46 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08255777834998157		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.08255777834998157 | validation: 0.08602787000099266]
	TIME [epoch: 6.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08452168367631914		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.08452168367631914 | validation: 0.10413783642097793]
	TIME [epoch: 6.47 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09332767134947739		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.09332767134947739 | validation: 0.08819770167951935]
	TIME [epoch: 6.45 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0734692051675839		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.0734692051675839 | validation: 0.11385723520278021]
	TIME [epoch: 6.45 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08398547900849915		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.08398547900849915 | validation: 0.09601619222447974]
	TIME [epoch: 6.46 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07380266686588413		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.07380266686588413 | validation: 0.08734562152660164]
	TIME [epoch: 6.46 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07385364966153252		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.07385364966153252 | validation: 0.09007796753990904]
	TIME [epoch: 6.47 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08149688883069456		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.08149688883069456 | validation: 0.09501457604135301]
	TIME [epoch: 6.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07847529627536694		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.07847529627536694 | validation: 0.0900860355011572]
	TIME [epoch: 6.47 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0689774649104785		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.0689774649104785 | validation: 0.07740722247193388]
	TIME [epoch: 6.46 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06686404679360558		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.06686404679360558 | validation: 0.08350629172243408]
	TIME [epoch: 6.46 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07441051314945618		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.07441051314945618 | validation: 0.08094627838200882]
	TIME [epoch: 6.46 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06546165079080886		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.06546165079080886 | validation: 0.07100224024651774]
	TIME [epoch: 6.46 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07477962991639282		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.07477962991639282 | validation: 0.079576875767949]
	TIME [epoch: 6.46 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08050954113739783		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.08050954113739783 | validation: 0.0855263049213863]
	TIME [epoch: 6.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08421709544263327		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.08421709544263327 | validation: 0.11984669969995086]
	TIME [epoch: 6.47 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09207783476194956		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.09207783476194956 | validation: 0.09976940819694927]
	TIME [epoch: 6.45 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08278176566085976		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.08278176566085976 | validation: 0.08858644615336936]
	TIME [epoch: 6.46 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06770268764283877		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.06770268764283877 | validation: 0.08650552425193478]
	TIME [epoch: 6.46 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06585072435017336		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.06585072435017336 | validation: 0.09188084271921877]
	TIME [epoch: 6.46 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08335271902858866		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.08335271902858866 | validation: 0.11656293531565474]
	TIME [epoch: 6.45 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08224692866600487		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.08224692866600487 | validation: 0.15760646161470018]
	TIME [epoch: 6.49 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08708275740384669		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.08708275740384669 | validation: 0.12429652625738037]
	TIME [epoch: 6.45 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09149866948160597		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.09149866948160597 | validation: 0.11267663567470909]
	TIME [epoch: 6.46 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07214666503274844		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.07214666503274844 | validation: 0.10749255991330937]
	TIME [epoch: 6.46 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08384386840857566		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.08384386840857566 | validation: 0.10263809972401595]
	TIME [epoch: 6.46 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06935353630140433		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.06935353630140433 | validation: 0.11824324242725608]
	TIME [epoch: 6.46 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07952003067364892		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.07952003067364892 | validation: 0.10456010772368204]
	TIME [epoch: 6.46 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07170295735267529		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.07170295735267529 | validation: 0.10874870995466349]
	TIME [epoch: 6.48 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07251266871483579		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.07251266871483579 | validation: 0.09770213671802762]
	TIME [epoch: 6.49 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07232470781987319		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.07232470781987319 | validation: 0.09975954687089168]
	TIME [epoch: 6.45 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0809267612039052		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.0809267612039052 | validation: 0.09032743134173365]
	TIME [epoch: 6.46 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07288519888425841		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.07288519888425841 | validation: 0.10883644357365135]
	TIME [epoch: 6.46 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07210846909342228		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.07210846909342228 | validation: 0.0998724149376741]
	TIME [epoch: 6.46 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07655292878296145		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.07655292878296145 | validation: 0.10404810627099544]
	TIME [epoch: 6.47 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0763597369977494		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.0763597369977494 | validation: 0.09490953974408822]
	TIME [epoch: 6.48 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07840560948721977		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.07840560948721977 | validation: 0.09448841938760864]
	TIME [epoch: 6.47 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07412825334276153		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.07412825334276153 | validation: 0.10693075484339097]
	TIME [epoch: 6.47 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0814601378816428		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.0814601378816428 | validation: 0.10084751792521245]
	TIME [epoch: 6.47 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07295142803325769		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.07295142803325769 | validation: 0.09210726957344871]
	TIME [epoch: 6.46 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06864319019314256		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.06864319019314256 | validation: 0.07329319273083511]
	TIME [epoch: 6.46 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06792091429417847		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.06792091429417847 | validation: 0.08718706988574557]
	TIME [epoch: 6.46 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06585435843909944		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.06585435843909944 | validation: 0.07240197031137352]
	TIME [epoch: 6.46 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06973429141271587		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.06973429141271587 | validation: 0.07996771859530842]
	TIME [epoch: 6.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08555209758370669		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.08555209758370669 | validation: 0.07667440184504326]
	TIME [epoch: 6.45 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0733008244441062		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.0733008244441062 | validation: 0.06889603688537797]
	TIME [epoch: 6.46 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06914151595236595		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.06914151595236595 | validation: 0.0930513073276156]
	TIME [epoch: 6.46 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07980695226040489		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.07980695226040489 | validation: 0.11472482263689092]
	TIME [epoch: 6.46 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08212341090744885		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.08212341090744885 | validation: 0.08507215702338551]
	TIME [epoch: 6.46 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0759302669731077		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.0759302669731077 | validation: 0.07499900358911542]
	TIME [epoch: 6.46 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0698693626304974		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.0698693626304974 | validation: 0.0860967430991289]
	TIME [epoch: 6.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06976199574908966		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.06976199574908966 | validation: 0.0819338287306881]
	TIME [epoch: 6.46 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0809908744164427		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.0809908744164427 | validation: 0.07894941821488911]
	TIME [epoch: 6.46 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07489187250242808		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.07489187250242808 | validation: 0.08957590069964547]
	TIME [epoch: 6.46 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07643124407821547		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.07643124407821547 | validation: 0.06618672676595491]
	TIME [epoch: 6.46 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07128714234054206		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.07128714234054206 | validation: 0.07965988161076112]
	TIME [epoch: 6.46 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07012421955019274		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.07012421955019274 | validation: 0.07289719516031966]
	TIME [epoch: 6.45 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06721807943897654		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.06721807943897654 | validation: 0.09564572267063032]
	TIME [epoch: 6.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07071784514866115		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.07071784514866115 | validation: 0.08520186226475943]
	TIME [epoch: 6.46 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062102750726464984		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.062102750726464984 | validation: 0.07555139224810609]
	TIME [epoch: 6.46 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06094241778046496		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.06094241778046496 | validation: 0.07878838345508248]
	TIME [epoch: 6.46 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06402859409589362		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.06402859409589362 | validation: 0.06923941164366386]
	TIME [epoch: 6.46 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06967846351888926		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.06967846351888926 | validation: 0.0740237533870509]
	TIME [epoch: 6.46 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07251900567408297		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.07251900567408297 | validation: 0.07479299099781815]
	TIME [epoch: 6.46 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0772469736881406		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.0772469736881406 | validation: 0.08806393937125767]
	TIME [epoch: 6.49 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06525447638989791		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.06525447638989791 | validation: 0.07432311782074327]
	TIME [epoch: 6.46 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06582590484570609		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.06582590484570609 | validation: 0.06253522947221817]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_1244.pth
	Model improved!!!
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07127473946971816		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.07127473946971816 | validation: 0.07425247050634087]
	TIME [epoch: 6.46 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06932896594691566		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.06932896594691566 | validation: 0.08360795184332975]
	TIME [epoch: 6.46 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06983055685160452		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.06983055685160452 | validation: 0.07965603001680395]
	TIME [epoch: 6.46 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.071979288326973		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.071979288326973 | validation: 0.07637648258081255]
	TIME [epoch: 6.46 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06453661729085808		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.06453661729085808 | validation: 0.0795006628811061]
	TIME [epoch: 6.49 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06708594936389475		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.06708594936389475 | validation: 0.06444708640727016]
	TIME [epoch: 6.46 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07540527101055129		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.07540527101055129 | validation: 0.08370924402974937]
	TIME [epoch: 6.46 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06893741061953401		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.06893741061953401 | validation: 0.07570620985965058]
	TIME [epoch: 6.46 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06845883144440473		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.06845883144440473 | validation: 0.09147258800973783]
	TIME [epoch: 6.46 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07951789637931968		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.07951789637931968 | validation: 0.10577220374381127]
	TIME [epoch: 6.46 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06905927454775748		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.06905927454775748 | validation: 0.09083216066287339]
	TIME [epoch: 6.46 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06631677912876391		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.06631677912876391 | validation: 0.08383439125077946]
	TIME [epoch: 6.47 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06482064267401072		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.06482064267401072 | validation: 0.09890135948545553]
	TIME [epoch: 6.48 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07948087864171574		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.07948087864171574 | validation: 0.09482891530447322]
	TIME [epoch: 6.46 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07341984597144169		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.07341984597144169 | validation: 0.07717074949869199]
	TIME [epoch: 6.46 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07135003976088189		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.07135003976088189 | validation: 0.09189407745484418]
	TIME [epoch: 6.46 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08825970620569366		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.08825970620569366 | validation: 0.09095328409377236]
	TIME [epoch: 6.46 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07409846167325639		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.07409846167325639 | validation: 0.08915074280096215]
	TIME [epoch: 6.45 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07206340867076998		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.07206340867076998 | validation: 0.09392693281915197]
	TIME [epoch: 6.47 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07143461749624173		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.07143461749624173 | validation: 0.08099174361298239]
	TIME [epoch: 6.48 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07975080941204488		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.07975080941204488 | validation: 0.09313886845764771]
	TIME [epoch: 6.46 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09158513176393197		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.09158513176393197 | validation: 0.0828068556854538]
	TIME [epoch: 6.46 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07448840603904737		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.07448840603904737 | validation: 0.07079670114227982]
	TIME [epoch: 6.45 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06462432427002292		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.06462432427002292 | validation: 0.06482778162848414]
	TIME [epoch: 6.45 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07095892585919684		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.07095892585919684 | validation: 0.08355595826677087]
	TIME [epoch: 6.45 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0777777866001945		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.0777777866001945 | validation: 0.09022168133818205]
	TIME [epoch: 6.46 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07265122962268672		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.07265122962268672 | validation: 0.07140750907867581]
	TIME [epoch: 6.49 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06475649220390217		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.06475649220390217 | validation: 0.07505084659981004]
	TIME [epoch: 6.46 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06435758055300149		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.06435758055300149 | validation: 0.07126559144925071]
	TIME [epoch: 6.45 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06585353136964799		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.06585353136964799 | validation: 0.06364416938133831]
	TIME [epoch: 6.46 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06686960688377114		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.06686960688377114 | validation: 0.08522072322844287]
	TIME [epoch: 6.45 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.072584763961006		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.072584763961006 | validation: 0.08596532905531873]
	TIME [epoch: 6.46 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07271422039517746		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.07271422039517746 | validation: 0.07017287166845229]
	TIME [epoch: 6.46 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062232203658062674		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.062232203658062674 | validation: 0.07933022881623236]
	TIME [epoch: 6.49 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756341178818134		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.0756341178818134 | validation: 0.103006387375216]
	TIME [epoch: 6.46 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06935986372365349		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.06935986372365349 | validation: 0.0747206852918801]
	TIME [epoch: 6.47 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06130448649498933		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.06130448649498933 | validation: 0.08365281236056124]
	TIME [epoch: 6.46 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0739076013386201		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.0739076013386201 | validation: 0.06802695630035845]
	TIME [epoch: 6.47 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06986377883911317		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.06986377883911317 | validation: 0.09072533279361795]
	TIME [epoch: 6.46 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06854207583999974		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.06854207583999974 | validation: 0.07908943483196837]
	TIME [epoch: 6.46 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702329935613875		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.06702329935613875 | validation: 0.0832392387228332]
	TIME [epoch: 6.49 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06961051931130544		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.06961051931130544 | validation: 0.07812917168250685]
	TIME [epoch: 6.47 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06626964395439872		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.06626964395439872 | validation: 0.06374397745265427]
	TIME [epoch: 6.46 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060145232098221306		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.060145232098221306 | validation: 0.07624199178045003]
	TIME [epoch: 6.47 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06385706269103686		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.06385706269103686 | validation: 0.09143698803517358]
	TIME [epoch: 6.46 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06648336861730808		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.06648336861730808 | validation: 0.0754085263652155]
	TIME [epoch: 6.47 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0706182627458729		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.0706182627458729 | validation: 0.08222750512587489]
	TIME [epoch: 6.46 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06444934813572134		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.06444934813572134 | validation: 0.06898716695493907]
	TIME [epoch: 6.48 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07132063012139628		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.07132063012139628 | validation: 0.08305523645086486]
	TIME [epoch: 6.46 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08019472933278676		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.08019472933278676 | validation: 0.08018700499435104]
	TIME [epoch: 6.44 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06976417240074027		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.06976417240074027 | validation: 0.06878946163844038]
	TIME [epoch: 6.46 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07007121686777068		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.07007121686777068 | validation: 0.07679389322705138]
	TIME [epoch: 6.46 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06452942773444907		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.06452942773444907 | validation: 0.10313963135304015]
	TIME [epoch: 6.46 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06350506939862371		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.06350506939862371 | validation: 0.07880720705171194]
	TIME [epoch: 6.45 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07582332035831502		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.07582332035831502 | validation: 0.07979142229094305]
	TIME [epoch: 6.49 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06478892896246631		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.06478892896246631 | validation: 0.0678074524257132]
	TIME [epoch: 6.47 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05973987127863509		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.05973987127863509 | validation: 0.0721240049072093]
	TIME [epoch: 6.46 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06868444230487893		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.06868444230487893 | validation: 0.0762286628323546]
	TIME [epoch: 6.46 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06554673930428324		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.06554673930428324 | validation: 0.08980201566965551]
	TIME [epoch: 6.46 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06038223364821006		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.06038223364821006 | validation: 0.08410451733895265]
	TIME [epoch: 6.47 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06418784401386171		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.06418784401386171 | validation: 0.07432933860529445]
	TIME [epoch: 6.46 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06424790817688418		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.06424790817688418 | validation: 0.0773720879631476]
	TIME [epoch: 6.48 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07161790710718552		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.07161790710718552 | validation: 0.07211159445939803]
	TIME [epoch: 6.47 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07189743531701737		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.07189743531701737 | validation: 0.0772449009348925]
	TIME [epoch: 6.47 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06710794432354183		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.06710794432354183 | validation: 0.07529455278476231]
	TIME [epoch: 6.45 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06706445250860354		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.06706445250860354 | validation: 0.09295917614495265]
	TIME [epoch: 6.46 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06520456411333009		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.06520456411333009 | validation: 0.0687044284839364]
	TIME [epoch: 6.45 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740926757011458		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.07740926757011458 | validation: 0.0811899749421952]
	TIME [epoch: 6.45 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0618564850226445		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.0618564850226445 | validation: 0.06595526842080908]
	TIME [epoch: 6.48 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06570613815801939		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.06570613815801939 | validation: 0.08236782276935287]
	TIME [epoch: 6.48 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06198282084648535		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.06198282084648535 | validation: 0.08210299035184619]
	TIME [epoch: 6.45 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06600682227800853		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.06600682227800853 | validation: 0.07400611339635767]
	TIME [epoch: 6.45 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06950952721655689		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.06950952721655689 | validation: 0.08415020625623353]
	TIME [epoch: 6.45 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06929651553015384		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.06929651553015384 | validation: 0.09465951539393333]
	TIME [epoch: 6.46 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06427247259874173		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.06427247259874173 | validation: 0.09526865173999502]
	TIME [epoch: 6.45 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06715022307585088		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.06715022307585088 | validation: 0.08213478391787446]
	TIME [epoch: 6.46 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061116984351086236		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.061116984351086236 | validation: 0.08758281002427261]
	TIME [epoch: 6.49 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06832552677980823		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.06832552677980823 | validation: 0.0858159791961569]
	TIME [epoch: 6.46 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07068181022703666		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.07068181022703666 | validation: 0.08577338725317332]
	TIME [epoch: 6.46 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06293345164095067		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.06293345164095067 | validation: 0.07593810439926173]
	TIME [epoch: 6.46 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06499944833035771		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.06499944833035771 | validation: 0.08265346646407401]
	TIME [epoch: 6.46 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0628856294488035		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.0628856294488035 | validation: 0.08581597490702621]
	TIME [epoch: 6.47 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06376536157461139		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.06376536157461139 | validation: 0.06876640585012739]
	TIME [epoch: 6.47 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06423920771590269		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.06423920771590269 | validation: 0.07335835649108156]
	TIME [epoch: 6.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06317786076202854		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.06317786076202854 | validation: 0.08303805580465114]
	TIME [epoch: 6.47 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.078708744360922		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.078708744360922 | validation: 0.09479636137460368]
	TIME [epoch: 6.47 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06806102473261244		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.06806102473261244 | validation: 0.08317639078594079]
	TIME [epoch: 6.46 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0628493837259928		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.0628493837259928 | validation: 0.08244860555749693]
	TIME [epoch: 6.47 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06528566911073297		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.06528566911073297 | validation: 0.0860189017236609]
	TIME [epoch: 6.47 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06317268007689408		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.06317268007689408 | validation: 0.07184091441143506]
	TIME [epoch: 6.46 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0629747145871831		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.0629747145871831 | validation: 0.08475534080236154]
	TIME [epoch: 6.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06260336730586577		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.06260336730586577 | validation: 0.0704184421490903]
	TIME [epoch: 6.47 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06450429403605756		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.06450429403605756 | validation: 0.08187666096691945]
	TIME [epoch: 6.47 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06345201153382801		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.06345201153382801 | validation: 0.06977062750325926]
	TIME [epoch: 6.46 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06242585374921532		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.06242585374921532 | validation: 0.07183998631709641]
	TIME [epoch: 6.47 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06662677772648332		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.06662677772648332 | validation: 0.07153564175699424]
	TIME [epoch: 6.47 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06274380149559806		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.06274380149559806 | validation: 0.06284472049640517]
	TIME [epoch: 6.46 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060446251250355375		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.060446251250355375 | validation: 0.07461336786982094]
	TIME [epoch: 6.49 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06285564061883565		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.06285564061883565 | validation: 0.0785459032731438]
	TIME [epoch: 6.47 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07102000849161556		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.07102000849161556 | validation: 0.10515233563274247]
	TIME [epoch: 6.47 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07099421279193904		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.07099421279193904 | validation: 0.08711409115561689]
	TIME [epoch: 6.46 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06398665980784268		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.06398665980784268 | validation: 0.087858926250465]
	TIME [epoch: 6.47 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06406524150458769		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.06406524150458769 | validation: 0.09149480701554823]
	TIME [epoch: 6.46 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062358584135555284		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.062358584135555284 | validation: 0.07443708417657541]
	TIME [epoch: 6.47 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06459164517588377		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.06459164517588377 | validation: 0.06682635792567096]
	TIME [epoch: 6.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644344796368822		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.0644344796368822 | validation: 0.07340714841197216]
	TIME [epoch: 6.48 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06242852353274801		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.06242852353274801 | validation: 0.07910009039356254]
	TIME [epoch: 6.45 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05916435132898869		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.05916435132898869 | validation: 0.06760044403669493]
	TIME [epoch: 6.47 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06806930483336746		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.06806930483336746 | validation: 0.06289399690528306]
	TIME [epoch: 6.47 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059701688996819983		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.059701688996819983 | validation: 0.06986288097623934]
	TIME [epoch: 6.47 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06600522183228094		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.06600522183228094 | validation: 0.06358232658585226]
	TIME [epoch: 6.46 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06471332874933858		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.06471332874933858 | validation: 0.09250255912063651]
	TIME [epoch: 6.48 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06606174897010408		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.06606174897010408 | validation: 0.0764082194630365]
	TIME [epoch: 6.48 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06701197864336077		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.06701197864336077 | validation: 0.08375887480326956]
	TIME [epoch: 6.47 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0728383050666514		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.0728383050666514 | validation: 0.08268314318890439]
	TIME [epoch: 6.47 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06136181239647381		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.06136181239647381 | validation: 0.06610355043343005]
	TIME [epoch: 6.47 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06191239854191695		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.06191239854191695 | validation: 0.059475883442542406]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_1361.pth
	Model improved!!!
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06512410183115214		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.06512410183115214 | validation: 0.06431128668121938]
	TIME [epoch: 6.47 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06397824076116547		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.06397824076116547 | validation: 0.0886984851316879]
	TIME [epoch: 6.49 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07272328665376418		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.07272328665376418 | validation: 0.06713345258350197]
	TIME [epoch: 6.49 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06790697676915036		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.06790697676915036 | validation: 0.0705739870501798]
	TIME [epoch: 6.46 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05932012275872992		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.05932012275872992 | validation: 0.07560870081161611]
	TIME [epoch: 6.46 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06391893845733822		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.06391893845733822 | validation: 0.07110334274772029]
	TIME [epoch: 6.47 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06642450129199592		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.06642450129199592 | validation: 0.0740006419029486]
	TIME [epoch: 6.46 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344144464075356		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.06344144464075356 | validation: 0.06657828246818442]
	TIME [epoch: 6.46 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06321242687934897		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.06321242687934897 | validation: 0.06376603916679427]
	TIME [epoch: 6.48 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059843347455118635		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.059843347455118635 | validation: 0.06184111706722492]
	TIME [epoch: 6.49 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06264365522062035		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.06264365522062035 | validation: 0.0695538660782458]
	TIME [epoch: 6.47 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06270428356839743		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.06270428356839743 | validation: 0.07479719806230914]
	TIME [epoch: 6.47 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06290641821306885		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.06290641821306885 | validation: 0.07612381093041538]
	TIME [epoch: 6.46 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06302249242112958		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.06302249242112958 | validation: 0.07225172004645268]
	TIME [epoch: 6.47 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06258339914595518		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.06258339914595518 | validation: 0.08012549828139036]
	TIME [epoch: 6.47 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058421813874630635		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.058421813874630635 | validation: 0.06438506472496915]
	TIME [epoch: 6.47 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356986927279247		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.06356986927279247 | validation: 0.07776339446470693]
	TIME [epoch: 6.49 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06542176214840645		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.06542176214840645 | validation: 0.07063568572439223]
	TIME [epoch: 6.47 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06997781840003083		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.06997781840003083 | validation: 0.07647182227022381]
	TIME [epoch: 6.47 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06265305994207605		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.06265305994207605 | validation: 0.07434451318726197]
	TIME [epoch: 6.46 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06678169716822432		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.06678169716822432 | validation: 0.06198225906571201]
	TIME [epoch: 6.46 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06511215646563824		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.06511215646563824 | validation: 0.07238778851042602]
	TIME [epoch: 6.47 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06871066399179533		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.06871066399179533 | validation: 0.07816960720981504]
	TIME [epoch: 6.47 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06801499173906912		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.06801499173906912 | validation: 0.08510250565751512]
	TIME [epoch: 6.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06318293522811658		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.06318293522811658 | validation: 0.07833134283429437]
	TIME [epoch: 6.47 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05945017218847711		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.05945017218847711 | validation: 0.06878882155249169]
	TIME [epoch: 6.46 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06582186541332423		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.06582186541332423 | validation: 0.07458455200889906]
	TIME [epoch: 6.46 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06152824052114711		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.06152824052114711 | validation: 0.07958810298054103]
	TIME [epoch: 6.45 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06577116726066924		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.06577116726066924 | validation: 0.06295119866201923]
	TIME [epoch: 6.46 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061420255456105355		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.061420255456105355 | validation: 0.07388089835176005]
	TIME [epoch: 6.45 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06843644745884933		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.06843644745884933 | validation: 0.0678847066173071]
	TIME [epoch: 6.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06578392744908862		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.06578392744908862 | validation: 0.07039912896695015]
	TIME [epoch: 6.46 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06810741175420569		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.06810741175420569 | validation: 0.06452833113215577]
	TIME [epoch: 6.46 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06687360022735653		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.06687360022735653 | validation: 0.07337669173849229]
	TIME [epoch: 6.46 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0663063707612094		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.0663063707612094 | validation: 0.062399244145481925]
	TIME [epoch: 6.46 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0649505274577458		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.0649505274577458 | validation: 0.07615087583461909]
	TIME [epoch: 6.45 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06903913272467051		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.06903913272467051 | validation: 0.07533585485957181]
	TIME [epoch: 6.46 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07474770828217303		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.07474770828217303 | validation: 0.0657285393764038]
	TIME [epoch: 6.49 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06398248405595607		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.06398248405595607 | validation: 0.06252349774152859]
	TIME [epoch: 6.46 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06263924368358996		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.06263924368358996 | validation: 0.07057330324529114]
	TIME [epoch: 6.45 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0626999205637659		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.0626999205637659 | validation: 0.07021604043816514]
	TIME [epoch: 6.44 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06290224731187752		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.06290224731187752 | validation: 0.060145499503731624]
	TIME [epoch: 6.44 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0663324043178544		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.0663324043178544 | validation: 0.07750353104689796]
	TIME [epoch: 6.44 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06715578068801885		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.06715578068801885 | validation: 0.07224519323773373]
	TIME [epoch: 6.45 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060093853872480806		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.060093853872480806 | validation: 0.07200185786483347]
	TIME [epoch: 6.47 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0618298997043573		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.0618298997043573 | validation: 0.07425492957705104]
	TIME [epoch: 6.45 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06464893245417284		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.06464893245417284 | validation: 0.06568674830452542]
	TIME [epoch: 6.44 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05789803311230129		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.05789803311230129 | validation: 0.08156319277756768]
	TIME [epoch: 6.45 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06534350162175744		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.06534350162175744 | validation: 0.0828333241843864]
	TIME [epoch: 6.44 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06317821067501678		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.06317821067501678 | validation: 0.07807338608892293]
	TIME [epoch: 6.45 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06448305515814051		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.06448305515814051 | validation: 0.07378358614886903]
	TIME [epoch: 6.44 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07054631923760155		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.07054631923760155 | validation: 0.07301965535646783]
	TIME [epoch: 6.46 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06893041470174872		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.06893041470174872 | validation: 0.07708570834835937]
	TIME [epoch: 6.48 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06518707033793633		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.06518707033793633 | validation: 0.07242169565898017]
	TIME [epoch: 6.44 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06169052132329467		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.06169052132329467 | validation: 0.07303196326191552]
	TIME [epoch: 6.45 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06409636363318015		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.06409636363318015 | validation: 0.06581610241037016]
	TIME [epoch: 6.45 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06474301446938464		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.06474301446938464 | validation: 0.07222534843445214]
	TIME [epoch: 6.45 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06359748334903957		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.06359748334903957 | validation: 0.07639039121830322]
	TIME [epoch: 6.45 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06394663293890838		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.06394663293890838 | validation: 0.06449810779947958]
	TIME [epoch: 6.46 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06405485288041754		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.06405485288041754 | validation: 0.06257015879873651]
	TIME [epoch: 6.47 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06345166711291497		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.06345166711291497 | validation: 0.0669949925659543]
	TIME [epoch: 6.45 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0621594623194469		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.0621594623194469 | validation: 0.07299140140921093]
	TIME [epoch: 6.45 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06382675342435787		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.06382675342435787 | validation: 0.06708848924305719]
	TIME [epoch: 6.45 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060764482587131165		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.060764482587131165 | validation: 0.06925628926952188]
	TIME [epoch: 6.46 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06586167710447668		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.06586167710447668 | validation: 0.0800253572563715]
	TIME [epoch: 6.47 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06922143619043641		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.06922143619043641 | validation: 0.07709671030136851]
	TIME [epoch: 6.46 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06690734262666134		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.06690734262666134 | validation: 0.0749181900560225]
	TIME [epoch: 6.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06341176640764379		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.06341176640764379 | validation: 0.07335557847200101]
	TIME [epoch: 6.46 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06075611637492302		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.06075611637492302 | validation: 0.06802680747931344]
	TIME [epoch: 6.47 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06403215025792089		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.06403215025792089 | validation: 0.07401484375981902]
	TIME [epoch: 6.46 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06607710424701699		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.06607710424701699 | validation: 0.07923503070282246]
	TIME [epoch: 6.45 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279747284098071		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.06279747284098071 | validation: 0.05853068357287033]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_1433.pth
	Model improved!!!
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06669216226469919		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.06669216226469919 | validation: 0.0641883640043082]
	TIME [epoch: 6.48 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07332365871050174		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.07332365871050174 | validation: 0.06545984085103604]
	TIME [epoch: 6.49 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06672001584325611		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.06672001584325611 | validation: 0.0636185042558368]
	TIME [epoch: 6.46 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06614565377979197		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.06614565377979197 | validation: 0.06423330161120347]
	TIME [epoch: 6.45 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0666948070015744		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.0666948070015744 | validation: 0.07553923202714687]
	TIME [epoch: 6.45 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06513805669596613		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.06513805669596613 | validation: 0.07124838084363298]
	TIME [epoch: 6.46 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06498755179304244		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.06498755179304244 | validation: 0.0758845672233036]
	TIME [epoch: 6.45 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06393654470818662		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.06393654470818662 | validation: 0.06831315592579817]
	TIME [epoch: 6.45 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05954606445023702		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.05954606445023702 | validation: 0.06816437702496782]
	TIME [epoch: 6.49 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06227973786855305		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.06227973786855305 | validation: 0.0748439204576992]
	TIME [epoch: 6.46 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061384876979104164		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.061384876979104164 | validation: 0.07183772616828014]
	TIME [epoch: 6.45 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06541362164582655		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.06541362164582655 | validation: 0.07607284377335873]
	TIME [epoch: 6.45 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06694633575929468		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.06694633575929468 | validation: 0.07697489177715715]
	TIME [epoch: 6.45 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06390097227477673		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.06390097227477673 | validation: 0.07303491368812154]
	TIME [epoch: 6.45 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06777519328909673		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.06777519328909673 | validation: 0.06744843548753064]
	TIME [epoch: 6.45 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06790111325825476		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.06790111325825476 | validation: 0.07028990056931553]
	TIME [epoch: 6.49 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06796767272224805		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.06796767272224805 | validation: 0.07217604922745695]
	TIME [epoch: 6.45 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0670870502749995		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.0670870502749995 | validation: 0.07098942199632816]
	TIME [epoch: 6.45 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05907738435363155		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.05907738435363155 | validation: 0.06656112687851877]
	TIME [epoch: 6.45 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0645971588872869		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.0645971588872869 | validation: 0.09069685308756599]
	TIME [epoch: 6.45 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07039647987878447		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.07039647987878447 | validation: 0.07449363476160788]
	TIME [epoch: 6.46 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06513917047206644		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.06513917047206644 | validation: 0.07365357602368383]
	TIME [epoch: 6.46 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644460862368581		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.0644460862368581 | validation: 0.07769074081711512]
	TIME [epoch: 6.49 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06444650902152202		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.06444650902152202 | validation: 0.07299076991616446]
	TIME [epoch: 6.46 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06318280718445374		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.06318280718445374 | validation: 0.06681180845933964]
	TIME [epoch: 6.46 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06767353691533812		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.06767353691533812 | validation: 0.07230905974861168]
	TIME [epoch: 6.46 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06810498799866108		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.06810498799866108 | validation: 0.07001716268739307]
	TIME [epoch: 6.46 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06691615070488147		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.06691615070488147 | validation: 0.06213560273288098]
	TIME [epoch: 6.46 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06188004191991449		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.06188004191991449 | validation: 0.06581042745800636]
	TIME [epoch: 6.47 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06276657244720663		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.06276657244720663 | validation: 0.07135521814331047]
	TIME [epoch: 6.48 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06081945841004708		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.06081945841004708 | validation: 0.07154821405100317]
	TIME [epoch: 6.48 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06210063226170937		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.06210063226170937 | validation: 0.07416542802267297]
	TIME [epoch: 6.47 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06096037107396449		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.06096037107396449 | validation: 0.07916164364733687]
	TIME [epoch: 6.47 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06691749012729514		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.06691749012729514 | validation: 0.07810405604392755]
	TIME [epoch: 6.47 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06500419025433445		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.06500419025433445 | validation: 0.06929521096872422]
	TIME [epoch: 6.47 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06910931389730643		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.06910931389730643 | validation: 0.07768120972073617]
	TIME [epoch: 6.47 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0697457814639996		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.0697457814639996 | validation: 0.06880502976219131]
	TIME [epoch: 6.49 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06463959775778126		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.06463959775778126 | validation: 0.07268580642543009]
	TIME [epoch: 6.49 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06901974220017013		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.06901974220017013 | validation: 0.07025115669824959]
	TIME [epoch: 6.47 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06241514576879555		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.06241514576879555 | validation: 0.06655789366431694]
	TIME [epoch: 6.47 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06335729587446683		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.06335729587446683 | validation: 0.06511117684905614]
	TIME [epoch: 6.47 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056521860117226055		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.056521860117226055 | validation: 0.07516108922765502]
	TIME [epoch: 6.47 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06325898564695973		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.06325898564695973 | validation: 0.06486931594942288]
	TIME [epoch: 6.47 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06394942730667649		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.06394942730667649 | validation: 0.07325960982239667]
	TIME [epoch: 6.48 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06376821699654696		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.06376821699654696 | validation: 0.06482392655312365]
	TIME [epoch: 6.49 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06355119344334932		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.06355119344334932 | validation: 0.06511689444652699]
	TIME [epoch: 6.47 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05990469218962599		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.05990469218962599 | validation: 0.06493711250268962]
	TIME [epoch: 6.47 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06861324711991293		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.06861324711991293 | validation: 0.07963029543659422]
	TIME [epoch: 6.47 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06402971720113183		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.06402971720113183 | validation: 0.07193626237122108]
	TIME [epoch: 6.47 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06621451491232039		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.06621451491232039 | validation: 0.07003870253573116]
	TIME [epoch: 6.47 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06397497017074522		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.06397497017074522 | validation: 0.07660577022676272]
	TIME [epoch: 6.48 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06313573136108325		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.06313573136108325 | validation: 0.06907370756681344]
	TIME [epoch: 6.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407717273460331		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.06407717273460331 | validation: 0.06241389066399954]
	TIME [epoch: 6.48 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05842728388073513		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.05842728388073513 | validation: 0.08021355575297145]
	TIME [epoch: 6.47 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060245844982166744		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.060245844982166744 | validation: 0.06746999780348913]
	TIME [epoch: 6.47 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062223328240334316		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.062223328240334316 | validation: 0.08099195166047704]
	TIME [epoch: 6.46 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0632580148548772		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.0632580148548772 | validation: 0.06502368108035027]
	TIME [epoch: 6.47 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059169903141597424		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.059169903141597424 | validation: 0.0652400094933326]
	TIME [epoch: 6.48 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06312176374261938		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.06312176374261938 | validation: 0.08710530791450098]
	TIME [epoch: 6.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06609911048192091		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.06609911048192091 | validation: 0.08175054018778834]
	TIME [epoch: 6.48 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0718111975249211		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.0718111975249211 | validation: 0.07192346154608883]
	TIME [epoch: 6.47 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06265226871894478		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.06265226871894478 | validation: 0.07920968674994218]
	TIME [epoch: 6.47 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06340457335500796		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.06340457335500796 | validation: 0.06585501684287948]
	TIME [epoch: 6.47 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059559790422140546		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.059559790422140546 | validation: 0.07377987516954586]
	TIME [epoch: 6.47 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06122791275893831		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.06122791275893831 | validation: 0.07010738734574748]
	TIME [epoch: 6.47 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06940034090279251		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.06940034090279251 | validation: 0.07876038974055219]
	TIME [epoch: 6.51 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06977304375555302		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.06977304375555302 | validation: 0.06654120207651272]
	TIME [epoch: 6.46 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07266375639244255		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.07266375639244255 | validation: 0.07138605748128318]
	TIME [epoch: 6.47 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0710414554279394		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.0710414554279394 | validation: 0.08339146044467466]
	TIME [epoch: 6.48 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06462580490630461		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.06462580490630461 | validation: 0.07907290853216992]
	TIME [epoch: 6.47 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468604377545362		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.06468604377545362 | validation: 0.07793054767838907]
	TIME [epoch: 6.47 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06514231883188483		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.06514231883188483 | validation: 0.08572315755819386]
	TIME [epoch: 6.47 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06666469264204389		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.06666469264204389 | validation: 0.07820526618479955]
	TIME [epoch: 6.51 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06509967333167774		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.06509967333167774 | validation: 0.0775235772326706]
	TIME [epoch: 6.48 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058511103480078125		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.058511103480078125 | validation: 0.07612345471725344]
	TIME [epoch: 6.47 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05941696236076068		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.05941696236076068 | validation: 0.07070478042063374]
	TIME [epoch: 6.47 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06152320692794613		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.06152320692794613 | validation: 0.06925271505457298]
	TIME [epoch: 6.47 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060138210770227934		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.060138210770227934 | validation: 0.07329554572836415]
	TIME [epoch: 6.48 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06068218196150327		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.06068218196150327 | validation: 0.07416162397036145]
	TIME [epoch: 6.47 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0692988729479467		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.0692988729479467 | validation: 0.09560286807205269]
	TIME [epoch: 6.51 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07063762988600264		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.07063762988600264 | validation: 0.092110653225128]
	TIME [epoch: 6.48 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07351611892361065		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.07351611892361065 | validation: 0.08876346489231977]
	TIME [epoch: 6.47 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06869483948990371		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.06869483948990371 | validation: 0.08254638789031941]
	TIME [epoch: 6.48 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07049803502360544		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.07049803502360544 | validation: 0.08681258991518932]
	TIME [epoch: 6.47 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062135877116049745		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.062135877116049745 | validation: 0.07772525868899276]
	TIME [epoch: 6.47 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06748093882538367		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.06748093882538367 | validation: 0.07919864416434404]
	TIME [epoch: 6.47 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06911407053918214		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.06911407053918214 | validation: 0.07189520900905753]
	TIME [epoch: 6.49 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06463295709388134		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.06463295709388134 | validation: 0.07616538080841535]
	TIME [epoch: 6.49 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0660122866471914		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.0660122866471914 | validation: 0.07215149795043539]
	TIME [epoch: 6.47 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0609759718867336		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.0609759718867336 | validation: 0.07835056665545592]
	TIME [epoch: 6.47 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06258401479182071		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.06258401479182071 | validation: 0.07454539192610848]
	TIME [epoch: 6.47 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0666316779887361		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.0666316779887361 | validation: 0.09230350692218046]
	TIME [epoch: 6.46 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06555129741873097		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.06555129741873097 | validation: 0.08621044180394698]
	TIME [epoch: 6.47 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06590032979275276		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.06590032979275276 | validation: 0.07750836721939024]
	TIME [epoch: 6.49 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056616782759592255		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.056616782759592255 | validation: 0.07988827848482484]
	TIME [epoch: 6.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060734276591845424		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.060734276591845424 | validation: 0.08545925987035022]
	TIME [epoch: 6.47 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062037169034518044		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.062037169034518044 | validation: 0.08493579693680407]
	TIME [epoch: 6.46 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059084033072278594		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.059084033072278594 | validation: 0.0771176284517849]
	TIME [epoch: 6.47 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06686741151180658		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.06686741151180658 | validation: 0.06454323717987996]
	TIME [epoch: 6.47 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0583584233670659		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.0583584233670659 | validation: 0.07775050744735527]
	TIME [epoch: 6.47 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05477313720164894		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.05477313720164894 | validation: 0.07387345545478831]
	TIME [epoch: 6.49 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06355875791381671		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.06355875791381671 | validation: 0.07554144716073]
	TIME [epoch: 6.48 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05804064123484605		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.05804064123484605 | validation: 0.08394318308498498]
	TIME [epoch: 6.48 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06342479418036838		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.06342479418036838 | validation: 0.08156837989165215]
	TIME [epoch: 6.47 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060980315633499135		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.060980315633499135 | validation: 0.06983179815600943]
	TIME [epoch: 6.47 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057200610614961775		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.057200610614961775 | validation: 0.06926941993637781]
	TIME [epoch: 6.48 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062173434027189244		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.062173434027189244 | validation: 0.07495464425789425]
	TIME [epoch: 6.47 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06154969375157927		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.06154969375157927 | validation: 0.08654483900155104]
	TIME [epoch: 6.48 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06600859487767181		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.06600859487767181 | validation: 0.0688613564520764]
	TIME [epoch: 6.51 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06501182702587069		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.06501182702587069 | validation: 0.07973377140252748]
	TIME [epoch: 6.48 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06664246283693906		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.06664246283693906 | validation: 0.06866785122287553]
	TIME [epoch: 6.46 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06151732422263839		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.06151732422263839 | validation: 0.07230939388161885]
	TIME [epoch: 6.47 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06246742161241976		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.06246742161241976 | validation: 0.07676698470191283]
	TIME [epoch: 6.47 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061138907204751076		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.061138907204751076 | validation: 0.07506578268328933]
	TIME [epoch: 6.46 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0636090692758078		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.0636090692758078 | validation: 0.06922366780354507]
	TIME [epoch: 6.47 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06374102657442496		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.06374102657442496 | validation: 0.07879992244938461]
	TIME [epoch: 6.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06447987613860132		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.06447987613860132 | validation: 0.07778364838155791]
	TIME [epoch: 6.48 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05956094423321317		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.05956094423321317 | validation: 0.07409355253639399]
	TIME [epoch: 6.46 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06018932224429717		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.06018932224429717 | validation: 0.06745198707007381]
	TIME [epoch: 6.47 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06697936106899544		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.06697936106899544 | validation: 0.07513608297987023]
	TIME [epoch: 6.47 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06591160053137865		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.06591160053137865 | validation: 0.07766311151193547]
	TIME [epoch: 6.48 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06045489769863438		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.06045489769863438 | validation: 0.07641271635517287]
	TIME [epoch: 6.46 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06389366149272374		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.06389366149272374 | validation: 0.07730275808389167]
	TIME [epoch: 6.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05489875486592931		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.05489875486592931 | validation: 0.07838506163641334]
	TIME [epoch: 6.47 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059325165691701945		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.059325165691701945 | validation: 0.07381178125542917]
	TIME [epoch: 6.47 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05871480145955901		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.05871480145955901 | validation: 0.07471711386523484]
	TIME [epoch: 6.46 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05832721643446142		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.05832721643446142 | validation: 0.07415855073491111]
	TIME [epoch: 6.46 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06209404271498037		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.06209404271498037 | validation: 0.07721121136721092]
	TIME [epoch: 6.46 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058224698015638496		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.058224698015638496 | validation: 0.0761205897784405]
	TIME [epoch: 6.47 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05931912148726791		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.05931912148726791 | validation: 0.08048916636907377]
	TIME [epoch: 6.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06398105481323663		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.06398105481323663 | validation: 0.08947736334174541]
	TIME [epoch: 6.48 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060536921342954006		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.060536921342954006 | validation: 0.06728626290918843]
	TIME [epoch: 6.46 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05957934540686123		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.05957934540686123 | validation: 0.07098652707894806]
	TIME [epoch: 6.48 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06288047858932644		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.06288047858932644 | validation: 0.07744718030135479]
	TIME [epoch: 6.47 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0651317482883554		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.0651317482883554 | validation: 0.07843829421079594]
	TIME [epoch: 6.47 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06313670728004318		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.06313670728004318 | validation: 0.07279920945741085]
	TIME [epoch: 6.47 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05942164012880985		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.05942164012880985 | validation: 0.07996187038195675]
	TIME [epoch: 6.51 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059235006369969034		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.059235006369969034 | validation: 0.06806879685015897]
	TIME [epoch: 6.47 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06330215230334621		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.06330215230334621 | validation: 0.07317446828003801]
	TIME [epoch: 6.47 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06009688989519319		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.06009688989519319 | validation: 0.07968755812687492]
	TIME [epoch: 6.45 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05733616867743433		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.05733616867743433 | validation: 0.08048414117382904]
	TIME [epoch: 6.46 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060802258187349786		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.060802258187349786 | validation: 0.06862556582459649]
	TIME [epoch: 6.46 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06058496653610135		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.06058496653610135 | validation: 0.07896302925229103]
	TIME [epoch: 6.47 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06048960762126399		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.06048960762126399 | validation: 0.07300251056046649]
	TIME [epoch: 6.49 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06341024259376635		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.06341024259376635 | validation: 0.0824582901845832]
	TIME [epoch: 6.49 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06335008440050144		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.06335008440050144 | validation: 0.0704785799881453]
	TIME [epoch: 6.47 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06162147712847814		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.06162147712847814 | validation: 0.07991340790291687]
	TIME [epoch: 6.48 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05967569526193467		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.05967569526193467 | validation: 0.06845328744972677]
	TIME [epoch: 6.47 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06015188531099479		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.06015188531099479 | validation: 0.06831233115654667]
	TIME [epoch: 6.47 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056468499844384804		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.056468499844384804 | validation: 0.06421605128150759]
	TIME [epoch: 6.48 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06071203253525895		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.06071203253525895 | validation: 0.0686073016920961]
	TIME [epoch: 6.49 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05705452740666027		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.05705452740666027 | validation: 0.07079174173305736]
	TIME [epoch: 6.49 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06151075994433505		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.06151075994433505 | validation: 0.06229747879923576]
	TIME [epoch: 6.47 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0582221266305832		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.0582221266305832 | validation: 0.06800020305141444]
	TIME [epoch: 6.46 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058643859115620964		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.058643859115620964 | validation: 0.06757164633851749]
	TIME [epoch: 6.46 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059451506460899015		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.059451506460899015 | validation: 0.07033941883513266]
	TIME [epoch: 6.45 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058201532814378225		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.058201532814378225 | validation: 0.06526537681692586]
	TIME [epoch: 6.45 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06600497146756923		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.06600497146756923 | validation: 0.07495708421796471]
	TIME [epoch: 6.46 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07315398150425809		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.07315398150425809 | validation: 0.06184301374871288]
	TIME [epoch: 6.49 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058328205603326355		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.058328205603326355 | validation: 0.07079950355741288]
	TIME [epoch: 6.46 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06195624396077885		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.06195624396077885 | validation: 0.07235381346669113]
	TIME [epoch: 6.47 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062386437280945166		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.062386437280945166 | validation: 0.06985007341510235]
	TIME [epoch: 6.47 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059554635419091964		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.059554635419091964 | validation: 0.07465176586616236]
	TIME [epoch: 6.45 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06058023462458059		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.06058023462458059 | validation: 0.07108742477654756]
	TIME [epoch: 6.45 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0621335869552292		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.0621335869552292 | validation: 0.06440204695442758]
	TIME [epoch: 6.47 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058458103767605935		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.058458103767605935 | validation: 0.06610804655576749]
	TIME [epoch: 6.49 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0574064972291796		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.0574064972291796 | validation: 0.07188448582719144]
	TIME [epoch: 6.47 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06267464718491056		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.06267464718491056 | validation: 0.07620820186247144]
	TIME [epoch: 6.46 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06686829347121541		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.06686829347121541 | validation: 0.07031242374496934]
	TIME [epoch: 6.46 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05689796797041011		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.05689796797041011 | validation: 0.06225744590494829]
	TIME [epoch: 6.46 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05745844963502923		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.05745844963502923 | validation: 0.06623217472520018]
	TIME [epoch: 6.47 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06213447467317865		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.06213447467317865 | validation: 0.07486254087192207]
	TIME [epoch: 6.48 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06395127307980551		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.06395127307980551 | validation: 0.07437668236471785]
	TIME [epoch: 6.49 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06018779107964282		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.06018779107964282 | validation: 0.06662329605543305]
	TIME [epoch: 6.48 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05949823304941596		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.05949823304941596 | validation: 0.0670027047581873]
	TIME [epoch: 6.48 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06190300986364748		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.06190300986364748 | validation: 0.06993825506164665]
	TIME [epoch: 6.48 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059648354785743776		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.059648354785743776 | validation: 0.07156548107379239]
	TIME [epoch: 6.47 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06367682481051486		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.06367682481051486 | validation: 0.08086124244339775]
	TIME [epoch: 6.47 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06199912259488151		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.06199912259488151 | validation: 0.061312267376624326]
	TIME [epoch: 6.47 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05874602874995652		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.05874602874995652 | validation: 0.07602319971943497]
	TIME [epoch: 6.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05852278613034179		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.05852278613034179 | validation: 0.0708166529154729]
	TIME [epoch: 6.47 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058062199397090196		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.058062199397090196 | validation: 0.0709743202313927]
	TIME [epoch: 6.47 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05726958866726386		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.05726958866726386 | validation: 0.06821760020276811]
	TIME [epoch: 6.47 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05578208440463678		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.05578208440463678 | validation: 0.06792954359207863]
	TIME [epoch: 6.48 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05827498053308725		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.05827498053308725 | validation: 0.0700887540907065]
	TIME [epoch: 6.47 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06418772064790365		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.06418772064790365 | validation: 0.0668042018844272]
	TIME [epoch: 6.47 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06112761702527029		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.06112761702527029 | validation: 0.06364498322856289]
	TIME [epoch: 6.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05900813233839426		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.05900813233839426 | validation: 0.06831907134077778]
	TIME [epoch: 6.48 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061424466093165035		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.061424466093165035 | validation: 0.06404255484882225]
	TIME [epoch: 6.47 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06206822940678426		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.06206822940678426 | validation: 0.07353809677072395]
	TIME [epoch: 6.46 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06090543012787995		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.06090543012787995 | validation: 0.0708832803326484]
	TIME [epoch: 6.47 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05868886346132271		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.05868886346132271 | validation: 0.06531003023121863]
	TIME [epoch: 6.47 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06113169569019744		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.06113169569019744 | validation: 0.06264683983951053]
	TIME [epoch: 6.47 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05811549487237945		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.05811549487237945 | validation: 0.06868321514017756]
	TIME [epoch: 6.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05972507755676349		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.05972507755676349 | validation: 0.061911995811167186]
	TIME [epoch: 6.47 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05881944198905098		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.05881944198905098 | validation: 0.07549037429721256]
	TIME [epoch: 6.46 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058387643565523284		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.058387643565523284 | validation: 0.07338416474748115]
	TIME [epoch: 6.47 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062338332383578075		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.062338332383578075 | validation: 0.06537215312916252]
	TIME [epoch: 6.48 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06157552679230711		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.06157552679230711 | validation: 0.062794385303791]
	TIME [epoch: 6.46 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060542705996297956		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.060542705996297956 | validation: 0.07205825344227255]
	TIME [epoch: 6.47 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062253532257885366		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.062253532257885366 | validation: 0.0719168175133311]
	TIME [epoch: 6.48 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059204556405728546		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.059204556405728546 | validation: 0.0779991574936858]
	TIME [epoch: 6.49 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06228484046721671		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.06228484046721671 | validation: 0.07626890626756958]
	TIME [epoch: 6.47 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05972002166372352		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.05972002166372352 | validation: 0.07803679194590032]
	TIME [epoch: 6.46 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057467554202011634		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.057467554202011634 | validation: 0.07556539460947159]
	TIME [epoch: 6.46 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06434684581049856		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.06434684581049856 | validation: 0.07142763866945172]
	TIME [epoch: 6.47 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061234028178139624		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.061234028178139624 | validation: 0.07549625901792047]
	TIME [epoch: 6.47 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06180903778274831		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.06180903778274831 | validation: 0.07733542910210678]
	TIME [epoch: 6.47 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0585838791401592		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.0585838791401592 | validation: 0.06742845559792673]
	TIME [epoch: 6.48 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057791553840172344		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.057791553840172344 | validation: 0.06563532147271892]
	TIME [epoch: 6.48 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06274216661317757		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.06274216661317757 | validation: 0.06363429199639603]
	TIME [epoch: 6.46 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06000053249725333		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.06000053249725333 | validation: 0.05695826184799875]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_1645.pth
	Model improved!!!
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0594425317066956		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.0594425317066956 | validation: 0.05973356512487932]
	TIME [epoch: 6.45 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06220558041911742		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.06220558041911742 | validation: 0.07340104544248786]
	TIME [epoch: 6.46 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05979999325514113		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.05979999325514113 | validation: 0.063609227146336]
	TIME [epoch: 6.47 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0576077421371779		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.0576077421371779 | validation: 0.06450396590765216]
	TIME [epoch: 6.49 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05743224914732303		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.05743224914732303 | validation: 0.06152592974902261]
	TIME [epoch: 6.46 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05906979493755831		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.05906979493755831 | validation: 0.07421620531327093]
	TIME [epoch: 6.45 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061508637214306335		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.061508637214306335 | validation: 0.06602006999316448]
	TIME [epoch: 6.45 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058727726858358226		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.058727726858358226 | validation: 0.06836894546885733]
	TIME [epoch: 6.46 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059301116607203316		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.059301116607203316 | validation: 0.07334857741345874]
	TIME [epoch: 6.46 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056238228213868084		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.056238228213868084 | validation: 0.06463958502141073]
	TIME [epoch: 6.46 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05505319092695733		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.05505319092695733 | validation: 0.07123421088573005]
	TIME [epoch: 6.49 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059778802834193075		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.059778802834193075 | validation: 0.07563205560764188]
	TIME [epoch: 6.45 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05954691008107491		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.05954691008107491 | validation: 0.06564629280982379]
	TIME [epoch: 6.44 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0577943350255133		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.0577943350255133 | validation: 0.0665583268433594]
	TIME [epoch: 6.46 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05605482309257316		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.05605482309257316 | validation: 0.05895023439028229]
	TIME [epoch: 6.46 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05987165508814585		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.05987165508814585 | validation: 0.06435572152857104]
	TIME [epoch: 6.46 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058835312686569226		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.058835312686569226 | validation: 0.06601123041841046]
	TIME [epoch: 6.47 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05923760745147695		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.05923760745147695 | validation: 0.0667463148584856]
	TIME [epoch: 6.49 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06122632618573465		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.06122632618573465 | validation: 0.06447538917035732]
	TIME [epoch: 6.46 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0583775399207206		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.0583775399207206 | validation: 0.06339318507211134]
	TIME [epoch: 6.46 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06200589121861968		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.06200589121861968 | validation: 0.07865277742925438]
	TIME [epoch: 6.46 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060733560801384597		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.060733560801384597 | validation: 0.0712906605083142]
	TIME [epoch: 6.46 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061957199092551866		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.061957199092551866 | validation: 0.0758129332989527]
	TIME [epoch: 6.46 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060844870603879275		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.060844870603879275 | validation: 0.07573430284707025]
	TIME [epoch: 6.46 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058946141623535925		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.058946141623535925 | validation: 0.0776979766543109]
	TIME [epoch: 6.51 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06802162416298738		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.06802162416298738 | validation: 0.08892545354775955]
	TIME [epoch: 6.47 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06296895954125523		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.06296895954125523 | validation: 0.08130000801931463]
	TIME [epoch: 6.46 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06411837081295091		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.06411837081295091 | validation: 0.07166515114827787]
	TIME [epoch: 6.46 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06359975963321651		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.06359975963321651 | validation: 0.06914072666556986]
	TIME [epoch: 6.45 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05968615269952607		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.05968615269952607 | validation: 0.07553718467956753]
	TIME [epoch: 6.46 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06301107720496514		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.06301107720496514 | validation: 0.08019470195449206]
	TIME [epoch: 6.45 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061966799855758314		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.061966799855758314 | validation: 0.07413649241599568]
	TIME [epoch: 6.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06148553503536054		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.06148553503536054 | validation: 0.07210601295844614]
	TIME [epoch: 6.46 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061918174014483116		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.061918174014483116 | validation: 0.08390534694500301]
	TIME [epoch: 6.46 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061017565976368385		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.061017565976368385 | validation: 0.06569894203782801]
	TIME [epoch: 6.46 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0585214511177534		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.0585214511177534 | validation: 0.07515564314668437]
	TIME [epoch: 6.47 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058616527454301626		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.058616527454301626 | validation: 0.06697593768727125]
	TIME [epoch: 6.46 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057986633769213		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.057986633769213 | validation: 0.07257594183208137]
	TIME [epoch: 6.47 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05638275893331557		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.05638275893331557 | validation: 0.06731992482583993]
	TIME [epoch: 6.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06253051284110324		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.06253051284110324 | validation: 0.07321706134889963]
	TIME [epoch: 6.47 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059920650515914345		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.059920650515914345 | validation: 0.06446742181864329]
	TIME [epoch: 6.47 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05880849959911297		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.05880849959911297 | validation: 0.08337228831486054]
	TIME [epoch: 6.46 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06231228620722512		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.06231228620722512 | validation: 0.07306845842137759]
	TIME [epoch: 6.46 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05969198247142779		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.05969198247142779 | validation: 0.07157906017080416]
	TIME [epoch: 6.45 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05925051210184437		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.05925051210184437 | validation: 0.07446631997684997]
	TIME [epoch: 6.45 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05664327152393893		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.05664327152393893 | validation: 0.06957962303449787]
	TIME [epoch: 6.49 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05867894822237703		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.05867894822237703 | validation: 0.07195227287693497]
	TIME [epoch: 6.49 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060020120578407894		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.060020120578407894 | validation: 0.06961796910628619]
	TIME [epoch: 6.47 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056462558326635465		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.056462558326635465 | validation: 0.06230182132330267]
	TIME [epoch: 6.47 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0560695865339942		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.0560695865339942 | validation: 0.07664631173986576]
	TIME [epoch: 6.46 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05968154072708474		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.05968154072708474 | validation: 0.0667082714187499]
	TIME [epoch: 6.47 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344666464307828		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.06344666464307828 | validation: 0.0729435584671738]
	TIME [epoch: 6.47 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05908718786884392		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.05908718786884392 | validation: 0.06639253605989508]
	TIME [epoch: 6.48 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06018029907566941		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.06018029907566941 | validation: 0.07017873640845766]
	TIME [epoch: 6.49 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059653802268516756		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.059653802268516756 | validation: 0.06521174771618285]
	TIME [epoch: 6.47 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05920449683979926		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.05920449683979926 | validation: 0.07318513791768287]
	TIME [epoch: 6.46 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05926830334053866		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.05926830334053866 | validation: 0.07615004358777114]
	TIME [epoch: 6.46 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05800346002919056		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.05800346002919056 | validation: 0.059679888840714526]
	TIME [epoch: 6.46 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058920752551720676		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.058920752551720676 | validation: 0.06830781355299478]
	TIME [epoch: 6.46 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0607921472227861		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.0607921472227861 | validation: 0.06502042304827986]
	TIME [epoch: 6.47 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06693871637650406		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.06693871637650406 | validation: 0.060800765493724346]
	TIME [epoch: 6.49 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059793752816628		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.059793752816628 | validation: 0.07176846203615793]
	TIME [epoch: 6.47 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06140033558723539		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.06140033558723539 | validation: 0.06579695418202605]
	TIME [epoch: 6.46 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060415469295834086		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.060415469295834086 | validation: 0.06298696335818592]
	TIME [epoch: 6.46 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0599160098355		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.0599160098355 | validation: 0.06584598124509881]
	TIME [epoch: 6.46 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059390227542324175		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.059390227542324175 | validation: 0.07291510785034844]
	TIME [epoch: 6.46 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06037069466465715		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.06037069466465715 | validation: 0.06683246866666136]
	TIME [epoch: 6.46 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0620758933102758		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.0620758933102758 | validation: 0.07549759438077797]
	TIME [epoch: 6.49 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059204835825307126		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.059204835825307126 | validation: 0.06196584923445267]
	TIME [epoch: 6.46 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05738885165630088		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.05738885165630088 | validation: 0.07365179442047536]
	TIME [epoch: 6.46 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057545315448622535		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.057545315448622535 | validation: 0.07246056698615377]
	TIME [epoch: 6.46 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056346166503329305		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.056346166503329305 | validation: 0.06876753062628259]
	TIME [epoch: 6.46 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05910580394315059		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.05910580394315059 | validation: 0.06953426253697663]
	TIME [epoch: 6.46 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05548115813473377		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.05548115813473377 | validation: 0.07671534547094032]
	TIME [epoch: 6.46 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05671892996655031		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.05671892996655031 | validation: 0.06427009200738598]
	TIME [epoch: 6.49 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05459772924279671		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.05459772924279671 | validation: 0.06037332229579107]
	TIME [epoch: 6.46 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06122629559949462		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.06122629559949462 | validation: 0.07530712635016404]
	TIME [epoch: 6.45 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05575192775420037		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.05575192775420037 | validation: 0.07574670152109675]
	TIME [epoch: 6.46 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05813397510400593		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.05813397510400593 | validation: 0.07265155990764315]
	TIME [epoch: 6.45 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06093434982211268		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.06093434982211268 | validation: 0.06733972002486664]
	TIME [epoch: 6.45 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06312023908862		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.06312023908862 | validation: 0.061783334113729174]
	TIME [epoch: 6.45 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060425163491330425		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.060425163491330425 | validation: 0.062456788197304144]
	TIME [epoch: 6.49 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06033318044301198		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.06033318044301198 | validation: 0.06354802478327316]
	TIME [epoch: 6.46 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05885865766512541		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.05885865766512541 | validation: 0.06340904408055566]
	TIME [epoch: 6.45 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06048824014921731		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.06048824014921731 | validation: 0.07070557224586216]
	TIME [epoch: 6.45 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05953563600608615		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.05953563600608615 | validation: 0.07411394180150736]
	TIME [epoch: 6.45 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023003917784589		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.06023003917784589 | validation: 0.07537242958755438]
	TIME [epoch: 6.46 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06321349051174927		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.06321349051174927 | validation: 0.06889083188150762]
	TIME [epoch: 6.45 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05534385250437691		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.05534385250437691 | validation: 0.05647485564248548]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_1734.pth
	Model improved!!!
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023470524120848		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.06023470524120848 | validation: 0.06686926727962372]
	TIME [epoch: 6.46 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06148003391046075		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.06148003391046075 | validation: 0.06660523260463937]
	TIME [epoch: 6.45 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05620594176777467		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.05620594176777467 | validation: 0.06739204875220335]
	TIME [epoch: 6.45 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060996317357828275		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.060996317357828275 | validation: 0.06528438077436423]
	TIME [epoch: 6.45 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06090175233985779		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.06090175233985779 | validation: 0.06795033701011455]
	TIME [epoch: 6.45 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06245532759034303		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.06245532759034303 | validation: 0.06690405594874281]
	TIME [epoch: 6.45 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05798039948003684		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.05798039948003684 | validation: 0.05509733215997098]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_1741.pth
	Model improved!!!
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05230714540450832		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.05230714540450832 | validation: 0.0625600363478216]
	TIME [epoch: 6.46 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05637874904587885		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.05637874904587885 | validation: 0.06773773357316291]
	TIME [epoch: 6.46 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06289050074992023		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.06289050074992023 | validation: 0.05977195504244582]
	TIME [epoch: 6.46 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057499809449927		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.057499809449927 | validation: 0.06493111315833815]
	TIME [epoch: 6.46 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05878470304163306		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.05878470304163306 | validation: 0.06126693218523015]
	TIME [epoch: 6.46 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056995850592003		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.056995850592003 | validation: 0.07322593923260101]
	TIME [epoch: 6.46 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055873035429646195		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.055873035429646195 | validation: 0.07168326357264587]
	TIME [epoch: 6.49 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05730297112862901		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.05730297112862901 | validation: 0.06771132655050922]
	TIME [epoch: 6.46 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05763281651336506		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.05763281651336506 | validation: 0.07000965948012108]
	TIME [epoch: 6.46 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05916920032634906		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.05916920032634906 | validation: 0.06751546618519798]
	TIME [epoch: 6.46 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059988481237650534		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.059988481237650534 | validation: 0.06322886408870886]
	TIME [epoch: 6.46 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05924464623679762		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.05924464623679762 | validation: 0.0644523947291348]
	TIME [epoch: 6.46 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05222819285390004		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.05222819285390004 | validation: 0.06830353556447272]
	TIME [epoch: 6.46 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0559239415803517		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.0559239415803517 | validation: 0.05964428046488972]
	TIME [epoch: 6.48 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05990800408268371		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.05990800408268371 | validation: 0.07027887510004234]
	TIME [epoch: 6.48 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05906091678776785		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.05906091678776785 | validation: 0.07188532434301231]
	TIME [epoch: 6.46 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057983001040527574		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.057983001040527574 | validation: 0.06782138743821597]
	TIME [epoch: 6.47 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05755695787085588		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.05755695787085588 | validation: 0.06907432902900638]
	TIME [epoch: 6.47 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05934505513507997		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.05934505513507997 | validation: 0.06987974403653406]
	TIME [epoch: 6.47 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05437223429870039		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.05437223429870039 | validation: 0.07138598101038081]
	TIME [epoch: 6.47 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0580894222235699		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.0580894222235699 | validation: 0.05854876841534948]
	TIME [epoch: 6.47 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05882409120762359		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.05882409120762359 | validation: 0.06877713250281244]
	TIME [epoch: 6.47 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05791233674484034		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.05791233674484034 | validation: 0.0548168595146428]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240310_003036/states/model_tr_study1_1764.pth
	Model improved!!!
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056472653520134405		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.056472653520134405 | validation: 0.06510513029642476]
	TIME [epoch: 6.45 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0562226186341364		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.0562226186341364 | validation: 0.06628622674193654]
	TIME [epoch: 6.45 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058095937138348465		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.058095937138348465 | validation: 0.062276928894186345]
	TIME [epoch: 6.45 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05507951472383414		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.05507951472383414 | validation: 0.07055094965661261]
	TIME [epoch: 6.45 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05708743667304931		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.05708743667304931 | validation: 0.06820111144551615]
	TIME [epoch: 6.47 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058642359286796925		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.058642359286796925 | validation: 0.06721902090942021]
	TIME [epoch: 6.47 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05966835947876076		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.05966835947876076 | validation: 0.060736934357566455]
	TIME [epoch: 6.45 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05953923689100285		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.05953923689100285 | validation: 0.06901285904950355]
	TIME [epoch: 6.45 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057877805863498985		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.057877805863498985 | validation: 0.06310944996368881]
	TIME [epoch: 6.45 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05611182339418756		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.05611182339418756 | validation: 0.0680029632180402]
	TIME [epoch: 6.46 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054770142995320015		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.054770142995320015 | validation: 0.06753689273581595]
	TIME [epoch: 6.46 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0562825572842867		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.0562825572842867 | validation: 0.06448151682237288]
	TIME [epoch: 6.46 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06053071802450864		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.06053071802450864 | validation: 0.07657352790139692]
	TIME [epoch: 6.49 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06058210566559141		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.06058210566559141 | validation: 0.07840690715186906]
	TIME [epoch: 6.47 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058456345724335085		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.058456345724335085 | validation: 0.06411393017954428]
	TIME [epoch: 6.46 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057370630186866334		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.057370630186866334 | validation: 0.07205040447050641]
	TIME [epoch: 6.47 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060386072024564225		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.060386072024564225 | validation: 0.0674959545257147]
	TIME [epoch: 6.46 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061390035537401744		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.061390035537401744 | validation: 0.0686370237307895]
	TIME [epoch: 6.47 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060318774593738196		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.060318774593738196 | validation: 0.07364778211050264]
	TIME [epoch: 6.47 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05532256875085949		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.05532256875085949 | validation: 0.06777281477542126]
	TIME [epoch: 6.51 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055125326986835935		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.055125326986835935 | validation: 0.06865542273353277]
	TIME [epoch: 6.47 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06123897901571292		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.06123897901571292 | validation: 0.06772685626949702]
	TIME [epoch: 6.47 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058388296942111326		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.058388296942111326 | validation: 0.06815795918826473]
	TIME [epoch: 6.47 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058476576277706985		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.058476576277706985 | validation: 0.06448544253866681]
	TIME [epoch: 6.47 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05769370763278338		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.05769370763278338 | validation: 0.06647611938198661]
	TIME [epoch: 6.47 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05476450530086794		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.05476450530086794 | validation: 0.07027056184986114]
	TIME [epoch: 6.46 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05794886571307663		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.05794886571307663 | validation: 0.06963936255545015]
	TIME [epoch: 6.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05769768828674669		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.05769768828674669 | validation: 0.07450072146861338]
	TIME [epoch: 6.47 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056078946998811295		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.056078946998811295 | validation: 0.07445158932535971]
	TIME [epoch: 6.47 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06048473610906509		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.06048473610906509 | validation: 0.07014670702633273]
	TIME [epoch: 6.47 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05645105992706291		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.05645105992706291 | validation: 0.06207665015895934]
	TIME [epoch: 6.46 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056028012905129876		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.056028012905129876 | validation: 0.07101024244562298]
	TIME [epoch: 6.47 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05793897745271315		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.05793897745271315 | validation: 0.06362624401142586]
	TIME [epoch: 6.47 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05378139706379024		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.05378139706379024 | validation: 0.06504738916703985]
	TIME [epoch: 6.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055892296690942714		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.055892296690942714 | validation: 0.07070861056320686]
	TIME [epoch: 6.46 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05880466632876656		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.05880466632876656 | validation: 0.06686363776501585]
	TIME [epoch: 6.46 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05808175293853807		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.05808175293853807 | validation: 0.062115373169129545]
	TIME [epoch: 6.45 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06016190156748923		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.06016190156748923 | validation: 0.06550035630944319]
	TIME [epoch: 6.46 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055892744823893274		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.055892744823893274 | validation: 0.06987380869346682]
	TIME [epoch: 6.47 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05764242662666695		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.05764242662666695 | validation: 0.07298171627255845]
	TIME [epoch: 6.46 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0623115741354246		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.0623115741354246 | validation: 0.06902668743968206]
	TIME [epoch: 6.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057261031436618565		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.057261031436618565 | validation: 0.06980314136771154]
	TIME [epoch: 6.47 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05794423281857388		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.05794423281857388 | validation: 0.06462975507997054]
	TIME [epoch: 6.46 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06154882951366482		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.06154882951366482 | validation: 0.07342027628167427]
	TIME [epoch: 6.46 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06033250737093481		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.06033250737093481 | validation: 0.06762170189698676]
	TIME [epoch: 6.47 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0596040860130477		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.0596040860130477 | validation: 0.06427440307255824]
	TIME [epoch: 6.46 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06201796276088522		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.06201796276088522 | validation: 0.06296420410947677]
	TIME [epoch: 6.45 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059062351500278366		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.059062351500278366 | validation: 0.06879191179834429]
	TIME [epoch: 6.48 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060148002383273405		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.060148002383273405 | validation: 0.07474025783210009]
	TIME [epoch: 6.48 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060867443284767356		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.060867443284767356 | validation: 0.06394299308003508]
	TIME [epoch: 6.47 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059797726670330946		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.059797726670330946 | validation: 0.06705821815925443]
	TIME [epoch: 6.47 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05916689519863192		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.05916689519863192 | validation: 0.06878770920422304]
	TIME [epoch: 6.45 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058041914200139585		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.058041914200139585 | validation: 0.06609861067273737]
	TIME [epoch: 6.46 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05325981089274385		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.05325981089274385 | validation: 0.06949561970472905]
	TIME [epoch: 6.46 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05673810417987284		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.05673810417987284 | validation: 0.065704773436078]
	TIME [epoch: 6.49 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05572531063448498		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.05572531063448498 | validation: 0.07230859440711186]
	TIME [epoch: 6.48 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05566858907266784		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.05566858907266784 | validation: 0.071570609091176]
	TIME [epoch: 6.47 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05490233774472262		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.05490233774472262 | validation: 0.06816772622738886]
	TIME [epoch: 6.47 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0583310781330182		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.0583310781330182 | validation: 0.0678133226709638]
	TIME [epoch: 6.47 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059866426299050625		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.059866426299050625 | validation: 0.07125761487476538]
	TIME [epoch: 6.47 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05726277618141035		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.05726277618141035 | validation: 0.06960997079204088]
	TIME [epoch: 6.47 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05613857163648432		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.05613857163648432 | validation: 0.06783712715978228]
	TIME [epoch: 6.46 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05559232408632808		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.05559232408632808 | validation: 0.07487087423611827]
	TIME [epoch: 6.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059762593862398294		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.059762593862398294 | validation: 0.06321547923028911]
	TIME [epoch: 6.47 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06063131274133597		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.06063131274133597 | validation: 0.07280921111668999]
	TIME [epoch: 6.46 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05424461898176753		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.05424461898176753 | validation: 0.06732823281691955]
	TIME [epoch: 6.45 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05702880263524189		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.05702880263524189 | validation: 0.07109275447483858]
	TIME [epoch: 6.46 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05886685368148494		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.05886685368148494 | validation: 0.06197611039502359]
	TIME [epoch: 6.45 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06255046068776494		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.06255046068776494 | validation: 0.06898578181696265]
	TIME [epoch: 6.45 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056506547007415454		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.056506547007415454 | validation: 0.06451023677731785]
	TIME [epoch: 6.48 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05451874046721485		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.05451874046721485 | validation: 0.06740769016921944]
	TIME [epoch: 6.45 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05716589829000154		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.05716589829000154 | validation: 0.06786223637395793]
	TIME [epoch: 6.46 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059310246456182505		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.059310246456182505 | validation: 0.06467785445105001]
	TIME [epoch: 6.45 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058219699472658766		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.058219699472658766 | validation: 0.06532403297427739]
	TIME [epoch: 6.45 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057957040931556944		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.057957040931556944 | validation: 0.07299612743456681]
	TIME [epoch: 6.44 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05821374547890979		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.05821374547890979 | validation: 0.06774120677975623]
	TIME [epoch: 6.45 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05543882259251308		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.05543882259251308 | validation: 0.0688360192154393]
	TIME [epoch: 6.49 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0557625321445494		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.0557625321445494 | validation: 0.06177296222336981]
	TIME [epoch: 6.45 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05680459624110472		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.05680459624110472 | validation: 0.07267681339540726]
	TIME [epoch: 6.45 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05553801150887681		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.05553801150887681 | validation: 0.07417192933950774]
	TIME [epoch: 6.46 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05954753820172238		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.05954753820172238 | validation: 0.0717793846997952]
	TIME [epoch: 6.46 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05888925396621407		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.05888925396621407 | validation: 0.05969034250076209]
	TIME [epoch: 6.46 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060250274677192024		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.060250274677192024 | validation: 0.0598445612267567]
	TIME [epoch: 6.47 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05572131913974528		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.05572131913974528 | validation: 0.06895802781631698]
	TIME [epoch: 6.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055609328628442596		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.055609328628442596 | validation: 0.0672501060146266]
	TIME [epoch: 6.47 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059291463967151244		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.059291463967151244 | validation: 0.06306050069023264]
	TIME [epoch: 6.46 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06095519223934537		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.06095519223934537 | validation: 0.07456328990069054]
	TIME [epoch: 6.46 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05716908240430827		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.05716908240430827 | validation: 0.06723219221290272]
	TIME [epoch: 6.45 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059916335241485895		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.059916335241485895 | validation: 0.06438458420777791]
	TIME [epoch: 6.46 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05806307831459275		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.05806307831459275 | validation: 0.06615019723102916]
	TIME [epoch: 6.46 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05639611897864556		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.05639611897864556 | validation: 0.0638656189418103]
	TIME [epoch: 6.51 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05647780474039838		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.05647780474039838 | validation: 0.0686927895088213]
	TIME [epoch: 6.47 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054482046146499326		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.054482046146499326 | validation: 0.064622873790329]
	TIME [epoch: 6.46 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0545437521334472		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.0545437521334472 | validation: 0.06559281505692421]
	TIME [epoch: 6.46 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06051278689641671		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.06051278689641671 | validation: 0.0638475583980944]
	TIME [epoch: 6.46 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057287563800820465		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.057287563800820465 | validation: 0.06056376905183381]
	TIME [epoch: 6.46 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06073179170970909		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.06073179170970909 | validation: 0.06260536425665245]
	TIME [epoch: 6.46 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05724341548319322		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.05724341548319322 | validation: 0.06603227517892934]
	TIME [epoch: 6.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056431151811212256		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.056431151811212256 | validation: 0.076575532800754]
	TIME [epoch: 6.46 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055882881729444375		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.055882881729444375 | validation: 0.06433822098539753]
	TIME [epoch: 6.46 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0586376848866021		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.0586376848866021 | validation: 0.07414673464247815]
	TIME [epoch: 6.47 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05842375636282288		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.05842375636282288 | validation: 0.06660655278062953]
	TIME [epoch: 6.46 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059849316870647415		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.059849316870647415 | validation: 0.06570246299527976]
	TIME [epoch: 6.47 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058691521605961486		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.058691521605961486 | validation: 0.07806457734822501]
	TIME [epoch: 6.46 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05493933682754931		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.05493933682754931 | validation: 0.07095896445094296]
	TIME [epoch: 6.48 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06164325323108435		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.06164325323108435 | validation: 0.06623796857841296]
	TIME [epoch: 6.49 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05647048409262184		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.05647048409262184 | validation: 0.07705122749700173]
	TIME [epoch: 6.46 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06015637906429023		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.06015637906429023 | validation: 0.07024126708803632]
	TIME [epoch: 6.47 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06030775921411695		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.06030775921411695 | validation: 0.06940086170530932]
	TIME [epoch: 6.46 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05692988929639179		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.05692988929639179 | validation: 0.07287810933186484]
	TIME [epoch: 6.45 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05807346393324467		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.05807346393324467 | validation: 0.06887571447434832]
	TIME [epoch: 6.47 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05726034096987436		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.05726034096987436 | validation: 0.07308335454734527]
	TIME [epoch: 6.47 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05896005602210766		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.05896005602210766 | validation: 0.07631182413795007]
	TIME [epoch: 6.48 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056649468484084364		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.056649468484084364 | validation: 0.06348520891770981]
	TIME [epoch: 6.47 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06143808726107258		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.06143808726107258 | validation: 0.06660545461851085]
	TIME [epoch: 6.46 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05301560035950851		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.05301560035950851 | validation: 0.07170737443084907]
	TIME [epoch: 6.46 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05472639855860846		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.05472639855860846 | validation: 0.06904394487983488]
	TIME [epoch: 6.47 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060243847014923274		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.060243847014923274 | validation: 0.06576996127995771]
	TIME [epoch: 6.46 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05939024033601543		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.05939024033601543 | validation: 0.06014438916870054]
	TIME [epoch: 6.46 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058004695083073814		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.058004695083073814 | validation: 0.07357227345084993]
	TIME [epoch: 6.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05757277762547557		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.05757277762547557 | validation: 0.069882051339235]
	TIME [epoch: 6.47 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058814032417423		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.058814032417423 | validation: 0.06425796177676696]
	TIME [epoch: 6.46 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054639972458652604		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.054639972458652604 | validation: 0.070764610296735]
	TIME [epoch: 6.46 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05648639580859857		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.05648639580859857 | validation: 0.06880728200487242]
	TIME [epoch: 6.46 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05435146411102862		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.05435146411102862 | validation: 0.0712459156524268]
	TIME [epoch: 6.46 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057530923511826836		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.057530923511826836 | validation: 0.06312441332476838]
	TIME [epoch: 6.46 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060086466330162465		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.060086466330162465 | validation: 0.06960196411342671]
	TIME [epoch: 6.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058070067689853816		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.058070067689853816 | validation: 0.08184152019019646]
	TIME [epoch: 6.46 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023621691001174		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.06023621691001174 | validation: 0.07206913829702186]
	TIME [epoch: 6.46 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05717680801381277		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.05717680801381277 | validation: 0.0694664438484939]
	TIME [epoch: 6.48 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06122526480071307		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.06122526480071307 | validation: 0.07056463351127219]
	TIME [epoch: 6.47 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057187251686854984		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.057187251686854984 | validation: 0.06644290447703054]
	TIME [epoch: 6.46 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05542581642535743		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.05542581642535743 | validation: 0.07167245813221895]
	TIME [epoch: 6.46 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06047913411254245		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.06047913411254245 | validation: 0.07901277401104417]
	TIME [epoch: 6.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05657122794417606		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.05657122794417606 | validation: 0.06745819992523362]
	TIME [epoch: 6.47 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0529953781984723		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.0529953781984723 | validation: 0.06391005567246764]
	TIME [epoch: 6.47 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05976973615248005		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.05976973615248005 | validation: 0.07686344685943902]
	TIME [epoch: 6.46 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06263964091915444		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.06263964091915444 | validation: 0.06790460609069109]
	TIME [epoch: 6.46 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060826905440000835		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.060826905440000835 | validation: 0.06885969365958268]
	TIME [epoch: 6.45 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057338886633950245		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.057338886633950245 | validation: 0.07035662248793548]
	TIME [epoch: 6.45 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055304687133431826		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.055304687133431826 | validation: 0.06854020346844633]
	TIME [epoch: 6.49 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05780263994888708		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.05780263994888708 | validation: 0.06980246170290273]
	TIME [epoch: 6.45 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06352215927207136		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.06352215927207136 | validation: 0.05973886865533375]
	TIME [epoch: 6.45 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05882998256300621		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.05882998256300621 | validation: 0.07047962857307791]
	TIME [epoch: 6.46 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05609298295679751		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.05609298295679751 | validation: 0.0654416396397845]
	TIME [epoch: 6.46 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056612854101230195		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.056612854101230195 | validation: 0.06865687106215036]
	TIME [epoch: 6.46 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05549256470965397		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.05549256470965397 | validation: 0.06995014983545954]
	TIME [epoch: 6.46 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05809472151879554		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.05809472151879554 | validation: 0.07491785359456905]
	TIME [epoch: 6.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057377546661008305		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.057377546661008305 | validation: 0.06292951071448374]
	TIME [epoch: 6.47 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055943998391962554		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.055943998391962554 | validation: 0.061159148492913186]
	TIME [epoch: 6.46 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058038494361968826		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.058038494361968826 | validation: 0.07301703016347749]
	TIME [epoch: 6.47 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05973140180030177		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.05973140180030177 | validation: 0.06488017122077279]
	TIME [epoch: 6.47 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06168642378935886		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.06168642378935886 | validation: 0.06730020384961616]
	TIME [epoch: 6.46 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05549616766445223		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.05549616766445223 | validation: 0.07409762486096903]
	TIME [epoch: 6.46 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05967909422078067		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.05967909422078067 | validation: 0.068611831522663]
	TIME [epoch: 6.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05929594616907821		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.05929594616907821 | validation: 0.05626032729221249]
	TIME [epoch: 6.47 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058134897738077014		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.058134897738077014 | validation: 0.07435063277399996]
	TIME [epoch: 6.46 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05676668748004249		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.05676668748004249 | validation: 0.07196264926006471]
	TIME [epoch: 6.46 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05738001138509418		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.05738001138509418 | validation: 0.062277800265927115]
	TIME [epoch: 6.46 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06076714642017924		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.06076714642017924 | validation: 0.0664527594141679]
	TIME [epoch: 6.47 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05443559871698567		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.05443559871698567 | validation: 0.07127334311286583]
	TIME [epoch: 6.46 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05918279949812873		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.05918279949812873 | validation: 0.07364712753722477]
	TIME [epoch: 6.49 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06383281709839349		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.06383281709839349 | validation: 0.0749102310781554]
	TIME [epoch: 6.48 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054589299015525436		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.054589299015525436 | validation: 0.06274151878307047]
	TIME [epoch: 6.46 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054343750337724143		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.054343750337724143 | validation: 0.07154742402380576]
	TIME [epoch: 6.45 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056905180189174925		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.056905180189174925 | validation: 0.06718869467908194]
	TIME [epoch: 6.45 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06010825747919466		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.06010825747919466 | validation: 0.06375090046275911]
	TIME [epoch: 6.45 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06251714652403041		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.06251714652403041 | validation: 0.07546656922203027]
	TIME [epoch: 6.45 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059785883771726		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.059785883771726 | validation: 0.07198161928032291]
	TIME [epoch: 6.47 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05533391516195658		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.05533391516195658 | validation: 0.06524654062010958]
	TIME [epoch: 6.47 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05911540210488869		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.05911540210488869 | validation: 0.06236009611228389]
	TIME [epoch: 6.45 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05803687357886252		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.05803687357886252 | validation: 0.0706285622682521]
	TIME [epoch: 6.45 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0568614649751768		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.0568614649751768 | validation: 0.07586731471962739]
	TIME [epoch: 6.45 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05571711816129804		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.05571711816129804 | validation: 0.06458908034297109]
	TIME [epoch: 6.45 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05669797320677017		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.05669797320677017 | validation: 0.0640188194644393]
	TIME [epoch: 6.45 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05742174660610645		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.05742174660610645 | validation: 0.0732008905412818]
	TIME [epoch: 6.46 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05702802744185102		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.05702802744185102 | validation: 0.07149847107635217]
	TIME [epoch: 6.47 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055579395839886886		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.055579395839886886 | validation: 0.07133106972928992]
	TIME [epoch: 6.45 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05698663355456379		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.05698663355456379 | validation: 0.06968944594849273]
	TIME [epoch: 6.46 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054307077848303555		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.054307077848303555 | validation: 0.0737366317517011]
	TIME [epoch: 6.46 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056755007192947446		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.056755007192947446 | validation: 0.06642212778867682]
	TIME [epoch: 6.45 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0562074239780915		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.0562074239780915 | validation: 0.07206164528062643]
	TIME [epoch: 6.45 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05735154863460526		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.05735154863460526 | validation: 0.06769920498631858]
	TIME [epoch: 6.45 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05658870735990331		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.05658870735990331 | validation: 0.06570981617121217]
	TIME [epoch: 6.48 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057465636304652117		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.057465636304652117 | validation: 0.06927818649834512]
	TIME [epoch: 6.45 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05988670125508543		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.05988670125508543 | validation: 0.06896402861110483]
	TIME [epoch: 6.45 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05680654495928592		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.05680654495928592 | validation: 0.0685352562061189]
	TIME [epoch: 6.45 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05540907233521451		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.05540907233521451 | validation: 0.07183222670241905]
	TIME [epoch: 6.45 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05830264683955458		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.05830264683955458 | validation: 0.06582704887801975]
	TIME [epoch: 6.45 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05758581459866454		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.05758581459866454 | validation: 0.07725732953068282]
	TIME [epoch: 6.45 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057632482791186095		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.057632482791186095 | validation: 0.07055782057410764]
	TIME [epoch: 6.49 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058433895853427134		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.058433895853427134 | validation: 0.06818700200683024]
	TIME [epoch: 6.45 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05594953915228412		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.05594953915228412 | validation: 0.05903425185589645]
	TIME [epoch: 6.45 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0580220390975847		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.0580220390975847 | validation: 0.0636136631770706]
	TIME [epoch: 6.45 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0575351835866052		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.0575351835866052 | validation: 0.06985048479353127]
	TIME [epoch: 6.45 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05636049790287195		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.05636049790287195 | validation: 0.06825978792287975]
	TIME [epoch: 6.46 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05632728771416288		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.05632728771416288 | validation: 0.060883003776152335]
	TIME [epoch: 6.46 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06093496178781422		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.06093496178781422 | validation: 0.06585465701658841]
	TIME [epoch: 6.51 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06107320199614891		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.06107320199614891 | validation: 0.05971201187671441]
	TIME [epoch: 6.47 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05443415949494025		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.05443415949494025 | validation: 0.06442708942194594]
	TIME [epoch: 6.46 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05777297540931021		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.05777297540931021 | validation: 0.07435727503563078]
	TIME [epoch: 6.46 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054516003280395714		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.054516003280395714 | validation: 0.0719684699791253]
	TIME [epoch: 6.46 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056493875140155136		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.056493875140155136 | validation: 0.06974098344171896]
	TIME [epoch: 6.47 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05540874704993266		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.05540874704993266 | validation: 0.05988355040944367]
	TIME [epoch: 6.46 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061319052287246587		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.061319052287246587 | validation: 0.0626362101213035]
	TIME [epoch: 6.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05907973998615901		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.05907973998615901 | validation: 0.06819106902638732]
	TIME [epoch: 6.47 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05780458542468885		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.05780458542468885 | validation: 0.0714944230908354]
	TIME [epoch: 6.46 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057244663914333284		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.057244663914333284 | validation: 0.06239242100815307]
	TIME [epoch: 6.47 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06057073726974099		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.06057073726974099 | validation: 0.07152889366839352]
	TIME [epoch: 6.46 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057621461215967534		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.057621461215967534 | validation: 0.07047271248996584]
	TIME [epoch: 6.46 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05511129119202592		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.05511129119202592 | validation: 0.06540348162537375]
	TIME [epoch: 6.46 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05864211712837687		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.05864211712837687 | validation: 0.060218540671979195]
	TIME [epoch: 6.48 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05670447416545416		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.05670447416545416 | validation: 0.06759975341267746]
	TIME [epoch: 6.49 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05976784562953254		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.05976784562953254 | validation: 0.07554678400514658]
	TIME [epoch: 6.48 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061262269235899544		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.061262269235899544 | validation: 0.07144595357602102]
	TIME [epoch: 6.46 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05618466878436872		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.05618466878436872 | validation: 0.06380452409956526]
	TIME [epoch: 6.46 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054883210457711086		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.054883210457711086 | validation: 0.06867150506641749]
	TIME [epoch: 6.46 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05349051460589509		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.05349051460589509 | validation: 0.057595408309603906]
	TIME [epoch: 6.47 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0575123844445005		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.0575123844445005 | validation: 0.06856806207062147]
	TIME [epoch: 6.49 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053330442809977535		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.053330442809977535 | validation: 0.0706136042473658]
	TIME [epoch: 6.48 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05656822890505891		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.05656822890505891 | validation: 0.06816637331268949]
	TIME [epoch: 6.47 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06008555923904672		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.06008555923904672 | validation: 0.0787811377371437]
	TIME [epoch: 6.46 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05549700635385746		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.05549700635385746 | validation: 0.0682512126683226]
	TIME [epoch: 6.46 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059165115199665504		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.059165115199665504 | validation: 0.06432494584194562]
	TIME [epoch: 6.46 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05461402109274921		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.05461402109274921 | validation: 0.06686504450216503]
	TIME [epoch: 6.46 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05826165294949072		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.05826165294949072 | validation: 0.07426030192026842]
	TIME [epoch: 6.48 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06031318372540664		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.06031318372540664 | validation: 0.06862624481233555]
	TIME [epoch: 6.48 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05458381796219269		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.05458381796219269 | validation: 0.07343464055045618]
	TIME [epoch: 6.46 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05646133928373592		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.05646133928373592 | validation: 0.06815169377536814]
	TIME [epoch: 6.46 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05888420784974217		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.05888420784974217 | validation: 0.07229254094705978]
	TIME [epoch: 6.46 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054495797516799324		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.054495797516799324 | validation: 0.07546764762948784]
	TIME [epoch: 6.46 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0554499268988063		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.0554499268988063 | validation: 0.07455593039657042]
	TIME [epoch: 6.46 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06049863389729328		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.06049863389729328 | validation: 0.0660469291329225]
	TIME [epoch: 6.46 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057069897864334515		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.057069897864334515 | validation: 0.0697359580997468]
	TIME [epoch: 6.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05497736240095389		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.05497736240095389 | validation: 0.07326220995033322]
	TIME [epoch: 6.46 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05905966764309538		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.05905966764309538 | validation: 0.0714929875654702]
	TIME [epoch: 6.46 sec]
Finished training in 13121.799 seconds.
