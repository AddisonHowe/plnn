Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r0', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 615533753

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.849599720387214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.849599720387214 | validation: 8.987704480973191]
	TIME [epoch: 98.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.507176824774223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.507176824774223 | validation: 8.252644355072047]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.94843949674675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.94843949674675 | validation: 7.342180329641054]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.179328701717343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.179328701717343 | validation: 6.672639668504029]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8892406647248965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8892406647248965 | validation: 6.034418318799982]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.148004439633035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.148004439633035 | validation: 5.822859825138412]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.91511409634403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.91511409634403 | validation: 5.785644330782475]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.750859567689539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.750859567689539 | validation: 5.369708317558303]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4950370200849425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4950370200849425 | validation: 5.1400751561086455]
	TIME [epoch: 6.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.425098159061109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.425098159061109 | validation: 5.441417348735788]
	TIME [epoch: 6.46 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.590967376361715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.590967376361715 | validation: 5.508736097407036]
	TIME [epoch: 6.44 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3780232275404884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3780232275404884 | validation: 5.1981061299717375]
	TIME [epoch: 6.43 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.207122724901378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.207122724901378 | validation: 5.957825081405424]
	TIME [epoch: 6.44 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.524836353611258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.524836353611258 | validation: 5.176290564682542]
	TIME [epoch: 6.44 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.194132591330012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.194132591330012 | validation: 4.930437069022181]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.092529184850598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.092529184850598 | validation: 4.926845623315691]
	TIME [epoch: 6.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.042366625327583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.042366625327583 | validation: 4.815695632984793]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.020733594632386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.020733594632386 | validation: 4.966183288855769]
	TIME [epoch: 6.54 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.869863960468777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.869863960468777 | validation: 4.687183347500054]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.829122330075711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.829122330075711 | validation: 5.008049780709613]
	TIME [epoch: 6.52 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.782188123648609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.782188123648609 | validation: 5.124378859873339]
	TIME [epoch: 6.42 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1360890900250675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1360890900250675 | validation: 4.44301723473353]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6665672845259385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6665672845259385 | validation: 4.367578723017271]
	TIME [epoch: 6.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.507725228532664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.507725228532664 | validation: 4.28291971590902]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510391184404456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.510391184404456 | validation: 4.178118704495427]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.34472799498529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.34472799498529 | validation: 4.391430551603601]
	TIME [epoch: 6.58 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.44788843110517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.44788843110517 | validation: 4.537270104160817]
	TIME [epoch: 6.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.344470676520958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.344470676520958 | validation: 4.309595574735829]
	TIME [epoch: 6.48 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.155353209868123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.155353209868123 | validation: 4.20733360237735]
	TIME [epoch: 6.5 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1532290817501964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1532290817501964 | validation: 3.816033327533163]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.771650828136921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.771650828136921 | validation: 3.7807820299061463]
	TIME [epoch: 6.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.018076098101437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.018076098101437 | validation: 3.5298189776601565]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6271929227274198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6271929227274198 | validation: 3.9701038287354598]
	TIME [epoch: 6.55 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.745304318637924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.745304318637924 | validation: 3.1328443531490824]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2471944831410027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2471944831410027 | validation: 3.208489939979013]
	TIME [epoch: 6.54 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1701765119401326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1701765119401326 | validation: 3.015732358422398]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1485535077921645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1485535077921645 | validation: 3.5205181748196033]
	TIME [epoch: 6.54 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0734382471867447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0734382471867447 | validation: 2.6358405125616993]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0808475135582185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0808475135582185 | validation: 2.568847091996241]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.620791612796251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.620791612796251 | validation: 3.653061275251939]
	TIME [epoch: 6.52 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0993440409108786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0993440409108786 | validation: 2.509524635880753]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.75097642936082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.75097642936082 | validation: 3.384393987153263]
	TIME [epoch: 6.57 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6215425519870887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6215425519870887 | validation: 2.674516975797537]
	TIME [epoch: 6.53 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.849655766213421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.849655766213421 | validation: 2.4547156840604756]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4591298679004705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4591298679004705 | validation: 2.1230673131921343]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.415005521042466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.415005521042466 | validation: 2.053031490838774]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1364508045269996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1364508045269996 | validation: 2.391851443990106]
	TIME [epoch: 6.44 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2712705690193076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2712705690193076 | validation: 1.9434864296243763]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0689714872155367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0689714872155367 | validation: 2.1434402230017437]
	TIME [epoch: 6.58 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291063055339802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.291063055339802 | validation: 3.4942721518111344]
	TIME [epoch: 6.51 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5428197465911766		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.5428197465911766 | validation: 2.4576069127999887]
	TIME [epoch: 6.46 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.022365733923163		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.022365733923163 | validation: 2.127658724486862]
	TIME [epoch: 6.83 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9789237789939629		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.9789237789939629 | validation: 3.4739841352508485]
	TIME [epoch: 6.45 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.431092162772441		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.431092162772441 | validation: 1.9499867656256151]
	TIME [epoch: 6.46 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9295616127006125		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.9295616127006125 | validation: 2.658657914903334]
	TIME [epoch: 6.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8027201618576956		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.8027201618576956 | validation: 2.286491414458817]
	TIME [epoch: 6.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9324869852317381		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.9324869852317381 | validation: 2.2449771233464406]
	TIME [epoch: 6.53 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1631729843616156		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.1631729843616156 | validation: 2.0366856315175377]
	TIME [epoch: 6.49 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8366919241575164		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.8366919241575164 | validation: 2.173916532999153]
	TIME [epoch: 6.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.948191153812397		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.948191153812397 | validation: 1.6881604583262435]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7047574012136106		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.7047574012136106 | validation: 3.4112574898913204]
	TIME [epoch: 6.56 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.389362965687948		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.389362965687948 | validation: 2.113950868959409]
	TIME [epoch: 6.49 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.697000619133516		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.697000619133516 | validation: 1.6186976812555784]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6290436270342055		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.6290436270342055 | validation: 1.7386449165336195]
	TIME [epoch: 6.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.543992682477353		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.543992682477353 | validation: 1.5473514180394239]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.65160660562894		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.65160660562894 | validation: 1.3562621015720513]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4442463390111238		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.4442463390111238 | validation: 1.8684010229602175]
	TIME [epoch: 6.58 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6887260251516056		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.6887260251516056 | validation: 1.6707506996438515]
	TIME [epoch: 6.47 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4705855657807896		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.4705855657807896 | validation: 1.3348175380621252]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3411270813899865		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.3411270813899865 | validation: 2.047636783314885]
	TIME [epoch: 6.66 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6487491479766248		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.6487491479766248 | validation: 1.4090557614158403]
	TIME [epoch: 6.59 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4428136334387867		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.4428136334387867 | validation: 2.012607242287819]
	TIME [epoch: 6.51 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.411519399255026		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.411519399255026 | validation: 1.2735264661761334]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3323873666529293		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.3323873666529293 | validation: 1.4581895954464086]
	TIME [epoch: 6.55 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240563408984044		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.240563408984044 | validation: 1.3533156069085448]
	TIME [epoch: 6.46 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4137381174607204		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.4137381174607204 | validation: 1.7057047735387978]
	TIME [epoch: 6.46 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.385456925411326		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.385456925411326 | validation: 1.8732679934408134]
	TIME [epoch: 6.49 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4424860850604184		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.4424860850604184 | validation: 1.2925478991137533]
	TIME [epoch: 6.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3666029672165845		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.3666029672165845 | validation: 1.6359331692737857]
	TIME [epoch: 6.47 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2385272514027226		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.2385272514027226 | validation: 1.2305800807952236]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3026881056001915		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.3026881056001915 | validation: 1.304450121089875]
	TIME [epoch: 6.62 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2021903850915856		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.2021903850915856 | validation: 1.4807925577998544]
	TIME [epoch: 6.53 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1869037249933925		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.1869037249933925 | validation: 3.449712109457791]
	TIME [epoch: 6.52 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8468717157421712		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.8468717157421712 | validation: 1.3240003802909097]
	TIME [epoch: 6.51 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2020476535959796		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.2020476535959796 | validation: 2.3285076062991807]
	TIME [epoch: 6.52 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3135005861555937		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.3135005861555937 | validation: 1.5587346961361157]
	TIME [epoch: 6.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2670884082402458		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.2670884082402458 | validation: 1.363163296871417]
	TIME [epoch: 6.58 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3280705604816714		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.3280705604816714 | validation: 2.305869294423329]
	TIME [epoch: 6.57 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4346229074852817		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.4346229074852817 | validation: 1.5588715807325961]
	TIME [epoch: 6.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3069459437019466		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.3069459437019466 | validation: 1.2373598631932585]
	TIME [epoch: 6.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.145878509851678		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.145878509851678 | validation: 1.202831582803677]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.216185921236965		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.216185921236965 | validation: 1.0754079287104037]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3438709173564478		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.3438709173564478 | validation: 1.2804050478823716]
	TIME [epoch: 6.47 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2678248843610551		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.2678248843610551 | validation: 1.192094420997018]
	TIME [epoch: 6.48 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1739300288186783		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.1739300288186783 | validation: 1.0101570582292125]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0211288383550812		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.0211288383550812 | validation: 2.433296797195221]
	TIME [epoch: 6.54 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6455772937023345		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.6455772937023345 | validation: 2.4249485544433003]
	TIME [epoch: 6.47 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4103246239290717		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.4103246239290717 | validation: 1.201068062323871]
	TIME [epoch: 6.52 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1115331103664534		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.1115331103664534 | validation: 1.3856974435833684]
	TIME [epoch: 6.53 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2159262634414834		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.2159262634414834 | validation: 1.2310767615948237]
	TIME [epoch: 6.52 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3794629051750056		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.3794629051750056 | validation: 1.2294493235804285]
	TIME [epoch: 6.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4646976087947714		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.4646976087947714 | validation: 1.3535363440479142]
	TIME [epoch: 6.51 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.202209556350474		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.202209556350474 | validation: 1.0805181942846478]
	TIME [epoch: 6.52 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1520216553408809		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.1520216553408809 | validation: 1.0462801867880345]
	TIME [epoch: 6.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0667470454132144		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.0667470454132144 | validation: 1.3346898499691782]
	TIME [epoch: 6.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0672471006482414		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.0672471006482414 | validation: 2.1791672217066376]
	TIME [epoch: 6.54 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7389702957326538		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.7389702957326538 | validation: 1.0771121241454091]
	TIME [epoch: 6.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051915936361468		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.051915936361468 | validation: 1.0146918115445107]
	TIME [epoch: 6.48 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3390190333207355		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.3390190333207355 | validation: 1.1256295112223154]
	TIME [epoch: 6.49 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.069270369933354		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.069270369933354 | validation: 2.23736534472579]
	TIME [epoch: 6.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5308381476508535		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.5308381476508535 | validation: 1.1020434608465444]
	TIME [epoch: 6.58 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1215101163976706		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.1215101163976706 | validation: 1.0527715349340792]
	TIME [epoch: 6.58 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639601896582644		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.0639601896582644 | validation: 1.2824725537522312]
	TIME [epoch: 6.63 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0812159365665464		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.0812159365665464 | validation: 1.547268603870757]
	TIME [epoch: 6.51 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1872744880929857		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.1872744880929857 | validation: 1.1320444625598978]
	TIME [epoch: 6.46 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1714599350749708		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.1714599350749708 | validation: 1.1062081031957085]
	TIME [epoch: 6.48 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.218217710151729		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.218217710151729 | validation: 1.1944423224868328]
	TIME [epoch: 6.48 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0698557714325725		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.0698557714325725 | validation: 1.1334791427636335]
	TIME [epoch: 6.47 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0530251415855287		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.0530251415855287 | validation: 1.0938878582350375]
	TIME [epoch: 6.47 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1606573769333612		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.1606573769333612 | validation: 1.1068008213765288]
	TIME [epoch: 6.53 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1220487967137072		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.1220487967137072 | validation: 1.8993794641302797]
	TIME [epoch: 6.55 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2993881938497467		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.2993881938497467 | validation: 1.3866212331168253]
	TIME [epoch: 6.56 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2143815069369293		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.2143815069369293 | validation: 1.4573160967507963]
	TIME [epoch: 6.53 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.169389066031295		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.169389066031295 | validation: 1.4004952206871064]
	TIME [epoch: 6.49 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142501966749308		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.142501966749308 | validation: 1.483851777340746]
	TIME [epoch: 6.49 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.359537323700871		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.359537323700871 | validation: 1.3004947569083884]
	TIME [epoch: 6.49 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1724549098482182		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.1724549098482182 | validation: 1.1946169561541538]
	TIME [epoch: 6.54 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9850199745533632		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.9850199745533632 | validation: 1.30197653687576]
	TIME [epoch: 6.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1471672649090274		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.1471672649090274 | validation: 1.574676480784438]
	TIME [epoch: 6.46 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0476028710471452		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.0476028710471452 | validation: 1.074697518644931]
	TIME [epoch: 6.48 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0022549085205124		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.0022549085205124 | validation: 1.1402055427721411]
	TIME [epoch: 6.49 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1282495693389523		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.1282495693389523 | validation: 1.1919103902971444]
	TIME [epoch: 6.49 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2043017856387694		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.2043017856387694 | validation: 1.1835761966223637]
	TIME [epoch: 6.49 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.342791012474637		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.342791012474637 | validation: 1.0189370374673699]
	TIME [epoch: 6.53 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.072470259853034		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.072470259853034 | validation: 1.2729900851184248]
	TIME [epoch: 6.49 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0670492405498506		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.0670492405498506 | validation: 1.168848296706116]
	TIME [epoch: 6.48 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1877202650335077		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.1877202650335077 | validation: 1.0550294426920999]
	TIME [epoch: 6.46 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9628964142874811		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.9628964142874811 | validation: 1.3320526266880506]
	TIME [epoch: 6.49 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8813123535621528		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.8813123535621528 | validation: 1.3255792237754924]
	TIME [epoch: 6.49 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9774302811367656		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.9774302811367656 | validation: 1.2023936890512181]
	TIME [epoch: 6.48 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1726108284498897		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.1726108284498897 | validation: 0.9514238970773952]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9947366506773949		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.9947366506773949 | validation: 1.0869976520033082]
	TIME [epoch: 6.62 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.161426082946141		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.161426082946141 | validation: 0.961073593609489]
	TIME [epoch: 6.51 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0396894205867317		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.0396894205867317 | validation: 1.2111252180089989]
	TIME [epoch: 6.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.048978048501387		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.048978048501387 | validation: 1.4132231867531584]
	TIME [epoch: 6.49 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1771112771285355		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.1771112771285355 | validation: 1.335436210540197]
	TIME [epoch: 6.47 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1605476088611844		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.1605476088611844 | validation: 1.3322103118098627]
	TIME [epoch: 6.47 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1353198892279541		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.1353198892279541 | validation: 0.989046702309852]
	TIME [epoch: 6.49 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0322460159456075		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.0322460159456075 | validation: 0.9976465882194069]
	TIME [epoch: 6.51 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1271149529956932		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.1271149529956932 | validation: 1.1063133890956471]
	TIME [epoch: 6.48 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0050047772713537		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.0050047772713537 | validation: 1.2370735884289603]
	TIME [epoch: 6.48 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1093324361752805		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.1093324361752805 | validation: 1.7902318173509268]
	TIME [epoch: 6.48 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2628973970341055		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.2628973970341055 | validation: 1.0054185601886867]
	TIME [epoch: 6.47 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.929958391785314		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.929958391785314 | validation: 1.9821625716292082]
	TIME [epoch: 6.47 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2024122792064722		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.2024122792064722 | validation: 1.481428520239572]
	TIME [epoch: 6.48 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2692567922635312		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.2692567922635312 | validation: 1.5611207012568757]
	TIME [epoch: 6.48 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.106640656412016		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.106640656412016 | validation: 1.4248319569920096]
	TIME [epoch: 6.47 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1274892352942059		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.1274892352942059 | validation: 1.6130747465677289]
	TIME [epoch: 6.47 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0877302812230814		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.0877302812230814 | validation: 1.128849920503828]
	TIME [epoch: 6.47 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0303282857077127		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.0303282857077127 | validation: 1.1181901618504588]
	TIME [epoch: 6.48 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.881054012137762		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.881054012137762 | validation: 0.9094141166197823]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8993527204070912		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.8993527204070912 | validation: 1.463346918468954]
	TIME [epoch: 6.57 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0731529629665681		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.0731529629665681 | validation: 1.4972278654567246]
	TIME [epoch: 6.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153331284905112		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.153331284905112 | validation: 1.5848620943600296]
	TIME [epoch: 6.48 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.041853377746505		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.041853377746505 | validation: 1.2050862532249367]
	TIME [epoch: 6.48 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9784910143960486		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.9784910143960486 | validation: 1.2750492471320751]
	TIME [epoch: 6.48 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1834610549541815		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.1834610549541815 | validation: 1.83961341111001]
	TIME [epoch: 6.49 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1787202585867695		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.1787202585867695 | validation: 1.3745778599309173]
	TIME [epoch: 6.49 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6189467991882576		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.6189467991882576 | validation: 2.3874343891697087]
	TIME [epoch: 6.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4174568592495969		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.4174568592495969 | validation: 1.0637687570853624]
	TIME [epoch: 6.54 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8610901934357197		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.8610901934357197 | validation: 1.2134207642487236]
	TIME [epoch: 6.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8921406976214303		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.8921406976214303 | validation: 1.5276800534173918]
	TIME [epoch: 6.49 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0716296780296029		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.0716296780296029 | validation: 1.0562143531950414]
	TIME [epoch: 6.48 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0659562353362912		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.0659562353362912 | validation: 0.8636613758817075]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9585990076827988		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.9585990076827988 | validation: 0.859867515924899]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1059705609293846		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.1059705609293846 | validation: 1.003751442504772]
	TIME [epoch: 6.55 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1229125122824501		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.1229125122824501 | validation: 0.9664453677828615]
	TIME [epoch: 6.52 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9028007102451683		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.9028007102451683 | validation: 0.9674778946309541]
	TIME [epoch: 6.48 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0218134316327283		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.0218134316327283 | validation: 0.8216510766412881]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0788964645953039		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.0788964645953039 | validation: 1.0970826608257513]
	TIME [epoch: 6.54 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0013523227741734		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.0013523227741734 | validation: 1.1923718018449507]
	TIME [epoch: 6.48 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0035752450565396		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.0035752450565396 | validation: 1.1093678902144875]
	TIME [epoch: 6.48 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.844128345844688		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.844128345844688 | validation: 1.0916096922668852]
	TIME [epoch: 6.49 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9202508153533384		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9202508153533384 | validation: 0.8448280936943436]
	TIME [epoch: 6.53 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9215363667763		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.9215363667763 | validation: 1.6163385667189467]
	TIME [epoch: 6.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1655735196526695		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.1655735196526695 | validation: 0.9339346272905381]
	TIME [epoch: 6.48 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0157551849270103		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.0157551849270103 | validation: 1.1283471524958384]
	TIME [epoch: 6.49 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0589530740876778		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.0589530740876778 | validation: 0.886877000860913]
	TIME [epoch: 6.49 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8771927991062638		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.8771927991062638 | validation: 0.920499414662388]
	TIME [epoch: 6.49 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9976454322822645		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.9976454322822645 | validation: 0.8888330772725194]
	TIME [epoch: 6.48 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0970484451657434		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.0970484451657434 | validation: 0.9605218400372539]
	TIME [epoch: 6.54 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9887413956460184		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.9887413956460184 | validation: 1.1911628293185976]
	TIME [epoch: 6.49 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9951050429692367		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.9951050429692367 | validation: 1.111176844545682]
	TIME [epoch: 6.48 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.851736002431517		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.851736002431517 | validation: 1.0591928596553306]
	TIME [epoch: 6.49 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0562665316628943		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.0562665316628943 | validation: 0.8489894857525857]
	TIME [epoch: 6.49 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9592894585858338		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.9592894585858338 | validation: 1.0702381448280698]
	TIME [epoch: 6.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9441568943014835		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.9441568943014835 | validation: 1.2083750219603515]
	TIME [epoch: 6.48 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.014472271767135		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.014472271767135 | validation: 1.1665671422481447]
	TIME [epoch: 6.54 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8748132153017272		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.8748132153017272 | validation: 0.8771591204040081]
	TIME [epoch: 6.49 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0072920050771892		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.0072920050771892 | validation: 0.9398455708935447]
	TIME [epoch: 6.49 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8270656562512002		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.8270656562512002 | validation: 1.0873423927779942]
	TIME [epoch: 6.48 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8264184577461171		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.8264184577461171 | validation: 0.8838419468709189]
	TIME [epoch: 6.48 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7629438638409407		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.7629438638409407 | validation: 1.0474762074099033]
	TIME [epoch: 6.46 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9108278206914295		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.9108278206914295 | validation: 0.9154196091344587]
	TIME [epoch: 6.48 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8042701059571559		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.8042701059571559 | validation: 0.6920717945967299]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8339117414618782		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.8339117414618782 | validation: 1.1723771818612816]
	TIME [epoch: 6.58 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.097719143129825		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.097719143129825 | validation: 1.0356253271812954]
	TIME [epoch: 6.45 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8379018098031039		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.8379018098031039 | validation: 0.7561887773472925]
	TIME [epoch: 6.47 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7787293618844711		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.7787293618844711 | validation: 0.8069829485374822]
	TIME [epoch: 6.47 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7580508824429281		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.7580508824429281 | validation: 1.516455233062296]
	TIME [epoch: 6.48 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0655206771145438		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.0655206771145438 | validation: 0.928983202873306]
	TIME [epoch: 6.47 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8589080792894022		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8589080792894022 | validation: 1.1215871444418657]
	TIME [epoch: 6.54 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9175858066733634		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.9175858066733634 | validation: 1.0038250317237525]
	TIME [epoch: 6.49 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8692563347074223		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.8692563347074223 | validation: 0.7492819332766035]
	TIME [epoch: 6.49 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7915914634574726		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.7915914634574726 | validation: 1.1584374704767466]
	TIME [epoch: 6.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.90687019917377		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.90687019917377 | validation: 1.2246578716225576]
	TIME [epoch: 6.49 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9492954151901876		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.9492954151901876 | validation: 1.0190975221597063]
	TIME [epoch: 6.48 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9389413636104647		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.9389413636104647 | validation: 1.085298131541762]
	TIME [epoch: 6.49 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.016923823207503		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.016923823207503 | validation: 1.069003406329805]
	TIME [epoch: 6.48 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8847720794350225		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.8847720794350225 | validation: 0.8381993319932687]
	TIME [epoch: 6.51 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.050720262598848		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.050720262598848 | validation: 0.9864207441416432]
	TIME [epoch: 6.48 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8267285851136185		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.8267285851136185 | validation: 0.8262874492562778]
	TIME [epoch: 6.49 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8752446650509473		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.8752446650509473 | validation: 0.7485626921831934]
	TIME [epoch: 6.47 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8939675735812839		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.8939675735812839 | validation: 0.7341727119063017]
	TIME [epoch: 6.48 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.793264102130866		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.793264102130866 | validation: 1.070056353251771]
	TIME [epoch: 6.48 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8215954914938985		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.8215954914938985 | validation: 0.8046715061097476]
	TIME [epoch: 6.59 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8020908218538538		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.8020908218538538 | validation: 1.180046134358934]
	TIME [epoch: 6.51 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8694139126197622		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.8694139126197622 | validation: 1.0233856786945743]
	TIME [epoch: 6.49 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7880425893599382		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.7880425893599382 | validation: 1.128590680347665]
	TIME [epoch: 6.48 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.963367923420851		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.963367923420851 | validation: 1.0204021769583693]
	TIME [epoch: 6.46 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8034042982250762		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.8034042982250762 | validation: 0.830585811565006]
	TIME [epoch: 6.49 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.757061871550176		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.757061871550176 | validation: 0.9396526282183391]
	TIME [epoch: 6.47 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7551695669535388		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.7551695669535388 | validation: 0.7656728442157069]
	TIME [epoch: 6.52 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0149114112278992		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.0149114112278992 | validation: 0.8264196951690687]
	TIME [epoch: 6.54 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8169656534752616		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.8169656534752616 | validation: 0.872462676667712]
	TIME [epoch: 6.51 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8862598231850402		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.8862598231850402 | validation: 1.2052849990446297]
	TIME [epoch: 6.51 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9617918835700453		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.9617918835700453 | validation: 1.011606086058285]
	TIME [epoch: 6.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.843939854364081		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.843939854364081 | validation: 0.7152752967480478]
	TIME [epoch: 6.48 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.851028568939143		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.851028568939143 | validation: 0.9439850709579463]
	TIME [epoch: 6.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7758066526308561		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.7758066526308561 | validation: 0.7751648675332462]
	TIME [epoch: 6.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7725296935323485		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.7725296935323485 | validation: 0.8971135562950261]
	TIME [epoch: 6.55 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7881101688733668		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.7881101688733668 | validation: 1.1265752579699781]
	TIME [epoch: 6.49 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9928808533792522		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.9928808533792522 | validation: 1.1960162011020108]
	TIME [epoch: 6.48 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9184428846138428		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.9184428846138428 | validation: 1.0532963882417912]
	TIME [epoch: 6.51 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.795337181500546		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.795337181500546 | validation: 0.8184372242820299]
	TIME [epoch: 6.51 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170291485109463		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.7170291485109463 | validation: 0.7156259450371154]
	TIME [epoch: 6.48 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258316582760485		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.7258316582760485 | validation: 1.0635158930377633]
	TIME [epoch: 6.49 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8439531739254649		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.8439531739254649 | validation: 0.8696713291102897]
	TIME [epoch: 6.53 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8554986243537464		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.8554986243537464 | validation: 0.720261867806714]
	TIME [epoch: 6.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7630553807181721		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.7630553807181721 | validation: 0.8108406087771846]
	TIME [epoch: 6.59 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6992583018079559		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.6992583018079559 | validation: 1.0410492561558033]
	TIME [epoch: 6.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8464515577045605		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.8464515577045605 | validation: 0.7800148636682743]
	TIME [epoch: 6.58 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7921121287828872		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7921121287828872 | validation: 0.857277291908495]
	TIME [epoch: 6.52 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7520298148006306		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.7520298148006306 | validation: 0.7331415636478767]
	TIME [epoch: 6.48 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6482134226879279		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.6482134226879279 | validation: 1.2931123632996153]
	TIME [epoch: 6.53 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0030881626679717		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.0030881626679717 | validation: 0.6700756364705217]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7582963221047413		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.7582963221047413 | validation: 0.7687582467950993]
	TIME [epoch: 6.53 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7509980500160712		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.7509980500160712 | validation: 0.6931700290920607]
	TIME [epoch: 6.47 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6711851383672249		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.6711851383672249 | validation: 0.7622688148686586]
	TIME [epoch: 6.49 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7371733896976252		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.7371733896976252 | validation: 1.112718317510189]
	TIME [epoch: 6.49 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9291812821367847		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.9291812821367847 | validation: 0.7196594211832172]
	TIME [epoch: 6.51 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.78009456895812		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.78009456895812 | validation: 0.7906447990004997]
	TIME [epoch: 6.56 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245683169613544		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.0245683169613544 | validation: 0.756964715148019]
	TIME [epoch: 6.51 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8075317997206521		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.8075317997206521 | validation: 0.6599539888229949]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7969778598646449		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.7969778598646449 | validation: 0.7540868472097644]
	TIME [epoch: 6.53 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7275940956208838		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7275940956208838 | validation: 0.8581104953761064]
	TIME [epoch: 6.49 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7133241851722253		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.7133241851722253 | validation: 0.8608684537503001]
	TIME [epoch: 6.48 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7062999481825033		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7062999481825033 | validation: 0.7295794756916206]
	TIME [epoch: 6.48 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257850899534444		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.7257850899534444 | validation: 0.9612483233759447]
	TIME [epoch: 6.54 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8611797971091744		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.8611797971091744 | validation: 1.3694254575255094]
	TIME [epoch: 6.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8566410105468976		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.8566410105468976 | validation: 0.7747500314367761]
	TIME [epoch: 6.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.742072687097833		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.742072687097833 | validation: 0.8099704885372481]
	TIME [epoch: 6.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8213964760853045		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.8213964760853045 | validation: 0.7262459747795441]
	TIME [epoch: 6.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7826666444278781		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.7826666444278781 | validation: 0.9328324582454542]
	TIME [epoch: 6.51 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0610018067494573		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.0610018067494573 | validation: 1.29627114809616]
	TIME [epoch: 6.51 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.155717518480306		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.155717518480306 | validation: 1.0453481213031703]
	TIME [epoch: 6.54 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9046254454765403		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.9046254454765403 | validation: 0.9856875717774243]
	TIME [epoch: 6.53 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8374630576722486		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.8374630576722486 | validation: 0.7455420713204925]
	TIME [epoch: 6.51 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8351372827230463		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.8351372827230463 | validation: 0.7703303623727901]
	TIME [epoch: 6.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7146527684837718		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.7146527684837718 | validation: 0.9920641848525699]
	TIME [epoch: 6.51 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.759733753432417		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.759733753432417 | validation: 0.8165146655239462]
	TIME [epoch: 6.49 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194096340413323		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7194096340413323 | validation: 1.121639706917529]
	TIME [epoch: 6.53 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7466982630751351		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.7466982630751351 | validation: 1.1559553492979573]
	TIME [epoch: 6.53 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.747863708395891		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.747863708395891 | validation: 1.1549847598052114]
	TIME [epoch: 6.56 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7622495487334785		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.7622495487334785 | validation: 0.706176654334756]
	TIME [epoch: 6.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6486133074418965		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.6486133074418965 | validation: 0.7494790386979608]
	TIME [epoch: 6.49 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6916205999095433		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6916205999095433 | validation: 0.7980614659630461]
	TIME [epoch: 6.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8934031062601222		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.8934031062601222 | validation: 0.8536021557697612]
	TIME [epoch: 6.49 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7634404578599266		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.7634404578599266 | validation: 1.0618530245952797]
	TIME [epoch: 6.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8754543843619909		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.8754543843619909 | validation: 1.140151420585749]
	TIME [epoch: 6.55 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208243206843573		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.7208243206843573 | validation: 0.7101112284927404]
	TIME [epoch: 6.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863773603117487		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.6863773603117487 | validation: 0.8094599437987864]
	TIME [epoch: 6.55 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7618762935377505		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.7618762935377505 | validation: 1.204179877967784]
	TIME [epoch: 6.48 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7468914492419721		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.7468914492419721 | validation: 0.7223012985877467]
	TIME [epoch: 6.48 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235291550922163		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.7235291550922163 | validation: 1.0381480346542302]
	TIME [epoch: 6.47 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6749303481680959		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.6749303481680959 | validation: 0.6512702702036068]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.732982433212168		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.732982433212168 | validation: 0.6996589285280291]
	TIME [epoch: 6.58 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7074692841717272		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.7074692841717272 | validation: 0.6715087785282521]
	TIME [epoch: 6.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7464883436358927		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.7464883436358927 | validation: 0.8315406353119323]
	TIME [epoch: 6.46 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7263907930013479		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.7263907930013479 | validation: 0.6816960919180266]
	TIME [epoch: 6.48 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6722405419588182		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.6722405419588182 | validation: 0.6462956555540893]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6233814987487838		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6233814987487838 | validation: 0.590339089832108]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843159941662214		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.6843159941662214 | validation: 0.715350350060578]
	TIME [epoch: 6.58 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6314607323566833		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.6314607323566833 | validation: 0.7354791793690433]
	TIME [epoch: 6.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7338384360959387		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.7338384360959387 | validation: 1.0229790699328445]
	TIME [epoch: 6.51 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7526471485638588		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.7526471485638588 | validation: 0.7128942160687683]
	TIME [epoch: 6.49 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206935606251482		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.7206935606251482 | validation: 0.6291421968817457]
	TIME [epoch: 6.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.59861968708636		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.59861968708636 | validation: 0.9604178653580793]
	TIME [epoch: 6.48 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7341355152096305		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.7341355152096305 | validation: 0.7156998739339371]
	TIME [epoch: 6.48 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213418884845797		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.7213418884845797 | validation: 0.9009499641688501]
	TIME [epoch: 6.47 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7125377519324282		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.7125377519324282 | validation: 0.9970988634379672]
	TIME [epoch: 6.54 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8352308350636755		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.8352308350636755 | validation: 0.7523765999519448]
	TIME [epoch: 6.53 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6799810958470568		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.6799810958470568 | validation: 0.7838457732239078]
	TIME [epoch: 6.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881177391250388		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.6881177391250388 | validation: 0.8426922803975597]
	TIME [epoch: 6.49 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6261201671002844		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.6261201671002844 | validation: 0.9090794703453751]
	TIME [epoch: 6.49 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.728881480321635		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.728881480321635 | validation: 1.0320900021142878]
	TIME [epoch: 6.49 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8033072479547086		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.8033072479547086 | validation: 0.7906070002117092]
	TIME [epoch: 6.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6446808805925064		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.6446808805925064 | validation: 0.7798835591456558]
	TIME [epoch: 6.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201585872511019		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.7201585872511019 | validation: 1.0790013174973492]
	TIME [epoch: 6.52 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7952593469840884		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.7952593469840884 | validation: 0.7985740025405255]
	TIME [epoch: 6.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6930431139323154		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6930431139323154 | validation: 0.6934228301595947]
	TIME [epoch: 6.49 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813794779809194		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.6813794779809194 | validation: 0.7632256816420272]
	TIME [epoch: 6.53 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7786755880366546		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7786755880366546 | validation: 0.9848887881105806]
	TIME [epoch: 6.55 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7865620291411987		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.7865620291411987 | validation: 0.7106609934326139]
	TIME [epoch: 6.54 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6403854220751051		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.6403854220751051 | validation: 1.103092444248223]
	TIME [epoch: 6.53 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8435292154107971		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.8435292154107971 | validation: 0.9121889545013275]
	TIME [epoch: 6.62 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7480511262440784		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.7480511262440784 | validation: 0.8507490519131622]
	TIME [epoch: 6.52 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.603146431954016		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.603146431954016 | validation: 0.7632493028851133]
	TIME [epoch: 6.52 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7144061849835537		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.7144061849835537 | validation: 0.729047628554915]
	TIME [epoch: 6.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.708064431654291		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.708064431654291 | validation: 0.7309606977504646]
	TIME [epoch: 6.53 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6567758362072078		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.6567758362072078 | validation: 0.7407264618128601]
	TIME [epoch: 6.51 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6310486687352093		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.6310486687352093 | validation: 0.8596174127889075]
	TIME [epoch: 6.52 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6740561521778052		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.6740561521778052 | validation: 0.6013350434070965]
	TIME [epoch: 6.56 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6803283005542117		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.6803283005542117 | validation: 0.8176830290168828]
	TIME [epoch: 6.48 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6662187827158417		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.6662187827158417 | validation: 0.6845783952963964]
	TIME [epoch: 6.48 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.667685922297911		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.667685922297911 | validation: 0.769996850092457]
	TIME [epoch: 6.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6518537502388839		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.6518537502388839 | validation: 0.568609730720642]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_337.pth
	Model improved!!!
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5949041001033233		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.5949041001033233 | validation: 0.8310930511475226]
	TIME [epoch: 6.59 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6040061469844178		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.6040061469844178 | validation: 0.9128727980326835]
	TIME [epoch: 6.46 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.641754312813707		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.641754312813707 | validation: 0.8002008638999561]
	TIME [epoch: 6.52 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6474186850019975		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.6474186850019975 | validation: 0.6246555632711455]
	TIME [epoch: 6.49 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7551196104653193		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.7551196104653193 | validation: 0.5759857324306189]
	TIME [epoch: 6.53 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.62248252352867		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.62248252352867 | validation: 0.6806582985249111]
	TIME [epoch: 6.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5786061026839356		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5786061026839356 | validation: 0.651562477436466]
	TIME [epoch: 6.51 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.803297218764943		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.803297218764943 | validation: 0.7146473983590752]
	TIME [epoch: 6.51 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863259821372146		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.6863259821372146 | validation: 0.6238209233762977]
	TIME [epoch: 6.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.779250632204116		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.779250632204116 | validation: 1.0806805379344737]
	TIME [epoch: 6.55 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.657032976442794		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.657032976442794 | validation: 0.602533463675472]
	TIME [epoch: 6.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5387593234380847		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.5387593234380847 | validation: 0.9219398698935549]
	TIME [epoch: 6.48 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6596219148858055		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.6596219148858055 | validation: 0.7234683323083141]
	TIME [epoch: 6.49 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6177969232099845		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.6177969232099845 | validation: 0.9563054488629285]
	TIME [epoch: 6.47 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6053286415076731		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.6053286415076731 | validation: 0.6808457695426847]
	TIME [epoch: 6.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9084552645000048		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.9084552645000048 | validation: 1.0906314471358962]
	TIME [epoch: 6.48 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7684014689949439		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.7684014689949439 | validation: 0.6165210730613072]
	TIME [epoch: 6.54 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937015020854009		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.6937015020854009 | validation: 0.7833613830543652]
	TIME [epoch: 6.49 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6002962007093023		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.6002962007093023 | validation: 0.9441592728157762]
	TIME [epoch: 6.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.777147903907152		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.777147903907152 | validation: 0.8737957867542946]
	TIME [epoch: 6.49 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6320912394620855		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.6320912394620855 | validation: 0.6434135808335077]
	TIME [epoch: 6.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6453629983361746		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.6453629983361746 | validation: 0.7365923143191644]
	TIME [epoch: 6.49 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6179326244457094		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.6179326244457094 | validation: 0.9792534052575391]
	TIME [epoch: 6.51 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8934387514214335		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.8934387514214335 | validation: 0.7980591042960112]
	TIME [epoch: 6.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6136217911218279		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.6136217911218279 | validation: 0.8579054774803513]
	TIME [epoch: 6.52 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6147598340128515		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.6147598340128515 | validation: 0.8660714718923054]
	TIME [epoch: 6.51 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6399658797206469		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.6399658797206469 | validation: 0.8264274588659022]
	TIME [epoch: 6.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6796881674967732		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.6796881674967732 | validation: 0.8233194112812978]
	TIME [epoch: 6.47 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7601263918638728		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.7601263918638728 | validation: 0.8758831397928225]
	TIME [epoch: 6.47 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9799082781544318		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.9799082781544318 | validation: 0.9366308607530849]
	TIME [epoch: 6.49 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7032652539534208		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.7032652539534208 | validation: 0.6499693530097491]
	TIME [epoch: 6.51 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5936068500788191		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.5936068500788191 | validation: 0.7174542762359315]
	TIME [epoch: 6.51 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5993878286784854		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.5993878286784854 | validation: 1.0728418273928546]
	TIME [epoch: 6.47 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6413217679345266		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.6413217679345266 | validation: 0.5599646080731171]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5129461812886322		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.5129461812886322 | validation: 1.0580545761613638]
	TIME [epoch: 6.51 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.710030242184279		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.710030242184279 | validation: 0.6826129716835625]
	TIME [epoch: 6.44 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5859999327636207		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.5859999327636207 | validation: 0.7394488885789923]
	TIME [epoch: 6.46 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.650804642632371		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.650804642632371 | validation: 0.5138273759530807]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_375.pth
	Model improved!!!
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.53692551722418		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.53692551722418 | validation: 0.7293104946659849]
	TIME [epoch: 6.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6948162457256346		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.6948162457256346 | validation: 0.7343289188659143]
	TIME [epoch: 6.49 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6566928730803421		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.6566928730803421 | validation: 0.7047531731598882]
	TIME [epoch: 6.48 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6107904306184945		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.6107904306184945 | validation: 0.5641026303265565]
	TIME [epoch: 6.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.584370653531622		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.584370653531622 | validation: 0.9412389265332126]
	TIME [epoch: 6.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6649537110837831		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.6649537110837831 | validation: 0.6977972469929722]
	TIME [epoch: 6.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.696812878425018		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.696812878425018 | validation: 0.7573272138893132]
	TIME [epoch: 6.52 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7184939058290849		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.7184939058290849 | validation: 0.6417055455073469]
	TIME [epoch: 6.55 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6408584313107633		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.6408584313107633 | validation: 0.6597220500010428]
	TIME [epoch: 6.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6683666810204104		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.6683666810204104 | validation: 0.6431548580080402]
	TIME [epoch: 6.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6544916139408505		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.6544916139408505 | validation: 0.7030471337687522]
	TIME [epoch: 6.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5764838561540551		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.5764838561540551 | validation: 0.5405561998638403]
	TIME [epoch: 6.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5310798249553585		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.5310798249553585 | validation: 0.561702191838049]
	TIME [epoch: 6.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5760959357692186		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.5760959357692186 | validation: 0.691315512115499]
	TIME [epoch: 6.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6147722179342481		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.6147722179342481 | validation: 0.6416372389535853]
	TIME [epoch: 6.54 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5722881802938908		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.5722881802938908 | validation: 0.7859050302745826]
	TIME [epoch: 6.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5741756907442466		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.5741756907442466 | validation: 0.5792645288676136]
	TIME [epoch: 6.49 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5576402238786662		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.5576402238786662 | validation: 0.750337294128288]
	TIME [epoch: 6.49 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5874390901919759		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.5874390901919759 | validation: 0.6045041604740182]
	TIME [epoch: 6.49 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6476621279579446		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.6476621279579446 | validation: 0.6341589462654678]
	TIME [epoch: 6.48 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5912832876163273		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.5912832876163273 | validation: 0.7970620511282573]
	TIME [epoch: 6.49 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6361687301963257		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.6361687301963257 | validation: 0.6963740365650936]
	TIME [epoch: 6.53 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5772925431693934		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.5772925431693934 | validation: 0.7926636823703899]
	TIME [epoch: 6.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6206256247470722		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.6206256247470722 | validation: 0.6070395246994851]
	TIME [epoch: 6.49 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5562889712238661		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.5562889712238661 | validation: 0.6782986597704086]
	TIME [epoch: 6.49 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6394927858441177		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.6394927858441177 | validation: 0.5565621512818958]
	TIME [epoch: 6.47 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5890127110382688		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.5890127110382688 | validation: 0.5731678632804859]
	TIME [epoch: 6.48 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5613408192048943		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.5613408192048943 | validation: 0.5724805967181658]
	TIME [epoch: 6.47 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228832921461342		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.6228832921461342 | validation: 0.5403598814919779]
	TIME [epoch: 6.52 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5492002831172684		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.5492002831172684 | validation: 0.6415549688445691]
	TIME [epoch: 6.49 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8640414852251599		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.8640414852251599 | validation: 0.7677683902971589]
	TIME [epoch: 6.48 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6134552717859648		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.6134552717859648 | validation: 0.6693691432054228]
	TIME [epoch: 6.49 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6670988217878917		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.6670988217878917 | validation: 0.5087749818097127]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6046782651489606		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.6046782651489606 | validation: 0.9109044700030688]
	TIME [epoch: 6.55 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7810371098879196		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.7810371098879196 | validation: 0.6958228914875082]
	TIME [epoch: 6.47 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6166070939148772		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.6166070939148772 | validation: 0.6391418773655551]
	TIME [epoch: 6.53 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199591545784827		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.5199591545784827 | validation: 0.5278239010439346]
	TIME [epoch: 6.48 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5115814280799701		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.5115814280799701 | validation: 0.842910033470203]
	TIME [epoch: 6.48 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6149147547835582		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.6149147547835582 | validation: 0.5071532623618417]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5549676241724417		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.5549676241724417 | validation: 0.6133887582797718]
	TIME [epoch: 6.58 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5323437332067386		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.5323437332067386 | validation: 0.7749609570659118]
	TIME [epoch: 6.47 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5972610308051715		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.5972610308051715 | validation: 0.6410785244572295]
	TIME [epoch: 6.49 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.590047311383975		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.590047311383975 | validation: 0.601134102530375]
	TIME [epoch: 6.52 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.725741554513531		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.725741554513531 | validation: 0.6234888099937387]
	TIME [epoch: 6.49 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5771719936203635		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.5771719936203635 | validation: 0.6497667119218429]
	TIME [epoch: 6.49 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5992385510018658		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.5992385510018658 | validation: 0.7757435514457619]
	TIME [epoch: 6.48 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5995862312013498		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.5995862312013498 | validation: 0.760930243773546]
	TIME [epoch: 6.49 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5565344137061695		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.5565344137061695 | validation: 0.6142178735458202]
	TIME [epoch: 6.48 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6726493966334346		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.6726493966334346 | validation: 0.5926768708262542]
	TIME [epoch: 6.48 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5648842021870717		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.5648842021870717 | validation: 0.681486405494928]
	TIME [epoch: 6.52 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6565571704374022		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.6565571704374022 | validation: 0.7227587657120637]
	TIME [epoch: 6.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540613765666613		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.5540613765666613 | validation: 0.566677683665625]
	TIME [epoch: 6.49 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5292082524965427		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.5292082524965427 | validation: 0.628367497971106]
	TIME [epoch: 6.49 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5877035103281967		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.5877035103281967 | validation: 0.6601063836966603]
	TIME [epoch: 6.48 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6376412391440194		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.6376412391440194 | validation: 1.0042074476979703]
	TIME [epoch: 6.49 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6436672787866005		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.6436672787866005 | validation: 0.5789972447840911]
	TIME [epoch: 6.47 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49870516641089846		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.49870516641089846 | validation: 0.5971605940910104]
	TIME [epoch: 6.51 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5896428072553346		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.5896428072553346 | validation: 0.4996508212435306]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_433.pth
	Model improved!!!
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5241163335899327		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.5241163335899327 | validation: 0.6797542959168028]
	TIME [epoch: 6.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5425540343714161		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.5425540343714161 | validation: 0.5248921672325241]
	TIME [epoch: 6.49 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5307037673939525		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.5307037673939525 | validation: 0.7088415207569092]
	TIME [epoch: 6.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5968333444175776		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.5968333444175776 | validation: 0.7460054794530195]
	TIME [epoch: 6.48 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6554795574124447		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.6554795574124447 | validation: 0.5318203194980218]
	TIME [epoch: 6.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.499257580448287		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.499257580448287 | validation: 0.6047698900785313]
	TIME [epoch: 6.52 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.514653477923321		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.514653477923321 | validation: 0.5664428306696049]
	TIME [epoch: 6.54 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5104469761398398		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.5104469761398398 | validation: 0.6534262705606986]
	TIME [epoch: 6.51 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155646419251683		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.5155646419251683 | validation: 0.504004631586576]
	TIME [epoch: 6.51 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47971371806882473		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.47971371806882473 | validation: 0.6010561428530719]
	TIME [epoch: 6.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5645267653777574		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.5645267653777574 | validation: 0.586948922204094]
	TIME [epoch: 6.51 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5519774664663999		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5519774664663999 | validation: 0.6071271260011738]
	TIME [epoch: 6.48 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5642357963470647		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.5642357963470647 | validation: 0.5782068514024795]
	TIME [epoch: 6.51 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5489273991594119		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.5489273991594119 | validation: 0.5615673861473004]
	TIME [epoch: 6.57 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247571588356711		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.5247571588356711 | validation: 0.4997518644380678]
	TIME [epoch: 6.51 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5655296180478856		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.5655296180478856 | validation: 0.6401016860745327]
	TIME [epoch: 6.52 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5219331955244555		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.5219331955244555 | validation: 0.6338617603453789]
	TIME [epoch: 6.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6659581630916838		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.6659581630916838 | validation: 0.6884618864419259]
	TIME [epoch: 6.51 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.615289599318692		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.615289599318692 | validation: 0.6017014366810388]
	TIME [epoch: 6.52 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49954993045590085		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.49954993045590085 | validation: 0.5320133681385026]
	TIME [epoch: 6.52 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5352477514512419		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.5352477514512419 | validation: 0.5682389138342043]
	TIME [epoch: 6.53 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5194913816096467		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.5194913816096467 | validation: 0.5189295545366502]
	TIME [epoch: 6.47 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5992311231666824		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.5992311231666824 | validation: 0.699508346834585]
	TIME [epoch: 6.49 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5210116416251496		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.5210116416251496 | validation: 0.5140950679318842]
	TIME [epoch: 6.49 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5254472106622737		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.5254472106622737 | validation: 0.601353066655798]
	TIME [epoch: 6.62 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5101875212544708		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.5101875212544708 | validation: 0.5137512183574827]
	TIME [epoch: 6.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5846715908439257		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.5846715908439257 | validation: 0.5853532332696892]
	TIME [epoch: 6.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5126074712846891		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.5126074712846891 | validation: 0.5707967104182554]
	TIME [epoch: 6.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47112898217441446		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.47112898217441446 | validation: 0.5104177466509012]
	TIME [epoch: 6.52 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47677857951530306		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.47677857951530306 | validation: 0.5772441729939537]
	TIME [epoch: 6.49 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49687024375572986		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.49687024375572986 | validation: 0.9194133677736978]
	TIME [epoch: 6.53 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5918478100531281		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.5918478100531281 | validation: 0.6030152463689326]
	TIME [epoch: 6.49 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4698126188805976		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.4698126188805976 | validation: 0.544234086625022]
	TIME [epoch: 6.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5154172868263077		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.5154172868263077 | validation: 0.6628556339727368]
	TIME [epoch: 6.52 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.61636804730503		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.61636804730503 | validation: 0.5746570444425558]
	TIME [epoch: 6.54 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46663957820610075		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.46663957820610075 | validation: 0.71527011509105]
	TIME [epoch: 6.49 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5488514018208491		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.5488514018208491 | validation: 0.6123630679021106]
	TIME [epoch: 6.53 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48090142491919574		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.48090142491919574 | validation: 0.8138726799327735]
	TIME [epoch: 6.51 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6562181282558028		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.6562181282558028 | validation: 0.639449401243772]
	TIME [epoch: 6.52 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.558718284207049		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.558718284207049 | validation: 0.5223653405530743]
	TIME [epoch: 6.51 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4621381395795643		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.4621381395795643 | validation: 0.49016345127321814]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_474.pth
	Model improved!!!
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4351703923468266		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.4351703923468266 | validation: 0.6367910624953665]
	TIME [epoch: 6.61 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5103101186909474		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.5103101186909474 | validation: 0.5746743510886145]
	TIME [epoch: 6.49 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4739370818110096		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.4739370818110096 | validation: 0.4662541348528757]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_477.pth
	Model improved!!!
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4828664151479388		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.4828664151479388 | validation: 0.4104302553717335]
	TIME [epoch: 6.64 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4414451594748836		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.4414451594748836 | validation: 0.4580508467478691]
	TIME [epoch: 6.63 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5244728905520744		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.5244728905520744 | validation: 0.5330385114095495]
	TIME [epoch: 6.48 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5194461760550323		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.5194461760550323 | validation: 0.5138265456293664]
	TIME [epoch: 6.47 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4580633652707896		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.4580633652707896 | validation: 0.6086074241455777]
	TIME [epoch: 6.49 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49423555589357643		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.49423555589357643 | validation: 0.6438686761945818]
	TIME [epoch: 6.47 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467080459824064		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5467080459824064 | validation: 0.47563926138165047]
	TIME [epoch: 6.48 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4501198310921187		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.4501198310921187 | validation: 0.5219878562082484]
	TIME [epoch: 6.47 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4142104375836767		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.4142104375836767 | validation: 0.5776705518844591]
	TIME [epoch: 6.49 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5298412997505596		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.5298412997505596 | validation: 0.4741075627634879]
	TIME [epoch: 6.51 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.559173050124736		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.559173050124736 | validation: 0.7692693054712189]
	TIME [epoch: 6.49 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6083249303136987		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.6083249303136987 | validation: 0.5422915499134165]
	TIME [epoch: 6.57 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5450799982511001		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.5450799982511001 | validation: 0.5342657981763342]
	TIME [epoch: 6.55 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5751835993109473		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.5751835993109473 | validation: 0.47625387709888883]
	TIME [epoch: 6.57 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4927990813125738		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.4927990813125738 | validation: 0.566527466866076]
	TIME [epoch: 6.54 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47681099769878177		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.47681099769878177 | validation: 0.5119496610073442]
	TIME [epoch: 6.55 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.447879932116736		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.447879932116736 | validation: 0.5651382154912241]
	TIME [epoch: 6.51 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45186285486761923		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.45186285486761923 | validation: 0.43750547402012346]
	TIME [epoch: 6.51 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293467836091381		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.5293467836091381 | validation: 0.5315094237542063]
	TIME [epoch: 6.57 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5103274317204313		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.5103274317204313 | validation: 0.44888537013905205]
	TIME [epoch: 6.51 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6334858731720352		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.6334858731720352 | validation: 0.45689201074340857]
	TIME [epoch: 6.48 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5586480048243638		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.5586480048243638 | validation: 0.8675514848792858]
	TIME [epoch: 6.55 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5386939877235165		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.5386939877235165 | validation: 0.5159309673479056]
	TIME [epoch: 6.51 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45235360131408653		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.45235360131408653 | validation: 0.5359866731285878]
	TIME [epoch: 6.49 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48936154250933467		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.48936154250933467 | validation: 0.5453281920984909]
	TIME [epoch: 6.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45537308177599456		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.45537308177599456 | validation: 0.45085595055259026]
	TIME [epoch: 6.51 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.432276359058112		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.432276359058112 | validation: 0.42405328236761164]
	TIME [epoch: 6.49 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4190674121274326		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.4190674121274326 | validation: 0.5202428861723664]
	TIME [epoch: 6.47 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4787854642152919		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.4787854642152919 | validation: 0.540713740776346]
	TIME [epoch: 6.49 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4505388989964848		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.4505388989964848 | validation: 0.9354690285284076]
	TIME [epoch: 6.47 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6448116227779249		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.6448116227779249 | validation: 0.49455057566305477]
	TIME [epoch: 6.46 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4278237016564816		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.4278237016564816 | validation: 0.5276195741063563]
	TIME [epoch: 6.48 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5253633470709621		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.5253633470709621 | validation: 0.5819860951395682]
	TIME [epoch: 6.54 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4538662515092332		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.4538662515092332 | validation: 0.4054516825169411]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_511.pth
	Model improved!!!
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4065826802363209		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.4065826802363209 | validation: 0.40603367093687487]
	TIME [epoch: 6.59 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46588042786053213		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.46588042786053213 | validation: 0.46597114686075786]
	TIME [epoch: 6.46 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4705705402876633		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.4705705402876633 | validation: 0.4531774113797697]
	TIME [epoch: 6.48 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4845506163970638		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.4845506163970638 | validation: 0.4128266918915637]
	TIME [epoch: 6.49 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38961852849395995		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.38961852849395995 | validation: 0.4649622005391474]
	TIME [epoch: 6.49 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4052969138817172		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.4052969138817172 | validation: 0.5143929130576059]
	TIME [epoch: 6.54 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.407294976147121		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.407294976147121 | validation: 0.7316039068973368]
	TIME [epoch: 6.52 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5048017520783176		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.5048017520783176 | validation: 0.4312596625583876]
	TIME [epoch: 6.51 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4107449659854244		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.4107449659854244 | validation: 0.4917513380024131]
	TIME [epoch: 6.52 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.477953610421165		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.477953610421165 | validation: 0.5264095744737269]
	TIME [epoch: 6.51 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47237749403331036		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.47237749403331036 | validation: 0.4324401683733214]
	TIME [epoch: 6.53 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46940393303037853		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.46940393303037853 | validation: 0.5056630157986886]
	TIME [epoch: 6.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3922472866945551		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.3922472866945551 | validation: 0.40074541074355324]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43258704001514103		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.43258704001514103 | validation: 0.49018985789092895]
	TIME [epoch: 6.56 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.468690500793266		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.468690500793266 | validation: 0.4489478551870438]
	TIME [epoch: 6.49 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41591158130746636		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.41591158130746636 | validation: 0.435842347348138]
	TIME [epoch: 6.48 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3764902641054373		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.3764902641054373 | validation: 0.6231710631304429]
	TIME [epoch: 6.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4562933241920293		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.4562933241920293 | validation: 0.4502061765213074]
	TIME [epoch: 6.49 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4712269114309259		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.4712269114309259 | validation: 0.4334872635777056]
	TIME [epoch: 6.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4289047973879918		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.4289047973879918 | validation: 0.46858139068792304]
	TIME [epoch: 6.51 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45198786749835107		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.45198786749835107 | validation: 0.5115046163546184]
	TIME [epoch: 6.53 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44055620528202843		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.44055620528202843 | validation: 0.5890900150027087]
	TIME [epoch: 6.58 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4551962018110365		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.4551962018110365 | validation: 0.4372275993813821]
	TIME [epoch: 6.58 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3891403624169715		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.3891403624169715 | validation: 0.4969252109970323]
	TIME [epoch: 6.51 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.418641824944843		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.418641824944843 | validation: 0.49639117840946173]
	TIME [epoch: 6.49 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41214250414186654		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.41214250414186654 | validation: 0.5885876248993883]
	TIME [epoch: 6.48 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44493193098508566		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.44493193098508566 | validation: 0.47264914591346213]
	TIME [epoch: 6.51 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.432771269186918		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.432771269186918 | validation: 0.3749026043155099]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_539.pth
	Model improved!!!
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.423143754163657		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.423143754163657 | validation: 0.43113201289607134]
	TIME [epoch: 6.56 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3895391595165422		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.3895391595165422 | validation: 0.5165073921644303]
	TIME [epoch: 6.47 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4192462918599068		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.4192462918599068 | validation: 0.41342182347597123]
	TIME [epoch: 6.48 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40350461369532153		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.40350461369532153 | validation: 0.5067352449576906]
	TIME [epoch: 6.48 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3941077299142657		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.3941077299142657 | validation: 0.6630169799074664]
	TIME [epoch: 6.48 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48919101782850166		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.48919101782850166 | validation: 0.4489242411522452]
	TIME [epoch: 6.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39763371867484865		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.39763371867484865 | validation: 0.525884058168908]
	TIME [epoch: 6.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41580980647160715		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.41580980647160715 | validation: 0.582425777496794]
	TIME [epoch: 6.49 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47644265157434895		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.47644265157434895 | validation: 0.41463102244600264]
	TIME [epoch: 6.47 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41689934976639453		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.41689934976639453 | validation: 0.418849782837738]
	TIME [epoch: 6.53 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4736229253512424		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.4736229253512424 | validation: 0.4262373887878663]
	TIME [epoch: 6.53 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45031053909987245		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.45031053909987245 | validation: 0.42986173905596614]
	TIME [epoch: 6.52 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.383276666969366		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.383276666969366 | validation: 0.5803899392036421]
	TIME [epoch: 6.53 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4058949965104655		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.4058949965104655 | validation: 0.3683387271807967]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_553.pth
	Model improved!!!
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39803897695934665		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.39803897695934665 | validation: 0.41895030425999835]
	TIME [epoch: 6.57 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44769703191117177		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.44769703191117177 | validation: 0.344753531748415]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_555.pth
	Model improved!!!
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39776791776753095		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.39776791776753095 | validation: 0.5702284119249265]
	TIME [epoch: 6.59 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45245531067233685		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.45245531067233685 | validation: 0.6057540774150669]
	TIME [epoch: 6.54 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4263099225167144		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.4263099225167144 | validation: 0.39119315475252114]
	TIME [epoch: 6.57 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39947984432013856		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.39947984432013856 | validation: 0.36596527941588286]
	TIME [epoch: 6.57 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3825254081214189		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.3825254081214189 | validation: 0.42648337166575645]
	TIME [epoch: 6.51 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39245255497110176		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.39245255497110176 | validation: 0.38361686315496735]
	TIME [epoch: 6.48 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3804211640499111		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.3804211640499111 | validation: 0.41850017649514215]
	TIME [epoch: 6.48 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458034046032423		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.5458034046032423 | validation: 0.5075902955325755]
	TIME [epoch: 6.48 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3745266646303733		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.3745266646303733 | validation: 0.3688413344395978]
	TIME [epoch: 6.48 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4405142327225937		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.4405142327225937 | validation: 0.49172312841540716]
	TIME [epoch: 6.47 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4616881657966706		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.4616881657966706 | validation: 0.3745187661379235]
	TIME [epoch: 6.49 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4050631080713996		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.4050631080713996 | validation: 0.6018340321309702]
	TIME [epoch: 6.51 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4949219040269932		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.4949219040269932 | validation: 0.4382242112454591]
	TIME [epoch: 6.48 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475198820164197		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.3475198820164197 | validation: 0.4193129066560486]
	TIME [epoch: 6.49 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673215499846235		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.3673215499846235 | validation: 0.37511028517619444]
	TIME [epoch: 6.49 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43990222339101087		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.43990222339101087 | validation: 0.6058830733183781]
	TIME [epoch: 6.49 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4355768087084842		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.4355768087084842 | validation: 0.3959087661010433]
	TIME [epoch: 6.47 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37637928202115856		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.37637928202115856 | validation: 0.3927397873826331]
	TIME [epoch: 6.49 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667349210954358		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.3667349210954358 | validation: 0.5490278519369229]
	TIME [epoch: 6.56 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4740753810961509		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.4740753810961509 | validation: 0.5112448250701606]
	TIME [epoch: 6.53 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4372122557081808		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.4372122557081808 | validation: 0.4738855218624928]
	TIME [epoch: 6.49 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41234736217937656		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.41234736217937656 | validation: 0.512980624622583]
	TIME [epoch: 6.47 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41352507314528647		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.41352507314528647 | validation: 0.4518315989959611]
	TIME [epoch: 6.48 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38534137957026315		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.38534137957026315 | validation: 0.46519714464207906]
	TIME [epoch: 6.51 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3891564863568456		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.3891564863568456 | validation: 0.41537550652300537]
	TIME [epoch: 6.47 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43301263964644576		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.43301263964644576 | validation: 0.40146941529317715]
	TIME [epoch: 6.54 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347887498418967		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.347887498418967 | validation: 0.3172328923916893]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3907979870523456		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.3907979870523456 | validation: 0.3778208241645505]
	TIME [epoch: 6.55 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3806830246656061		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.3806830246656061 | validation: 0.46195890799675243]
	TIME [epoch: 6.47 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40817375343749934		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.40817375343749934 | validation: 0.4340183180157189]
	TIME [epoch: 6.49 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46062492521576986		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.46062492521576986 | validation: 0.3495016340650699]
	TIME [epoch: 6.48 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35266659608260653		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.35266659608260653 | validation: 0.3600253472479696]
	TIME [epoch: 6.54 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143301790942705		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.3143301790942705 | validation: 0.40961137910659057]
	TIME [epoch: 6.57 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32771347657874994		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.32771347657874994 | validation: 0.3418778474829382]
	TIME [epoch: 6.54 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34268513497315933		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.34268513497315933 | validation: 0.31295192886069084]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_590.pth
	Model improved!!!
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3783633507550751		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.3783633507550751 | validation: 0.3449356307344607]
	TIME [epoch: 6.61 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4621551055702505		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.4621551055702505 | validation: 0.5890380575852006]
	TIME [epoch: 6.52 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3826217611866064		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.3826217611866064 | validation: 0.340504499218913]
	TIME [epoch: 6.49 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3313366369581073		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.3313366369581073 | validation: 0.4216982149891399]
	TIME [epoch: 6.51 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6476692757219743		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.6476692757219743 | validation: 0.3477183259064653]
	TIME [epoch: 6.53 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33936736456555217		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.33936736456555217 | validation: 0.44651205853026954]
	TIME [epoch: 6.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3769326864594112		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.3769326864594112 | validation: 0.3941530236929314]
	TIME [epoch: 6.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37419028514697494		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.37419028514697494 | validation: 0.5887348845135348]
	TIME [epoch: 6.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6430229510404565		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.6430229510404565 | validation: 0.3847967997747769]
	TIME [epoch: 6.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4012033386044651		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.4012033386044651 | validation: 0.44084921997376114]
	TIME [epoch: 6.51 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3580262646818836		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.3580262646818836 | validation: 0.3532652605148052]
	TIME [epoch: 6.52 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3864583329808787		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.3864583329808787 | validation: 0.486650312873798]
	TIME [epoch: 6.55 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38607257292278685		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.38607257292278685 | validation: 0.5021714937207488]
	TIME [epoch: 6.52 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925270798981054		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.3925270798981054 | validation: 0.4002566202387802]
	TIME [epoch: 6.51 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36887459229668085		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.36887459229668085 | validation: 0.3121984218179535]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_605.pth
	Model improved!!!
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38998298384212454		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.38998298384212454 | validation: 0.4248338143703823]
	TIME [epoch: 6.58 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3587598031545563		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.3587598031545563 | validation: 0.32375854561534495]
	TIME [epoch: 6.52 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3283714589374326		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.3283714589374326 | validation: 0.4696154552888092]
	TIME [epoch: 6.53 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468439704533181		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.3468439704533181 | validation: 0.3968600743329438]
	TIME [epoch: 6.56 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33994203871556183		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.33994203871556183 | validation: 0.42949352010881414]
	TIME [epoch: 6.54 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3523424565089333		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.3523424565089333 | validation: 0.36526512484611656]
	TIME [epoch: 6.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440764592270665		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.3440764592270665 | validation: 0.4176874261735074]
	TIME [epoch: 6.52 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38479460734084375		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.38479460734084375 | validation: 0.3675116949173193]
	TIME [epoch: 6.49 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3350391334186178		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.3350391334186178 | validation: 0.31556784365372886]
	TIME [epoch: 6.49 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35457496992662785		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.35457496992662785 | validation: 0.3832073483339649]
	TIME [epoch: 6.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3873948101801206		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.3873948101801206 | validation: 0.29259206615107575]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3930390002992172		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.3930390002992172 | validation: 0.4067901485089309]
	TIME [epoch: 6.54 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32924556114030995		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.32924556114030995 | validation: 0.2983195881107314]
	TIME [epoch: 6.49 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41651491312362754		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.41651491312362754 | validation: 0.34694500832149033]
	TIME [epoch: 6.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.332410310648053		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.332410310648053 | validation: 0.532654363341]
	TIME [epoch: 6.48 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37247363904514147		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.37247363904514147 | validation: 0.3594732060002049]
	TIME [epoch: 6.48 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3728598097165177		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.3728598097165177 | validation: 0.44139045145430844]
	TIME [epoch: 6.51 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38763396677849743		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.38763396677849743 | validation: 0.5487676289459197]
	TIME [epoch: 6.55 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3693552068242597		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.3693552068242597 | validation: 0.3852574555498189]
	TIME [epoch: 6.52 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918109571379735		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.3918109571379735 | validation: 0.31472358597988354]
	TIME [epoch: 6.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3513505611393775		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.3513505611393775 | validation: 0.38643275250042125]
	TIME [epoch: 6.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3951203285849238		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.3951203285849238 | validation: 0.36691765752094485]
	TIME [epoch: 6.52 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3494471649059033		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.3494471649059033 | validation: 0.3934222925755447]
	TIME [epoch: 6.55 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33251996293666264		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.33251996293666264 | validation: 0.3013597983536368]
	TIME [epoch: 6.51 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37375841548192135		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.37375841548192135 | validation: 0.3563259890026275]
	TIME [epoch: 6.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33998510809702426		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.33998510809702426 | validation: 0.34962115378479863]
	TIME [epoch: 6.59 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3929540234859775		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.3929540234859775 | validation: 0.4721114695534716]
	TIME [epoch: 6.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3584906858934188		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.3584906858934188 | validation: 0.3817123944167258]
	TIME [epoch: 6.57 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.399261283457649		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.399261283457649 | validation: 0.3871469243716824]
	TIME [epoch: 6.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336703476819296		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.3336703476819296 | validation: 0.3015966728992811]
	TIME [epoch: 6.55 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3693310199955376		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.3693310199955376 | validation: 0.36657531924543807]
	TIME [epoch: 6.51 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34253214439903806		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.34253214439903806 | validation: 0.335146097172972]
	TIME [epoch: 6.51 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943950361884701		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.2943950361884701 | validation: 0.4166942131987913]
	TIME [epoch: 6.51 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.404377221919501		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.404377221919501 | validation: 0.3848219212936846]
	TIME [epoch: 6.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3371783020391347		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.3371783020391347 | validation: 0.28955658858709743]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2920333468389753		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.2920333468389753 | validation: 0.2930201034490478]
	TIME [epoch: 6.57 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37499494302693426		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.37499494302693426 | validation: 0.3941284253498173]
	TIME [epoch: 6.46 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3345723655228023		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.3345723655228023 | validation: 0.4076529897217472]
	TIME [epoch: 6.48 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3273846954235063		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.3273846954235063 | validation: 0.3689833421979256]
	TIME [epoch: 6.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31783881364131594		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.31783881364131594 | validation: 0.2987714956695509]
	TIME [epoch: 6.51 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3410112463883518		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.3410112463883518 | validation: 0.3914535337120491]
	TIME [epoch: 6.49 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3565488145561245		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.3565488145561245 | validation: 0.3063084791498328]
	TIME [epoch: 6.49 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34720445646880455		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.34720445646880455 | validation: 0.44278350892417095]
	TIME [epoch: 6.49 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4777415706462848		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.4777415706462848 | validation: 0.340496501527787]
	TIME [epoch: 6.47 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35725631153314497		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.35725631153314497 | validation: 0.4617566695786717]
	TIME [epoch: 6.48 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3715265313694123		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.3715265313694123 | validation: 0.2861754104344302]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_651.pth
	Model improved!!!
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2967965928030446		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.2967965928030446 | validation: 0.3853851477398457]
	TIME [epoch: 6.58 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3191366121642667		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.3191366121642667 | validation: 0.2860226369615902]
	TIME [epoch: 6.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3554843340259376		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.3554843340259376 | validation: 0.30031085698550664]
	TIME [epoch: 6.55 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38297177373488983		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.38297177373488983 | validation: 0.28869212696315244]
	TIME [epoch: 6.49 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2737684449663062		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.2737684449663062 | validation: 0.35342171926864413]
	TIME [epoch: 6.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3311892499579249		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.3311892499579249 | validation: 0.3413304451956017]
	TIME [epoch: 6.49 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36412864698232883		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.36412864698232883 | validation: 0.32945321659291343]
	TIME [epoch: 6.52 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3001645628380473		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.3001645628380473 | validation: 0.33788870698065393]
	TIME [epoch: 6.53 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3200363005902257		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.3200363005902257 | validation: 0.2989713931219966]
	TIME [epoch: 6.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839944400040101		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.2839944400040101 | validation: 0.2957438680399889]
	TIME [epoch: 6.53 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37245155104727057		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.37245155104727057 | validation: 0.41479955030477944]
	TIME [epoch: 6.57 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343238154275562		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.3343238154275562 | validation: 0.29472794957918547]
	TIME [epoch: 6.51 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33243736884762004		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.33243736884762004 | validation: 0.36111406899100706]
	TIME [epoch: 6.49 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3165123841307017		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.3165123841307017 | validation: 0.356613121837475]
	TIME [epoch: 6.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31737044559564664		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.31737044559564664 | validation: 0.24861766886147607]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_666.pth
	Model improved!!!
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2620929628997433		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.2620929628997433 | validation: 0.2850270634180735]
	TIME [epoch: 6.58 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2571575473252434		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.2571575473252434 | validation: 0.2875510376194674]
	TIME [epoch: 6.48 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33817846796354845		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.33817846796354845 | validation: 0.30133244697348166]
	TIME [epoch: 6.48 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30927445892290445		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.30927445892290445 | validation: 0.24097554542180433]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2894814639966975		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.2894814639966975 | validation: 0.30844557421861196]
	TIME [epoch: 6.54 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34511101157264934		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.34511101157264934 | validation: 0.38472327001493456]
	TIME [epoch: 6.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3376627938361821		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.3376627938361821 | validation: 0.36910254041167717]
	TIME [epoch: 6.52 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3688325138115949		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.3688325138115949 | validation: 0.7073796203368677]
	TIME [epoch: 6.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4097579368821453		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.4097579368821453 | validation: 0.30253782428666987]
	TIME [epoch: 6.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848606939522007		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.2848606939522007 | validation: 0.25228241401466406]
	TIME [epoch: 6.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2835662587598504		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.2835662587598504 | validation: 0.4149627559069224]
	TIME [epoch: 6.51 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3020065993884145		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.3020065993884145 | validation: 0.2858380854915821]
	TIME [epoch: 6.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27656383423511544		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.27656383423511544 | validation: 0.35056066787684204]
	TIME [epoch: 6.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31341725005563176		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.31341725005563176 | validation: 0.29148838209790684]
	TIME [epoch: 6.53 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.305758081707188		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.305758081707188 | validation: 0.3196323797001429]
	TIME [epoch: 6.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27700580091195304		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.27700580091195304 | validation: 0.281329790618284]
	TIME [epoch: 6.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2835182332790812		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.2835182332790812 | validation: 0.35183847537956325]
	TIME [epoch: 6.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667002465361438		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.3667002465361438 | validation: 0.3190327781165337]
	TIME [epoch: 6.49 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.327294351120752		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.327294351120752 | validation: 0.3017226559667205]
	TIME [epoch: 6.49 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3384689045656577		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.3384689045656577 | validation: 0.46249405259114923]
	TIME [epoch: 6.51 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3464660738324077		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.3464660738324077 | validation: 0.2753955868490435]
	TIME [epoch: 6.56 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2879068578811791		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.2879068578811791 | validation: 0.6592969466617241]
	TIME [epoch: 6.49 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39434095844904254		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.39434095844904254 | validation: 0.25198513348130597]
	TIME [epoch: 6.49 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2643610966161216		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.2643610966161216 | validation: 0.3437567046278147]
	TIME [epoch: 6.49 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3266735084931244		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.3266735084931244 | validation: 0.27255002715458043]
	TIME [epoch: 6.48 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301477820303137		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.3301477820303137 | validation: 0.38803592193405684]
	TIME [epoch: 6.49 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3242703590518121		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.3242703590518121 | validation: 0.24983503258499545]
	TIME [epoch: 6.48 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26805707424028197		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.26805707424028197 | validation: 0.3208915447145519]
	TIME [epoch: 6.52 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3194173456033363		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.3194173456033363 | validation: 0.3095983588776635]
	TIME [epoch: 6.49 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3021656407209184		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.3021656407209184 | validation: 0.28429918899542683]
	TIME [epoch: 6.48 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385934527342055		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.3385934527342055 | validation: 0.4491929823934302]
	TIME [epoch: 6.47 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352694439650578		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.352694439650578 | validation: 0.3181960738961181]
	TIME [epoch: 6.48 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3010138230669331		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.3010138230669331 | validation: 0.39147381669960424]
	TIME [epoch: 6.49 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34207026845825983		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.34207026845825983 | validation: 0.3026354045402278]
	TIME [epoch: 6.49 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2911237682856054		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.2911237682856054 | validation: 0.3751455530023041]
	TIME [epoch: 6.53 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31062755351159765		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.31062755351159765 | validation: 0.2952233667328981]
	TIME [epoch: 6.49 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2971408096324741		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.2971408096324741 | validation: 0.28301501866478446]
	TIME [epoch: 6.48 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30755545603592016		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.30755545603592016 | validation: 0.3295059239534968]
	TIME [epoch: 6.48 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36045511803542857		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.36045511803542857 | validation: 0.6382312312842584]
	TIME [epoch: 6.49 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40740468988807066		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.40740468988807066 | validation: 0.3022856878673683]
	TIME [epoch: 6.49 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3012104139619268		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.3012104139619268 | validation: 0.35191489300326795]
	TIME [epoch: 6.48 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3046038643031713		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.3046038643031713 | validation: 0.3177091850754137]
	TIME [epoch: 6.53 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3223671332277703		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.3223671332277703 | validation: 0.3546599298524849]
	TIME [epoch: 6.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2902566203101801		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.2902566203101801 | validation: 0.2605613807945098]
	TIME [epoch: 6.49 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859026558449825		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.2859026558449825 | validation: 0.39114114309714565]
	TIME [epoch: 6.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2871625746999183		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.2871625746999183 | validation: 0.2857950831847705]
	TIME [epoch: 6.49 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26383299777919567		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.26383299777919567 | validation: 0.36412458731719377]
	TIME [epoch: 6.51 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039438527261034		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.3039438527261034 | validation: 0.24434024969984605]
	TIME [epoch: 6.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3196226560228238		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.3196226560228238 | validation: 0.29776853800676856]
	TIME [epoch: 6.54 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.314727434013779		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.314727434013779 | validation: 0.29129060916806077]
	TIME [epoch: 6.53 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3820520194071827		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.3820520194071827 | validation: 0.2854719543525736]
	TIME [epoch: 6.51 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31837210514288233		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.31837210514288233 | validation: 0.24097653974308905]
	TIME [epoch: 6.52 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35785704955021796		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.35785704955021796 | validation: 0.2817471579976281]
	TIME [epoch: 6.53 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3545423576850691		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.3545423576850691 | validation: 0.4732963495685212]
	TIME [epoch: 6.51 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.296357264473263		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.296357264473263 | validation: 0.30369465644625143]
	TIME [epoch: 6.51 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2646370678061755		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.2646370678061755 | validation: 0.29521746502013657]
	TIME [epoch: 6.54 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25345396797595604		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.25345396797595604 | validation: 0.32926814959454476]
	TIME [epoch: 6.54 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2992214282890342		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.2992214282890342 | validation: 0.5098647376867165]
	TIME [epoch: 6.51 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.412931912293216		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.412931912293216 | validation: 0.29746071976319344]
	TIME [epoch: 6.49 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29543071145403943		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.29543071145403943 | validation: 0.5524042304081452]
	TIME [epoch: 6.48 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4209798488385388		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.4209798488385388 | validation: 0.33344289997432014]
	TIME [epoch: 6.48 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27260032293807696		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.27260032293807696 | validation: 0.25173086127083244]
	TIME [epoch: 6.47 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29825471741272763		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.29825471741272763 | validation: 0.3911736728863478]
	TIME [epoch: 6.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29368459258889246		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.29368459258889246 | validation: 0.28967694620427714]
	TIME [epoch: 6.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32127054283889744		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.32127054283889744 | validation: 0.3150031047910166]
	TIME [epoch: 6.48 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27645487475355074		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.27645487475355074 | validation: 0.34086412018429463]
	TIME [epoch: 6.48 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26649791524424116		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.26649791524424116 | validation: 0.2456338990927478]
	TIME [epoch: 6.47 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28304344729941866		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.28304344729941866 | validation: 0.23740586215897735]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_734.pth
	Model improved!!!
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27802059473315655		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.27802059473315655 | validation: 0.3122039910262964]
	TIME [epoch: 6.52 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30064051439789		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.30064051439789 | validation: 0.3579672648188448]
	TIME [epoch: 6.49 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28281450398849256		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.28281450398849256 | validation: 0.28941553783854795]
	TIME [epoch: 6.49 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26192375400014856		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.26192375400014856 | validation: 0.31697620165337975]
	TIME [epoch: 6.48 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24584720812063138		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.24584720812063138 | validation: 0.2580178587011786]
	TIME [epoch: 6.48 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3633846306300629		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.3633846306300629 | validation: 0.43110879510440603]
	TIME [epoch: 6.48 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28772848937004586		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.28772848937004586 | validation: 0.40364492694834425]
	TIME [epoch: 6.48 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093710670557384		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.3093710670557384 | validation: 0.33734294851915037]
	TIME [epoch: 6.48 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2795131129123618		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.2795131129123618 | validation: 0.3087903810136061]
	TIME [epoch: 6.49 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26989357947433656		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.26989357947433656 | validation: 0.28248602331318057]
	TIME [epoch: 6.52 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27268859989278815		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.27268859989278815 | validation: 0.33638818561819983]
	TIME [epoch: 6.48 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2829711583494493		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.2829711583494493 | validation: 0.23921032129724953]
	TIME [epoch: 6.48 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26065525987489435		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.26065525987489435 | validation: 0.3815471427544803]
	TIME [epoch: 6.48 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28432292918196644		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.28432292918196644 | validation: 0.2571480265221292]
	TIME [epoch: 6.48 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25253813628638544		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.25253813628638544 | validation: 0.37416119630387246]
	TIME [epoch: 6.48 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30856359830927715		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.30856359830927715 | validation: 0.3291323842704661]
	TIME [epoch: 6.48 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26201439101338514		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.26201439101338514 | validation: 0.2425692342675074]
	TIME [epoch: 6.52 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24558877178202276		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.24558877178202276 | validation: 0.21859724618148924]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_752.pth
	Model improved!!!
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26070728469622245		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.26070728469622245 | validation: 0.23843055172900843]
	TIME [epoch: 6.56 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2546894790622587		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.2546894790622587 | validation: 0.36779604020520057]
	TIME [epoch: 6.47 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703225537576973		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.2703225537576973 | validation: 0.35511326715772557]
	TIME [epoch: 6.47 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36181367463159037		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.36181367463159037 | validation: 0.3216767965219021]
	TIME [epoch: 6.47 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733157894858013		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.2733157894858013 | validation: 0.30193312711417714]
	TIME [epoch: 6.47 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28405476960247655		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.28405476960247655 | validation: 0.24857973598751493]
	TIME [epoch: 6.52 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2850799443277807		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.2850799443277807 | validation: 0.30639011479648426]
	TIME [epoch: 6.48 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3125558687597769		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.3125558687597769 | validation: 0.31104973248688533]
	TIME [epoch: 6.47 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27008305309404956		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.27008305309404956 | validation: 0.2784854862982104]
	TIME [epoch: 6.47 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27282125394366785		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.27282125394366785 | validation: 0.25741968184425806]
	TIME [epoch: 6.47 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30897426028120556		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.30897426028120556 | validation: 0.2866509492231547]
	TIME [epoch: 6.47 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26822668421029205		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.26822668421029205 | validation: 0.2619756875600174]
	TIME [epoch: 6.47 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29297559755054825		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.29297559755054825 | validation: 0.31921069619939596]
	TIME [epoch: 6.51 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2696649257778441		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.2696649257778441 | validation: 0.2999113701136679]
	TIME [epoch: 6.47 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26979353403959216		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.26979353403959216 | validation: 0.3688853993480657]
	TIME [epoch: 6.48 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2980674194437316		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.2980674194437316 | validation: 0.373315861879587]
	TIME [epoch: 6.49 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351588220907084		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.351588220907084 | validation: 0.3356387762077055]
	TIME [epoch: 6.48 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768661931297345		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.2768661931297345 | validation: 0.275234445478507]
	TIME [epoch: 6.47 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2883465353460575		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.2883465353460575 | validation: 0.27500548415163145]
	TIME [epoch: 6.49 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28993407566620033		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.28993407566620033 | validation: 0.4229693389690379]
	TIME [epoch: 6.52 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4531365729217892		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.4531365729217892 | validation: 0.39062619924407044]
	TIME [epoch: 6.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2769461107158951		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.2769461107158951 | validation: 0.3014762831024836]
	TIME [epoch: 6.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2573017628649877		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.2573017628649877 | validation: 0.2991749123739967]
	TIME [epoch: 6.48 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24485353248785452		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.24485353248785452 | validation: 0.2328439037214606]
	TIME [epoch: 6.48 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25680860737350325		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.25680860737350325 | validation: 0.2577664261735143]
	TIME [epoch: 6.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24964236496401251		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.24964236496401251 | validation: 0.29926623562107574]
	TIME [epoch: 6.48 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33071640071674935		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.33071640071674935 | validation: 0.30220958734611514]
	TIME [epoch: 6.54 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26408489202850804		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.26408489202850804 | validation: 0.3520593137884703]
	TIME [epoch: 6.55 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2780757793441395		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.2780757793441395 | validation: 0.3191944932880582]
	TIME [epoch: 6.54 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925502452293805		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.2925502452293805 | validation: 0.4570755480937802]
	TIME [epoch: 6.52 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3485470053184624		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.3485470053184624 | validation: 0.21351064268184278]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_783.pth
	Model improved!!!
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2444490172945164		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.2444490172945164 | validation: 0.29234361485167454]
	TIME [epoch: 6.56 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607810530443251		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.2607810530443251 | validation: 0.3577484734686281]
	TIME [epoch: 6.49 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26919278980232564		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.26919278980232564 | validation: 0.27540036285365843]
	TIME [epoch: 6.51 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31222083509155535		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.31222083509155535 | validation: 0.29005604829331105]
	TIME [epoch: 6.53 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29527243726075847		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.29527243726075847 | validation: 0.30042165486108774]
	TIME [epoch: 6.48 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3186686419210082		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.3186686419210082 | validation: 0.24107978593854928]
	TIME [epoch: 6.49 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24854555104111742		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.24854555104111742 | validation: 0.25640951644968957]
	TIME [epoch: 6.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26758636252954104		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.26758636252954104 | validation: 0.2605736686216226]
	TIME [epoch: 6.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27163180915079743		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.27163180915079743 | validation: 0.3009930896684768]
	TIME [epoch: 6.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24441899626851268		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.24441899626851268 | validation: 0.2383559426047265]
	TIME [epoch: 6.53 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2515703654087754		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.2515703654087754 | validation: 0.24711400415639534]
	TIME [epoch: 6.54 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2374845114447396		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.2374845114447396 | validation: 0.3239291386251796]
	TIME [epoch: 6.51 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2358677161771451		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.2358677161771451 | validation: 0.27392242272955825]
	TIME [epoch: 6.52 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23443136877616394		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.23443136877616394 | validation: 0.21683814744166036]
	TIME [epoch: 6.53 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24511624492426898		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.24511624492426898 | validation: 0.2749021920162436]
	TIME [epoch: 6.52 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23332886252965993		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.23332886252965993 | validation: 0.24595920425512396]
	TIME [epoch: 6.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24217397593487852		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.24217397593487852 | validation: 0.282497103165868]
	TIME [epoch: 6.51 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25237306289717704		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.25237306289717704 | validation: 0.35453954521765]
	TIME [epoch: 6.51 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28705341879189933		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.28705341879189933 | validation: 0.2966917156550227]
	TIME [epoch: 6.48 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29068502859894685		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.29068502859894685 | validation: 0.5280911633599561]
	TIME [epoch: 6.48 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333526104380862		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.333526104380862 | validation: 0.2591252928464365]
	TIME [epoch: 6.48 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29037011230002446		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.29037011230002446 | validation: 0.3465389908865014]
	TIME [epoch: 6.49 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2511228415371248		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.2511228415371248 | validation: 0.21970369242458926]
	TIME [epoch: 6.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29427346847877206		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.29427346847877206 | validation: 0.24282218245065654]
	TIME [epoch: 6.49 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23869545467113454		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.23869545467113454 | validation: 0.27914161895149653]
	TIME [epoch: 6.52 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.268943445647176		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.268943445647176 | validation: 0.2650997761708031]
	TIME [epoch: 6.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22165650937441173		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.22165650937441173 | validation: 0.23566149767401726]
	TIME [epoch: 6.49 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23075848038314625		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.23075848038314625 | validation: 0.2169511588159596]
	TIME [epoch: 6.49 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2763836864829591		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.2763836864829591 | validation: 0.23984008330129925]
	TIME [epoch: 6.52 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071015624580542		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.3071015624580542 | validation: 0.32494298311613556]
	TIME [epoch: 6.49 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24283740284811428		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.24283740284811428 | validation: 0.34221199397060476]
	TIME [epoch: 6.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785519906269812		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.2785519906269812 | validation: 0.27785986285499337]
	TIME [epoch: 6.58 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27735713800620276		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.27735713800620276 | validation: 0.35902124920365536]
	TIME [epoch: 6.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35098284794827284		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.35098284794827284 | validation: 0.23277105154432803]
	TIME [epoch: 6.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2670335262000889		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.2670335262000889 | validation: 0.419552900383173]
	TIME [epoch: 6.49 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846097698864802		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.2846097698864802 | validation: 0.29393772450289385]
	TIME [epoch: 6.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2516734629618968		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.2516734629618968 | validation: 0.23647869481485995]
	TIME [epoch: 6.49 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.246098293489108		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.246098293489108 | validation: 0.25569928695342536]
	TIME [epoch: 6.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326085463407614		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.3326085463407614 | validation: 0.23551588841452037]
	TIME [epoch: 6.53 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24656271756972148		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.24656271756972148 | validation: 0.31180300333225275]
	TIME [epoch: 6.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2761648033184102		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.2761648033184102 | validation: 0.3388388796706135]
	TIME [epoch: 6.49 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2816787431291008		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.2816787431291008 | validation: 0.2528358535004873]
	TIME [epoch: 6.49 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071278147141746		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.3071278147141746 | validation: 0.31402542958335644]
	TIME [epoch: 6.47 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26540253200122205		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.26540253200122205 | validation: 0.2478232901276089]
	TIME [epoch: 6.52 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23866361934452676		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.23866361934452676 | validation: 0.29005177003064236]
	TIME [epoch: 6.49 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26569190580848256		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.26569190580848256 | validation: 0.24545562167928253]
	TIME [epoch: 6.52 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22705347279029056		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.22705347279029056 | validation: 0.24046518169777378]
	TIME [epoch: 6.49 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2623645991623239		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.2623645991623239 | validation: 0.2517652081221074]
	TIME [epoch: 6.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2377202961617743		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.2377202961617743 | validation: 0.20589282059088312]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_832.pth
	Model improved!!!
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24622920434968018		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.24622920434968018 | validation: 0.23844041963376747]
	TIME [epoch: 6.54 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2539190700438346		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.2539190700438346 | validation: 0.19430333057015664]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_834.pth
	Model improved!!!
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545372489069		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.2545372489069 | validation: 0.261590806287715]
	TIME [epoch: 6.59 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2660500366983809		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.2660500366983809 | validation: 0.28708553332963216]
	TIME [epoch: 6.56 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2434458546042276		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.2434458546042276 | validation: 0.2436336201021749]
	TIME [epoch: 6.49 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24407695853281963		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.24407695853281963 | validation: 0.22988529211305]
	TIME [epoch: 6.53 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24268836153166048		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.24268836153166048 | validation: 0.30804745226940133]
	TIME [epoch: 6.64 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23442723599945667		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.23442723599945667 | validation: 0.29043823861584217]
	TIME [epoch: 6.63 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2869860304934442		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.2869860304934442 | validation: 0.2576624626455747]
	TIME [epoch: 6.62 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22904249118491082		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.22904249118491082 | validation: 0.3514493658909542]
	TIME [epoch: 6.57 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30128977636561366		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.30128977636561366 | validation: 0.2591727237917595]
	TIME [epoch: 6.55 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538015825679956		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.2538015825679956 | validation: 0.22004502559162936]
	TIME [epoch: 6.51 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24671431514339803		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.24671431514339803 | validation: 0.21971825372134413]
	TIME [epoch: 6.52 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2219124259891023		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.2219124259891023 | validation: 0.24596021876105176]
	TIME [epoch: 6.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28097434099471086		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.28097434099471086 | validation: 0.28232029063479547]
	TIME [epoch: 6.51 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22005416451854415		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.22005416451854415 | validation: 0.1986414504111783]
	TIME [epoch: 6.53 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.235176790923401		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.235176790923401 | validation: 0.2659215653891049]
	TIME [epoch: 6.51 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24777151973658434		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.24777151973658434 | validation: 0.2735089750648761]
	TIME [epoch: 6.54 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27307422647982277		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.27307422647982277 | validation: 0.22583655603786645]
	TIME [epoch: 6.51 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22116033717352063		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.22116033717352063 | validation: 0.33858500191111646]
	TIME [epoch: 6.52 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2424372795153438		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.2424372795153438 | validation: 0.19793903292775977]
	TIME [epoch: 6.52 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32526708460284914		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.32526708460284914 | validation: 0.5185971772405429]
	TIME [epoch: 6.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3056558824751796		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.3056558824751796 | validation: 0.2815879502820024]
	TIME [epoch: 6.51 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22250432467490108		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.22250432467490108 | validation: 0.3287377725513628]
	TIME [epoch: 6.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747845152745617		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.2747845152745617 | validation: 0.30951054520699234]
	TIME [epoch: 6.54 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2706006888756311		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.2706006888756311 | validation: 0.21144167483401652]
	TIME [epoch: 6.52 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22497970124306657		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.22497970124306657 | validation: 0.3058455677227209]
	TIME [epoch: 6.51 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2467881998138432		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.2467881998138432 | validation: 0.20457485173356432]
	TIME [epoch: 6.52 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21449342759904794		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.21449342759904794 | validation: 0.2135131571175875]
	TIME [epoch: 6.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23603772243994242		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.23603772243994242 | validation: 0.2918352074195865]
	TIME [epoch: 6.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26297500537875224		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.26297500537875224 | validation: 0.23485762268192711]
	TIME [epoch: 6.47 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22417477334404065		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.22417477334404065 | validation: 0.20406991778136532]
	TIME [epoch: 6.53 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21817718099419947		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.21817718099419947 | validation: 0.20402674178526176]
	TIME [epoch: 6.53 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20412029530308373		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.20412029530308373 | validation: 0.2397623977767829]
	TIME [epoch: 6.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23032777199780124		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.23032777199780124 | validation: 0.19230987246789497]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_867.pth
	Model improved!!!
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538794353964872		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.2538794353964872 | validation: 0.2255670465159085]
	TIME [epoch: 6.52 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23110782499917593		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.23110782499917593 | validation: 0.19838873604849988]
	TIME [epoch: 6.47 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22062550228247138		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.22062550228247138 | validation: 0.2177086170490416]
	TIME [epoch: 6.47 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2212199434816316		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.2212199434816316 | validation: 0.2579441375573092]
	TIME [epoch: 6.51 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25276519148391785		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.25276519148391785 | validation: 0.21321464258121336]
	TIME [epoch: 6.52 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23054067158318653		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.23054067158318653 | validation: 0.2507507063022438]
	TIME [epoch: 6.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.205642885759935		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.205642885759935 | validation: 0.1777731644732983]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_874.pth
	Model improved!!!
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22335948073567233		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.22335948073567233 | validation: 0.28660571466569]
	TIME [epoch: 6.58 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2308333891711926		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.2308333891711926 | validation: 0.2150278298664139]
	TIME [epoch: 6.47 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22960478233342638		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.22960478233342638 | validation: 0.21365554332539666]
	TIME [epoch: 6.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20377145707507344		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.20377145707507344 | validation: 0.3053397085760556]
	TIME [epoch: 6.53 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2498126240854019		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.2498126240854019 | validation: 0.23913353558405567]
	TIME [epoch: 6.55 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22711819913287123		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.22711819913287123 | validation: 0.2332706454554349]
	TIME [epoch: 6.51 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23387892724911857		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.23387892724911857 | validation: 0.18735403479787585]
	TIME [epoch: 6.52 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19961389837171964		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.19961389837171964 | validation: 0.19040780535001567]
	TIME [epoch: 6.51 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20919124642887413		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.20919124642887413 | validation: 0.20887972323834939]
	TIME [epoch: 6.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2145063297289684		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.2145063297289684 | validation: 0.23308985926744905]
	TIME [epoch: 6.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2077237471168717		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.2077237471168717 | validation: 0.22021956624257036]
	TIME [epoch: 6.53 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19405251086109898		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.19405251086109898 | validation: 0.200093630367418]
	TIME [epoch: 6.54 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.219515404144		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.219515404144 | validation: 0.21452097339718065]
	TIME [epoch: 6.52 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22158956088885612		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.22158956088885612 | validation: 0.32041491573822206]
	TIME [epoch: 6.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25775385230415393		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.25775385230415393 | validation: 0.27533750730048356]
	TIME [epoch: 6.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21697435559715744		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.21697435559715744 | validation: 0.210694122230945]
	TIME [epoch: 6.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20845405416754167		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.20845405416754167 | validation: 0.2148654788272694]
	TIME [epoch: 6.51 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22307576899857245		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.22307576899857245 | validation: 0.19751142944672168]
	TIME [epoch: 6.51 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23037778090286873		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.23037778090286873 | validation: 0.23558307387335617]
	TIME [epoch: 6.54 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21108299797452837		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.21108299797452837 | validation: 0.20641825134607164]
	TIME [epoch: 6.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19341028768982937		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.19341028768982937 | validation: 0.18853766454565773]
	TIME [epoch: 6.49 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19911514750684764		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.19911514750684764 | validation: 0.19204405958870938]
	TIME [epoch: 6.51 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18569634007576769		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.18569634007576769 | validation: 0.20728979823071025]
	TIME [epoch: 6.51 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2555299118751288		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.2555299118751288 | validation: 0.21896098135105163]
	TIME [epoch: 6.51 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2043177958189079		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.2043177958189079 | validation: 0.23594818792210606]
	TIME [epoch: 6.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.211458850114849		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.211458850114849 | validation: 0.1869014907230611]
	TIME [epoch: 6.54 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19075866347175655		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.19075866347175655 | validation: 0.23118859133869826]
	TIME [epoch: 6.51 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2118666685003647		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.2118666685003647 | validation: 0.21395640496366358]
	TIME [epoch: 6.51 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2270620303853586		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.2270620303853586 | validation: 0.21577569611498804]
	TIME [epoch: 6.51 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20889143306342162		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.20889143306342162 | validation: 0.23780835009104637]
	TIME [epoch: 6.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24344266708626738		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.24344266708626738 | validation: 0.22104794617468812]
	TIME [epoch: 6.48 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22155780852035833		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.22155780852035833 | validation: 0.2799300250625298]
	TIME [epoch: 6.48 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27545460498468005		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.27545460498468005 | validation: 0.2244355284427719]
	TIME [epoch: 6.54 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2068097364959504		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.2068097364959504 | validation: 0.2753672953311393]
	TIME [epoch: 6.48 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2398016825423922		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.2398016825423922 | validation: 0.2000850849399683]
	TIME [epoch: 6.49 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20703418614763514		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.20703418614763514 | validation: 0.20058574041364885]
	TIME [epoch: 6.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21403681230112995		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.21403681230112995 | validation: 0.19038563400870012]
	TIME [epoch: 6.49 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20153583596279734		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.20153583596279734 | validation: 0.1933892080820578]
	TIME [epoch: 6.49 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22198405305612867		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.22198405305612867 | validation: 0.18204972668880345]
	TIME [epoch: 6.49 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2209441232974713		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.2209441232974713 | validation: 0.22208990841038825]
	TIME [epoch: 6.53 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19849761588398854		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.19849761588398854 | validation: 0.21359465317595733]
	TIME [epoch: 6.48 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2793016578862325		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.2793016578862325 | validation: 0.2248689260453356]
	TIME [epoch: 6.48 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20028252712583183		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.20028252712583183 | validation: 0.20495503628555306]
	TIME [epoch: 6.47 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19840588743795456		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.19840588743795456 | validation: 0.18936207896846374]
	TIME [epoch: 6.48 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22924497625798207		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.22924497625798207 | validation: 0.24440316099323325]
	TIME [epoch: 6.47 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19727287031706534		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.19727287031706534 | validation: 0.22031282664396057]
	TIME [epoch: 6.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.213932659681441		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.213932659681441 | validation: 0.19285070483646055]
	TIME [epoch: 6.51 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17529368395634373		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.17529368395634373 | validation: 0.21579967173127798]
	TIME [epoch: 6.48 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20410602907140268		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.20410602907140268 | validation: 0.2157135160109274]
	TIME [epoch: 6.46 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2028864335069359		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.2028864335069359 | validation: 0.21508405452940968]
	TIME [epoch: 6.48 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21166990140163536		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.21166990140163536 | validation: 0.2618404968562372]
	TIME [epoch: 6.47 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2207997792923184		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.2207997792923184 | validation: 0.23289349505330897]
	TIME [epoch: 6.47 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22802593716347194		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.22802593716347194 | validation: 0.21879259516561844]
	TIME [epoch: 6.47 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25189815686984074		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.25189815686984074 | validation: 0.2347674977552832]
	TIME [epoch: 6.52 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2032320631612367		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.2032320631612367 | validation: 0.20450280534950355]
	TIME [epoch: 6.48 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20132762690744332		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.20132762690744332 | validation: 0.20694778182901974]
	TIME [epoch: 6.48 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1953389483748112		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.1953389483748112 | validation: 0.18720686350134713]
	TIME [epoch: 6.47 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21623944002871737		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.21623944002871737 | validation: 0.35386129010741657]
	TIME [epoch: 6.47 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785062338677412		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.2785062338677412 | validation: 0.2164290477177407]
	TIME [epoch: 6.47 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20238107659685778		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.20238107659685778 | validation: 0.25031917990039915]
	TIME [epoch: 6.47 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21294266510335877		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.21294266510335877 | validation: 0.21544256830884542]
	TIME [epoch: 6.49 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18889228703897487		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.18889228703897487 | validation: 0.2419753241358839]
	TIME [epoch: 6.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21815903425796537		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.21815903425796537 | validation: 0.231425937080203]
	TIME [epoch: 6.47 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2066756179951058		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.2066756179951058 | validation: 0.20675307507605956]
	TIME [epoch: 6.47 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21826389785030093		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.21826389785030093 | validation: 0.17750688746950874]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_939.pth
	Model improved!!!
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24478755216683845		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.24478755216683845 | validation: 0.2676178876838883]
	TIME [epoch: 6.57 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20822567645113838		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.20822567645113838 | validation: 0.21039842584749674]
	TIME [epoch: 6.46 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2156295876492086		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.2156295876492086 | validation: 0.2021439445785193]
	TIME [epoch: 6.49 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19064472713838887		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.19064472713838887 | validation: 0.17105355964448116]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_943.pth
	Model improved!!!
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1884381796107854		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.1884381796107854 | validation: 0.22510449255464943]
	TIME [epoch: 6.58 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21480063304846758		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.21480063304846758 | validation: 0.28301355456745386]
	TIME [epoch: 6.47 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21660213711985407		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.21660213711985407 | validation: 0.17903595830332875]
	TIME [epoch: 6.48 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20452615156576506		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.20452615156576506 | validation: 0.181961088134169]
	TIME [epoch: 6.48 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1925945041687967		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.1925945041687967 | validation: 0.21441769480217582]
	TIME [epoch: 6.49 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20266943408825255		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.20266943408825255 | validation: 0.17650144363181816]
	TIME [epoch: 6.51 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18780756932579665		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.18780756932579665 | validation: 0.21798592556346927]
	TIME [epoch: 6.52 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19216828005998046		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.19216828005998046 | validation: 0.2266777376899291]
	TIME [epoch: 6.49 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21558012595180975		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.21558012595180975 | validation: 0.18547085394962173]
	TIME [epoch: 6.48 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18630091174957933		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.18630091174957933 | validation: 0.1867128253778018]
	TIME [epoch: 6.49 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18857026466404003		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.18857026466404003 | validation: 0.18470370938705594]
	TIME [epoch: 6.52 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20771693976224137		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.20771693976224137 | validation: 0.21674905612812315]
	TIME [epoch: 6.49 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1988956905391625		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.1988956905391625 | validation: 0.18179670685268223]
	TIME [epoch: 6.51 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17923535214659073		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.17923535214659073 | validation: 0.19767136431286184]
	TIME [epoch: 6.52 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19518457636094688		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.19518457636094688 | validation: 0.1976488682229652]
	TIME [epoch: 6.52 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19416748668563297		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.19416748668563297 | validation: 0.22532602300663734]
	TIME [epoch: 6.51 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23198092300566897		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.23198092300566897 | validation: 0.2353551338060221]
	TIME [epoch: 6.51 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2054529492929584		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.2054529492929584 | validation: 0.20457233329222255]
	TIME [epoch: 6.53 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23134486236840146		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.23134486236840146 | validation: 0.28345764389198136]
	TIME [epoch: 6.57 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2245990052757371		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.2245990052757371 | validation: 0.3152329833361719]
	TIME [epoch: 6.59 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24456842059991266		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.24456842059991266 | validation: 0.3024389770086293]
	TIME [epoch: 6.58 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24785636324107654		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.24785636324107654 | validation: 0.17238331313161553]
	TIME [epoch: 6.51 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18597595638112463		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.18597595638112463 | validation: 0.20756944768421767]
	TIME [epoch: 6.48 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18781104416838135		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.18781104416838135 | validation: 0.22851959198201782]
	TIME [epoch: 6.49 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1919331542633439		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.1919331542633439 | validation: 0.17440276474849958]
	TIME [epoch: 6.51 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1895142384611636		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.1895142384611636 | validation: 0.19569588785127523]
	TIME [epoch: 6.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19232122574300944		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.19232122574300944 | validation: 0.18186443211179845]
	TIME [epoch: 6.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18654128217023136		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.18654128217023136 | validation: 0.1673199650923913]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_971.pth
	Model improved!!!
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19564624176171488		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.19564624176171488 | validation: 0.22525869663923556]
	TIME [epoch: 6.56 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18995936643207606		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.18995936643207606 | validation: 0.18245386878071995]
	TIME [epoch: 6.48 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18218084729753242		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.18218084729753242 | validation: 0.20197096488172342]
	TIME [epoch: 6.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19994155386116885		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.19994155386116885 | validation: 0.27575630801449924]
	TIME [epoch: 6.49 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23758500337432553		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.23758500337432553 | validation: 0.16836904342068895]
	TIME [epoch: 6.49 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21077206890475617		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.21077206890475617 | validation: 0.24421295874685836]
	TIME [epoch: 6.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23962944960415655		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.23962944960415655 | validation: 0.20851938303832662]
	TIME [epoch: 6.54 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22475887195108046		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.22475887195108046 | validation: 0.17565904957355627]
	TIME [epoch: 6.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2061432969358477		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.2061432969358477 | validation: 0.19219664382383692]
	TIME [epoch: 6.51 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1995751352021268		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.1995751352021268 | validation: 0.2177226221660805]
	TIME [epoch: 6.52 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2065531853185248		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.2065531853185248 | validation: 0.18879546819020931]
	TIME [epoch: 6.51 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19519114576591193		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.19519114576591193 | validation: 0.22912986918968983]
	TIME [epoch: 6.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2050570255972955		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.2050570255972955 | validation: 0.17334161851364735]
	TIME [epoch: 6.49 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896610787860292		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.1896610787860292 | validation: 0.17204792526463414]
	TIME [epoch: 6.54 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2102956650799642		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.2102956650799642 | validation: 0.20727653191469317]
	TIME [epoch: 6.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18502831166465408		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.18502831166465408 | validation: 0.17681979635414188]
	TIME [epoch: 6.52 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18108704033080328		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.18108704033080328 | validation: 0.20549974190292275]
	TIME [epoch: 6.51 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20312470390093595		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.20312470390093595 | validation: 0.2385639569475103]
	TIME [epoch: 6.49 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21062296565222902		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.21062296565222902 | validation: 0.20776692379659537]
	TIME [epoch: 6.49 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20644486649429775		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.20644486649429775 | validation: 0.23258934122406338]
	TIME [epoch: 6.48 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21326095764411424		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.21326095764411424 | validation: 0.21199573803344712]
	TIME [epoch: 6.53 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1744082003848567		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.1744082003848567 | validation: 0.18055377813840376]
	TIME [epoch: 6.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2011363961825282		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.2011363961825282 | validation: 0.19672479353120664]
	TIME [epoch: 6.52 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17582180443301895		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.17582180443301895 | validation: 0.18794333716525205]
	TIME [epoch: 6.51 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18557077492738622		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.18557077492738622 | validation: 0.20268533431019342]
	TIME [epoch: 6.51 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22493440118625224		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.22493440118625224 | validation: 0.1837648062818753]
	TIME [epoch: 6.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23895156710981244		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.23895156710981244 | validation: 0.3058094315728036]
	TIME [epoch: 6.51 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24206332064508648		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.24206332064508648 | validation: 0.20986640457143121]
	TIME [epoch: 6.53 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18980519055116316		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.18980519055116316 | validation: 0.2080719599620596]
	TIME [epoch: 6.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17775230562785996		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.17775230562785996 | validation: 0.21224927766451657]
	TIME [epoch: 6.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18626371833215202		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.18626371833215202 | validation: 0.22603402793444935]
	TIME [epoch: 6.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17917183747520862		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.17917183747520862 | validation: 0.17251392305361854]
	TIME [epoch: 6.48 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17996561150668577		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.17996561150668577 | validation: 0.2897422622390669]
	TIME [epoch: 6.48 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22867636733281035		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.22867636733281035 | validation: 0.19634133391001368]
	TIME [epoch: 6.51 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19170853033621005		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.19170853033621005 | validation: 0.22422283236631074]
	TIME [epoch: 6.54 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21795271057579635		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.21795271057579635 | validation: 0.17158508393877106]
	TIME [epoch: 6.51 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1914644697861304		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.1914644697861304 | validation: 0.18860671588911776]
	TIME [epoch: 6.51 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18886303092161116		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.18886303092161116 | validation: 0.1605283181361147]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1009.pth
	Model improved!!!
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17632623414797793		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.17632623414797793 | validation: 0.18416461470460319]
	TIME [epoch: 6.59 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1764658909842447		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.1764658909842447 | validation: 0.1886706134692995]
	TIME [epoch: 6.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18049150590976598		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.18049150590976598 | validation: 0.2244294365907731]
	TIME [epoch: 6.49 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18196808897466565		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.18196808897466565 | validation: 0.19704392642538493]
	TIME [epoch: 6.54 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18521591611732205		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.18521591611732205 | validation: 0.18400632068892533]
	TIME [epoch: 6.56 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17919736549042642		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.17919736549042642 | validation: 0.20705783955457094]
	TIME [epoch: 6.58 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18784010409981405		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.18784010409981405 | validation: 0.1845022598834536]
	TIME [epoch: 6.55 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17577192225237487		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.17577192225237487 | validation: 0.2067587861262347]
	TIME [epoch: 6.49 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18484660453532697		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.18484660453532697 | validation: 0.18461845019088816]
	TIME [epoch: 6.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19433867235642138		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.19433867235642138 | validation: 0.19106916809366375]
	TIME [epoch: 6.51 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21724018488041563		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.21724018488041563 | validation: 0.2829172229480099]
	TIME [epoch: 6.57 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20286138658055614		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.20286138658055614 | validation: 0.23503298486546612]
	TIME [epoch: 6.52 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20240739640607863		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.20240739640607863 | validation: 0.20742246830634742]
	TIME [epoch: 6.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1811026627708992		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.1811026627708992 | validation: 0.19504824761863895]
	TIME [epoch: 6.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718497160960476		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.1718497160960476 | validation: 0.1771845358310356]
	TIME [epoch: 6.51 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20761383048596987		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.20761383048596987 | validation: 0.2205714614740898]
	TIME [epoch: 6.49 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18287488317093367		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.18287488317093367 | validation: 0.20485752472752716]
	TIME [epoch: 6.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18771292337586873		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.18771292337586873 | validation: 0.19080354390760348]
	TIME [epoch: 6.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19799804554441613		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.19799804554441613 | validation: 0.2114401745107922]
	TIME [epoch: 6.51 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18992134688694512		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.18992134688694512 | validation: 0.21237697606343875]
	TIME [epoch: 6.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2073063399483271		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.2073063399483271 | validation: 0.18127493425034782]
	TIME [epoch: 6.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17779732842551255		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.17779732842551255 | validation: 0.1794782401863897]
	TIME [epoch: 6.52 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1824187376123665		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.1824187376123665 | validation: 0.17942484853683704]
	TIME [epoch: 6.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19268097173166537		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.19268097173166537 | validation: 0.16688647873917967]
	TIME [epoch: 6.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1980140766742841		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.1980140766742841 | validation: 0.23259705647249632]
	TIME [epoch: 6.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19244422333317734		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.19244422333317734 | validation: 0.2073126795632875]
	TIME [epoch: 6.54 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19260202842924873		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.19260202842924873 | validation: 0.24321304873320398]
	TIME [epoch: 6.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20505062491517453		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.20505062491517453 | validation: 0.16874436709870166]
	TIME [epoch: 6.53 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18264450977582247		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.18264450977582247 | validation: 0.184087874526023]
	TIME [epoch: 6.48 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18703649220840732		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.18703649220840732 | validation: 0.17389442818461193]
	TIME [epoch: 6.49 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726063664250369		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.1726063664250369 | validation: 0.178549637810521]
	TIME [epoch: 6.48 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19173519356586696		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.19173519356586696 | validation: 0.1740486398399751]
	TIME [epoch: 6.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2142763443531443		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.2142763443531443 | validation: 0.22857521993064872]
	TIME [epoch: 6.53 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20375325115419404		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.20375325115419404 | validation: 0.16684020106351302]
	TIME [epoch: 6.51 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18558041238998493		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.18558041238998493 | validation: 0.17258907196035048]
	TIME [epoch: 6.49 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17641807949014218		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.17641807949014218 | validation: 0.2146139855566983]
	TIME [epoch: 6.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19977394152581296		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.19977394152581296 | validation: 0.17504055629864815]
	TIME [epoch: 6.49 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1729730279116218		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.1729730279116218 | validation: 0.1947584524565739]
	TIME [epoch: 6.48 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18104804170376324		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.18104804170376324 | validation: 0.1663830139961153]
	TIME [epoch: 6.49 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16986408791298754		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.16986408791298754 | validation: 0.1840752236014777]
	TIME [epoch: 6.56 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18444347958123763		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.18444347958123763 | validation: 0.17711218404129525]
	TIME [epoch: 6.51 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1773085626640209		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.1773085626640209 | validation: 0.21229489724618553]
	TIME [epoch: 6.49 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18339872408162575		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.18339872408162575 | validation: 0.17844499170665273]
	TIME [epoch: 6.52 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18001281050323695		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.18001281050323695 | validation: 0.1970325009296847]
	TIME [epoch: 6.49 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1696281244078513		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.1696281244078513 | validation: 0.16852695735311646]
	TIME [epoch: 6.51 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18271548977987379		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.18271548977987379 | validation: 0.20284800373207287]
	TIME [epoch: 6.51 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838458566778424		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.1838458566778424 | validation: 0.1874852783266099]
	TIME [epoch: 6.55 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18036193713468612		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.18036193713468612 | validation: 0.1953776889134948]
	TIME [epoch: 6.51 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17562014938010972		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.17562014938010972 | validation: 0.16524273214575588]
	TIME [epoch: 6.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1822010944274572		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.1822010944274572 | validation: 0.19615477944524592]
	TIME [epoch: 6.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18566109342611975		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.18566109342611975 | validation: 0.1988721419366636]
	TIME [epoch: 6.49 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18706546838612567		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.18706546838612567 | validation: 0.18013914970093395]
	TIME [epoch: 6.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18213055765228475		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.18213055765228475 | validation: 0.22533722990461386]
	TIME [epoch: 6.51 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1891925887453304		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.1891925887453304 | validation: 0.19487263452255682]
	TIME [epoch: 6.53 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17563575182449692		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.17563575182449692 | validation: 0.21166485601372556]
	TIME [epoch: 6.52 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1945795370840448		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.1945795370840448 | validation: 0.24241153881496613]
	TIME [epoch: 6.53 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19426825872858788		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.19426825872858788 | validation: 0.1666347573036712]
	TIME [epoch: 6.49 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19295339224623229		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.19295339224623229 | validation: 0.17864067577489426]
	TIME [epoch: 6.51 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19290145113550386		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.19290145113550386 | validation: 0.17693807048395063]
	TIME [epoch: 6.49 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19398270542870827		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.19398270542870827 | validation: 0.19601825600796566]
	TIME [epoch: 6.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733853369804421		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.1733853369804421 | validation: 0.18954746150984186]
	TIME [epoch: 6.55 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.185364717895796		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.185364717895796 | validation: 0.16142624962752566]
	TIME [epoch: 6.51 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18428913915417866		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.18428913915417866 | validation: 0.1870714257416662]
	TIME [epoch: 6.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16867111318562122		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.16867111318562122 | validation: 0.17324233902529015]
	TIME [epoch: 6.49 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17976103419938994		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.17976103419938994 | validation: 0.18241514031421863]
	TIME [epoch: 6.51 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17491613583176685		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.17491613583176685 | validation: 0.1984401345190412]
	TIME [epoch: 6.51 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19781543344605146		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.19781543344605146 | validation: 0.19384198434051186]
	TIME [epoch: 6.49 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1753267563028082		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.1753267563028082 | validation: 0.2056102017044866]
	TIME [epoch: 6.59 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17846125844013833		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.17846125844013833 | validation: 0.17228194566123306]
	TIME [epoch: 6.53 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17840737164766426		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.17840737164766426 | validation: 0.1672152266177187]
	TIME [epoch: 6.49 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17286597349051036		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.17286597349051036 | validation: 0.18111157822388235]
	TIME [epoch: 6.48 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16819047790454097		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.16819047790454097 | validation: 0.19249774672280853]
	TIME [epoch: 6.48 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16786063067073595		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.16786063067073595 | validation: 0.16263663105360338]
	TIME [epoch: 6.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16689898369656353		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.16689898369656353 | validation: 0.16603828283995486]
	TIME [epoch: 6.49 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16717896488732298		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.16717896488732298 | validation: 0.1946696039386135]
	TIME [epoch: 6.49 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1680692142874556		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.1680692142874556 | validation: 0.19373846957820007]
	TIME [epoch: 6.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17573243420819645		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.17573243420819645 | validation: 0.18609860448772478]
	TIME [epoch: 6.48 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16282849498571994		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.16282849498571994 | validation: 0.17216871272430773]
	TIME [epoch: 6.49 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17289743276845942		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.17289743276845942 | validation: 0.16815047196511576]
	TIME [epoch: 6.48 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1786747169309961		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.1786747169309961 | validation: 0.1981669252945172]
	TIME [epoch: 6.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21819614718826366		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.21819614718826366 | validation: 0.22208397674368485]
	TIME [epoch: 6.48 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17682544527074548		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.17682544527074548 | validation: 0.18681236928398093]
	TIME [epoch: 6.52 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1938288312919491		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.1938288312919491 | validation: 0.16843569122303023]
	TIME [epoch: 6.51 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16734421855274173		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.16734421855274173 | validation: 0.1859790715102289]
	TIME [epoch: 6.52 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16265854720890355		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.16265854720890355 | validation: 0.17885048163665915]
	TIME [epoch: 6.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18644954858811938		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.18644954858811938 | validation: 0.18922223721570933]
	TIME [epoch: 6.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17144360035920486		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.17144360035920486 | validation: 0.18335079318412384]
	TIME [epoch: 6.51 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17339804969160091		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.17339804969160091 | validation: 0.1696796380910676]
	TIME [epoch: 6.49 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621153250650605		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.1621153250650605 | validation: 0.16434796408575927]
	TIME [epoch: 6.52 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16732361150626557		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.16732361150626557 | validation: 0.1635730047675849]
	TIME [epoch: 6.52 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18455883569463166		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.18455883569463166 | validation: 0.18494356200698683]
	TIME [epoch: 6.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17626785038285894		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.17626785038285894 | validation: 0.19317021186421854]
	TIME [epoch: 6.51 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1725318479958306		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.1725318479958306 | validation: 0.1752386275618723]
	TIME [epoch: 6.48 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17431434935264903		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.17431434935264903 | validation: 0.19211992949729442]
	TIME [epoch: 6.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18625866249328624		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.18625866249328624 | validation: 0.2099733790827342]
	TIME [epoch: 6.48 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18994776424161713		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.18994776424161713 | validation: 0.1781441538805458]
	TIME [epoch: 6.48 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638546358754195		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.1638546358754195 | validation: 0.19193428421290265]
	TIME [epoch: 6.51 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1735658928275373		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.1735658928275373 | validation: 0.1951255748294247]
	TIME [epoch: 6.48 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18964221415302412		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.18964221415302412 | validation: 0.20555935209142726]
	TIME [epoch: 6.47 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17642750060904708		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.17642750060904708 | validation: 0.18065179927880393]
	TIME [epoch: 6.48 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17111444283573138		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.17111444283573138 | validation: 0.1757793404265948]
	TIME [epoch: 6.49 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18875556934732363		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.18875556934732363 | validation: 0.19990895903448636]
	TIME [epoch: 6.47 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17140083250671798		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.17140083250671798 | validation: 0.19251046004940223]
	TIME [epoch: 6.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1851666156661047		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.1851666156661047 | validation: 0.1951133337883634]
	TIME [epoch: 6.53 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1891872534371732		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.1891872534371732 | validation: 0.19247198934305254]
	TIME [epoch: 6.48 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1876138270687793		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.1876138270687793 | validation: 0.17106450845992732]
	TIME [epoch: 6.49 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1915964942874252		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.1915964942874252 | validation: 0.2160373535293622]
	TIME [epoch: 6.47 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20375140369072692		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.20375140369072692 | validation: 0.20262639946737962]
	TIME [epoch: 6.47 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17666182494471272		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.17666182494471272 | validation: 0.16825385889259864]
	TIME [epoch: 6.49 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585750591600174		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.1585750591600174 | validation: 0.19231732534971518]
	TIME [epoch: 6.47 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17409709466042272		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.17409709466042272 | validation: 0.17356897001951527]
	TIME [epoch: 6.52 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17292707342742		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.17292707342742 | validation: 0.18568742248500666]
	TIME [epoch: 6.47 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17858954801630753		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.17858954801630753 | validation: 0.17070794111992463]
	TIME [epoch: 6.47 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1642420168025386		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.1642420168025386 | validation: 0.19593080718439232]
	TIME [epoch: 6.49 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16942406285099867		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.16942406285099867 | validation: 0.18200087600797887]
	TIME [epoch: 6.47 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16105668283960922		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.16105668283960922 | validation: 0.17752609617554663]
	TIME [epoch: 6.48 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17698754919786341		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.17698754919786341 | validation: 0.16262740621720448]
	TIME [epoch: 6.47 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654802634972338		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.1654802634972338 | validation: 0.1844004198122044]
	TIME [epoch: 6.51 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165591751304901		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.165591751304901 | validation: 0.16828648784297887]
	TIME [epoch: 6.49 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1903079112306081		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.1903079112306081 | validation: 0.17751109801729825]
	TIME [epoch: 6.48 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16345243412068283		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.16345243412068283 | validation: 0.1870695069330482]
	TIME [epoch: 6.48 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16184602924706587		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.16184602924706587 | validation: 0.16089139555848728]
	TIME [epoch: 6.47 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1780072555495754		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.1780072555495754 | validation: 0.19670316656502482]
	TIME [epoch: 6.47 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16428291489444738		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.16428291489444738 | validation: 0.16254650257630174]
	TIME [epoch: 6.49 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16905368134618196		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.16905368134618196 | validation: 0.1821361760010531]
	TIME [epoch: 6.52 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17356142354335755		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.17356142354335755 | validation: 0.207994497166601]
	TIME [epoch: 6.48 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1831712341191131		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.1831712341191131 | validation: 0.16965020136466222]
	TIME [epoch: 6.47 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1640664245924448		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.1640664245924448 | validation: 0.1572285977373888]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1137.pth
	Model improved!!!
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16097855601881725		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.16097855601881725 | validation: 0.16772352264481302]
	TIME [epoch: 6.56 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1764617218699604		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.1764617218699604 | validation: 0.1689327430838051]
	TIME [epoch: 6.47 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17234599595867772		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.17234599595867772 | validation: 0.17247698420156865]
	TIME [epoch: 6.47 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16818500127471658		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.16818500127471658 | validation: 0.20227058990248753]
	TIME [epoch: 6.54 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19141430542719245		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.19141430542719245 | validation: 0.1776611901102168]
	TIME [epoch: 6.49 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665407126606629		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.1665407126606629 | validation: 0.1872451885300921]
	TIME [epoch: 6.49 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18309598754096487		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.18309598754096487 | validation: 0.17727412166275905]
	TIME [epoch: 6.49 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18378210917593718		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.18378210917593718 | validation: 0.2006138073243109]
	TIME [epoch: 6.49 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17272845246960758		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.17272845246960758 | validation: 0.1712848588500965]
	TIME [epoch: 6.49 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1840538318215672		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.1840538318215672 | validation: 0.17956970995245022]
	TIME [epoch: 6.49 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18574106087679423		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.18574106087679423 | validation: 0.17140633724376528]
	TIME [epoch: 6.53 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16934369126406243		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.16934369126406243 | validation: 0.16065322645808286]
	TIME [epoch: 6.53 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621810562601602		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.1621810562601602 | validation: 0.1699498492674362]
	TIME [epoch: 6.48 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16401303964233843		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.16401303964233843 | validation: 0.15510854829260354]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1151.pth
	Model improved!!!
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17363956025115773		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.17363956025115773 | validation: 0.15328444884876957]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1152.pth
	Model improved!!!
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15894411331978903		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.15894411331978903 | validation: 0.1866855019775469]
	TIME [epoch: 6.56 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17768231289908426		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.17768231289908426 | validation: 0.16302121556329183]
	TIME [epoch: 6.48 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1657533957926981		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.1657533957926981 | validation: 0.17566980223441087]
	TIME [epoch: 6.52 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740598464252633		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.1740598464252633 | validation: 0.17552427439168253]
	TIME [epoch: 6.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18001490215081165		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.18001490215081165 | validation: 0.16051368300503516]
	TIME [epoch: 6.49 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17805002549019258		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.17805002549019258 | validation: 0.179661053994123]
	TIME [epoch: 6.49 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1714639266906228		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.1714639266906228 | validation: 0.17820738938243294]
	TIME [epoch: 6.48 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16700891543659374		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.16700891543659374 | validation: 0.1891142059427922]
	TIME [epoch: 6.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17192817839453275		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.17192817839453275 | validation: 0.2066687323741781]
	TIME [epoch: 6.49 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17352068138193896		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.17352068138193896 | validation: 0.17068118069656968]
	TIME [epoch: 6.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17082697936774038		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.17082697936774038 | validation: 0.18258933340262573]
	TIME [epoch: 6.52 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19452994761068051		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.19452994761068051 | validation: 0.17747651303106005]
	TIME [epoch: 6.48 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1818373982412625		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.1818373982412625 | validation: 0.18219115890547627]
	TIME [epoch: 6.48 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17015422046150547		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.17015422046150547 | validation: 0.17622217572677307]
	TIME [epoch: 6.49 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17258382024113644		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.17258382024113644 | validation: 0.16805334909376726]
	TIME [epoch: 6.48 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15974124320237454		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.15974124320237454 | validation: 0.1717363151632919]
	TIME [epoch: 6.48 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16873904663283648		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.16873904663283648 | validation: 0.15660538846414823]
	TIME [epoch: 6.51 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15908633909394224		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.15908633909394224 | validation: 0.18743214935808072]
	TIME [epoch: 6.52 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1757614750200067		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.1757614750200067 | validation: 0.15444923277723982]
	TIME [epoch: 6.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15863867643995186		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.15863867643995186 | validation: 0.1527526685587317]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1172.pth
	Model improved!!!
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1674231870519836		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.1674231870519836 | validation: 0.16015127735048437]
	TIME [epoch: 6.54 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16592301488938715		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.16592301488938715 | validation: 0.16409356554741542]
	TIME [epoch: 6.49 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16299545958205608		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.16299545958205608 | validation: 0.16437129879124635]
	TIME [epoch: 6.49 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16093565130003015		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.16093565130003015 | validation: 0.17328682437189485]
	TIME [epoch: 6.51 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17176324238308813		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.17176324238308813 | validation: 0.20374922607720244]
	TIME [epoch: 6.52 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1775029629558894		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.1775029629558894 | validation: 0.16177822763224506]
	TIME [epoch: 6.49 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16478221385027397		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.16478221385027397 | validation: 0.1619021006717578]
	TIME [epoch: 6.51 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620371770193115		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.1620371770193115 | validation: 0.15965212467107243]
	TIME [epoch: 6.51 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1551378047933475		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.1551378047933475 | validation: 0.16875814692116464]
	TIME [epoch: 6.52 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16965737660999478		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.16965737660999478 | validation: 0.1594778674906755]
	TIME [epoch: 6.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16018449943691793		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.16018449943691793 | validation: 0.15337330312086347]
	TIME [epoch: 6.52 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1599185014085194		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.1599185014085194 | validation: 0.15058371579424534]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1184.pth
	Model improved!!!
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16878310266673088		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.16878310266673088 | validation: 0.17938335460131227]
	TIME [epoch: 6.55 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17473456237984494		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.17473456237984494 | validation: 0.17088718620314886]
	TIME [epoch: 6.49 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18440092186684087		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.18440092186684087 | validation: 0.19770328160704254]
	TIME [epoch: 6.49 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17434862762952674		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.17434862762952674 | validation: 0.16159020463777946]
	TIME [epoch: 6.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15915688109219894		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.15915688109219894 | validation: 0.16040740314337482]
	TIME [epoch: 6.54 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16355434242589167		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.16355434242589167 | validation: 0.15971847897599198]
	TIME [epoch: 6.53 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643872246740943		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.1643872246740943 | validation: 0.15296379179760655]
	TIME [epoch: 6.53 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15667766006900846		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.15667766006900846 | validation: 0.15524243993462383]
	TIME [epoch: 6.51 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15544043799635027		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.15544043799635027 | validation: 0.16221307503234975]
	TIME [epoch: 6.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15801027125357198		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.15801027125357198 | validation: 0.17120685067098954]
	TIME [epoch: 6.49 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15499955803230464		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.15499955803230464 | validation: 0.16437779933058264]
	TIME [epoch: 6.49 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153121496844621		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.153121496844621 | validation: 0.16084817144259242]
	TIME [epoch: 6.49 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15611533819265885		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.15611533819265885 | validation: 0.16457023240052718]
	TIME [epoch: 6.51 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15779735254446497		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.15779735254446497 | validation: 0.16904373563673325]
	TIME [epoch: 6.54 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16044803859654233		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.16044803859654233 | validation: 0.16538964390490743]
	TIME [epoch: 6.48 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16316811193703545		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.16316811193703545 | validation: 0.16212834512253818]
	TIME [epoch: 6.48 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.166549427180707		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.166549427180707 | validation: 0.17082414107179908]
	TIME [epoch: 6.52 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17681978765988438		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.17681978765988438 | validation: 0.19438804533969048]
	TIME [epoch: 6.52 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1730421249713971		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.1730421249713971 | validation: 0.1763947977642363]
	TIME [epoch: 6.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16770981908134944		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.16770981908134944 | validation: 0.16595925918930113]
	TIME [epoch: 6.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16528596928591316		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.16528596928591316 | validation: 0.1604988778173227]
	TIME [epoch: 6.55 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16366742180519692		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.16366742180519692 | validation: 0.1786240742722715]
	TIME [epoch: 6.49 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708299326092457		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.1708299326092457 | validation: 0.18031099328996697]
	TIME [epoch: 6.51 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16125708422383875		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.16125708422383875 | validation: 0.20326944365275026]
	TIME [epoch: 6.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19588180096685762		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.19588180096685762 | validation: 0.20426546762482276]
	TIME [epoch: 6.49 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19107757782364293		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.19107757782364293 | validation: 0.19593308561175268]
	TIME [epoch: 6.48 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18564905003904175		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.18564905003904175 | validation: 0.15424287370816703]
	TIME [epoch: 6.49 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1644487018765164		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.1644487018765164 | validation: 0.18239466526505305]
	TIME [epoch: 6.53 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17344053225291473		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.17344053225291473 | validation: 0.15809561229926203]
	TIME [epoch: 6.49 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665229202382112		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.1665229202382112 | validation: 0.1584204801292892]
	TIME [epoch: 6.49 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15833704096395368		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.15833704096395368 | validation: 0.1862212900962912]
	TIME [epoch: 6.51 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17123620149246593		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.17123620149246593 | validation: 0.1567643915854452]
	TIME [epoch: 6.49 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1636401898291861		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.1636401898291861 | validation: 0.16912954954658435]
	TIME [epoch: 6.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15964483743782035		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.15964483743782035 | validation: 0.21866764463693933]
	TIME [epoch: 6.47 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19363805383735963		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.19363805383735963 | validation: 0.19852006064954508]
	TIME [epoch: 6.55 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17375705688431178		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.17375705688431178 | validation: 0.1736631588699127]
	TIME [epoch: 6.55 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15973433465623044		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.15973433465623044 | validation: 0.16455696826555957]
	TIME [epoch: 6.53 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15635758978691333		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.15635758978691333 | validation: 0.1846995521047522]
	TIME [epoch: 6.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1872248691602691		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.1872248691602691 | validation: 0.20529767824538936]
	TIME [epoch: 6.48 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16937296890634918		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.16937296890634918 | validation: 0.16432544224634582]
	TIME [epoch: 6.48 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15709104345275046		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.15709104345275046 | validation: 0.15782275725631034]
	TIME [epoch: 6.51 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15657602292776754		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.15657602292776754 | validation: 0.15857781488435285]
	TIME [epoch: 6.52 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16057636903988998		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.16057636903988998 | validation: 0.15929980252918438]
	TIME [epoch: 6.48 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15911853397624304		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.15911853397624304 | validation: 0.16281820365321892]
	TIME [epoch: 6.48 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1533577908106016		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.1533577908106016 | validation: 0.15663398814469992]
	TIME [epoch: 6.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15739723209626633		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.15739723209626633 | validation: 0.14623106935662544]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1230.pth
	Model improved!!!
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15573478811578878		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.15573478811578878 | validation: 0.15670511342418084]
	TIME [epoch: 6.54 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15308529117561737		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.15308529117561737 | validation: 0.15343512959894307]
	TIME [epoch: 6.48 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15389727672009215		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.15389727672009215 | validation: 0.1555984366688717]
	TIME [epoch: 6.84 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16226761996347255		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.16226761996347255 | validation: 0.1817269070530667]
	TIME [epoch: 6.55 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1697267323578119		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.1697267323578119 | validation: 0.16942499750019419]
	TIME [epoch: 6.56 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15605195081493414		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.15605195081493414 | validation: 0.1765113082895698]
	TIME [epoch: 6.52 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15769204567274153		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.15769204567274153 | validation: 0.15661914076381242]
	TIME [epoch: 6.52 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18226165079299902		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.18226165079299902 | validation: 0.19140214177708334]
	TIME [epoch: 6.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17668487316712916		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.17668487316712916 | validation: 0.16222829851651135]
	TIME [epoch: 6.48 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15401749695125586		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.15401749695125586 | validation: 0.17160071755986236]
	TIME [epoch: 6.53 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1606901472861696		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.1606901472861696 | validation: 0.1758917767970322]
	TIME [epoch: 6.49 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15961540619859596		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.15961540619859596 | validation: 0.1716614663801965]
	TIME [epoch: 6.48 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16374289364683292		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.16374289364683292 | validation: 0.16417518063376257]
	TIME [epoch: 6.49 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15542826615950192		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.15542826615950192 | validation: 0.16676667804311862]
	TIME [epoch: 6.48 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17020674521745202		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.17020674521745202 | validation: 0.15961817022566002]
	TIME [epoch: 6.48 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15730360949634592		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.15730360949634592 | validation: 0.16729058663032106]
	TIME [epoch: 6.49 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.171589756898757		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.171589756898757 | validation: 0.17423825777335908]
	TIME [epoch: 6.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1668457601328191		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.1668457601328191 | validation: 0.2005337418304492]
	TIME [epoch: 6.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17684865109141015		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.17684865109141015 | validation: 0.16393467043416624]
	TIME [epoch: 6.48 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17248535705465415		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.17248535705465415 | validation: 0.20141886571977466]
	TIME [epoch: 6.48 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1751390620060802		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.1751390620060802 | validation: 0.1679576840401067]
	TIME [epoch: 6.48 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16216164940757768		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.16216164940757768 | validation: 0.16725678382289347]
	TIME [epoch: 6.47 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17540578209878838		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.17540578209878838 | validation: 0.1745630021772557]
	TIME [epoch: 6.48 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16104478714371354		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.16104478714371354 | validation: 0.1762501019838505]
	TIME [epoch: 6.49 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1644513650584574		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.1644513650584574 | validation: 0.1604206183046256]
	TIME [epoch: 6.51 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15195931852532668		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.15195931852532668 | validation: 0.14976146007330607]
	TIME [epoch: 6.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15487289793631925		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.15487289793631925 | validation: 0.16822608994168894]
	TIME [epoch: 6.48 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15719840587617942		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.15719840587617942 | validation: 0.15571463364200683]
	TIME [epoch: 6.47 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603625910053407		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.1603625910053407 | validation: 0.166010809967001]
	TIME [epoch: 6.49 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1584250653961874		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.1584250653961874 | validation: 0.1571484514557326]
	TIME [epoch: 6.47 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15889269103532028		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.15889269103532028 | validation: 0.18739505076975024]
	TIME [epoch: 6.49 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17198054222069947		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.17198054222069947 | validation: 0.16773360548886093]
	TIME [epoch: 6.51 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1594181104470938		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.1594181104470938 | validation: 0.15796362574446654]
	TIME [epoch: 6.48 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15081173529011727		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.15081173529011727 | validation: 0.15373428501937372]
	TIME [epoch: 6.48 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16425371633717306		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.16425371633717306 | validation: 0.16828121661385112]
	TIME [epoch: 6.49 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16481120356515705		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.16481120356515705 | validation: 0.17261195825289435]
	TIME [epoch: 6.51 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17324116642834628		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.17324116642834628 | validation: 0.17261618444005702]
	TIME [epoch: 6.51 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15224251770538533		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.15224251770538533 | validation: 0.16555818604325706]
	TIME [epoch: 6.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15401773887243253		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.15401773887243253 | validation: 0.15682601503301724]
	TIME [epoch: 6.54 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15476765576801504		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.15476765576801504 | validation: 0.17236063267080493]
	TIME [epoch: 6.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15183773859788505		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.15183773859788505 | validation: 0.15775216706105133]
	TIME [epoch: 6.48 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15525113992035305		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.15525113992035305 | validation: 0.17188892640652845]
	TIME [epoch: 6.48 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1545157314639073		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.1545157314639073 | validation: 0.1663115962836249]
	TIME [epoch: 6.48 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15385152475048125		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.15385152475048125 | validation: 0.15726487957911045]
	TIME [epoch: 6.49 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15684891440125745		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.15684891440125745 | validation: 0.1818056582605039]
	TIME [epoch: 6.51 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16114129775959343		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.16114129775959343 | validation: 0.16779533136023664]
	TIME [epoch: 6.52 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16017357764620965		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.16017357764620965 | validation: 0.1639920849078695]
	TIME [epoch: 6.48 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16896279998399297		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.16896279998399297 | validation: 0.17835051590984471]
	TIME [epoch: 6.49 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1705220717178947		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.1705220717178947 | validation: 0.16562206193330734]
	TIME [epoch: 6.51 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16033590782390536		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.16033590782390536 | validation: 0.15784052636908708]
	TIME [epoch: 6.48 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15606347538089027		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.15606347538089027 | validation: 0.1586992105666455]
	TIME [epoch: 6.49 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15178304352366703		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.15178304352366703 | validation: 0.1866171674917792]
	TIME [epoch: 6.49 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156398843156586		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.156398843156586 | validation: 0.16322135278395253]
	TIME [epoch: 6.54 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502429267160696		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.1502429267160696 | validation: 0.19586014851984224]
	TIME [epoch: 6.51 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16619030016361735		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.16619030016361735 | validation: 0.17061771485164628]
	TIME [epoch: 6.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15878810466529383		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.15878810466529383 | validation: 0.1894091095988634]
	TIME [epoch: 6.49 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16326480242168256		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.16326480242168256 | validation: 0.1636069184902911]
	TIME [epoch: 6.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1525718584476211		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.1525718584476211 | validation: 0.17005465202105946]
	TIME [epoch: 6.49 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16517172327086932		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.16517172327086932 | validation: 0.15878912563067626]
	TIME [epoch: 6.49 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15632067335500194		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.15632067335500194 | validation: 0.15817663683821148]
	TIME [epoch: 6.53 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16003981885091748		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.16003981885091748 | validation: 0.16286469636025708]
	TIME [epoch: 6.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16249452976024842		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.16249452976024842 | validation: 0.18234197778838565]
	TIME [epoch: 6.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16837367261331435		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.16837367261331435 | validation: 0.17708718904992743]
	TIME [epoch: 6.51 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572330349798272		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.1572330349798272 | validation: 0.1575573691549594]
	TIME [epoch: 6.49 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15394192438358614		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.15394192438358614 | validation: 0.17874299479124403]
	TIME [epoch: 6.49 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16242822494461492		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.16242822494461492 | validation: 0.1858753119553925]
	TIME [epoch: 6.48 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1683359346419106		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.1683359346419106 | validation: 0.15883734839557181]
	TIME [epoch: 6.54 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489302551217875		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.1489302551217875 | validation: 0.16701679492538557]
	TIME [epoch: 6.53 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1475953292159776		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.1475953292159776 | validation: 0.14953845284458886]
	TIME [epoch: 6.49 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16461801397709033		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.16461801397709033 | validation: 0.16801894018714142]
	TIME [epoch: 6.51 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15875864432719256		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.15875864432719256 | validation: 0.17497202574639178]
	TIME [epoch: 6.49 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1664055600239044		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.1664055600239044 | validation: 0.15089703787731457]
	TIME [epoch: 6.48 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15072488428292144		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.15072488428292144 | validation: 0.16424771462243434]
	TIME [epoch: 6.48 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15513953702966812		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.15513953702966812 | validation: 0.1593000755374201]
	TIME [epoch: 6.51 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16135787161847848		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.16135787161847848 | validation: 0.18830633363720573]
	TIME [epoch: 6.48 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1736202078555791		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.1736202078555791 | validation: 0.15967447040639932]
	TIME [epoch: 6.48 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15395889103286692		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.15395889103286692 | validation: 0.1605320132155744]
	TIME [epoch: 6.48 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506402999235038		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.1506402999235038 | validation: 0.1489860246197572]
	TIME [epoch: 6.49 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15615905655817416		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.15615905655817416 | validation: 0.1640581956383703]
	TIME [epoch: 6.48 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15267496741489284		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.15267496741489284 | validation: 0.1623007800772836]
	TIME [epoch: 6.48 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15611389512664953		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.15611389512664953 | validation: 0.14510198078330214]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1311.pth
	Model improved!!!
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506193173452174		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.1506193173452174 | validation: 0.15675212292102794]
	TIME [epoch: 6.58 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536652580687159		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.1536652580687159 | validation: 0.17989912173282654]
	TIME [epoch: 6.48 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555328956478373		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.1555328956478373 | validation: 0.15750944460668462]
	TIME [epoch: 6.48 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16127980173076456		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.16127980173076456 | validation: 0.15380814793700845]
	TIME [epoch: 6.48 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1568920102954065		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.1568920102954065 | validation: 0.14184796647099757]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1316.pth
	Model improved!!!
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15610515345682505		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.15610515345682505 | validation: 0.16330622034035486]
	TIME [epoch: 6.55 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16998778221553956		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.16998778221553956 | validation: 0.19252279653306312]
	TIME [epoch: 6.53 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19078552312795227		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.19078552312795227 | validation: 0.1551290887995267]
	TIME [epoch: 6.49 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15983328825754814		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.15983328825754814 | validation: 0.14458373441026204]
	TIME [epoch: 6.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1556183650643129		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.1556183650643129 | validation: 0.1877023004393119]
	TIME [epoch: 6.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16831302748250837		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.16831302748250837 | validation: 0.18457808665414624]
	TIME [epoch: 6.49 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16531396518627553		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.16531396518627553 | validation: 0.14974694810237688]
	TIME [epoch: 6.49 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14480767998240487		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.14480767998240487 | validation: 0.159103575539331]
	TIME [epoch: 6.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15197119073195753		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.15197119073195753 | validation: 0.16051314020599222]
	TIME [epoch: 6.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15802256394430003		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.15802256394430003 | validation: 0.1625556278935506]
	TIME [epoch: 6.51 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16350813349914656		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.16350813349914656 | validation: 0.18979603564195338]
	TIME [epoch: 6.49 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16923404216545362		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.16923404216545362 | validation: 0.15296270229905967]
	TIME [epoch: 6.48 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16169676091623864		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.16169676091623864 | validation: 0.158758177272049]
	TIME [epoch: 6.49 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153123970662793		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.153123970662793 | validation: 0.1523272222693981]
	TIME [epoch: 6.49 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514059401836078		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.1514059401836078 | validation: 0.17136154612561635]
	TIME [epoch: 6.48 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16102427296165658		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.16102427296165658 | validation: 0.17880118082601862]
	TIME [epoch: 6.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15482576555405222		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.15482576555405222 | validation: 0.15415224283770262]
	TIME [epoch: 6.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15368216554724368		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.15368216554724368 | validation: 0.15819932121819977]
	TIME [epoch: 6.49 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15129457621841297		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.15129457621841297 | validation: 0.15991682894921394]
	TIME [epoch: 6.48 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15729148022641556		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.15729148022641556 | validation: 0.16232474814572903]
	TIME [epoch: 6.48 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506092123318094		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.1506092123318094 | validation: 0.15401357068221022]
	TIME [epoch: 6.48 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14683359694860612		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.14683359694860612 | validation: 0.15883397752153935]
	TIME [epoch: 6.48 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532735377864179		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.1532735377864179 | validation: 0.15452585660478715]
	TIME [epoch: 6.48 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14397179636202212		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.14397179636202212 | validation: 0.1615631391021139]
	TIME [epoch: 6.52 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16188797512457528		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.16188797512457528 | validation: 0.17154450553027423]
	TIME [epoch: 6.48 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1619872415492793		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.1619872415492793 | validation: 0.1758945666889443]
	TIME [epoch: 6.48 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16412455558985325		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.16412455558985325 | validation: 0.19180541288482653]
	TIME [epoch: 6.49 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1571279489028996		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.1571279489028996 | validation: 0.17563550242699788]
	TIME [epoch: 6.48 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16146036778290612		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.16146036778290612 | validation: 0.16565229858021951]
	TIME [epoch: 6.48 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1571055741210547		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.1571055741210547 | validation: 0.1645560495903338]
	TIME [epoch: 6.48 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15928046196666706		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.15928046196666706 | validation: 0.15825960230501013]
	TIME [epoch: 6.51 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1640383579910893		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.1640383579910893 | validation: 0.1519194984809433]
	TIME [epoch: 6.48 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15874468378252643		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.15874468378252643 | validation: 0.1583198302759632]
	TIME [epoch: 6.48 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15345789205072355		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.15345789205072355 | validation: 0.15970400170906504]
	TIME [epoch: 6.48 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16485773402414539		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.16485773402414539 | validation: 0.1564248150807905]
	TIME [epoch: 6.47 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500402238894582		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.1500402238894582 | validation: 0.1497148385814784]
	TIME [epoch: 6.47 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14909568588345656		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.14909568588345656 | validation: 0.14241524884775292]
	TIME [epoch: 6.48 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15349831720454676		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.15349831720454676 | validation: 0.14740471658094959]
	TIME [epoch: 6.52 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15739430800954174		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.15739430800954174 | validation: 0.15920693076591094]
	TIME [epoch: 6.49 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17755156883268008		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.17755156883268008 | validation: 0.17011709242898518]
	TIME [epoch: 6.48 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16642267039742675		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.16642267039742675 | validation: 0.18112588356115822]
	TIME [epoch: 6.47 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15880942090102118		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.15880942090102118 | validation: 0.15371047993465412]
	TIME [epoch: 6.48 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521736679603844		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.1521736679603844 | validation: 0.15269987495562234]
	TIME [epoch: 6.48 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15270714037576505		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.15270714037576505 | validation: 0.16238731272656778]
	TIME [epoch: 6.47 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555797342203979		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.1555797342203979 | validation: 0.1608738106438353]
	TIME [epoch: 6.52 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1498453077997401		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.1498453077997401 | validation: 0.15563310361553387]
	TIME [epoch: 6.49 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632275848998714		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.1632275848998714 | validation: 0.16888253046881424]
	TIME [epoch: 6.48 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1599983582893317		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.1599983582893317 | validation: 0.1634162192937386]
	TIME [epoch: 6.49 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15492957440214417		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.15492957440214417 | validation: 0.1633304599063625]
	TIME [epoch: 6.49 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15895777543708908		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.15895777543708908 | validation: 0.18280894814392007]
	TIME [epoch: 6.48 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16783279121279626		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.16783279121279626 | validation: 0.18918663270858865]
	TIME [epoch: 6.49 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16777876498529584		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.16777876498529584 | validation: 0.16230134498326493]
	TIME [epoch: 6.53 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532145704196759		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.1532145704196759 | validation: 0.18869586763129054]
	TIME [epoch: 6.51 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16498596808692856		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.16498596808692856 | validation: 0.16823823573773325]
	TIME [epoch: 6.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14886362390858227		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.14886362390858227 | validation: 0.15650883973490737]
	TIME [epoch: 6.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15125925362613143		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.15125925362613143 | validation: 0.16673639696773634]
	TIME [epoch: 6.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15502445003099272		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.15502445003099272 | validation: 0.15312560643635253]
	TIME [epoch: 6.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530902063204666		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.1530902063204666 | validation: 0.15117177958099456]
	TIME [epoch: 6.48 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15335602224844874		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.15335602224844874 | validation: 0.15381584683808858]
	TIME [epoch: 6.53 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14876033668565175		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.14876033668565175 | validation: 0.14894224629511482]
	TIME [epoch: 6.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1525585851332251		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.1525585851332251 | validation: 0.15184120328151718]
	TIME [epoch: 6.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14613943619140796		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.14613943619140796 | validation: 0.1436536742225812]
	TIME [epoch: 6.48 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14901220553940725		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.14901220553940725 | validation: 0.15623545885584122]
	TIME [epoch: 6.48 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14972494493768335		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.14972494493768335 | validation: 0.1645230429007591]
	TIME [epoch: 6.51 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15662004982241348		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.15662004982241348 | validation: 0.1498134316467801]
	TIME [epoch: 6.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15009270617130743		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.15009270617130743 | validation: 0.17449347674503482]
	TIME [epoch: 6.51 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.173309767932243		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.173309767932243 | validation: 0.19751180000580587]
	TIME [epoch: 6.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19943722468517475		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.19943722468517475 | validation: 0.18843471986053537]
	TIME [epoch: 6.49 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1676137388971209		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.1676137388971209 | validation: 0.15549892206636637]
	TIME [epoch: 6.49 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517662645677229		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.1517662645677229 | validation: 0.15703272313873548]
	TIME [epoch: 6.47 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15390165506147938		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.15390165506147938 | validation: 0.16337342532206123]
	TIME [epoch: 6.49 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517272790039187		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.1517272790039187 | validation: 0.16789638831920456]
	TIME [epoch: 6.48 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15755542426265481		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.15755542426265481 | validation: 0.17632637630123493]
	TIME [epoch: 6.51 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1504723177939914		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.1504723177939914 | validation: 0.157472536565696]
	TIME [epoch: 6.51 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15055772593120104		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.15055772593120104 | validation: 0.1616240862028917]
	TIME [epoch: 6.49 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1602644298785495		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.1602644298785495 | validation: 0.1718619288089797]
	TIME [epoch: 6.48 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1570970439576641		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.1570970439576641 | validation: 0.17988107800181638]
	TIME [epoch: 6.51 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16151492827842945		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.16151492827842945 | validation: 0.18926737366810537]
	TIME [epoch: 6.51 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1648075623088781		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.1648075623088781 | validation: 0.17972345917996294]
	TIME [epoch: 6.49 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1499122625868899		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.1499122625868899 | validation: 0.15451509854721412]
	TIME [epoch: 6.52 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14488511612831464		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.14488511612831464 | validation: 0.15544175810262462]
	TIME [epoch: 6.51 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14671642745384095		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.14671642745384095 | validation: 0.15417907195769848]
	TIME [epoch: 6.49 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14703370202433055		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.14703370202433055 | validation: 0.157486053823026]
	TIME [epoch: 6.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14863406337498042		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.14863406337498042 | validation: 0.1709821492974096]
	TIME [epoch: 6.49 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15458144122859033		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.15458144122859033 | validation: 0.16413592393554702]
	TIME [epoch: 6.49 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15718355109049126		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.15718355109049126 | validation: 0.17185729990516968]
	TIME [epoch: 6.49 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14968630991857185		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.14968630991857185 | validation: 0.15515001737104286]
	TIME [epoch: 6.51 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14993982187333565		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.14993982187333565 | validation: 0.16267973034582597]
	TIME [epoch: 6.53 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15445076109182945		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.15445076109182945 | validation: 0.15168007358866384]
	TIME [epoch: 6.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14981763556388789		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.14981763556388789 | validation: 0.15787254094338732]
	TIME [epoch: 6.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1594964266459268		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.1594964266459268 | validation: 0.18038747163455895]
	TIME [epoch: 6.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16063215919168566		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.16063215919168566 | validation: 0.17090918080893538]
	TIME [epoch: 6.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14830895283125178		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.14830895283125178 | validation: 0.1564254048079764]
	TIME [epoch: 6.49 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14633651772042905		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.14633651772042905 | validation: 0.16424823312270076]
	TIME [epoch: 6.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15423108022426937		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.15423108022426937 | validation: 0.15111610302183148]
	TIME [epoch: 6.54 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14540754901081532		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.14540754901081532 | validation: 0.16832936655452138]
	TIME [epoch: 6.49 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16289947818034728		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.16289947818034728 | validation: 0.18042402225334564]
	TIME [epoch: 6.48 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16893901858358312		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.16893901858358312 | validation: 0.16716227777298223]
	TIME [epoch: 6.48 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16268612808427038		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.16268612808427038 | validation: 0.16339097603289593]
	TIME [epoch: 6.48 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15328189488227492		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.15328189488227492 | validation: 0.1574367827789477]
	TIME [epoch: 6.48 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15194638013237893		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.15194638013237893 | validation: 0.15440226238102064]
	TIME [epoch: 6.51 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15317492842432007		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.15317492842432007 | validation: 0.15405832499016062]
	TIME [epoch: 6.52 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1529740747133877		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.1529740747133877 | validation: 0.16123164281968458]
	TIME [epoch: 6.51 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15036671435248286		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.15036671435248286 | validation: 0.15597108019610084]
	TIME [epoch: 6.51 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15219054580471564		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.15219054580471564 | validation: 0.16175865873081408]
	TIME [epoch: 6.51 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15227894632916586		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.15227894632916586 | validation: 0.1505458657246064]
	TIME [epoch: 6.49 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522610571110286		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.1522610571110286 | validation: 0.13642920157742588]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1423.pth
	Model improved!!!
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1465790593329628		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.1465790593329628 | validation: 0.1482042882323863]
	TIME [epoch: 6.48 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14489309643212284		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.14489309643212284 | validation: 0.15036654193086485]
	TIME [epoch: 6.54 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488955093464931		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.1488955093464931 | validation: 0.15903240464159257]
	TIME [epoch: 6.48 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15167575168603478		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.15167575168603478 | validation: 0.15701481457249597]
	TIME [epoch: 6.49 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15564781887195273		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.15564781887195273 | validation: 0.15311338875056066]
	TIME [epoch: 6.49 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15061271725619618		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.15061271725619618 | validation: 0.1566687594183956]
	TIME [epoch: 6.49 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14883144327302011		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.14883144327302011 | validation: 0.16014236172064014]
	TIME [epoch: 6.48 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503912240879496		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.1503912240879496 | validation: 0.16458675004439244]
	TIME [epoch: 6.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14899299954071915		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.14899299954071915 | validation: 0.14813356336924366]
	TIME [epoch: 6.53 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486719193884357		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.1486719193884357 | validation: 0.15752238870347082]
	TIME [epoch: 6.49 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464524127071007		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.1464524127071007 | validation: 0.1538485369091029]
	TIME [epoch: 6.46 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16271176741476018		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.16271176741476018 | validation: 0.17809413368726645]
	TIME [epoch: 6.46 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670227697156321		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.1670227697156321 | validation: 0.17113520689868508]
	TIME [epoch: 6.45 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15391560837597593		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.15391560837597593 | validation: 0.15208799387202418]
	TIME [epoch: 6.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1491845847832989		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.1491845847832989 | validation: 0.14945176560261714]
	TIME [epoch: 6.47 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15155218119397432		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.15155218119397432 | validation: 0.1589485390013377]
	TIME [epoch: 6.52 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14912653899510886		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.14912653899510886 | validation: 0.15366307311717817]
	TIME [epoch: 6.49 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14527994489342444		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.14527994489342444 | validation: 0.14344608003374051]
	TIME [epoch: 6.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14774841678081876		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.14774841678081876 | validation: 0.15038835709755646]
	TIME [epoch: 6.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14442807574098457		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.14442807574098457 | validation: 0.1500020095517257]
	TIME [epoch: 6.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15108871585793143		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.15108871585793143 | validation: 0.14361364704183807]
	TIME [epoch: 6.49 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15152804715406348		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.15152804715406348 | validation: 0.1555592222077195]
	TIME [epoch: 6.53 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15213272293312016		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.15213272293312016 | validation: 0.15033195251369028]
	TIME [epoch: 6.54 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14663628436616066		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.14663628436616066 | validation: 0.14743725152154055]
	TIME [epoch: 6.48 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14673845955771375		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.14673845955771375 | validation: 0.1482081439427855]
	TIME [epoch: 6.48 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15475477290881445		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.15475477290881445 | validation: 0.14943601530880427]
	TIME [epoch: 6.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14651569205048626		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.14651569205048626 | validation: 0.1488289113542068]
	TIME [epoch: 6.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14762783207381766		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.14762783207381766 | validation: 0.14013576750603973]
	TIME [epoch: 6.47 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15261779176220677		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.15261779176220677 | validation: 0.15953718958282476]
	TIME [epoch: 6.48 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16705508958971127		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.16705508958971127 | validation: 0.1539349395961038]
	TIME [epoch: 6.52 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15604760384300267		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.15604760384300267 | validation: 0.15163970888993134]
	TIME [epoch: 6.53 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15259095841321724		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.15259095841321724 | validation: 0.14758839594531126]
	TIME [epoch: 6.49 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14889443036676403		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.14889443036676403 | validation: 0.15176809038346656]
	TIME [epoch: 6.49 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14640958001490728		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.14640958001490728 | validation: 0.15242103522122294]
	TIME [epoch: 6.55 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14710499734746446		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.14710499734746446 | validation: 0.15033318516141797]
	TIME [epoch: 6.57 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14745989648173286		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.14745989648173286 | validation: 0.14639636033045514]
	TIME [epoch: 6.55 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14768908285394255		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.14768908285394255 | validation: 0.15203335811196245]
	TIME [epoch: 6.51 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15554810815026732		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.15554810815026732 | validation: 0.18365862364446858]
	TIME [epoch: 6.58 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162285450365711		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.162285450365711 | validation: 0.1838537486350967]
	TIME [epoch: 6.52 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15718632575382485		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.15718632575382485 | validation: 0.16364214358728035]
	TIME [epoch: 6.49 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15618680992799097		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.15618680992799097 | validation: 0.16143288203470746]
	TIME [epoch: 6.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15564765530146693		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.15564765530146693 | validation: 0.14967470605237929]
	TIME [epoch: 6.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15706833944639498		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.15706833944639498 | validation: 0.14611448392658005]
	TIME [epoch: 6.54 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14938260724661864		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.14938260724661864 | validation: 0.13746530106749086]
	TIME [epoch: 6.54 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.149414377715534		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.149414377715534 | validation: 0.13806561499339506]
	TIME [epoch: 6.52 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14935852538794164		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.14935852538794164 | validation: 0.140092240355278]
	TIME [epoch: 6.51 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14924394513989409		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.14924394513989409 | validation: 0.15304074428998127]
	TIME [epoch: 6.52 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18231681802442284		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.18231681802442284 | validation: 0.1611606667793539]
	TIME [epoch: 6.52 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1798594800103814		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.1798594800103814 | validation: 0.1513253212650017]
	TIME [epoch: 6.49 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1554020010744513		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.1554020010744513 | validation: 0.1443628496819375]
	TIME [epoch: 6.49 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15251698361160032		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.15251698361160032 | validation: 0.15158148422999834]
	TIME [epoch: 6.53 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15248369815603466		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.15248369815603466 | validation: 0.1454719401732475]
	TIME [epoch: 6.59 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14611506799132465		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.14611506799132465 | validation: 0.15022655826653844]
	TIME [epoch: 6.52 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1472668812658404		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.1472668812658404 | validation: 0.16016837494272035]
	TIME [epoch: 6.57 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15112090438057402		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.15112090438057402 | validation: 0.15534891974013065]
	TIME [epoch: 6.57 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14754129637574054		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.14754129637574054 | validation: 0.1396498839754365]
	TIME [epoch: 6.56 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14392976306832234		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.14392976306832234 | validation: 0.15152570663469772]
	TIME [epoch: 6.53 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15015972311021164		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.15015972311021164 | validation: 0.14841890276227077]
	TIME [epoch: 6.52 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14629110436225468		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.14629110436225468 | validation: 0.1412787723321057]
	TIME [epoch: 6.56 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15322190262180718		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.15322190262180718 | validation: 0.1399661235943467]
	TIME [epoch: 6.49 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14763053503767468		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.14763053503767468 | validation: 0.14577321506184931]
	TIME [epoch: 6.51 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14938970585513073		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.14938970585513073 | validation: 0.14542939248962117]
	TIME [epoch: 6.61 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15373621252925085		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.15373621252925085 | validation: 0.16305312990427898]
	TIME [epoch: 6.49 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1545587152908437		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.1545587152908437 | validation: 0.15558144757337844]
	TIME [epoch: 6.51 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460127324053803		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.1460127324053803 | validation: 0.14753311399409783]
	TIME [epoch: 6.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14153215838880448		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.14153215838880448 | validation: 0.14226391700861957]
	TIME [epoch: 6.53 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452859735218353		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.1452859735218353 | validation: 0.15960222062986748]
	TIME [epoch: 6.52 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15134826677970198		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.15134826677970198 | validation: 0.16024965056067678]
	TIME [epoch: 6.51 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15310332518004288		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.15310332518004288 | validation: 0.15912275998138875]
	TIME [epoch: 6.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1573920371955696		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.1573920371955696 | validation: 0.16287221497322507]
	TIME [epoch: 6.53 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15561753349296373		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.15561753349296373 | validation: 0.16572184837252324]
	TIME [epoch: 6.52 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14715044365477536		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.14715044365477536 | validation: 0.15512035446403435]
	TIME [epoch: 6.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14497964359612234		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.14497964359612234 | validation: 0.14287671134212238]
	TIME [epoch: 6.61 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15167937668844328		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.15167937668844328 | validation: 0.1716061876666518]
	TIME [epoch: 6.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15301039267672		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.15301039267672 | validation: 0.14264158323030832]
	TIME [epoch: 6.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14602141816777778		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.14602141816777778 | validation: 0.15751160836158373]
	TIME [epoch: 6.48 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1454846055510794		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.1454846055510794 | validation: 0.15714420378606483]
	TIME [epoch: 6.48 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1482901995353686		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.1482901995353686 | validation: 0.1617856143193024]
	TIME [epoch: 6.48 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510785051758947		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.1510785051758947 | validation: 0.1568785022381123]
	TIME [epoch: 6.49 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1490701876315315		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.1490701876315315 | validation: 0.1487636445218127]
	TIME [epoch: 6.53 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14771646650712467		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.14771646650712467 | validation: 0.1733266796003487]
	TIME [epoch: 6.49 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550296623249891		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.1550296623249891 | validation: 0.16845692728164197]
	TIME [epoch: 6.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1473373293447894		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.1473373293447894 | validation: 0.16528693807485234]
	TIME [epoch: 6.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493045628101837		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.1493045628101837 | validation: 0.14499408544490677]
	TIME [epoch: 6.51 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14407472685756337		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.14407472685756337 | validation: 0.1462132868878336]
	TIME [epoch: 6.51 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14103261635299158		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.14103261635299158 | validation: 0.1494123959530684]
	TIME [epoch: 6.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14462395129086048		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.14462395129086048 | validation: 0.1424389343864135]
	TIME [epoch: 6.55 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1430758882889881		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.1430758882889881 | validation: 0.15115147417491992]
	TIME [epoch: 6.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14962920470933186		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.14962920470933186 | validation: 0.15003838387524426]
	TIME [epoch: 6.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14408516491434173		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.14408516491434173 | validation: 0.13815681846529373]
	TIME [epoch: 6.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14703532292683125		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.14703532292683125 | validation: 0.14297903327941597]
	TIME [epoch: 6.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14521425522982268		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.14521425522982268 | validation: 0.14523751910909088]
	TIME [epoch: 6.49 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14570846974307772		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.14570846974307772 | validation: 0.1501006389197387]
	TIME [epoch: 6.49 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14552781506840315		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.14552781506840315 | validation: 0.1673432758103909]
	TIME [epoch: 6.54 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14570864607522335		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.14570864607522335 | validation: 0.151123253863179]
	TIME [epoch: 6.49 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14408451285937274		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.14408451285937274 | validation: 0.14233589193872961]
	TIME [epoch: 6.48 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14999571980258677		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.14999571980258677 | validation: 0.14812484767739445]
	TIME [epoch: 6.47 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509860994694168		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.1509860994694168 | validation: 0.14754932695256998]
	TIME [epoch: 6.49 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461453240230763		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.1461453240230763 | validation: 0.145610673278478]
	TIME [epoch: 6.48 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14449593707230443		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.14449593707230443 | validation: 0.15048190728998687]
	TIME [epoch: 6.46 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15224919971695292		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.15224919971695292 | validation: 0.162817394312593]
	TIME [epoch: 6.51 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14708938840372326		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.14708938840372326 | validation: 0.1467442430779797]
	TIME [epoch: 6.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14342473971623534		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.14342473971623534 | validation: 0.1515264151246042]
	TIME [epoch: 6.6 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14863503213973828		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.14863503213973828 | validation: 0.14704935559885574]
	TIME [epoch: 6.6 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.145004083948162		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.145004083948162 | validation: 0.14386988030244038]
	TIME [epoch: 6.58 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14642542224769048		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.14642542224769048 | validation: 0.13525687568799555]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1529.pth
	Model improved!!!
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438526837072307		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.1438526837072307 | validation: 0.14491475124318481]
	TIME [epoch: 6.58 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14286857344594714		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.14286857344594714 | validation: 0.1505245368755114]
	TIME [epoch: 6.54 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15485349052274638		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.15485349052274638 | validation: 0.16005541087696956]
	TIME [epoch: 6.48 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16266005193872907		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.16266005193872907 | validation: 0.16445299512293562]
	TIME [epoch: 6.48 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15593521536200455		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.15593521536200455 | validation: 0.1554687747038646]
	TIME [epoch: 6.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14996369752883204		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.14996369752883204 | validation: 0.15184179985691676]
	TIME [epoch: 6.49 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14739747991091173		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.14739747991091173 | validation: 0.14879384816078461]
	TIME [epoch: 6.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14868489389779724		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.14868489389779724 | validation: 0.16039768714531272]
	TIME [epoch: 6.52 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14919433568918242		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.14919433568918242 | validation: 0.1620501364732656]
	TIME [epoch: 6.55 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14482903794228172		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.14482903794228172 | validation: 0.14873015505536757]
	TIME [epoch: 6.57 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429745933773635		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.1429745933773635 | validation: 0.14212004716050416]
	TIME [epoch: 6.54 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14201257005204698		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.14201257005204698 | validation: 0.1394765778127996]
	TIME [epoch: 6.52 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14586184018322074		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.14586184018322074 | validation: 0.14791501883004465]
	TIME [epoch: 6.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14360754199989492		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.14360754199989492 | validation: 0.1477025714078495]
	TIME [epoch: 6.49 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14622596452652967		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.14622596452652967 | validation: 0.14616109225302482]
	TIME [epoch: 6.49 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14177029353200737		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.14177029353200737 | validation: 0.1405507718797769]
	TIME [epoch: 6.53 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14124004527172918		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.14124004527172918 | validation: 0.15532471891027302]
	TIME [epoch: 6.53 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14369823867677806		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.14369823867677806 | validation: 0.14749928360601464]
	TIME [epoch: 6.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14998186015837195		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.14998186015837195 | validation: 0.14344852178078005]
	TIME [epoch: 6.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14441030893698		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.14441030893698 | validation: 0.15391403334949236]
	TIME [epoch: 6.49 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15010869513595992		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.15010869513595992 | validation: 0.15128218214812156]
	TIME [epoch: 6.52 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497628974911436		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.1497628974911436 | validation: 0.16296373160579303]
	TIME [epoch: 6.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14653706871975883		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.14653706871975883 | validation: 0.14980251782197962]
	TIME [epoch: 6.53 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142231667152531		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.142231667152531 | validation: 0.15151313658545798]
	TIME [epoch: 6.52 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14007831906005813		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.14007831906005813 | validation: 0.1363374211359568]
	TIME [epoch: 6.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14232344437113975		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.14232344437113975 | validation: 0.1444358662333824]
	TIME [epoch: 6.51 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14392984804420444		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.14392984804420444 | validation: 0.14528574867779917]
	TIME [epoch: 6.49 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468973754338711		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.1468973754338711 | validation: 0.1414008823878379]
	TIME [epoch: 6.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14673781431976265		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.14673781431976265 | validation: 0.13980613392213637]
	TIME [epoch: 6.49 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14401215894812242		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.14401215894812242 | validation: 0.14161086522687363]
	TIME [epoch: 6.51 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14011518636699558		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.14011518636699558 | validation: 0.14577861318452914]
	TIME [epoch: 6.55 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14262764401683298		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.14262764401683298 | validation: 0.14178304318674584]
	TIME [epoch: 6.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14152082074695346		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.14152082074695346 | validation: 0.14304690527749966]
	TIME [epoch: 6.51 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14087436325314018		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.14087436325314018 | validation: 0.1496348523916326]
	TIME [epoch: 6.53 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14105995246596584		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.14105995246596584 | validation: 0.14959497675822797]
	TIME [epoch: 6.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14577727564796433		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.14577727564796433 | validation: 0.1535229153096969]
	TIME [epoch: 6.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15143408898415486		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.15143408898415486 | validation: 0.15943617566115184]
	TIME [epoch: 6.52 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14991247181137216		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.14991247181137216 | validation: 0.15332586294406977]
	TIME [epoch: 6.53 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14978249153739562		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.14978249153739562 | validation: 0.15078273541133436]
	TIME [epoch: 6.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14491890104986535		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.14491890104986535 | validation: 0.152979350184705]
	TIME [epoch: 6.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497757055187151		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.1497757055187151 | validation: 0.16273848551952275]
	TIME [epoch: 6.51 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14677457297970484		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.14677457297970484 | validation: 0.1510944045984757]
	TIME [epoch: 6.52 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14299236937734405		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.14299236937734405 | validation: 0.14622540035797302]
	TIME [epoch: 6.51 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14316041274862493		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.14316041274862493 | validation: 0.15461684113157476]
	TIME [epoch: 6.52 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14766107431312825		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.14766107431312825 | validation: 0.1516497110543365]
	TIME [epoch: 6.55 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14424049775846876		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.14424049775846876 | validation: 0.14965279700563325]
	TIME [epoch: 6.49 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14786003568461836		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.14786003568461836 | validation: 0.1365871448874946]
	TIME [epoch: 6.51 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14375752905764405		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.14375752905764405 | validation: 0.14565359957639698]
	TIME [epoch: 6.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14064716591155646		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.14064716591155646 | validation: 0.14873535261623402]
	TIME [epoch: 6.47 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14579110423873984		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.14579110423873984 | validation: 0.14524028469187963]
	TIME [epoch: 6.49 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15088744194967693		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.15088744194967693 | validation: 0.1591292443144894]
	TIME [epoch: 6.52 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1455750796400414		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.1455750796400414 | validation: 0.15412926307403685]
	TIME [epoch: 6.55 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508898057864411		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.1508898057864411 | validation: 0.14941992938790782]
	TIME [epoch: 6.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14198556501461884		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.14198556501461884 | validation: 0.15107745056569225]
	TIME [epoch: 6.48 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1401110705758753		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.1401110705758753 | validation: 0.15224965303692523]
	TIME [epoch: 6.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14334513310319497		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.14334513310319497 | validation: 0.14002330927540127]
	TIME [epoch: 6.48 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13845968823579546		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.13845968823579546 | validation: 0.15250363647007134]
	TIME [epoch: 6.51 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14322273413112588		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.14322273413112588 | validation: 0.15203776878007708]
	TIME [epoch: 6.48 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14576576533253072		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.14576576533253072 | validation: 0.15174391197580836]
	TIME [epoch: 6.54 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461383689927227		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.1461383689927227 | validation: 0.15265418919959725]
	TIME [epoch: 6.51 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14816714013757484		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.14816714013757484 | validation: 0.1558474384044959]
	TIME [epoch: 6.49 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14320918802439636		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.14320918802439636 | validation: 0.15617657662389933]
	TIME [epoch: 6.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14452129751475448		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.14452129751475448 | validation: 0.14689026325555563]
	TIME [epoch: 6.53 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14359045281577335		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.14359045281577335 | validation: 0.14306963712539802]
	TIME [epoch: 6.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141163411937968		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.141163411937968 | validation: 0.1449136296515305]
	TIME [epoch: 6.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14078225578546874		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.14078225578546874 | validation: 0.14810055224737306]
	TIME [epoch: 6.58 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1450987596307747		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.1450987596307747 | validation: 0.15085847571895017]
	TIME [epoch: 6.51 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14398154123149634		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.14398154123149634 | validation: 0.1451449049967984]
	TIME [epoch: 6.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14551724109313952		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.14551724109313952 | validation: 0.15203224088088782]
	TIME [epoch: 6.48 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1419133110748627		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.1419133110748627 | validation: 0.15139341349237928]
	TIME [epoch: 6.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14224020574423887		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.14224020574423887 | validation: 0.14763661974372233]
	TIME [epoch: 6.49 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14850698319516553		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.14850698319516553 | validation: 0.15023001415169887]
	TIME [epoch: 6.51 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14764298885999605		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.14764298885999605 | validation: 0.15231470658717708]
	TIME [epoch: 6.53 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14570786008856804		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.14570786008856804 | validation: 0.14743742376061586]
	TIME [epoch: 6.53 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14606890844444403		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.14606890844444403 | validation: 0.1524340684875249]
	TIME [epoch: 6.52 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1426816520180162		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.1426816520180162 | validation: 0.14693336313592795]
	TIME [epoch: 6.49 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14051857939116502		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.14051857939116502 | validation: 0.15667345344927608]
	TIME [epoch: 6.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428331465587214		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.1428331465587214 | validation: 0.13986237019503503]
	TIME [epoch: 6.58 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422861105052094		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.1422861105052094 | validation: 0.14930379434289479]
	TIME [epoch: 6.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403971360864471		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.1403971360864471 | validation: 0.14863013965113744]
	TIME [epoch: 6.57 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14743719644801861		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.14743719644801861 | validation: 0.14924255658677685]
	TIME [epoch: 6.61 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14729330065049745		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.14729330065049745 | validation: 0.14635884567887755]
	TIME [epoch: 6.59 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14666824198089035		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.14666824198089035 | validation: 0.14477464100794046]
	TIME [epoch: 6.48 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14403243238632593		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.14403243238632593 | validation: 0.14452579925438494]
	TIME [epoch: 6.53 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442935378148148		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.1442935378148148 | validation: 0.13580112433094152]
	TIME [epoch: 6.55 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1430547446804228		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.1430547446804228 | validation: 0.1467697715638112]
	TIME [epoch: 6.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14304677734227558		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.14304677734227558 | validation: 0.1484834365803709]
	TIME [epoch: 6.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14777264751723035		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.14777264751723035 | validation: 0.142050752189049]
	TIME [epoch: 6.51 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14198005747009745		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.14198005747009745 | validation: 0.14056099743260497]
	TIME [epoch: 6.48 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1414449741128844		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.1414449741128844 | validation: 0.15785491290141226]
	TIME [epoch: 6.47 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14917493183033345		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.14917493183033345 | validation: 0.14573507067314817]
	TIME [epoch: 6.49 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442947755955655		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.1442947755955655 | validation: 0.13178282282002107]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1621.pth
	Model improved!!!
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14759494280999536		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.14759494280999536 | validation: 0.13598744502403567]
	TIME [epoch: 6.56 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14822588968812306		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.14822588968812306 | validation: 0.15315325396363502]
	TIME [epoch: 6.51 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14904810780950767		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.14904810780950767 | validation: 0.14863830445397738]
	TIME [epoch: 6.52 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14251238392111293		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.14251238392111293 | validation: 0.1552496797892817]
	TIME [epoch: 6.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483518662095672		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.1483518662095672 | validation: 0.1531089304821494]
	TIME [epoch: 6.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14172076134058118		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.14172076134058118 | validation: 0.14914274083281828]
	TIME [epoch: 6.49 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14375790188165127		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.14375790188165127 | validation: 0.1460106018216759]
	TIME [epoch: 6.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14363468381484143		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.14363468381484143 | validation: 0.14469183081627565]
	TIME [epoch: 6.48 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14166376603132919		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.14166376603132919 | validation: 0.14497319676715106]
	TIME [epoch: 6.52 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14074330232115795		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.14074330232115795 | validation: 0.14745853345370097]
	TIME [epoch: 6.51 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14483335362117888		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.14483335362117888 | validation: 0.149315136487254]
	TIME [epoch: 6.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1407535959098648		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.1407535959098648 | validation: 0.1595896568300205]
	TIME [epoch: 6.49 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14370716566335884		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.14370716566335884 | validation: 0.13912227071331887]
	TIME [epoch: 6.49 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432547435313242		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.1432547435313242 | validation: 0.15884107977785353]
	TIME [epoch: 6.48 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14098420857918692		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.14098420857918692 | validation: 0.15487793781720618]
	TIME [epoch: 6.47 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14413389617437183		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.14413389617437183 | validation: 0.14192361067498296]
	TIME [epoch: 6.51 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14677626343990371		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.14677626343990371 | validation: 0.15063572617175586]
	TIME [epoch: 6.52 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428226241004207		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.1428226241004207 | validation: 0.15176303001164446]
	TIME [epoch: 6.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14154963009580668		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.14154963009580668 | validation: 0.14252682051813267]
	TIME [epoch: 6.48 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14078905758261312		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.14078905758261312 | validation: 0.13580996688282146]
	TIME [epoch: 6.49 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144964003280568		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.144964003280568 | validation: 0.1431694177578965]
	TIME [epoch: 6.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14512682214390904		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.14512682214390904 | validation: 0.1499418903498238]
	TIME [epoch: 6.49 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14548852953656521		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.14548852953656521 | validation: 0.1492957716112986]
	TIME [epoch: 6.49 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14785155433278033		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.14785155433278033 | validation: 0.1563830962427835]
	TIME [epoch: 6.53 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14657052583634533		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.14657052583634533 | validation: 0.1455555759246839]
	TIME [epoch: 6.48 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14176300068660924		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.14176300068660924 | validation: 0.15897319416056296]
	TIME [epoch: 6.49 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13980636589495474		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.13980636589495474 | validation: 0.15607371782086127]
	TIME [epoch: 6.48 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14766605247381814		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.14766605247381814 | validation: 0.14787882951667533]
	TIME [epoch: 6.47 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433148916704981		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.1433148916704981 | validation: 0.15195234476123765]
	TIME [epoch: 6.48 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14084657930052946		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.14084657930052946 | validation: 0.1494982756395146]
	TIME [epoch: 6.48 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14107597105804753		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.14107597105804753 | validation: 0.15770929785385002]
	TIME [epoch: 6.51 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14523013124084477		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.14523013124084477 | validation: 0.14431821203498182]
	TIME [epoch: 6.48 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14639109140741685		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.14639109140741685 | validation: 0.15441496780533084]
	TIME [epoch: 6.48 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14429848038940585		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.14429848038940585 | validation: 0.15206141765973127]
	TIME [epoch: 6.47 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14768098361778814		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.14768098361778814 | validation: 0.14858128316108773]
	TIME [epoch: 6.49 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13983201158575606		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.13983201158575606 | validation: 0.14870469206959333]
	TIME [epoch: 6.49 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14223978380769348		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.14223978380769348 | validation: 0.15171869498052054]
	TIME [epoch: 6.49 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13950918509938645		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.13950918509938645 | validation: 0.1478357757368123]
	TIME [epoch: 6.53 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437743070783496		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.1437743070783496 | validation: 0.14339556768806225]
	TIME [epoch: 6.48 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14339434199100382		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.14339434199100382 | validation: 0.146899031428431]
	TIME [epoch: 6.47 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14412455048166556		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.14412455048166556 | validation: 0.14258764118489065]
	TIME [epoch: 6.48 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14316817946741917		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.14316817946741917 | validation: 0.14701924253933876]
	TIME [epoch: 6.49 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441645149750939		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.1441645149750939 | validation: 0.14737364646500117]
	TIME [epoch: 6.48 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14219595486666584		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.14219595486666584 | validation: 0.14969444854445743]
	TIME [epoch: 6.49 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14480438813301155		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.14480438813301155 | validation: 0.1565926114766027]
	TIME [epoch: 6.53 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14506702650034076		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.14506702650034076 | validation: 0.14833128372858445]
	TIME [epoch: 6.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14570024480045948		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.14570024480045948 | validation: 0.15419146511412873]
	TIME [epoch: 6.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479382833186713		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.1479382833186713 | validation: 0.1473914210825162]
	TIME [epoch: 6.49 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14624997884800928		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.14624997884800928 | validation: 0.1535616168422037]
	TIME [epoch: 6.48 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15567749559851501		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.15567749559851501 | validation: 0.16055784702053058]
	TIME [epoch: 6.49 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14800239294680045		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.14800239294680045 | validation: 0.15112529247101025]
	TIME [epoch: 6.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14805231682286701		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.14805231682286701 | validation: 0.15107375223640124]
	TIME [epoch: 6.52 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14791109681447193		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.14791109681447193 | validation: 0.15174270833343884]
	TIME [epoch: 6.48 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460789586999018		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.1460789586999018 | validation: 0.14630320641233044]
	TIME [epoch: 6.49 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14451322915232237		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.14451322915232237 | validation: 0.1440115973132595]
	TIME [epoch: 6.49 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14631909841522597		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.14631909841522597 | validation: 0.14826844109085185]
	TIME [epoch: 6.49 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.145167155868711		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.145167155868711 | validation: 0.14565261147892378]
	TIME [epoch: 6.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14351128853939712		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.14351128853939712 | validation: 0.14589109196831207]
	TIME [epoch: 6.49 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14105491820013796		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.14105491820013796 | validation: 0.13945801902994048]
	TIME [epoch: 6.52 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14357399682594735		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.14357399682594735 | validation: 0.14999931103490205]
	TIME [epoch: 6.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449921402552525		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.1449921402552525 | validation: 0.14462626397364461]
	TIME [epoch: 6.48 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14159859271220945		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.14159859271220945 | validation: 0.15306395686830362]
	TIME [epoch: 6.48 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14217552871898753		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.14217552871898753 | validation: 0.15623955504067458]
	TIME [epoch: 6.49 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441065109343142		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.1441065109343142 | validation: 0.15465883219274848]
	TIME [epoch: 6.48 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424250163664428		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.1424250163664428 | validation: 0.1457717193122991]
	TIME [epoch: 6.49 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14404838884084617		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.14404838884084617 | validation: 0.15925264171944334]
	TIME [epoch: 6.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418912606528525		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.1418912606528525 | validation: 0.14623509159704254]
	TIME [epoch: 6.52 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14491169449195362		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.14491169449195362 | validation: 0.14176544357597945]
	TIME [epoch: 6.49 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14229119713691715		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.14229119713691715 | validation: 0.1446416101296397]
	TIME [epoch: 6.49 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14268288534670398		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.14268288534670398 | validation: 0.15439069080968065]
	TIME [epoch: 6.49 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14056044855807612		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.14056044855807612 | validation: 0.14677009577038566]
	TIME [epoch: 6.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14302054464421565		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.14302054464421565 | validation: 0.15732260694379405]
	TIME [epoch: 6.49 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14993891045739105		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.14993891045739105 | validation: 0.15446692155669325]
	TIME [epoch: 6.51 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459795455306796		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.1459795455306796 | validation: 0.15590707239980423]
	TIME [epoch: 6.51 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1472531636970895		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.1472531636970895 | validation: 0.1553790069558113]
	TIME [epoch: 6.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14107050705653532		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.14107050705653532 | validation: 0.14154159316179984]
	TIME [epoch: 6.49 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448603922410775		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.1448603922410775 | validation: 0.1416887217458747]
	TIME [epoch: 6.47 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13892465604155702		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.13892465604155702 | validation: 0.14788394908166683]
	TIME [epoch: 6.49 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14439101297789633		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.14439101297789633 | validation: 0.13903734147837343]
	TIME [epoch: 6.49 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14424895219819087		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.14424895219819087 | validation: 0.14737009691820643]
	TIME [epoch: 6.52 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1453347627556691		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.1453347627556691 | validation: 0.14257840248513684]
	TIME [epoch: 6.52 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14855791922094058		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.14855791922094058 | validation: 0.14940933505359147]
	TIME [epoch: 6.49 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14409112677008093		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.14409112677008093 | validation: 0.13486196547807353]
	TIME [epoch: 6.48 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464342101432684		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.1464342101432684 | validation: 0.14401442065575787]
	TIME [epoch: 6.48 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14491601582797287		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.14491601582797287 | validation: 0.13866724962353513]
	TIME [epoch: 6.48 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14628622183712953		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.14628622183712953 | validation: 0.14146227463306288]
	TIME [epoch: 6.49 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14949202513842164		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.14949202513842164 | validation: 0.14393277069755991]
	TIME [epoch: 6.47 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1470207315515599		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.1470207315515599 | validation: 0.14306802862714704]
	TIME [epoch: 6.53 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14408617243276536		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.14408617243276536 | validation: 0.14965676378481887]
	TIME [epoch: 6.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14503757797862202		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.14503757797862202 | validation: 0.14649869702013416]
	TIME [epoch: 6.49 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13857755014431689		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.13857755014431689 | validation: 0.12904687442290144]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240310_003100/states/model_tr_study1_1712.pth
	Model improved!!!
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14314872896963857		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.14314872896963857 | validation: 0.1497044626376908]
	TIME [epoch: 6.56 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14683843397644136		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.14683843397644136 | validation: 0.14019469874992468]
	TIME [epoch: 6.47 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14516334230843272		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.14516334230843272 | validation: 0.13643848163429578]
	TIME [epoch: 6.48 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14357939066345876		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.14357939066345876 | validation: 0.1559629735195022]
	TIME [epoch: 6.55 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14725161795345681		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.14725161795345681 | validation: 0.14757300695994816]
	TIME [epoch: 6.49 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14721332306821114		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.14721332306821114 | validation: 0.14979783906709188]
	TIME [epoch: 6.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14332121245864898		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.14332121245864898 | validation: 0.148792747814749]
	TIME [epoch: 6.48 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14011359430538803		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.14011359430538803 | validation: 0.1505462386034665]
	TIME [epoch: 6.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14087100157462656		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.14087100157462656 | validation: 0.14715842715553965]
	TIME [epoch: 6.49 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14343196497432176		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.14343196497432176 | validation: 0.1459976573281143]
	TIME [epoch: 6.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14668513321483886		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.14668513321483886 | validation: 0.14637796086358867]
	TIME [epoch: 6.52 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1458797525803569		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.1458797525803569 | validation: 0.15037489909450963]
	TIME [epoch: 6.48 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448859069978033		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.1448859069978033 | validation: 0.16057819565145606]
	TIME [epoch: 6.48 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14144767012932324		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.14144767012932324 | validation: 0.14941945134481555]
	TIME [epoch: 6.48 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1451319572528918		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.1451319572528918 | validation: 0.1458918904789985]
	TIME [epoch: 6.48 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14610450982980427		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.14610450982980427 | validation: 0.15678918453763432]
	TIME [epoch: 6.47 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14212673480457375		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.14212673480457375 | validation: 0.15183446183569368]
	TIME [epoch: 6.47 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14832897562886188		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.14832897562886188 | validation: 0.1688907041090441]
	TIME [epoch: 6.54 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486897622295644		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.1486897622295644 | validation: 0.16342716729645368]
	TIME [epoch: 6.48 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14569001645778595		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.14569001645778595 | validation: 0.1581548269962484]
	TIME [epoch: 6.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14594309077016057		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.14594309077016057 | validation: 0.144924334172276]
	TIME [epoch: 6.48 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14178242755322104		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.14178242755322104 | validation: 0.1446930973338414]
	TIME [epoch: 6.49 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140568507710016		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.140568507710016 | validation: 0.14887965978837603]
	TIME [epoch: 6.47 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14563636306143107		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.14563636306143107 | validation: 0.14616672433516337]
	TIME [epoch: 6.48 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14779564451522595		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.14779564451522595 | validation: 0.14956427932907437]
	TIME [epoch: 6.53 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14948201981400855		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.14948201981400855 | validation: 0.15905321689576224]
	TIME [epoch: 6.48 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14930151218135343		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.14930151218135343 | validation: 0.14463424499980157]
	TIME [epoch: 6.48 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14120671870881574		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.14120671870881574 | validation: 0.1462805826850786]
	TIME [epoch: 6.47 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14422008185232688		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.14422008185232688 | validation: 0.14825742764075603]
	TIME [epoch: 6.46 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14583407524716427		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.14583407524716427 | validation: 0.14994120413920503]
	TIME [epoch: 6.49 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14625490235909733		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.14625490235909733 | validation: 0.14838628836678086]
	TIME [epoch: 6.47 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14430216052226358		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.14430216052226358 | validation: 0.14737935330908034]
	TIME [epoch: 6.53 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140326962433096		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.140326962433096 | validation: 0.14701645025363225]
	TIME [epoch: 6.49 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14427058535603265		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.14427058535603265 | validation: 0.13982730579425692]
	TIME [epoch: 6.47 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14076985781898377		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.14076985781898377 | validation: 0.14249421791727668]
	TIME [epoch: 6.49 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14266334519323806		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.14266334519323806 | validation: 0.14532180290375935]
	TIME [epoch: 6.49 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437614314855028		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.1437614314855028 | validation: 0.13450641185156528]
	TIME [epoch: 6.49 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13962490095720256		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.13962490095720256 | validation: 0.14921888757830412]
	TIME [epoch: 6.49 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1426083813012246		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.1426083813012246 | validation: 0.1428330375753326]
	TIME [epoch: 6.52 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14309455120243217		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.14309455120243217 | validation: 0.14168748051923755]
	TIME [epoch: 6.49 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14036577619491894		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.14036577619491894 | validation: 0.14709697498504723]
	TIME [epoch: 6.48 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13960775957771493		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.13960775957771493 | validation: 0.13991484511299956]
	TIME [epoch: 6.48 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14004377860759437		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.14004377860759437 | validation: 0.14533860114987268]
	TIME [epoch: 6.49 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1413299381580937		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.1413299381580937 | validation: 0.13668928279781362]
	TIME [epoch: 6.49 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13816878192777343		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.13816878192777343 | validation: 0.1412216642220505]
	TIME [epoch: 6.48 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13948136051361085		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.13948136051361085 | validation: 0.14615155788563006]
	TIME [epoch: 6.51 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14035068620327812		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.14035068620327812 | validation: 0.15164610483619165]
	TIME [epoch: 6.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14225447429217936		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.14225447429217936 | validation: 0.14684730080011085]
	TIME [epoch: 6.49 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14435540816169104		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.14435540816169104 | validation: 0.14154804936649742]
	TIME [epoch: 6.48 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14391979892962614		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.14391979892962614 | validation: 0.13934797494160336]
	TIME [epoch: 6.47 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461783621621608		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.1461783621621608 | validation: 0.14027185413747142]
	TIME [epoch: 6.48 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13853841582246595		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.13853841582246595 | validation: 0.1462086269180248]
	TIME [epoch: 6.49 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13899279616872054		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.13899279616872054 | validation: 0.1453557866434331]
	TIME [epoch: 6.51 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391307974648603		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.1391307974648603 | validation: 0.1472304817256989]
	TIME [epoch: 6.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14273258920431234		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.14273258920431234 | validation: 0.14724875353181532]
	TIME [epoch: 6.49 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14365643033816444		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.14365643033816444 | validation: 0.14291304745112698]
	TIME [epoch: 6.49 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14330562854342938		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.14330562854342938 | validation: 0.1435366645226883]
	TIME [epoch: 6.51 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14145832379945533		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.14145832379945533 | validation: 0.14164736565477307]
	TIME [epoch: 6.54 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14516024701508662		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.14516024701508662 | validation: 0.14222693294703231]
	TIME [epoch: 6.58 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13967907776640118		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.13967907776640118 | validation: 0.1525542735579149]
	TIME [epoch: 6.56 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14178141683308595		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.14178141683308595 | validation: 0.14551494943938337]
	TIME [epoch: 6.54 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1387130390804101		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.1387130390804101 | validation: 0.14464340382924268]
	TIME [epoch: 6.48 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14066445259576357		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.14066445259576357 | validation: 0.15107229593826996]
	TIME [epoch: 6.49 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1388734875561181		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.1388734875561181 | validation: 0.14896156066143898]
	TIME [epoch: 6.52 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14153580978524544		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.14153580978524544 | validation: 0.14470084813768846]
	TIME [epoch: 6.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14187219773001267		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.14187219773001267 | validation: 0.14404565912883568]
	TIME [epoch: 6.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14220258232835933		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.14220258232835933 | validation: 0.14498246583135999]
	TIME [epoch: 6.51 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13923434630788312		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.13923434630788312 | validation: 0.14691228034426979]
	TIME [epoch: 6.53 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13953570194319348		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.13953570194319348 | validation: 0.14448275855228324]
	TIME [epoch: 6.51 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1423508542078666		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.1423508542078666 | validation: 0.14605928321471356]
	TIME [epoch: 6.52 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14514835317469435		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.14514835317469435 | validation: 0.14734131625092617]
	TIME [epoch: 6.49 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14236898968382444		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.14236898968382444 | validation: 0.14448032140831177]
	TIME [epoch: 6.49 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14309400377301595		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.14309400377301595 | validation: 0.15231122580262327]
	TIME [epoch: 6.49 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14171687411167583		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.14171687411167583 | validation: 0.15507282623551444]
	TIME [epoch: 6.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13941356255424803		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.13941356255424803 | validation: 0.14420184506152006]
	TIME [epoch: 6.55 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14396285854679752		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.14396285854679752 | validation: 0.14949063370215068]
	TIME [epoch: 6.51 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14316462133525062		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.14316462133525062 | validation: 0.14742098479915078]
	TIME [epoch: 6.52 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14221425905081397		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.14221425905081397 | validation: 0.137165933265318]
	TIME [epoch: 6.51 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1431393418792235		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.1431393418792235 | validation: 0.14010325372777982]
	TIME [epoch: 6.49 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13906388451571117		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.13906388451571117 | validation: 0.1411845662736913]
	TIME [epoch: 6.47 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14313210197834153		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.14313210197834153 | validation: 0.14390699608251198]
	TIME [epoch: 6.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1423644227990119		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.1423644227990119 | validation: 0.1413722119453]
	TIME [epoch: 6.55 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14080513621001142		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.14080513621001142 | validation: 0.14392352272152267]
	TIME [epoch: 6.51 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14252075155894173		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.14252075155894173 | validation: 0.1391959615367031]
	TIME [epoch: 6.49 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13958209127628401		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.13958209127628401 | validation: 0.14395955412999764]
	TIME [epoch: 6.49 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14373062230374878		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.14373062230374878 | validation: 0.14138798405375125]
	TIME [epoch: 6.49 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1405376779739579		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.1405376779739579 | validation: 0.13785579233970877]
	TIME [epoch: 6.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13983680903675155		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.13983680903675155 | validation: 0.1426293491901779]
	TIME [epoch: 6.48 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13922753930297066		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.13922753930297066 | validation: 0.143406409124112]
	TIME [epoch: 6.55 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13814722704284785		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.13814722704284785 | validation: 0.14633648831785134]
	TIME [epoch: 6.52 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13789692525125608		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.13789692525125608 | validation: 0.1430148708248993]
	TIME [epoch: 6.58 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1413592409115185		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.1413592409115185 | validation: 0.13710167144215288]
	TIME [epoch: 6.55 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14244395976176177		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.14244395976176177 | validation: 0.1417718598750577]
	TIME [epoch: 6.52 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14326834517631543		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.14326834517631543 | validation: 0.14347894561238447]
	TIME [epoch: 6.51 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438355968085061		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.1438355968085061 | validation: 0.15074085791304354]
	TIME [epoch: 6.49 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14328110313180242		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.14328110313180242 | validation: 0.13909692509038235]
	TIME [epoch: 6.54 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14474661626195798		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.14474661626195798 | validation: 0.14633224663046016]
	TIME [epoch: 6.49 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396712307797007		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.1396712307797007 | validation: 0.14827772860857072]
	TIME [epoch: 6.51 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14360856751393086		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.14360856751393086 | validation: 0.14940762481592962]
	TIME [epoch: 6.49 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14250328774007856		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.14250328774007856 | validation: 0.13756997440687627]
	TIME [epoch: 6.52 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14072376023069053		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.14072376023069053 | validation: 0.14454572514217293]
	TIME [epoch: 6.51 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14363963764319362		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.14363963764319362 | validation: 0.14823180568417563]
	TIME [epoch: 6.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1444182520250387		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.1444182520250387 | validation: 0.14371187495122725]
	TIME [epoch: 6.55 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14093741039337745		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.14093741039337745 | validation: 0.14025734355467862]
	TIME [epoch: 6.49 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14085651365178978		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.14085651365178978 | validation: 0.1528213523133483]
	TIME [epoch: 6.51 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1378280725357404		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.1378280725357404 | validation: 0.14996795253138173]
	TIME [epoch: 6.51 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13876629292695764		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.13876629292695764 | validation: 0.15094358106328581]
	TIME [epoch: 6.49 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140389338362938		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.140389338362938 | validation: 0.150878297156047]
	TIME [epoch: 6.52 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13884211546828196		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.13884211546828196 | validation: 0.15264182193829162]
	TIME [epoch: 6.49 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140903182230042		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.140903182230042 | validation: 0.14621298781187897]
	TIME [epoch: 6.56 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1423495423669819		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.1423495423669819 | validation: 0.1597717466383652]
	TIME [epoch: 6.51 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1439724245110364		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.1439724245110364 | validation: 0.1517785306597687]
	TIME [epoch: 6.51 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14314043361887807		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.14314043361887807 | validation: 0.15052247615811967]
	TIME [epoch: 6.49 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13769520050174666		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.13769520050174666 | validation: 0.1489362313108812]
	TIME [epoch: 6.51 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14187965137242842		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.14187965137242842 | validation: 0.15550306032710587]
	TIME [epoch: 6.54 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396865062462266		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.1396865062462266 | validation: 0.15000978070943816]
	TIME [epoch: 6.51 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14007055165182097		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.14007055165182097 | validation: 0.1496928202184804]
	TIME [epoch: 6.54 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14197050712723405		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.14197050712723405 | validation: 0.14918816988059455]
	TIME [epoch: 6.52 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1454925133291712		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.1454925133291712 | validation: 0.1379494411866594]
	TIME [epoch: 6.56 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13799577816643602		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.13799577816643602 | validation: 0.14817053313927797]
	TIME [epoch: 6.55 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14041874451747008		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.14041874451747008 | validation: 0.14944651801747802]
	TIME [epoch: 6.53 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13876459995726445		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.13876459995726445 | validation: 0.14318894436517904]
	TIME [epoch: 6.53 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13932998156804338		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.13932998156804338 | validation: 0.1469196643220053]
	TIME [epoch: 6.59 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13853036055497425		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.13853036055497425 | validation: 0.15016835471589182]
	TIME [epoch: 6.62 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1367903446542758		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.1367903446542758 | validation: 0.14468627995070849]
	TIME [epoch: 6.58 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379828977403314		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.1379828977403314 | validation: 0.13984671216531283]
	TIME [epoch: 6.52 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13755813220979965		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.13755813220979965 | validation: 0.1458414972457563]
	TIME [epoch: 6.51 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394021330994611		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.1394021330994611 | validation: 0.1420380078557465]
	TIME [epoch: 6.47 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14026693316134517		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.14026693316134517 | validation: 0.14019006279302312]
	TIME [epoch: 6.53 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383495697669169		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.1383495697669169 | validation: 0.15136568852892407]
	TIME [epoch: 6.52 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14571466483390216		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.14571466483390216 | validation: 0.15662666654680663]
	TIME [epoch: 6.52 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410989232160048		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.1410989232160048 | validation: 0.14521173056777528]
	TIME [epoch: 6.51 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13825711760814746		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.13825711760814746 | validation: 0.15486544033027783]
	TIME [epoch: 6.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14555757840401834		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.14555757840401834 | validation: 0.154182474978355]
	TIME [epoch: 6.49 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14347067893102786		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.14347067893102786 | validation: 0.14647316077479292]
	TIME [epoch: 6.48 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14341684442584832		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.14341684442584832 | validation: 0.14854150212183173]
	TIME [epoch: 6.52 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1476164112866575		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.1476164112866575 | validation: 0.15342701140076964]
	TIME [epoch: 6.53 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14910219438838263		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.14910219438838263 | validation: 0.14839143163006163]
	TIME [epoch: 6.55 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14717463518185706		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.14717463518185706 | validation: 0.15154615918249012]
	TIME [epoch: 6.55 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1444575354950865		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.1444575354950865 | validation: 0.13616398463244522]
	TIME [epoch: 6.49 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13978857430581743		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.13978857430581743 | validation: 0.14076971271770258]
	TIME [epoch: 6.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13475387380109988		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.13475387380109988 | validation: 0.14351391091341373]
	TIME [epoch: 6.48 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13951203099355305		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.13951203099355305 | validation: 0.1422942381787544]
	TIME [epoch: 6.49 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14029986443869225		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.14029986443869225 | validation: 0.1339569764263084]
	TIME [epoch: 6.49 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13865005437419387		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.13865005437419387 | validation: 0.15099796368487828]
	TIME [epoch: 6.52 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14242503605514073		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.14242503605514073 | validation: 0.14242326030786376]
	TIME [epoch: 6.54 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14306733603910743		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.14306733603910743 | validation: 0.14166224594545587]
	TIME [epoch: 6.51 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13716171861845922		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.13716171861845922 | validation: 0.1483307601650052]
	TIME [epoch: 6.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1445065495128963		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.1445065495128963 | validation: 0.14815019967918167]
	TIME [epoch: 6.51 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14362848264995565		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.14362848264995565 | validation: 0.1404753904187169]
	TIME [epoch: 6.49 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398413082044515		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.1398413082044515 | validation: 0.1415397831485667]
	TIME [epoch: 6.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477631187378529		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.1477631187378529 | validation: 0.13597201897719138]
	TIME [epoch: 6.53 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14278381211658145		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.14278381211658145 | validation: 0.15312280338793524]
	TIME [epoch: 6.55 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408371708525954		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.1408371708525954 | validation: 0.1451293324882285]
	TIME [epoch: 6.52 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381284073265243		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.1381284073265243 | validation: 0.14639890134852174]
	TIME [epoch: 6.49 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13775582434064534		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.13775582434064534 | validation: 0.14968941127719643]
	TIME [epoch: 6.48 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394257259689232		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.1394257259689232 | validation: 0.1527929574772022]
	TIME [epoch: 6.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14340313998480148		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.14340313998480148 | validation: 0.14880997613120112]
	TIME [epoch: 6.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1416728974465372		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.1416728974465372 | validation: 0.1439896813454366]
	TIME [epoch: 6.49 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14081577114956056		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.14081577114956056 | validation: 0.14177612441236725]
	TIME [epoch: 6.52 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14214028166658982		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.14214028166658982 | validation: 0.14151790808828504]
	TIME [epoch: 6.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.137578257885705		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.137578257885705 | validation: 0.14839448580566839]
	TIME [epoch: 6.49 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142514087923701		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.142514087923701 | validation: 0.1441150914495213]
	TIME [epoch: 6.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14280644128877074		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.14280644128877074 | validation: 0.14641080381718974]
	TIME [epoch: 6.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13909388490084812		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.13909388490084812 | validation: 0.14158434247887466]
	TIME [epoch: 6.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428709971142989		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.1428709971142989 | validation: 0.1444240130269723]
	TIME [epoch: 6.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14116229301123445		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.14116229301123445 | validation: 0.1471556379173031]
	TIME [epoch: 6.55 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13870914158533637		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.13870914158533637 | validation: 0.1412395713557329]
	TIME [epoch: 6.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13872573142678185		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.13872573142678185 | validation: 0.15054759187281605]
	TIME [epoch: 6.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13968562145264143		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.13968562145264143 | validation: 0.14583755106909613]
	TIME [epoch: 6.49 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1417076067906285		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.1417076067906285 | validation: 0.1444968086202704]
	TIME [epoch: 6.49 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140317516303685		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.140317516303685 | validation: 0.1376404291841971]
	TIME [epoch: 6.58 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14235708350776177		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.14235708350776177 | validation: 0.14563018305575812]
	TIME [epoch: 6.59 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13957382883803146		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.13957382883803146 | validation: 0.14594134547471455]
	TIME [epoch: 6.55 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13889159640921322		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.13889159640921322 | validation: 0.14038652817972375]
	TIME [epoch: 6.49 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13932549299508143		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.13932549299508143 | validation: 0.1436217471266962]
	TIME [epoch: 6.47 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13655257928625616		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.13655257928625616 | validation: 0.14974113522991392]
	TIME [epoch: 6.48 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14057895305200502		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.14057895305200502 | validation: 0.1524760324558011]
	TIME [epoch: 6.48 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14014653294050838		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.14014653294050838 | validation: 0.13872281924616953]
	TIME [epoch: 6.47 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13685541220665048		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.13685541220665048 | validation: 0.14255072708132016]
	TIME [epoch: 6.47 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13736194145326625		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.13736194145326625 | validation: 0.15237264537498946]
	TIME [epoch: 6.54 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14195054079829356		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.14195054079829356 | validation: 0.13306156195420088]
	TIME [epoch: 6.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13846103923361686		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.13846103923361686 | validation: 0.1464078701164543]
	TIME [epoch: 6.48 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13967783825441815		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.13967783825441815 | validation: 0.1431740557552526]
	TIME [epoch: 6.49 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13987902129274926		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.13987902129274926 | validation: 0.14623088692860853]
	TIME [epoch: 6.49 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1414195211832655		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.1414195211832655 | validation: 0.14479326025771713]
	TIME [epoch: 6.49 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14324228096209202		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.14324228096209202 | validation: 0.14657333481509408]
	TIME [epoch: 6.49 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14370241915277554		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.14370241915277554 | validation: 0.14072719219758661]
	TIME [epoch: 6.55 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14019071338896605		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.14019071338896605 | validation: 0.1468938089329183]
	TIME [epoch: 6.52 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13945197117039576		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.13945197117039576 | validation: 0.13302604703203805]
	TIME [epoch: 6.48 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13863899671387658		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.13863899671387658 | validation: 0.14599218614723636]
	TIME [epoch: 6.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14262945168393099		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.14262945168393099 | validation: 0.14709366666358045]
	TIME [epoch: 6.51 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14229534795578033		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.14229534795578033 | validation: 0.14224185375163384]
	TIME [epoch: 6.49 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13893301971065145		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.13893301971065145 | validation: 0.1459992577528973]
	TIME [epoch: 6.49 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13933402447801047		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.13933402447801047 | validation: 0.14676671750214135]
	TIME [epoch: 6.54 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14177569942305598		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.14177569942305598 | validation: 0.15016774323289697]
	TIME [epoch: 6.51 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14312094162612377		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.14312094162612377 | validation: 0.1449231504740209]
	TIME [epoch: 6.49 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1366159264738956		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.1366159264738956 | validation: 0.15481851156345522]
	TIME [epoch: 6.51 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441910066749693		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.1441910066749693 | validation: 0.14966028062653844]
	TIME [epoch: 6.51 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459325274530627		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.1459325274530627 | validation: 0.14333420512219713]
	TIME [epoch: 6.48 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14224148473497875		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.14224148473497875 | validation: 0.14902546654086749]
	TIME [epoch: 6.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14338029271663275		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.14338029271663275 | validation: 0.1416653388327655]
	TIME [epoch: 6.52 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14291517619701602		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.14291517619701602 | validation: 0.14501135678716842]
	TIME [epoch: 6.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14111493683889123		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.14111493683889123 | validation: 0.14300926695999958]
	TIME [epoch: 6.49 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13769314887817646		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.13769314887817646 | validation: 0.14373750970808086]
	TIME [epoch: 6.49 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424311690604554		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.1424311690604554 | validation: 0.14972113685995705]
	TIME [epoch: 6.49 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377987969370809		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.1377987969370809 | validation: 0.14340067772371506]
	TIME [epoch: 6.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13819412232623554		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.13819412232623554 | validation: 0.13662927671720707]
	TIME [epoch: 6.49 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411853036825304		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.1411853036825304 | validation: 0.14516942059387292]
	TIME [epoch: 6.51 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14066092809619665		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.14066092809619665 | validation: 0.1417529589319938]
	TIME [epoch: 6.48 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13755545259198326		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.13755545259198326 | validation: 0.13913363911270865]
	TIME [epoch: 6.47 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1407433539602606		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.1407433539602606 | validation: 0.14653495343657955]
	TIME [epoch: 6.48 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13961258065474852		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.13961258065474852 | validation: 0.14408576505481416]
	TIME [epoch: 6.49 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13969837796072693		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.13969837796072693 | validation: 0.14756148664455007]
	TIME [epoch: 6.47 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14158626288390833		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.14158626288390833 | validation: 0.14985051839835825]
	TIME [epoch: 6.47 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1416484564186628		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.1416484564186628 | validation: 0.14176228715438924]
	TIME [epoch: 6.49 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14248195980725384		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.14248195980725384 | validation: 0.1404953454639153]
	TIME [epoch: 6.51 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14095489484809925		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.14095489484809925 | validation: 0.14313363682220176]
	TIME [epoch: 6.49 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13483835547956613		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.13483835547956613 | validation: 0.1476620811191597]
	TIME [epoch: 6.49 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.137850990703006		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.137850990703006 | validation: 0.14376942305788884]
	TIME [epoch: 6.47 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14166344062483283		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.14166344062483283 | validation: 0.14642566318157507]
	TIME [epoch: 6.48 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13463746809541027		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.13463746809541027 | validation: 0.14640385186493038]
	TIME [epoch: 6.48 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13961879299717678		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.13961879299717678 | validation: 0.1462755200250793]
	TIME [epoch: 6.49 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14147489386033726		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.14147489386033726 | validation: 0.14010268541511953]
	TIME [epoch: 6.51 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13996662517042735		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.13996662517042735 | validation: 0.14394588725927246]
	TIME [epoch: 6.49 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13883570547295326		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.13883570547295326 | validation: 0.14107448574534706]
	TIME [epoch: 6.48 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13957458999911265		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.13957458999911265 | validation: 0.14323902868668104]
	TIME [epoch: 6.47 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14192363861616897		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.14192363861616897 | validation: 0.14244404135269026]
	TIME [epoch: 6.48 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398130096387993		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.1398130096387993 | validation: 0.1516191778946725]
	TIME [epoch: 6.48 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1367834806337171		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.1367834806337171 | validation: 0.14729341666037005]
	TIME [epoch: 6.49 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1419188147834392		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.1419188147834392 | validation: 0.1539953294342473]
	TIME [epoch: 6.52 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374593344805403		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.1374593344805403 | validation: 0.14496095561980016]
	TIME [epoch: 6.49 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410507614855417		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.1410507614855417 | validation: 0.14518982089450114]
	TIME [epoch: 6.49 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14032212095583668		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.14032212095583668 | validation: 0.14604757530580842]
	TIME [epoch: 6.49 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1415973191801762		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.1415973191801762 | validation: 0.1496685189678397]
	TIME [epoch: 6.48 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400625642539044		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.1400625642539044 | validation: 0.15256853682270005]
	TIME [epoch: 6.48 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14731524881329539		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.14731524881329539 | validation: 0.1557811707007314]
	TIME [epoch: 6.49 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14426408898131493		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.14426408898131493 | validation: 0.1551702181922461]
	TIME [epoch: 6.52 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144734775436575		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.144734775436575 | validation: 0.14204813426953836]
	TIME [epoch: 6.49 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14102658233683013		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.14102658233683013 | validation: 0.14510214288740778]
	TIME [epoch: 6.48 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433028914248411		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.1433028914248411 | validation: 0.1511856213610732]
	TIME [epoch: 6.49 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14128146495130567		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.14128146495130567 | validation: 0.1374054853618373]
	TIME [epoch: 6.49 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369249178196584		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.1369249178196584 | validation: 0.1361355580036228]
	TIME [epoch: 6.49 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13791685866996367		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.13791685866996367 | validation: 0.1401637670640331]
	TIME [epoch: 6.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14313365946778617		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.14313365946778617 | validation: 0.14754537285313704]
	TIME [epoch: 6.54 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14001178336974676		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.14001178336974676 | validation: 0.14048510728836547]
	TIME [epoch: 6.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14230591717163268		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.14230591717163268 | validation: 0.1400077854571151]
	TIME [epoch: 6.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394364467467083		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.1394364467467083 | validation: 0.1387196529344524]
	TIME [epoch: 6.49 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13413136080744123		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.13413136080744123 | validation: 0.14611811132085095]
	TIME [epoch: 6.51 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350293109021123		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.1350293109021123 | validation: 0.1416497585075192]
	TIME [epoch: 6.51 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14038686051964058		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.14038686051964058 | validation: 0.13757143160100008]
	TIME [epoch: 6.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13679068139915507		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.13679068139915507 | validation: 0.13913200614387503]
	TIME [epoch: 6.54 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13748231434056535		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.13748231434056535 | validation: 0.14463239835698663]
	TIME [epoch: 6.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14230979119257436		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.14230979119257436 | validation: 0.1378998282950518]
	TIME [epoch: 6.47 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13572611943441004		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.13572611943441004 | validation: 0.1427017053456956]
	TIME [epoch: 6.48 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14085840000304195		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.14085840000304195 | validation: 0.14491971959269936]
	TIME [epoch: 6.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13749643465318231		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.13749643465318231 | validation: 0.14311885909114716]
	TIME [epoch: 6.48 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136714711265346		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.136714711265346 | validation: 0.13693134325502143]
	TIME [epoch: 6.49 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14030785269182647		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.14030785269182647 | validation: 0.1386028841971925]
	TIME [epoch: 6.53 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13843480341109998		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.13843480341109998 | validation: 0.15163617317622147]
	TIME [epoch: 6.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13824848974385698		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.13824848974385698 | validation: 0.1457516360369898]
	TIME [epoch: 6.51 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383012204082961		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.1383012204082961 | validation: 0.1503655384753358]
	TIME [epoch: 6.51 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13823293164782588		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.13823293164782588 | validation: 0.1433241813157979]
	TIME [epoch: 6.49 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13727839122423813		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.13727839122423813 | validation: 0.1485118427685271]
	TIME [epoch: 6.49 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13759809202766238		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.13759809202766238 | validation: 0.1497608973725874]
	TIME [epoch: 6.48 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14131054743944077		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.14131054743944077 | validation: 0.14174036051481842]
	TIME [epoch: 6.52 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13980617340202395		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.13980617340202395 | validation: 0.1548418387684776]
	TIME [epoch: 6.54 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13871287787883496		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.13871287787883496 | validation: 0.1470386267219261]
	TIME [epoch: 6.61 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14018408099697954		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.14018408099697954 | validation: 0.14616347659649676]
	TIME [epoch: 6.59 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402531859693328		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.1402531859693328 | validation: 0.14636982195279674]
	TIME [epoch: 6.59 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13745018317796132		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.13745018317796132 | validation: 0.1450557490894888]
	TIME [epoch: 6.52 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380349341209908		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.1380349341209908 | validation: 0.1425760676485308]
	TIME [epoch: 6.49 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402703673429806		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.1402703673429806 | validation: 0.1432600740736621]
	TIME [epoch: 6.52 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13970710194973318		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.13970710194973318 | validation: 0.14381677500695209]
	TIME [epoch: 6.54 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13996901609332352		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.13996901609332352 | validation: 0.14514377127384734]
	TIME [epoch: 6.49 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409483202491733		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.1409483202491733 | validation: 0.14562719999984583]
	TIME [epoch: 6.48 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424751630413326		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.1424751630413326 | validation: 0.14293747686729527]
	TIME [epoch: 6.51 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14058551628900837		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.14058551628900837 | validation: 0.14242101048774186]
	TIME [epoch: 6.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14072920013925322		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.14072920013925322 | validation: 0.1405200973313737]
	TIME [epoch: 6.49 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14048870454882145		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.14048870454882145 | validation: 0.1455698989357504]
	TIME [epoch: 6.55 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14357296558458807		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.14357296558458807 | validation: 0.13808890177963445]
	TIME [epoch: 6.48 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14215499132314371		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.14215499132314371 | validation: 0.13418328735673604]
	TIME [epoch: 6.51 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14112055920529176		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.14112055920529176 | validation: 0.14171923125061114]
	TIME [epoch: 6.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442224910843709		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.1442224910843709 | validation: 0.14363955284892627]
	TIME [epoch: 6.48 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14207082749686079		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.14207082749686079 | validation: 0.1410836939702674]
	TIME [epoch: 6.52 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753582221043492		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.13753582221043492 | validation: 0.13924295366981537]
	TIME [epoch: 6.55 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14226526084059052		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.14226526084059052 | validation: 0.1311487699339909]
	TIME [epoch: 6.52 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411944513147264		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.1411944513147264 | validation: 0.14210692428670077]
	TIME [epoch: 6.59 sec]
Finished training in 14083.295 seconds.
