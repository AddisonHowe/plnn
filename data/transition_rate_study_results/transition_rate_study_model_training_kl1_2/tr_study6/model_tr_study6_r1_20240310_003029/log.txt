Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r1', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3498897602

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.241268681061806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.241268681061806 | validation: 8.096091494858078]
	TIME [epoch: 106 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.411601489677656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.411601489677656 | validation: 6.2636780610649545]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7525978731862235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7525978731862235 | validation: 4.608101045411612]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.919172296184911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.919172296184911 | validation: 3.8901407904963117]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.385467187491332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.385467187491332 | validation: 3.2938869009929035]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.858498977391886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.858498977391886 | validation: 3.5695095291360817]
	TIME [epoch: 27.8 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.305952354021386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.305952354021386 | validation: 2.9645607377935677]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.486856898166982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.486856898166982 | validation: 3.048677432958626]
	TIME [epoch: 27.9 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.805808922742441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.805808922742441 | validation: 2.978529706511679]
	TIME [epoch: 27.9 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.232602127425184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.232602127425184 | validation: 3.066298075350527]
	TIME [epoch: 27.9 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3320354959811835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3320354959811835 | validation: 2.931021952283643]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.341497021139691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.341497021139691 | validation: 2.8550418608401906]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.201148433415496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.201148433415496 | validation: 5.434675027249409]
	TIME [epoch: 27.8 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.259460210911863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.259460210911863 | validation: 3.1022580045966226]
	TIME [epoch: 27.9 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.175842625169003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.175842625169003 | validation: 3.1792897272709584]
	TIME [epoch: 27.8 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.156344950359797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.156344950359797 | validation: 2.813501294529676]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6139609756416884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6139609756416884 | validation: 3.3604125217393648]
	TIME [epoch: 27.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.334920404049379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.334920404049379 | validation: 7.9250219717533765]
	TIME [epoch: 27.8 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.716676872594878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.716676872594878 | validation: 3.1498282914163203]
	TIME [epoch: 27.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.124248050583238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.124248050583238 | validation: 2.948287572798755]
	TIME [epoch: 27.8 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9571490894718364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9571490894718364 | validation: 4.082733312588724]
	TIME [epoch: 27.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.521983088507673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.521983088507673 | validation: 2.835159110111121]
	TIME [epoch: 27.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.151183769411431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.151183769411431 | validation: 3.0787102303972733]
	TIME [epoch: 27.8 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9502572731912027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9502572731912027 | validation: 3.025364268921203]
	TIME [epoch: 27.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0187531438006148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0187531438006148 | validation: 2.8275621352972626]
	TIME [epoch: 27.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9492906919241806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9492906919241806 | validation: 3.029125835653781]
	TIME [epoch: 27.8 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8889370425828735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8889370425828735 | validation: 2.625189657580964]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.280647006124225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.280647006124225 | validation: 2.667236844485995]
	TIME [epoch: 27.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3646272727249498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3646272727249498 | validation: 3.674098101628953]
	TIME [epoch: 27.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1480994920802328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1480994920802328 | validation: 2.716008849057762]
	TIME [epoch: 27.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2155303690778867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2155303690778867 | validation: 2.721148788383183]
	TIME [epoch: 27.8 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.990467767430164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.990467767430164 | validation: 3.062617389215646]
	TIME [epoch: 27.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2793104175005063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2793104175005063 | validation: 2.94024161436398]
	TIME [epoch: 27.8 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.249531825958316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.249531825958316 | validation: 4.103920855523908]
	TIME [epoch: 27.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2370062378942563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2370062378942563 | validation: 2.6572352027446766]
	TIME [epoch: 27.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1598029769230394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1598029769230394 | validation: 3.1637100599670194]
	TIME [epoch: 27.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9904336072899564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9904336072899564 | validation: 3.4333095416447708]
	TIME [epoch: 27.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2510276540688556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2510276540688556 | validation: 2.731508307534434]
	TIME [epoch: 27.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7783949347413044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7783949347413044 | validation: 2.6270742302187275]
	TIME [epoch: 27.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.242649427214719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.242649427214719 | validation: 2.866780885197613]
	TIME [epoch: 27.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7810784064041867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7810784064041867 | validation: 2.528151244123641]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6640004521133496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6640004521133496 | validation: 2.6023377444399007]
	TIME [epoch: 27.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.953023195577552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.953023195577552 | validation: 2.905845834924309]
	TIME [epoch: 27.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.823563284410647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.823563284410647 | validation: 3.4037879623105733]
	TIME [epoch: 27.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9817915729632096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9817915729632096 | validation: 2.782429911296796]
	TIME [epoch: 27.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.062898482140147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.062898482140147 | validation: 3.890486643824751]
	TIME [epoch: 27.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5543617912714836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5543617912714836 | validation: 3.015446600787314]
	TIME [epoch: 27.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7464685976055208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7464685976055208 | validation: 2.3998655891517036]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.75865758890378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.75865758890378 | validation: 2.5545382052209966]
	TIME [epoch: 27.8 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4428402850741504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4428402850741504 | validation: 2.4212024793584948]
	TIME [epoch: 27.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4023459608074798		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.4023459608074798 | validation: 2.1516378680761274]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3427762007297313		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.3427762007297313 | validation: 3.4532353645926155]
	TIME [epoch: 27.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.225960916938717		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.225960916938717 | validation: 3.330669308639646]
	TIME [epoch: 27.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.680114581779326		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.680114581779326 | validation: 4.197169720081704]
	TIME [epoch: 27.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.402669374280108		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.402669374280108 | validation: 2.844579181394414]
	TIME [epoch: 27.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.716757392023139		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.716757392023139 | validation: 2.270983890786191]
	TIME [epoch: 27.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.514185254392898		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.514185254392898 | validation: 3.245669243301835]
	TIME [epoch: 27.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.419511948702032		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.419511948702032 | validation: 4.123798205749191]
	TIME [epoch: 27.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.346291729947842		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.346291729947842 | validation: 2.8854569802508023]
	TIME [epoch: 27.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0327014184355625		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.0327014184355625 | validation: 3.950713743517466]
	TIME [epoch: 27.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1445457352145114		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.1445457352145114 | validation: 2.5410571502494346]
	TIME [epoch: 27.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.506673089202164		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.506673089202164 | validation: 2.3825208781388834]
	TIME [epoch: 27.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3447537486585786		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.3447537486585786 | validation: 2.446809250290322]
	TIME [epoch: 27.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6306250229330788		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.6306250229330788 | validation: 2.5111958852031133]
	TIME [epoch: 27.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5237219282467747		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.5237219282467747 | validation: 3.054805769064688]
	TIME [epoch: 27.8 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.884269622977961		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.884269622977961 | validation: 2.340439856540538]
	TIME [epoch: 27.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.396058156296664		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.396058156296664 | validation: 2.402599125311365]
	TIME [epoch: 27.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5135918378382653		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.5135918378382653 | validation: 3.806598094478535]
	TIME [epoch: 27.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.482179622513588		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.482179622513588 | validation: 2.6992177883946282]
	TIME [epoch: 27.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.74715342487821		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.74715342487821 | validation: 2.425496194750092]
	TIME [epoch: 27.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.502745057805128		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.502745057805128 | validation: 2.8726435553956735]
	TIME [epoch: 27.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5099839807801434		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.5099839807801434 | validation: 2.567613123796846]
	TIME [epoch: 27.8 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4620653847006935		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.4620653847006935 | validation: 2.425557376793068]
	TIME [epoch: 27.8 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5581285199524872		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.5581285199524872 | validation: 2.293024478299927]
	TIME [epoch: 27.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.61232579000833		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.61232579000833 | validation: 3.032220839575381]
	TIME [epoch: 27.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6243915720915254		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.6243915720915254 | validation: 2.1475093176948428]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4268405192439895		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.4268405192439895 | validation: 2.373417692174797]
	TIME [epoch: 27.8 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3752156912355638		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.3752156912355638 | validation: 2.0839154479696664]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4650704897396802		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.4650704897396802 | validation: 2.124172165777493]
	TIME [epoch: 27.9 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1052889188739075		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.1052889188739075 | validation: 1.843490019025625]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9545127090267207		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.9545127090267207 | validation: 2.3543885194456626]
	TIME [epoch: 28 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2580267713851647		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.2580267713851647 | validation: 1.7889498474979408]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.176164135390179		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.176164135390179 | validation: 1.9794060753649283]
	TIME [epoch: 27.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.091198186925842		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.091198186925842 | validation: 1.8420385562548627]
	TIME [epoch: 27.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8693936912130487		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.8693936912130487 | validation: 1.5641283927711027]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.710036835683836		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.710036835683836 | validation: 1.9116816460341841]
	TIME [epoch: 27.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.137842927103941		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.137842927103941 | validation: 1.6281024686993146]
	TIME [epoch: 27.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9640122121146182		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.9640122121146182 | validation: 1.3698100141852882]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.951548579685228		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.951548579685228 | validation: 1.9923598367120283]
	TIME [epoch: 28 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.355287531182476		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.355287531182476 | validation: 1.4960134719195899]
	TIME [epoch: 28 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5017906315499876		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.5017906315499876 | validation: 1.273896340229927]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.549613498427543		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.549613498427543 | validation: 1.544612765277359]
	TIME [epoch: 27.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7863078840820947		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.7863078840820947 | validation: 5.673131785008332]
	TIME [epoch: 27.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.470296629315753		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.470296629315753 | validation: 1.3916551932586925]
	TIME [epoch: 27.8 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2818346697077905		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.2818346697077905 | validation: 1.424544840389452]
	TIME [epoch: 27.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1762568392140773		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.1762568392140773 | validation: 1.5071177702548968]
	TIME [epoch: 27.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3693505908748862		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.3693505908748862 | validation: 1.0199625772380687]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2130047173389773		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.2130047173389773 | validation: 1.1607925446082943]
	TIME [epoch: 27.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9891804164701846		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.9891804164701846 | validation: 1.1012297061159324]
	TIME [epoch: 27.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.205870074285865		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.205870074285865 | validation: 1.6927958778352366]
	TIME [epoch: 27.8 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5827084741067292		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.5827084741067292 | validation: 0.7767181631915995]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.656403154566081		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.656403154566081 | validation: 1.2425257706267672]
	TIME [epoch: 27.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.562954472627215		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.562954472627215 | validation: 2.8885449722304872]
	TIME [epoch: 27.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8877455907883218		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.8877455907883218 | validation: 1.2085411142412081]
	TIME [epoch: 27.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.294830530485099		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.294830530485099 | validation: 0.8779489156205472]
	TIME [epoch: 27.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2723006272856319		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.2723006272856319 | validation: 1.0156942425795077]
	TIME [epoch: 27.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.098496935092278		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.098496935092278 | validation: 0.8741115468013915]
	TIME [epoch: 27.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1749131208278054		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.1749131208278054 | validation: 1.0479090826629283]
	TIME [epoch: 27.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9849362609084464		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.9849362609084464 | validation: 0.7173351568332501]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1547229099363299		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.1547229099363299 | validation: 1.066204564609734]
	TIME [epoch: 27.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1897223508760626		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.1897223508760626 | validation: 2.8817688367883982]
	TIME [epoch: 27.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6805908055519074		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.6805908055519074 | validation: 2.8729790308629526]
	TIME [epoch: 27.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.111691270808925		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.111691270808925 | validation: 2.8012136416865974]
	TIME [epoch: 27.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0007923461092543		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.0007923461092543 | validation: 2.6089097120051683]
	TIME [epoch: 27.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2930222119000048		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.2930222119000048 | validation: 2.8474666284796166]
	TIME [epoch: 27.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2819692006584646		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.2819692006584646 | validation: 3.7066160238805663]
	TIME [epoch: 27.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.957318284195317		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.957318284195317 | validation: 3.351067615450534]
	TIME [epoch: 27.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.426522567147002		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.426522567147002 | validation: 3.0655963616160236]
	TIME [epoch: 27.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.158683620688072		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.158683620688072 | validation: 2.8004170741676844]
	TIME [epoch: 27.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3996443611310148		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.3996443611310148 | validation: 4.009143117163288]
	TIME [epoch: 27.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7263517627698457		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.7263517627698457 | validation: 4.70259972284589]
	TIME [epoch: 27.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.365664985099101		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 5.365664985099101 | validation: 6.964534187153715]
	TIME [epoch: 27.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.437478619994378		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 6.437478619994378 | validation: 5.890223967332412]
	TIME [epoch: 27.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.308989010068662		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 5.308989010068662 | validation: 3.064420739293064]
	TIME [epoch: 27.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7706033829990253		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.7706033829990253 | validation: 2.3446831182795247]
	TIME [epoch: 27.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4422307238053524		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.4422307238053524 | validation: 2.224222081538486]
	TIME [epoch: 27.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.726020777924922		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.726020777924922 | validation: 3.4490886888274286]
	TIME [epoch: 27.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8699534982063186		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.8699534982063186 | validation: 2.967768427370207]
	TIME [epoch: 27.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.959586625803625		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.959586625803625 | validation: 2.188730565460917]
	TIME [epoch: 27.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.373236700359069		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.373236700359069 | validation: 2.339241734602766]
	TIME [epoch: 27.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2502433167131626		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.2502433167131626 | validation: 1.9520504347853822]
	TIME [epoch: 27.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8365178125983888		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.8365178125983888 | validation: 1.5517043860195532]
	TIME [epoch: 27.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7324404906066002		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.7324404906066002 | validation: 1.5700891286255125]
	TIME [epoch: 27.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.509260213086851		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.509260213086851 | validation: 1.257488312726319]
	TIME [epoch: 27.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3195314656448183		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.3195314656448183 | validation: 1.153339059819661]
	TIME [epoch: 27.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4744389542188072		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.4744389542188072 | validation: 1.699998858424713]
	TIME [epoch: 27.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7529011832896293		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.7529011832896293 | validation: 1.4017147905617686]
	TIME [epoch: 27.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.325888989981563		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.325888989981563 | validation: 0.9519531303722691]
	TIME [epoch: 27.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.271619591942049		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.271619591942049 | validation: 0.8781876512533543]
	TIME [epoch: 27.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1263984626086516		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.1263984626086516 | validation: 0.8709737181676471]
	TIME [epoch: 27.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.125542996294779		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.125542996294779 | validation: 1.9834769936090229]
	TIME [epoch: 27.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5004812521191553		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.5004812521191553 | validation: 1.04253880503929]
	TIME [epoch: 27.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8972249797746821		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.8972249797746821 | validation: 0.8353573026851582]
	TIME [epoch: 27.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7453766861009523		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.7453766861009523 | validation: 0.6909293394038906]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3724245427079784		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.3724245427079784 | validation: 1.1414924883017907]
	TIME [epoch: 27.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1349189578096315		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.1349189578096315 | validation: 0.8101771600809733]
	TIME [epoch: 27.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.145782935174321		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.145782935174321 | validation: 1.551930299326142]
	TIME [epoch: 27.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.425764685968987		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.425764685968987 | validation: 0.8973047176396929]
	TIME [epoch: 27.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8210182640151041		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.8210182640151041 | validation: 0.8204345587450783]
	TIME [epoch: 27.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8656564255656342		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.8656564255656342 | validation: 0.7224698838040721]
	TIME [epoch: 27.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0528058401157738		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.0528058401157738 | validation: 0.7053305062888313]
	TIME [epoch: 27.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7557633320217747		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.7557633320217747 | validation: 0.7345955715604305]
	TIME [epoch: 27.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0960550841357886		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.0960550841357886 | validation: 1.4805792641849393]
	TIME [epoch: 27.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4443313750400524		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.4443313750400524 | validation: 1.1827611414922141]
	TIME [epoch: 27.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4248137612789846		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.4248137612789846 | validation: 1.540697607198481]
	TIME [epoch: 27.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1039046948686262		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.1039046948686262 | validation: 0.7596398673701729]
	TIME [epoch: 27.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7943073295663012		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.7943073295663012 | validation: 0.8411627585712086]
	TIME [epoch: 27.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3176825526453038		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.3176825526453038 | validation: 0.6364612815109044]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.90275816559824		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.90275816559824 | validation: 1.0173503760546228]
	TIME [epoch: 27.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2302484597955172		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.2302484597955172 | validation: 1.0924884460818924]
	TIME [epoch: 27.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9374983436235382		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.9374983436235382 | validation: 0.7892075916999579]
	TIME [epoch: 27.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.905725710704215		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.905725710704215 | validation: 1.0804383546681964]
	TIME [epoch: 27.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.893852235387847		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.893852235387847 | validation: 1.6206708924613378]
	TIME [epoch: 27.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.002317214380334		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.002317214380334 | validation: 4.164667930509724]
	TIME [epoch: 27.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.51862359600297		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.51862359600297 | validation: 2.9447297395647336]
	TIME [epoch: 27.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.569739983358998		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.569739983358998 | validation: 4.136941373003579]
	TIME [epoch: 27.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.045967579480063		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 4.045967579480063 | validation: 2.953711931402284]
	TIME [epoch: 27.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.158710644879902		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.158710644879902 | validation: 3.5068294326478724]
	TIME [epoch: 27.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0521284483595297		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.0521284483595297 | validation: 1.9818101427269361]
	TIME [epoch: 27.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9247648327025184		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.9247648327025184 | validation: 1.516696910080811]
	TIME [epoch: 27.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.363382052704071		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.363382052704071 | validation: 1.659698174181042]
	TIME [epoch: 27.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4298168698689395		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.4298168698689395 | validation: 1.1469041882900683]
	TIME [epoch: 27.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.04573336877118		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.04573336877118 | validation: 1.0667776341162247]
	TIME [epoch: 27.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1952228041916637		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.1952228041916637 | validation: 1.4316370582018427]
	TIME [epoch: 27.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0896544759208362		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.0896544759208362 | validation: 0.7903587986050904]
	TIME [epoch: 27.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8579558235052325		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.8579558235052325 | validation: 0.823921939320892]
	TIME [epoch: 27.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7669549408531889		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.7669549408531889 | validation: 0.8231315597322302]
	TIME [epoch: 28 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.772931436110764		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.772931436110764 | validation: 0.6865629724923562]
	TIME [epoch: 27.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7740415571644079		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.7740415571644079 | validation: 0.7243558622502659]
	TIME [epoch: 27.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.76390972102899		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.76390972102899 | validation: 0.6495602500437186]
	TIME [epoch: 27.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7336222665157788		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.7336222665157788 | validation: 0.931372371953264]
	TIME [epoch: 27.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2634640971270508		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.2634640971270508 | validation: 1.003712130667968]
	TIME [epoch: 27.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8295251761022172		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.8295251761022172 | validation: 0.655031613689349]
	TIME [epoch: 27.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312426951405157		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.6312426951405157 | validation: 0.7270745613295871]
	TIME [epoch: 28 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6957350925357758		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.6957350925357758 | validation: 1.3068494606148842]
	TIME [epoch: 27.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0933827232610578		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.0933827232610578 | validation: 0.6377004828308958]
	TIME [epoch: 27.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832374511158111		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.6832374511158111 | validation: 0.9589668325517868]
	TIME [epoch: 27.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8824394066278738		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.8824394066278738 | validation: 0.6494108419132453]
	TIME [epoch: 27.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7291895338185787		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.7291895338185787 | validation: 0.8537265964667518]
	TIME [epoch: 28 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7111561535906687		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.7111561535906687 | validation: 0.565834762814199]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8063591729230999		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.8063591729230999 | validation: 1.009556999087655]
	TIME [epoch: 27.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860029674064285		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.6860029674064285 | validation: 0.579000677367989]
	TIME [epoch: 27.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6634161090799303		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.6634161090799303 | validation: 0.6381860629894478]
	TIME [epoch: 27.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6924051315831723		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.6924051315831723 | validation: 0.9017603652226961]
	TIME [epoch: 28 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7564180341726254		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.7564180341726254 | validation: 0.7057300027872471]
	TIME [epoch: 27.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0640904488872929		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.0640904488872929 | validation: 0.7460742520576278]
	TIME [epoch: 27.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7421152649825492		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.7421152649825492 | validation: 0.6934800044672995]
	TIME [epoch: 27.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7351590931271728		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.7351590931271728 | validation: 0.5203013902083763]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8433079002986451		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.8433079002986451 | validation: 0.9318294573789083]
	TIME [epoch: 27.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.799977637413143		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.799977637413143 | validation: 0.7578589767248205]
	TIME [epoch: 27.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6103115457288713		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.6103115457288713 | validation: 4.890044698176307]
	TIME [epoch: 27.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.621308627361555		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 4.621308627361555 | validation: 3.8607197331113974]
	TIME [epoch: 27.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8762491843765385		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 4.8762491843765385 | validation: 3.8703935587911253]
	TIME [epoch: 27.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.43642377025815		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 4.43642377025815 | validation: 3.8427356458683075]
	TIME [epoch: 27.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3534012414342245		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 4.3534012414342245 | validation: 3.808634020605046]
	TIME [epoch: 27.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.262142672526488		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 4.262142672526488 | validation: 3.8730075090825324]
	TIME [epoch: 27.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2018147902743035		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 4.2018147902743035 | validation: 3.6674124783969297]
	TIME [epoch: 27.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1024110310825606		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 4.1024110310825606 | validation: 3.5024429558254755]
	TIME [epoch: 27.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8895176377934715		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.8895176377934715 | validation: 1.4866586801012016]
	TIME [epoch: 27.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2587040321510454		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.2587040321510454 | validation: 0.7678589404368867]
	TIME [epoch: 27.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9550871437543772		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.9550871437543772 | validation: 4.12577241189555]
	TIME [epoch: 27.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.300982329693688		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 3.300982329693688 | validation: 1.571326622995841]
	TIME [epoch: 27.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1714008094261716		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.1714008094261716 | validation: 0.7805851507685236]
	TIME [epoch: 27.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8143019116708237		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.8143019116708237 | validation: 0.9776299178774022]
	TIME [epoch: 27.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.781217638486414		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.781217638486414 | validation: 2.932619776509508]
	TIME [epoch: 27.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.926623211128286		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.926623211128286 | validation: 0.9773776799923276]
	TIME [epoch: 27.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7835665070404639		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.7835665070404639 | validation: 0.5282823223606247]
	TIME [epoch: 27.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6457958561510129		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.6457958561510129 | validation: 0.5402018602798809]
	TIME [epoch: 27.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9647337652611583		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.9647337652611583 | validation: 0.786047735661353]
	TIME [epoch: 27.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1313715081524793		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.1313715081524793 | validation: 1.9333221941062442]
	TIME [epoch: 27.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1175462862268257		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.1175462862268257 | validation: 0.7648460417203987]
	TIME [epoch: 27.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7478066618847732		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.7478066618847732 | validation: 0.713457938349245]
	TIME [epoch: 27.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8914219420794658		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.8914219420794658 | validation: 0.8390424653356783]
	TIME [epoch: 27.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9071939839788372		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.9071939839788372 | validation: 0.8150545539342666]
	TIME [epoch: 27.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9639052166344942		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.9639052166344942 | validation: 0.9165442960572415]
	TIME [epoch: 27.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8814400031208792		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.8814400031208792 | validation: 0.7867823178719908]
	TIME [epoch: 27.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7154663170125886		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.7154663170125886 | validation: 2.1002425484219867]
	TIME [epoch: 27.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.168656108966407		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.168656108966407 | validation: 0.6671868474541448]
	TIME [epoch: 27.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818808051445762		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.6818808051445762 | validation: 0.6367969125924055]
	TIME [epoch: 27.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0613616452737085		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.0613616452737085 | validation: 0.7871564698081491]
	TIME [epoch: 27.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8582743747316789		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.8582743747316789 | validation: 1.7444894248936231]
	TIME [epoch: 27.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.75339865668152		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 3.75339865668152 | validation: 5.121441070562193]
	TIME [epoch: 27.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.221266618743306		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 4.221266618743306 | validation: 5.147954723529502]
	TIME [epoch: 27.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.299273874183168		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 4.299273874183168 | validation: 5.021873146998348]
	TIME [epoch: 27.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.728382046546215		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 3.728382046546215 | validation: 0.7842916434319189]
	TIME [epoch: 27.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7920935066741367		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.7920935066741367 | validation: 0.6455637244104796]
	TIME [epoch: 27.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6544668904298233		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.6544668904298233 | validation: 0.5959446092257192]
	TIME [epoch: 27.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8330287061246362		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.8330287061246362 | validation: 0.5076784205395712]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8462800079858197		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.8462800079858197 | validation: 0.8196975555089304]
	TIME [epoch: 27.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6957777885592216		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.6957777885592216 | validation: 1.0463036954802203]
	TIME [epoch: 27.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9436312376439995		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.9436312376439995 | validation: 0.8289268854362943]
	TIME [epoch: 27.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9523509056971086		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.9523509056971086 | validation: 0.6052209791448709]
	TIME [epoch: 27.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812609945680304		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.6812609945680304 | validation: 0.8904322570276156]
	TIME [epoch: 27.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4338793947839186		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.4338793947839186 | validation: 3.3818636333437633]
	TIME [epoch: 27.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9359630609362375		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 3.9359630609362375 | validation: 3.603842121697003]
	TIME [epoch: 27.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.430325431647818		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 3.430325431647818 | validation: 2.6815613127595004]
	TIME [epoch: 27.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0724460317647924		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 3.0724460317647924 | validation: 2.736763318747395]
	TIME [epoch: 27.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9496808005560258		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.9496808005560258 | validation: 2.649295777035957]
	TIME [epoch: 27.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.929744798859427		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 2.929744798859427 | validation: 2.579197464206994]
	TIME [epoch: 27.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9428501053111242		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.9428501053111242 | validation: 2.6578289432989193]
	TIME [epoch: 27.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.902501518166566		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 2.902501518166566 | validation: 2.576973908809139]
	TIME [epoch: 27.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8888760540646725		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 2.8888760540646725 | validation: 2.639730325065932]
	TIME [epoch: 27.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.956364222451942		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 2.956364222451942 | validation: 2.6117849635505737]
	TIME [epoch: 27.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8791282738977864		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.8791282738977864 | validation: 2.4867391689460794]
	TIME [epoch: 27.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.852202020395648		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.852202020395648 | validation: 2.5877875391782705]
	TIME [epoch: 28 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.750172942908065		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.750172942908065 | validation: 2.5909740384793087]
	TIME [epoch: 27.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.426766836881913		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 2.426766836881913 | validation: 1.8288500945688797]
	TIME [epoch: 27.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8546672473641639		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.8546672473641639 | validation: 1.636983221939297]
	TIME [epoch: 27.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6412619263831194		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.6412619263831194 | validation: 1.4115663158998724]
	TIME [epoch: 27.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.565783568199516		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.565783568199516 | validation: 1.2019613057504974]
	TIME [epoch: 28 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.20788250255544		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.20788250255544 | validation: 1.3403321584795527]
	TIME [epoch: 27.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.299167005626329		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.299167005626329 | validation: 1.0081536772573316]
	TIME [epoch: 27.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9897691395383859		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.9897691395383859 | validation: 0.6699556607860648]
	TIME [epoch: 27.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828230082158152		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.6828230082158152 | validation: 0.9710346957519838]
	TIME [epoch: 27.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.77242194671618		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.77242194671618 | validation: 0.588092568677195]
	TIME [epoch: 27.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0320961974308114		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.0320961974308114 | validation: 1.861008909622857]
	TIME [epoch: 27.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7025469992137432		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.7025469992137432 | validation: 0.8987101134775705]
	TIME [epoch: 27.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031895862006043		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.031895862006043 | validation: 1.2684003639589536]
	TIME [epoch: 27.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1835901022193696		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.1835901022193696 | validation: 0.6855363191323026]
	TIME [epoch: 27.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818573551339229		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.6818573551339229 | validation: 0.6733547728209499]
	TIME [epoch: 28 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7179385038186009		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.7179385038186009 | validation: 0.5464000212014187]
	TIME [epoch: 27.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5958673107068483		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.5958673107068483 | validation: 0.6721813268709853]
	TIME [epoch: 27.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5730273431885369		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.5730273431885369 | validation: 0.7504744450297682]
	TIME [epoch: 27.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8549824133729087		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.8549824133729087 | validation: 0.9986547885271878]
	TIME [epoch: 27.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7597018876234851		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.7597018876234851 | validation: 0.7487085029399583]
	TIME [epoch: 27.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6508784583669883		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.6508784583669883 | validation: 0.6923541591791056]
	TIME [epoch: 27.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6354331978616343		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.6354331978616343 | validation: 0.6071102288566741]
	TIME [epoch: 27.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5987776702492712		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.5987776702492712 | validation: 0.8767037634190694]
	TIME [epoch: 27.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7507779004733977		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.7507779004733977 | validation: 0.6831540807881095]
	TIME [epoch: 27.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.070032672049374		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.070032672049374 | validation: 1.2866148279576535]
	TIME [epoch: 27.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9491727391706264		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.9491727391706264 | validation: 0.7016848128746156]
	TIME [epoch: 27.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853090824290495		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.6853090824290495 | validation: 0.6287271293347573]
	TIME [epoch: 27.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6517840461208196		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.6517840461208196 | validation: 0.7848842881218846]
	TIME [epoch: 27.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6298838864698405		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.6298838864698405 | validation: 0.4859512827493163]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.666432588216853		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.666432588216853 | validation: 0.5927977331565696]
	TIME [epoch: 27.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9270267259693982		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.9270267259693982 | validation: 0.9359466395729483]
	TIME [epoch: 27.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7058276840631805		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.7058276840631805 | validation: 0.5367446677700001]
	TIME [epoch: 27.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7734230674401891		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.7734230674401891 | validation: 0.7294720633756339]
	TIME [epoch: 27.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7449279964710152		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.7449279964710152 | validation: 0.7617520416919428]
	TIME [epoch: 27.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6784703233789163		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.6784703233789163 | validation: 0.6495158474135394]
	TIME [epoch: 27.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265575512566467		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.7265575512566467 | validation: 0.6549158180358764]
	TIME [epoch: 27.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7323098052722486		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.7323098052722486 | validation: 0.6529543665279794]
	TIME [epoch: 27.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6557950403895445		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.6557950403895445 | validation: 0.5982185888270874]
	TIME [epoch: 27.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6322773050402481		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.6322773050402481 | validation: 0.6853679432193153]
	TIME [epoch: 27.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.357893210291876		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.357893210291876 | validation: 1.3662463099468727]
	TIME [epoch: 27.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9723279363345652		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.9723279363345652 | validation: 0.6765406968310248]
	TIME [epoch: 27.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.586235173548488		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.586235173548488 | validation: 0.5257231015375371]
	TIME [epoch: 27.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5699540856407275		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.5699540856407275 | validation: 0.6183017591378461]
	TIME [epoch: 27.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5087063831497742		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.5087063831497742 | validation: 0.4524830164678395]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7308619389689304		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.7308619389689304 | validation: 0.830361799288988]
	TIME [epoch: 27.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3630691682140732		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.3630691682140732 | validation: 0.8832758218826031]
	TIME [epoch: 27.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657319203527646		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6657319203527646 | validation: 0.4102101722963289]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4918872438426545		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.4918872438426545 | validation: 0.5553946919140867]
	TIME [epoch: 27.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48723442286506424		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.48723442286506424 | validation: 0.49708032823294745]
	TIME [epoch: 27.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5762690842049688		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.5762690842049688 | validation: 1.0624679267761425]
	TIME [epoch: 28 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9419542150380582		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.9419542150380582 | validation: 1.5009997227018606]
	TIME [epoch: 27.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3707563824107898		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.3707563824107898 | validation: 0.5716110846538635]
	TIME [epoch: 27.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5654331916959394		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.5654331916959394 | validation: 0.5120287558656738]
	TIME [epoch: 28 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4808695289055468		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.4808695289055468 | validation: 0.48900883549904367]
	TIME [epoch: 27.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46166599594541646		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.46166599594541646 | validation: 0.7468147565640145]
	TIME [epoch: 28 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6417198373329133		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.6417198373329133 | validation: 0.4273869109815488]
	TIME [epoch: 27.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6793761958448403		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.6793761958448403 | validation: 0.8852662095183922]
	TIME [epoch: 27.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7783160585845323		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.7783160585845323 | validation: 0.568849581206281]
	TIME [epoch: 27.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5803277233113706		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5803277233113706 | validation: 1.0832838985003677]
	TIME [epoch: 27.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.165401092955794		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.165401092955794 | validation: 0.813492348410273]
	TIME [epoch: 27.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8142603269231932		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.8142603269231932 | validation: 0.5564070951124167]
	TIME [epoch: 28 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5039490143767165		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.5039490143767165 | validation: 0.4522249908804328]
	TIME [epoch: 27.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5816050946645686		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5816050946645686 | validation: 0.6921697920696974]
	TIME [epoch: 28 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.61950059130402		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.61950059130402 | validation: 0.5470734221401787]
	TIME [epoch: 27.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5838400578194728		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.5838400578194728 | validation: 0.4942693835621054]
	TIME [epoch: 27.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5281422622769498		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.5281422622769498 | validation: 0.4980963435783998]
	TIME [epoch: 27.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7779322812455479		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.7779322812455479 | validation: 1.0753121380301787]
	TIME [epoch: 27.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1432558560222295		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.1432558560222295 | validation: 0.7819531932563604]
	TIME [epoch: 27.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8152793097734514		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.8152793097734514 | validation: 0.8623301446683774]
	TIME [epoch: 27.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.853941405248404		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.853941405248404 | validation: 0.848996000121201]
	TIME [epoch: 28 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7563458113413773		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.7563458113413773 | validation: 0.7237031279777256]
	TIME [epoch: 28 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6733090372864391		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.6733090372864391 | validation: 0.6900166412970039]
	TIME [epoch: 27.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.738048686669105		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.738048686669105 | validation: 0.6739244909283824]
	TIME [epoch: 27.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6811019741609514		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6811019741609514 | validation: 0.9027911830174142]
	TIME [epoch: 27.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9816952222311203		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.9816952222311203 | validation: 0.8178945027474634]
	TIME [epoch: 27.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8362349733714176		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.8362349733714176 | validation: 0.6496840927630433]
	TIME [epoch: 27.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7292853542859898		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.7292853542859898 | validation: 0.8869988707898742]
	TIME [epoch: 27.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9724717205644812		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.9724717205644812 | validation: 0.8631590070208814]
	TIME [epoch: 28 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0429321711518478		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.0429321711518478 | validation: 0.8940702517888469]
	TIME [epoch: 27.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7787041814911793		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.7787041814911793 | validation: 0.6766001288137025]
	TIME [epoch: 27.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023381210599808		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.7023381210599808 | validation: 0.7491540534093218]
	TIME [epoch: 27.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6501313513086027		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.6501313513086027 | validation: 0.772452974427387]
	TIME [epoch: 27.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8020993586655707		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.8020993586655707 | validation: 0.7919446283393187]
	TIME [epoch: 28 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6526760530115909		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.6526760530115909 | validation: 0.7588683597068429]
	TIME [epoch: 27.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6680319515288622		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.6680319515288622 | validation: 0.5744547074219789]
	TIME [epoch: 27.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5614002714316744		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.5614002714316744 | validation: 0.5285332088413808]
	TIME [epoch: 28 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6755264577630806		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.6755264577630806 | validation: 0.5454977310902777]
	TIME [epoch: 27.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6373365997184651		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.6373365997184651 | validation: 0.7004916455528902]
	TIME [epoch: 27.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7077077017352231		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.7077077017352231 | validation: 0.8020000113150562]
	TIME [epoch: 28 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6734002413483787		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.6734002413483787 | validation: 0.7076123108627148]
	TIME [epoch: 28 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6004996820331624		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.6004996820331624 | validation: 0.6560128155271298]
	TIME [epoch: 28 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5619896699545089		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5619896699545089 | validation: 0.5365059718680423]
	TIME [epoch: 27.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6263688349690861		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.6263688349690861 | validation: 0.9119562547140038]
	TIME [epoch: 27.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8333278119642085		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.8333278119642085 | validation: 0.6581602869318628]
	TIME [epoch: 28 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.633817131716591		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.633817131716591 | validation: 0.6225637828936742]
	TIME [epoch: 27.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.54238132508221		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.54238132508221 | validation: 0.5622674993295671]
	TIME [epoch: 27.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5369687998091086		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.5369687998091086 | validation: 0.5174863682571317]
	TIME [epoch: 27.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2220364801131063		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.2220364801131063 | validation: 1.5436964070946813]
	TIME [epoch: 27.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6072280276986437		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.6072280276986437 | validation: 0.6296533260827863]
	TIME [epoch: 27.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5991252186053798		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5991252186053798 | validation: 0.5617338126137496]
	TIME [epoch: 27.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6118524977852088		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.6118524977852088 | validation: 0.5831567856894505]
	TIME [epoch: 28.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6588621230118216		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.6588621230118216 | validation: 0.6778290705136512]
	TIME [epoch: 27.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6256222906889933		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.6256222906889933 | validation: 0.6252447231222149]
	TIME [epoch: 27.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5888051725350112		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.5888051725350112 | validation: 0.6432156580467162]
	TIME [epoch: 27.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6768762260264455		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.6768762260264455 | validation: 0.505568392468788]
	TIME [epoch: 27.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5222660250985113		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.5222660250985113 | validation: 0.6290307591610775]
	TIME [epoch: 27.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5298230064050765		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.5298230064050765 | validation: 0.5079009578424083]
	TIME [epoch: 27.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44528806778410956		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.44528806778410956 | validation: 0.4400024980940168]
	TIME [epoch: 27.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4695816220704396		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.4695816220704396 | validation: 0.5065936665302183]
	TIME [epoch: 27.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4757037747842906		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.4757037747842906 | validation: 0.5313309537250883]
	TIME [epoch: 27.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5355734179812601		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.5355734179812601 | validation: 1.1798063199403803]
	TIME [epoch: 27.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9166375806350427		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.9166375806350427 | validation: 0.5026867917268559]
	TIME [epoch: 27.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5001016092988182		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5001016092988182 | validation: 0.5369830026333283]
	TIME [epoch: 27.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48868620220454967		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.48868620220454967 | validation: 0.44671285212957557]
	TIME [epoch: 27.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4755610623277545		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.4755610623277545 | validation: 0.6893511838030054]
	TIME [epoch: 27.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5638908282132796		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.5638908282132796 | validation: 0.6507096085848315]
	TIME [epoch: 27.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507724195084828		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.5507724195084828 | validation: 0.5625130006805383]
	TIME [epoch: 27.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5406230982944934		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.5406230982944934 | validation: 0.5301585495866107]
	TIME [epoch: 27.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5883128944990007		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.5883128944990007 | validation: 0.7522636682047965]
	TIME [epoch: 27.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8179642120131976		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.8179642120131976 | validation: 0.5915138366420831]
	TIME [epoch: 27.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6219256359064999		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.6219256359064999 | validation: 0.6839611657888988]
	TIME [epoch: 27.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.053373556728854		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.053373556728854 | validation: 0.8346213898337541]
	TIME [epoch: 27.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956856483613377		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.6956856483613377 | validation: 0.5059439837923935]
	TIME [epoch: 27.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024925783242298		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.5024925783242298 | validation: 0.6779131806284687]
	TIME [epoch: 27.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5640201285385773		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.5640201285385773 | validation: 0.5895199900521182]
	TIME [epoch: 27.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5844193609677257		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5844193609677257 | validation: 0.9612798073462636]
	TIME [epoch: 27.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9398650285815379		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.9398650285815379 | validation: 0.7716889535622466]
	TIME [epoch: 27.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7958625969896955		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.7958625969896955 | validation: 0.8777064979806387]
	TIME [epoch: 27.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9837703080742977		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.9837703080742977 | validation: 0.8713052575711038]
	TIME [epoch: 27.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.785193340364404		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.785193340364404 | validation: 0.5571796661376487]
	TIME [epoch: 27.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5497332841529984		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.5497332841529984 | validation: 0.583481134849701]
	TIME [epoch: 27.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70693189200002		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.70693189200002 | validation: 0.8140365449059042]
	TIME [epoch: 27.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9234781590119436		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.9234781590119436 | validation: 0.7530472718920672]
	TIME [epoch: 27.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8490223674346522		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.8490223674346522 | validation: 0.8584624562377198]
	TIME [epoch: 27.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.866843869173036		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.866843869173036 | validation: 0.7677094387473895]
	TIME [epoch: 27.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6624238702331944		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.6624238702331944 | validation: 0.6024582310110844]
	TIME [epoch: 27.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5668727752150113		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.5668727752150113 | validation: 0.5880245793215296]
	TIME [epoch: 27.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5649392045329941		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.5649392045329941 | validation: 0.6496874285036662]
	TIME [epoch: 27.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014460692987364		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.7014460692987364 | validation: 0.6010911987017326]
	TIME [epoch: 27.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5376267580836955		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.5376267580836955 | validation: 0.6383966816935976]
	TIME [epoch: 27.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6168763092945369		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.6168763092945369 | validation: 0.7995589786644081]
	TIME [epoch: 27.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.616855207209574		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.616855207209574 | validation: 0.6145562627351965]
	TIME [epoch: 27.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034037291772072		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.7034037291772072 | validation: 0.6930004835790865]
	TIME [epoch: 27.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8520718127147884		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.8520718127147884 | validation: 0.9159895385279109]
	TIME [epoch: 27.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0924129471233324		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.0924129471233324 | validation: 0.8996267575314782]
	TIME [epoch: 27.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8791201879350042		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.8791201879350042 | validation: 0.6440002870447133]
	TIME [epoch: 27.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5907956290963675		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.5907956290963675 | validation: 0.5138216642244235]
	TIME [epoch: 27.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4891363890602118		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.4891363890602118 | validation: 0.5095858232499527]
	TIME [epoch: 27.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451136245720237		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.5451136245720237 | validation: 0.6175381440843414]
	TIME [epoch: 27.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301391577425536		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.5301391577425536 | validation: 0.5779093494474205]
	TIME [epoch: 27.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5842775223224521		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.5842775223224521 | validation: 0.578243553512823]
	TIME [epoch: 27.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6126222324034836		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.6126222324034836 | validation: 0.6514943705391434]
	TIME [epoch: 27.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490755486165105		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.5490755486165105 | validation: 0.6364842693451979]
	TIME [epoch: 27.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5818588388116899		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.5818588388116899 | validation: 0.5096805238747607]
	TIME [epoch: 27.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6180425207482105		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.6180425207482105 | validation: 0.9907900485946327]
	TIME [epoch: 27.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1077099742686987		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.1077099742686987 | validation: 0.7351653475593867]
	TIME [epoch: 27.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7659400914417231		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.7659400914417231 | validation: 0.6570415878251263]
	TIME [epoch: 27.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6075668281230976		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.6075668281230976 | validation: 0.6084831934280105]
	TIME [epoch: 27.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5950819169926851		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.5950819169926851 | validation: 0.6023119015771184]
	TIME [epoch: 27.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5937561348256281		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.5937561348256281 | validation: 0.4855254718959898]
	TIME [epoch: 27.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5339014090873248		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.5339014090873248 | validation: 0.7269181163911321]
	TIME [epoch: 27.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7726603844612774		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.7726603844612774 | validation: 0.8091429894230902]
	TIME [epoch: 27.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688365042412441		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.7688365042412441 | validation: 0.7120176345806469]
	TIME [epoch: 27.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7791005814223094		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.7791005814223094 | validation: 0.7380377573363915]
	TIME [epoch: 27.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.788386089250967		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.788386089250967 | validation: 0.7929237701853962]
	TIME [epoch: 27.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7610930538762778		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.7610930538762778 | validation: 0.7615166789778938]
	TIME [epoch: 27.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7310990410781456		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.7310990410781456 | validation: 0.6932789202091152]
	TIME [epoch: 27.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701818468870966		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.701818468870966 | validation: 0.7630275867042857]
	TIME [epoch: 27.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7104660068745966		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.7104660068745966 | validation: 0.5533632301000279]
	TIME [epoch: 27.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7472774469875078		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.7472774469875078 | validation: 0.7373780857655542]
	TIME [epoch: 27.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7879742022109373		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.7879742022109373 | validation: 0.5705442715817266]
	TIME [epoch: 27.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6467414674873887		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.6467414674873887 | validation: 0.7494237865686916]
	TIME [epoch: 27.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7479853382668152		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.7479853382668152 | validation: 0.6156139327530707]
	TIME [epoch: 27.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6232302397949852		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.6232302397949852 | validation: 0.4660235797391485]
	TIME [epoch: 27.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5213078965915272		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.5213078965915272 | validation: 0.47152408315343075]
	TIME [epoch: 27.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5387837456053292		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.5387837456053292 | validation: 0.6245141252674278]
	TIME [epoch: 27.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6662398241344694		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.6662398241344694 | validation: 0.5525425721510935]
	TIME [epoch: 27.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5138010495377282		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.5138010495377282 | validation: 0.45438740900017605]
	TIME [epoch: 27.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5759431519762678		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.5759431519762678 | validation: 0.5939255284416028]
	TIME [epoch: 27.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6013666948483748		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.6013666948483748 | validation: 0.7058775846294735]
	TIME [epoch: 27.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6755530506227444		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.6755530506227444 | validation: 0.6069160644551763]
	TIME [epoch: 27.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5074646196289752		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.5074646196289752 | validation: 0.41225426385311603]
	TIME [epoch: 27.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.391233574536163		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.391233574536163 | validation: 0.34936519500666935]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_438.pth
	Model improved!!!
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692404119665911		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.3692404119665911 | validation: 0.35899534223942864]
	TIME [epoch: 27.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4182066123847931		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.4182066123847931 | validation: 0.3700790089174031]
	TIME [epoch: 27.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3823278815807615		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.3823278815807615 | validation: 0.40385107410609167]
	TIME [epoch: 27.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.435639713986892		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.435639713986892 | validation: 0.4174020799864418]
	TIME [epoch: 27.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4193053234679112		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.4193053234679112 | validation: 0.7116176400845657]
	TIME [epoch: 27.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5115157689408955		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.5115157689408955 | validation: 0.48214031469810464]
	TIME [epoch: 27.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43466338807528815		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.43466338807528815 | validation: 0.34590072735585436]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3770879008891891		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.3770879008891891 | validation: 0.7749958563038828]
	TIME [epoch: 27.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5348566168404153		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.5348566168404153 | validation: 0.4309322024980905]
	TIME [epoch: 27.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44923195200887583		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.44923195200887583 | validation: 0.45023640287885064]
	TIME [epoch: 27.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4513920180680702		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.4513920180680702 | validation: 0.38642154154868813]
	TIME [epoch: 27.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4080371989378656		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.4080371989378656 | validation: 0.40833769360999767]
	TIME [epoch: 27.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43790388863804836		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.43790388863804836 | validation: 0.471492675750324]
	TIME [epoch: 27.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6260138731633731		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.6260138731633731 | validation: 0.6309924062207507]
	TIME [epoch: 27.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5586565487836779		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.5586565487836779 | validation: 0.47192091501137234]
	TIME [epoch: 27.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4634740989132266		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.4634740989132266 | validation: 0.6345709737455245]
	TIME [epoch: 27.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5487201154827974		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.5487201154827974 | validation: 0.501030762010107]
	TIME [epoch: 28 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5076161205273961		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.5076161205273961 | validation: 0.5256788261724156]
	TIME [epoch: 27.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.50642596387658		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.50642596387658 | validation: 0.45672120310726644]
	TIME [epoch: 27.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.477312051316878		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.477312051316878 | validation: 0.49517511056706653]
	TIME [epoch: 27.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5237135206483154		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.5237135206483154 | validation: 0.42877292996732347]
	TIME [epoch: 27.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45005565716840856		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.45005565716840856 | validation: 0.40111136353357213]
	TIME [epoch: 27.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.484048258837739		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.484048258837739 | validation: 0.5020602742177143]
	TIME [epoch: 27.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4294140436105306		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.4294140436105306 | validation: 0.4290579220556212]
	TIME [epoch: 27.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4085381342339097		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.4085381342339097 | validation: 0.5309632228167636]
	TIME [epoch: 27.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45205438030283096		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.45205438030283096 | validation: 0.4231289756355616]
	TIME [epoch: 27.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293036382166869		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.5293036382166869 | validation: 0.749369240871377]
	TIME [epoch: 27.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113624411648627		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.8113624411648627 | validation: 0.6552001623081788]
	TIME [epoch: 27.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6125542556980919		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.6125542556980919 | validation: 0.48096526466563777]
	TIME [epoch: 27.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43676119599995045		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.43676119599995045 | validation: 0.5092758470806209]
	TIME [epoch: 27.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47722890786279787		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.47722890786279787 | validation: 0.4838949399491788]
	TIME [epoch: 28 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42710305121636216		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.42710305121636216 | validation: 0.39725162933956326]
	TIME [epoch: 27.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4178811061577599		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.4178811061577599 | validation: 0.5393748881037742]
	TIME [epoch: 27.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4399373505890324		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.4399373505890324 | validation: 0.4657987846049824]
	TIME [epoch: 28 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3906092319055594		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.3906092319055594 | validation: 0.44798471896172914]
	TIME [epoch: 27.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6943959727696298		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.6943959727696298 | validation: 0.7917274859844821]
	TIME [epoch: 27.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113340048436717		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.8113340048436717 | validation: 0.5846655050667631]
	TIME [epoch: 27.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.638741223622388		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.638741223622388 | validation: 0.6401912034478167]
	TIME [epoch: 27.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7662012138760251		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.7662012138760251 | validation: 0.5039304836462478]
	TIME [epoch: 27.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5830989054101692		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.5830989054101692 | validation: 0.5471352834338414]
	TIME [epoch: 27.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6101418656498894		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.6101418656498894 | validation: 0.505618825299707]
	TIME [epoch: 28 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.582373196411627		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.582373196411627 | validation: 0.4354625599004983]
	TIME [epoch: 28 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48579152843475876		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.48579152843475876 | validation: 0.4420482243171793]
	TIME [epoch: 27.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4416327608952507		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.4416327608952507 | validation: 0.5203920521873668]
	TIME [epoch: 27.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48250198137955713		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.48250198137955713 | validation: 0.535038481926151]
	TIME [epoch: 28 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5207663011382558		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5207663011382558 | validation: 0.5089852390819664]
	TIME [epoch: 28 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5447706777942165		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.5447706777942165 | validation: 0.5749747630298762]
	TIME [epoch: 28 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7311699108083992		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.7311699108083992 | validation: 0.6410132932441596]
	TIME [epoch: 27.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6477242505795131		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.6477242505795131 | validation: 0.5327466586495747]
	TIME [epoch: 28 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5938279454847485		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.5938279454847485 | validation: 0.5342851929965191]
	TIME [epoch: 28 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083707475611882		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.5083707475611882 | validation: 0.43696456952035206]
	TIME [epoch: 27.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569134254542522		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.4569134254542522 | validation: 0.47960177232430795]
	TIME [epoch: 28 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46051268549170166		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.46051268549170166 | validation: 0.5948583529419195]
	TIME [epoch: 27.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5466457834380348		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.5466457834380348 | validation: 0.5017028068815053]
	TIME [epoch: 27.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48982739218779403		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.48982739218779403 | validation: 0.456185971530947]
	TIME [epoch: 28 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5291223462684844		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.5291223462684844 | validation: 0.535278769628436]
	TIME [epoch: 27.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7057596912328938		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.7057596912328938 | validation: 0.8444746439537676]
	TIME [epoch: 28 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9944400385827297		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.9944400385827297 | validation: 0.7503152332676174]
	TIME [epoch: 27.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.905929290850541		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.905929290850541 | validation: 0.9888775284016587]
	TIME [epoch: 28 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.233728848796896		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.233728848796896 | validation: 1.3215257673728689]
	TIME [epoch: 28 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5555069879518753		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.5555069879518753 | validation: 1.2011888073016395]
	TIME [epoch: 27.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1916675521359286		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.1916675521359286 | validation: 0.9131654540401334]
	TIME [epoch: 28 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9033475128439321		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.9033475128439321 | validation: 0.6387581289202513]
	TIME [epoch: 28 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6552726001452155		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.6552726001452155 | validation: 0.47929874066331585]
	TIME [epoch: 28 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.507775523752711		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.507775523752711 | validation: 0.513073358680055]
	TIME [epoch: 28 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5684615286470329		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.5684615286470329 | validation: 0.6101984526873935]
	TIME [epoch: 28 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984457690570209		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.6984457690570209 | validation: 0.6881232308217414]
	TIME [epoch: 28 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.887873607844763		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.887873607844763 | validation: 0.9665402478521682]
	TIME [epoch: 28 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1228731448756017		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.1228731448756017 | validation: 0.842523570851538]
	TIME [epoch: 28 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9672985823267901		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.9672985823267901 | validation: 0.812768574873616]
	TIME [epoch: 28 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0067045034192805		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.0067045034192805 | validation: 0.8316550295924597]
	TIME [epoch: 27.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.96292213514518		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.96292213514518 | validation: 0.9285251596253622]
	TIME [epoch: 28 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1252136295557515		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.1252136295557515 | validation: 1.0986618150034744]
	TIME [epoch: 28 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5193704367160927		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.5193704367160927 | validation: 1.6496535322853396]
	TIME [epoch: 27.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8227408798958518		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.8227408798958518 | validation: 1.4296803495330561]
	TIME [epoch: 28 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3347969028981175		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.3347969028981175 | validation: 0.9695079478508347]
	TIME [epoch: 27.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1638944085764442		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.1638944085764442 | validation: 1.0091611610696587]
	TIME [epoch: 28 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8228975515447239		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.8228975515447239 | validation: 0.6393452835495347]
	TIME [epoch: 28 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6522632399519346		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.6522632399519346 | validation: 0.7061977918904809]
	TIME [epoch: 28 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7965165795439143		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.7965165795439143 | validation: 0.822069201487023]
	TIME [epoch: 27.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.764781500876025		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.764781500876025 | validation: 0.553153617851981]
	TIME [epoch: 27.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5717744247405567		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.5717744247405567 | validation: 0.5471326610491052]
	TIME [epoch: 27.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.624104381789395		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.624104381789395 | validation: 0.5743551000763385]
	TIME [epoch: 27.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6297057375198952		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.6297057375198952 | validation: 0.5696799752397939]
	TIME [epoch: 27.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6216939307821661		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.6216939307821661 | validation: 0.6766375633787639]
	TIME [epoch: 27.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7461686846125057		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.7461686846125057 | validation: 0.5497753359488518]
	TIME [epoch: 27.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5933348007231964		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.5933348007231964 | validation: 0.5549270719901996]
	TIME [epoch: 27.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5852626140949226		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.5852626140949226 | validation: 0.6011516547419444]
	TIME [epoch: 27.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6923294570059686		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.6923294570059686 | validation: 0.7886760001423313]
	TIME [epoch: 27.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9443169882193349		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.9443169882193349 | validation: 0.7981441974118694]
	TIME [epoch: 27.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197761858831552		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.7197761858831552 | validation: 0.5540004039606481]
	TIME [epoch: 27.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5264131030739071		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.5264131030739071 | validation: 0.4206459616631]
	TIME [epoch: 27.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072569839530121		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.5072569839530121 | validation: 0.48482704343456967]
	TIME [epoch: 27.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.486814031803974		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.486814031803974 | validation: 0.46544989184569474]
	TIME [epoch: 28 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.485683916961573		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.485683916961573 | validation: 0.5737499082049569]
	TIME [epoch: 27.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6599785646968308		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.6599785646968308 | validation: 0.6025999577077902]
	TIME [epoch: 27.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5707086791338905		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.5707086791338905 | validation: 0.529555541359157]
	TIME [epoch: 27.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247354007691167		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.5247354007691167 | validation: 0.5201231628964476]
	TIME [epoch: 27.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4668264632534782		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.4668264632534782 | validation: 0.4458775731980129]
	TIME [epoch: 27.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5020765914346534		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.5020765914346534 | validation: 0.6069669274748845]
	TIME [epoch: 27.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5029515530350495		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.5029515530350495 | validation: 0.48085439080319364]
	TIME [epoch: 27.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46427604453078075		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.46427604453078075 | validation: 0.4450415852563522]
	TIME [epoch: 27.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6307846815410229		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.6307846815410229 | validation: 0.731274242150235]
	TIME [epoch: 27.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7611716202540333		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.7611716202540333 | validation: 0.6279839241800609]
	TIME [epoch: 27.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6468659842390965		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.6468659842390965 | validation: 0.548363800068503]
	TIME [epoch: 27.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6473904128142725		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.6473904128142725 | validation: 0.7368408327597702]
	TIME [epoch: 27.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6710635068369956		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.6710635068369956 | validation: 0.5875494219828856]
	TIME [epoch: 27.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6421287396145257		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.6421287396145257 | validation: 0.5488798864115755]
	TIME [epoch: 27.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5728093430365695		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.5728093430365695 | validation: 0.623089476704711]
	TIME [epoch: 27.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224938396103397		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.7224938396103397 | validation: 0.7204962258123361]
	TIME [epoch: 28 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.671523779272343		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.671523779272343 | validation: 0.6144146923263463]
	TIME [epoch: 28 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220310144687195		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.7220310144687195 | validation: 0.6558032861593779]
	TIME [epoch: 27.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688887017733336		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.688887017733336 | validation: 0.6046973493985446]
	TIME [epoch: 28 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6276274595584663		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.6276274595584663 | validation: 0.6025148717880069]
	TIME [epoch: 28 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7823179441716165		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.7823179441716165 | validation: 0.7048182949500387]
	TIME [epoch: 28 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7148227599345653		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.7148227599345653 | validation: 0.5369062360521911]
	TIME [epoch: 28 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.601827146926299		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.601827146926299 | validation: 0.7636898817476151]
	TIME [epoch: 28 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8269227069870023		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.8269227069870023 | validation: 0.929430330666187]
	TIME [epoch: 28 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9519601167873053		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.9519601167873053 | validation: 0.6109611615011685]
	TIME [epoch: 27.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.591952685691877		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.591952685691877 | validation: 0.3958130481131504]
	TIME [epoch: 28 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4726822545559516		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.4726822545559516 | validation: 0.4992955093035765]
	TIME [epoch: 28 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5363040123967313		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.5363040123967313 | validation: 0.4653589103596451]
	TIME [epoch: 27.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4132659035559973		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.4132659035559973 | validation: 0.3415067636032359]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_561.pth
	Model improved!!!
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36442490819810514		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.36442490819810514 | validation: 0.40660618506300467]
	TIME [epoch: 28 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37945854772734244		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.37945854772734244 | validation: 0.4566625155522067]
	TIME [epoch: 28 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4451517794103853		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.4451517794103853 | validation: 0.3760623373070165]
	TIME [epoch: 28 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3785401859036071		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.3785401859036071 | validation: 0.33478379066715264]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33728217782156034		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.33728217782156034 | validation: 0.34687052432827276]
	TIME [epoch: 28 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32272199504921534		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.32272199504921534 | validation: 0.32417591789782646]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_567.pth
	Model improved!!!
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39624326411565625		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.39624326411565625 | validation: 0.3606497823050364]
	TIME [epoch: 27.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372135850880668		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.3372135850880668 | validation: 0.3810624563574328]
	TIME [epoch: 28 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35498883333133197		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.35498883333133197 | validation: 0.28067935118965515]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_570.pth
	Model improved!!!
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3195056413094735		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.3195056413094735 | validation: 0.3035806292804045]
	TIME [epoch: 27.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31426083703143665		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.31426083703143665 | validation: 0.45106485482573344]
	TIME [epoch: 28 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4136679531287405		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.4136679531287405 | validation: 0.5020850413583345]
	TIME [epoch: 27.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47487270052335784		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.47487270052335784 | validation: 0.3489372042571657]
	TIME [epoch: 27.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3427910331906261		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.3427910331906261 | validation: 0.31702138119336176]
	TIME [epoch: 27.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44588580243009446		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.44588580243009446 | validation: 0.35711567129289046]
	TIME [epoch: 27.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3665255607480852		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.3665255607480852 | validation: 0.35412266412158]
	TIME [epoch: 27.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33896238572080073		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.33896238572080073 | validation: 0.34750616233174647]
	TIME [epoch: 27.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36616413708201523		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.36616413708201523 | validation: 0.30425287325741246]
	TIME [epoch: 28 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3182591911659193		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.3182591911659193 | validation: 0.34102629990923616]
	TIME [epoch: 28 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33490838046911087		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.33490838046911087 | validation: 0.2925982923210566]
	TIME [epoch: 28 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3173846046837008		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.3173846046837008 | validation: 0.293921387820617]
	TIME [epoch: 28 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925217128553602		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.2925217128553602 | validation: 0.28948598084923627]
	TIME [epoch: 27.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3409465214121015		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.3409465214121015 | validation: 0.3576892004856832]
	TIME [epoch: 28 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574124147620274		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.3574124147620274 | validation: 0.38334556810182085]
	TIME [epoch: 27.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36255735202273165		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.36255735202273165 | validation: 0.2971259429815789]
	TIME [epoch: 27.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29597605166642504		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.29597605166642504 | validation: 0.3228647217842224]
	TIME [epoch: 28 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3883262640070664		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.3883262640070664 | validation: 0.5058159739568534]
	TIME [epoch: 27.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38605338655062427		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.38605338655062427 | validation: 0.28904547238663975]
	TIME [epoch: 28 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033012338743093		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.3033012338743093 | validation: 0.33854697728904726]
	TIME [epoch: 27.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31680493466972953		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.31680493466972953 | validation: 0.3586041954430074]
	TIME [epoch: 27.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34022099001839556		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.34022099001839556 | validation: 0.3575193144761572]
	TIME [epoch: 28 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33244898869120354		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.33244898869120354 | validation: 0.2882665633791692]
	TIME [epoch: 27.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29892427046107856		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.29892427046107856 | validation: 0.30917906024289105]
	TIME [epoch: 27.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30205952830267646		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.30205952830267646 | validation: 0.31053242773972833]
	TIME [epoch: 27.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31676557047662623		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.31676557047662623 | validation: 0.3124257679669089]
	TIME [epoch: 27.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4050603816248045		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.4050603816248045 | validation: 0.4132852265798208]
	TIME [epoch: 27.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3930189479788533		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.3930189479788533 | validation: 0.4167694141844468]
	TIME [epoch: 27.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3455497526173214		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.3455497526173214 | validation: 0.36037081552565964]
	TIME [epoch: 27.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3159104495676138		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.3159104495676138 | validation: 0.3474607179292985]
	TIME [epoch: 28 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32252105523402036		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.32252105523402036 | validation: 0.34987443986917244]
	TIME [epoch: 27.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3403734875288268		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.3403734875288268 | validation: 0.43910923282063047]
	TIME [epoch: 27.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42852981252191846		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.42852981252191846 | validation: 0.42243445551049535]
	TIME [epoch: 27.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4067976457915503		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.4067976457915503 | validation: 0.3470603653313261]
	TIME [epoch: 28 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30253541859817956		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.30253541859817956 | validation: 0.2709372514750181]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_605.pth
	Model improved!!!
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2938616159806295		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.2938616159806295 | validation: 0.309800481750675]
	TIME [epoch: 27.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2994933518778815		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.2994933518778815 | validation: 0.3366667442136976]
	TIME [epoch: 28 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42582012687770027		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.42582012687770027 | validation: 0.43479639085723365]
	TIME [epoch: 28 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4266186096314632		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.4266186096314632 | validation: 0.43220255974587546]
	TIME [epoch: 27.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.401503570310357		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.401503570310357 | validation: 0.4290453353873679]
	TIME [epoch: 28 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4068728815689405		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.4068728815689405 | validation: 0.44276751455581276]
	TIME [epoch: 27.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40905317328332497		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.40905317328332497 | validation: 0.3489662999809985]
	TIME [epoch: 27.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34075614511817326		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.34075614511817326 | validation: 0.3136945632656988]
	TIME [epoch: 27.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32114265018873334		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.32114265018873334 | validation: 0.322754029218473]
	TIME [epoch: 28 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32067814719118254		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.32067814719118254 | validation: 0.3211365638685588]
	TIME [epoch: 27.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3024749408500386		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.3024749408500386 | validation: 0.2493421611366389]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2786103364865501		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.2786103364865501 | validation: 0.24802564654682016]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_617.pth
	Model improved!!!
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2893626790373969		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.2893626790373969 | validation: 0.26461569428817927]
	TIME [epoch: 28 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2643099498043236		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.2643099498043236 | validation: 0.2500257042878254]
	TIME [epoch: 27.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25901653254761814		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.25901653254761814 | validation: 0.2724633631704951]
	TIME [epoch: 28 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595048707911504		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.2595048707911504 | validation: 0.2433729167667035]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_621.pth
	Model improved!!!
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2631546320327245		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.2631546320327245 | validation: 0.25304764813265207]
	TIME [epoch: 27.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27325753957579074		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.27325753957579074 | validation: 0.26061091597841296]
	TIME [epoch: 27.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2993179217221383		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.2993179217221383 | validation: 0.2571326877710307]
	TIME [epoch: 28 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039740544271924		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.3039740544271924 | validation: 0.3457908117968945]
	TIME [epoch: 28 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35994164220748626		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.35994164220748626 | validation: 0.3730814375717419]
	TIME [epoch: 27.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35154619589086405		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.35154619589086405 | validation: 0.4126359632800452]
	TIME [epoch: 28 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39599399556665876		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.39599399556665876 | validation: 0.39653753349748255]
	TIME [epoch: 27.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435729316041556		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.3435729316041556 | validation: 0.2837448301904492]
	TIME [epoch: 28 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2787002430832245		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.2787002430832245 | validation: 0.3736512159517336]
	TIME [epoch: 28 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34750274052131946		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.34750274052131946 | validation: 0.4103436656997391]
	TIME [epoch: 27.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4017224940379379		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.4017224940379379 | validation: 0.470706203204368]
	TIME [epoch: 27.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4213768687504944		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.4213768687504944 | validation: 0.4012931537292529]
	TIME [epoch: 27.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461041694866413		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.3461041694866413 | validation: 0.37284157157978537]
	TIME [epoch: 27.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3625313908067474		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.3625313908067474 | validation: 0.3814727946572806]
	TIME [epoch: 27.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3156765047303114		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.3156765047303114 | validation: 0.33142871940580093]
	TIME [epoch: 27.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30812851964869026		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.30812851964869026 | validation: 0.29518335723028727]
	TIME [epoch: 27.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.332058339292511		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.332058339292511 | validation: 0.3762060203127319]
	TIME [epoch: 27.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3209797140971392		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.3209797140971392 | validation: 0.32755667129131083]
	TIME [epoch: 27.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038368525597674		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.3038368525597674 | validation: 0.27381013606130195]
	TIME [epoch: 27.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26343996068193937		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.26343996068193937 | validation: 0.25667107764661423]
	TIME [epoch: 27.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624907055388094		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.2624907055388094 | validation: 0.38302919505505695]
	TIME [epoch: 27.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30589709312131996		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.30589709312131996 | validation: 0.2552807291618548]
	TIME [epoch: 28 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897068675144224		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.2897068675144224 | validation: 0.30422924230062026]
	TIME [epoch: 27.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31340394876152455		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.31340394876152455 | validation: 0.4056746172087787]
	TIME [epoch: 27.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43629751583846293		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.43629751583846293 | validation: 0.4583418512684073]
	TIME [epoch: 27.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4245444299017848		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.4245444299017848 | validation: 0.4588416367782985]
	TIME [epoch: 28 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4473038897160161		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.4473038897160161 | validation: 0.4199395933260776]
	TIME [epoch: 28 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42157598175952427		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.42157598175952427 | validation: 0.4918661367564414]
	TIME [epoch: 27.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4513528467715443		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.4513528467715443 | validation: 0.43453263502363276]
	TIME [epoch: 27.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4303024817270702		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.4303024817270702 | validation: 0.42085687089658896]
	TIME [epoch: 27.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4360979222487834		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.4360979222487834 | validation: 0.46852205078560005]
	TIME [epoch: 27.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48972630525977867		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.48972630525977867 | validation: 0.4741590492412216]
	TIME [epoch: 28 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4424118076193261		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.4424118076193261 | validation: 0.4327581468044576]
	TIME [epoch: 27.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43167403556543754		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.43167403556543754 | validation: 0.4569391734806309]
	TIME [epoch: 28 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4624256169953938		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.4624256169953938 | validation: 0.47511553143021473]
	TIME [epoch: 27.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44975129192433927		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.44975129192433927 | validation: 0.46020947153612796]
	TIME [epoch: 27.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419440519342955		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.4419440519342955 | validation: 0.4258195981084547]
	TIME [epoch: 27.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4075827603436741		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.4075827603436741 | validation: 0.40129107428995203]
	TIME [epoch: 27.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41173153516610994		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.41173153516610994 | validation: 0.47289343317953686]
	TIME [epoch: 27.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5180770568744368		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.5180770568744368 | validation: 0.47513313098162047]
	TIME [epoch: 27.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46863711975519196		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.46863711975519196 | validation: 0.46173686881350756]
	TIME [epoch: 27.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4648158853619758		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.4648158853619758 | validation: 0.4426160360070874]
	TIME [epoch: 27.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45089849167188356		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.45089849167188356 | validation: 0.4703506466029465]
	TIME [epoch: 27.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47123451905290353		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.47123451905290353 | validation: 0.4843491282099032]
	TIME [epoch: 27.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4636950803196027		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.4636950803196027 | validation: 0.44404587500781306]
	TIME [epoch: 27.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40519297248911773		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.40519297248911773 | validation: 0.36984869831251277]
	TIME [epoch: 27.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3514935912619569		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.3514935912619569 | validation: 0.3500696332683759]
	TIME [epoch: 27.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42445152781290174		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.42445152781290174 | validation: 0.4755725809345861]
	TIME [epoch: 27.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4831976034224034		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.4831976034224034 | validation: 0.4551854715310161]
	TIME [epoch: 27.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46567286277898984		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.46567286277898984 | validation: 0.4705222933894582]
	TIME [epoch: 27.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40960465393089285		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.40960465393089285 | validation: 0.37352784833776964]
	TIME [epoch: 27.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507250234026711		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.3507250234026711 | validation: 0.33255988376121204]
	TIME [epoch: 27.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.310425139399166		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.310425139399166 | validation: 0.2917837950433532]
	TIME [epoch: 27.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27693583488142104		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.27693583488142104 | validation: 0.29038734916338715]
	TIME [epoch: 27.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3144875617754655		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.3144875617754655 | validation: 0.3458047700664888]
	TIME [epoch: 27.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039097496565937		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.3039097496565937 | validation: 0.25476085231264894]
	TIME [epoch: 27.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27715805731915016		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.27715805731915016 | validation: 0.2607781017814177]
	TIME [epoch: 27.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26349059368939776		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.26349059368939776 | validation: 0.3034533955240335]
	TIME [epoch: 27.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29396265436017455		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.29396265436017455 | validation: 0.28837751628428554]
	TIME [epoch: 27.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858119288490242		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.2858119288490242 | validation: 0.26389731476287803]
	TIME [epoch: 27.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33744300234087043		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.33744300234087043 | validation: 0.46077861219567584]
	TIME [epoch: 27.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5051739876376127		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.5051739876376127 | validation: 0.43139589842051407]
	TIME [epoch: 27.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41804308100856563		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.41804308100856563 | validation: 0.35547093971131993]
	TIME [epoch: 27.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37169910953603824		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.37169910953603824 | validation: 0.32846183180883787]
	TIME [epoch: 27.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3377560310720491		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.3377560310720491 | validation: 0.32425697478654864]
	TIME [epoch: 27.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4193582421856139		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.4193582421856139 | validation: 0.5167128611664827]
	TIME [epoch: 27.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5650049245940114		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.5650049245940114 | validation: 0.5828942850645888]
	TIME [epoch: 27.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8234791399360414		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.8234791399360414 | validation: 0.9039281881446587]
	TIME [epoch: 27.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8775588987936705		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.8775588987936705 | validation: 0.7562952751011551]
	TIME [epoch: 27.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7341949661783939		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.7341949661783939 | validation: 0.5357250029795984]
	TIME [epoch: 27.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5364558350387711		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.5364558350387711 | validation: 0.3947110628291067]
	TIME [epoch: 27.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40135492628186437		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.40135492628186437 | validation: 0.36137527488766646]
	TIME [epoch: 27.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37377067936695363		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.37377067936695363 | validation: 0.3874081602741501]
	TIME [epoch: 28 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.407626599040801		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.407626599040801 | validation: 0.3670690194071291]
	TIME [epoch: 27.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4336174061696424		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.4336174061696424 | validation: 0.5144189468125392]
	TIME [epoch: 27.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.613848971594766		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.613848971594766 | validation: 0.5226182109268307]
	TIME [epoch: 27.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5643770143484668		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.5643770143484668 | validation: 0.47634681098717907]
	TIME [epoch: 27.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.52668893012423		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.52668893012423 | validation: 0.47132401608460733]
	TIME [epoch: 27.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5095228272445298		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.5095228272445298 | validation: 0.43118100523463554]
	TIME [epoch: 28 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44877488463358156		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.44877488463358156 | validation: 0.39460496501088943]
	TIME [epoch: 27.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4485125699152187		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.4485125699152187 | validation: 0.37969247306842574]
	TIME [epoch: 27.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40646260534998313		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.40646260534998313 | validation: 0.4343304247212534]
	TIME [epoch: 28 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5621897848971557		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.5621897848971557 | validation: 0.5633039192628816]
	TIME [epoch: 27.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5698148492846872		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.5698148492846872 | validation: 0.4663143408742778]
	TIME [epoch: 27.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189247766832835		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.5189247766832835 | validation: 0.5064865375137605]
	TIME [epoch: 27.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.589675535656508		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.589675535656508 | validation: 0.5491587103427625]
	TIME [epoch: 27.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5712065424370131		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.5712065424370131 | validation: 0.48300742279306363]
	TIME [epoch: 27.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4383056820689234		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.4383056820689234 | validation: 0.3799186947083859]
	TIME [epoch: 27.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4103202300449852		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.4103202300449852 | validation: 0.37945173732967746]
	TIME [epoch: 27.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42709630599587		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.42709630599587 | validation: 0.49221334703981084]
	TIME [epoch: 27.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47976671113346586		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.47976671113346586 | validation: 0.40929025926530443]
	TIME [epoch: 27.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4389914210584551		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.4389914210584551 | validation: 0.4630166141717447]
	TIME [epoch: 27.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38476943599181523		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.38476943599181523 | validation: 0.3085669632294092]
	TIME [epoch: 27.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32471744624179777		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.32471744624179777 | validation: 0.2895701682675945]
	TIME [epoch: 27.9 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2984028459590682		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.2984028459590682 | validation: 0.27840519898786675]
	TIME [epoch: 27.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31091679828507557		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.31091679828507557 | validation: 0.3177113663115297]
	TIME [epoch: 27.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35107993072025867		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.35107993072025867 | validation: 0.3367947923060812]
	TIME [epoch: 28 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3450390350126922		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.3450390350126922 | validation: 0.29749446869648033]
	TIME [epoch: 27.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31896738272806985		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.31896738272806985 | validation: 0.2816177101403852]
	TIME [epoch: 27.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28506576216902807		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.28506576216902807 | validation: 0.29678703911234616]
	TIME [epoch: 27.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30251478894538236		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.30251478894538236 | validation: 0.27472533606086513]
	TIME [epoch: 27.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2910396476614822		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.2910396476614822 | validation: 0.25357115518018025]
	TIME [epoch: 27.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2945628911031575		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.2945628911031575 | validation: 0.3376824929821894]
	TIME [epoch: 27.9 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34303152895520006		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.34303152895520006 | validation: 0.31659265594333236]
	TIME [epoch: 27.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31388044444193247		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.31388044444193247 | validation: 0.2719519500612215]
	TIME [epoch: 27.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2809619223535684		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.2809619223535684 | validation: 0.27119251711919684]
	TIME [epoch: 28 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2730866016122441		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.2730866016122441 | validation: 0.30894045591352254]
	TIME [epoch: 27.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3658848457661932		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.3658848457661932 | validation: 0.3232906899356604]
	TIME [epoch: 27.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3775099684473118		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.3775099684473118 | validation: 0.4407250213384583]
	TIME [epoch: 27.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4297757618164446		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.4297757618164446 | validation: 0.4070431815932231]
	TIME [epoch: 27.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4014538557355583		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.4014538557355583 | validation: 0.3766131365129058]
	TIME [epoch: 27.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295569904664778		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.3295569904664778 | validation: 0.29305938122103653]
	TIME [epoch: 27.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3094744483060819		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.3094744483060819 | validation: 0.296971512817914]
	TIME [epoch: 27.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3238219028384843		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.3238219028384843 | validation: 0.4209556386556846]
	TIME [epoch: 27.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4062958286003995		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.4062958286003995 | validation: 0.3373058512904062]
	TIME [epoch: 27.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32086661823061663		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.32086661823061663 | validation: 0.3054617565076438]
	TIME [epoch: 27.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3183927670196077		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.3183927670196077 | validation: 0.29482755644748926]
	TIME [epoch: 27.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30985000893697956		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.30985000893697956 | validation: 0.27588521682109474]
	TIME [epoch: 27.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2988334184132742		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.2988334184132742 | validation: 0.26020162570972194]
	TIME [epoch: 27.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26994145545069514		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.26994145545069514 | validation: 0.256482094587308]
	TIME [epoch: 28 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778227066702734		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.2778227066702734 | validation: 0.2764497284889128]
	TIME [epoch: 27.9 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30469659839001856		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.30469659839001856 | validation: 0.3140423929969813]
	TIME [epoch: 28 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31132897873081444		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.31132897873081444 | validation: 0.29844981165672985]
	TIME [epoch: 28 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318860803196984		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.3318860803196984 | validation: 0.3590101075277667]
	TIME [epoch: 28 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3549535502821612		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.3549535502821612 | validation: 0.3254302941153718]
	TIME [epoch: 28 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3279426368417595		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.3279426368417595 | validation: 0.3416617886949836]
	TIME [epoch: 28 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3361766630933566		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.3361766630933566 | validation: 0.3157402433637026]
	TIME [epoch: 27.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3293441970272074		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.3293441970272074 | validation: 0.29893162460357464]
	TIME [epoch: 27.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31239322471633796		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.31239322471633796 | validation: 0.32493443883018264]
	TIME [epoch: 27.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3345567391586318		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.3345567391586318 | validation: 0.3172589444311947]
	TIME [epoch: 28 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34345229982332015		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.34345229982332015 | validation: 0.3025069798322838]
	TIME [epoch: 27.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3509303062866587		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.3509303062866587 | validation: 0.39488239631410893]
	TIME [epoch: 27.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37597212061152396		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.37597212061152396 | validation: 0.32699323727658836]
	TIME [epoch: 27.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3561720411235155		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.3561720411235155 | validation: 0.34790861230341635]
	TIME [epoch: 27.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3748522689361584		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.3748522689361584 | validation: 0.3872023128253727]
	TIME [epoch: 28 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4862874993273675		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.4862874993273675 | validation: 0.5884653080063998]
	TIME [epoch: 27.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5218874066179192		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.5218874066179192 | validation: 0.38221941697066614]
	TIME [epoch: 27.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39466763199500277		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.39466763199500277 | validation: 0.3821762144819637]
	TIME [epoch: 27.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34465396296283823		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.34465396296283823 | validation: 0.2955145296201222]
	TIME [epoch: 27.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28896995999805525		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.28896995999805525 | validation: 0.27001455611975117]
	TIME [epoch: 28 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2961732881949348		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.2961732881949348 | validation: 0.33145383718902177]
	TIME [epoch: 28 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33885101845443055		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.33885101845443055 | validation: 0.2946625636759142]
	TIME [epoch: 27.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3371160688835808		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.3371160688835808 | validation: 0.38695444145780294]
	TIME [epoch: 28 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3995408731453174		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.3995408731453174 | validation: 0.39511233538918666]
	TIME [epoch: 28 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36165035357201414		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.36165035357201414 | validation: 0.3308567541551302]
	TIME [epoch: 27.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32854574455022484		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.32854574455022484 | validation: 0.3168204158139455]
	TIME [epoch: 27.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442133676960918		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.3442133676960918 | validation: 0.38309290588354555]
	TIME [epoch: 27.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36832445692964966		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.36832445692964966 | validation: 0.3160839559056786]
	TIME [epoch: 27.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33595406761141533		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.33595406761141533 | validation: 0.3412301271637642]
	TIME [epoch: 27.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2993208035414957		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.2993208035414957 | validation: 0.2801933905236311]
	TIME [epoch: 28 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2774251827418641		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.2774251827418641 | validation: 0.26237098883605897]
	TIME [epoch: 28 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2826651885326679		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.2826651885326679 | validation: 0.2886394557126786]
	TIME [epoch: 27.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2903558473723685		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.2903558473723685 | validation: 0.28296024309125983]
	TIME [epoch: 28 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2902323098987512		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.2902323098987512 | validation: 0.2966451808787837]
	TIME [epoch: 27.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34037885124272715		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.34037885124272715 | validation: 0.35309616433640884]
	TIME [epoch: 28 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34484438159290387		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.34484438159290387 | validation: 0.31973613792002126]
	TIME [epoch: 27.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35121765512643804		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.35121765512643804 | validation: 0.36081897081351894]
	TIME [epoch: 27.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37543354764255343		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.37543354764255343 | validation: 0.42170707159673326]
	TIME [epoch: 27.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4183091035800899		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.4183091035800899 | validation: 0.3905950565936499]
	TIME [epoch: 27.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39631189085371404		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.39631189085371404 | validation: 0.3565742928296465]
	TIME [epoch: 27.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37056315781850113		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.37056315781850113 | validation: 0.35757636592696157]
	TIME [epoch: 27.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3545647331734585		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.3545647331734585 | validation: 0.35044255345158676]
	TIME [epoch: 27.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34422896343751713		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.34422896343751713 | validation: 0.329979321830967]
	TIME [epoch: 27.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453725304866821		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.3453725304866821 | validation: 0.3296141521298623]
	TIME [epoch: 27.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3080680860919127		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.3080680860919127 | validation: 0.268608388541646]
	TIME [epoch: 27.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2956143228961184		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.2956143228961184 | validation: 0.3155239655075362]
	TIME [epoch: 27.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3090014918749255		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.3090014918749255 | validation: 0.31808669747234786]
	TIME [epoch: 27.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31647520819152125		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.31647520819152125 | validation: 0.26917711561527197]
	TIME [epoch: 27.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2738424784076364		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.2738424784076364 | validation: 0.2626885155907223]
	TIME [epoch: 27.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2643248421930346		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.2643248421930346 | validation: 0.25123696211855445]
	TIME [epoch: 27.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27518963872909424		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.27518963872909424 | validation: 0.29614353653724096]
	TIME [epoch: 27.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3014367967336134		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.3014367967336134 | validation: 0.31372271725032613]
	TIME [epoch: 27.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31736668280525365		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.31736668280525365 | validation: 0.34271975440587527]
	TIME [epoch: 27.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3653158382217462		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.3653158382217462 | validation: 0.37695606933826215]
	TIME [epoch: 27.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37585489635466396		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.37585489635466396 | validation: 0.3822653348649206]
	TIME [epoch: 27.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40978406975749004		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.40978406975749004 | validation: 0.44587444041350355]
	TIME [epoch: 27.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3753319357353342		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.3753319357353342 | validation: 0.31592676586157326]
	TIME [epoch: 27.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31702891383036913		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.31702891383036913 | validation: 0.2862496295193355]
	TIME [epoch: 27.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2779267979833655		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.2779267979833655 | validation: 0.2629750653684263]
	TIME [epoch: 27.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29608683920807655		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.29608683920807655 | validation: 0.2631349961786432]
	TIME [epoch: 27.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509598103867956		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.2509598103867956 | validation: 0.2466175125904509]
	TIME [epoch: 28 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25223279662493564		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.25223279662493564 | validation: 0.25340779161464555]
	TIME [epoch: 27.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25128761086576873		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.25128761086576873 | validation: 0.2716979293034395]
	TIME [epoch: 28 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2402167980732303		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.2402167980732303 | validation: 0.2202596735851605]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_805.pth
	Model improved!!!
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2248219198154768		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.2248219198154768 | validation: 0.2288462155842227]
	TIME [epoch: 27.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24786705695190603		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.24786705695190603 | validation: 0.25767539217849117]
	TIME [epoch: 28 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2631652610500991		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.2631652610500991 | validation: 0.2392492072428361]
	TIME [epoch: 27.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2345672014279298		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.2345672014279298 | validation: 0.22745569437468774]
	TIME [epoch: 27.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22370011629646952		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.22370011629646952 | validation: 0.20695154851142245]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.228976587904486		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.228976587904486 | validation: 0.27724123145840557]
	TIME [epoch: 27.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719250556878261		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.2719250556878261 | validation: 0.27836520474983345]
	TIME [epoch: 27.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2694282079629834		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.2694282079629834 | validation: 0.28789680499945275]
	TIME [epoch: 27.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2835828875016033		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.2835828875016033 | validation: 0.34559869269369187]
	TIME [epoch: 27.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34514619227236465		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.34514619227236465 | validation: 0.3489569014335859]
	TIME [epoch: 27.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33770890802070813		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.33770890802070813 | validation: 0.2709621135105879]
	TIME [epoch: 27.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2867932136706555		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.2867932136706555 | validation: 0.28665451957213256]
	TIME [epoch: 27.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28909462494687554		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.28909462494687554 | validation: 0.30322970242268954]
	TIME [epoch: 27.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30493877273187275		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.30493877273187275 | validation: 0.29467683865452066]
	TIME [epoch: 27.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2672027575898777		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.2672027575898777 | validation: 0.2396744200766215]
	TIME [epoch: 28 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24176408287844228		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.24176408287844228 | validation: 0.2551306885171447]
	TIME [epoch: 27.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26342280811484536		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.26342280811484536 | validation: 0.23196878543542085]
	TIME [epoch: 28 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2433527835103734		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.2433527835103734 | validation: 0.21234208995672582]
	TIME [epoch: 27.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22317428936991174		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.22317428936991174 | validation: 0.23386353305020044]
	TIME [epoch: 27.9 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23745145941219487		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.23745145941219487 | validation: 0.2435664086856282]
	TIME [epoch: 28 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31607823733859697		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.31607823733859697 | validation: 0.34926655068870477]
	TIME [epoch: 27.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34246758323498255		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.34246758323498255 | validation: 0.34351944995614125]
	TIME [epoch: 27.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3739017322991758		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.3739017322991758 | validation: 0.4382163048575152]
	TIME [epoch: 27.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43212610115706807		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.43212610115706807 | validation: 0.3481627629711124]
	TIME [epoch: 27.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36557504495299326		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.36557504495299326 | validation: 0.34672917272376924]
	TIME [epoch: 27.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.374078975592545		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.374078975592545 | validation: 0.3190926924708199]
	TIME [epoch: 27.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31052304419256677		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.31052304419256677 | validation: 0.3013540845169242]
	TIME [epoch: 27.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507356399643987		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.3507356399643987 | validation: 0.369506608124737]
	TIME [epoch: 27.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3807476619811765		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.3807476619811765 | validation: 0.3152274801521488]
	TIME [epoch: 27.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29787441468103387		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.29787441468103387 | validation: 0.2573585826491726]
	TIME [epoch: 27.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26019150606328734		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.26019150606328734 | validation: 0.2501195124339111]
	TIME [epoch: 27.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2441832948290646		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.2441832948290646 | validation: 0.21756102204863]
	TIME [epoch: 27.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22501204629835234		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.22501204629835234 | validation: 0.23266928137328072]
	TIME [epoch: 27.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2526485210147092		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.2526485210147092 | validation: 0.2785081310659722]
	TIME [epoch: 27.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24135128804696154		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.24135128804696154 | validation: 0.22000236845738086]
	TIME [epoch: 28 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21576454884612117		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.21576454884612117 | validation: 0.2105028194451099]
	TIME [epoch: 27.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21195364494246804		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.21195364494246804 | validation: 0.21623841087576787]
	TIME [epoch: 28 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22361010584695476		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.22361010584695476 | validation: 0.2603578613474621]
	TIME [epoch: 27.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24916900455180943		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.24916900455180943 | validation: 0.2392417991043462]
	TIME [epoch: 27.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24454196909285825		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.24454196909285825 | validation: 0.24683906167631697]
	TIME [epoch: 28 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2280803438972231		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.2280803438972231 | validation: 0.23114164690584915]
	TIME [epoch: 27.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2155279693046371		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.2155279693046371 | validation: 0.23791369332028445]
	TIME [epoch: 27.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21973718182391952		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.21973718182391952 | validation: 0.22156965712739635]
	TIME [epoch: 27.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23293689236495377		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.23293689236495377 | validation: 0.2651181306138164]
	TIME [epoch: 27.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25749866581505865		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.25749866581505865 | validation: 0.2595783948296637]
	TIME [epoch: 27.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2481169367986783		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.2481169367986783 | validation: 0.26883308611814366]
	TIME [epoch: 27.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24124501890174643		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.24124501890174643 | validation: 0.2618985653404677]
	TIME [epoch: 27.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2577915985503388		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.2577915985503388 | validation: 0.2509770218072635]
	TIME [epoch: 27.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26784271611285027		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.26784271611285027 | validation: 0.296892924267407]
	TIME [epoch: 27.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2814937111796223		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.2814937111796223 | validation: 0.33331172412410126]
	TIME [epoch: 27.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29009840225863165		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.29009840225863165 | validation: 0.3148592885325845]
	TIME [epoch: 27.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2869738944788403		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.2869738944788403 | validation: 0.31244679847657725]
	TIME [epoch: 27.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30647442257200375		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.30647442257200375 | validation: 0.3090178307995391]
	TIME [epoch: 28 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790846895344296		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.2790846895344296 | validation: 0.2801269354328508]
	TIME [epoch: 27.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24971558189288062		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.24971558189288062 | validation: 0.27068057650360394]
	TIME [epoch: 28 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601302812625617		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.2601302812625617 | validation: 0.2659021914787185]
	TIME [epoch: 27.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.255506130213805		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.255506130213805 | validation: 0.2703160051199272]
	TIME [epoch: 27.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519837482763563		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.2519837482763563 | validation: 0.28571572430531955]
	TIME [epoch: 27.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740229809030933		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.2740229809030933 | validation: 0.27265376343544434]
	TIME [epoch: 27.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2442484899285573		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.2442484899285573 | validation: 0.24706014242450913]
	TIME [epoch: 27.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23807235219779993		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.23807235219779993 | validation: 0.24301749078690404]
	TIME [epoch: 27.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23819841209344253		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.23819841209344253 | validation: 0.2500729428191425]
	TIME [epoch: 27.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23517170918153707		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.23517170918153707 | validation: 0.23877188023753332]
	TIME [epoch: 27.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24190311716004564		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.24190311716004564 | validation: 0.24281485104673306]
	TIME [epoch: 27.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24194081722143662		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.24194081722143662 | validation: 0.2360098242367365]
	TIME [epoch: 28 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24483559169497304		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.24483559169497304 | validation: 0.2562345434653509]
	TIME [epoch: 28 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23422852207699685		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.23422852207699685 | validation: 0.22404101220462244]
	TIME [epoch: 27.9 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23055875970454803		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.23055875970454803 | validation: 0.21306164370912797]
	TIME [epoch: 27.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2383414232853756		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.2383414232853756 | validation: 0.23740730984036795]
	TIME [epoch: 27.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2466477181159248		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.2466477181159248 | validation: 0.24094901863263382]
	TIME [epoch: 27.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2478014511771594		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.2478014511771594 | validation: 0.23076501588805926]
	TIME [epoch: 28 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24085745112644796		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.24085745112644796 | validation: 0.26499608987096435]
	TIME [epoch: 27.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29085986540776865		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.29085986540776865 | validation: 0.2863690247331211]
	TIME [epoch: 28 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2959086794127657		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.2959086794127657 | validation: 0.2463600560886338]
	TIME [epoch: 28 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626285100712364		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.2626285100712364 | validation: 0.24680986935396262]
	TIME [epoch: 28 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25909309911999945		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.25909309911999945 | validation: 0.2400602581481577]
	TIME [epoch: 28 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25908195291114594		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.25908195291114594 | validation: 0.22736943638168583]
	TIME [epoch: 27.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24578748356220118		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.24578748356220118 | validation: 0.2349716091045545]
	TIME [epoch: 27.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2386298965783187		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.2386298965783187 | validation: 0.2281659801322957]
	TIME [epoch: 27.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23398969616521637		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.23398969616521637 | validation: 0.2289782790110109]
	TIME [epoch: 27.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23457389756982974		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.23457389756982974 | validation: 0.222485694707871]
	TIME [epoch: 28 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2214484760408621		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.2214484760408621 | validation: 0.21335509731687133]
	TIME [epoch: 27.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20574918006868903		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.20574918006868903 | validation: 0.21634416549733484]
	TIME [epoch: 28 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2128912347374431		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.2128912347374431 | validation: 0.22924738066558412]
	TIME [epoch: 27.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22871480012228718		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.22871480012228718 | validation: 0.24251295815865212]
	TIME [epoch: 27.9 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22766517434418887		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.22766517434418887 | validation: 0.20903231020730326]
	TIME [epoch: 28 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20979550619550558		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.20979550619550558 | validation: 0.2138301514176336]
	TIME [epoch: 27.9 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21169190664109466		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.21169190664109466 | validation: 0.21370588010614916]
	TIME [epoch: 27.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2153263932355695		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.2153263932355695 | validation: 0.22604143703378451]
	TIME [epoch: 28 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22549943144206758		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.22549943144206758 | validation: 0.21897691662202745]
	TIME [epoch: 27.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2110857434765458		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.2110857434765458 | validation: 0.20905259413384641]
	TIME [epoch: 28 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2125939714047675		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.2125939714047675 | validation: 0.21331375791192003]
	TIME [epoch: 27.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21027351213647438		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.21027351213647438 | validation: 0.22601770086751663]
	TIME [epoch: 28 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22458338343033865		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.22458338343033865 | validation: 0.24989315146169389]
	TIME [epoch: 28 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2424161145578351		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.2424161145578351 | validation: 0.2165994468537478]
	TIME [epoch: 28 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21244857429152456		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.21244857429152456 | validation: 0.21567045222630937]
	TIME [epoch: 28 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21434568127171966		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.21434568127171966 | validation: 0.2210517486830095]
	TIME [epoch: 28 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21326615505653235		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.21326615505653235 | validation: 0.22360402626579007]
	TIME [epoch: 28 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21000615642787338		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.21000615642787338 | validation: 0.2226147791423923]
	TIME [epoch: 28 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22643930556970324		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.22643930556970324 | validation: 0.2378660511346272]
	TIME [epoch: 27.9 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22136830778742478		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.22136830778742478 | validation: 0.2258417635996765]
	TIME [epoch: 28 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20888771564092914		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.20888771564092914 | validation: 0.2217575560671109]
	TIME [epoch: 27.9 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21515407769509873		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.21515407769509873 | validation: 0.22853107224178043]
	TIME [epoch: 28 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21972320323503505		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.21972320323503505 | validation: 0.2236802839579945]
	TIME [epoch: 28 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21062274454114396		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.21062274454114396 | validation: 0.2177680225243953]
	TIME [epoch: 27.9 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20905915859937485		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.20905915859937485 | validation: 0.212128664543121]
	TIME [epoch: 28 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22249139857335162		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.22249139857335162 | validation: 0.23772570811149707]
	TIME [epoch: 27.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23772977810460694		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.23772977810460694 | validation: 0.2629156811500878]
	TIME [epoch: 28 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.239959108057526		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.239959108057526 | validation: 0.23912608074320585]
	TIME [epoch: 28 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21350176256280512		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.21350176256280512 | validation: 0.21986329956973605]
	TIME [epoch: 27.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21407491497337938		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.21407491497337938 | validation: 0.23654667507806992]
	TIME [epoch: 28 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23854862382098702		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.23854862382098702 | validation: 0.28821236445791726]
	TIME [epoch: 27.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26039544851303087		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.26039544851303087 | validation: 0.27723177211336625]
	TIME [epoch: 28 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2580504724042532		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.2580504724042532 | validation: 0.3027712026604443]
	TIME [epoch: 27.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2618928919148071		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.2618928919148071 | validation: 0.25505012964622514]
	TIME [epoch: 27.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23650018135625733		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.23650018135625733 | validation: 0.25070855824488325]
	TIME [epoch: 28 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24441874427012283		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.24441874427012283 | validation: 0.2684155306504495]
	TIME [epoch: 27.9 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24806997934745065		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.24806997934745065 | validation: 0.27139839066007404]
	TIME [epoch: 27.9 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2699529076412467		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.2699529076412467 | validation: 0.29150154624496066]
	TIME [epoch: 28 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27126377250634337		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.27126377250634337 | validation: 0.2406432321645877]
	TIME [epoch: 27.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2280645300535898		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.2280645300535898 | validation: 0.24106709313637611]
	TIME [epoch: 28 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21504390109671842		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.21504390109671842 | validation: 0.20956509690781155]
	TIME [epoch: 27.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21057632944570642		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.21057632944570642 | validation: 0.2172695664204112]
	TIME [epoch: 28 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2205196721278136		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.2205196721278136 | validation: 0.24445119939322943]
	TIME [epoch: 28 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2333294050807943		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.2333294050807943 | validation: 0.24093517696380118]
	TIME [epoch: 27.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23139073563152115		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.23139073563152115 | validation: 0.24919574526286262]
	TIME [epoch: 28 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25980851006394834		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.25980851006394834 | validation: 0.2655358279953018]
	TIME [epoch: 28 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26518392067058866		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.26518392067058866 | validation: 0.2543600704392938]
	TIME [epoch: 28 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2591272437532183		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.2591272437532183 | validation: 0.2523805954646319]
	TIME [epoch: 27.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2528556573987727		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.2528556573987727 | validation: 0.2540337497512134]
	TIME [epoch: 27.9 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22592911677318142		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.22592911677318142 | validation: 0.2189808859644679]
	TIME [epoch: 27.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2231688227079418		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.2231688227079418 | validation: 0.256554061134494]
	TIME [epoch: 28 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24665060498464084		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.24665060498464084 | validation: 0.24787831227049176]
	TIME [epoch: 27.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519956378313804		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.2519956378313804 | validation: 0.281861668454053]
	TIME [epoch: 28 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27595655171856714		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.27595655171856714 | validation: 0.28326440611310794]
	TIME [epoch: 28 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29977688310869705		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.29977688310869705 | validation: 0.3547599693621612]
	TIME [epoch: 28 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3444522754637052		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.3444522754637052 | validation: 0.32754552950844473]
	TIME [epoch: 28 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049940219307078		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.3049940219307078 | validation: 0.29020071562587396]
	TIME [epoch: 27.9 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758502350444305		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.2758502350444305 | validation: 0.27599373509511615]
	TIME [epoch: 28 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2873065314728721		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.2873065314728721 | validation: 0.3241755918707939]
	TIME [epoch: 28 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29007369138145794		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.29007369138145794 | validation: 0.30169262507583694]
	TIME [epoch: 27.9 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2797713846443989		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.2797713846443989 | validation: 0.2764152121196626]
	TIME [epoch: 28 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766519804276375		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.2766519804276375 | validation: 0.2656041023900279]
	TIME [epoch: 27.9 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26371406720652313		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.26371406720652313 | validation: 0.2798257419775891]
	TIME [epoch: 27.9 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26401692330140214		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.26401692330140214 | validation: 0.2427785575448569]
	TIME [epoch: 27.9 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23455251849490003		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.23455251849490003 | validation: 0.22996195560534674]
	TIME [epoch: 28 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22681288071695435		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.22681288071695435 | validation: 0.23615850134120167]
	TIME [epoch: 28 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22233555046329342		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.22233555046329342 | validation: 0.22791542289641342]
	TIME [epoch: 27.9 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22239922967957124		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.22239922967957124 | validation: 0.2205729772272558]
	TIME [epoch: 28 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22270261536648242		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.22270261536648242 | validation: 0.2242156548850505]
	TIME [epoch: 27.9 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21200425808080411		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.21200425808080411 | validation: 0.20151069378587586]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_956.pth
	Model improved!!!
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2070421145316931		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.2070421145316931 | validation: 0.2201089222909501]
	TIME [epoch: 28 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21172121704892602		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.21172121704892602 | validation: 0.211153546764581]
	TIME [epoch: 27.9 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21218349850744267		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.21218349850744267 | validation: 0.2217410221518117]
	TIME [epoch: 28 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2068780764815687		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.2068780764815687 | validation: 0.2190585027517984]
	TIME [epoch: 28 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21808019422488356		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.21808019422488356 | validation: 0.22782399076873955]
	TIME [epoch: 28 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20892290241452124		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.20892290241452124 | validation: 0.21300062785850726]
	TIME [epoch: 28 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20485295430243564		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.20485295430243564 | validation: 0.23519988703827718]
	TIME [epoch: 27.9 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23332462706257734		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.23332462706257734 | validation: 0.21376620307225253]
	TIME [epoch: 27.9 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21180575888416442		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.21180575888416442 | validation: 0.21355227410445324]
	TIME [epoch: 28 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20799484534255966		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.20799484534255966 | validation: 0.21523038428441976]
	TIME [epoch: 28 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21240323834037783		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.21240323834037783 | validation: 0.20312311322522952]
	TIME [epoch: 28 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20568871409236597		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.20568871409236597 | validation: 0.22991573964861103]
	TIME [epoch: 28 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22192170245602647		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.22192170245602647 | validation: 0.20940091251723858]
	TIME [epoch: 27.9 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20079912538410194		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.20079912538410194 | validation: 0.21183069993307554]
	TIME [epoch: 28 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20579379984972873		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.20579379984972873 | validation: 0.21060186493922217]
	TIME [epoch: 27.9 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2310530980167396		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.2310530980167396 | validation: 0.24290080191643248]
	TIME [epoch: 28 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23787174290286547		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.23787174290286547 | validation: 0.21734353491999842]
	TIME [epoch: 28 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20774804067673122		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.20774804067673122 | validation: 0.2048722444261563]
	TIME [epoch: 28 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2125361679473431		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.2125361679473431 | validation: 0.23286179090558123]
	TIME [epoch: 28 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22444888328088655		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.22444888328088655 | validation: 0.22668813030819826]
	TIME [epoch: 28 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2189789173891683		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.2189789173891683 | validation: 0.22586585974636755]
	TIME [epoch: 27.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22942669779793745		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.22942669779793745 | validation: 0.23618762108210448]
	TIME [epoch: 28 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21793253038460111		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.21793253038460111 | validation: 0.2311044779944865]
	TIME [epoch: 28 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21259672818966202		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.21259672818966202 | validation: 0.22219276442860547]
	TIME [epoch: 28 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20773548275490086		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.20773548275490086 | validation: 0.2103786215266758]
	TIME [epoch: 27.9 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19945976030108686		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.19945976030108686 | validation: 0.2053555002493415]
	TIME [epoch: 28 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20819744668711201		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.20819744668711201 | validation: 0.21299980187905362]
	TIME [epoch: 28 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20116506208125778		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.20116506208125778 | validation: 0.20549384549347005]
	TIME [epoch: 28 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1997678242310178		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.1997678242310178 | validation: 0.2021343766438384]
	TIME [epoch: 27.9 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19703293643370073		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.19703293643370073 | validation: 0.20839186698087805]
	TIME [epoch: 28 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2024071320594953		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.2024071320594953 | validation: 0.195042098461932]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_987.pth
	Model improved!!!
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20286265317045427		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.20286265317045427 | validation: 0.2090146495236444]
	TIME [epoch: 28 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023004818638306		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.2023004818638306 | validation: 0.19503614743769437]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_989.pth
	Model improved!!!
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2038423128266078		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.2038423128266078 | validation: 0.20634880246248863]
	TIME [epoch: 28 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20721617435221598		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.20721617435221598 | validation: 0.21097872405444493]
	TIME [epoch: 27.9 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2070426379018755		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.2070426379018755 | validation: 0.20036977495934238]
	TIME [epoch: 27.9 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19972348597781572		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.19972348597781572 | validation: 0.20614850620373723]
	TIME [epoch: 27.9 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21017715671032072		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.21017715671032072 | validation: 0.2207322001311323]
	TIME [epoch: 27.9 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22292102152981608		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.22292102152981608 | validation: 0.21472781326096838]
	TIME [epoch: 28 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21980601407195519		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.21980601407195519 | validation: 0.24686279594877128]
	TIME [epoch: 28 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23012583195801478		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.23012583195801478 | validation: 0.22797347047068262]
	TIME [epoch: 28 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21893162347197495		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.21893162347197495 | validation: 0.20866452214993192]
	TIME [epoch: 27.9 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20831917116652354		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.20831917116652354 | validation: 0.20414757224239147]
	TIME [epoch: 28 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20318655663824778		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.20318655663824778 | validation: 0.19352364878332387]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_1000.pth
	Model improved!!!
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20457174864956557		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.20457174864956557 | validation: 0.21071810735854718]
	TIME [epoch: 27.9 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2036823002109764		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.2036823002109764 | validation: 0.199798065201751]
	TIME [epoch: 27.9 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20603537809400993		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.20603537809400993 | validation: 0.20518373616648206]
	TIME [epoch: 28 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2018746740542894		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.2018746740542894 | validation: 0.19566477990126857]
	TIME [epoch: 27.9 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20142755267356088		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.20142755267356088 | validation: 0.20445110659815263]
	TIME [epoch: 27.9 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2061039040362276		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.2061039040362276 | validation: 0.2175733847718001]
	TIME [epoch: 27.9 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21750433602046654		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.21750433602046654 | validation: 0.20876428939545094]
	TIME [epoch: 28 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21255322388758394		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.21255322388758394 | validation: 0.2078181911455849]
	TIME [epoch: 28 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20270067685022614		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.20270067685022614 | validation: 0.21333407167798585]
	TIME [epoch: 28 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.207217847692378		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.207217847692378 | validation: 0.20354652738472256]
	TIME [epoch: 28 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21131445918154046		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.21131445918154046 | validation: 0.2048668102577996]
	TIME [epoch: 27.9 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20800109579672835		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.20800109579672835 | validation: 0.23218024183299102]
	TIME [epoch: 28 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2143549394897356		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.2143549394897356 | validation: 0.22230086996542267]
	TIME [epoch: 28 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22028114518070285		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.22028114518070285 | validation: 0.2375223599892655]
	TIME [epoch: 27.9 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23839622620748668		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.23839622620748668 | validation: 0.238876036637869]
	TIME [epoch: 28 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23097125816236935		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.23097125816236935 | validation: 0.22750882850928306]
	TIME [epoch: 27.9 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22035915332471542		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.22035915332471542 | validation: 0.21453095074985373]
	TIME [epoch: 27.9 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21023399281412192		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.21023399281412192 | validation: 0.23080454122798422]
	TIME [epoch: 27.9 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22281062067482918		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.22281062067482918 | validation: 0.20827619047457124]
	TIME [epoch: 27.9 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21580888763767525		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.21580888763767525 | validation: 0.24047290296366286]
	TIME [epoch: 28 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2295930032842785		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.2295930032842785 | validation: 0.24376039898469834]
	TIME [epoch: 28 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22770694140403774		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.22770694140403774 | validation: 0.23415772671622953]
	TIME [epoch: 28 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22606027809513352		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.22606027809513352 | validation: 0.2124253520109922]
	TIME [epoch: 28 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22012601352134037		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.22012601352134037 | validation: 0.2215350030240687]
	TIME [epoch: 27.9 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2343755283201963		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.2343755283201963 | validation: 0.24918881386228978]
	TIME [epoch: 28 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2414179054223869		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.2414179054223869 | validation: 0.22296955691854983]
	TIME [epoch: 28 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2256543495680796		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.2256543495680796 | validation: 0.2340800192437961]
	TIME [epoch: 28 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24624166900512287		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.24624166900512287 | validation: 0.2583254447590565]
	TIME [epoch: 28 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2540758463769115		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.2540758463769115 | validation: 0.26663075578912315]
	TIME [epoch: 27.9 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2598047147580553		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.2598047147580553 | validation: 0.27398479798175523]
	TIME [epoch: 28 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2903240165020287		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.2903240165020287 | validation: 0.3271001933360097]
	TIME [epoch: 27.9 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3593078235194543		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.3593078235194543 | validation: 0.35223744159045994]
	TIME [epoch: 28 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32198604745807413		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.32198604745807413 | validation: 0.2601041142775027]
	TIME [epoch: 28 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25274427833218915		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.25274427833218915 | validation: 0.21501508894172675]
	TIME [epoch: 27.9 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22658927357915618		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.22658927357915618 | validation: 0.2287422860850792]
	TIME [epoch: 28 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2324686066741472		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.2324686066741472 | validation: 0.21712931931588159]
	TIME [epoch: 27.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21132483327828241		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.21132483327828241 | validation: 0.20911489856638882]
	TIME [epoch: 27.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2063614271232		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.2063614271232 | validation: 0.2027415812562335]
	TIME [epoch: 27.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023149593887898		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.2023149593887898 | validation: 0.21107573848041228]
	TIME [epoch: 27.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20160188164017753		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.20160188164017753 | validation: 0.20741017122678987]
	TIME [epoch: 27.9 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19619454973981168		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.19619454973981168 | validation: 0.19769726101809248]
	TIME [epoch: 27.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19945875147425465		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.19945875147425465 | validation: 0.19131543681443688]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_1042.pth
	Model improved!!!
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1973125654066022		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.1973125654066022 | validation: 0.20344084878767937]
	TIME [epoch: 28 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19533914595516158		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.19533914595516158 | validation: 0.1901788517392517]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_1044.pth
	Model improved!!!
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19154426542132325		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.19154426542132325 | validation: 0.202962677029223]
	TIME [epoch: 28 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20122639097088005		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.20122639097088005 | validation: 0.18940149218756105]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_1046.pth
	Model improved!!!
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19260234219599182		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.19260234219599182 | validation: 0.19851019385813012]
	TIME [epoch: 27.9 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19367471814080056		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.19367471814080056 | validation: 0.19057752091092284]
	TIME [epoch: 27.9 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1968762190988579		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.1968762190988579 | validation: 0.1920346554936618]
	TIME [epoch: 27.9 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19727179622803562		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.19727179622803562 | validation: 0.1976717193484732]
	TIME [epoch: 27.9 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19073417168864246		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.19073417168864246 | validation: 0.1944265498257724]
	TIME [epoch: 27.9 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1976831946799388		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.1976831946799388 | validation: 0.21307291409005558]
	TIME [epoch: 27.9 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2077682947188749		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.2077682947188749 | validation: 0.2023599064141072]
	TIME [epoch: 27.9 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19724872413794922		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.19724872413794922 | validation: 0.20168241584280844]
	TIME [epoch: 27.9 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19546907366356106		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.19546907366356106 | validation: 0.19923838715259812]
	TIME [epoch: 27.9 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20868192484989503		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.20868192484989503 | validation: 0.19990624542163463]
	TIME [epoch: 28 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20102920415038222		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.20102920415038222 | validation: 0.20437898167116741]
	TIME [epoch: 28 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1985030330056099		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.1985030330056099 | validation: 0.21554432924052497]
	TIME [epoch: 28 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21113553132837337		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.21113553132837337 | validation: 0.2112594287898215]
	TIME [epoch: 28 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21196338413116705		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.21196338413116705 | validation: 0.20863128250648527]
	TIME [epoch: 27.9 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20291754448218632		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.20291754448218632 | validation: 0.19444392277801156]
	TIME [epoch: 28 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1950047307457727		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.1950047307457727 | validation: 0.2041809727043194]
	TIME [epoch: 27.9 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19752778979907565		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.19752778979907565 | validation: 0.18673036514334868]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_1063.pth
	Model improved!!!
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19114062273575816		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.19114062273575816 | validation: 0.18726759808081705]
	TIME [epoch: 28 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1926603293018291		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.1926603293018291 | validation: 0.18980410798109773]
	TIME [epoch: 27.9 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19235599043952742		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.19235599043952742 | validation: 0.1900527490055709]
	TIME [epoch: 28 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19531043700280748		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.19531043700280748 | validation: 0.19713634330628793]
	TIME [epoch: 27.9 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19724533949374926		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.19724533949374926 | validation: 0.19783953648613156]
	TIME [epoch: 28 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1985087139737424		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.1985087139737424 | validation: 0.197029389544318]
	TIME [epoch: 27.9 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20009447445677658		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.20009447445677658 | validation: 0.20504783593002843]
	TIME [epoch: 28 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19864756473993522		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.19864756473993522 | validation: 0.19763443296634947]
	TIME [epoch: 28 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1988703859633517		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.1988703859633517 | validation: 0.19364385393843642]
	TIME [epoch: 28 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1975141312838645		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.1975141312838645 | validation: 0.21085053243407373]
	TIME [epoch: 27.9 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20712430813601673		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.20712430813601673 | validation: 0.20147242062685639]
	TIME [epoch: 28 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1968335834034874		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.1968335834034874 | validation: 0.19262088599072327]
	TIME [epoch: 27.9 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18961650616451153		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.18961650616451153 | validation: 0.19707205464695704]
	TIME [epoch: 28 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19639416560419434		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.19639416560419434 | validation: 0.20484819396759896]
	TIME [epoch: 27.9 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20868479321068434		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.20868479321068434 | validation: 0.2051563582002909]
	TIME [epoch: 27.9 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20471082414445496		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.20471082414445496 | validation: 0.1958760954783579]
	TIME [epoch: 28 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20138790782109595		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.20138790782109595 | validation: 0.19589016237191337]
	TIME [epoch: 27.9 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20617504283621912		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.20617504283621912 | validation: 0.22224577184594407]
	TIME [epoch: 27.9 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20957613856067092		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.20957613856067092 | validation: 0.18589149445563707]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_1082.pth
	Model improved!!!
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19209622309942648		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.19209622309942648 | validation: 0.18230739845579702]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_1083.pth
	Model improved!!!
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1910695336170671		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.1910695336170671 | validation: 0.1799752140985604]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_1084.pth
	Model improved!!!
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19055483314945856		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.19055483314945856 | validation: 0.18898409375284808]
	TIME [epoch: 27.9 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1834563213625972		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.1834563213625972 | validation: 0.18962077367801022]
	TIME [epoch: 28 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19075275506962858		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.19075275506962858 | validation: 0.1922265402252478]
	TIME [epoch: 28 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19546864767712066		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.19546864767712066 | validation: 0.2047416076902843]
	TIME [epoch: 27.9 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19562148270842855		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.19562148270842855 | validation: 0.20379435063944776]
	TIME [epoch: 28 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19948607288410442		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.19948607288410442 | validation: 0.20853465095548615]
	TIME [epoch: 28 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20863617496187356		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.20863617496187356 | validation: 0.20271766728802662]
	TIME [epoch: 27.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18871480367660223		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.18871480367660223 | validation: 0.1882648179779286]
	TIME [epoch: 28 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18759661875077402		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.18759661875077402 | validation: 0.19399567286838956]
	TIME [epoch: 27.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1890279638955987		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.1890279638955987 | validation: 0.19060104471486405]
	TIME [epoch: 28 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1861186378040422		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.1861186378040422 | validation: 0.18971516659062698]
	TIME [epoch: 28 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18991282298104495		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.18991282298104495 | validation: 0.20056939154690193]
	TIME [epoch: 28 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1988837085262676		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.1988837085262676 | validation: 0.19550992993641203]
	TIME [epoch: 28 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19762842011714965		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.19762842011714965 | validation: 0.19102411004959713]
	TIME [epoch: 27.9 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1946797585094652		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.1946797585094652 | validation: 0.19862206653848646]
	TIME [epoch: 28 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18588544364774204		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.18588544364774204 | validation: 0.18619727068738354]
	TIME [epoch: 28 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.185854164314735		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.185854164314735 | validation: 0.18592805487857086]
	TIME [epoch: 28 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18922955824625168		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.18922955824625168 | validation: 0.2009343846559856]
	TIME [epoch: 28 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1978533753156485		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.1978533753156485 | validation: 0.206320105155761]
	TIME [epoch: 27.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19434669992587772		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.19434669992587772 | validation: 0.18577436879715026]
	TIME [epoch: 28 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18496424032004768		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.18496424032004768 | validation: 0.19162594892105017]
	TIME [epoch: 28 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18181998954636897		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.18181998954636897 | validation: 0.19029632272359556]
	TIME [epoch: 27.9 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1852408261819017		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.1852408261819017 | validation: 0.1853381684774835]
	TIME [epoch: 28 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18663306823825299		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.18663306823825299 | validation: 0.18211871260533918]
	TIME [epoch: 27.9 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18333310808738817		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.18333310808738817 | validation: 0.18762301081955002]
	TIME [epoch: 28 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1817358682830382		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.1817358682830382 | validation: 0.1878551970173156]
	TIME [epoch: 28 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18542875663486022		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.18542875663486022 | validation: 0.16993301730784638]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240310_003029/states/model_tr_study6_1111.pth
	Model improved!!!
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17880361636818698		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.17880361636818698 | validation: 0.18269963101649178]
	TIME [epoch: 28 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1787434660840322		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.1787434660840322 | validation: 0.18020154671101032]
	TIME [epoch: 27.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18186919467432522		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.18186919467432522 | validation: 0.17508981712611724]
	TIME [epoch: 28 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1810781856397396		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.1810781856397396 | validation: 0.19545595329366486]
	TIME [epoch: 28 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.207249034596732		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.207249034596732 | validation: 0.20217622821196443]
	TIME [epoch: 27.9 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20530787988468188		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.20530787988468188 | validation: 0.20411216419732303]
	TIME [epoch: 28 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19646697361930804		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.19646697361930804 | validation: 0.18760184818375158]
	TIME [epoch: 27.9 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18754565601227005		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.18754565601227005 | validation: 0.19394344979660907]
	TIME [epoch: 28 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20182221434118686		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.20182221434118686 | validation: 0.2020397814567494]
	TIME [epoch: 28 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20643216017529215		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.20643216017529215 | validation: 0.21397737024695015]
	TIME [epoch: 27.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20001375806043306		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.20001375806043306 | validation: 0.19708903580660664]
	TIME [epoch: 28 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2094224914407533		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.2094224914407533 | validation: 0.21104311107192225]
	TIME [epoch: 28 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22489484920755015		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.22489484920755015 | validation: 0.2380334286378839]
	TIME [epoch: 27.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2342535913973887		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.2342535913973887 | validation: 0.20944557452365156]
	TIME [epoch: 28 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23098709232149184		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.23098709232149184 | validation: 0.23295873805259862]
	TIME [epoch: 27.9 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25446611603189084		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.25446611603189084 | validation: 0.26747147917521025]
	TIME [epoch: 28 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29373526637291214		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.29373526637291214 | validation: 0.2967138306313228]
	TIME [epoch: 27.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898769676867299		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.2898769676867299 | validation: 0.25334751206540507]
	TIME [epoch: 27.9 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2801583733517452		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.2801583733517452 | validation: 0.2806219304859327]
	TIME [epoch: 27.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856314252138712		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.2856314252138712 | validation: 0.26288959079405233]
	TIME [epoch: 27.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28630636807726706		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.28630636807726706 | validation: 0.27139203503160547]
	TIME [epoch: 28 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2947685456642979		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.2947685456642979 | validation: 0.2813114800072078]
	TIME [epoch: 27.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31503693010428996		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.31503693010428996 | validation: 0.2867536765532643]
	TIME [epoch: 27.9 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2953180232710081		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.2953180232710081 | validation: 0.26398584827144284]
	TIME [epoch: 27.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27480236091605004		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.27480236091605004 | validation: 0.2598253610338667]
	TIME [epoch: 27.9 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26187374878679504		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.26187374878679504 | validation: 0.2552947824969363]
	TIME [epoch: 28 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26267885670427804		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.26267885670427804 | validation: 0.24285040415217005]
	TIME [epoch: 27.9 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2540232311817744		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.2540232311817744 | validation: 0.24500572287257086]
	TIME [epoch: 27.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26607106226299126		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.26607106226299126 | validation: 0.2845301160518618]
	TIME [epoch: 28 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3094317871312244		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.3094317871312244 | validation: 0.2902924065087885]
	TIME [epoch: 27.9 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3035151483154201		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.3035151483154201 | validation: 0.2764968202681615]
	TIME [epoch: 27.9 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28672411257538755		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.28672411257538755 | validation: 0.26229655143891156]
	TIME [epoch: 28 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686612671235364		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.2686612671235364 | validation: 0.2479107288526288]
	TIME [epoch: 27.9 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2629756984472974		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.2629756984472974 | validation: 0.24074680088175462]
	TIME [epoch: 28 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251889604427614		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.251889604427614 | validation: 0.24101608094776325]
	TIME [epoch: 27.9 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25676939972282864		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.25676939972282864 | validation: 0.2447314158502484]
	TIME [epoch: 28 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595315977122926		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.2595315977122926 | validation: 0.25206999321579127]
	TIME [epoch: 28 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2724235396316757		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.2724235396316757 | validation: 0.2643142391766816]
	TIME [epoch: 27.9 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28968898635161666		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.28968898635161666 | validation: 0.27162475200246566]
	TIME [epoch: 28 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2700162978040535		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.2700162978040535 | validation: 0.2615341064582975]
	TIME [epoch: 27.9 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.263633330794094		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.263633330794094 | validation: 0.24052098986274317]
	TIME [epoch: 28 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24331062359708122		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.24331062359708122 | validation: 0.2399445624386975]
	TIME [epoch: 28 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24609360687841822		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.24609360687841822 | validation: 0.23125536735918098]
	TIME [epoch: 27.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24526623277976728		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.24526623277976728 | validation: 0.23565078589383387]
	TIME [epoch: 28 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24134067916589824		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.24134067916589824 | validation: 0.2531613292037006]
	TIME [epoch: 27.9 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2691082426393532		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.2691082426393532 | validation: 0.2552185243861052]
	TIME [epoch: 27.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28546780202670385		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.28546780202670385 | validation: 0.2915584434762623]
	TIME [epoch: 28 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3043290875520481		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.3043290875520481 | validation: 0.27518537025801854]
	TIME [epoch: 27.9 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2765336361855811		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.2765336361855811 | validation: 0.2589088429367511]
	TIME [epoch: 28 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26477516588451794		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.26477516588451794 | validation: 0.2460405995696037]
	TIME [epoch: 27.9 sec]
EPOCH 1162/2000:
	Training over batches...
